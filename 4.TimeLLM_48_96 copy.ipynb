{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. TimeLLM](#1-timellm)\n",
    "- [2. TimeLLM](#2-timellm-336)\n",
    "\n",
    "Results for TimeLLM. The first one is default input length 512, the second one: 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"2\"\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['FR', 'IT']\n",
    "num_cols = [3, 3]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TimeLLM 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"TimeLLM\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32\n",
    "\n",
    "# List to store the results\n",
    "timellm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 86835\n",
      "val 18651\n",
      "test 18651\n",
      "[2024-11-05 17:33:50,243] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 17:33:51,233] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 17:33:51,234] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 17:33:51,234] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 17:33:51,328] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 17:33:51,328] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 17:33:51,979] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 17:33:51,980] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 17:33:51,980] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 17:33:51,982] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 17:33:51,982] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 17:33:51,982] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 17:33:51,982] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 17:33:51,982] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 17:33:51,982] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 17:33:51,982] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 17:33:52,307] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 17:33:52,308] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 17:33:52,308] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 276.29 GB, percent = 36.6%\n",
      "[2024-11-05 17:33:52,443] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 17:33:52,444] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 17:33:52,444] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 276.26 GB, percent = 36.6%\n",
      "[2024-11-05 17:33:52,444] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 17:33:52,557] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 17:33:52,558] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 17:33:52,558] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 276.26 GB, percent = 36.6%\n",
      "[2024-11-05 17:33:52,559] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 17:33:52,559] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 17:33:52,559] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 17:33:52,559] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 17:33:52,560] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 17:33:52,560] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 17:33:52,560] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1fe9929b10>\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 17:33:52,561] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 17:33:52,562] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 17:33:52,563] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1354474\n",
      "\tspeed: 0.1666s/iter; left time: 9022.5500s\n",
      "\titers: 200, epoch: 1 | loss: 0.1104270\n",
      "\tspeed: 0.1237s/iter; left time: 6689.7671s\n",
      "\titers: 300, epoch: 1 | loss: 0.0970104\n",
      "\tspeed: 0.1235s/iter; left time: 6664.9546s\n",
      "\titers: 400, epoch: 1 | loss: 0.0873522\n",
      "\tspeed: 0.1222s/iter; left time: 6582.2624s\n",
      "\titers: 500, epoch: 1 | loss: 0.0952150\n",
      "\tspeed: 0.1250s/iter; left time: 6719.3572s\n",
      "\titers: 600, epoch: 1 | loss: 0.0775518\n",
      "\tspeed: 0.1271s/iter; left time: 6821.0284s\n",
      "\titers: 700, epoch: 1 | loss: 0.0573632\n",
      "\tspeed: 0.1226s/iter; left time: 6566.7995s\n",
      "\titers: 800, epoch: 1 | loss: 0.0748523\n",
      "\tspeed: 0.1216s/iter; left time: 6498.3629s\n",
      "\titers: 900, epoch: 1 | loss: 0.0780433\n",
      "\tspeed: 0.1215s/iter; left time: 6480.8660s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0557578\n",
      "\tspeed: 0.1213s/iter; left time: 6460.0312s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0642440\n",
      "\tspeed: 0.1221s/iter; left time: 6493.2537s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0581125\n",
      "\tspeed: 0.1216s/iter; left time: 6453.2522s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0653733\n",
      "\tspeed: 0.1263s/iter; left time: 6691.2688s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0488294\n",
      "\tspeed: 0.1237s/iter; left time: 6538.8856s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0503552\n",
      "\tspeed: 0.1224s/iter; left time: 6456.8807s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0823918\n",
      "\tspeed: 0.1218s/iter; left time: 6416.0704s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0652934\n",
      "\tspeed: 0.1219s/iter; left time: 6408.4328s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0500252\n",
      "\tspeed: 0.1219s/iter; left time: 6396.1075s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0572330\n",
      "\tspeed: 0.1268s/iter; left time: 6640.6743s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0619874\n",
      "\tspeed: 0.1198s/iter; left time: 6261.4817s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0681035\n",
      "\tspeed: 0.1217s/iter; left time: 6349.6221s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0608845\n",
      "\tspeed: 0.1264s/iter; left time: 6582.5667s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0644549\n",
      "\tspeed: 0.1228s/iter; left time: 6383.2854s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0775569\n",
      "\tspeed: 0.1184s/iter; left time: 6142.2885s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0627126\n",
      "\tspeed: 0.1230s/iter; left time: 6366.4997s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0516025\n",
      "\tspeed: 0.1221s/iter; left time: 6305.4119s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0530432\n",
      "\tspeed: 0.0982s/iter; left time: 5065.7611s\n",
      "Epoch: 1 cost time: 00h:05m:31.96s\n",
      "Epoch: 1 | Train Loss: 0.0728902 Vali Loss: 0.0621570 Test Loss: 0.0659448\n",
      "Validation loss decreased (inf --> 0.062157).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0542284\n",
      "\tspeed: 0.8965s/iter; left time: 46121.4560s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670467\n",
      "\tspeed: 0.0905s/iter; left time: 4647.4782s\n",
      "\titers: 300, epoch: 2 | loss: 0.0648869\n",
      "\tspeed: 0.0788s/iter; left time: 4040.7958s\n",
      "\titers: 400, epoch: 2 | loss: 0.0566343\n",
      "\tspeed: 0.0797s/iter; left time: 4077.7240s\n",
      "\titers: 500, epoch: 2 | loss: 0.0552219\n",
      "\tspeed: 0.0875s/iter; left time: 4465.0586s\n",
      "\titers: 600, epoch: 2 | loss: 0.0683327\n",
      "\tspeed: 0.0902s/iter; left time: 4594.0719s\n",
      "\titers: 700, epoch: 2 | loss: 0.0712316\n",
      "\tspeed: 0.0832s/iter; left time: 4229.3016s\n",
      "\titers: 800, epoch: 2 | loss: 0.0804125\n",
      "\tspeed: 0.0837s/iter; left time: 4249.9734s\n",
      "\titers: 900, epoch: 2 | loss: 0.0530134\n",
      "\tspeed: 0.0795s/iter; left time: 4025.6659s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0582712\n",
      "\tspeed: 0.0840s/iter; left time: 4243.5174s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0622718\n",
      "\tspeed: 0.0904s/iter; left time: 4558.4273s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0549985\n",
      "\tspeed: 0.0853s/iter; left time: 4292.5095s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0656118\n",
      "\tspeed: 0.0811s/iter; left time: 4073.8659s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0517154\n",
      "\tspeed: 0.0809s/iter; left time: 4055.6803s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0427679\n",
      "\tspeed: 0.0908s/iter; left time: 4545.8725s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0651983\n",
      "\tspeed: 0.0974s/iter; left time: 4863.9017s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0515183\n",
      "\tspeed: 0.0821s/iter; left time: 4094.2494s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0569872\n",
      "\tspeed: 0.0796s/iter; left time: 3958.1849s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0680767\n",
      "\tspeed: 0.0879s/iter; left time: 4362.4712s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0464256\n",
      "\tspeed: 0.0845s/iter; left time: 4186.4011s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0640577\n",
      "\tspeed: 0.0889s/iter; left time: 4394.3154s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0648689\n",
      "\tspeed: 0.0972s/iter; left time: 4794.5783s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0449513\n",
      "\tspeed: 0.0890s/iter; left time: 4381.4988s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0613574\n",
      "\tspeed: 0.0910s/iter; left time: 4472.5628s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0518990\n",
      "\tspeed: 0.0848s/iter; left time: 4161.4554s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0474766\n",
      "\tspeed: 0.0876s/iter; left time: 4290.0066s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0680457\n",
      "\tspeed: 0.0950s/iter; left time: 4639.2748s\n",
      "Epoch: 2 cost time: 00h:03m:55.07s\n",
      "Epoch: 2 | Train Loss: 0.0595214 Vali Loss: 0.0592604 Test Loss: 0.0632206\n",
      "Validation loss decreased (0.062157 --> 0.059260).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0527481\n",
      "\tspeed: 0.7370s/iter; left time: 35919.9381s\n",
      "\titers: 200, epoch: 3 | loss: 0.0537563\n",
      "\tspeed: 0.0985s/iter; left time: 4790.6901s\n",
      "\titers: 300, epoch: 3 | loss: 0.0542177\n",
      "\tspeed: 0.0893s/iter; left time: 4336.1385s\n",
      "\titers: 400, epoch: 3 | loss: 0.0633696\n",
      "\tspeed: 0.0838s/iter; left time: 4059.5191s\n",
      "\titers: 500, epoch: 3 | loss: 0.0534021\n",
      "\tspeed: 0.0828s/iter; left time: 4003.6351s\n",
      "\titers: 600, epoch: 3 | loss: 0.0545771\n",
      "\tspeed: 0.0850s/iter; left time: 4098.7223s\n",
      "\titers: 700, epoch: 3 | loss: 0.0464762\n",
      "\tspeed: 0.0858s/iter; left time: 4129.9910s\n",
      "\titers: 800, epoch: 3 | loss: 0.0627529\n",
      "\tspeed: 0.0916s/iter; left time: 4400.3987s\n",
      "\titers: 900, epoch: 3 | loss: 0.0454887\n",
      "\tspeed: 0.0931s/iter; left time: 4463.3470s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0584920\n",
      "\tspeed: 0.0868s/iter; left time: 4152.6850s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0574579\n",
      "\tspeed: 0.0869s/iter; left time: 4145.8226s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0545672\n",
      "\tspeed: 0.0922s/iter; left time: 4391.7270s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0527900\n",
      "\tspeed: 0.0923s/iter; left time: 4389.1748s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0470590\n",
      "\tspeed: 0.0856s/iter; left time: 4059.2545s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0458568\n",
      "\tspeed: 0.0900s/iter; left time: 4259.7432s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0699025\n",
      "\tspeed: 0.0890s/iter; left time: 4201.7763s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0668973\n",
      "\tspeed: 0.0847s/iter; left time: 3993.5367s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0553001\n",
      "\tspeed: 0.0911s/iter; left time: 4286.1169s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0509166\n",
      "\tspeed: 0.0890s/iter; left time: 4179.2301s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0639876\n",
      "\tspeed: 0.0885s/iter; left time: 4144.6312s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0520401\n",
      "\tspeed: 0.0897s/iter; left time: 4194.2350s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0500856\n",
      "\tspeed: 0.0963s/iter; left time: 4488.7959s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0568108\n",
      "\tspeed: 0.0762s/iter; left time: 3544.4891s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0540239\n",
      "\tspeed: 0.0871s/iter; left time: 4044.9905s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0509569\n",
      "\tspeed: 0.0902s/iter; left time: 4179.4435s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0659207\n",
      "\tspeed: 0.0820s/iter; left time: 3791.0477s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0683112\n",
      "\tspeed: 0.0959s/iter; left time: 4424.9084s\n",
      "Epoch: 3 cost time: 00h:03m:59.83s\n",
      "Epoch: 3 | Train Loss: 0.0574231 Vali Loss: 0.0575017 Test Loss: 0.0612840\n",
      "Validation loss decreased (0.059260 --> 0.057502).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0781622\n",
      "\tspeed: 0.7648s/iter; left time: 35196.9393s\n",
      "\titers: 200, epoch: 4 | loss: 0.0560807\n",
      "\tspeed: 0.0882s/iter; left time: 4048.0845s\n",
      "\titers: 300, epoch: 4 | loss: 0.0589079\n",
      "\tspeed: 0.0836s/iter; left time: 3831.8881s\n",
      "\titers: 400, epoch: 4 | loss: 0.0561776\n",
      "\tspeed: 0.0876s/iter; left time: 4005.0217s\n",
      "\titers: 500, epoch: 4 | loss: 0.0670672\n",
      "\tspeed: 0.0871s/iter; left time: 3972.7931s\n",
      "\titers: 600, epoch: 4 | loss: 0.0503391\n",
      "\tspeed: 0.0766s/iter; left time: 3487.7376s\n",
      "\titers: 700, epoch: 4 | loss: 0.0583979\n",
      "\tspeed: 0.0881s/iter; left time: 4002.8022s\n",
      "\titers: 800, epoch: 4 | loss: 0.0665963\n",
      "\tspeed: 0.0929s/iter; left time: 4209.1403s\n",
      "\titers: 900, epoch: 4 | loss: 0.0550917\n",
      "\tspeed: 0.0953s/iter; left time: 4308.2435s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0679721\n",
      "\tspeed: 0.0897s/iter; left time: 4048.0075s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0764208\n",
      "\tspeed: 0.0841s/iter; left time: 3786.0659s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0676172\n",
      "\tspeed: 0.1138s/iter; left time: 5110.1732s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0591371\n",
      "\tspeed: 0.1123s/iter; left time: 5034.3154s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0634342\n",
      "\tspeed: 0.1098s/iter; left time: 4911.1543s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0473038\n",
      "\tspeed: 0.1065s/iter; left time: 4752.9182s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0534925\n",
      "\tspeed: 0.1119s/iter; left time: 4983.9196s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0474229\n",
      "\tspeed: 0.1154s/iter; left time: 5124.4663s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0530520\n",
      "\tspeed: 0.1188s/iter; left time: 5267.2975s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0509128\n",
      "\tspeed: 0.1106s/iter; left time: 4890.0498s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0509156\n",
      "\tspeed: 0.1072s/iter; left time: 4730.9409s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0578413\n",
      "\tspeed: 0.1114s/iter; left time: 4905.8343s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0589333\n",
      "\tspeed: 0.1114s/iter; left time: 4891.5140s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0512787\n",
      "\tspeed: 0.1101s/iter; left time: 4826.4839s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0698794\n",
      "\tspeed: 0.1132s/iter; left time: 4949.1344s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0507337\n",
      "\tspeed: 0.1156s/iter; left time: 5041.8380s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0569324\n",
      "\tspeed: 0.1161s/iter; left time: 5050.9102s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0545301\n",
      "\tspeed: 0.1160s/iter; left time: 5038.8962s\n",
      "Epoch: 4 cost time: 00h:04m:37.01s\n",
      "Epoch: 4 | Train Loss: 0.0560099 Vali Loss: 0.0569086 Test Loss: 0.0609416\n",
      "Validation loss decreased (0.057502 --> 0.056909).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0523451\n",
      "\tspeed: 0.8788s/iter; left time: 38059.5831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0497674\n",
      "\tspeed: 0.1103s/iter; left time: 4764.7741s\n",
      "\titers: 300, epoch: 5 | loss: 0.0677950\n",
      "\tspeed: 0.1140s/iter; left time: 4915.4661s\n",
      "\titers: 400, epoch: 5 | loss: 0.0410538\n",
      "\tspeed: 0.1141s/iter; left time: 4909.2596s\n",
      "\titers: 500, epoch: 5 | loss: 0.0496694\n",
      "\tspeed: 0.1174s/iter; left time: 5038.4478s\n",
      "\titers: 600, epoch: 5 | loss: 0.0560091\n",
      "\tspeed: 0.1119s/iter; left time: 4789.3662s\n",
      "\titers: 700, epoch: 5 | loss: 0.0574259\n",
      "\tspeed: 0.1126s/iter; left time: 4807.6724s\n",
      "\titers: 800, epoch: 5 | loss: 0.0590554\n",
      "\tspeed: 0.1072s/iter; left time: 4569.6309s\n",
      "\titers: 900, epoch: 5 | loss: 0.0660535\n",
      "\tspeed: 0.1018s/iter; left time: 4325.5992s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0557318\n",
      "\tspeed: 0.1116s/iter; left time: 4730.7549s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0514192\n",
      "\tspeed: 0.1134s/iter; left time: 4797.8104s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0523998\n",
      "\tspeed: 0.1138s/iter; left time: 4805.1339s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0702193\n",
      "\tspeed: 0.1106s/iter; left time: 4657.2852s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0504459\n",
      "\tspeed: 0.1110s/iter; left time: 4665.0821s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0524809\n",
      "\tspeed: 0.1135s/iter; left time: 4757.0242s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0419785\n",
      "\tspeed: 0.1137s/iter; left time: 4753.0507s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0602485\n",
      "\tspeed: 0.1117s/iter; left time: 4660.1585s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0465609\n",
      "\tspeed: 0.1138s/iter; left time: 4735.2570s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0668926\n",
      "\tspeed: 0.1192s/iter; left time: 4949.3840s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0561600\n",
      "\tspeed: 0.1169s/iter; left time: 4839.2758s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0525165\n",
      "\tspeed: 0.1085s/iter; left time: 4480.7588s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0475404\n",
      "\tspeed: 0.1145s/iter; left time: 4718.2912s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0609381\n",
      "\tspeed: 0.1115s/iter; left time: 4585.1428s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0569825\n",
      "\tspeed: 0.1118s/iter; left time: 4585.0923s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0503497\n",
      "\tspeed: 0.1086s/iter; left time: 4443.0813s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0623354\n",
      "\tspeed: 0.1145s/iter; left time: 4672.3651s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0581161\n",
      "\tspeed: 0.1110s/iter; left time: 4519.2724s\n",
      "Epoch: 5 cost time: 00h:05m:04.50s\n",
      "Epoch: 5 | Train Loss: 0.0549737 Vali Loss: 0.0551702 Test Loss: 0.0595538\n",
      "Validation loss decreased (0.056909 --> 0.055170).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0640795\n",
      "\tspeed: 0.8758s/iter; left time: 35555.0643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0591650\n",
      "\tspeed: 0.1126s/iter; left time: 4558.2917s\n",
      "\titers: 300, epoch: 6 | loss: 0.0403310\n",
      "\tspeed: 0.1095s/iter; left time: 4423.3636s\n",
      "\titers: 400, epoch: 6 | loss: 0.0585927\n",
      "\tspeed: 0.1077s/iter; left time: 4338.7252s\n",
      "\titers: 500, epoch: 6 | loss: 0.0706630\n",
      "\tspeed: 0.1057s/iter; left time: 4247.9175s\n",
      "\titers: 600, epoch: 6 | loss: 0.0629400\n",
      "\tspeed: 0.1145s/iter; left time: 4592.2383s\n",
      "\titers: 700, epoch: 6 | loss: 0.0465301\n",
      "\tspeed: 0.1091s/iter; left time: 4361.6979s\n",
      "\titers: 800, epoch: 6 | loss: 0.0500698\n",
      "\tspeed: 0.1164s/iter; left time: 4642.5301s\n",
      "\titers: 900, epoch: 6 | loss: 0.0374198\n",
      "\tspeed: 0.1128s/iter; left time: 4488.3621s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0572367\n",
      "\tspeed: 0.1114s/iter; left time: 4423.8307s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0585453\n",
      "\tspeed: 0.1125s/iter; left time: 4455.6604s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0552741\n",
      "\tspeed: 0.1159s/iter; left time: 4577.2766s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0588804\n",
      "\tspeed: 0.1115s/iter; left time: 4394.1562s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0558417\n",
      "\tspeed: 0.1113s/iter; left time: 4374.4470s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0464093\n",
      "\tspeed: 0.1108s/iter; left time: 4343.8093s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0549806\n",
      "\tspeed: 0.1112s/iter; left time: 4349.0345s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0530618\n",
      "\tspeed: 0.1080s/iter; left time: 4211.6033s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0517453\n",
      "\tspeed: 0.1144s/iter; left time: 4450.1429s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0441919\n",
      "\tspeed: 0.1174s/iter; left time: 4555.6554s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0632877\n",
      "\tspeed: 0.1167s/iter; left time: 4514.3296s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0537774\n",
      "\tspeed: 0.1137s/iter; left time: 4387.9013s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0450462\n",
      "\tspeed: 0.1113s/iter; left time: 4283.3146s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0424794\n",
      "\tspeed: 0.1159s/iter; left time: 4448.6077s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0694882\n",
      "\tspeed: 0.1158s/iter; left time: 4435.0225s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0587732\n",
      "\tspeed: 0.1104s/iter; left time: 4218.6104s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0412575\n",
      "\tspeed: 0.1111s/iter; left time: 4234.1367s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0436005\n",
      "\tspeed: 0.1118s/iter; left time: 4248.1620s\n",
      "Epoch: 6 cost time: 00h:05m:05.58s\n",
      "Epoch: 6 | Train Loss: 0.0540165 Vali Loss: 0.0547559 Test Loss: 0.0589155\n",
      "Validation loss decreased (0.055170 --> 0.054756).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0437865\n",
      "\tspeed: 0.8670s/iter; left time: 32845.4185s\n",
      "\titers: 200, epoch: 7 | loss: 0.0635800\n",
      "\tspeed: 0.1067s/iter; left time: 4033.1296s\n",
      "\titers: 300, epoch: 7 | loss: 0.0539604\n",
      "\tspeed: 0.1076s/iter; left time: 4053.5285s\n",
      "\titers: 400, epoch: 7 | loss: 0.0468464\n",
      "\tspeed: 0.1080s/iter; left time: 4058.3971s\n",
      "\titers: 500, epoch: 7 | loss: 0.0673882\n",
      "\tspeed: 0.1125s/iter; left time: 4217.6831s\n",
      "\titers: 600, epoch: 7 | loss: 0.0433701\n",
      "\tspeed: 0.1135s/iter; left time: 4242.8985s\n",
      "\titers: 700, epoch: 7 | loss: 0.0496241\n",
      "\tspeed: 0.1110s/iter; left time: 4137.6178s\n",
      "\titers: 800, epoch: 7 | loss: 0.0539288\n",
      "\tspeed: 0.1139s/iter; left time: 4236.1734s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559073\n",
      "\tspeed: 0.1187s/iter; left time: 4403.1869s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0429134\n",
      "\tspeed: 0.1098s/iter; left time: 4059.5357s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0474347\n",
      "\tspeed: 0.1103s/iter; left time: 4069.6839s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0658824\n",
      "\tspeed: 0.1164s/iter; left time: 4280.4749s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0500594\n",
      "\tspeed: 0.1167s/iter; left time: 4280.9729s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0414436\n",
      "\tspeed: 0.1141s/iter; left time: 4174.5856s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0401539\n",
      "\tspeed: 0.1158s/iter; left time: 4225.9008s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0647994\n",
      "\tspeed: 0.1180s/iter; left time: 4291.6219s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0431331\n",
      "\tspeed: 0.1136s/iter; left time: 4121.4731s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0427611\n",
      "\tspeed: 0.1138s/iter; left time: 4116.6595s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0491915\n",
      "\tspeed: 0.1125s/iter; left time: 4060.3119s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0504405\n",
      "\tspeed: 0.1120s/iter; left time: 4029.4071s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0658533\n",
      "\tspeed: 0.1149s/iter; left time: 4121.9120s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0528282\n",
      "\tspeed: 0.1140s/iter; left time: 4077.9187s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0440166\n",
      "\tspeed: 0.1155s/iter; left time: 4122.9186s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0523644\n",
      "\tspeed: 0.1117s/iter; left time: 3973.0087s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0418222\n",
      "\tspeed: 0.1147s/iter; left time: 4068.3144s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0577403\n",
      "\tspeed: 0.1117s/iter; left time: 3953.7638s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0498971\n",
      "\tspeed: 0.1114s/iter; left time: 3929.0427s\n",
      "Epoch: 7 cost time: 00h:05m:06.71s\n",
      "Epoch: 7 | Train Loss: 0.0532535 Vali Loss: 0.0542020 Test Loss: 0.0582736\n",
      "Validation loss decreased (0.054756 --> 0.054202).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0573966\n",
      "\tspeed: 0.8794s/iter; left time: 30928.6049s\n",
      "\titers: 200, epoch: 8 | loss: 0.0378367\n",
      "\tspeed: 0.1121s/iter; left time: 3930.6411s\n",
      "\titers: 300, epoch: 8 | loss: 0.0562231\n",
      "\tspeed: 0.1197s/iter; left time: 4187.4986s\n",
      "\titers: 400, epoch: 8 | loss: 0.0488417\n",
      "\tspeed: 0.1107s/iter; left time: 3859.4953s\n",
      "\titers: 500, epoch: 8 | loss: 0.0503265\n",
      "\tspeed: 0.1115s/iter; left time: 3877.8209s\n",
      "\titers: 600, epoch: 8 | loss: 0.0405856\n",
      "\tspeed: 0.1113s/iter; left time: 3858.0169s\n",
      "\titers: 700, epoch: 8 | loss: 0.0551430\n",
      "\tspeed: 0.1119s/iter; left time: 3869.9414s\n",
      "\titers: 800, epoch: 8 | loss: 0.0555346\n",
      "\tspeed: 0.1081s/iter; left time: 3726.7275s\n",
      "\titers: 900, epoch: 8 | loss: 0.0408218\n",
      "\tspeed: 0.1116s/iter; left time: 3834.8020s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0541077\n",
      "\tspeed: 0.1113s/iter; left time: 3814.5766s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0542165\n",
      "\tspeed: 0.1174s/iter; left time: 4010.2359s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0430974\n",
      "\tspeed: 0.1135s/iter; left time: 3867.0124s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0546644\n",
      "\tspeed: 0.1075s/iter; left time: 3652.4791s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0473207\n",
      "\tspeed: 0.1051s/iter; left time: 3558.7666s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0554659\n",
      "\tspeed: 0.1148s/iter; left time: 3876.2012s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0602234\n",
      "\tspeed: 0.1143s/iter; left time: 3848.6557s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0496314\n",
      "\tspeed: 0.1135s/iter; left time: 3811.2164s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0466059\n",
      "\tspeed: 0.1135s/iter; left time: 3799.3220s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0463335\n",
      "\tspeed: 0.1078s/iter; left time: 3597.7205s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0426725\n",
      "\tspeed: 0.1153s/iter; left time: 3835.3375s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0589549\n",
      "\tspeed: 0.1155s/iter; left time: 3829.7955s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0500997\n",
      "\tspeed: 0.1140s/iter; left time: 3771.2343s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0411206\n",
      "\tspeed: 0.1050s/iter; left time: 3462.2980s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0632741\n",
      "\tspeed: 0.1110s/iter; left time: 3649.2562s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0388545\n",
      "\tspeed: 0.1116s/iter; left time: 3656.6582s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0507245\n",
      "\tspeed: 0.1089s/iter; left time: 3557.9631s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0499838\n",
      "\tspeed: 0.1099s/iter; left time: 3580.1632s\n",
      "Epoch: 8 cost time: 00h:05m:03.86s\n",
      "Epoch: 8 | Train Loss: 0.0526945 Vali Loss: 0.0546429 Test Loss: 0.0590354\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0452876\n",
      "\tspeed: 0.8609s/iter; left time: 27942.1554s\n",
      "\titers: 200, epoch: 9 | loss: 0.0480845\n",
      "\tspeed: 0.1119s/iter; left time: 3622.3323s\n",
      "\titers: 300, epoch: 9 | loss: 0.0544482\n",
      "\tspeed: 0.1167s/iter; left time: 3765.9914s\n",
      "\titers: 400, epoch: 9 | loss: 0.0746930\n",
      "\tspeed: 0.1140s/iter; left time: 3665.9921s\n",
      "\titers: 500, epoch: 9 | loss: 0.0501334\n",
      "\tspeed: 0.1062s/iter; left time: 3403.8328s\n",
      "\titers: 600, epoch: 9 | loss: 0.0635273\n",
      "\tspeed: 0.0951s/iter; left time: 3039.0421s\n",
      "\titers: 700, epoch: 9 | loss: 0.0512731\n",
      "\tspeed: 0.1140s/iter; left time: 3630.3818s\n",
      "\titers: 800, epoch: 9 | loss: 0.0456901\n",
      "\tspeed: 0.1153s/iter; left time: 3661.0661s\n",
      "\titers: 900, epoch: 9 | loss: 0.0357962\n",
      "\tspeed: 0.1097s/iter; left time: 3473.5149s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0669423\n",
      "\tspeed: 0.1145s/iter; left time: 3613.4281s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0517661\n",
      "\tspeed: 0.1155s/iter; left time: 3634.1604s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0524863\n",
      "\tspeed: 0.1156s/iter; left time: 3625.0207s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0638670\n",
      "\tspeed: 0.1197s/iter; left time: 3741.6601s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0642590\n",
      "\tspeed: 0.1070s/iter; left time: 3333.3228s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0405757\n",
      "\tspeed: 0.1149s/iter; left time: 3568.8392s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0553760\n",
      "\tspeed: 0.0972s/iter; left time: 3008.8442s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0406495\n",
      "\tspeed: 0.1122s/iter; left time: 3460.9885s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0517201\n",
      "\tspeed: 0.1133s/iter; left time: 3483.5439s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0603963\n",
      "\tspeed: 0.1125s/iter; left time: 3449.4380s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0596839\n",
      "\tspeed: 0.1134s/iter; left time: 3464.6330s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0531674\n",
      "\tspeed: 0.1107s/iter; left time: 3372.7647s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0617280\n",
      "\tspeed: 0.0953s/iter; left time: 2891.6842s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0490168\n",
      "\tspeed: 0.1106s/iter; left time: 3346.1116s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0517670\n",
      "\tspeed: 0.1123s/iter; left time: 3387.9349s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0449308\n",
      "\tspeed: 0.1099s/iter; left time: 3304.4494s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0445644\n",
      "\tspeed: 0.1110s/iter; left time: 3326.4706s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0493163\n",
      "\tspeed: 0.1117s/iter; left time: 3334.1486s\n",
      "Epoch: 9 cost time: 00h:05m:01.33s\n",
      "Epoch: 9 | Train Loss: 0.0521549 Vali Loss: 0.0539455 Test Loss: 0.0584838\n",
      "Validation loss decreased (0.054202 --> 0.053945).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0550047\n",
      "\tspeed: 0.8810s/iter; left time: 26203.6562s\n",
      "\titers: 200, epoch: 10 | loss: 0.0475402\n",
      "\tspeed: 0.1121s/iter; left time: 3323.8581s\n",
      "\titers: 300, epoch: 10 | loss: 0.0488127\n",
      "\tspeed: 0.1108s/iter; left time: 3274.1374s\n",
      "\titers: 400, epoch: 10 | loss: 0.0480546\n",
      "\tspeed: 0.0995s/iter; left time: 2930.8588s\n",
      "\titers: 500, epoch: 10 | loss: 0.0767341\n",
      "\tspeed: 0.1068s/iter; left time: 3135.1872s\n",
      "\titers: 600, epoch: 10 | loss: 0.0561193\n",
      "\tspeed: 0.1125s/iter; left time: 3291.0663s\n",
      "\titers: 700, epoch: 10 | loss: 0.0496133\n",
      "\tspeed: 0.1105s/iter; left time: 3220.1261s\n",
      "\titers: 800, epoch: 10 | loss: 0.0508256\n",
      "\tspeed: 0.1120s/iter; left time: 3252.1192s\n",
      "\titers: 900, epoch: 10 | loss: 0.0678400\n",
      "\tspeed: 0.1092s/iter; left time: 3160.3232s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0481478\n",
      "\tspeed: 0.1114s/iter; left time: 3213.8952s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0505144\n",
      "\tspeed: 0.1106s/iter; left time: 3178.8874s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0530811\n",
      "\tspeed: 0.0986s/iter; left time: 2825.6260s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0448338\n",
      "\tspeed: 0.0927s/iter; left time: 2647.0417s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0473159\n",
      "\tspeed: 0.1053s/iter; left time: 2996.1908s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0576004\n",
      "\tspeed: 0.1080s/iter; left time: 3061.9146s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0600859\n",
      "\tspeed: 0.1122s/iter; left time: 3167.7441s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0436083\n",
      "\tspeed: 0.1158s/iter; left time: 3259.9622s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0549228\n",
      "\tspeed: 0.1162s/iter; left time: 3257.4467s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0522889\n",
      "\tspeed: 0.1085s/iter; left time: 3031.6704s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0441791\n",
      "\tspeed: 0.1109s/iter; left time: 3087.1314s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0370428\n",
      "\tspeed: 0.1085s/iter; left time: 3011.0220s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0543491\n",
      "\tspeed: 0.1084s/iter; left time: 2997.4286s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0456150\n",
      "\tspeed: 0.1032s/iter; left time: 2843.9120s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0533350\n",
      "\tspeed: 0.1119s/iter; left time: 3070.6736s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0417818\n",
      "\tspeed: 0.1116s/iter; left time: 3052.1970s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0665143\n",
      "\tspeed: 0.1079s/iter; left time: 2939.7485s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0492287\n",
      "\tspeed: 0.1103s/iter; left time: 2995.0917s\n",
      "Epoch: 10 cost time: 00h:04m:55.56s\n",
      "Epoch: 10 | Train Loss: 0.0517371 Vali Loss: 0.0541538 Test Loss: 0.0582333\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0495415\n",
      "\tspeed: 0.8578s/iter; left time: 23188.0945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0639661\n",
      "\tspeed: 0.1113s/iter; left time: 2998.7591s\n",
      "\titers: 300, epoch: 11 | loss: 0.0394840\n",
      "\tspeed: 0.1114s/iter; left time: 2990.0007s\n",
      "\titers: 400, epoch: 11 | loss: 0.0479258\n",
      "\tspeed: 0.1121s/iter; left time: 2997.0617s\n",
      "\titers: 500, epoch: 11 | loss: 0.0605572\n",
      "\tspeed: 0.1107s/iter; left time: 2948.3803s\n",
      "\titers: 600, epoch: 11 | loss: 0.0410986\n",
      "\tspeed: 0.1113s/iter; left time: 2952.7931s\n",
      "\titers: 700, epoch: 11 | loss: 0.0496964\n",
      "\tspeed: 0.1127s/iter; left time: 2977.5756s\n",
      "\titers: 800, epoch: 11 | loss: 0.0561572\n",
      "\tspeed: 0.1109s/iter; left time: 2919.9113s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498041\n",
      "\tspeed: 0.1110s/iter; left time: 2911.8614s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0640917\n",
      "\tspeed: 0.1110s/iter; left time: 2899.4644s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0404759\n",
      "\tspeed: 0.1127s/iter; left time: 2934.8064s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0475856\n",
      "\tspeed: 0.1108s/iter; left time: 2872.3935s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0453046\n",
      "\tspeed: 0.1120s/iter; left time: 2891.7917s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0415090\n",
      "\tspeed: 0.1117s/iter; left time: 2874.5034s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0474752\n",
      "\tspeed: 0.1124s/iter; left time: 2880.1275s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.1113s/iter; left time: 2840.6769s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0548703\n",
      "\tspeed: 0.1143s/iter; left time: 2906.0152s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0471928\n",
      "\tspeed: 0.1144s/iter; left time: 2899.0478s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0565440\n",
      "\tspeed: 0.1118s/iter; left time: 2821.8639s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0390263\n",
      "\tspeed: 0.1102s/iter; left time: 2768.7369s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0482574\n",
      "\tspeed: 0.1081s/iter; left time: 2706.8978s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0472797\n",
      "\tspeed: 0.0947s/iter; left time: 2361.0924s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0409271\n",
      "\tspeed: 0.1045s/iter; left time: 2595.2813s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0562022\n",
      "\tspeed: 0.1109s/iter; left time: 2741.7237s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0520623\n",
      "\tspeed: 0.1104s/iter; left time: 2719.8567s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0492270\n",
      "\tspeed: 0.1114s/iter; left time: 2732.3784s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0518520\n",
      "\tspeed: 0.1108s/iter; left time: 2706.2065s\n",
      "Epoch: 11 cost time: 00h:05m:00.34s\n",
      "Epoch: 11 | Train Loss: 0.0514131 Vali Loss: 0.0529610 Test Loss: 0.0576995\n",
      "Validation loss decreased (0.053945 --> 0.052961).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0502807\n",
      "\tspeed: 0.8948s/iter; left time: 21760.6514s\n",
      "\titers: 200, epoch: 12 | loss: 0.0557354\n",
      "\tspeed: 0.1118s/iter; left time: 2706.9977s\n",
      "\titers: 300, epoch: 12 | loss: 0.0386777\n",
      "\tspeed: 0.1135s/iter; left time: 2736.9395s\n",
      "\titers: 400, epoch: 12 | loss: 0.0553932\n",
      "\tspeed: 0.1133s/iter; left time: 2720.2545s\n",
      "\titers: 500, epoch: 12 | loss: 0.0378364\n",
      "\tspeed: 0.1121s/iter; left time: 2682.2442s\n",
      "\titers: 600, epoch: 12 | loss: 0.0540264\n",
      "\tspeed: 0.1103s/iter; left time: 2627.6801s\n",
      "\titers: 700, epoch: 12 | loss: 0.0621938\n",
      "\tspeed: 0.1129s/iter; left time: 2678.5099s\n",
      "\titers: 800, epoch: 12 | loss: 0.0448379\n",
      "\tspeed: 0.1078s/iter; left time: 2546.1947s\n",
      "\titers: 900, epoch: 12 | loss: 0.0561696\n",
      "\tspeed: 0.1133s/iter; left time: 2664.4799s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0486420\n",
      "\tspeed: 0.1120s/iter; left time: 2623.9261s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0610481\n",
      "\tspeed: 0.1108s/iter; left time: 2584.1043s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0372218\n",
      "\tspeed: 0.1112s/iter; left time: 2581.0559s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0546993\n",
      "\tspeed: 0.1109s/iter; left time: 2564.5606s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0634329\n",
      "\tspeed: 0.1119s/iter; left time: 2574.9179s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0394930\n",
      "\tspeed: 0.1127s/iter; left time: 2582.5888s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0403461\n",
      "\tspeed: 0.1128s/iter; left time: 2574.4013s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0504131\n",
      "\tspeed: 0.1091s/iter; left time: 2478.3154s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0509365\n",
      "\tspeed: 0.1101s/iter; left time: 2489.5659s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0800472\n",
      "\tspeed: 0.1093s/iter; left time: 2460.9086s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0498694\n",
      "\tspeed: 0.1067s/iter; left time: 2391.5913s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0703021\n",
      "\tspeed: 0.1078s/iter; left time: 2406.7248s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0438494\n",
      "\tspeed: 0.1085s/iter; left time: 2410.5348s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0436303\n",
      "\tspeed: 0.1081s/iter; left time: 2391.2044s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0613145\n",
      "\tspeed: 0.1035s/iter; left time: 2278.6478s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0408842\n",
      "\tspeed: 0.0997s/iter; left time: 2184.8055s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0455322\n",
      "\tspeed: 0.1085s/iter; left time: 2367.6197s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0498312\n",
      "\tspeed: 0.1078s/iter; left time: 2340.5364s\n",
      "Epoch: 12 cost time: 00h:04m:58.92s\n",
      "Epoch: 12 | Train Loss: 0.0509285 Vali Loss: 0.0533803 Test Loss: 0.0574770\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0473562\n",
      "\tspeed: 0.8417s/iter; left time: 18184.9568s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477646\n",
      "\tspeed: 0.1033s/iter; left time: 2220.9687s\n",
      "\titers: 300, epoch: 13 | loss: 0.0395454\n",
      "\tspeed: 0.1072s/iter; left time: 2295.5467s\n",
      "\titers: 400, epoch: 13 | loss: 0.0617377\n",
      "\tspeed: 0.1081s/iter; left time: 2303.4315s\n",
      "\titers: 500, epoch: 13 | loss: 0.0466661\n",
      "\tspeed: 0.1094s/iter; left time: 2319.4114s\n",
      "\titers: 600, epoch: 13 | loss: 0.0459740\n",
      "\tspeed: 0.1054s/iter; left time: 2224.1775s\n",
      "\titers: 700, epoch: 13 | loss: 0.0358780\n",
      "\tspeed: 0.1077s/iter; left time: 2261.1889s\n",
      "\titers: 800, epoch: 13 | loss: 0.0430494\n",
      "\tspeed: 0.1070s/iter; left time: 2236.5716s\n",
      "\titers: 900, epoch: 13 | loss: 0.0609718\n",
      "\tspeed: 0.1033s/iter; left time: 2149.8008s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0560533\n",
      "\tspeed: 0.1047s/iter; left time: 2168.4898s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0503981\n",
      "\tspeed: 0.0928s/iter; left time: 1912.5414s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0347893\n",
      "\tspeed: 0.1008s/iter; left time: 2066.4420s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0692828\n",
      "\tspeed: 0.1066s/iter; left time: 2174.1659s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0522809\n",
      "\tspeed: 0.1013s/iter; left time: 2056.5869s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0531173\n",
      "\tspeed: 0.1049s/iter; left time: 2118.8894s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0422813\n",
      "\tspeed: 0.1074s/iter; left time: 2159.5814s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0572872\n",
      "\tspeed: 0.1092s/iter; left time: 2185.0135s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0473013\n",
      "\tspeed: 0.1080s/iter; left time: 2149.2146s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0517932\n",
      "\tspeed: 0.1080s/iter; left time: 2139.6704s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0525181\n",
      "\tspeed: 0.1094s/iter; left time: 2155.2147s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0514347\n",
      "\tspeed: 0.1090s/iter; left time: 2137.3959s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0526717\n",
      "\tspeed: 0.1068s/iter; left time: 2082.6089s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0463375\n",
      "\tspeed: 0.1038s/iter; left time: 2013.3305s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0481802\n",
      "\tspeed: 0.1078s/iter; left time: 2080.8564s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0474825\n",
      "\tspeed: 0.1084s/iter; left time: 2081.4243s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0461329\n",
      "\tspeed: 0.1056s/iter; left time: 2017.3482s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0459378\n",
      "\tspeed: 0.1092s/iter; left time: 2075.0258s\n",
      "Epoch: 13 cost time: 00h:04m:48.20s\n",
      "Epoch: 13 | Train Loss: 0.0506729 Vali Loss: 0.0530220 Test Loss: 0.0578316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0657005\n",
      "\tspeed: 0.8452s/iter; left time: 15966.9104s\n",
      "\titers: 200, epoch: 14 | loss: 0.0501025\n",
      "\tspeed: 0.1039s/iter; left time: 1952.2974s\n",
      "\titers: 300, epoch: 14 | loss: 0.0531937\n",
      "\tspeed: 0.1062s/iter; left time: 1985.3777s\n",
      "\titers: 400, epoch: 14 | loss: 0.0399528\n",
      "\tspeed: 0.1088s/iter; left time: 2022.8467s\n",
      "\titers: 500, epoch: 14 | loss: 0.0502588\n",
      "\tspeed: 0.1028s/iter; left time: 1900.3126s\n",
      "\titers: 600, epoch: 14 | loss: 0.0481835\n",
      "\tspeed: 0.0914s/iter; left time: 1680.5202s\n",
      "\titers: 700, epoch: 14 | loss: 0.0441985\n",
      "\tspeed: 0.0977s/iter; left time: 1787.9557s\n",
      "\titers: 800, epoch: 14 | loss: 0.0487092\n",
      "\tspeed: 0.1053s/iter; left time: 1915.4993s\n",
      "\titers: 900, epoch: 14 | loss: 0.0387260\n",
      "\tspeed: 0.1090s/iter; left time: 1971.5797s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0497734\n",
      "\tspeed: 0.1106s/iter; left time: 1989.0990s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0448196\n",
      "\tspeed: 0.1094s/iter; left time: 1957.5278s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0617918\n",
      "\tspeed: 0.1057s/iter; left time: 1881.3552s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0521033\n",
      "\tspeed: 0.1070s/iter; left time: 1892.5544s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0631672\n",
      "\tspeed: 0.1092s/iter; left time: 1921.3470s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0497660\n",
      "\tspeed: 0.1071s/iter; left time: 1874.0935s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0527748\n",
      "\tspeed: 0.1049s/iter; left time: 1824.7275s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0401833\n",
      "\tspeed: 0.1073s/iter; left time: 1855.7073s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0646718\n",
      "\tspeed: 0.1094s/iter; left time: 1881.3550s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0461747\n",
      "\tspeed: 0.0946s/iter; left time: 1616.8352s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0555299\n",
      "\tspeed: 0.0971s/iter; left time: 1649.3925s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0489289\n",
      "\tspeed: 0.1076s/iter; left time: 1817.4311s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0530368\n",
      "\tspeed: 0.1082s/iter; left time: 1816.0776s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0565491\n",
      "\tspeed: 0.0976s/iter; left time: 1628.6236s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0374595\n",
      "\tspeed: 0.1013s/iter; left time: 1680.1331s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0439480\n",
      "\tspeed: 0.1067s/iter; left time: 1760.4713s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0447525\n",
      "\tspeed: 0.1075s/iter; left time: 1762.2520s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0427074\n",
      "\tspeed: 0.1093s/iter; left time: 1781.2248s\n",
      "Epoch: 14 cost time: 00h:04m:45.01s\n",
      "Epoch: 14 | Train Loss: 0.0503469 Vali Loss: 0.0530163 Test Loss: 0.0572603\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0475976\n",
      "\tspeed: 0.8447s/iter; left time: 13665.9716s\n",
      "\titers: 200, epoch: 15 | loss: 0.0496813\n",
      "\tspeed: 0.1076s/iter; left time: 1729.3386s\n",
      "\titers: 300, epoch: 15 | loss: 0.0528194\n",
      "\tspeed: 0.1063s/iter; left time: 1698.7703s\n",
      "\titers: 400, epoch: 15 | loss: 0.0485182\n",
      "\tspeed: 0.1103s/iter; left time: 1751.3104s\n",
      "\titers: 500, epoch: 15 | loss: 0.0504476\n",
      "\tspeed: 0.1094s/iter; left time: 1726.3283s\n",
      "\titers: 600, epoch: 15 | loss: 0.0500270\n",
      "\tspeed: 0.1085s/iter; left time: 1700.8137s\n",
      "\titers: 700, epoch: 15 | loss: 0.0390998\n",
      "\tspeed: 0.1070s/iter; left time: 1666.8994s\n",
      "\titers: 800, epoch: 15 | loss: 0.0446774\n",
      "\tspeed: 0.1018s/iter; left time: 1576.3825s\n",
      "\titers: 900, epoch: 15 | loss: 0.0552191\n",
      "\tspeed: 0.1073s/iter; left time: 1650.8449s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0480956\n",
      "\tspeed: 0.1054s/iter; left time: 1609.6581s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0563352\n",
      "\tspeed: 0.0983s/iter; left time: 1491.5990s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0470802\n",
      "\tspeed: 0.1011s/iter; left time: 1524.2712s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0426255\n",
      "\tspeed: 0.1099s/iter; left time: 1645.8201s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0568796\n",
      "\tspeed: 0.1088s/iter; left time: 1619.4270s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0468034\n",
      "\tspeed: 0.1051s/iter; left time: 1553.0914s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0503813\n",
      "\tspeed: 0.1076s/iter; left time: 1579.8105s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0526259\n",
      "\tspeed: 0.1089s/iter; left time: 1587.9122s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0433962\n",
      "\tspeed: 0.1074s/iter; left time: 1554.9113s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0518279\n",
      "\tspeed: 0.0983s/iter; left time: 1413.0937s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0688984\n",
      "\tspeed: 0.1025s/iter; left time: 1463.4974s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0473993\n",
      "\tspeed: 0.1038s/iter; left time: 1471.9657s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0679344\n",
      "\tspeed: 0.1079s/iter; left time: 1519.7419s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0412253\n",
      "\tspeed: 0.1072s/iter; left time: 1498.2730s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0508351\n",
      "\tspeed: 0.1090s/iter; left time: 1513.1975s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0516523\n",
      "\tspeed: 0.1078s/iter; left time: 1485.1797s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0560802\n",
      "\tspeed: 0.1042s/iter; left time: 1425.3568s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0496466\n",
      "\tspeed: 0.1116s/iter; left time: 1516.0169s\n",
      "Epoch: 15 cost time: 00h:04m:48.92s\n",
      "Epoch: 15 | Train Loss: 0.0501232 Vali Loss: 0.0528784 Test Loss: 0.0574421\n",
      "Validation loss decreased (0.052961 --> 0.052878).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0592056\n",
      "\tspeed: 0.8713s/iter; left time: 11732.9486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0455804\n",
      "\tspeed: 0.1075s/iter; left time: 1437.0374s\n",
      "\titers: 300, epoch: 16 | loss: 0.0491524\n",
      "\tspeed: 0.1087s/iter; left time: 1441.9227s\n",
      "\titers: 400, epoch: 16 | loss: 0.0579208\n",
      "\tspeed: 0.1162s/iter; left time: 1529.2814s\n",
      "\titers: 500, epoch: 16 | loss: 0.0550992\n",
      "\tspeed: 0.1100s/iter; left time: 1437.4950s\n",
      "\titers: 600, epoch: 16 | loss: 0.0417632\n",
      "\tspeed: 0.1112s/iter; left time: 1442.2369s\n",
      "\titers: 700, epoch: 16 | loss: 0.0493300\n",
      "\tspeed: 0.1057s/iter; left time: 1359.8513s\n",
      "\titers: 800, epoch: 16 | loss: 0.0447646\n",
      "\tspeed: 0.1000s/iter; left time: 1277.2375s\n",
      "\titers: 900, epoch: 16 | loss: 0.0361148\n",
      "\tspeed: 0.1041s/iter; left time: 1318.8014s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0575270\n",
      "\tspeed: 0.1137s/iter; left time: 1428.7613s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0508707\n",
      "\tspeed: 0.1108s/iter; left time: 1381.6880s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0627444\n",
      "\tspeed: 0.1037s/iter; left time: 1282.4815s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0539518\n",
      "\tspeed: 0.1123s/iter; left time: 1378.0319s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0662120\n",
      "\tspeed: 0.1079s/iter; left time: 1312.3093s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0524773\n",
      "\tspeed: 0.1022s/iter; left time: 1232.7472s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0491869\n",
      "\tspeed: 0.1028s/iter; left time: 1230.0382s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0545447\n",
      "\tspeed: 0.1051s/iter; left time: 1246.5370s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0401777\n",
      "\tspeed: 0.0995s/iter; left time: 1171.1900s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0377282\n",
      "\tspeed: 0.1053s/iter; left time: 1228.9637s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0500316\n",
      "\tspeed: 0.0946s/iter; left time: 1093.6562s\n",
      "\titers: 2100, epoch: 16 | loss: 0.0506953\n",
      "\tspeed: 0.0931s/iter; left time: 1067.2029s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0641350\n",
      "\tspeed: 0.1020s/iter; left time: 1159.4070s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0503439\n",
      "\tspeed: 0.1037s/iter; left time: 1168.5012s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0517973\n",
      "\tspeed: 0.0969s/iter; left time: 1081.6431s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0474104\n",
      "\tspeed: 0.1066s/iter; left time: 1180.1763s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0474249\n",
      "\tspeed: 0.1028s/iter; left time: 1127.6732s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0513577\n",
      "\tspeed: 0.0906s/iter; left time: 984.9425s\n",
      "Epoch: 16 cost time: 00h:04m:44.22s\n",
      "Epoch: 16 | Train Loss: 0.0498373 Vali Loss: 0.0525651 Test Loss: 0.0572174\n",
      "Validation loss decreased (0.052878 --> 0.052565).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0437276\n",
      "\tspeed: 0.8622s/iter; left time: 9271.7698s\n",
      "\titers: 200, epoch: 17 | loss: 0.0517245\n",
      "\tspeed: 0.1063s/iter; left time: 1132.5772s\n",
      "\titers: 300, epoch: 17 | loss: 0.0473911\n",
      "\tspeed: 0.1004s/iter; left time: 1059.5013s\n",
      "\titers: 400, epoch: 17 | loss: 0.0500144\n",
      "\tspeed: 0.1079s/iter; left time: 1128.0561s\n",
      "\titers: 500, epoch: 17 | loss: 0.0376926\n",
      "\tspeed: 0.0971s/iter; left time: 1005.1892s\n",
      "\titers: 600, epoch: 17 | loss: 0.0466761\n",
      "\tspeed: 0.1016s/iter; left time: 1041.5789s\n",
      "\titers: 700, epoch: 17 | loss: 0.0454352\n",
      "\tspeed: 0.0998s/iter; left time: 1013.7713s\n",
      "\titers: 800, epoch: 17 | loss: 0.0449937\n",
      "\tspeed: 0.1018s/iter; left time: 1022.9951s\n",
      "\titers: 900, epoch: 17 | loss: 0.0483547\n",
      "\tspeed: 0.0941s/iter; left time: 936.7134s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0483076\n",
      "\tspeed: 0.0998s/iter; left time: 983.1518s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0475199\n",
      "\tspeed: 0.1010s/iter; left time: 984.6811s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0430593\n",
      "\tspeed: 0.1005s/iter; left time: 970.3838s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0419449\n",
      "\tspeed: 0.0950s/iter; left time: 907.4671s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0654212\n",
      "\tspeed: 0.1057s/iter; left time: 999.2603s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0503327\n",
      "\tspeed: 0.1043s/iter; left time: 975.9307s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0477077\n",
      "\tspeed: 0.1045s/iter; left time: 966.5873s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0499838\n",
      "\tspeed: 0.1036s/iter; left time: 948.0650s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0490089\n",
      "\tspeed: 0.0992s/iter; left time: 898.2044s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0722298\n",
      "\tspeed: 0.1056s/iter; left time: 945.2846s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0595167\n",
      "\tspeed: 0.1046s/iter; left time: 926.0951s\n",
      "\titers: 2100, epoch: 17 | loss: 0.0426991\n",
      "\tspeed: 0.1054s/iter; left time: 922.5754s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0500218\n",
      "\tspeed: 0.1029s/iter; left time: 890.0315s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0657111\n",
      "\tspeed: 0.1015s/iter; left time: 867.9839s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0557682\n",
      "\tspeed: 0.1026s/iter; left time: 867.0014s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0509930\n",
      "\tspeed: 0.1008s/iter; left time: 842.2752s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0464508\n",
      "\tspeed: 0.1036s/iter; left time: 854.8560s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0461689\n",
      "\tspeed: 0.1060s/iter; left time: 864.5868s\n",
      "Epoch: 17 cost time: 00h:04m:37.60s\n",
      "Epoch: 17 | Train Loss: 0.0496203 Vali Loss: 0.0519349 Test Loss: 0.0565374\n",
      "Validation loss decreased (0.052565 --> 0.051935).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0533527\n",
      "\tspeed: 0.8494s/iter; left time: 6829.2267s\n",
      "\titers: 200, epoch: 18 | loss: 0.0461609\n",
      "\tspeed: 0.0953s/iter; left time: 757.0012s\n",
      "\titers: 300, epoch: 18 | loss: 0.0506517\n",
      "\tspeed: 0.0902s/iter; left time: 706.7874s\n",
      "\titers: 400, epoch: 18 | loss: 0.0597992\n",
      "\tspeed: 0.0912s/iter; left time: 705.5248s\n",
      "\titers: 500, epoch: 18 | loss: 0.0695819\n",
      "\tspeed: 0.1009s/iter; left time: 771.1711s\n",
      "\titers: 600, epoch: 18 | loss: 0.0409655\n",
      "\tspeed: 0.1054s/iter; left time: 795.0345s\n",
      "\titers: 700, epoch: 18 | loss: 0.0497337\n",
      "\tspeed: 0.0984s/iter; left time: 732.1501s\n",
      "\titers: 800, epoch: 18 | loss: 0.0523130\n",
      "\tspeed: 0.1052s/iter; left time: 772.4382s\n",
      "\titers: 900, epoch: 18 | loss: 0.0643639\n",
      "\tspeed: 0.1057s/iter; left time: 765.3405s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0481267\n",
      "\tspeed: 0.1047s/iter; left time: 747.8991s\n",
      "\titers: 1100, epoch: 18 | loss: 0.0624701\n",
      "\tspeed: 0.1030s/iter; left time: 724.8069s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0415299\n",
      "\tspeed: 0.0975s/iter; left time: 676.3946s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0519827\n",
      "\tspeed: 0.0929s/iter; left time: 635.2593s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0643114\n",
      "\tspeed: 0.0957s/iter; left time: 644.9870s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0481849\n",
      "\tspeed: 0.1020s/iter; left time: 677.0366s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0358117\n",
      "\tspeed: 0.1013s/iter; left time: 662.7448s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0437583\n",
      "\tspeed: 0.0984s/iter; left time: 633.5809s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0499794\n",
      "\tspeed: 0.1052s/iter; left time: 666.9242s\n",
      "\titers: 1900, epoch: 18 | loss: 0.0541243\n",
      "\tspeed: 0.0998s/iter; left time: 622.5647s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0551410\n",
      "\tspeed: 0.0992s/iter; left time: 609.0602s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0460900\n",
      "\tspeed: 0.1002s/iter; left time: 605.1174s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0440878\n",
      "\tspeed: 0.1087s/iter; left time: 645.9425s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0524883\n",
      "\tspeed: 0.1063s/iter; left time: 620.5519s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0437363\n",
      "\tspeed: 0.1061s/iter; left time: 608.7894s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0446741\n",
      "\tspeed: 0.0966s/iter; left time: 544.6689s\n",
      "\titers: 2600, epoch: 18 | loss: 0.0372233\n",
      "\tspeed: 0.0995s/iter; left time: 551.4732s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0551410\n",
      "\tspeed: 0.1000s/iter; left time: 544.0604s\n",
      "Epoch: 18 cost time: 00h:04m:33.16s\n",
      "Epoch: 18 | Train Loss: 0.0493919 Vali Loss: 0.0524303 Test Loss: 0.0568722\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0474852\n",
      "\tspeed: 0.8349s/iter; left time: 4447.2801s\n",
      "\titers: 200, epoch: 19 | loss: 0.0383426\n",
      "\tspeed: 0.1067s/iter; left time: 557.6950s\n",
      "\titers: 300, epoch: 19 | loss: 0.0517355\n",
      "\tspeed: 0.1056s/iter; left time: 541.1687s\n",
      "\titers: 400, epoch: 19 | loss: 0.0579502\n",
      "\tspeed: 0.0970s/iter; left time: 487.4642s\n",
      "\titers: 500, epoch: 19 | loss: 0.0699855\n",
      "\tspeed: 0.0978s/iter; left time: 481.9359s\n",
      "\titers: 600, epoch: 19 | loss: 0.0354675\n",
      "\tspeed: 0.0998s/iter; left time: 481.9249s\n",
      "\titers: 700, epoch: 19 | loss: 0.0561534\n",
      "\tspeed: 0.0987s/iter; left time: 466.3221s\n",
      "\titers: 800, epoch: 19 | loss: 0.0504431\n",
      "\tspeed: 0.1041s/iter; left time: 481.4858s\n",
      "\titers: 900, epoch: 19 | loss: 0.0574905\n",
      "\tspeed: 0.0948s/iter; left time: 429.3542s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0476026\n",
      "\tspeed: 0.1035s/iter; left time: 458.3605s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0579937\n",
      "\tspeed: 0.1043s/iter; left time: 451.1618s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0513450\n",
      "\tspeed: 0.1056s/iter; left time: 446.3079s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0452443\n",
      "\tspeed: 0.0939s/iter; left time: 387.6507s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0447390\n",
      "\tspeed: 0.1020s/iter; left time: 410.6567s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0393573\n",
      "\tspeed: 0.1073s/iter; left time: 421.5001s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0433779\n",
      "\tspeed: 0.1020s/iter; left time: 390.4468s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0571398\n",
      "\tspeed: 0.1010s/iter; left time: 376.3165s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0451176\n",
      "\tspeed: 0.1048s/iter; left time: 380.1747s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0420777\n",
      "\tspeed: 0.1018s/iter; left time: 359.0424s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0462035\n",
      "\tspeed: 0.1002s/iter; left time: 343.3943s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0529378\n",
      "\tspeed: 0.1000s/iter; left time: 332.6676s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0378183\n",
      "\tspeed: 0.0977s/iter; left time: 315.2628s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0418065\n",
      "\tspeed: 0.1036s/iter; left time: 324.0281s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0494923\n",
      "\tspeed: 0.1067s/iter; left time: 322.9943s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0547716\n",
      "\tspeed: 0.1016s/iter; left time: 297.3954s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0534549\n",
      "\tspeed: 0.1074s/iter; left time: 303.7392s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0477377\n",
      "\tspeed: 0.1075s/iter; left time: 293.0507s\n",
      "Epoch: 19 cost time: 00h:04m:38.00s\n",
      "Epoch: 19 | Train Loss: 0.0491679 Vali Loss: 0.0524268 Test Loss: 0.0569408\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0494476\n",
      "\tspeed: 0.8341s/iter; left time: 2180.4163s\n",
      "\titers: 200, epoch: 20 | loss: 0.0418466\n",
      "\tspeed: 0.1007s/iter; left time: 253.1154s\n",
      "\titers: 300, epoch: 20 | loss: 0.0383608\n",
      "\tspeed: 0.0997s/iter; left time: 240.6552s\n",
      "\titers: 400, epoch: 20 | loss: 0.0415717\n",
      "\tspeed: 0.0975s/iter; left time: 225.6100s\n",
      "\titers: 500, epoch: 20 | loss: 0.0421772\n",
      "\tspeed: 0.0980s/iter; left time: 217.0150s\n",
      "\titers: 600, epoch: 20 | loss: 0.0474148\n",
      "\tspeed: 0.1028s/iter; left time: 217.3352s\n",
      "\titers: 700, epoch: 20 | loss: 0.0522053\n",
      "\tspeed: 0.1028s/iter; left time: 207.1382s\n",
      "\titers: 800, epoch: 20 | loss: 0.0431458\n",
      "\tspeed: 0.1002s/iter; left time: 191.7638s\n",
      "\titers: 900, epoch: 20 | loss: 0.0494134\n",
      "\tspeed: 0.0982s/iter; left time: 178.2049s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0537831\n",
      "\tspeed: 0.1050s/iter; left time: 180.0472s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0439577\n",
      "\tspeed: 0.1083s/iter; left time: 174.8368s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0657683\n",
      "\tspeed: 0.1071s/iter; left time: 162.1233s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0374616\n",
      "\tspeed: 0.0985s/iter; left time: 139.3076s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0473699\n",
      "\tspeed: 0.0990s/iter; left time: 130.0962s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0485304\n",
      "\tspeed: 0.1049s/iter; left time: 127.3566s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0544698\n",
      "\tspeed: 0.1042s/iter; left time: 116.0429s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0494165\n",
      "\tspeed: 0.1030s/iter; left time: 104.4706s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0361732\n",
      "\tspeed: 0.1014s/iter; left time: 92.7166s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0554559\n",
      "\tspeed: 0.1088s/iter; left time: 88.5450s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0443465\n",
      "\tspeed: 0.1039s/iter; left time: 74.1740s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0529985\n",
      "\tspeed: 0.0979s/iter; left time: 60.1369s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0447284\n",
      "\tspeed: 0.1020s/iter; left time: 52.4281s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0501268\n",
      "\tspeed: 0.1042s/iter; left time: 43.1441s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0494811\n",
      "\tspeed: 0.1053s/iter; left time: 33.0695s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0503117\n",
      "\tspeed: 0.1007s/iter; left time: 21.5579s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0497328\n",
      "\tspeed: 0.1043s/iter; left time: 11.8928s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0414248\n",
      "\tspeed: 0.1024s/iter; left time: 1.4332s\n",
      "Epoch: 20 cost time: 00h:04m:38.65s\n",
      "Epoch: 20 | Train Loss: 0.0489081 Vali Loss: 0.0528455 Test Loss: 0.0567938\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.010154812596738338, rmse:0.10077109187841415, mae:0.05653735250234604, rse:0.388770192861557\n",
      "success delete checkpoints\n",
      "Intermediate time for FR and pred_len 24: 02h:01m:08.72s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 86619\n",
      "val 18435\n",
      "test 18435\n",
      "[2024-11-05 19:34:58,770] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 19:34:59,837] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 19:34:59,837] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 19:34:59,837] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 19:34:59,942] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 19:34:59,942] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 19:35:00,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 19:35:00,605] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 19:35:00,606] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 19:35:00,607] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 19:35:00,607] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 19:35:00,607] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 19:35:00,608] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 19:35:00,608] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 19:35:00,608] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 19:35:00,608] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 19:35:00,964] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 19:35:00,965] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 19:35:00,965] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 292.06 GB, percent = 38.7%\n",
      "[2024-11-05 19:35:01,094] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 19:35:01,095] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-05 19:35:01,095] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 292.06 GB, percent = 38.7%\n",
      "[2024-11-05 19:35:01,096] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 19:35:01,218] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 19:35:01,219] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-05 19:35:01,219] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 292.06 GB, percent = 38.7%\n",
      "[2024-11-05 19:35:01,220] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 19:35:01,220] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 19:35:01,220] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 19:35:01,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 19:35:01,221] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f57d08af150>\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 19:35:01,222] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 19:35:01,223] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1180274\n",
      "\tspeed: 0.1567s/iter; left time: 8463.1387s\n",
      "\titers: 200, epoch: 1 | loss: 0.1456531\n",
      "\tspeed: 0.1184s/iter; left time: 6383.7986s\n",
      "\titers: 300, epoch: 1 | loss: 0.1177239\n",
      "\tspeed: 0.1203s/iter; left time: 6475.4321s\n",
      "\titers: 400, epoch: 1 | loss: 0.1051027\n",
      "\tspeed: 0.1167s/iter; left time: 6266.5961s\n",
      "\titers: 500, epoch: 1 | loss: 0.0929279\n",
      "\tspeed: 0.1142s/iter; left time: 6125.5043s\n",
      "\titers: 600, epoch: 1 | loss: 0.0756746\n",
      "\tspeed: 0.1093s/iter; left time: 5847.9993s\n",
      "\titers: 700, epoch: 1 | loss: 0.0912399\n",
      "\tspeed: 0.1187s/iter; left time: 6343.4208s\n",
      "\titers: 800, epoch: 1 | loss: 0.0769103\n",
      "\tspeed: 0.1140s/iter; left time: 6076.7121s\n",
      "\titers: 900, epoch: 1 | loss: 0.0860128\n",
      "\tspeed: 0.1147s/iter; left time: 6103.0685s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0746874\n",
      "\tspeed: 0.1162s/iter; left time: 6170.8464s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0808015\n",
      "\tspeed: 0.1122s/iter; left time: 5948.0665s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0680625\n",
      "\tspeed: 0.1117s/iter; left time: 5910.9503s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0851584\n",
      "\tspeed: 0.1167s/iter; left time: 6165.9507s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0989581\n",
      "\tspeed: 0.1153s/iter; left time: 6078.2611s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0919076\n",
      "\tspeed: 0.1218s/iter; left time: 6408.6433s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0757395\n",
      "\tspeed: 0.1204s/iter; left time: 6321.7607s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0897562\n",
      "\tspeed: 0.1218s/iter; left time: 6382.4278s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0818964\n",
      "\tspeed: 0.1167s/iter; left time: 6106.7109s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0940115\n",
      "\tspeed: 0.1124s/iter; left time: 5869.3812s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0752767\n",
      "\tspeed: 0.1162s/iter; left time: 6055.8273s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0733735\n",
      "\tspeed: 0.1154s/iter; left time: 6005.1390s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0800274\n",
      "\tspeed: 0.1188s/iter; left time: 6168.5276s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0590007\n",
      "\tspeed: 0.1105s/iter; left time: 5725.4550s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0846301\n",
      "\tspeed: 0.1104s/iter; left time: 5711.1749s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0711006\n",
      "\tspeed: 0.1136s/iter; left time: 5865.8665s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0627394\n",
      "\tspeed: 0.1153s/iter; left time: 5942.3046s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0747052\n",
      "\tspeed: 0.1171s/iter; left time: 6023.3131s\n",
      "Epoch: 1 cost time: 00h:05m:14.17s\n",
      "Epoch: 1 | Train Loss: 0.0880198 Vali Loss: 0.0779218 Test Loss: 0.0864457\n",
      "Validation loss decreased (inf --> 0.077922).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0757852\n",
      "\tspeed: 0.9661s/iter; left time: 49576.6866s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984501\n",
      "\tspeed: 0.1036s/iter; left time: 5307.6230s\n",
      "\titers: 300, epoch: 2 | loss: 0.0858931\n",
      "\tspeed: 0.1057s/iter; left time: 5404.3633s\n",
      "\titers: 400, epoch: 2 | loss: 0.0678129\n",
      "\tspeed: 0.1008s/iter; left time: 5141.6394s\n",
      "\titers: 500, epoch: 2 | loss: 0.0764950\n",
      "\tspeed: 0.0902s/iter; left time: 4591.3222s\n",
      "\titers: 600, epoch: 2 | loss: 0.0815546\n",
      "\tspeed: 0.0990s/iter; left time: 5028.9819s\n",
      "\titers: 700, epoch: 2 | loss: 0.0640524\n",
      "\tspeed: 0.1030s/iter; left time: 5222.6668s\n",
      "\titers: 800, epoch: 2 | loss: 0.0844075\n",
      "\tspeed: 0.1026s/iter; left time: 5194.1764s\n",
      "\titers: 900, epoch: 2 | loss: 0.0860210\n",
      "\tspeed: 0.1037s/iter; left time: 5235.9833s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0873393\n",
      "\tspeed: 0.1007s/iter; left time: 5077.8173s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0638573\n",
      "\tspeed: 0.1086s/iter; left time: 5465.5183s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0924232\n",
      "\tspeed: 0.0959s/iter; left time: 4818.0487s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0888966\n",
      "\tspeed: 0.1031s/iter; left time: 5168.5954s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0627556\n",
      "\tspeed: 0.1085s/iter; left time: 5424.2201s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0725209\n",
      "\tspeed: 0.0942s/iter; left time: 4700.0242s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0901358\n",
      "\tspeed: 0.1041s/iter; left time: 5186.9929s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0672607\n",
      "\tspeed: 0.1000s/iter; left time: 4971.6032s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0708371\n",
      "\tspeed: 0.1035s/iter; left time: 5134.9104s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0830795\n",
      "\tspeed: 0.1050s/iter; left time: 5199.3319s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0682695\n",
      "\tspeed: 0.1086s/iter; left time: 5364.2325s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0764010\n",
      "\tspeed: 0.1067s/iter; left time: 5263.9685s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0605409\n",
      "\tspeed: 0.1056s/iter; left time: 5197.0088s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0883992\n",
      "\tspeed: 0.1072s/iter; left time: 5264.9179s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0729705\n",
      "\tspeed: 0.1093s/iter; left time: 5355.0675s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0813760\n",
      "\tspeed: 0.1041s/iter; left time: 5093.8820s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0865509\n",
      "\tspeed: 0.1023s/iter; left time: 4991.8063s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0698382\n",
      "\tspeed: 0.0975s/iter; left time: 4751.5060s\n",
      "Epoch: 2 cost time: 00h:04m:38.12s\n",
      "Epoch: 2 | Train Loss: 0.0737351 Vali Loss: 0.0760496 Test Loss: 0.0853966\n",
      "Validation loss decreased (0.077922 --> 0.076050).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0598956\n",
      "\tspeed: 0.8480s/iter; left time: 41222.3833s\n",
      "\titers: 200, epoch: 3 | loss: 0.1016827\n",
      "\tspeed: 0.1047s/iter; left time: 5078.2286s\n",
      "\titers: 300, epoch: 3 | loss: 0.0773379\n",
      "\tspeed: 0.1009s/iter; left time: 4884.5775s\n",
      "\titers: 400, epoch: 3 | loss: 0.0793985\n",
      "\tspeed: 0.0936s/iter; left time: 4522.3245s\n",
      "\titers: 500, epoch: 3 | loss: 0.0861342\n",
      "\tspeed: 0.0903s/iter; left time: 4353.5997s\n",
      "\titers: 600, epoch: 3 | loss: 0.0687184\n",
      "\tspeed: 0.0981s/iter; left time: 4720.1899s\n",
      "\titers: 700, epoch: 3 | loss: 0.0915886\n",
      "\tspeed: 0.1077s/iter; left time: 5172.6174s\n",
      "\titers: 800, epoch: 3 | loss: 0.0631312\n",
      "\tspeed: 0.1095s/iter; left time: 5246.8625s\n",
      "\titers: 900, epoch: 3 | loss: 0.0705714\n",
      "\tspeed: 0.0934s/iter; left time: 4467.7382s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0791852\n",
      "\tspeed: 0.1065s/iter; left time: 5081.2878s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0685390\n",
      "\tspeed: 0.1070s/iter; left time: 5094.2411s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0687579\n",
      "\tspeed: 0.1049s/iter; left time: 4984.3737s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0676240\n",
      "\tspeed: 0.1006s/iter; left time: 4769.4222s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0635080\n",
      "\tspeed: 0.0946s/iter; left time: 4474.0899s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0843385\n",
      "\tspeed: 0.0946s/iter; left time: 4466.9939s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0650293\n",
      "\tspeed: 0.0999s/iter; left time: 4707.0010s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0606964\n",
      "\tspeed: 0.1053s/iter; left time: 4950.8294s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0594419\n",
      "\tspeed: 0.0999s/iter; left time: 4685.3695s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0600037\n",
      "\tspeed: 0.0938s/iter; left time: 4391.4844s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0689571\n",
      "\tspeed: 0.1009s/iter; left time: 4714.2080s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0822306\n",
      "\tspeed: 0.0974s/iter; left time: 4538.8639s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0558235\n",
      "\tspeed: 0.1005s/iter; left time: 4673.7982s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0629247\n",
      "\tspeed: 0.0976s/iter; left time: 4529.1614s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0662562\n",
      "\tspeed: 0.1020s/iter; left time: 4721.6875s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0629647\n",
      "\tspeed: 0.1059s/iter; left time: 4891.7324s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0619749\n",
      "\tspeed: 0.1061s/iter; left time: 4893.7404s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0712471\n",
      "\tspeed: 0.1027s/iter; left time: 4725.4370s\n",
      "Epoch: 3 cost time: 00h:04m:33.64s\n",
      "Epoch: 3 | Train Loss: 0.0716339 Vali Loss: 0.0740404 Test Loss: 0.0835884\n",
      "Validation loss decreased (0.076050 --> 0.074040).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0659460\n",
      "\tspeed: 0.8345s/iter; left time: 38307.5250s\n",
      "\titers: 200, epoch: 4 | loss: 0.0652347\n",
      "\tspeed: 0.1056s/iter; left time: 4835.5911s\n",
      "\titers: 300, epoch: 4 | loss: 0.0675584\n",
      "\tspeed: 0.0969s/iter; left time: 4427.6050s\n",
      "\titers: 400, epoch: 4 | loss: 0.0575672\n",
      "\tspeed: 0.1043s/iter; left time: 4756.2456s\n",
      "\titers: 500, epoch: 4 | loss: 0.0809128\n",
      "\tspeed: 0.1078s/iter; left time: 4905.5219s\n",
      "\titers: 600, epoch: 4 | loss: 0.0791411\n",
      "\tspeed: 0.1033s/iter; left time: 4688.1605s\n",
      "\titers: 700, epoch: 4 | loss: 0.0974628\n",
      "\tspeed: 0.1092s/iter; left time: 4947.8570s\n",
      "\titers: 800, epoch: 4 | loss: 0.0723504\n",
      "\tspeed: 0.0976s/iter; left time: 4409.6373s\n",
      "\titers: 900, epoch: 4 | loss: 0.0593577\n",
      "\tspeed: 0.0902s/iter; left time: 4066.1754s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0636031\n",
      "\tspeed: 0.0987s/iter; left time: 4439.9536s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0663474\n",
      "\tspeed: 0.1032s/iter; left time: 4636.0695s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0570367\n",
      "\tspeed: 0.1019s/iter; left time: 4566.3856s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0665866\n",
      "\tspeed: 0.1002s/iter; left time: 4480.0356s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0990248\n",
      "\tspeed: 0.0918s/iter; left time: 4094.3324s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0823950\n",
      "\tspeed: 0.1029s/iter; left time: 4579.8506s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0690160\n",
      "\tspeed: 0.1025s/iter; left time: 4550.7834s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0902368\n",
      "\tspeed: 0.0944s/iter; left time: 4184.1836s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0584478\n",
      "\tspeed: 0.0950s/iter; left time: 4197.4177s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0582067\n",
      "\tspeed: 0.0933s/iter; left time: 4114.7165s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0873670\n",
      "\tspeed: 0.0901s/iter; left time: 3966.4187s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0701413\n",
      "\tspeed: 0.0902s/iter; left time: 3962.1633s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0885223\n",
      "\tspeed: 0.0953s/iter; left time: 4173.6538s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0559932\n",
      "\tspeed: 0.1040s/iter; left time: 4544.8919s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0651490\n",
      "\tspeed: 0.1014s/iter; left time: 4420.0643s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0717561\n",
      "\tspeed: 0.1080s/iter; left time: 4696.2969s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0724399\n",
      "\tspeed: 0.0973s/iter; left time: 4224.5952s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0676078\n",
      "\tspeed: 0.1097s/iter; left time: 4749.4082s\n",
      "Epoch: 4 cost time: 00h:04m:31.19s\n",
      "Epoch: 4 | Train Loss: 0.0703399 Vali Loss: 0.0740457 Test Loss: 0.0833150\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0710808\n",
      "\tspeed: 0.8216s/iter; left time: 35491.6071s\n",
      "\titers: 200, epoch: 5 | loss: 0.0884828\n",
      "\tspeed: 0.0970s/iter; left time: 4179.9103s\n",
      "\titers: 300, epoch: 5 | loss: 0.0645084\n",
      "\tspeed: 0.0997s/iter; left time: 4288.4671s\n",
      "\titers: 400, epoch: 5 | loss: 0.0578531\n",
      "\tspeed: 0.1026s/iter; left time: 4401.3083s\n",
      "\titers: 500, epoch: 5 | loss: 0.0646244\n",
      "\tspeed: 0.0968s/iter; left time: 4144.3723s\n",
      "\titers: 600, epoch: 5 | loss: 0.0648577\n",
      "\tspeed: 0.0921s/iter; left time: 3932.5394s\n",
      "\titers: 700, epoch: 5 | loss: 0.0685318\n",
      "\tspeed: 0.0902s/iter; left time: 3841.8055s\n",
      "\titers: 800, epoch: 5 | loss: 0.0614903\n",
      "\tspeed: 0.0910s/iter; left time: 3866.3075s\n",
      "\titers: 900, epoch: 5 | loss: 0.0736456\n",
      "\tspeed: 0.0903s/iter; left time: 3829.6658s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0701113\n",
      "\tspeed: 0.1035s/iter; left time: 4379.4237s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0689163\n",
      "\tspeed: 0.1024s/iter; left time: 4319.2734s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0661009\n",
      "\tspeed: 0.1027s/iter; left time: 4324.0999s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0704694\n",
      "\tspeed: 0.1050s/iter; left time: 4410.6302s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0749205\n",
      "\tspeed: 0.1001s/iter; left time: 4191.9653s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0910459\n",
      "\tspeed: 0.1067s/iter; left time: 4459.7575s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0718202\n",
      "\tspeed: 0.1074s/iter; left time: 4479.5194s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0672593\n",
      "\tspeed: 0.1077s/iter; left time: 4478.2600s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0531688\n",
      "\tspeed: 0.0937s/iter; left time: 3890.1536s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0595710\n",
      "\tspeed: 0.0901s/iter; left time: 3728.7150s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0823330\n",
      "\tspeed: 0.0901s/iter; left time: 3720.9915s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0638121\n",
      "\tspeed: 0.0902s/iter; left time: 3715.5710s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0626150\n",
      "\tspeed: 0.0935s/iter; left time: 3841.7702s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0583169\n",
      "\tspeed: 0.1041s/iter; left time: 4268.6982s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0830918\n",
      "\tspeed: 0.1116s/iter; left time: 4564.1141s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0889929\n",
      "\tspeed: 0.1026s/iter; left time: 4185.4307s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0703940\n",
      "\tspeed: 0.1098s/iter; left time: 4470.1908s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0744374\n",
      "\tspeed: 0.1021s/iter; left time: 4144.4154s\n",
      "Epoch: 5 cost time: 00h:04m:29.09s\n",
      "Epoch: 5 | Train Loss: 0.0691479 Vali Loss: 0.0728152 Test Loss: 0.0832145\n",
      "Validation loss decreased (0.074040 --> 0.072815).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0733926\n",
      "\tspeed: 0.8722s/iter; left time: 35317.7082s\n",
      "\titers: 200, epoch: 6 | loss: 0.0796082\n",
      "\tspeed: 0.1013s/iter; left time: 4092.1317s\n",
      "\titers: 300, epoch: 6 | loss: 0.0514746\n",
      "\tspeed: 0.1054s/iter; left time: 4246.0031s\n",
      "\titers: 400, epoch: 6 | loss: 0.0817475\n",
      "\tspeed: 0.1018s/iter; left time: 4091.0651s\n",
      "\titers: 500, epoch: 6 | loss: 0.0637893\n",
      "\tspeed: 0.0900s/iter; left time: 3606.7363s\n",
      "\titers: 600, epoch: 6 | loss: 0.0659236\n",
      "\tspeed: 0.0902s/iter; left time: 3607.7935s\n",
      "\titers: 700, epoch: 6 | loss: 0.0737557\n",
      "\tspeed: 0.1045s/iter; left time: 4167.3558s\n",
      "\titers: 800, epoch: 6 | loss: 0.0593111\n",
      "\tspeed: 0.1097s/iter; left time: 4365.3645s\n",
      "\titers: 900, epoch: 6 | loss: 0.0894239\n",
      "\tspeed: 0.1108s/iter; left time: 4396.2903s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0658894\n",
      "\tspeed: 0.1127s/iter; left time: 4462.3772s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0708223\n",
      "\tspeed: 0.1139s/iter; left time: 4497.0707s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0761138\n",
      "\tspeed: 0.0990s/iter; left time: 3899.8377s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0849874\n",
      "\tspeed: 0.1016s/iter; left time: 3990.5648s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0722972\n",
      "\tspeed: 0.1050s/iter; left time: 4116.2253s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0764843\n",
      "\tspeed: 0.1032s/iter; left time: 4033.5901s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0552304\n",
      "\tspeed: 0.1035s/iter; left time: 4036.0068s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0634706\n",
      "\tspeed: 0.0991s/iter; left time: 3853.8785s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0525037\n",
      "\tspeed: 0.0901s/iter; left time: 3497.0012s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0710541\n",
      "\tspeed: 0.0964s/iter; left time: 3729.7267s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0668513\n",
      "\tspeed: 0.0939s/iter; left time: 3624.9784s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0585239\n",
      "\tspeed: 0.0989s/iter; left time: 3808.6437s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0661883\n",
      "\tspeed: 0.1044s/iter; left time: 4006.9436s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0924985\n",
      "\tspeed: 0.1002s/iter; left time: 3835.3649s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0624355\n",
      "\tspeed: 0.0901s/iter; left time: 3440.7511s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0642578\n",
      "\tspeed: 0.0974s/iter; left time: 3710.6330s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0749044\n",
      "\tspeed: 0.0950s/iter; left time: 3609.8449s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0596391\n",
      "\tspeed: 0.1051s/iter; left time: 3983.3891s\n",
      "Epoch: 6 cost time: 00h:04m:34.67s\n",
      "Epoch: 6 | Train Loss: 0.0683068 Vali Loss: 0.0722721 Test Loss: 0.0822182\n",
      "Validation loss decreased (0.072815 --> 0.072272).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0776968\n",
      "\tspeed: 0.9462s/iter; left time: 35752.1079s\n",
      "\titers: 200, epoch: 7 | loss: 0.0612086\n",
      "\tspeed: 0.1100s/iter; left time: 4143.5472s\n",
      "\titers: 300, epoch: 7 | loss: 0.0560953\n",
      "\tspeed: 0.1034s/iter; left time: 3887.2629s\n",
      "\titers: 400, epoch: 7 | loss: 0.0492145\n",
      "\tspeed: 0.1153s/iter; left time: 4320.7595s\n",
      "\titers: 500, epoch: 7 | loss: 0.0782152\n",
      "\tspeed: 0.1183s/iter; left time: 4421.8347s\n",
      "\titers: 600, epoch: 7 | loss: 0.0731607\n",
      "\tspeed: 0.1161s/iter; left time: 4330.2822s\n",
      "\titers: 700, epoch: 7 | loss: 0.0633121\n",
      "\tspeed: 0.1121s/iter; left time: 4167.5723s\n",
      "\titers: 800, epoch: 7 | loss: 0.0597769\n",
      "\tspeed: 0.1119s/iter; left time: 4148.7605s\n",
      "\titers: 900, epoch: 7 | loss: 0.0643496\n",
      "\tspeed: 0.1140s/iter; left time: 4217.8339s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0734983\n",
      "\tspeed: 0.1125s/iter; left time: 4149.6032s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0539922\n",
      "\tspeed: 0.1113s/iter; left time: 4094.4233s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0686129\n",
      "\tspeed: 0.1144s/iter; left time: 4195.5706s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0601908\n",
      "\tspeed: 0.1173s/iter; left time: 4291.6410s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0555281\n",
      "\tspeed: 0.1166s/iter; left time: 4255.0322s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0685173\n",
      "\tspeed: 0.1071s/iter; left time: 3897.1279s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0658529\n",
      "\tspeed: 0.1100s/iter; left time: 3991.4602s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0574584\n",
      "\tspeed: 0.1005s/iter; left time: 3636.6409s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0602260\n",
      "\tspeed: 0.0904s/iter; left time: 3261.8021s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0628480\n",
      "\tspeed: 0.1071s/iter; left time: 3853.1539s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0680207\n",
      "\tspeed: 0.1018s/iter; left time: 3654.2505s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0650357\n",
      "\tspeed: 0.1061s/iter; left time: 3795.3377s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0587740\n",
      "\tspeed: 0.1053s/iter; left time: 3756.0796s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0720224\n",
      "\tspeed: 0.1121s/iter; left time: 3987.7955s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0785954\n",
      "\tspeed: 0.1090s/iter; left time: 3867.8046s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0582689\n",
      "\tspeed: 0.1085s/iter; left time: 3838.1896s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0756124\n",
      "\tspeed: 0.1113s/iter; left time: 3928.5343s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0662144\n",
      "\tspeed: 0.1114s/iter; left time: 3918.1829s\n",
      "Epoch: 7 cost time: 00h:04m:57.96s\n",
      "Epoch: 7 | Train Loss: 0.0675787 Vali Loss: 0.0710317 Test Loss: 0.0812885\n",
      "Validation loss decreased (0.072272 --> 0.071032).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0727610\n",
      "\tspeed: 0.8947s/iter; left time: 31385.3442s\n",
      "\titers: 200, epoch: 8 | loss: 0.0711253\n",
      "\tspeed: 0.1166s/iter; left time: 4079.2851s\n",
      "\titers: 300, epoch: 8 | loss: 0.0615649\n",
      "\tspeed: 0.1156s/iter; left time: 4031.4067s\n",
      "\titers: 400, epoch: 8 | loss: 0.0649232\n",
      "\tspeed: 0.1129s/iter; left time: 3927.2865s\n",
      "\titers: 500, epoch: 8 | loss: 0.0596484\n",
      "\tspeed: 0.1110s/iter; left time: 3847.6528s\n",
      "\titers: 600, epoch: 8 | loss: 0.0493135\n",
      "\tspeed: 0.1109s/iter; left time: 3836.1694s\n",
      "\titers: 700, epoch: 8 | loss: 0.0739790\n",
      "\tspeed: 0.1137s/iter; left time: 3919.8510s\n",
      "\titers: 800, epoch: 8 | loss: 0.0595486\n",
      "\tspeed: 0.1173s/iter; left time: 4033.8002s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699764\n",
      "\tspeed: 0.1097s/iter; left time: 3761.7660s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0564226\n",
      "\tspeed: 0.1196s/iter; left time: 4086.1728s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0665268\n",
      "\tspeed: 0.1184s/iter; left time: 4034.9235s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0813253\n",
      "\tspeed: 0.1136s/iter; left time: 3858.3496s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0546051\n",
      "\tspeed: 0.1170s/iter; left time: 3962.2447s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0610035\n",
      "\tspeed: 0.1108s/iter; left time: 3744.1932s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0726437\n",
      "\tspeed: 0.1074s/iter; left time: 3616.6503s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0775348\n",
      "\tspeed: 0.1110s/iter; left time: 3728.5176s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0688549\n",
      "\tspeed: 0.1118s/iter; left time: 3741.6379s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0591776\n",
      "\tspeed: 0.1116s/iter; left time: 3725.6163s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0674870\n",
      "\tspeed: 0.1117s/iter; left time: 3716.4732s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0641274\n",
      "\tspeed: 0.1115s/iter; left time: 3700.0980s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0732145\n",
      "\tspeed: 0.1111s/iter; left time: 3674.1678s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0766461\n",
      "\tspeed: 0.1092s/iter; left time: 3601.5041s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0686456\n",
      "\tspeed: 0.0925s/iter; left time: 3040.9535s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0811659\n",
      "\tspeed: 0.0926s/iter; left time: 3035.0795s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0584365\n",
      "\tspeed: 0.0948s/iter; left time: 3099.0448s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0682489\n",
      "\tspeed: 0.1028s/iter; left time: 3348.7718s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0781496\n",
      "\tspeed: 0.1111s/iter; left time: 3609.5752s\n",
      "Epoch: 8 cost time: 00h:04m:59.36s\n",
      "Epoch: 8 | Train Loss: 0.0668469 Vali Loss: 0.0716354 Test Loss: 0.0820779\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0642082\n",
      "\tspeed: 0.8482s/iter; left time: 27457.5291s\n",
      "\titers: 200, epoch: 9 | loss: 0.0722886\n",
      "\tspeed: 0.1133s/iter; left time: 3655.7052s\n",
      "\titers: 300, epoch: 9 | loss: 0.0563756\n",
      "\tspeed: 0.1200s/iter; left time: 3862.0472s\n",
      "\titers: 400, epoch: 9 | loss: 0.0583035\n",
      "\tspeed: 0.1175s/iter; left time: 3770.0137s\n",
      "\titers: 500, epoch: 9 | loss: 0.0508993\n",
      "\tspeed: 0.1120s/iter; left time: 3580.4840s\n",
      "\titers: 600, epoch: 9 | loss: 0.0525132\n",
      "\tspeed: 0.1108s/iter; left time: 3532.1095s\n",
      "\titers: 700, epoch: 9 | loss: 0.0599365\n",
      "\tspeed: 0.1107s/iter; left time: 3518.5486s\n",
      "\titers: 800, epoch: 9 | loss: 0.0627635\n",
      "\tspeed: 0.1180s/iter; left time: 3735.9898s\n",
      "\titers: 900, epoch: 9 | loss: 0.0603625\n",
      "\tspeed: 0.1188s/iter; left time: 3750.2627s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0669214\n",
      "\tspeed: 0.1183s/iter; left time: 3724.7412s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0726000\n",
      "\tspeed: 0.1160s/iter; left time: 3640.5127s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0536474\n",
      "\tspeed: 0.1117s/iter; left time: 3491.8032s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0593494\n",
      "\tspeed: 0.1110s/iter; left time: 3459.5121s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0626211\n",
      "\tspeed: 0.1107s/iter; left time: 3441.0155s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0570845\n",
      "\tspeed: 0.1111s/iter; left time: 3442.4420s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0683315\n",
      "\tspeed: 0.1107s/iter; left time: 3418.8785s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0661876\n",
      "\tspeed: 0.1103s/iter; left time: 3395.7076s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0527195\n",
      "\tspeed: 0.1028s/iter; left time: 3153.9385s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0860783\n",
      "\tspeed: 0.0928s/iter; left time: 2837.7011s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0559389\n",
      "\tspeed: 0.0936s/iter; left time: 2851.6554s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0743512\n",
      "\tspeed: 0.1061s/iter; left time: 3222.8312s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0750299\n",
      "\tspeed: 0.1149s/iter; left time: 3479.0981s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0538675\n",
      "\tspeed: 0.1200s/iter; left time: 3620.4063s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0602465\n",
      "\tspeed: 0.1116s/iter; left time: 3356.0827s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0626537\n",
      "\tspeed: 0.1191s/iter; left time: 3568.9593s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0584263\n",
      "\tspeed: 0.1178s/iter; left time: 3520.5145s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0832215\n",
      "\tspeed: 0.1126s/iter; left time: 3353.3526s\n",
      "Epoch: 9 cost time: 00h:05m:03.67s\n",
      "Epoch: 9 | Train Loss: 0.0662619 Vali Loss: 0.0720566 Test Loss: 0.0832348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0798982\n",
      "\tspeed: 0.8470s/iter; left time: 25127.5359s\n",
      "\titers: 200, epoch: 10 | loss: 0.0546947\n",
      "\tspeed: 0.1085s/iter; left time: 3206.8482s\n",
      "\titers: 300, epoch: 10 | loss: 0.0763564\n",
      "\tspeed: 0.1003s/iter; left time: 2956.4553s\n",
      "\titers: 400, epoch: 10 | loss: 0.0590158\n",
      "\tspeed: 0.1106s/iter; left time: 3247.1926s\n",
      "\titers: 500, epoch: 10 | loss: 0.0715616\n",
      "\tspeed: 0.1060s/iter; left time: 3102.0023s\n",
      "\titers: 600, epoch: 10 | loss: 0.0701054\n",
      "\tspeed: 0.1034s/iter; left time: 3015.7437s\n",
      "\titers: 700, epoch: 10 | loss: 0.0581082\n",
      "\tspeed: 0.0999s/iter; left time: 2903.6012s\n",
      "\titers: 800, epoch: 10 | loss: 0.0519056\n",
      "\tspeed: 0.1045s/iter; left time: 3028.0242s\n",
      "\titers: 900, epoch: 10 | loss: 0.0611435\n",
      "\tspeed: 0.1012s/iter; left time: 2921.8188s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0593141\n",
      "\tspeed: 0.1067s/iter; left time: 3069.8666s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0662135\n",
      "\tspeed: 0.1073s/iter; left time: 3075.2316s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0509836\n",
      "\tspeed: 0.1035s/iter; left time: 2957.8947s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0571669\n",
      "\tspeed: 0.0948s/iter; left time: 2699.0632s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0723531\n",
      "\tspeed: 0.1047s/iter; left time: 2968.8848s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0617078\n",
      "\tspeed: 0.1011s/iter; left time: 2858.0744s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0563496\n",
      "\tspeed: 0.1013s/iter; left time: 2853.9285s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0710252\n",
      "\tspeed: 0.1044s/iter; left time: 2929.2983s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0589763\n",
      "\tspeed: 0.1022s/iter; left time: 2857.9581s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0624647\n",
      "\tspeed: 0.1043s/iter; left time: 2907.6127s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0642931\n",
      "\tspeed: 0.1079s/iter; left time: 2997.1811s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0600686\n",
      "\tspeed: 0.1031s/iter; left time: 2853.2171s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0620920\n",
      "\tspeed: 0.1050s/iter; left time: 2894.9811s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0592551\n",
      "\tspeed: 0.0977s/iter; left time: 2684.7289s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0639569\n",
      "\tspeed: 0.0927s/iter; left time: 2536.3480s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0540252\n",
      "\tspeed: 0.1016s/iter; left time: 2770.5289s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0591027\n",
      "\tspeed: 0.1044s/iter; left time: 2837.0384s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0798775\n",
      "\tspeed: 0.0992s/iter; left time: 2683.9340s\n",
      "Epoch: 10 cost time: 00h:04m:39.89s\n",
      "Epoch: 10 | Train Loss: 0.0656602 Vali Loss: 0.0715535 Test Loss: 0.0815294\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0659401\n",
      "\tspeed: 0.8077s/iter; left time: 21776.0984s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669563\n",
      "\tspeed: 0.1086s/iter; left time: 2917.3393s\n",
      "\titers: 300, epoch: 11 | loss: 0.0633592\n",
      "\tspeed: 0.1028s/iter; left time: 2750.3940s\n",
      "\titers: 400, epoch: 11 | loss: 0.0480135\n",
      "\tspeed: 0.0994s/iter; left time: 2648.8616s\n",
      "\titers: 500, epoch: 11 | loss: 0.0643558\n",
      "\tspeed: 0.1052s/iter; left time: 2794.1724s\n",
      "\titers: 600, epoch: 11 | loss: 0.0570078\n",
      "\tspeed: 0.1138s/iter; left time: 3011.7371s\n",
      "\titers: 700, epoch: 11 | loss: 0.0644932\n",
      "\tspeed: 0.1152s/iter; left time: 3035.7377s\n",
      "\titers: 800, epoch: 11 | loss: 0.0783950\n",
      "\tspeed: 0.1148s/iter; left time: 3014.9483s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628730\n",
      "\tspeed: 0.1130s/iter; left time: 2955.7111s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0605555\n",
      "\tspeed: 0.1165s/iter; left time: 3034.9696s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0622459\n",
      "\tspeed: 0.1059s/iter; left time: 2749.2063s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0601752\n",
      "\tspeed: 0.1087s/iter; left time: 2810.4269s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0593103\n",
      "\tspeed: 0.1056s/iter; left time: 2720.5216s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0788163\n",
      "\tspeed: 0.1104s/iter; left time: 2833.1119s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0782274\n",
      "\tspeed: 0.1002s/iter; left time: 2560.2621s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0566930\n",
      "\tspeed: 0.0991s/iter; left time: 2522.7439s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0715099\n",
      "\tspeed: 0.0974s/iter; left time: 2469.0436s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0569858\n",
      "\tspeed: 0.1130s/iter; left time: 2853.2957s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0847080\n",
      "\tspeed: 0.0989s/iter; left time: 2488.0007s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0854547\n",
      "\tspeed: 0.1033s/iter; left time: 2588.1707s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0591162\n",
      "\tspeed: 0.1023s/iter; left time: 2553.9342s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0537549\n",
      "\tspeed: 0.0973s/iter; left time: 2418.3892s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0599643\n",
      "\tspeed: 0.0982s/iter; left time: 2430.5137s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0621327\n",
      "\tspeed: 0.0982s/iter; left time: 2421.1303s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0568906\n",
      "\tspeed: 0.1057s/iter; left time: 2595.2349s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0581609\n",
      "\tspeed: 0.1019s/iter; left time: 2492.5015s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0680945\n",
      "\tspeed: 0.1060s/iter; left time: 2582.1120s\n",
      "Epoch: 11 cost time: 00h:04m:46.01s\n",
      "Epoch: 11 | Train Loss: 0.0650049 Vali Loss: 0.0712278 Test Loss: 0.0820249\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0661491\n",
      "\tspeed: 0.8243s/iter; left time: 19994.3066s\n",
      "\titers: 200, epoch: 12 | loss: 0.0705223\n",
      "\tspeed: 0.0953s/iter; left time: 2302.9453s\n",
      "\titers: 300, epoch: 12 | loss: 0.0751145\n",
      "\tspeed: 0.1010s/iter; left time: 2429.4673s\n",
      "\titers: 400, epoch: 12 | loss: 0.0599013\n",
      "\tspeed: 0.0998s/iter; left time: 2391.0256s\n",
      "\titers: 500, epoch: 12 | loss: 0.0593433\n",
      "\tspeed: 0.1051s/iter; left time: 2506.1222s\n",
      "\titers: 600, epoch: 12 | loss: 0.0627291\n",
      "\tspeed: 0.1102s/iter; left time: 2617.5402s\n",
      "\titers: 700, epoch: 12 | loss: 0.0741353\n",
      "\tspeed: 0.1050s/iter; left time: 2484.5707s\n",
      "\titers: 800, epoch: 12 | loss: 0.0535758\n",
      "\tspeed: 0.0993s/iter; left time: 2340.0286s\n",
      "\titers: 900, epoch: 12 | loss: 0.0484967\n",
      "\tspeed: 0.0983s/iter; left time: 2304.8493s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0579805\n",
      "\tspeed: 0.1009s/iter; left time: 2355.4250s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0648144\n",
      "\tspeed: 0.0987s/iter; left time: 2294.3112s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0545619\n",
      "\tspeed: 0.1004s/iter; left time: 2325.5261s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0569381\n",
      "\tspeed: 0.0949s/iter; left time: 2187.5236s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0627295\n",
      "\tspeed: 0.1011s/iter; left time: 2319.7011s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0613075\n",
      "\tspeed: 0.1019s/iter; left time: 2328.5669s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0590654\n",
      "\tspeed: 0.1062s/iter; left time: 2415.5165s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0584627\n",
      "\tspeed: 0.1080s/iter; left time: 2446.6209s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0590165\n",
      "\tspeed: 0.1106s/iter; left time: 2494.0158s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0608725\n",
      "\tspeed: 0.1070s/iter; left time: 2403.0223s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0720614\n",
      "\tspeed: 0.1070s/iter; left time: 2391.2589s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0731259\n",
      "\tspeed: 0.1079s/iter; left time: 2400.4654s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0612299\n",
      "\tspeed: 0.1020s/iter; left time: 2260.4336s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0604366\n",
      "\tspeed: 0.1023s/iter; left time: 2257.1133s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0801308\n",
      "\tspeed: 0.1039s/iter; left time: 2281.9633s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0517701\n",
      "\tspeed: 0.0998s/iter; left time: 2181.3293s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0689210\n",
      "\tspeed: 0.1018s/iter; left time: 2214.5385s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0514609\n",
      "\tspeed: 0.1054s/iter; left time: 2283.1631s\n",
      "Epoch: 12 cost time: 00h:04m:39.02s\n",
      "Epoch: 12 | Train Loss: 0.0644515 Vali Loss: 0.0719438 Test Loss: 0.0828678\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.019628532230854034, rmse:0.1401018649339676, mae:0.08128844946622849, rse:0.5419946908950806\n",
      "success delete checkpoints\n",
      "Intermediate time for FR and pred_len 96: 01h:12m:58.63s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "train 86403\n",
      "val 18219\n",
      "test 18219\n",
      "[2024-11-05 20:47:56,868] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 20:47:57,860] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 20:47:57,860] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 20:47:57,860] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 20:47:57,984] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 20:47:57,984] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 20:47:58,654] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 20:47:58,655] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 20:47:58,655] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 20:47:58,657] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 20:47:58,657] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 20:47:58,657] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 20:47:58,657] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 20:47:58,657] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 20:47:58,657] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 20:47:58,657] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 20:47:58,971] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 20:47:58,972] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 20:47:58,972] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 256.11 GB, percent = 33.9%\n",
      "[2024-11-05 20:47:59,124] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 20:47:59,125] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-05 20:47:59,125] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 256.82 GB, percent = 34.0%\n",
      "[2024-11-05 20:47:59,125] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 20:47:59,279] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 20:47:59,280] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-05 20:47:59,280] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 257.52 GB, percent = 34.1%\n",
      "[2024-11-05 20:47:59,281] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 20:47:59,281] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 20:47:59,281] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 20:47:59,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 20:47:59,282] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 20:47:59,282] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 20:47:59,282] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 20:47:59,282] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 20:47:59,282] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa8ac17aa10>\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 20:47:59,283] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 20:47:59,284] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 20:47:59,285] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1480640\n",
      "\tspeed: 0.1694s/iter; left time: 9130.2612s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326918\n",
      "\tspeed: 0.1263s/iter; left time: 6793.7540s\n",
      "\titers: 300, epoch: 1 | loss: 0.1436223\n",
      "\tspeed: 0.1264s/iter; left time: 6785.7785s\n",
      "\titers: 400, epoch: 1 | loss: 0.1370232\n",
      "\tspeed: 0.1248s/iter; left time: 6688.0465s\n",
      "\titers: 500, epoch: 1 | loss: 0.1282854\n",
      "\tspeed: 0.1194s/iter; left time: 6387.2295s\n",
      "\titers: 600, epoch: 1 | loss: 0.1016604\n",
      "\tspeed: 0.1074s/iter; left time: 5733.7713s\n",
      "\titers: 700, epoch: 1 | loss: 0.0820344\n",
      "\tspeed: 0.1143s/iter; left time: 6094.3748s\n",
      "\titers: 800, epoch: 1 | loss: 0.0905941\n",
      "\tspeed: 0.1225s/iter; left time: 6517.4712s\n",
      "\titers: 900, epoch: 1 | loss: 0.0951419\n",
      "\tspeed: 0.1212s/iter; left time: 6436.2160s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0796341\n",
      "\tspeed: 0.1174s/iter; left time: 6222.6213s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0717497\n",
      "\tspeed: 0.1087s/iter; left time: 5748.8388s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0844347\n",
      "\tspeed: 0.1165s/iter; left time: 6148.8050s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1052428\n",
      "\tspeed: 0.1212s/iter; left time: 6387.6594s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0807175\n",
      "\tspeed: 0.1237s/iter; left time: 6506.4169s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0904513\n",
      "\tspeed: 0.1210s/iter; left time: 6354.5446s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0672294\n",
      "\tspeed: 0.1169s/iter; left time: 6125.1689s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0714964\n",
      "\tspeed: 0.1219s/iter; left time: 6373.3666s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0698988\n",
      "\tspeed: 0.1195s/iter; left time: 6235.4552s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0826391\n",
      "\tspeed: 0.1150s/iter; left time: 5993.0030s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1031276\n",
      "\tspeed: 0.1136s/iter; left time: 5908.1760s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0801321\n",
      "\tspeed: 0.1209s/iter; left time: 6273.3035s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0705847\n",
      "\tspeed: 0.1187s/iter; left time: 6150.0590s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0834047\n",
      "\tspeed: 0.1202s/iter; left time: 6216.9427s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0755059\n",
      "\tspeed: 0.1261s/iter; left time: 6507.1056s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0792811\n",
      "\tspeed: 0.1245s/iter; left time: 6410.9120s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0920582\n",
      "\tspeed: 0.1226s/iter; left time: 6301.1648s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0893142\n",
      "\tspeed: 0.1203s/iter; left time: 6171.7202s\n",
      "Epoch: 1 cost time: 00h:05m:25.14s\n",
      "Epoch: 1 | Train Loss: 0.0945147 Vali Loss: 0.0834073 Test Loss: 0.0927286\n",
      "Validation loss decreased (inf --> 0.083407).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0740698\n",
      "\tspeed: 0.9643s/iter; left time: 49372.5193s\n",
      "\titers: 200, epoch: 2 | loss: 0.0633438\n",
      "\tspeed: 0.1101s/iter; left time: 5628.1191s\n",
      "\titers: 300, epoch: 2 | loss: 0.0990868\n",
      "\tspeed: 0.1053s/iter; left time: 5372.6738s\n",
      "\titers: 400, epoch: 2 | loss: 0.0840126\n",
      "\tspeed: 0.1073s/iter; left time: 5464.1738s\n",
      "\titers: 500, epoch: 2 | loss: 0.0705981\n",
      "\tspeed: 0.1077s/iter; left time: 5470.8119s\n",
      "\titers: 600, epoch: 2 | loss: 0.0704488\n",
      "\tspeed: 0.1080s/iter; left time: 5473.2113s\n",
      "\titers: 700, epoch: 2 | loss: 0.0880861\n",
      "\tspeed: 0.1043s/iter; left time: 5275.8842s\n",
      "\titers: 800, epoch: 2 | loss: 0.0737586\n",
      "\tspeed: 0.1015s/iter; left time: 5123.5710s\n",
      "\titers: 900, epoch: 2 | loss: 0.0808669\n",
      "\tspeed: 0.1051s/iter; left time: 5295.5804s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0901496\n",
      "\tspeed: 0.1061s/iter; left time: 5336.3374s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0766896\n",
      "\tspeed: 0.1065s/iter; left time: 5348.6167s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0860757\n",
      "\tspeed: 0.1116s/iter; left time: 5593.5359s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0622538\n",
      "\tspeed: 0.1081s/iter; left time: 5406.5658s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0693071\n",
      "\tspeed: 0.1106s/iter; left time: 5516.8051s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0800351\n",
      "\tspeed: 0.1090s/iter; left time: 5426.0044s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0886204\n",
      "\tspeed: 0.1128s/iter; left time: 5607.7748s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0809490\n",
      "\tspeed: 0.1087s/iter; left time: 5391.6398s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0760458\n",
      "\tspeed: 0.1130s/iter; left time: 5591.9328s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0968032\n",
      "\tspeed: 0.1151s/iter; left time: 5686.9966s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0872404\n",
      "\tspeed: 0.1104s/iter; left time: 5444.7871s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0800749\n",
      "\tspeed: 0.0999s/iter; left time: 4916.4705s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0689195\n",
      "\tspeed: 0.1071s/iter; left time: 5260.4756s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0806217\n",
      "\tspeed: 0.1060s/iter; left time: 5196.1245s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0685093\n",
      "\tspeed: 0.1035s/iter; left time: 5061.1036s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0832198\n",
      "\tspeed: 0.1053s/iter; left time: 5137.0861s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0577823\n",
      "\tspeed: 0.1101s/iter; left time: 5361.8775s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0700328\n",
      "\tspeed: 0.1093s/iter; left time: 5311.6336s\n",
      "Epoch: 2 cost time: 00h:04m:51.83s\n",
      "Epoch: 2 | Train Loss: 0.0789389 Vali Loss: 0.0817467 Test Loss: 0.0915837\n",
      "Validation loss decreased (0.083407 --> 0.081747).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0697995\n",
      "\tspeed: 0.8355s/iter; left time: 40522.0492s\n",
      "\titers: 200, epoch: 3 | loss: 0.0571884\n",
      "\tspeed: 0.1060s/iter; left time: 5129.8092s\n",
      "\titers: 300, epoch: 3 | loss: 0.0888654\n",
      "\tspeed: 0.0990s/iter; left time: 4781.8964s\n",
      "\titers: 400, epoch: 3 | loss: 0.0897905\n",
      "\tspeed: 0.1047s/iter; left time: 5046.7740s\n",
      "\titers: 500, epoch: 3 | loss: 0.0570455\n",
      "\tspeed: 0.0927s/iter; left time: 4460.3580s\n",
      "\titers: 600, epoch: 3 | loss: 0.0703308\n",
      "\tspeed: 0.1039s/iter; left time: 4985.3863s\n",
      "\titers: 700, epoch: 3 | loss: 0.0719969\n",
      "\tspeed: 0.1115s/iter; left time: 5338.6806s\n",
      "\titers: 800, epoch: 3 | loss: 0.0772546\n",
      "\tspeed: 0.1123s/iter; left time: 5365.8933s\n",
      "\titers: 900, epoch: 3 | loss: 0.0835371\n",
      "\tspeed: 0.1113s/iter; left time: 5307.9973s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0737978\n",
      "\tspeed: 0.1072s/iter; left time: 5104.2110s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0621786\n",
      "\tspeed: 0.1101s/iter; left time: 5228.0919s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0773723\n",
      "\tspeed: 0.1062s/iter; left time: 5036.0865s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0674613\n",
      "\tspeed: 0.1070s/iter; left time: 5061.9525s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0672880\n",
      "\tspeed: 0.1105s/iter; left time: 5217.0035s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0698024\n",
      "\tspeed: 0.1117s/iter; left time: 5263.2932s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0711279\n",
      "\tspeed: 0.1079s/iter; left time: 5069.5080s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0874978\n",
      "\tspeed: 0.1087s/iter; left time: 5096.5161s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0646509\n",
      "\tspeed: 0.1108s/iter; left time: 5186.5823s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0637321\n",
      "\tspeed: 0.1087s/iter; left time: 5074.2816s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0720374\n",
      "\tspeed: 0.1090s/iter; left time: 5081.2881s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0802795\n",
      "\tspeed: 0.1105s/iter; left time: 5137.4173s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0668583\n",
      "\tspeed: 0.1048s/iter; left time: 4860.7319s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0804939\n",
      "\tspeed: 0.1029s/iter; left time: 4762.4306s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0713874\n",
      "\tspeed: 0.1084s/iter; left time: 5010.3360s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0580129\n",
      "\tspeed: 0.0970s/iter; left time: 4471.1693s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0737468\n",
      "\tspeed: 0.1068s/iter; left time: 4911.7925s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0830055\n",
      "\tspeed: 0.1112s/iter; left time: 5103.8646s\n",
      "Epoch: 3 cost time: 00h:04m:48.44s\n",
      "Epoch: 3 | Train Loss: 0.0767469 Vali Loss: 0.0798090 Test Loss: 0.0901377\n",
      "Validation loss decreased (0.081747 --> 0.079809).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0710287\n",
      "\tspeed: 0.8414s/iter; left time: 38539.1207s\n",
      "\titers: 200, epoch: 4 | loss: 0.0744253\n",
      "\tspeed: 0.1090s/iter; left time: 4980.5609s\n",
      "\titers: 300, epoch: 4 | loss: 0.0754263\n",
      "\tspeed: 0.1098s/iter; left time: 5005.8104s\n",
      "\titers: 400, epoch: 4 | loss: 0.0717835\n",
      "\tspeed: 0.1110s/iter; left time: 5051.1760s\n",
      "\titers: 500, epoch: 4 | loss: 0.0776161\n",
      "\tspeed: 0.1103s/iter; left time: 5009.0135s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902967\n",
      "\tspeed: 0.1086s/iter; left time: 4919.1058s\n",
      "\titers: 700, epoch: 4 | loss: 0.0901349\n",
      "\tspeed: 0.1058s/iter; left time: 4780.3407s\n",
      "\titers: 800, epoch: 4 | loss: 0.0783323\n",
      "\tspeed: 0.1065s/iter; left time: 4803.3080s\n",
      "\titers: 900, epoch: 4 | loss: 0.0774601\n",
      "\tspeed: 0.1096s/iter; left time: 4931.4269s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0715911\n",
      "\tspeed: 0.1076s/iter; left time: 4830.9912s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0853423\n",
      "\tspeed: 0.1115s/iter; left time: 4997.5431s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0797879\n",
      "\tspeed: 0.1112s/iter; left time: 4969.8709s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0913231\n",
      "\tspeed: 0.1115s/iter; left time: 4973.8102s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0611501\n",
      "\tspeed: 0.1114s/iter; left time: 4959.5112s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1057012\n",
      "\tspeed: 0.1126s/iter; left time: 5001.1364s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0632340\n",
      "\tspeed: 0.1086s/iter; left time: 4809.2933s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0699417\n",
      "\tspeed: 0.1093s/iter; left time: 4831.7653s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0645578\n",
      "\tspeed: 0.1095s/iter; left time: 4828.3745s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0684393\n",
      "\tspeed: 0.1114s/iter; left time: 4901.4304s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0742295\n",
      "\tspeed: 0.1081s/iter; left time: 4745.2197s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0732207\n",
      "\tspeed: 0.0984s/iter; left time: 4308.8493s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0663624\n",
      "\tspeed: 0.0980s/iter; left time: 4282.3403s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0678291\n",
      "\tspeed: 0.1094s/iter; left time: 4771.2961s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0867032\n",
      "\tspeed: 0.1090s/iter; left time: 4741.3666s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0763287\n",
      "\tspeed: 0.1064s/iter; left time: 4619.0337s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0674522\n",
      "\tspeed: 0.1122s/iter; left time: 4858.9472s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0685823\n",
      "\tspeed: 0.1083s/iter; left time: 4677.6785s\n",
      "Epoch: 4 cost time: 00h:04m:53.81s\n",
      "Epoch: 4 | Train Loss: 0.0755592 Vali Loss: 0.0785529 Test Loss: 0.0887212\n",
      "Validation loss decreased (0.079809 --> 0.078553).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0765404\n",
      "\tspeed: 0.8431s/iter; left time: 36340.3361s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715873\n",
      "\tspeed: 0.1104s/iter; left time: 4749.3559s\n",
      "\titers: 300, epoch: 5 | loss: 0.0836785\n",
      "\tspeed: 0.1097s/iter; left time: 4705.0613s\n",
      "\titers: 400, epoch: 5 | loss: 0.0785768\n",
      "\tspeed: 0.1067s/iter; left time: 4566.2297s\n",
      "\titers: 500, epoch: 5 | loss: 0.0712529\n",
      "\tspeed: 0.1074s/iter; left time: 4585.2179s\n",
      "\titers: 600, epoch: 5 | loss: 0.0612621\n",
      "\tspeed: 0.1082s/iter; left time: 4608.1346s\n",
      "\titers: 700, epoch: 5 | loss: 0.0741821\n",
      "\tspeed: 0.1061s/iter; left time: 4510.2509s\n",
      "\titers: 800, epoch: 5 | loss: 0.0690322\n",
      "\tspeed: 0.1083s/iter; left time: 4590.6129s\n",
      "\titers: 900, epoch: 5 | loss: 0.0563307\n",
      "\tspeed: 0.1102s/iter; left time: 4661.2652s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0563184\n",
      "\tspeed: 0.1122s/iter; left time: 4735.6126s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0831931\n",
      "\tspeed: 0.1122s/iter; left time: 4725.1868s\n",
      "\titers: 1200, epoch: 5 | loss: 0.1046245\n",
      "\tspeed: 0.1066s/iter; left time: 4477.3984s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0724949\n",
      "\tspeed: 0.1108s/iter; left time: 4643.7017s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0672690\n",
      "\tspeed: 0.1095s/iter; left time: 4575.1410s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0740977\n",
      "\tspeed: 0.1073s/iter; left time: 4475.2731s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0653220\n",
      "\tspeed: 0.1068s/iter; left time: 4441.9002s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0818285\n",
      "\tspeed: 0.1035s/iter; left time: 4295.2870s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0999166\n",
      "\tspeed: 0.1096s/iter; left time: 4536.6996s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0745104\n",
      "\tspeed: 0.1125s/iter; left time: 4645.6983s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1037759\n",
      "\tspeed: 0.1078s/iter; left time: 4442.4463s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0614654\n",
      "\tspeed: 0.1065s/iter; left time: 4376.7723s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0639651\n",
      "\tspeed: 0.1101s/iter; left time: 4512.6550s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0953831\n",
      "\tspeed: 0.1053s/iter; left time: 4307.0224s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0597811\n",
      "\tspeed: 0.1062s/iter; left time: 4331.2272s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0786193\n",
      "\tspeed: 0.1111s/iter; left time: 4521.2489s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0698698\n",
      "\tspeed: 0.1107s/iter; left time: 4493.8751s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0756479\n",
      "\tspeed: 0.1115s/iter; left time: 4514.4124s\n",
      "Epoch: 5 cost time: 00h:04m:54.22s\n",
      "Epoch: 5 | Train Loss: 0.0747169 Vali Loss: 0.0780021 Test Loss: 0.0884628\n",
      "Validation loss decreased (0.078553 --> 0.078002).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0711357\n",
      "\tspeed: 0.9063s/iter; left time: 36614.5919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0767272\n",
      "\tspeed: 0.1125s/iter; left time: 4532.6363s\n",
      "\titers: 300, epoch: 6 | loss: 0.0666458\n",
      "\tspeed: 0.1105s/iter; left time: 4444.1925s\n",
      "\titers: 400, epoch: 6 | loss: 0.0671970\n",
      "\tspeed: 0.0989s/iter; left time: 3967.4252s\n",
      "\titers: 500, epoch: 6 | loss: 0.0710725\n",
      "\tspeed: 0.1138s/iter; left time: 4553.3951s\n",
      "\titers: 600, epoch: 6 | loss: 0.0734514\n",
      "\tspeed: 0.1096s/iter; left time: 4371.6903s\n",
      "\titers: 700, epoch: 6 | loss: 0.0802906\n",
      "\tspeed: 0.1102s/iter; left time: 4385.6384s\n",
      "\titers: 800, epoch: 6 | loss: 0.0953359\n",
      "\tspeed: 0.1109s/iter; left time: 4402.7296s\n",
      "\titers: 900, epoch: 6 | loss: 0.0872949\n",
      "\tspeed: 0.1095s/iter; left time: 4336.7492s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0830929\n",
      "\tspeed: 0.1112s/iter; left time: 4393.2753s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0736103\n",
      "\tspeed: 0.1104s/iter; left time: 4348.9181s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0682348\n",
      "\tspeed: 0.1048s/iter; left time: 4117.9126s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0675761\n",
      "\tspeed: 0.1088s/iter; left time: 4264.5013s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0831418\n",
      "\tspeed: 0.1095s/iter; left time: 4282.8762s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0576885\n",
      "\tspeed: 0.1034s/iter; left time: 4031.3086s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0715426\n",
      "\tspeed: 0.1060s/iter; left time: 4124.0870s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0853029\n",
      "\tspeed: 0.1081s/iter; left time: 4195.6911s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0805578\n",
      "\tspeed: 0.1080s/iter; left time: 4178.7630s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0810728\n",
      "\tspeed: 0.1099s/iter; left time: 4241.2264s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0620804\n",
      "\tspeed: 0.1103s/iter; left time: 4245.3674s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0559064\n",
      "\tspeed: 0.1108s/iter; left time: 4255.8557s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0944726\n",
      "\tspeed: 0.1177s/iter; left time: 4506.3024s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0714347\n",
      "\tspeed: 0.1101s/iter; left time: 4204.2945s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0716578\n",
      "\tspeed: 0.1133s/iter; left time: 4316.3987s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0752620\n",
      "\tspeed: 0.1113s/iter; left time: 4230.5228s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0662965\n",
      "\tspeed: 0.1099s/iter; left time: 4163.8420s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0762098\n",
      "\tspeed: 0.0984s/iter; left time: 3719.2775s\n",
      "Epoch: 6 cost time: 00h:04m:55.42s\n",
      "Epoch: 6 | Train Loss: 0.0739681 Vali Loss: 0.0778127 Test Loss: 0.0883272\n",
      "Validation loss decreased (0.078002 --> 0.077813).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0592984\n",
      "\tspeed: 0.8586s/iter; left time: 32371.2989s\n",
      "\titers: 200, epoch: 7 | loss: 0.0823950\n",
      "\tspeed: 0.1088s/iter; left time: 4092.8238s\n",
      "\titers: 300, epoch: 7 | loss: 0.0622965\n",
      "\tspeed: 0.1049s/iter; left time: 3935.5728s\n",
      "\titers: 400, epoch: 7 | loss: 0.0922223\n",
      "\tspeed: 0.1025s/iter; left time: 3832.0418s\n",
      "\titers: 500, epoch: 7 | loss: 0.0628040\n",
      "\tspeed: 0.1056s/iter; left time: 3939.8536s\n",
      "\titers: 600, epoch: 7 | loss: 0.0545688\n",
      "\tspeed: 0.1054s/iter; left time: 3920.4557s\n",
      "\titers: 700, epoch: 7 | loss: 0.0655805\n",
      "\tspeed: 0.1073s/iter; left time: 3982.7202s\n",
      "\titers: 800, epoch: 7 | loss: 0.0820508\n",
      "\tspeed: 0.1096s/iter; left time: 4055.0468s\n",
      "\titers: 900, epoch: 7 | loss: 0.0721417\n",
      "\tspeed: 0.1116s/iter; left time: 4119.6774s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0743012\n",
      "\tspeed: 0.1125s/iter; left time: 4139.7849s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0740961\n",
      "\tspeed: 0.1093s/iter; left time: 4010.3027s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0798689\n",
      "\tspeed: 0.1038s/iter; left time: 3799.5058s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0787044\n",
      "\tspeed: 0.1027s/iter; left time: 3749.9374s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0807659\n",
      "\tspeed: 0.1104s/iter; left time: 4017.8189s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0842854\n",
      "\tspeed: 0.1114s/iter; left time: 4044.7994s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0720778\n",
      "\tspeed: 0.1059s/iter; left time: 3832.4730s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0773522\n",
      "\tspeed: 0.1019s/iter; left time: 3679.4889s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0772960\n",
      "\tspeed: 0.0924s/iter; left time: 3328.2515s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0745947\n",
      "\tspeed: 0.0972s/iter; left time: 3487.8604s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0744979\n",
      "\tspeed: 0.1107s/iter; left time: 3961.9084s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0619413\n",
      "\tspeed: 0.1062s/iter; left time: 3791.5043s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0801493\n",
      "\tspeed: 0.1134s/iter; left time: 4036.8802s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0653252\n",
      "\tspeed: 0.1088s/iter; left time: 3861.8646s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0682275\n",
      "\tspeed: 0.1027s/iter; left time: 3636.8223s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0722434\n",
      "\tspeed: 0.0928s/iter; left time: 3274.2567s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0874485\n",
      "\tspeed: 0.0924s/iter; left time: 3254.1875s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0724617\n",
      "\tspeed: 0.0999s/iter; left time: 3506.0510s\n",
      "Epoch: 7 cost time: 00h:04m:45.21s\n",
      "Epoch: 7 | Train Loss: 0.0732280 Vali Loss: 0.0771653 Test Loss: 0.0881268\n",
      "Validation loss decreased (0.077813 --> 0.077165).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0822646\n",
      "\tspeed: 0.9006s/iter; left time: 31523.4262s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745872\n",
      "\tspeed: 0.1124s/iter; left time: 3921.4775s\n",
      "\titers: 300, epoch: 8 | loss: 0.0699675\n",
      "\tspeed: 0.1117s/iter; left time: 3888.4724s\n",
      "\titers: 400, epoch: 8 | loss: 0.0663150\n",
      "\tspeed: 0.1104s/iter; left time: 3831.7707s\n",
      "\titers: 500, epoch: 8 | loss: 0.0713106\n",
      "\tspeed: 0.1112s/iter; left time: 3848.1425s\n",
      "\titers: 600, epoch: 8 | loss: 0.0660359\n",
      "\tspeed: 0.1113s/iter; left time: 3841.3446s\n",
      "\titers: 700, epoch: 8 | loss: 0.0732458\n",
      "\tspeed: 0.1111s/iter; left time: 3823.2749s\n",
      "\titers: 800, epoch: 8 | loss: 0.0659571\n",
      "\tspeed: 0.1129s/iter; left time: 3874.2878s\n",
      "\titers: 900, epoch: 8 | loss: 0.0593963\n",
      "\tspeed: 0.1123s/iter; left time: 3840.2575s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0693393\n",
      "\tspeed: 0.1101s/iter; left time: 3754.0937s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0762123\n",
      "\tspeed: 0.1074s/iter; left time: 3650.0489s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0930533\n",
      "\tspeed: 0.1090s/iter; left time: 3695.7915s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0701164\n",
      "\tspeed: 0.1139s/iter; left time: 3850.8536s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0765828\n",
      "\tspeed: 0.1119s/iter; left time: 3770.2997s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0599631\n",
      "\tspeed: 0.1079s/iter; left time: 3624.0180s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0809273\n",
      "\tspeed: 0.1103s/iter; left time: 3696.7075s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0767053\n",
      "\tspeed: 0.1065s/iter; left time: 3557.2707s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0721011\n",
      "\tspeed: 0.1058s/iter; left time: 3522.8273s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0632089\n",
      "\tspeed: 0.1105s/iter; left time: 3668.6927s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0648941\n",
      "\tspeed: 0.1113s/iter; left time: 3685.0885s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0789213\n",
      "\tspeed: 0.1068s/iter; left time: 3524.0358s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0617707\n",
      "\tspeed: 0.0980s/iter; left time: 3223.5065s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0664686\n",
      "\tspeed: 0.1027s/iter; left time: 3368.2728s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0860251\n",
      "\tspeed: 0.1087s/iter; left time: 3555.9554s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0789836\n",
      "\tspeed: 0.1097s/iter; left time: 3576.1329s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0645306\n",
      "\tspeed: 0.1110s/iter; left time: 3608.8125s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0771525\n",
      "\tspeed: 0.1112s/iter; left time: 3602.2172s\n",
      "Epoch: 8 cost time: 00h:04m:56.05s\n",
      "Epoch: 8 | Train Loss: 0.0726925 Vali Loss: 0.0763515 Test Loss: 0.0873776\n",
      "Validation loss decreased (0.077165 --> 0.076351).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0700596\n",
      "\tspeed: 0.8483s/iter; left time: 27400.5408s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682641\n",
      "\tspeed: 0.1068s/iter; left time: 3438.4740s\n",
      "\titers: 300, epoch: 9 | loss: 0.0712042\n",
      "\tspeed: 0.1058s/iter; left time: 3396.5589s\n",
      "\titers: 400, epoch: 9 | loss: 0.0928532\n",
      "\tspeed: 0.1018s/iter; left time: 3256.7887s\n",
      "\titers: 500, epoch: 9 | loss: 0.0683410\n",
      "\tspeed: 0.0923s/iter; left time: 2945.3917s\n",
      "\titers: 600, epoch: 9 | loss: 0.0719134\n",
      "\tspeed: 0.0929s/iter; left time: 2954.2986s\n",
      "\titers: 700, epoch: 9 | loss: 0.0746341\n",
      "\tspeed: 0.1083s/iter; left time: 3433.2864s\n",
      "\titers: 800, epoch: 9 | loss: 0.0717996\n",
      "\tspeed: 0.1081s/iter; left time: 3415.9624s\n",
      "\titers: 900, epoch: 9 | loss: 0.0635917\n",
      "\tspeed: 0.1108s/iter; left time: 3490.0403s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0834341\n",
      "\tspeed: 0.1088s/iter; left time: 3417.8389s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0663731\n",
      "\tspeed: 0.1089s/iter; left time: 3409.3990s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0829868\n",
      "\tspeed: 0.1053s/iter; left time: 3285.2800s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0871881\n",
      "\tspeed: 0.1051s/iter; left time: 3267.7646s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0649625\n",
      "\tspeed: 0.1134s/iter; left time: 3514.3495s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0966050\n",
      "\tspeed: 0.1094s/iter; left time: 3380.9430s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0693577\n",
      "\tspeed: 0.1075s/iter; left time: 3309.8356s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0917838\n",
      "\tspeed: 0.1078s/iter; left time: 3308.2852s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0823744\n",
      "\tspeed: 0.1092s/iter; left time: 3341.2545s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0787729\n",
      "\tspeed: 0.1115s/iter; left time: 3401.8354s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0798299\n",
      "\tspeed: 0.1109s/iter; left time: 3371.8748s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0721684\n",
      "\tspeed: 0.1051s/iter; left time: 3183.9160s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0481129\n",
      "\tspeed: 0.1122s/iter; left time: 3387.8625s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0763919\n",
      "\tspeed: 0.1104s/iter; left time: 3322.2478s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0701488\n",
      "\tspeed: 0.1112s/iter; left time: 3337.2648s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0688713\n",
      "\tspeed: 0.1103s/iter; left time: 3298.5658s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0775270\n",
      "\tspeed: 0.1129s/iter; left time: 3364.0563s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0692621\n",
      "\tspeed: 0.1053s/iter; left time: 3127.6035s\n",
      "Epoch: 9 cost time: 00h:04m:50.70s\n",
      "Epoch: 9 | Train Loss: 0.0721007 Vali Loss: 0.0764830 Test Loss: 0.0873338\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0644606\n",
      "\tspeed: 0.8025s/iter; left time: 23754.2632s\n",
      "\titers: 200, epoch: 10 | loss: 0.0641842\n",
      "\tspeed: 0.1061s/iter; left time: 3129.7400s\n",
      "\titers: 300, epoch: 10 | loss: 0.0595393\n",
      "\tspeed: 0.1087s/iter; left time: 3194.5724s\n",
      "\titers: 400, epoch: 10 | loss: 0.0690156\n",
      "\tspeed: 0.1098s/iter; left time: 3216.7597s\n",
      "\titers: 500, epoch: 10 | loss: 0.0633710\n",
      "\tspeed: 0.0970s/iter; left time: 2833.3464s\n",
      "\titers: 600, epoch: 10 | loss: 0.0694625\n",
      "\tspeed: 0.0930s/iter; left time: 2706.4901s\n",
      "\titers: 700, epoch: 10 | loss: 0.0710054\n",
      "\tspeed: 0.1083s/iter; left time: 3139.8130s\n",
      "\titers: 800, epoch: 10 | loss: 0.0822758\n",
      "\tspeed: 0.1082s/iter; left time: 3127.0047s\n",
      "\titers: 900, epoch: 10 | loss: 0.0806922\n",
      "\tspeed: 0.1116s/iter; left time: 3214.2149s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0616231\n",
      "\tspeed: 0.1109s/iter; left time: 3182.5863s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0697792\n",
      "\tspeed: 0.1112s/iter; left time: 3180.0163s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0686159\n",
      "\tspeed: 0.1107s/iter; left time: 3154.7294s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0619783\n",
      "\tspeed: 0.1082s/iter; left time: 3073.4356s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0592824\n",
      "\tspeed: 0.1095s/iter; left time: 3099.8693s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0626494\n",
      "\tspeed: 0.1101s/iter; left time: 3106.1527s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0534205\n",
      "\tspeed: 0.1083s/iter; left time: 3042.3639s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0724649\n",
      "\tspeed: 0.1136s/iter; left time: 3180.4326s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0587640\n",
      "\tspeed: 0.1104s/iter; left time: 3081.2379s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0587747\n",
      "\tspeed: 0.1057s/iter; left time: 2938.6587s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0710408\n",
      "\tspeed: 0.1133s/iter; left time: 3139.0543s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0719662\n",
      "\tspeed: 0.1104s/iter; left time: 3047.7932s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0728131\n",
      "\tspeed: 0.1086s/iter; left time: 2987.4905s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0668237\n",
      "\tspeed: 0.1100s/iter; left time: 3013.3548s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0772574\n",
      "\tspeed: 0.1104s/iter; left time: 3013.3305s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0698502\n",
      "\tspeed: 0.1083s/iter; left time: 2945.2437s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0658091\n",
      "\tspeed: 0.1074s/iter; left time: 2909.8978s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0772609\n",
      "\tspeed: 0.1115s/iter; left time: 3011.1167s\n",
      "Epoch: 10 cost time: 00h:04m:51.75s\n",
      "Epoch: 10 | Train Loss: 0.0715281 Vali Loss: 0.0768491 Test Loss: 0.0877656\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0705548\n",
      "\tspeed: 0.8282s/iter; left time: 22278.7704s\n",
      "\titers: 200, epoch: 11 | loss: 0.0814234\n",
      "\tspeed: 0.1113s/iter; left time: 2984.2600s\n",
      "\titers: 300, epoch: 11 | loss: 0.0766159\n",
      "\tspeed: 0.1065s/iter; left time: 2842.5832s\n",
      "\titers: 400, epoch: 11 | loss: 0.0666164\n",
      "\tspeed: 0.1105s/iter; left time: 2938.3383s\n",
      "\titers: 500, epoch: 11 | loss: 0.0851309\n",
      "\tspeed: 0.1102s/iter; left time: 2920.8379s\n",
      "\titers: 600, epoch: 11 | loss: 0.0598273\n",
      "\tspeed: 0.1055s/iter; left time: 2785.9542s\n",
      "\titers: 700, epoch: 11 | loss: 0.0648270\n",
      "\tspeed: 0.0929s/iter; left time: 2442.2023s\n",
      "\titers: 800, epoch: 11 | loss: 0.0735529\n",
      "\tspeed: 0.1014s/iter; left time: 2657.7652s\n",
      "\titers: 900, epoch: 11 | loss: 0.0741642\n",
      "\tspeed: 0.1045s/iter; left time: 2728.0876s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0763345\n",
      "\tspeed: 0.1104s/iter; left time: 2870.5199s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0667310\n",
      "\tspeed: 0.1110s/iter; left time: 2876.2636s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0605709\n",
      "\tspeed: 0.1140s/iter; left time: 2941.7807s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0713719\n",
      "\tspeed: 0.1060s/iter; left time: 2723.4465s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0633434\n",
      "\tspeed: 0.1098s/iter; left time: 2810.0570s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0653598\n",
      "\tspeed: 0.1108s/iter; left time: 2824.6625s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0680930\n",
      "\tspeed: 0.1064s/iter; left time: 2701.8241s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0699883\n",
      "\tspeed: 0.1087s/iter; left time: 2750.4270s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0625792\n",
      "\tspeed: 0.1104s/iter; left time: 2781.9939s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0612677\n",
      "\tspeed: 0.1038s/iter; left time: 2604.9303s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0619615\n",
      "\tspeed: 0.1009s/iter; left time: 2523.1171s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0626441\n",
      "\tspeed: 0.1081s/iter; left time: 2691.7353s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0826620\n",
      "\tspeed: 0.1099s/iter; left time: 2724.4135s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0550705\n",
      "\tspeed: 0.1069s/iter; left time: 2640.8076s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0661533\n",
      "\tspeed: 0.1057s/iter; left time: 2600.3102s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0531935\n",
      "\tspeed: 0.1121s/iter; left time: 2747.7091s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0776297\n",
      "\tspeed: 0.1105s/iter; left time: 2695.8331s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0609898\n",
      "\tspeed: 0.1095s/iter; left time: 2660.0296s\n",
      "Epoch: 11 cost time: 00h:04m:51.31s\n",
      "Epoch: 11 | Train Loss: 0.0709394 Vali Loss: 0.0760373 Test Loss: 0.0874976\n",
      "Validation loss decreased (0.076351 --> 0.076037).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0698360\n",
      "\tspeed: 0.8425s/iter; left time: 20389.9715s\n",
      "\titers: 200, epoch: 12 | loss: 0.0743771\n",
      "\tspeed: 0.1071s/iter; left time: 2580.5142s\n",
      "\titers: 300, epoch: 12 | loss: 0.0555990\n",
      "\tspeed: 0.1112s/iter; left time: 2669.7897s\n",
      "\titers: 400, epoch: 12 | loss: 0.0786083\n",
      "\tspeed: 0.1126s/iter; left time: 2690.1301s\n",
      "\titers: 500, epoch: 12 | loss: 0.0606389\n",
      "\tspeed: 0.1096s/iter; left time: 2609.3021s\n",
      "\titers: 600, epoch: 12 | loss: 0.0734370\n",
      "\tspeed: 0.1038s/iter; left time: 2461.1635s\n",
      "\titers: 700, epoch: 12 | loss: 0.0739000\n",
      "\tspeed: 0.1059s/iter; left time: 2499.7290s\n",
      "\titers: 800, epoch: 12 | loss: 0.0816224\n",
      "\tspeed: 0.1115s/iter; left time: 2620.3555s\n",
      "\titers: 900, epoch: 12 | loss: 0.0803305\n",
      "\tspeed: 0.1052s/iter; left time: 2462.5591s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0797503\n",
      "\tspeed: 0.1013s/iter; left time: 2360.3035s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0675827\n",
      "\tspeed: 0.1100s/iter; left time: 2551.0573s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0542938\n",
      "\tspeed: 0.1094s/iter; left time: 2527.3739s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0686269\n",
      "\tspeed: 0.1096s/iter; left time: 2521.8804s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0769948\n",
      "\tspeed: 0.1062s/iter; left time: 2431.1388s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0635036\n",
      "\tspeed: 0.1100s/iter; left time: 2507.5247s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0607219\n",
      "\tspeed: 0.1107s/iter; left time: 2512.1850s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0650394\n",
      "\tspeed: 0.1110s/iter; left time: 2509.5838s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0484897\n",
      "\tspeed: 0.1094s/iter; left time: 2462.2564s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0698879\n",
      "\tspeed: 0.1093s/iter; left time: 2448.3290s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0646443\n",
      "\tspeed: 0.1103s/iter; left time: 2459.3817s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0637422\n",
      "\tspeed: 0.1075s/iter; left time: 2387.3584s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0639093\n",
      "\tspeed: 0.1081s/iter; left time: 2388.8837s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0698840\n",
      "\tspeed: 0.1115s/iter; left time: 2453.2758s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0890961\n",
      "\tspeed: 0.1114s/iter; left time: 2439.1833s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0697590\n",
      "\tspeed: 0.1082s/iter; left time: 2357.9412s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0774608\n",
      "\tspeed: 0.1105s/iter; left time: 2397.1399s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0616158\n",
      "\tspeed: 0.1107s/iter; left time: 2390.1788s\n",
      "Epoch: 12 cost time: 00h:04m:54.59s\n",
      "Epoch: 12 | Train Loss: 0.0704062 Vali Loss: 0.0770078 Test Loss: 0.0877966\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0546673\n",
      "\tspeed: 0.8202s/iter; left time: 17635.6559s\n",
      "\titers: 200, epoch: 13 | loss: 0.0609576\n",
      "\tspeed: 0.1102s/iter; left time: 2357.6652s\n",
      "\titers: 300, epoch: 13 | loss: 0.0664079\n",
      "\tspeed: 0.1102s/iter; left time: 2347.3200s\n",
      "\titers: 400, epoch: 13 | loss: 0.0634391\n",
      "\tspeed: 0.1108s/iter; left time: 2350.0295s\n",
      "\titers: 500, epoch: 13 | loss: 0.0723079\n",
      "\tspeed: 0.1117s/iter; left time: 2357.7013s\n",
      "\titers: 600, epoch: 13 | loss: 0.0553009\n",
      "\tspeed: 0.1129s/iter; left time: 2370.2741s\n",
      "\titers: 700, epoch: 13 | loss: 0.0620531\n",
      "\tspeed: 0.1013s/iter; left time: 2117.8089s\n",
      "\titers: 800, epoch: 13 | loss: 0.0668294\n",
      "\tspeed: 0.1048s/iter; left time: 2180.9029s\n",
      "\titers: 900, epoch: 13 | loss: 0.0879992\n",
      "\tspeed: 0.1114s/iter; left time: 2306.2266s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0732709\n",
      "\tspeed: 0.1099s/iter; left time: 2263.8093s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0752854\n",
      "\tspeed: 0.1085s/iter; left time: 2224.3502s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0625487\n",
      "\tspeed: 0.1091s/iter; left time: 2226.4642s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0654915\n",
      "\tspeed: 0.1058s/iter; left time: 2148.4246s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0481577\n",
      "\tspeed: 0.1078s/iter; left time: 2177.1117s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0789210\n",
      "\tspeed: 0.1110s/iter; left time: 2232.0067s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0560561\n",
      "\tspeed: 0.1136s/iter; left time: 2271.1564s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0794257\n",
      "\tspeed: 0.1125s/iter; left time: 2238.4848s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0690987\n",
      "\tspeed: 0.1096s/iter; left time: 2170.2160s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0847440\n",
      "\tspeed: 0.1113s/iter; left time: 2192.4113s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0696600\n",
      "\tspeed: 0.1091s/iter; left time: 2137.5071s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0735426\n",
      "\tspeed: 0.1077s/iter; left time: 2100.3816s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0604367\n",
      "\tspeed: 0.1073s/iter; left time: 2080.9730s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0683664\n",
      "\tspeed: 0.1124s/iter; left time: 2168.5280s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0862813\n",
      "\tspeed: 0.1068s/iter; left time: 2051.4222s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0711070\n",
      "\tspeed: 0.1078s/iter; left time: 2058.5884s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0755761\n",
      "\tspeed: 0.1096s/iter; left time: 2082.0700s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0758683\n",
      "\tspeed: 0.1109s/iter; left time: 2096.8716s\n",
      "Epoch: 13 cost time: 00h:04m:55.76s\n",
      "Epoch: 13 | Train Loss: 0.0698340 Vali Loss: 0.0759958 Test Loss: 0.0877444\n",
      "Validation loss decreased (0.076037 --> 0.075996).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0701379\n",
      "\tspeed: 0.8883s/iter; left time: 16700.1934s\n",
      "\titers: 200, epoch: 14 | loss: 0.0656885\n",
      "\tspeed: 0.1095s/iter; left time: 2048.3491s\n",
      "\titers: 300, epoch: 14 | loss: 0.0754617\n",
      "\tspeed: 0.1136s/iter; left time: 2112.1459s\n",
      "\titers: 400, epoch: 14 | loss: 0.0614114\n",
      "\tspeed: 0.1063s/iter; left time: 1967.3740s\n",
      "\titers: 500, epoch: 14 | loss: 0.0665783\n",
      "\tspeed: 0.1077s/iter; left time: 1982.1856s\n",
      "\titers: 600, epoch: 14 | loss: 0.0606005\n",
      "\tspeed: 0.1071s/iter; left time: 1959.7207s\n",
      "\titers: 700, epoch: 14 | loss: 0.0746587\n",
      "\tspeed: 0.1105s/iter; left time: 2010.8746s\n",
      "\titers: 800, epoch: 14 | loss: 0.0650777\n",
      "\tspeed: 0.1054s/iter; left time: 1907.9687s\n",
      "\titers: 900, epoch: 14 | loss: 0.0670985\n",
      "\tspeed: 0.1094s/iter; left time: 1968.7735s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0570620\n",
      "\tspeed: 0.1103s/iter; left time: 1973.8065s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0688099\n",
      "\tspeed: 0.1076s/iter; left time: 1915.7875s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0759139\n",
      "\tspeed: 0.0980s/iter; left time: 1735.4136s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0744558\n",
      "\tspeed: 0.1087s/iter; left time: 1912.9928s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0595178\n",
      "\tspeed: 0.1121s/iter; left time: 1961.8173s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0907364\n",
      "\tspeed: 0.1107s/iter; left time: 1926.3845s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0818383\n",
      "\tspeed: 0.1069s/iter; left time: 1849.6803s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0607890\n",
      "\tspeed: 0.1108s/iter; left time: 1905.8442s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0769098\n",
      "\tspeed: 0.1121s/iter; left time: 1916.8510s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0667415\n",
      "\tspeed: 0.1119s/iter; left time: 1903.0954s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0673113\n",
      "\tspeed: 0.1011s/iter; left time: 1708.2724s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0658833\n",
      "\tspeed: 0.1100s/iter; left time: 1848.3007s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0668054\n",
      "\tspeed: 0.1075s/iter; left time: 1795.0825s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0635448\n",
      "\tspeed: 0.1104s/iter; left time: 1833.5337s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0714409\n",
      "\tspeed: 0.1115s/iter; left time: 1840.5387s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0650972\n",
      "\tspeed: 0.1088s/iter; left time: 1784.3146s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0667197\n",
      "\tspeed: 0.1094s/iter; left time: 1782.6689s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0685410\n",
      "\tspeed: 0.1103s/iter; left time: 1787.7031s\n",
      "Epoch: 14 cost time: 00h:04m:54.04s\n",
      "Epoch: 14 | Train Loss: 0.0692304 Vali Loss: 0.0769487 Test Loss: 0.0887596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0771260\n",
      "\tspeed: 0.8146s/iter; left time: 13116.5973s\n",
      "\titers: 200, epoch: 15 | loss: 0.0620635\n",
      "\tspeed: 0.1113s/iter; left time: 1780.4934s\n",
      "\titers: 300, epoch: 15 | loss: 0.0627780\n",
      "\tspeed: 0.1120s/iter; left time: 1780.9493s\n",
      "\titers: 400, epoch: 15 | loss: 0.0707769\n",
      "\tspeed: 0.1083s/iter; left time: 1711.2169s\n",
      "\titers: 500, epoch: 15 | loss: 0.0696634\n",
      "\tspeed: 0.1079s/iter; left time: 1694.2205s\n",
      "\titers: 600, epoch: 15 | loss: 0.0650278\n",
      "\tspeed: 0.1097s/iter; left time: 1711.7300s\n",
      "\titers: 700, epoch: 15 | loss: 0.0639995\n",
      "\tspeed: 0.1051s/iter; left time: 1629.2626s\n",
      "\titers: 800, epoch: 15 | loss: 0.0587405\n",
      "\tspeed: 0.1108s/iter; left time: 1707.1222s\n",
      "\titers: 900, epoch: 15 | loss: 0.0600749\n",
      "\tspeed: 0.1098s/iter; left time: 1679.7681s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0557684\n",
      "\tspeed: 0.1071s/iter; left time: 1627.8241s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0578018\n",
      "\tspeed: 0.1109s/iter; left time: 1674.8477s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0601186\n",
      "\tspeed: 0.1132s/iter; left time: 1698.2480s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0765588\n",
      "\tspeed: 0.1100s/iter; left time: 1639.7105s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0610047\n",
      "\tspeed: 0.1095s/iter; left time: 1620.5008s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0888861\n",
      "\tspeed: 0.1119s/iter; left time: 1645.6113s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0738855\n",
      "\tspeed: 0.1112s/iter; left time: 1624.1855s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0744591\n",
      "\tspeed: 0.1103s/iter; left time: 1600.0948s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0750879\n",
      "\tspeed: 0.1060s/iter; left time: 1526.2966s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0650800\n",
      "\tspeed: 0.1077s/iter; left time: 1540.0342s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0538406\n",
      "\tspeed: 0.1096s/iter; left time: 1556.4559s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0607099\n",
      "\tspeed: 0.1090s/iter; left time: 1536.6943s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0656057\n",
      "\tspeed: 0.1095s/iter; left time: 1533.7352s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0621926\n",
      "\tspeed: 0.1098s/iter; left time: 1525.8476s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0767209\n",
      "\tspeed: 0.1099s/iter; left time: 1516.1534s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0655404\n",
      "\tspeed: 0.1080s/iter; left time: 1479.1893s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0790902\n",
      "\tspeed: 0.1102s/iter; left time: 1499.1115s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0678713\n",
      "\tspeed: 0.1126s/iter; left time: 1520.5166s\n",
      "Epoch: 15 cost time: 00h:04m:56.44s\n",
      "Epoch: 15 | Train Loss: 0.0686730 Vali Loss: 0.0765555 Test Loss: 0.0886747\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0662201\n",
      "\tspeed: 0.8254s/iter; left time: 11060.6672s\n",
      "\titers: 200, epoch: 16 | loss: 0.0593740\n",
      "\tspeed: 0.1092s/iter; left time: 1452.7100s\n",
      "\titers: 300, epoch: 16 | loss: 0.0666328\n",
      "\tspeed: 0.1128s/iter; left time: 1489.5958s\n",
      "\titers: 400, epoch: 16 | loss: 0.0546329\n",
      "\tspeed: 0.1110s/iter; left time: 1454.4778s\n",
      "\titers: 500, epoch: 16 | loss: 0.0779098\n",
      "\tspeed: 0.1102s/iter; left time: 1433.2353s\n",
      "\titers: 600, epoch: 16 | loss: 0.0673902\n",
      "\tspeed: 0.1110s/iter; left time: 1431.3927s\n",
      "\titers: 700, epoch: 16 | loss: 0.0889152\n",
      "\tspeed: 0.1132s/iter; left time: 1449.5401s\n",
      "\titers: 800, epoch: 16 | loss: 0.0624732\n",
      "\tspeed: 0.1042s/iter; left time: 1323.1227s\n",
      "\titers: 900, epoch: 16 | loss: 0.0669911\n",
      "\tspeed: 0.1067s/iter; left time: 1345.0003s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0697562\n",
      "\tspeed: 0.1109s/iter; left time: 1386.0151s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0636544\n",
      "\tspeed: 0.1117s/iter; left time: 1384.6617s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0551249\n",
      "\tspeed: 0.1106s/iter; left time: 1360.6116s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0716457\n",
      "\tspeed: 0.1077s/iter; left time: 1314.2514s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0630568\n",
      "\tspeed: 0.1097s/iter; left time: 1327.7423s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0741567\n",
      "\tspeed: 0.1114s/iter; left time: 1336.9530s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0702697\n",
      "\tspeed: 0.1094s/iter; left time: 1301.8930s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0711427\n",
      "\tspeed: 0.1043s/iter; left time: 1230.8323s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0765287\n",
      "\tspeed: 0.1099s/iter; left time: 1285.9557s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0689238\n",
      "\tspeed: 0.0990s/iter; left time: 1148.9031s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0663680\n",
      "\tspeed: 0.0990s/iter; left time: 1138.4814s\n",
      "\titers: 2100, epoch: 16 | loss: 0.0683312\n",
      "\tspeed: 0.1081s/iter; left time: 1232.6075s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0802281\n",
      "\tspeed: 0.1021s/iter; left time: 1154.3883s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0690996\n",
      "\tspeed: 0.1084s/iter; left time: 1214.3935s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0705913\n",
      "\tspeed: 0.1124s/iter; left time: 1247.2462s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0616952\n",
      "\tspeed: 0.1128s/iter; left time: 1241.0017s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0703709\n",
      "\tspeed: 0.1001s/iter; left time: 1091.7297s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0757938\n",
      "\tspeed: 0.1099s/iter; left time: 1187.0010s\n",
      "Epoch: 16 cost time: 00h:04m:53.07s\n",
      "Epoch: 16 | Train Loss: 0.0680917 Vali Loss: 0.0757173 Test Loss: 0.0888481\n",
      "Validation loss decreased (0.075996 --> 0.075717).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0602886\n",
      "\tspeed: 0.8382s/iter; left time: 8969.6277s\n",
      "\titers: 200, epoch: 17 | loss: 0.0741756\n",
      "\tspeed: 0.1118s/iter; left time: 1185.2204s\n",
      "\titers: 300, epoch: 17 | loss: 0.0749503\n",
      "\tspeed: 0.1098s/iter; left time: 1152.8388s\n",
      "\titers: 400, epoch: 17 | loss: 0.0676071\n",
      "\tspeed: 0.1076s/iter; left time: 1119.2921s\n",
      "\titers: 500, epoch: 17 | loss: 0.0766121\n",
      "\tspeed: 0.1094s/iter; left time: 1127.2117s\n",
      "\titers: 600, epoch: 17 | loss: 0.0681831\n",
      "\tspeed: 0.1077s/iter; left time: 1098.8033s\n",
      "\titers: 700, epoch: 17 | loss: 0.0637438\n",
      "\tspeed: 0.1027s/iter; left time: 1037.4919s\n",
      "\titers: 800, epoch: 17 | loss: 0.0544146\n",
      "\tspeed: 0.1089s/iter; left time: 1089.0261s\n",
      "\titers: 900, epoch: 17 | loss: 0.0586022\n",
      "\tspeed: 0.1099s/iter; left time: 1088.4634s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0685345\n",
      "\tspeed: 0.1082s/iter; left time: 1060.2047s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0778984\n",
      "\tspeed: 0.1079s/iter; left time: 1046.2538s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0712703\n",
      "\tspeed: 0.1066s/iter; left time: 1023.5521s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0754869\n",
      "\tspeed: 0.1079s/iter; left time: 1025.2685s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0578931\n",
      "\tspeed: 0.1111s/iter; left time: 1044.4273s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0653812\n",
      "\tspeed: 0.1078s/iter; left time: 1002.7731s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0751554\n",
      "\tspeed: 0.1103s/iter; left time: 1014.8200s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0487651\n",
      "\tspeed: 0.1126s/iter; left time: 1024.4030s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0528689\n",
      "\tspeed: 0.1107s/iter; left time: 996.0641s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0630695\n",
      "\tspeed: 0.1081s/iter; left time: 962.2848s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0712237\n",
      "\tspeed: 0.1127s/iter; left time: 991.9414s\n",
      "\titers: 2100, epoch: 17 | loss: 0.0660280\n",
      "\tspeed: 0.1120s/iter; left time: 974.8656s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0734475\n",
      "\tspeed: 0.1087s/iter; left time: 935.0716s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0648981\n",
      "\tspeed: 0.1115s/iter; left time: 947.5711s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0795884\n",
      "\tspeed: 0.1127s/iter; left time: 947.0921s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0597170\n",
      "\tspeed: 0.1096s/iter; left time: 909.3958s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0678583\n",
      "\tspeed: 0.1083s/iter; left time: 888.4279s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0624113\n",
      "\tspeed: 0.1055s/iter; left time: 854.5917s\n",
      "Epoch: 17 cost time: 00h:04m:55.33s\n",
      "Epoch: 17 | Train Loss: 0.0675561 Vali Loss: 0.0763748 Test Loss: 0.0893890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0761119\n",
      "\tspeed: 0.8114s/iter; left time: 6492.1159s\n",
      "\titers: 200, epoch: 18 | loss: 0.0620413\n",
      "\tspeed: 0.1041s/iter; left time: 822.4270s\n",
      "\titers: 300, epoch: 18 | loss: 0.0632600\n",
      "\tspeed: 0.1029s/iter; left time: 803.0581s\n",
      "\titers: 400, epoch: 18 | loss: 0.0618512\n",
      "\tspeed: 0.1087s/iter; left time: 837.0851s\n",
      "\titers: 500, epoch: 18 | loss: 0.0845522\n",
      "\tspeed: 0.1120s/iter; left time: 851.4685s\n",
      "\titers: 600, epoch: 18 | loss: 0.0672775\n",
      "\tspeed: 0.1105s/iter; left time: 829.1314s\n",
      "\titers: 700, epoch: 18 | loss: 0.0740555\n",
      "\tspeed: 0.1088s/iter; left time: 805.3801s\n",
      "\titers: 800, epoch: 18 | loss: 0.0813232\n",
      "\tspeed: 0.1064s/iter; left time: 777.0917s\n",
      "\titers: 900, epoch: 18 | loss: 0.0673259\n",
      "\tspeed: 0.1031s/iter; left time: 742.2310s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0704761\n",
      "\tspeed: 0.1132s/iter; left time: 803.4865s\n",
      "\titers: 1100, epoch: 18 | loss: 0.0638964\n",
      "\tspeed: 0.1076s/iter; left time: 753.2458s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0759692\n",
      "\tspeed: 0.1079s/iter; left time: 744.8555s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0558550\n",
      "\tspeed: 0.1131s/iter; left time: 769.3891s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0616353\n",
      "\tspeed: 0.1127s/iter; left time: 755.4325s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0576693\n",
      "\tspeed: 0.1072s/iter; left time: 707.3184s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0680424\n",
      "\tspeed: 0.1123s/iter; left time: 729.8193s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0637852\n",
      "\tspeed: 0.1156s/iter; left time: 739.9086s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0623822\n",
      "\tspeed: 0.1120s/iter; left time: 705.7677s\n",
      "\titers: 1900, epoch: 18 | loss: 0.0737275\n",
      "\tspeed: 0.1094s/iter; left time: 678.0998s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0682334\n",
      "\tspeed: 0.1091s/iter; left time: 665.8755s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0714906\n",
      "\tspeed: 0.1111s/iter; left time: 666.9554s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0640245\n",
      "\tspeed: 0.1099s/iter; left time: 648.2562s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0709489\n",
      "\tspeed: 0.1055s/iter; left time: 612.1698s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0636141\n",
      "\tspeed: 0.1108s/iter; left time: 631.4024s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0703164\n",
      "\tspeed: 0.0937s/iter; left time: 524.6586s\n",
      "\titers: 2600, epoch: 18 | loss: 0.0567367\n",
      "\tspeed: 0.1045s/iter; left time: 574.9026s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0659374\n",
      "\tspeed: 0.1076s/iter; left time: 581.2743s\n",
      "Epoch: 18 cost time: 00h:04m:51.77s\n",
      "Epoch: 18 | Train Loss: 0.0669565 Vali Loss: 0.0767569 Test Loss: 0.0896325\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0641657\n",
      "\tspeed: 0.8260s/iter; left time: 4378.3790s\n",
      "\titers: 200, epoch: 19 | loss: 0.0646652\n",
      "\tspeed: 0.1099s/iter; left time: 571.3944s\n",
      "\titers: 300, epoch: 19 | loss: 0.0688067\n",
      "\tspeed: 0.1095s/iter; left time: 558.6163s\n",
      "\titers: 400, epoch: 19 | loss: 0.0726631\n",
      "\tspeed: 0.1091s/iter; left time: 545.7130s\n",
      "\titers: 500, epoch: 19 | loss: 0.0629248\n",
      "\tspeed: 0.1061s/iter; left time: 520.1324s\n",
      "\titers: 600, epoch: 19 | loss: 0.0645429\n",
      "\tspeed: 0.1100s/iter; left time: 528.1849s\n",
      "\titers: 700, epoch: 19 | loss: 0.0700852\n",
      "\tspeed: 0.1062s/iter; left time: 499.4078s\n",
      "\titers: 800, epoch: 19 | loss: 0.0639606\n",
      "\tspeed: 0.1087s/iter; left time: 500.1422s\n",
      "\titers: 900, epoch: 19 | loss: 0.0706320\n",
      "\tspeed: 0.1066s/iter; left time: 479.7827s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0695931\n",
      "\tspeed: 0.1084s/iter; left time: 477.2130s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0555278\n",
      "\tspeed: 0.1096s/iter; left time: 471.4998s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0572991\n",
      "\tspeed: 0.1086s/iter; left time: 456.2259s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0593480\n",
      "\tspeed: 0.1111s/iter; left time: 455.5478s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0589893\n",
      "\tspeed: 0.1108s/iter; left time: 443.2908s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0764863\n",
      "\tspeed: 0.1080s/iter; left time: 421.2104s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0735297\n",
      "\tspeed: 0.1072s/iter; left time: 407.5560s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0632856\n",
      "\tspeed: 0.1068s/iter; left time: 395.2795s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0747443\n",
      "\tspeed: 0.1059s/iter; left time: 381.2796s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0623893\n",
      "\tspeed: 0.1111s/iter; left time: 388.7902s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0588666\n",
      "\tspeed: 0.1100s/iter; left time: 374.2189s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0590336\n",
      "\tspeed: 0.1128s/iter; left time: 372.2514s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0580204\n",
      "\tspeed: 0.1100s/iter; left time: 352.0380s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0696771\n",
      "\tspeed: 0.1097s/iter; left time: 340.0633s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0632380\n",
      "\tspeed: 0.1110s/iter; left time: 333.2404s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0646824\n",
      "\tspeed: 0.1113s/iter; left time: 322.7485s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0611326\n",
      "\tspeed: 0.1100s/iter; left time: 308.1299s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0704009\n",
      "\tspeed: 0.1096s/iter; left time: 296.0131s\n",
      "Epoch: 19 cost time: 00h:04m:55.17s\n",
      "Epoch: 19 | Train Loss: 0.0663659 Vali Loss: 0.0764648 Test Loss: 0.0899169\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0586496\n",
      "\tspeed: 0.8276s/iter; left time: 2152.6475s\n",
      "\titers: 200, epoch: 20 | loss: 0.0800007\n",
      "\tspeed: 0.1138s/iter; left time: 284.6904s\n",
      "\titers: 300, epoch: 20 | loss: 0.0638429\n",
      "\tspeed: 0.1102s/iter; left time: 264.5052s\n",
      "\titers: 400, epoch: 20 | loss: 0.0633048\n",
      "\tspeed: 0.1076s/iter; left time: 247.6345s\n",
      "\titers: 500, epoch: 20 | loss: 0.0687320\n",
      "\tspeed: 0.1116s/iter; left time: 245.6225s\n",
      "\titers: 600, epoch: 20 | loss: 0.0529214\n",
      "\tspeed: 0.1096s/iter; left time: 230.1679s\n",
      "\titers: 700, epoch: 20 | loss: 0.0601209\n",
      "\tspeed: 0.1077s/iter; left time: 215.5340s\n",
      "\titers: 800, epoch: 20 | loss: 0.0800438\n",
      "\tspeed: 0.1040s/iter; left time: 197.7148s\n",
      "\titers: 900, epoch: 20 | loss: 0.0602363\n",
      "\tspeed: 0.1121s/iter; left time: 201.8428s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0697969\n",
      "\tspeed: 0.1109s/iter; left time: 188.6217s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0687058\n",
      "\tspeed: 0.1086s/iter; left time: 173.8558s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0644168\n",
      "\tspeed: 0.1008s/iter; left time: 151.3714s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0669396\n",
      "\tspeed: 0.1098s/iter; left time: 153.7710s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0674091\n",
      "\tspeed: 0.0998s/iter; left time: 129.7804s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0665299\n",
      "\tspeed: 0.1165s/iter; left time: 139.9462s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0696090\n",
      "\tspeed: 0.1093s/iter; left time: 120.3603s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0573200\n",
      "\tspeed: 0.1094s/iter; left time: 109.4616s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0645324\n",
      "\tspeed: 0.1076s/iter; left time: 96.9392s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0616310\n",
      "\tspeed: 0.0996s/iter; left time: 79.7489s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0692438\n",
      "\tspeed: 0.1085s/iter; left time: 76.0304s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0552743\n",
      "\tspeed: 0.1076s/iter; left time: 64.6686s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0585063\n",
      "\tspeed: 0.1105s/iter; left time: 55.3684s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0722827\n",
      "\tspeed: 0.1128s/iter; left time: 45.2478s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0635998\n",
      "\tspeed: 0.1099s/iter; left time: 33.0692s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0766662\n",
      "\tspeed: 0.1079s/iter; left time: 21.6875s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0652511\n",
      "\tspeed: 0.0968s/iter; left time: 9.7817s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0614809\n",
      "\tspeed: 0.0954s/iter; left time: 0.0954s\n",
      "Epoch: 20 cost time: 00h:04m:51.58s\n",
      "Epoch: 20 | Train Loss: 0.0657833 Vali Loss: 0.0763873 Test Loss: 0.0895967\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.02272237464785576, rmse:0.15073943138122559, mae:0.08884815871715546, rse:0.5839818716049194\n",
      "success delete checkpoints\n",
      "Intermediate time for FR and pred_len 168: 02h:03m:39.96s\n",
      "\n",
      "Intermediate time for FR: 05h:17m:47.31s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 86835\n",
      "val 18651\n",
      "test 18651\n",
      "[2024-11-05 22:51:37,044] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 22:51:38,105] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 22:51:38,105] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 22:51:38,105] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 22:51:38,213] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 22:51:38,213] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 22:51:38,892] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 22:51:38,894] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 22:51:38,894] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 22:51:38,896] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 22:51:38,896] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 22:51:38,896] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 22:51:38,896] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 22:51:38,896] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 22:51:38,896] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 22:51:38,896] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 22:51:39,213] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 22:51:39,214] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 22:51:39,214] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 175.4 GB, percent = 23.2%\n",
      "[2024-11-05 22:51:39,343] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 22:51:39,344] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 22:51:39,344] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 175.4 GB, percent = 23.2%\n",
      "[2024-11-05 22:51:39,344] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 22:51:39,470] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 22:51:39,471] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 22:51:39,471] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 175.4 GB, percent = 23.2%\n",
      "[2024-11-05 22:51:39,471] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 22:51:39,472] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 22:51:39,472] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 22:51:39,472] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 22:51:39,472] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f85f0ceac90>\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 22:51:39,473] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 22:51:39,474] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 22:51:39,475] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1851583\n",
      "\tspeed: 0.1635s/iter; left time: 8855.2462s\n",
      "\titers: 200, epoch: 1 | loss: 0.1896693\n",
      "\tspeed: 0.1200s/iter; left time: 6488.2224s\n",
      "\titers: 300, epoch: 1 | loss: 0.1405992\n",
      "\tspeed: 0.1245s/iter; left time: 6716.0777s\n",
      "\titers: 400, epoch: 1 | loss: 0.1309502\n",
      "\tspeed: 0.1258s/iter; left time: 6773.2459s\n",
      "\titers: 500, epoch: 1 | loss: 0.1308798\n",
      "\tspeed: 0.1185s/iter; left time: 6368.5442s\n",
      "\titers: 600, epoch: 1 | loss: 0.0993159\n",
      "\tspeed: 0.1183s/iter; left time: 6349.0251s\n",
      "\titers: 700, epoch: 1 | loss: 0.0872111\n",
      "\tspeed: 0.1156s/iter; left time: 6192.6452s\n",
      "\titers: 800, epoch: 1 | loss: 0.1069587\n",
      "\tspeed: 0.1106s/iter; left time: 5915.4523s\n",
      "\titers: 900, epoch: 1 | loss: 0.1003581\n",
      "\tspeed: 0.1197s/iter; left time: 6386.9636s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0901062\n",
      "\tspeed: 0.1262s/iter; left time: 6723.5776s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0908355\n",
      "\tspeed: 0.1218s/iter; left time: 6476.0381s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0859928\n",
      "\tspeed: 0.1124s/iter; left time: 5961.5971s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0868541\n",
      "\tspeed: 0.1227s/iter; left time: 6499.8484s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0852073\n",
      "\tspeed: 0.1186s/iter; left time: 6271.6435s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0842514\n",
      "\tspeed: 0.1186s/iter; left time: 6255.8543s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0954585\n",
      "\tspeed: 0.1155s/iter; left time: 6084.5236s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0983973\n",
      "\tspeed: 0.1035s/iter; left time: 5442.3461s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0729079\n",
      "\tspeed: 0.1120s/iter; left time: 5873.4776s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0956048\n",
      "\tspeed: 0.1207s/iter; left time: 6319.9522s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0882810\n",
      "\tspeed: 0.1216s/iter; left time: 6352.4047s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0904718\n",
      "\tspeed: 0.1218s/iter; left time: 6353.0150s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0850427\n",
      "\tspeed: 0.1194s/iter; left time: 6215.8024s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0875075\n",
      "\tspeed: 0.1215s/iter; left time: 6313.0765s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0887870\n",
      "\tspeed: 0.1223s/iter; left time: 6342.2781s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0765667\n",
      "\tspeed: 0.1219s/iter; left time: 6307.4878s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0721322\n",
      "\tspeed: 0.1209s/iter; left time: 6247.4216s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0766703\n",
      "\tspeed: 0.1190s/iter; left time: 6136.6427s\n",
      "Epoch: 1 cost time: 00h:05m:24.39s\n",
      "Epoch: 1 | Train Loss: 0.1044628 Vali Loss: 0.0674386 Test Loss: 0.0705287\n",
      "Validation loss decreased (inf --> 0.067439).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0921422\n",
      "\tspeed: 0.9796s/iter; left time: 50399.9359s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833007\n",
      "\tspeed: 0.1081s/iter; left time: 5551.7037s\n",
      "\titers: 300, epoch: 2 | loss: 0.0729004\n",
      "\tspeed: 0.1087s/iter; left time: 5568.1552s\n",
      "\titers: 400, epoch: 2 | loss: 0.0800711\n",
      "\tspeed: 0.1114s/iter; left time: 5698.3956s\n",
      "\titers: 500, epoch: 2 | loss: 0.0856265\n",
      "\tspeed: 0.1076s/iter; left time: 5495.2575s\n",
      "\titers: 600, epoch: 2 | loss: 0.0829333\n",
      "\tspeed: 0.1088s/iter; left time: 5545.5597s\n",
      "\titers: 700, epoch: 2 | loss: 0.0822752\n",
      "\tspeed: 0.1064s/iter; left time: 5412.1722s\n",
      "\titers: 800, epoch: 2 | loss: 0.0862437\n",
      "\tspeed: 0.1074s/iter; left time: 5450.5265s\n",
      "\titers: 900, epoch: 2 | loss: 0.0676165\n",
      "\tspeed: 0.1069s/iter; left time: 5413.1223s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0690659\n",
      "\tspeed: 0.1108s/iter; left time: 5599.5604s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0822617\n",
      "\tspeed: 0.1112s/iter; left time: 5607.4293s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0995053\n",
      "\tspeed: 0.1089s/iter; left time: 5483.8841s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0759744\n",
      "\tspeed: 0.1040s/iter; left time: 5225.6746s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0787862\n",
      "\tspeed: 0.1111s/iter; left time: 5572.5310s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0664430\n",
      "\tspeed: 0.1129s/iter; left time: 5648.0191s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0843145\n",
      "\tspeed: 0.1108s/iter; left time: 5531.8775s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0781444\n",
      "\tspeed: 0.1021s/iter; left time: 5087.9535s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0804416\n",
      "\tspeed: 0.1119s/iter; left time: 5567.2816s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0867685\n",
      "\tspeed: 0.1123s/iter; left time: 5573.3867s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0691059\n",
      "\tspeed: 0.1081s/iter; left time: 5356.6220s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0798801\n",
      "\tspeed: 0.1103s/iter; left time: 5454.1828s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0859650\n",
      "\tspeed: 0.1081s/iter; left time: 5335.7513s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0678316\n",
      "\tspeed: 0.1106s/iter; left time: 5447.6101s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0749916\n",
      "\tspeed: 0.1070s/iter; left time: 5261.2903s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0696270\n",
      "\tspeed: 0.1098s/iter; left time: 5384.7381s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0941857\n",
      "\tspeed: 0.1117s/iter; left time: 5465.5033s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0867455\n",
      "\tspeed: 0.1084s/iter; left time: 5295.7574s\n",
      "Epoch: 2 cost time: 00h:04m:55.75s\n",
      "Epoch: 2 | Train Loss: 0.0812896 Vali Loss: 0.0645173 Test Loss: 0.0675343\n",
      "Validation loss decreased (0.067439 --> 0.064517).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0647804\n",
      "\tspeed: 0.8582s/iter; left time: 41823.9638s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733927\n",
      "\tspeed: 0.1120s/iter; left time: 5446.8421s\n",
      "\titers: 300, epoch: 3 | loss: 0.0871677\n",
      "\tspeed: 0.1126s/iter; left time: 5465.1260s\n",
      "\titers: 400, epoch: 3 | loss: 0.0864079\n",
      "\tspeed: 0.1065s/iter; left time: 5159.7331s\n",
      "\titers: 500, epoch: 3 | loss: 0.0774063\n",
      "\tspeed: 0.1061s/iter; left time: 5127.0921s\n",
      "\titers: 600, epoch: 3 | loss: 0.0876310\n",
      "\tspeed: 0.1089s/iter; left time: 5251.1783s\n",
      "\titers: 700, epoch: 3 | loss: 0.0812009\n",
      "\tspeed: 0.1069s/iter; left time: 5147.9780s\n",
      "\titers: 800, epoch: 3 | loss: 0.0810997\n",
      "\tspeed: 0.1045s/iter; left time: 5017.3379s\n",
      "\titers: 900, epoch: 3 | loss: 0.0666417\n",
      "\tspeed: 0.1047s/iter; left time: 5017.5447s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0780576\n",
      "\tspeed: 0.1063s/iter; left time: 5086.1318s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0602891\n",
      "\tspeed: 0.1108s/iter; left time: 5289.3871s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0924189\n",
      "\tspeed: 0.1088s/iter; left time: 5181.4639s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0733844\n",
      "\tspeed: 0.1029s/iter; left time: 4890.1568s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0668497\n",
      "\tspeed: 0.1040s/iter; left time: 4931.3642s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0706853\n",
      "\tspeed: 0.1109s/iter; left time: 5248.9818s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0696469\n",
      "\tspeed: 0.1085s/iter; left time: 5126.4382s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0791732\n",
      "\tspeed: 0.1109s/iter; left time: 5225.8982s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0654266\n",
      "\tspeed: 0.1094s/iter; left time: 5143.3349s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0752592\n",
      "\tspeed: 0.1054s/iter; left time: 4948.7373s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0607582\n",
      "\tspeed: 0.1103s/iter; left time: 5164.3470s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0663724\n",
      "\tspeed: 0.1093s/iter; left time: 5109.2538s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0662067\n",
      "\tspeed: 0.1109s/iter; left time: 5173.0941s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0644915\n",
      "\tspeed: 0.0978s/iter; left time: 4550.4569s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0611179\n",
      "\tspeed: 0.1029s/iter; left time: 4780.1489s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0781493\n",
      "\tspeed: 0.1094s/iter; left time: 5068.7912s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0839737\n",
      "\tspeed: 0.1057s/iter; left time: 4886.7913s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0684751\n",
      "\tspeed: 0.1087s/iter; left time: 5015.1163s\n",
      "Epoch: 3 cost time: 00h:04m:51.96s\n",
      "Epoch: 3 | Train Loss: 0.0774696 Vali Loss: 0.0608470 Test Loss: 0.0636243\n",
      "Validation loss decreased (0.064517 --> 0.060847).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0771001\n",
      "\tspeed: 0.8641s/iter; left time: 39767.1520s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828164\n",
      "\tspeed: 0.1102s/iter; left time: 5062.1924s\n",
      "\titers: 300, epoch: 4 | loss: 0.0709321\n",
      "\tspeed: 0.1109s/iter; left time: 5083.8964s\n",
      "\titers: 400, epoch: 4 | loss: 0.0732248\n",
      "\tspeed: 0.1105s/iter; left time: 5052.7814s\n",
      "\titers: 500, epoch: 4 | loss: 0.0765916\n",
      "\tspeed: 0.1078s/iter; left time: 4917.4627s\n",
      "\titers: 600, epoch: 4 | loss: 0.0644685\n",
      "\tspeed: 0.1033s/iter; left time: 4703.7558s\n",
      "\titers: 700, epoch: 4 | loss: 0.0753873\n",
      "\tspeed: 0.0938s/iter; left time: 4260.1232s\n",
      "\titers: 800, epoch: 4 | loss: 0.0885832\n",
      "\tspeed: 0.1041s/iter; left time: 4719.4769s\n",
      "\titers: 900, epoch: 4 | loss: 0.0712130\n",
      "\tspeed: 0.1081s/iter; left time: 4888.1180s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0893699\n",
      "\tspeed: 0.1080s/iter; left time: 4873.4151s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0855681\n",
      "\tspeed: 0.1092s/iter; left time: 4918.1718s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0917989\n",
      "\tspeed: 0.1058s/iter; left time: 4753.9935s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0656261\n",
      "\tspeed: 0.1091s/iter; left time: 4890.2437s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0857961\n",
      "\tspeed: 0.1103s/iter; left time: 4934.3730s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0647826\n",
      "\tspeed: 0.1086s/iter; left time: 4847.3273s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0727398\n",
      "\tspeed: 0.1084s/iter; left time: 4828.1249s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0728944\n",
      "\tspeed: 0.1089s/iter; left time: 4836.6631s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0711310\n",
      "\tspeed: 0.1117s/iter; left time: 4951.6417s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0806949\n",
      "\tspeed: 0.1093s/iter; left time: 4833.8018s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0818514\n",
      "\tspeed: 0.1082s/iter; left time: 4775.4835s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0634665\n",
      "\tspeed: 0.1106s/iter; left time: 4867.4518s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0902779\n",
      "\tspeed: 0.1111s/iter; left time: 4880.2183s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0541194\n",
      "\tspeed: 0.1101s/iter; left time: 4825.0414s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0841147\n",
      "\tspeed: 0.1085s/iter; left time: 4743.5553s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0627967\n",
      "\tspeed: 0.1099s/iter; left time: 4792.4804s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0698297\n",
      "\tspeed: 0.1105s/iter; left time: 4809.6695s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0902219\n",
      "\tspeed: 0.1120s/iter; left time: 4863.9277s\n",
      "Epoch: 4 cost time: 00h:04m:54.51s\n",
      "Epoch: 4 | Train Loss: 0.0751333 Vali Loss: 0.0612787 Test Loss: 0.0637516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0666326\n",
      "\tspeed: 0.8544s/iter; left time: 37002.8954s\n",
      "\titers: 200, epoch: 5 | loss: 0.0644114\n",
      "\tspeed: 0.1098s/iter; left time: 4746.2748s\n",
      "\titers: 300, epoch: 5 | loss: 0.0682919\n",
      "\tspeed: 0.1118s/iter; left time: 4820.2364s\n",
      "\titers: 400, epoch: 5 | loss: 0.0620925\n",
      "\tspeed: 0.1112s/iter; left time: 4783.4368s\n",
      "\titers: 500, epoch: 5 | loss: 0.0656417\n",
      "\tspeed: 0.1120s/iter; left time: 4805.4472s\n",
      "\titers: 600, epoch: 5 | loss: 0.0605619\n",
      "\tspeed: 0.1108s/iter; left time: 4744.3216s\n",
      "\titers: 700, epoch: 5 | loss: 0.0655195\n",
      "\tspeed: 0.1121s/iter; left time: 4787.4008s\n",
      "\titers: 800, epoch: 5 | loss: 0.0878194\n",
      "\tspeed: 0.1117s/iter; left time: 4759.6609s\n",
      "\titers: 900, epoch: 5 | loss: 0.0873649\n",
      "\tspeed: 0.1122s/iter; left time: 4767.4016s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0885441\n",
      "\tspeed: 0.1119s/iter; left time: 4747.2472s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0773957\n",
      "\tspeed: 0.1103s/iter; left time: 4666.4211s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0709531\n",
      "\tspeed: 0.1116s/iter; left time: 4708.6076s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0936801\n",
      "\tspeed: 0.1109s/iter; left time: 4671.3438s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0627290\n",
      "\tspeed: 0.1096s/iter; left time: 4602.2074s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0610520\n",
      "\tspeed: 0.1045s/iter; left time: 4379.6945s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0573209\n",
      "\tspeed: 0.1084s/iter; left time: 4532.1279s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0619759\n",
      "\tspeed: 0.1116s/iter; left time: 4653.6557s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0639222\n",
      "\tspeed: 0.1099s/iter; left time: 4574.8761s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0814546\n",
      "\tspeed: 0.1109s/iter; left time: 4601.2856s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0636832\n",
      "\tspeed: 0.1129s/iter; left time: 4673.1334s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0727494\n",
      "\tspeed: 0.1127s/iter; left time: 4654.6460s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0792865\n",
      "\tspeed: 0.1130s/iter; left time: 4658.3684s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0708624\n",
      "\tspeed: 0.1103s/iter; left time: 4535.2037s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0737677\n",
      "\tspeed: 0.1112s/iter; left time: 4560.5046s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0617305\n",
      "\tspeed: 0.1113s/iter; left time: 4554.3393s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0600602\n",
      "\tspeed: 0.1102s/iter; left time: 4496.5648s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0768839\n",
      "\tspeed: 0.1114s/iter; left time: 4536.7242s\n",
      "Epoch: 5 cost time: 00h:05m:01.59s\n",
      "Epoch: 5 | Train Loss: 0.0736190 Vali Loss: 0.0602323 Test Loss: 0.0629788\n",
      "Validation loss decreased (0.060847 --> 0.060232).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0755906\n",
      "\tspeed: 0.8702s/iter; left time: 35325.1507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862673\n",
      "\tspeed: 0.1124s/iter; left time: 4553.7383s\n",
      "\titers: 300, epoch: 6 | loss: 0.0546819\n",
      "\tspeed: 0.1125s/iter; left time: 4542.8097s\n",
      "\titers: 400, epoch: 6 | loss: 0.0591614\n",
      "\tspeed: 0.1140s/iter; left time: 4593.1907s\n",
      "\titers: 500, epoch: 6 | loss: 0.0898387\n",
      "\tspeed: 0.1103s/iter; left time: 4435.1773s\n",
      "\titers: 600, epoch: 6 | loss: 0.0772325\n",
      "\tspeed: 0.1099s/iter; left time: 4408.4162s\n",
      "\titers: 700, epoch: 6 | loss: 0.0667717\n",
      "\tspeed: 0.1144s/iter; left time: 4574.9141s\n",
      "\titers: 800, epoch: 6 | loss: 0.0708816\n",
      "\tspeed: 0.1148s/iter; left time: 4579.4367s\n",
      "\titers: 900, epoch: 6 | loss: 0.0802714\n",
      "\tspeed: 0.1115s/iter; left time: 4438.5924s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0587699\n",
      "\tspeed: 0.1113s/iter; left time: 4417.0208s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0817802\n",
      "\tspeed: 0.1114s/iter; left time: 4412.2093s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0701434\n",
      "\tspeed: 0.1123s/iter; left time: 4434.4814s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0784634\n",
      "\tspeed: 0.1113s/iter; left time: 4383.3548s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0716445\n",
      "\tspeed: 0.1097s/iter; left time: 4311.1508s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0575276\n",
      "\tspeed: 0.1104s/iter; left time: 4327.1829s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0727779\n",
      "\tspeed: 0.1111s/iter; left time: 4341.6632s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0698283\n",
      "\tspeed: 0.1113s/iter; left time: 4339.2529s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0537121\n",
      "\tspeed: 0.1114s/iter; left time: 4334.2940s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0726687\n",
      "\tspeed: 0.1102s/iter; left time: 4276.9460s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0684895\n",
      "\tspeed: 0.1107s/iter; left time: 4282.4081s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0757992\n",
      "\tspeed: 0.1112s/iter; left time: 4291.2632s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0624314\n",
      "\tspeed: 0.1111s/iter; left time: 4278.4754s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0650265\n",
      "\tspeed: 0.1109s/iter; left time: 4259.5572s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0914823\n",
      "\tspeed: 0.1105s/iter; left time: 4230.8658s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0612239\n",
      "\tspeed: 0.1014s/iter; left time: 3872.7234s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0734139\n",
      "\tspeed: 0.1133s/iter; left time: 4316.0632s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0664306\n",
      "\tspeed: 0.1119s/iter; left time: 4253.2958s\n",
      "Epoch: 6 cost time: 00h:05m:01.92s\n",
      "Epoch: 6 | Train Loss: 0.0725451 Vali Loss: 0.0602230 Test Loss: 0.0628235\n",
      "Validation loss decreased (0.060232 --> 0.060223).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0571372\n",
      "\tspeed: 0.8745s/iter; left time: 33128.8613s\n",
      "\titers: 200, epoch: 7 | loss: 0.0777741\n",
      "\tspeed: 0.1141s/iter; left time: 4312.0674s\n",
      "\titers: 300, epoch: 7 | loss: 0.0671924\n",
      "\tspeed: 0.1102s/iter; left time: 4153.3606s\n",
      "\titers: 400, epoch: 7 | loss: 0.0564569\n",
      "\tspeed: 0.1123s/iter; left time: 4220.5765s\n",
      "\titers: 500, epoch: 7 | loss: 0.0798100\n",
      "\tspeed: 0.1151s/iter; left time: 4315.5992s\n",
      "\titers: 600, epoch: 7 | loss: 0.0698144\n",
      "\tspeed: 0.1077s/iter; left time: 4027.9980s\n",
      "\titers: 700, epoch: 7 | loss: 0.0904418\n",
      "\tspeed: 0.0989s/iter; left time: 3687.5422s\n",
      "\titers: 800, epoch: 7 | loss: 0.0698428\n",
      "\tspeed: 0.0917s/iter; left time: 3409.0279s\n",
      "\titers: 900, epoch: 7 | loss: 0.0766821\n",
      "\tspeed: 0.1056s/iter; left time: 3917.5563s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0648788\n",
      "\tspeed: 0.1074s/iter; left time: 3971.3176s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0866726\n",
      "\tspeed: 0.1095s/iter; left time: 4037.0006s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0945042\n",
      "\tspeed: 0.1122s/iter; left time: 4127.6207s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0677338\n",
      "\tspeed: 0.1108s/iter; left time: 4065.2509s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0625327\n",
      "\tspeed: 0.1056s/iter; left time: 3862.9825s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0608290\n",
      "\tspeed: 0.1103s/iter; left time: 4022.8075s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0821567\n",
      "\tspeed: 0.1115s/iter; left time: 4057.2349s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0716091\n",
      "\tspeed: 0.1024s/iter; left time: 3715.8436s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0633846\n",
      "\tspeed: 0.0930s/iter; left time: 3363.4165s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0902185\n",
      "\tspeed: 0.1087s/iter; left time: 3923.1093s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0677963\n",
      "\tspeed: 0.1110s/iter; left time: 3994.9269s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0752863\n",
      "\tspeed: 0.1114s/iter; left time: 3998.6687s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0742749\n",
      "\tspeed: 0.1091s/iter; left time: 3902.3536s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0892707\n",
      "\tspeed: 0.1112s/iter; left time: 3969.1011s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0730157\n",
      "\tspeed: 0.1124s/iter; left time: 4001.0370s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0640349\n",
      "\tspeed: 0.1113s/iter; left time: 3948.6834s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0810196\n",
      "\tspeed: 0.1113s/iter; left time: 3939.3265s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0651655\n",
      "\tspeed: 0.1113s/iter; left time: 3928.3119s\n",
      "Epoch: 7 cost time: 00h:04m:54.91s\n",
      "Epoch: 7 | Train Loss: 0.0716687 Vali Loss: 0.0595544 Test Loss: 0.0624185\n",
      "Validation loss decreased (0.060223 --> 0.059554).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0701472\n",
      "\tspeed: 0.8627s/iter; left time: 30341.6104s\n",
      "\titers: 200, epoch: 8 | loss: 0.0694159\n",
      "\tspeed: 0.0917s/iter; left time: 3215.4254s\n",
      "\titers: 300, epoch: 8 | loss: 0.0596473\n",
      "\tspeed: 0.0949s/iter; left time: 3319.9244s\n",
      "\titers: 400, epoch: 8 | loss: 0.0729665\n",
      "\tspeed: 0.0927s/iter; left time: 3232.0642s\n",
      "\titers: 500, epoch: 8 | loss: 0.0790489\n",
      "\tspeed: 0.1049s/iter; left time: 3647.1353s\n",
      "\titers: 600, epoch: 8 | loss: 0.0600218\n",
      "\tspeed: 0.1113s/iter; left time: 3858.4564s\n",
      "\titers: 700, epoch: 8 | loss: 0.0736242\n",
      "\tspeed: 0.1108s/iter; left time: 3830.6892s\n",
      "\titers: 800, epoch: 8 | loss: 0.0761142\n",
      "\tspeed: 0.1110s/iter; left time: 3827.8390s\n",
      "\titers: 900, epoch: 8 | loss: 0.0568186\n",
      "\tspeed: 0.1110s/iter; left time: 3815.3979s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0640273\n",
      "\tspeed: 0.1095s/iter; left time: 3752.8738s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0739808\n",
      "\tspeed: 0.1116s/iter; left time: 3814.6285s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0622818\n",
      "\tspeed: 0.1115s/iter; left time: 3799.4881s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0857471\n",
      "\tspeed: 0.1113s/iter; left time: 3782.2102s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0638848\n",
      "\tspeed: 0.1069s/iter; left time: 3622.2788s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0843071\n",
      "\tspeed: 0.1051s/iter; left time: 3550.7848s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0780362\n",
      "\tspeed: 0.0935s/iter; left time: 3147.5140s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0616395\n",
      "\tspeed: 0.0917s/iter; left time: 3076.7258s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0652054\n",
      "\tspeed: 0.1042s/iter; left time: 3488.6584s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0586747\n",
      "\tspeed: 0.1037s/iter; left time: 3459.3488s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0525555\n",
      "\tspeed: 0.1110s/iter; left time: 3691.4580s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0683479\n",
      "\tspeed: 0.1155s/iter; left time: 3831.3193s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0687534\n",
      "\tspeed: 0.1124s/iter; left time: 3716.4432s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0675758\n",
      "\tspeed: 0.1104s/iter; left time: 3640.7418s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0795344\n",
      "\tspeed: 0.1089s/iter; left time: 3578.6448s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0789239\n",
      "\tspeed: 0.1108s/iter; left time: 3631.6202s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0719332\n",
      "\tspeed: 0.1115s/iter; left time: 3644.2191s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0688149\n",
      "\tspeed: 0.1116s/iter; left time: 3634.9828s\n",
      "Epoch: 8 cost time: 00h:04m:49.20s\n",
      "Epoch: 8 | Train Loss: 0.0709614 Vali Loss: 0.0593200 Test Loss: 0.0622572\n",
      "Validation loss decreased (0.059554 --> 0.059320).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0512352\n",
      "\tspeed: 0.8719s/iter; left time: 28298.7645s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579643\n",
      "\tspeed: 0.1108s/iter; left time: 3585.5536s\n",
      "\titers: 300, epoch: 9 | loss: 0.0638062\n",
      "\tspeed: 0.1113s/iter; left time: 3590.3988s\n",
      "\titers: 400, epoch: 9 | loss: 0.0820355\n",
      "\tspeed: 0.1098s/iter; left time: 3529.9972s\n",
      "\titers: 500, epoch: 9 | loss: 0.0679640\n",
      "\tspeed: 0.1115s/iter; left time: 3574.3245s\n",
      "\titers: 600, epoch: 9 | loss: 0.0786319\n",
      "\tspeed: 0.1115s/iter; left time: 3561.8779s\n",
      "\titers: 700, epoch: 9 | loss: 0.0668189\n",
      "\tspeed: 0.1125s/iter; left time: 3585.0974s\n",
      "\titers: 800, epoch: 9 | loss: 0.0750190\n",
      "\tspeed: 0.1110s/iter; left time: 3524.9071s\n",
      "\titers: 900, epoch: 9 | loss: 0.0588689\n",
      "\tspeed: 0.1115s/iter; left time: 3529.2866s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0779510\n",
      "\tspeed: 0.1114s/iter; left time: 3514.0108s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0763264\n",
      "\tspeed: 0.1122s/iter; left time: 3529.8896s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0745665\n",
      "\tspeed: 0.1105s/iter; left time: 3466.4067s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0657175\n",
      "\tspeed: 0.1108s/iter; left time: 3463.1316s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0792039\n",
      "\tspeed: 0.1113s/iter; left time: 3467.4510s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0600951\n",
      "\tspeed: 0.1121s/iter; left time: 3480.3619s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0986681\n",
      "\tspeed: 0.1110s/iter; left time: 3435.6930s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0488287\n",
      "\tspeed: 0.1108s/iter; left time: 3419.8063s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0910544\n",
      "\tspeed: 0.1105s/iter; left time: 3399.6515s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0778994\n",
      "\tspeed: 0.1082s/iter; left time: 3315.6301s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0907591\n",
      "\tspeed: 0.0929s/iter; left time: 2838.7502s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0740909\n",
      "\tspeed: 0.1108s/iter; left time: 3375.1393s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0921000\n",
      "\tspeed: 0.1085s/iter; left time: 3295.0146s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0664618\n",
      "\tspeed: 0.1126s/iter; left time: 3407.9808s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0572801\n",
      "\tspeed: 0.1138s/iter; left time: 3431.0191s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0785109\n",
      "\tspeed: 0.1114s/iter; left time: 3349.7939s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0589267\n",
      "\tspeed: 0.1103s/iter; left time: 3304.5616s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0677443\n",
      "\tspeed: 0.1114s/iter; left time: 3325.5100s\n",
      "Epoch: 9 cost time: 00h:05m:00.08s\n",
      "Epoch: 9 | Train Loss: 0.0704210 Vali Loss: 0.0582110 Test Loss: 0.0605948\n",
      "Validation loss decreased (0.059320 --> 0.058211).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0600175\n",
      "\tspeed: 0.8685s/iter; left time: 25833.1972s\n",
      "\titers: 200, epoch: 10 | loss: 0.0642688\n",
      "\tspeed: 0.1101s/iter; left time: 3262.5185s\n",
      "\titers: 300, epoch: 10 | loss: 0.0750425\n",
      "\tspeed: 0.1109s/iter; left time: 3276.6253s\n",
      "\titers: 400, epoch: 10 | loss: 0.0679206\n",
      "\tspeed: 0.1109s/iter; left time: 3266.1446s\n",
      "\titers: 500, epoch: 10 | loss: 0.0666797\n",
      "\tspeed: 0.1132s/iter; left time: 3323.1536s\n",
      "\titers: 600, epoch: 10 | loss: 0.0703106\n",
      "\tspeed: 0.1087s/iter; left time: 3179.4238s\n",
      "\titers: 700, epoch: 10 | loss: 0.0743619\n",
      "\tspeed: 0.1107s/iter; left time: 3227.1824s\n",
      "\titers: 800, epoch: 10 | loss: 0.0588059\n",
      "\tspeed: 0.1068s/iter; left time: 3100.7414s\n",
      "\titers: 900, epoch: 10 | loss: 0.0728827\n",
      "\tspeed: 0.0916s/iter; left time: 2651.5433s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0814928\n",
      "\tspeed: 0.0922s/iter; left time: 2659.6662s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0783780\n",
      "\tspeed: 0.0963s/iter; left time: 2766.8189s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0637280\n",
      "\tspeed: 0.1102s/iter; left time: 3156.1745s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0744967\n",
      "\tspeed: 0.1111s/iter; left time: 3171.3426s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0562558\n",
      "\tspeed: 0.1108s/iter; left time: 3151.8041s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0637931\n",
      "\tspeed: 0.1108s/iter; left time: 3141.0740s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0755076\n",
      "\tspeed: 0.1103s/iter; left time: 3115.4422s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0665627\n",
      "\tspeed: 0.1103s/iter; left time: 3102.9402s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0600282\n",
      "\tspeed: 0.1120s/iter; left time: 3141.3131s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0591334\n",
      "\tspeed: 0.1105s/iter; left time: 3087.2219s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0600669\n",
      "\tspeed: 0.0915s/iter; left time: 2547.3947s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0580529\n",
      "\tspeed: 0.0920s/iter; left time: 2552.9082s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0728620\n",
      "\tspeed: 0.1069s/iter; left time: 2954.2585s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0563242\n",
      "\tspeed: 0.1128s/iter; left time: 3108.2899s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0575170\n",
      "\tspeed: 0.1129s/iter; left time: 3097.7314s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0600950\n",
      "\tspeed: 0.1109s/iter; left time: 3033.4096s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0610115\n",
      "\tspeed: 0.1073s/iter; left time: 2924.0761s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0665297\n",
      "\tspeed: 0.1013s/iter; left time: 2750.4022s\n",
      "Epoch: 10 cost time: 00h:04m:50.33s\n",
      "Epoch: 10 | Train Loss: 0.0698349 Vali Loss: 0.0585172 Test Loss: 0.0612939\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0815858\n",
      "\tspeed: 0.8546s/iter; left time: 23101.5609s\n",
      "\titers: 200, epoch: 11 | loss: 0.0741079\n",
      "\tspeed: 0.1114s/iter; left time: 2999.2683s\n",
      "\titers: 300, epoch: 11 | loss: 0.0656348\n",
      "\tspeed: 0.0993s/iter; left time: 2664.7346s\n",
      "\titers: 400, epoch: 11 | loss: 0.0681296\n",
      "\tspeed: 0.1055s/iter; left time: 2820.2417s\n",
      "\titers: 500, epoch: 11 | loss: 0.0815347\n",
      "\tspeed: 0.0963s/iter; left time: 2563.6058s\n",
      "\titers: 600, epoch: 11 | loss: 0.0591361\n",
      "\tspeed: 0.1106s/iter; left time: 2933.0021s\n",
      "\titers: 700, epoch: 11 | loss: 0.0650938\n",
      "\tspeed: 0.1116s/iter; left time: 2950.2029s\n",
      "\titers: 800, epoch: 11 | loss: 0.0637617\n",
      "\tspeed: 0.1108s/iter; left time: 2918.3186s\n",
      "\titers: 900, epoch: 11 | loss: 0.0659567\n",
      "\tspeed: 0.1079s/iter; left time: 2830.1123s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0619472\n",
      "\tspeed: 0.1091s/iter; left time: 2852.0935s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0654344\n",
      "\tspeed: 0.1108s/iter; left time: 2885.2794s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0681081\n",
      "\tspeed: 0.1100s/iter; left time: 2851.1576s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0663103\n",
      "\tspeed: 0.1015s/iter; left time: 2621.1567s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0669588\n",
      "\tspeed: 0.1147s/iter; left time: 2951.2689s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0652764\n",
      "\tspeed: 0.1135s/iter; left time: 2909.8966s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0730307\n",
      "\tspeed: 0.1112s/iter; left time: 2837.9823s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0771409\n",
      "\tspeed: 0.1128s/iter; left time: 2868.7149s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0701232\n",
      "\tspeed: 0.1141s/iter; left time: 2890.0161s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0776491\n",
      "\tspeed: 0.1106s/iter; left time: 2790.0525s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0813687\n",
      "\tspeed: 0.1111s/iter; left time: 2791.1375s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0550424\n",
      "\tspeed: 0.1111s/iter; left time: 2782.0704s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0680556\n",
      "\tspeed: 0.1017s/iter; left time: 2534.2726s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0525015\n",
      "\tspeed: 0.1094s/iter; left time: 2717.2954s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0728819\n",
      "\tspeed: 0.1033s/iter; left time: 2554.9659s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0728738\n",
      "\tspeed: 0.1118s/iter; left time: 2753.2922s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0749296\n",
      "\tspeed: 0.1093s/iter; left time: 2681.3696s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0753787\n",
      "\tspeed: 0.1143s/iter; left time: 2793.3729s\n",
      "Epoch: 11 cost time: 00h:04m:55.64s\n",
      "Epoch: 11 | Train Loss: 0.0693435 Vali Loss: 0.0579570 Test Loss: 0.0610815\n",
      "Validation loss decreased (0.058211 --> 0.057957).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0734250\n",
      "\tspeed: 0.8910s/iter; left time: 21668.5045s\n",
      "\titers: 200, epoch: 12 | loss: 0.0918366\n",
      "\tspeed: 0.1088s/iter; left time: 2635.0906s\n",
      "\titers: 300, epoch: 12 | loss: 0.0711465\n",
      "\tspeed: 0.1105s/iter; left time: 2665.1282s\n",
      "\titers: 400, epoch: 12 | loss: 0.0795878\n",
      "\tspeed: 0.1112s/iter; left time: 2669.6966s\n",
      "\titers: 500, epoch: 12 | loss: 0.0576439\n",
      "\tspeed: 0.1108s/iter; left time: 2650.9844s\n",
      "\titers: 600, epoch: 12 | loss: 0.0876988\n",
      "\tspeed: 0.1100s/iter; left time: 2619.9739s\n",
      "\titers: 700, epoch: 12 | loss: 0.0690597\n",
      "\tspeed: 0.1119s/iter; left time: 2653.3986s\n",
      "\titers: 800, epoch: 12 | loss: 0.0678922\n",
      "\tspeed: 0.1135s/iter; left time: 2681.4480s\n",
      "\titers: 900, epoch: 12 | loss: 0.0772286\n",
      "\tspeed: 0.1100s/iter; left time: 2586.2907s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0652505\n",
      "\tspeed: 0.1131s/iter; left time: 2648.0966s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0717284\n",
      "\tspeed: 0.1132s/iter; left time: 2639.5623s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0709080\n",
      "\tspeed: 0.1106s/iter; left time: 2568.9983s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0606154\n",
      "\tspeed: 0.1132s/iter; left time: 2616.6957s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0653422\n",
      "\tspeed: 0.1110s/iter; left time: 2555.4031s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0649190\n",
      "\tspeed: 0.1110s/iter; left time: 2544.0105s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0586061\n",
      "\tspeed: 0.1107s/iter; left time: 2525.4674s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0832536\n",
      "\tspeed: 0.1110s/iter; left time: 2522.5131s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0663743\n",
      "\tspeed: 0.1099s/iter; left time: 2485.9431s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0751225\n",
      "\tspeed: 0.1089s/iter; left time: 2452.8106s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0708253\n",
      "\tspeed: 0.1109s/iter; left time: 2485.8251s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0835345\n",
      "\tspeed: 0.1108s/iter; left time: 2473.1269s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0674329\n",
      "\tspeed: 0.1107s/iter; left time: 2460.0119s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0679872\n",
      "\tspeed: 0.1105s/iter; left time: 2445.0382s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0656307\n",
      "\tspeed: 0.1041s/iter; left time: 2292.9724s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0607896\n",
      "\tspeed: 0.1112s/iter; left time: 2436.3088s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0541787\n",
      "\tspeed: 0.1098s/iter; left time: 2394.7746s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0810494\n",
      "\tspeed: 0.1120s/iter; left time: 2433.1505s\n",
      "Epoch: 12 cost time: 00h:05m:00.93s\n",
      "Epoch: 12 | Train Loss: 0.0688154 Vali Loss: 0.0579043 Test Loss: 0.0610286\n",
      "Validation loss decreased (0.057957 --> 0.057904).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0758406\n",
      "\tspeed: 0.8810s/iter; left time: 19035.0609s\n",
      "\titers: 200, epoch: 13 | loss: 0.0664402\n",
      "\tspeed: 0.1033s/iter; left time: 2222.4763s\n",
      "\titers: 300, epoch: 13 | loss: 0.0607426\n",
      "\tspeed: 0.1126s/iter; left time: 2409.1502s\n",
      "\titers: 400, epoch: 13 | loss: 0.0763412\n",
      "\tspeed: 0.1112s/iter; left time: 2368.1697s\n",
      "\titers: 500, epoch: 13 | loss: 0.0699283\n",
      "\tspeed: 0.1108s/iter; left time: 2350.0233s\n",
      "\titers: 600, epoch: 13 | loss: 0.0681189\n",
      "\tspeed: 0.1108s/iter; left time: 2337.4431s\n",
      "\titers: 700, epoch: 13 | loss: 0.0584503\n",
      "\tspeed: 0.1123s/iter; left time: 2359.8164s\n",
      "\titers: 800, epoch: 13 | loss: 0.0640463\n",
      "\tspeed: 0.1138s/iter; left time: 2378.5546s\n",
      "\titers: 900, epoch: 13 | loss: 0.0611771\n",
      "\tspeed: 0.1128s/iter; left time: 2347.3260s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0756470\n",
      "\tspeed: 0.1080s/iter; left time: 2236.2614s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0562203\n",
      "\tspeed: 0.1112s/iter; left time: 2290.4726s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0456233\n",
      "\tspeed: 0.1108s/iter; left time: 2272.5344s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0816890\n",
      "\tspeed: 0.1104s/iter; left time: 2253.3990s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0771169\n",
      "\tspeed: 0.1073s/iter; left time: 2178.7849s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0516760\n",
      "\tspeed: 0.1041s/iter; left time: 2102.5612s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0723313\n",
      "\tspeed: 0.0971s/iter; left time: 1951.5951s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0681259\n",
      "\tspeed: 0.1117s/iter; left time: 2234.5898s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0693684\n",
      "\tspeed: 0.1108s/iter; left time: 2205.9759s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0656218\n",
      "\tspeed: 0.1059s/iter; left time: 2098.0860s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0733089\n",
      "\tspeed: 0.1116s/iter; left time: 2199.9463s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0636119\n",
      "\tspeed: 0.1135s/iter; left time: 2224.9743s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0644889\n",
      "\tspeed: 0.1122s/iter; left time: 2187.6765s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0570966\n",
      "\tspeed: 0.1091s/iter; left time: 2117.0380s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0856168\n",
      "\tspeed: 0.1110s/iter; left time: 2141.9874s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0730749\n",
      "\tspeed: 0.1111s/iter; left time: 2133.1333s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0736826\n",
      "\tspeed: 0.1113s/iter; left time: 2125.5283s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0652475\n",
      "\tspeed: 0.1040s/iter; left time: 1977.3271s\n",
      "Epoch: 13 cost time: 00h:04m:57.72s\n",
      "Epoch: 13 | Train Loss: 0.0685333 Vali Loss: 0.0581087 Test Loss: 0.0616643\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0788586\n",
      "\tspeed: 0.8534s/iter; left time: 16123.0284s\n",
      "\titers: 200, epoch: 14 | loss: 0.0652545\n",
      "\tspeed: 0.1111s/iter; left time: 2088.1442s\n",
      "\titers: 300, epoch: 14 | loss: 0.0673679\n",
      "\tspeed: 0.1065s/iter; left time: 1991.0937s\n",
      "\titers: 400, epoch: 14 | loss: 0.0741327\n",
      "\tspeed: 0.0918s/iter; left time: 1706.7242s\n",
      "\titers: 500, epoch: 14 | loss: 0.0775125\n",
      "\tspeed: 0.0927s/iter; left time: 1713.3764s\n",
      "\titers: 600, epoch: 14 | loss: 0.0706720\n",
      "\tspeed: 0.0979s/iter; left time: 1800.3745s\n",
      "\titers: 700, epoch: 14 | loss: 0.0522443\n",
      "\tspeed: 0.1039s/iter; left time: 1899.8777s\n",
      "\titers: 800, epoch: 14 | loss: 0.0413472\n",
      "\tspeed: 0.1009s/iter; left time: 1835.8790s\n",
      "\titers: 900, epoch: 14 | loss: 0.0491034\n",
      "\tspeed: 0.1115s/iter; left time: 2017.2308s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0566853\n",
      "\tspeed: 0.1063s/iter; left time: 1913.2469s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0578251\n",
      "\tspeed: 0.1105s/iter; left time: 1977.3996s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0829943\n",
      "\tspeed: 0.1108s/iter; left time: 1971.4865s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0740947\n",
      "\tspeed: 0.1110s/iter; left time: 1963.0446s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0634795\n",
      "\tspeed: 0.1100s/iter; left time: 1934.3020s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0624947\n",
      "\tspeed: 0.1101s/iter; left time: 1925.6970s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0662082\n",
      "\tspeed: 0.1110s/iter; left time: 1930.4648s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0858546\n",
      "\tspeed: 0.1108s/iter; left time: 1916.5620s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0631794\n",
      "\tspeed: 0.1086s/iter; left time: 1867.4313s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0609466\n",
      "\tspeed: 0.1108s/iter; left time: 1894.0979s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0686416\n",
      "\tspeed: 0.1110s/iter; left time: 1885.5066s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0644152\n",
      "\tspeed: 0.1116s/iter; left time: 1884.4354s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0832569\n",
      "\tspeed: 0.1126s/iter; left time: 1891.4247s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0791013\n",
      "\tspeed: 0.1097s/iter; left time: 1831.7782s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0575649\n",
      "\tspeed: 0.1100s/iter; left time: 1825.9426s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0751156\n",
      "\tspeed: 0.1114s/iter; left time: 1837.9981s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0682990\n",
      "\tspeed: 0.0938s/iter; left time: 1537.8706s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0620878\n",
      "\tspeed: 0.1098s/iter; left time: 1788.5577s\n",
      "Epoch: 14 cost time: 00h:04m:51.43s\n",
      "Epoch: 14 | Train Loss: 0.0681188 Vali Loss: 0.0586869 Test Loss: 0.0619512\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0650434\n",
      "\tspeed: 0.8938s/iter; left time: 14460.1238s\n",
      "\titers: 200, epoch: 15 | loss: 0.0598584\n",
      "\tspeed: 0.1188s/iter; left time: 1909.5016s\n",
      "\titers: 300, epoch: 15 | loss: 0.0676129\n",
      "\tspeed: 0.1195s/iter; left time: 1909.3339s\n",
      "\titers: 400, epoch: 15 | loss: 0.0723423\n",
      "\tspeed: 0.1030s/iter; left time: 1635.4471s\n",
      "\titers: 500, epoch: 15 | loss: 0.0663884\n",
      "\tspeed: 0.1100s/iter; left time: 1735.8693s\n",
      "\titers: 600, epoch: 15 | loss: 0.0681057\n",
      "\tspeed: 0.1188s/iter; left time: 1862.8111s\n",
      "\titers: 700, epoch: 15 | loss: 0.0653562\n",
      "\tspeed: 0.1199s/iter; left time: 1867.1898s\n",
      "\titers: 800, epoch: 15 | loss: 0.0666989\n",
      "\tspeed: 0.1107s/iter; left time: 1713.9125s\n",
      "\titers: 900, epoch: 15 | loss: 0.0597021\n",
      "\tspeed: 0.1171s/iter; left time: 1801.0780s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0766062\n",
      "\tspeed: 0.1220s/iter; left time: 1863.6214s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0603577\n",
      "\tspeed: 0.1192s/iter; left time: 1809.1789s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0686030\n",
      "\tspeed: 0.1066s/iter; left time: 1607.3613s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0498057\n",
      "\tspeed: 0.1174s/iter; left time: 1759.1398s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0754516\n",
      "\tspeed: 0.1184s/iter; left time: 1761.1038s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0796645\n",
      "\tspeed: 0.1177s/iter; left time: 1739.3528s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0592015\n",
      "\tspeed: 0.1160s/iter; left time: 1702.1948s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0638401\n",
      "\tspeed: 0.1210s/iter; left time: 1763.7242s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0669481\n",
      "\tspeed: 0.1104s/iter; left time: 1598.2076s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0578073\n",
      "\tspeed: 0.1120s/iter; left time: 1610.9432s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0724017\n",
      "\tspeed: 0.1091s/iter; left time: 1558.4462s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0625106\n",
      "\tspeed: 0.1130s/iter; left time: 1602.3106s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0780056\n",
      "\tspeed: 0.1235s/iter; left time: 1738.5378s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0663293\n",
      "\tspeed: 0.1140s/iter; left time: 1593.8619s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0765920\n",
      "\tspeed: 0.1007s/iter; left time: 1396.9677s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0666724\n",
      "\tspeed: 0.1198s/iter; left time: 1651.2944s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0660892\n",
      "\tspeed: 0.1190s/iter; left time: 1627.5063s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0636557\n",
      "\tspeed: 0.1205s/iter; left time: 1636.5545s\n",
      "Epoch: 15 cost time: 00h:05m:13.59s\n",
      "Epoch: 15 | Train Loss: 0.0678573 Vali Loss: 0.0565290 Test Loss: 0.0598584\n",
      "Validation loss decreased (0.057904 --> 0.056529).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0631209\n",
      "\tspeed: 0.8820s/iter; left time: 11877.5378s\n",
      "\titers: 200, epoch: 16 | loss: 0.0795251\n",
      "\tspeed: 0.1093s/iter; left time: 1460.3808s\n",
      "\titers: 300, epoch: 16 | loss: 0.0614693\n",
      "\tspeed: 0.1161s/iter; left time: 1539.9782s\n",
      "\titers: 400, epoch: 16 | loss: 0.0656032\n",
      "\tspeed: 0.1064s/iter; left time: 1401.1767s\n",
      "\titers: 500, epoch: 16 | loss: 0.0546320\n",
      "\tspeed: 0.1063s/iter; left time: 1389.0109s\n",
      "\titers: 600, epoch: 16 | loss: 0.0657985\n",
      "\tspeed: 0.1046s/iter; left time: 1355.6678s\n",
      "\titers: 700, epoch: 16 | loss: 0.0745588\n",
      "\tspeed: 0.1056s/iter; left time: 1358.6307s\n",
      "\titers: 800, epoch: 16 | loss: 0.0647097\n",
      "\tspeed: 0.1216s/iter; left time: 1552.5884s\n",
      "\titers: 900, epoch: 16 | loss: 0.0602753\n",
      "\tspeed: 0.1998s/iter; left time: 2530.5606s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0768443\n",
      "\tspeed: 0.2287s/iter; left time: 2873.7649s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0662645\n",
      "\tspeed: 0.2319s/iter; left time: 2890.3562s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0667903\n",
      "\tspeed: 0.2341s/iter; left time: 2894.2679s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0648389\n",
      "\tspeed: 0.2301s/iter; left time: 2821.8677s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0689700\n",
      "\tspeed: 0.2289s/iter; left time: 2784.7372s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0808650\n",
      "\tspeed: 0.2274s/iter; left time: 2744.3308s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0555609\n",
      "\tspeed: 0.1198s/iter; left time: 1433.8328s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0623140\n",
      "\tspeed: 0.1066s/iter; left time: 1264.9881s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0579654\n",
      "\tspeed: 0.1128s/iter; left time: 1327.3246s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0493466\n",
      "\tspeed: 0.1120s/iter; left time: 1306.6768s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0698210\n",
      "\tspeed: 0.1080s/iter; left time: 1248.8039s\n",
      "\titers: 2100, epoch: 16 | loss: 0.0753044\n",
      "\tspeed: 0.1141s/iter; left time: 1308.4116s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0627794\n",
      "\tspeed: 0.1120s/iter; left time: 1272.5666s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0786058\n",
      "\tspeed: 0.1099s/iter; left time: 1238.0521s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0709041\n",
      "\tspeed: 0.1113s/iter; left time: 1242.7630s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0627271\n",
      "\tspeed: 0.1110s/iter; left time: 1227.8211s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0646193\n",
      "\tspeed: 0.1110s/iter; left time: 1217.6010s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0724357\n",
      "\tspeed: 0.1124s/iter; left time: 1221.1095s\n",
      "Epoch: 16 cost time: 00h:06m:21.35s\n",
      "Epoch: 16 | Train Loss: 0.0675493 Vali Loss: 0.0575828 Test Loss: 0.0610903\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0666367\n",
      "\tspeed: 0.8522s/iter; left time: 9163.4227s\n",
      "\titers: 200, epoch: 17 | loss: 0.0614539\n",
      "\tspeed: 0.1013s/iter; left time: 1079.5682s\n",
      "\titers: 300, epoch: 17 | loss: 0.0761035\n",
      "\tspeed: 0.1000s/iter; left time: 1055.7548s\n",
      "\titers: 400, epoch: 17 | loss: 0.0678350\n",
      "\tspeed: 0.1192s/iter; left time: 1246.0740s\n",
      "\titers: 500, epoch: 17 | loss: 0.0586687\n",
      "\tspeed: 0.1198s/iter; left time: 1240.1591s\n",
      "\titers: 600, epoch: 17 | loss: 0.0870444\n",
      "\tspeed: 0.1049s/iter; left time: 1075.0838s\n",
      "\titers: 700, epoch: 17 | loss: 0.0631548\n",
      "\tspeed: 0.1049s/iter; left time: 1065.1764s\n",
      "\titers: 800, epoch: 17 | loss: 0.0623753\n",
      "\tspeed: 0.1158s/iter; left time: 1164.4177s\n",
      "\titers: 900, epoch: 17 | loss: 0.0611374\n",
      "\tspeed: 0.1192s/iter; left time: 1186.7817s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0714000\n",
      "\tspeed: 0.1188s/iter; left time: 1170.3317s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0628234\n",
      "\tspeed: 0.1129s/iter; left time: 1101.3001s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0700513\n",
      "\tspeed: 0.1139s/iter; left time: 1099.5522s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0676770\n",
      "\tspeed: 0.1065s/iter; left time: 1017.5802s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0872798\n",
      "\tspeed: 0.1015s/iter; left time: 959.2718s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0634397\n",
      "\tspeed: 0.1154s/iter; left time: 1079.1275s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0798288\n",
      "\tspeed: 0.1169s/iter; left time: 1081.4243s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0628081\n",
      "\tspeed: 0.1154s/iter; left time: 1055.9911s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0707892\n",
      "\tspeed: 0.1117s/iter; left time: 1011.6195s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0751213\n",
      "\tspeed: 0.1126s/iter; left time: 1008.2340s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0686660\n",
      "\tspeed: 0.1159s/iter; left time: 1026.0753s\n",
      "\titers: 2100, epoch: 17 | loss: 0.0595742\n",
      "\tspeed: 0.1154s/iter; left time: 1010.4547s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0595573\n",
      "\tspeed: 0.1051s/iter; left time: 909.1447s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0705073\n",
      "\tspeed: 0.0943s/iter; left time: 806.6145s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0718705\n",
      "\tspeed: 0.1084s/iter; left time: 916.6195s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0698178\n",
      "\tspeed: 0.1128s/iter; left time: 942.6198s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0592912\n",
      "\tspeed: 0.1157s/iter; left time: 954.7280s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0550082\n",
      "\tspeed: 0.1164s/iter; left time: 949.0817s\n",
      "Epoch: 17 cost time: 00h:05m:02.43s\n",
      "Epoch: 17 | Train Loss: 0.0672067 Vali Loss: 0.0576827 Test Loss: 0.0610239\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0789864\n",
      "\tspeed: 0.8624s/iter; left time: 6933.3563s\n",
      "\titers: 200, epoch: 18 | loss: 0.0435059\n",
      "\tspeed: 0.1152s/iter; left time: 914.6468s\n",
      "\titers: 300, epoch: 18 | loss: 0.0671544\n",
      "\tspeed: 0.1164s/iter; left time: 912.1846s\n",
      "\titers: 400, epoch: 18 | loss: 0.0796799\n",
      "\tspeed: 0.1159s/iter; left time: 897.0268s\n",
      "\titers: 500, epoch: 18 | loss: 0.0769822\n",
      "\tspeed: 0.1112s/iter; left time: 849.8696s\n",
      "\titers: 600, epoch: 18 | loss: 0.0684877\n",
      "\tspeed: 0.1066s/iter; left time: 804.0396s\n",
      "\titers: 700, epoch: 18 | loss: 0.0847553\n",
      "\tspeed: 0.1128s/iter; left time: 839.0412s\n",
      "\titers: 800, epoch: 18 | loss: 0.0588445\n",
      "\tspeed: 0.1026s/iter; left time: 753.2849s\n",
      "\titers: 900, epoch: 18 | loss: 0.0584669\n",
      "\tspeed: 0.1193s/iter; left time: 863.8172s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0575440\n",
      "\tspeed: 0.1162s/iter; left time: 829.6596s\n",
      "\titers: 1100, epoch: 18 | loss: 0.0608165\n",
      "\tspeed: 0.1038s/iter; left time: 730.6099s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0741204\n",
      "\tspeed: 0.1046s/iter; left time: 725.9360s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0771337\n",
      "\tspeed: 0.1089s/iter; left time: 745.0385s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0640768\n",
      "\tspeed: 0.1020s/iter; left time: 687.4410s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0621601\n",
      "\tspeed: 0.1113s/iter; left time: 738.7186s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0565347\n",
      "\tspeed: 0.1086s/iter; left time: 710.5439s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0634464\n",
      "\tspeed: 0.1061s/iter; left time: 683.4246s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0826270\n",
      "\tspeed: 0.1335s/iter; left time: 846.6853s\n",
      "\titers: 1900, epoch: 18 | loss: 0.0675448\n",
      "\tspeed: 0.2256s/iter; left time: 1407.7919s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0728097\n",
      "\tspeed: 0.2288s/iter; left time: 1404.9851s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0788385\n",
      "\tspeed: 0.2295s/iter; left time: 1386.3839s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0569580\n",
      "\tspeed: 0.2292s/iter; left time: 1361.3257s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0673283\n",
      "\tspeed: 0.2296s/iter; left time: 1340.9934s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0724924\n",
      "\tspeed: 0.2292s/iter; left time: 1315.7113s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0593836\n",
      "\tspeed: 0.2264s/iter; left time: 1276.7140s\n",
      "\titers: 2600, epoch: 18 | loss: 0.0618837\n",
      "\tspeed: 0.2289s/iter; left time: 1268.1061s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0609959\n",
      "\tspeed: 0.2285s/iter; left time: 1242.9390s\n",
      "Epoch: 18 cost time: 00h:06m:48.78s\n",
      "Epoch: 18 | Train Loss: 0.0667939 Vali Loss: 0.0588081 Test Loss: 0.0623398\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0828640\n",
      "\tspeed: 1.4517s/iter; left time: 7733.2271s\n",
      "\titers: 200, epoch: 19 | loss: 0.0772517\n",
      "\tspeed: 0.1114s/iter; left time: 582.3604s\n",
      "\titers: 300, epoch: 19 | loss: 0.0560412\n",
      "\tspeed: 0.1105s/iter; left time: 566.4811s\n",
      "\titers: 400, epoch: 19 | loss: 0.0647806\n",
      "\tspeed: 0.1126s/iter; left time: 565.8410s\n",
      "\titers: 500, epoch: 19 | loss: 0.0863268\n",
      "\tspeed: 0.1165s/iter; left time: 574.0071s\n",
      "\titers: 600, epoch: 19 | loss: 0.0494796\n",
      "\tspeed: 0.1122s/iter; left time: 541.7874s\n",
      "\titers: 700, epoch: 19 | loss: 0.0642836\n",
      "\tspeed: 0.1087s/iter; left time: 513.7577s\n",
      "\titers: 800, epoch: 19 | loss: 0.0584095\n",
      "\tspeed: 0.1131s/iter; left time: 523.1200s\n",
      "\titers: 900, epoch: 19 | loss: 0.0670932\n",
      "\tspeed: 0.1162s/iter; left time: 526.0792s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0638209\n",
      "\tspeed: 0.1109s/iter; left time: 491.0876s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0763814\n",
      "\tspeed: 0.1102s/iter; left time: 476.6925s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0830418\n",
      "\tspeed: 0.1153s/iter; left time: 487.3204s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0502546\n",
      "\tspeed: 0.1160s/iter; left time: 478.6872s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0668910\n",
      "\tspeed: 0.1095s/iter; left time: 440.9723s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0682701\n",
      "\tspeed: 0.1024s/iter; left time: 402.1001s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0579406\n",
      "\tspeed: 0.0950s/iter; left time: 363.6590s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0660508\n",
      "\tspeed: 0.1106s/iter; left time: 412.1002s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0615531\n",
      "\tspeed: 0.1163s/iter; left time: 421.7762s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0670207\n",
      "\tspeed: 0.1125s/iter; left time: 396.9495s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0482179\n",
      "\tspeed: 0.1146s/iter; left time: 392.6039s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0669298\n",
      "\tspeed: 0.1174s/iter; left time: 390.4859s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0610184\n",
      "\tspeed: 0.1134s/iter; left time: 365.9877s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0640331\n",
      "\tspeed: 0.1120s/iter; left time: 350.3538s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0673938\n",
      "\tspeed: 0.1154s/iter; left time: 349.1690s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0637276\n",
      "\tspeed: 0.1158s/iter; left time: 338.9968s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0624715\n",
      "\tspeed: 0.1152s/iter; left time: 325.7087s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0603009\n",
      "\tspeed: 0.1047s/iter; left time: 285.4306s\n",
      "Epoch: 19 cost time: 00h:05m:04.06s\n",
      "Epoch: 19 | Train Loss: 0.0664445 Vali Loss: 0.0582531 Test Loss: 0.0613255\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0678439\n",
      "\tspeed: 0.8874s/iter; left time: 2319.5733s\n",
      "\titers: 200, epoch: 20 | loss: 0.0597879\n",
      "\tspeed: 0.1133s/iter; left time: 284.7188s\n",
      "\titers: 300, epoch: 20 | loss: 0.0638165\n",
      "\tspeed: 0.1165s/iter; left time: 281.3017s\n",
      "\titers: 400, epoch: 20 | loss: 0.0793275\n",
      "\tspeed: 0.1165s/iter; left time: 269.5985s\n",
      "\titers: 500, epoch: 20 | loss: 0.0754307\n",
      "\tspeed: 0.1160s/iter; left time: 256.7954s\n",
      "\titers: 600, epoch: 20 | loss: 0.0700399\n",
      "\tspeed: 0.1170s/iter; left time: 247.3626s\n",
      "\titers: 700, epoch: 20 | loss: 0.0739242\n",
      "\tspeed: 0.1017s/iter; left time: 204.8839s\n",
      "\titers: 800, epoch: 20 | loss: 0.0643072\n",
      "\tspeed: 0.1021s/iter; left time: 195.3970s\n",
      "\titers: 900, epoch: 20 | loss: 0.0854818\n",
      "\tspeed: 0.1156s/iter; left time: 209.6514s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0700538\n",
      "\tspeed: 0.1114s/iter; left time: 190.9019s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0834796\n",
      "\tspeed: 0.1148s/iter; left time: 185.2862s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0664011\n",
      "\tspeed: 0.1146s/iter; left time: 173.5264s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0820845\n",
      "\tspeed: 0.1030s/iter; left time: 145.7014s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0749179\n",
      "\tspeed: 0.1082s/iter; left time: 142.1798s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0761071\n",
      "\tspeed: 0.1049s/iter; left time: 127.3326s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0559327\n",
      "\tspeed: 0.1076s/iter; left time: 119.8807s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0721338\n",
      "\tspeed: 0.1080s/iter; left time: 109.5294s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0765517\n",
      "\tspeed: 0.1054s/iter; left time: 96.3279s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0804090\n",
      "\tspeed: 0.2049s/iter; left time: 166.7659s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0526108\n",
      "\tspeed: 0.2291s/iter; left time: 163.5579s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0641992\n",
      "\tspeed: 0.2285s/iter; left time: 140.3196s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0723800\n",
      "\tspeed: 0.2286s/iter; left time: 117.5210s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0592321\n",
      "\tspeed: 0.2294s/iter; left time: 94.9561s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0686284\n",
      "\tspeed: 0.2281s/iter; left time: 71.6264s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0732605\n",
      "\tspeed: 0.2272s/iter; left time: 48.6283s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0646918\n",
      "\tspeed: 0.2268s/iter; left time: 25.8536s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0760566\n",
      "\tspeed: 0.2304s/iter; left time: 3.2258s\n",
      "Epoch: 20 cost time: 00h:06m:46.00s\n",
      "Epoch: 20 | Train Loss: 0.0662078 Vali Loss: 0.0572421 Test Loss: 0.0609677\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.010610697790980339, rmse:0.10300824046134949, mae:0.05985838919878006, rse:0.3891950249671936\n",
      "success delete checkpoints\n",
      "Intermediate time for IT and pred_len 24: 02h:14m:22.16s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 86619\n",
      "val 18435\n",
      "test 18435\n",
      "[2024-11-06 01:05:58,592] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 01:05:59,631] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 01:05:59,631] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 01:05:59,631] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 01:05:59,718] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 01:05:59,718] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 01:06:00,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 01:06:01,000] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 01:06:01,001] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 01:06:01,002] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 01:06:01,002] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 01:06:01,003] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 01:06:01,003] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 01:06:01,003] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 01:06:01,003] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 01:06:01,003] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 01:06:01,366] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 01:06:01,367] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 01:06:01,367] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 201.16 GB, percent = 26.7%\n",
      "[2024-11-06 01:06:01,502] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 01:06:01,503] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 01:06:01,503] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 201.16 GB, percent = 26.7%\n",
      "[2024-11-06 01:06:01,503] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 01:06:01,633] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 01:06:01,634] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 01:06:01,634] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 201.15 GB, percent = 26.7%\n",
      "[2024-11-06 01:06:01,634] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 01:06:01,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 01:06:01,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 01:06:01,635] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 01:06:01,635] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1474e0ec10>\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 01:06:01,636] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 01:06:01,637] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 01:06:01,638] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 01:06:01,639] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1957371\n",
      "\tspeed: 0.2832s/iter; left time: 15301.1940s\n",
      "\titers: 200, epoch: 1 | loss: 0.1988407\n",
      "\tspeed: 0.2410s/iter; left time: 12992.3746s\n",
      "\titers: 300, epoch: 1 | loss: 0.1786245\n",
      "\tspeed: 0.2373s/iter; left time: 12772.6793s\n",
      "\titers: 400, epoch: 1 | loss: 0.1252623\n",
      "\tspeed: 0.2410s/iter; left time: 12944.2419s\n",
      "\titers: 500, epoch: 1 | loss: 0.1248590\n",
      "\tspeed: 0.2409s/iter; left time: 12915.5640s\n",
      "\titers: 600, epoch: 1 | loss: 0.1202253\n",
      "\tspeed: 0.2455s/iter; left time: 13139.3264s\n",
      "\titers: 700, epoch: 1 | loss: 0.1152071\n",
      "\tspeed: 0.2431s/iter; left time: 12988.7353s\n",
      "\titers: 800, epoch: 1 | loss: 0.1034337\n",
      "\tspeed: 0.2412s/iter; left time: 12861.9455s\n",
      "\titers: 900, epoch: 1 | loss: 0.1339738\n",
      "\tspeed: 0.2325s/iter; left time: 12376.1933s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1273936\n",
      "\tspeed: 0.2364s/iter; left time: 12559.0965s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1220186\n",
      "\tspeed: 0.2410s/iter; left time: 12779.4136s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0995854\n",
      "\tspeed: 0.2406s/iter; left time: 12733.8315s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1172113\n",
      "\tspeed: 0.2382s/iter; left time: 12583.6518s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1163251\n",
      "\tspeed: 0.2356s/iter; left time: 12422.5130s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1078431\n",
      "\tspeed: 0.2363s/iter; left time: 12431.9211s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1132996\n",
      "\tspeed: 0.2390s/iter; left time: 12553.5281s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1116063\n",
      "\tspeed: 0.2394s/iter; left time: 12551.1077s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1115839\n",
      "\tspeed: 0.2406s/iter; left time: 12587.2950s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0950819\n",
      "\tspeed: 0.2380s/iter; left time: 12430.8941s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0851256\n",
      "\tspeed: 0.2392s/iter; left time: 12465.8407s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1075162\n",
      "\tspeed: 0.2393s/iter; left time: 12447.2141s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1187029\n",
      "\tspeed: 0.2389s/iter; left time: 12402.1289s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0833484\n",
      "\tspeed: 0.2387s/iter; left time: 12372.1710s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1171133\n",
      "\tspeed: 0.2383s/iter; left time: 12323.6629s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0949937\n",
      "\tspeed: 0.2378s/iter; left time: 12274.1074s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1190286\n",
      "\tspeed: 0.2386s/iter; left time: 12292.8378s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0998210\n",
      "\tspeed: 0.2374s/iter; left time: 12205.3675s\n",
      "Epoch: 1 cost time: 00h:10m:47.90s\n",
      "Epoch: 1 | Train Loss: 0.1232995 Vali Loss: 0.0857182 Test Loss: 0.0901959\n",
      "Validation loss decreased (inf --> 0.085718).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1100685\n",
      "\tspeed: 2.1802s/iter; left time: 111875.3362s\n",
      "\titers: 200, epoch: 2 | loss: 0.0969959\n",
      "\tspeed: 0.2279s/iter; left time: 11673.8238s\n",
      "\titers: 300, epoch: 2 | loss: 0.0902633\n",
      "\tspeed: 0.2277s/iter; left time: 11638.4416s\n",
      "\titers: 400, epoch: 2 | loss: 0.0969641\n",
      "\tspeed: 0.2292s/iter; left time: 11694.6590s\n",
      "\titers: 500, epoch: 2 | loss: 0.0873474\n",
      "\tspeed: 0.2259s/iter; left time: 11499.9747s\n",
      "\titers: 600, epoch: 2 | loss: 0.1026691\n",
      "\tspeed: 0.2236s/iter; left time: 11361.9371s\n",
      "\titers: 700, epoch: 2 | loss: 0.1001140\n",
      "\tspeed: 0.2282s/iter; left time: 11571.0038s\n",
      "\titers: 800, epoch: 2 | loss: 0.1068980\n",
      "\tspeed: 0.2249s/iter; left time: 11382.8425s\n",
      "\titers: 900, epoch: 2 | loss: 0.1096655\n",
      "\tspeed: 0.2279s/iter; left time: 11512.5390s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0952892\n",
      "\tspeed: 0.2288s/iter; left time: 11534.3024s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1017811\n",
      "\tspeed: 0.2294s/iter; left time: 11542.7847s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0957464\n",
      "\tspeed: 0.2303s/iter; left time: 11564.8978s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0962172\n",
      "\tspeed: 0.2278s/iter; left time: 11417.3749s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0879679\n",
      "\tspeed: 0.2297s/iter; left time: 11489.4051s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0992792\n",
      "\tspeed: 0.2239s/iter; left time: 11176.5311s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1126515\n",
      "\tspeed: 0.2233s/iter; left time: 11125.9715s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0836290\n",
      "\tspeed: 0.2294s/iter; left time: 11402.4844s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0904936\n",
      "\tspeed: 0.2251s/iter; left time: 11170.3176s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1089717\n",
      "\tspeed: 0.2300s/iter; left time: 11386.2144s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0892252\n",
      "\tspeed: 0.2269s/iter; left time: 11213.7389s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1080279\n",
      "\tspeed: 0.2286s/iter; left time: 11275.7410s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0735722\n",
      "\tspeed: 0.2241s/iter; left time: 11029.7100s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0922903\n",
      "\tspeed: 0.2274s/iter; left time: 11169.4942s\n",
      "\titers: 2400, epoch: 2 | loss: 0.1064908\n",
      "\tspeed: 0.2284s/iter; left time: 11197.2046s\n",
      "\titers: 2500, epoch: 2 | loss: 0.1045327\n",
      "\tspeed: 0.2283s/iter; left time: 11165.5893s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0925256\n",
      "\tspeed: 0.2244s/iter; left time: 10951.9433s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1128943\n",
      "\tspeed: 0.2280s/iter; left time: 11105.0501s\n",
      "Epoch: 2 cost time: 00h:10m:15.30s\n",
      "Epoch: 2 | Train Loss: 0.0993053 Vali Loss: 0.0824271 Test Loss: 0.0869428\n",
      "Validation loss decreased (0.085718 --> 0.082427).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0988261\n",
      "\tspeed: 2.0600s/iter; left time: 100136.7629s\n",
      "\titers: 200, epoch: 3 | loss: 0.1125904\n",
      "\tspeed: 0.2261s/iter; left time: 10965.6799s\n",
      "\titers: 300, epoch: 3 | loss: 0.0923748\n",
      "\tspeed: 0.2263s/iter; left time: 10956.3439s\n",
      "\titers: 400, epoch: 3 | loss: 0.0975078\n",
      "\tspeed: 0.2272s/iter; left time: 10977.9039s\n",
      "\titers: 500, epoch: 3 | loss: 0.1072466\n",
      "\tspeed: 0.2269s/iter; left time: 10937.3286s\n",
      "\titers: 600, epoch: 3 | loss: 0.1010326\n",
      "\tspeed: 0.2272s/iter; left time: 10929.1662s\n",
      "\titers: 700, epoch: 3 | loss: 0.1278861\n",
      "\tspeed: 0.2281s/iter; left time: 10950.5055s\n",
      "\titers: 800, epoch: 3 | loss: 0.1012830\n",
      "\tspeed: 0.2277s/iter; left time: 10910.4600s\n",
      "\titers: 900, epoch: 3 | loss: 0.1159125\n",
      "\tspeed: 0.2293s/iter; left time: 10962.7103s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0913891\n",
      "\tspeed: 0.2266s/iter; left time: 10810.1632s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1035232\n",
      "\tspeed: 0.2289s/iter; left time: 10899.6212s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0950071\n",
      "\tspeed: 0.2262s/iter; left time: 10745.3343s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0945666\n",
      "\tspeed: 0.2286s/iter; left time: 10839.9119s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0814379\n",
      "\tspeed: 0.2280s/iter; left time: 10786.1589s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1054778\n",
      "\tspeed: 0.2264s/iter; left time: 10689.1913s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0851075\n",
      "\tspeed: 0.2275s/iter; left time: 10718.9797s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0814247\n",
      "\tspeed: 0.2262s/iter; left time: 10631.2988s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0740707\n",
      "\tspeed: 0.2243s/iter; left time: 10519.9388s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0963435\n",
      "\tspeed: 0.2264s/iter; left time: 10595.5939s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0979463\n",
      "\tspeed: 0.2264s/iter; left time: 10576.9333s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1166603\n",
      "\tspeed: 0.2242s/iter; left time: 10449.6448s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0865666\n",
      "\tspeed: 0.2299s/iter; left time: 10694.7112s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0728535\n",
      "\tspeed: 0.2263s/iter; left time: 10502.9724s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0970201\n",
      "\tspeed: 0.2301s/iter; left time: 10654.3113s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1138931\n",
      "\tspeed: 0.2288s/iter; left time: 10572.5712s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1135599\n",
      "\tspeed: 0.2253s/iter; left time: 10390.2970s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1026513\n",
      "\tspeed: 0.2256s/iter; left time: 10380.3061s\n",
      "Epoch: 3 cost time: 00h:10m:15.06s\n",
      "Epoch: 3 | Train Loss: 0.0955978 Vali Loss: 0.0799409 Test Loss: 0.0843901\n",
      "Validation loss decreased (0.082427 --> 0.079941).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0745731\n",
      "\tspeed: 2.0699s/iter; left time: 95013.1586s\n",
      "\titers: 200, epoch: 4 | loss: 0.1088843\n",
      "\tspeed: 0.2271s/iter; left time: 10401.7829s\n",
      "\titers: 300, epoch: 4 | loss: 0.1032390\n",
      "\tspeed: 0.2297s/iter; left time: 10498.7527s\n",
      "\titers: 400, epoch: 4 | loss: 0.0966639\n",
      "\tspeed: 0.2270s/iter; left time: 10354.1594s\n",
      "\titers: 500, epoch: 4 | loss: 0.1029449\n",
      "\tspeed: 0.2268s/iter; left time: 10319.2686s\n",
      "\titers: 600, epoch: 4 | loss: 0.0961366\n",
      "\tspeed: 0.2279s/iter; left time: 10347.0384s\n",
      "\titers: 700, epoch: 4 | loss: 0.1127898\n",
      "\tspeed: 0.2291s/iter; left time: 10379.7452s\n",
      "\titers: 800, epoch: 4 | loss: 0.1121482\n",
      "\tspeed: 0.2290s/iter; left time: 10351.7639s\n",
      "\titers: 900, epoch: 4 | loss: 0.0898312\n",
      "\tspeed: 0.2308s/iter; left time: 10411.7469s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0712290\n",
      "\tspeed: 0.2259s/iter; left time: 10168.2193s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1003033\n",
      "\tspeed: 0.2292s/iter; left time: 10291.0920s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0749003\n",
      "\tspeed: 0.2276s/iter; left time: 10196.2170s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0993114\n",
      "\tspeed: 0.2250s/iter; left time: 10059.9724s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1120606\n",
      "\tspeed: 0.2290s/iter; left time: 10214.2781s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0868077\n",
      "\tspeed: 0.2246s/iter; left time: 9995.2842s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1049751\n",
      "\tspeed: 0.2281s/iter; left time: 10128.0311s\n",
      "\titers: 1700, epoch: 4 | loss: 0.1109057\n",
      "\tspeed: 0.2284s/iter; left time: 10120.2033s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0809862\n",
      "\tspeed: 0.2215s/iter; left time: 9790.5155s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0779351\n",
      "\tspeed: 0.2292s/iter; left time: 10107.7885s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0920356\n",
      "\tspeed: 0.2295s/iter; left time: 10098.3482s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0986473\n",
      "\tspeed: 0.2281s/iter; left time: 10012.6455s\n",
      "\titers: 2200, epoch: 4 | loss: 0.1068006\n",
      "\tspeed: 0.2264s/iter; left time: 9916.4513s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0677806\n",
      "\tspeed: 0.2289s/iter; left time: 10005.1929s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0967659\n",
      "\tspeed: 0.2278s/iter; left time: 9932.6656s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0991127\n",
      "\tspeed: 0.2291s/iter; left time: 9966.8658s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0865883\n",
      "\tspeed: 0.2303s/iter; left time: 9993.6804s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0846880\n",
      "\tspeed: 0.2293s/iter; left time: 9929.7887s\n",
      "Epoch: 4 cost time: 00h:10m:17.40s\n",
      "Epoch: 4 | Train Loss: 0.0935948 Vali Loss: 0.0790068 Test Loss: 0.0837370\n",
      "Validation loss decreased (0.079941 --> 0.079007).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1062295\n",
      "\tspeed: 2.0463s/iter; left time: 88393.7757s\n",
      "\titers: 200, epoch: 5 | loss: 0.0903116\n",
      "\tspeed: 0.2249s/iter; left time: 9690.8981s\n",
      "\titers: 300, epoch: 5 | loss: 0.0880235\n",
      "\tspeed: 0.2287s/iter; left time: 9835.0749s\n",
      "\titers: 400, epoch: 5 | loss: 0.0965862\n",
      "\tspeed: 0.2291s/iter; left time: 9829.7606s\n",
      "\titers: 500, epoch: 5 | loss: 0.0847937\n",
      "\tspeed: 0.2276s/iter; left time: 9741.4246s\n",
      "\titers: 600, epoch: 5 | loss: 0.1054867\n",
      "\tspeed: 0.2282s/iter; left time: 9743.2941s\n",
      "\titers: 700, epoch: 5 | loss: 0.0905865\n",
      "\tspeed: 0.2284s/iter; left time: 9727.3954s\n",
      "\titers: 800, epoch: 5 | loss: 0.1002953\n",
      "\tspeed: 0.2291s/iter; left time: 9734.8112s\n",
      "\titers: 900, epoch: 5 | loss: 0.1049440\n",
      "\tspeed: 0.2280s/iter; left time: 9665.1751s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0971571\n",
      "\tspeed: 0.2294s/iter; left time: 9701.1370s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1012508\n",
      "\tspeed: 0.2300s/iter; left time: 9704.7312s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0732139\n",
      "\tspeed: 0.2290s/iter; left time: 9642.3083s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0912566\n",
      "\tspeed: 0.2282s/iter; left time: 9585.6282s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0849926\n",
      "\tspeed: 0.2279s/iter; left time: 9549.2770s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1157260\n",
      "\tspeed: 0.2273s/iter; left time: 9500.5420s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0936607\n",
      "\tspeed: 0.2272s/iter; left time: 9472.9182s\n",
      "\titers: 1700, epoch: 5 | loss: 0.1034186\n",
      "\tspeed: 0.2317s/iter; left time: 9639.5891s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0788058\n",
      "\tspeed: 0.2253s/iter; left time: 9349.0034s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0802007\n",
      "\tspeed: 0.2239s/iter; left time: 9267.8651s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1025417\n",
      "\tspeed: 0.2302s/iter; left time: 9508.4801s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0910085\n",
      "\tspeed: 0.2287s/iter; left time: 9420.6391s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0879219\n",
      "\tspeed: 0.2288s/iter; left time: 9400.9897s\n",
      "\titers: 2300, epoch: 5 | loss: 0.1013097\n",
      "\tspeed: 0.2296s/iter; left time: 9414.8910s\n",
      "\titers: 2400, epoch: 5 | loss: 0.1072742\n",
      "\tspeed: 0.2250s/iter; left time: 9201.4693s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0965127\n",
      "\tspeed: 0.2245s/iter; left time: 9158.7320s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0893447\n",
      "\tspeed: 0.2297s/iter; left time: 9346.4339s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1084350\n",
      "\tspeed: 0.2279s/iter; left time: 9253.4136s\n",
      "Epoch: 5 cost time: 00h:10m:17.31s\n",
      "Epoch: 5 | Train Loss: 0.0922661 Vali Loss: 0.0783976 Test Loss: 0.0831391\n",
      "Validation loss decreased (0.079007 --> 0.078398).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.1067788\n",
      "\tspeed: 2.0729s/iter; left time: 83933.3438s\n",
      "\titers: 200, epoch: 6 | loss: 0.1001673\n",
      "\tspeed: 0.2280s/iter; left time: 9208.6418s\n",
      "\titers: 300, epoch: 6 | loss: 0.0942380\n",
      "\tspeed: 0.2268s/iter; left time: 9136.9269s\n",
      "\titers: 400, epoch: 6 | loss: 0.0955386\n",
      "\tspeed: 0.2281s/iter; left time: 9165.7559s\n",
      "\titers: 500, epoch: 6 | loss: 0.0841621\n",
      "\tspeed: 0.2279s/iter; left time: 9138.1640s\n",
      "\titers: 600, epoch: 6 | loss: 0.0980613\n",
      "\tspeed: 0.2295s/iter; left time: 9176.1021s\n",
      "\titers: 700, epoch: 6 | loss: 0.0891403\n",
      "\tspeed: 0.2306s/iter; left time: 9197.9434s\n",
      "\titers: 800, epoch: 6 | loss: 0.0767781\n",
      "\tspeed: 0.2285s/iter; left time: 9091.9923s\n",
      "\titers: 900, epoch: 6 | loss: 0.1005376\n",
      "\tspeed: 0.2250s/iter; left time: 8932.2381s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0878510\n",
      "\tspeed: 0.2301s/iter; left time: 9110.9673s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0977888\n",
      "\tspeed: 0.2273s/iter; left time: 8976.9035s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0860134\n",
      "\tspeed: 0.2240s/iter; left time: 8822.4046s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1108063\n",
      "\tspeed: 0.2265s/iter; left time: 8898.1793s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0922976\n",
      "\tspeed: 0.2284s/iter; left time: 8952.2763s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0987637\n",
      "\tspeed: 0.2274s/iter; left time: 8890.6358s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0851591\n",
      "\tspeed: 0.2279s/iter; left time: 8884.8838s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1030514\n",
      "\tspeed: 0.2289s/iter; left time: 8903.7274s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0834364\n",
      "\tspeed: 0.2304s/iter; left time: 8937.7968s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0801122\n",
      "\tspeed: 0.2276s/iter; left time: 8804.6338s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0917051\n",
      "\tspeed: 0.2310s/iter; left time: 8914.2474s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0866274\n",
      "\tspeed: 0.2295s/iter; left time: 8835.1080s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0815608\n",
      "\tspeed: 0.2272s/iter; left time: 8724.1324s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0916223\n",
      "\tspeed: 0.2256s/iter; left time: 8639.4941s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0762965\n",
      "\tspeed: 0.2275s/iter; left time: 8690.2668s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0970992\n",
      "\tspeed: 0.2286s/iter; left time: 8705.8031s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0836657\n",
      "\tspeed: 0.2246s/iter; left time: 8531.5667s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0808477\n",
      "\tspeed: 0.2218s/iter; left time: 8404.1026s\n",
      "Epoch: 6 cost time: 00h:10m:16.49s\n",
      "Epoch: 6 | Train Loss: 0.0912449 Vali Loss: 0.0783005 Test Loss: 0.0833428\n",
      "Validation loss decreased (0.078398 --> 0.078301).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0933830\n",
      "\tspeed: 2.0673s/iter; left time: 78112.4358s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800593\n",
      "\tspeed: 0.2267s/iter; left time: 8544.5014s\n",
      "\titers: 300, epoch: 7 | loss: 0.0774078\n",
      "\tspeed: 0.2313s/iter; left time: 8691.7685s\n",
      "\titers: 400, epoch: 7 | loss: 0.0650603\n",
      "\tspeed: 0.2298s/iter; left time: 8613.7586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1061487\n",
      "\tspeed: 0.2260s/iter; left time: 8449.3455s\n",
      "\titers: 600, epoch: 7 | loss: 0.0871832\n",
      "\tspeed: 0.2294s/iter; left time: 8553.2941s\n",
      "\titers: 700, epoch: 7 | loss: 0.0940648\n",
      "\tspeed: 0.2282s/iter; left time: 8486.2346s\n",
      "\titers: 800, epoch: 7 | loss: 0.0777493\n",
      "\tspeed: 0.2296s/iter; left time: 8513.7045s\n",
      "\titers: 900, epoch: 7 | loss: 0.0757068\n",
      "\tspeed: 0.2299s/iter; left time: 8503.5141s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0884026\n",
      "\tspeed: 0.2276s/iter; left time: 8396.7130s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0753387\n",
      "\tspeed: 0.2294s/iter; left time: 8437.9753s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1094262\n",
      "\tspeed: 0.2275s/iter; left time: 8344.7905s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0878446\n",
      "\tspeed: 0.2290s/iter; left time: 8377.8570s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0869639\n",
      "\tspeed: 0.2221s/iter; left time: 8104.5486s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0855840\n",
      "\tspeed: 0.2305s/iter; left time: 8386.1492s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0769002\n",
      "\tspeed: 0.2295s/iter; left time: 8325.7656s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0746461\n",
      "\tspeed: 0.2271s/iter; left time: 8217.6652s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0780547\n",
      "\tspeed: 0.2299s/iter; left time: 8295.1275s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0815966\n",
      "\tspeed: 0.2294s/iter; left time: 8254.2594s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1014334\n",
      "\tspeed: 0.2263s/iter; left time: 8119.7891s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0728168\n",
      "\tspeed: 0.2266s/iter; left time: 8108.6668s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0900339\n",
      "\tspeed: 0.2297s/iter; left time: 8197.4014s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0897858\n",
      "\tspeed: 0.2209s/iter; left time: 7861.4778s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0888296\n",
      "\tspeed: 0.2278s/iter; left time: 8084.5686s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0678730\n",
      "\tspeed: 0.2277s/iter; left time: 8058.3051s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0817783\n",
      "\tspeed: 0.2284s/iter; left time: 8060.7617s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0662917\n",
      "\tspeed: 0.2291s/iter; left time: 8059.8656s\n",
      "Epoch: 7 cost time: 00h:10m:17.23s\n",
      "Epoch: 7 | Train Loss: 0.0903126 Vali Loss: 0.0772570 Test Loss: 0.0828798\n",
      "Validation loss decreased (0.078301 --> 0.077257).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0869290\n",
      "\tspeed: 2.0593s/iter; left time: 72237.6066s\n",
      "\titers: 200, epoch: 8 | loss: 0.0829621\n",
      "\tspeed: 0.2258s/iter; left time: 7899.7656s\n",
      "\titers: 300, epoch: 8 | loss: 0.0859614\n",
      "\tspeed: 0.2210s/iter; left time: 7708.0255s\n",
      "\titers: 400, epoch: 8 | loss: 0.0862031\n",
      "\tspeed: 0.2250s/iter; left time: 7824.2630s\n",
      "\titers: 500, epoch: 8 | loss: 0.0810150\n",
      "\tspeed: 0.2295s/iter; left time: 7959.1883s\n",
      "\titers: 600, epoch: 8 | loss: 0.0625824\n",
      "\tspeed: 0.2302s/iter; left time: 7959.3181s\n",
      "\titers: 700, epoch: 8 | loss: 0.0958674\n",
      "\tspeed: 0.2288s/iter; left time: 7889.8652s\n",
      "\titers: 800, epoch: 8 | loss: 0.0913017\n",
      "\tspeed: 0.2307s/iter; left time: 7932.1011s\n",
      "\titers: 900, epoch: 8 | loss: 0.0823395\n",
      "\tspeed: 0.2275s/iter; left time: 7797.2849s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0734029\n",
      "\tspeed: 0.2300s/iter; left time: 7862.5411s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0970133\n",
      "\tspeed: 0.2249s/iter; left time: 7665.5584s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0999753\n",
      "\tspeed: 0.2281s/iter; left time: 7750.1558s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0689049\n",
      "\tspeed: 0.2327s/iter; left time: 7883.0217s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0657704\n",
      "\tspeed: 0.2263s/iter; left time: 7642.6604s\n",
      "\titers: 1500, epoch: 8 | loss: 0.1042709\n",
      "\tspeed: 0.2276s/iter; left time: 7666.5505s\n",
      "\titers: 1600, epoch: 8 | loss: 0.1155130\n",
      "\tspeed: 0.2220s/iter; left time: 7452.9211s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0859954\n",
      "\tspeed: 0.2255s/iter; left time: 7549.7209s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1005618\n",
      "\tspeed: 0.2281s/iter; left time: 7612.3590s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0824714\n",
      "\tspeed: 0.2285s/iter; left time: 7604.7644s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0774560\n",
      "\tspeed: 0.2259s/iter; left time: 7495.0061s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0857615\n",
      "\tspeed: 0.2288s/iter; left time: 7569.6048s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0980939\n",
      "\tspeed: 0.2277s/iter; left time: 7509.9062s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0892760\n",
      "\tspeed: 0.2278s/iter; left time: 7489.8579s\n",
      "\titers: 2400, epoch: 8 | loss: 0.1013688\n",
      "\tspeed: 0.2302s/iter; left time: 7545.2275s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0786417\n",
      "\tspeed: 0.2229s/iter; left time: 7285.4652s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0908012\n",
      "\tspeed: 0.2249s/iter; left time: 7328.4156s\n",
      "\titers: 2700, epoch: 8 | loss: 0.1027749\n",
      "\tspeed: 0.2220s/iter; left time: 7210.7910s\n",
      "Epoch: 8 cost time: 00h:10m:14.99s\n",
      "Epoch: 8 | Train Loss: 0.0894802 Vali Loss: 0.0784343 Test Loss: 0.0844677\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0938907\n",
      "\tspeed: 2.0580s/iter; left time: 66624.9431s\n",
      "\titers: 200, epoch: 9 | loss: 0.0922647\n",
      "\tspeed: 0.2288s/iter; left time: 7382.5732s\n",
      "\titers: 300, epoch: 9 | loss: 0.0990870\n",
      "\tspeed: 0.2256s/iter; left time: 7257.2425s\n",
      "\titers: 400, epoch: 9 | loss: 0.0727495\n",
      "\tspeed: 0.2213s/iter; left time: 7096.8236s\n",
      "\titers: 500, epoch: 9 | loss: 0.0776802\n",
      "\tspeed: 0.2298s/iter; left time: 7347.0883s\n",
      "\titers: 600, epoch: 9 | loss: 0.0929402\n",
      "\tspeed: 0.2293s/iter; left time: 7306.9153s\n",
      "\titers: 700, epoch: 9 | loss: 0.0776053\n",
      "\tspeed: 0.2281s/iter; left time: 7248.3189s\n",
      "\titers: 800, epoch: 9 | loss: 0.0819415\n",
      "\tspeed: 0.2251s/iter; left time: 7130.7604s\n",
      "\titers: 900, epoch: 9 | loss: 0.0872308\n",
      "\tspeed: 0.2253s/iter; left time: 7114.4028s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0799938\n",
      "\tspeed: 0.2225s/iter; left time: 7003.8496s\n",
      "\titers: 1100, epoch: 9 | loss: 0.1004732\n",
      "\tspeed: 0.2279s/iter; left time: 7150.7610s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0863396\n",
      "\tspeed: 0.2301s/iter; left time: 7195.6552s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0726797\n",
      "\tspeed: 0.2307s/iter; left time: 7192.1935s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0818079\n",
      "\tspeed: 0.2250s/iter; left time: 6991.8093s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0683723\n",
      "\tspeed: 0.2292s/iter; left time: 7097.6485s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0943891\n",
      "\tspeed: 0.2280s/iter; left time: 7038.6219s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0987611\n",
      "\tspeed: 0.2277s/iter; left time: 7006.2719s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0835820\n",
      "\tspeed: 0.2273s/iter; left time: 6973.2375s\n",
      "\titers: 1900, epoch: 9 | loss: 0.1031984\n",
      "\tspeed: 0.2272s/iter; left time: 6945.8727s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0755022\n",
      "\tspeed: 0.2235s/iter; left time: 6811.5043s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0874260\n",
      "\tspeed: 0.2279s/iter; left time: 6920.9565s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0859342\n",
      "\tspeed: 0.2294s/iter; left time: 6945.1523s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0717571\n",
      "\tspeed: 0.2253s/iter; left time: 6799.0227s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0822097\n",
      "\tspeed: 0.2287s/iter; left time: 6878.6088s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0845796\n",
      "\tspeed: 0.2268s/iter; left time: 6798.2640s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0798697\n",
      "\tspeed: 0.2224s/iter; left time: 6644.6498s\n",
      "\titers: 2700, epoch: 9 | loss: 0.1105974\n",
      "\tspeed: 0.2262s/iter; left time: 6734.2512s\n",
      "Epoch: 9 cost time: 00h:10m:14.94s\n",
      "Epoch: 9 | Train Loss: 0.0886539 Vali Loss: 0.0787157 Test Loss: 0.0847376\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0874556\n",
      "\tspeed: 2.0700s/iter; left time: 61409.3890s\n",
      "\titers: 200, epoch: 10 | loss: 0.0866642\n",
      "\tspeed: 0.2298s/iter; left time: 6793.6056s\n",
      "\titers: 300, epoch: 10 | loss: 0.0994205\n",
      "\tspeed: 0.2305s/iter; left time: 6791.0720s\n",
      "\titers: 400, epoch: 10 | loss: 0.0752526\n",
      "\tspeed: 0.2275s/iter; left time: 6680.7774s\n",
      "\titers: 500, epoch: 10 | loss: 0.0786418\n",
      "\tspeed: 0.2302s/iter; left time: 6735.8655s\n",
      "\titers: 600, epoch: 10 | loss: 0.1021048\n",
      "\tspeed: 0.2268s/iter; left time: 6615.9534s\n",
      "\titers: 700, epoch: 10 | loss: 0.0798678\n",
      "\tspeed: 0.2277s/iter; left time: 6617.1855s\n",
      "\titers: 800, epoch: 10 | loss: 0.0819658\n",
      "\tspeed: 0.2275s/iter; left time: 6589.1757s\n",
      "\titers: 900, epoch: 10 | loss: 0.0833500\n",
      "\tspeed: 0.2287s/iter; left time: 6602.1506s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0758326\n",
      "\tspeed: 0.2265s/iter; left time: 6515.2836s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0892491\n",
      "\tspeed: 0.2290s/iter; left time: 6566.0752s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0651677\n",
      "\tspeed: 0.2303s/iter; left time: 6580.0008s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0821478\n",
      "\tspeed: 0.2268s/iter; left time: 6456.1787s\n",
      "\titers: 1400, epoch: 10 | loss: 0.1008194\n",
      "\tspeed: 0.2283s/iter; left time: 6476.4797s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0835169\n",
      "\tspeed: 0.2278s/iter; left time: 6439.4062s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0708604\n",
      "\tspeed: 0.2286s/iter; left time: 6438.8867s\n",
      "\titers: 1700, epoch: 10 | loss: 0.1074116\n",
      "\tspeed: 0.2299s/iter; left time: 6452.1582s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0712662\n",
      "\tspeed: 0.2261s/iter; left time: 6324.2909s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0885887\n",
      "\tspeed: 0.2272s/iter; left time: 6330.9750s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0865291\n",
      "\tspeed: 0.2283s/iter; left time: 6338.7904s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0656529\n",
      "\tspeed: 0.2286s/iter; left time: 6325.5060s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0781705\n",
      "\tspeed: 0.2299s/iter; left time: 6337.1756s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0958661\n",
      "\tspeed: 0.2250s/iter; left time: 6180.1009s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0746688\n",
      "\tspeed: 0.2247s/iter; left time: 6149.2334s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0720767\n",
      "\tspeed: 0.2269s/iter; left time: 6187.6314s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0687294\n",
      "\tspeed: 0.2291s/iter; left time: 6223.0661s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0908230\n",
      "\tspeed: 0.2268s/iter; left time: 6138.9450s\n",
      "Epoch: 10 cost time: 00h:10m:17.37s\n",
      "Epoch: 10 | Train Loss: 0.0877459 Vali Loss: 0.0779939 Test Loss: 0.0842481\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0776830\n",
      "\tspeed: 2.0758s/iter; left time: 55966.3404s\n",
      "\titers: 200, epoch: 11 | loss: 0.0933278\n",
      "\tspeed: 0.2297s/iter; left time: 6169.0706s\n",
      "\titers: 300, epoch: 11 | loss: 0.0823427\n",
      "\tspeed: 0.2315s/iter; left time: 6195.6647s\n",
      "\titers: 400, epoch: 11 | loss: 0.0700283\n",
      "\tspeed: 0.2285s/iter; left time: 6091.2051s\n",
      "\titers: 500, epoch: 11 | loss: 0.0820046\n",
      "\tspeed: 0.2292s/iter; left time: 6086.9311s\n",
      "\titers: 600, epoch: 11 | loss: 0.0748644\n",
      "\tspeed: 0.2294s/iter; left time: 6070.5606s\n",
      "\titers: 700, epoch: 11 | loss: 0.0903739\n",
      "\tspeed: 0.2263s/iter; left time: 5964.5787s\n",
      "\titers: 800, epoch: 11 | loss: 0.0948557\n",
      "\tspeed: 0.2266s/iter; left time: 5950.2648s\n",
      "\titers: 900, epoch: 11 | loss: 0.0864879\n",
      "\tspeed: 0.2260s/iter; left time: 5912.1737s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0793213\n",
      "\tspeed: 0.2287s/iter; left time: 5961.0123s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0860533\n",
      "\tspeed: 0.2298s/iter; left time: 5965.4391s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0833864\n",
      "\tspeed: 0.2264s/iter; left time: 5854.2973s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0650678\n",
      "\tspeed: 0.2274s/iter; left time: 5859.2789s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0936900\n",
      "\tspeed: 0.2294s/iter; left time: 5887.1358s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0996548\n",
      "\tspeed: 0.2282s/iter; left time: 5831.9567s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0783650\n",
      "\tspeed: 0.2271s/iter; left time: 5781.4421s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0888616\n",
      "\tspeed: 0.2234s/iter; left time: 5664.6804s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0896389\n",
      "\tspeed: 0.2235s/iter; left time: 5644.6919s\n",
      "\titers: 1900, epoch: 11 | loss: 0.1086010\n",
      "\tspeed: 0.2278s/iter; left time: 5732.2310s\n",
      "\titers: 2000, epoch: 11 | loss: 0.1042380\n",
      "\tspeed: 0.2272s/iter; left time: 5694.0076s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0908188\n",
      "\tspeed: 0.2264s/iter; left time: 5650.3283s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0692129\n",
      "\tspeed: 0.2283s/iter; left time: 5674.6839s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0979093\n",
      "\tspeed: 0.2276s/iter; left time: 5635.5559s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0857562\n",
      "\tspeed: 0.2227s/iter; left time: 5492.2956s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0813912\n",
      "\tspeed: 0.2257s/iter; left time: 5543.8959s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0672272\n",
      "\tspeed: 0.2252s/iter; left time: 5509.1713s\n",
      "\titers: 2700, epoch: 11 | loss: 0.1023378\n",
      "\tspeed: 0.2278s/iter; left time: 5550.5819s\n",
      "Epoch: 11 cost time: 00h:10m:15.87s\n",
      "Epoch: 11 | Train Loss: 0.0871100 Vali Loss: 0.0785727 Test Loss: 0.0849454\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0994891\n",
      "\tspeed: 2.0675s/iter; left time: 50147.4081s\n",
      "\titers: 200, epoch: 12 | loss: 0.0839722\n",
      "\tspeed: 0.2261s/iter; left time: 5460.8271s\n",
      "\titers: 300, epoch: 12 | loss: 0.0880861\n",
      "\tspeed: 0.2265s/iter; left time: 5448.5306s\n",
      "\titers: 400, epoch: 12 | loss: 0.1069446\n",
      "\tspeed: 0.2271s/iter; left time: 5439.5343s\n",
      "\titers: 500, epoch: 12 | loss: 0.0783294\n",
      "\tspeed: 0.2296s/iter; left time: 5476.3265s\n",
      "\titers: 600, epoch: 12 | loss: 0.0793551\n",
      "\tspeed: 0.2294s/iter; left time: 5449.4582s\n",
      "\titers: 700, epoch: 12 | loss: 0.0987530\n",
      "\tspeed: 0.2271s/iter; left time: 5372.0472s\n",
      "\titers: 800, epoch: 12 | loss: 0.0688068\n",
      "\tspeed: 0.2272s/iter; left time: 5351.5124s\n",
      "\titers: 900, epoch: 12 | loss: 0.0662728\n",
      "\tspeed: 0.2297s/iter; left time: 5386.8337s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0859272\n",
      "\tspeed: 0.2263s/iter; left time: 5284.6300s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0925045\n",
      "\tspeed: 0.2307s/iter; left time: 5364.8396s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0740721\n",
      "\tspeed: 0.2285s/iter; left time: 5291.2925s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0841157\n",
      "\tspeed: 0.2267s/iter; left time: 5226.2447s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0790025\n",
      "\tspeed: 0.2200s/iter; left time: 5049.4015s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0732340\n",
      "\tspeed: 0.2290s/iter; left time: 5233.3920s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0808714\n",
      "\tspeed: 0.2273s/iter; left time: 5172.1709s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0735467\n",
      "\tspeed: 0.2307s/iter; left time: 5226.9088s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0620219\n",
      "\tspeed: 0.2235s/iter; left time: 5042.1517s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0856399\n",
      "\tspeed: 0.2254s/iter; left time: 5061.6798s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0987511\n",
      "\tspeed: 0.2298s/iter; left time: 5138.2507s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0754601\n",
      "\tspeed: 0.2234s/iter; left time: 4971.3109s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0890225\n",
      "\tspeed: 0.2274s/iter; left time: 5039.0492s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0856011\n",
      "\tspeed: 0.2286s/iter; left time: 5042.3643s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0994250\n",
      "\tspeed: 0.2290s/iter; left time: 5027.3142s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0631269\n",
      "\tspeed: 0.2282s/iter; left time: 4986.3972s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0950215\n",
      "\tspeed: 0.2269s/iter; left time: 4937.1270s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0660365\n",
      "\tspeed: 0.2255s/iter; left time: 4883.9916s\n",
      "Epoch: 12 cost time: 00h:10m:15.69s\n",
      "Epoch: 12 | Train Loss: 0.0863925 Vali Loss: 0.0774864 Test Loss: 0.0834979\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.01913185976445675, rmse:0.13831797242164612, mae:0.08287986367940903, rse:0.5230119228363037\n",
      "success delete checkpoints\n",
      "Intermediate time for IT and pred_len 96: 02h:42m:15.75s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "train 86403\n",
      "val 18219\n",
      "test 18219\n",
      "[2024-11-06 03:48:14,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 03:48:15,667] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 03:48:15,668] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 03:48:15,668] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 03:48:15,766] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 03:48:15,766] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 03:48:16,939] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 03:48:16,940] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 03:48:16,940] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 03:48:16,941] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 03:48:16,941] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 03:48:16,941] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 03:48:16,941] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 03:48:16,941] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 03:48:16,941] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 03:48:16,941] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 03:48:17,291] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 03:48:17,292] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 03:48:17,292] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 141.03 GB, percent = 18.7%\n",
      "[2024-11-06 03:48:17,421] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 03:48:17,422] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 03:48:17,422] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 141.04 GB, percent = 18.7%\n",
      "[2024-11-06 03:48:17,422] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 03:48:17,546] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 03:48:17,547] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 03:48:17,547] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 141.04 GB, percent = 18.7%\n",
      "[2024-11-06 03:48:17,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 03:48:17,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 03:48:17,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 03:48:17,548] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 03:48:17,549] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f255a2b6d10>\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 03:48:17,550] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 03:48:17,551] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1961919\n",
      "\tspeed: 0.2902s/iter; left time: 15643.0877s\n",
      "\titers: 200, epoch: 1 | loss: 0.1798013\n",
      "\tspeed: 0.2384s/iter; left time: 12828.3614s\n",
      "\titers: 300, epoch: 1 | loss: 0.2230563\n",
      "\tspeed: 0.2406s/iter; left time: 12918.0863s\n",
      "\titers: 400, epoch: 1 | loss: 0.1821745\n",
      "\tspeed: 0.2389s/iter; left time: 12806.1021s\n",
      "\titers: 500, epoch: 1 | loss: 0.1422377\n",
      "\tspeed: 0.2425s/iter; left time: 12972.9354s\n",
      "\titers: 600, epoch: 1 | loss: 0.1301331\n",
      "\tspeed: 0.2352s/iter; left time: 12561.0814s\n",
      "\titers: 700, epoch: 1 | loss: 0.1176083\n",
      "\tspeed: 0.2381s/iter; left time: 12692.0507s\n",
      "\titers: 800, epoch: 1 | loss: 0.1207451\n",
      "\tspeed: 0.2370s/iter; left time: 12606.0764s\n",
      "\titers: 900, epoch: 1 | loss: 0.1089139\n",
      "\tspeed: 0.2413s/iter; left time: 12810.8925s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0996139\n",
      "\tspeed: 0.2455s/iter; left time: 13009.2037s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1053230\n",
      "\tspeed: 0.2430s/iter; left time: 12854.4146s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1308265\n",
      "\tspeed: 0.2443s/iter; left time: 12900.0094s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1152626\n",
      "\tspeed: 0.2406s/iter; left time: 12681.3439s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0974694\n",
      "\tspeed: 0.2408s/iter; left time: 12666.9203s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1289891\n",
      "\tspeed: 0.2399s/iter; left time: 12594.4339s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0871722\n",
      "\tspeed: 0.2353s/iter; left time: 12329.2490s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0964673\n",
      "\tspeed: 0.2372s/iter; left time: 12403.3320s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0952348\n",
      "\tspeed: 0.2366s/iter; left time: 12350.4499s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1064777\n",
      "\tspeed: 0.2405s/iter; left time: 12532.5147s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1419824\n",
      "\tspeed: 0.2406s/iter; left time: 12513.0652s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0985843\n",
      "\tspeed: 0.2451s/iter; left time: 12722.5870s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0946451\n",
      "\tspeed: 0.2401s/iter; left time: 12439.4564s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1188782\n",
      "\tspeed: 0.2395s/iter; left time: 12383.4115s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0970554\n",
      "\tspeed: 0.2394s/iter; left time: 12351.9619s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1054485\n",
      "\tspeed: 0.2370s/iter; left time: 12203.2071s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0926483\n",
      "\tspeed: 0.2399s/iter; left time: 12328.6320s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1117112\n",
      "\tspeed: 0.2409s/iter; left time: 12358.5142s\n",
      "Epoch: 1 cost time: 00h:10m:49.50s\n",
      "Epoch: 1 | Train Loss: 0.1303747 Vali Loss: 0.0896592 Test Loss: 0.0940958\n",
      "Validation loss decreased (inf --> 0.089659).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1065150\n",
      "\tspeed: 2.1555s/iter; left time: 110362.1663s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008407\n",
      "\tspeed: 0.2229s/iter; left time: 11390.0994s\n",
      "\titers: 300, epoch: 2 | loss: 0.1186741\n",
      "\tspeed: 0.2264s/iter; left time: 11549.0365s\n",
      "\titers: 400, epoch: 2 | loss: 0.1150408\n",
      "\tspeed: 0.2279s/iter; left time: 11601.3460s\n",
      "\titers: 500, epoch: 2 | loss: 0.1006458\n",
      "\tspeed: 0.2284s/iter; left time: 11603.8240s\n",
      "\titers: 600, epoch: 2 | loss: 0.0950594\n",
      "\tspeed: 0.2280s/iter; left time: 11561.2930s\n",
      "\titers: 700, epoch: 2 | loss: 0.1128592\n",
      "\tspeed: 0.2298s/iter; left time: 11627.7855s\n",
      "\titers: 800, epoch: 2 | loss: 0.1078845\n",
      "\tspeed: 0.2271s/iter; left time: 11471.0562s\n",
      "\titers: 900, epoch: 2 | loss: 0.1175409\n",
      "\tspeed: 0.2287s/iter; left time: 11528.7131s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1180231\n",
      "\tspeed: 0.2261s/iter; left time: 11372.6392s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0973808\n",
      "\tspeed: 0.2272s/iter; left time: 11404.4156s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1120816\n",
      "\tspeed: 0.2290s/iter; left time: 11474.1305s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0918837\n",
      "\tspeed: 0.2270s/iter; left time: 11350.7778s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0983080\n",
      "\tspeed: 0.2282s/iter; left time: 11387.0598s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0981998\n",
      "\tspeed: 0.2235s/iter; left time: 11129.5795s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1133390\n",
      "\tspeed: 0.2240s/iter; left time: 11130.5892s\n",
      "\titers: 1700, epoch: 2 | loss: 0.1083509\n",
      "\tspeed: 0.2285s/iter; left time: 11333.6122s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0981740\n",
      "\tspeed: 0.2253s/iter; left time: 11151.5051s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1255775\n",
      "\tspeed: 0.2308s/iter; left time: 11402.5839s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1185946\n",
      "\tspeed: 0.2282s/iter; left time: 11250.7388s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1105070\n",
      "\tspeed: 0.2287s/iter; left time: 11253.4323s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0952730\n",
      "\tspeed: 0.2278s/iter; left time: 11183.7222s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1276222\n",
      "\tspeed: 0.2278s/iter; left time: 11160.9920s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0829781\n",
      "\tspeed: 0.2230s/iter; left time: 10906.4222s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0998287\n",
      "\tspeed: 0.2271s/iter; left time: 11084.0204s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0916800\n",
      "\tspeed: 0.2273s/iter; left time: 11068.2130s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0958411\n",
      "\tspeed: 0.2250s/iter; left time: 10936.6543s\n",
      "Epoch: 2 cost time: 00h:10m:13.27s\n",
      "Epoch: 2 | Train Loss: 0.1040007 Vali Loss: 0.0861962 Test Loss: 0.0905470\n",
      "Validation loss decreased (0.089659 --> 0.086196).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1060886\n",
      "\tspeed: 2.0391s/iter; left time: 98900.6712s\n",
      "\titers: 200, epoch: 3 | loss: 0.0876618\n",
      "\tspeed: 0.2280s/iter; left time: 11033.9966s\n",
      "\titers: 300, epoch: 3 | loss: 0.1099090\n",
      "\tspeed: 0.2297s/iter; left time: 11093.6432s\n",
      "\titers: 400, epoch: 3 | loss: 0.0980329\n",
      "\tspeed: 0.2289s/iter; left time: 11031.0797s\n",
      "\titers: 500, epoch: 3 | loss: 0.0980682\n",
      "\tspeed: 0.2284s/iter; left time: 10986.5084s\n",
      "\titers: 600, epoch: 3 | loss: 0.0879648\n",
      "\tspeed: 0.2289s/iter; left time: 10988.7964s\n",
      "\titers: 700, epoch: 3 | loss: 0.1068656\n",
      "\tspeed: 0.2270s/iter; left time: 10874.1975s\n",
      "\titers: 800, epoch: 3 | loss: 0.0906697\n",
      "\tspeed: 0.2290s/iter; left time: 10946.8872s\n",
      "\titers: 900, epoch: 3 | loss: 0.1009806\n",
      "\tspeed: 0.2299s/iter; left time: 10964.0824s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0888015\n",
      "\tspeed: 0.2257s/iter; left time: 10741.5790s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1009142\n",
      "\tspeed: 0.2297s/iter; left time: 10913.0918s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1120786\n",
      "\tspeed: 0.2279s/iter; left time: 10803.6769s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0958838\n",
      "\tspeed: 0.2289s/iter; left time: 10827.1134s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0879296\n",
      "\tspeed: 0.2222s/iter; left time: 10488.3337s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1013727\n",
      "\tspeed: 0.2284s/iter; left time: 10756.4484s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0923846\n",
      "\tspeed: 0.2224s/iter; left time: 10452.6811s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1092383\n",
      "\tspeed: 0.2293s/iter; left time: 10756.1452s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0918913\n",
      "\tspeed: 0.2243s/iter; left time: 10497.0412s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0849155\n",
      "\tspeed: 0.2287s/iter; left time: 10682.5285s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0821795\n",
      "\tspeed: 0.2260s/iter; left time: 10530.2867s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0941431\n",
      "\tspeed: 0.2210s/iter; left time: 10274.6321s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0876495\n",
      "\tspeed: 0.2276s/iter; left time: 10559.6783s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1072377\n",
      "\tspeed: 0.2263s/iter; left time: 10475.8776s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0927039\n",
      "\tspeed: 0.2264s/iter; left time: 10460.4308s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0755107\n",
      "\tspeed: 0.2303s/iter; left time: 10615.7111s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0996851\n",
      "\tspeed: 0.2289s/iter; left time: 10529.1191s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0995900\n",
      "\tspeed: 0.2302s/iter; left time: 10566.6983s\n",
      "Epoch: 3 cost time: 00h:10m:14.72s\n",
      "Epoch: 3 | Train Loss: 0.0997662 Vali Loss: 0.0850377 Test Loss: 0.0890909\n",
      "Validation loss decreased (0.086196 --> 0.085038).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0924203\n",
      "\tspeed: 2.0232s/iter; left time: 92663.4425s\n",
      "\titers: 200, epoch: 4 | loss: 0.0994556\n",
      "\tspeed: 0.2275s/iter; left time: 10394.9785s\n",
      "\titers: 300, epoch: 4 | loss: 0.0993971\n",
      "\tspeed: 0.2265s/iter; left time: 10327.3776s\n",
      "\titers: 400, epoch: 4 | loss: 0.0973728\n",
      "\tspeed: 0.2245s/iter; left time: 10216.0151s\n",
      "\titers: 500, epoch: 4 | loss: 0.0876852\n",
      "\tspeed: 0.2269s/iter; left time: 10302.6495s\n",
      "\titers: 600, epoch: 4 | loss: 0.1151832\n",
      "\tspeed: 0.2290s/iter; left time: 10372.3111s\n",
      "\titers: 700, epoch: 4 | loss: 0.1262485\n",
      "\tspeed: 0.2251s/iter; left time: 10173.8739s\n",
      "\titers: 800, epoch: 4 | loss: 0.0998220\n",
      "\tspeed: 0.2269s/iter; left time: 10232.8245s\n",
      "\titers: 900, epoch: 4 | loss: 0.0979331\n",
      "\tspeed: 0.2273s/iter; left time: 10228.2283s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1018009\n",
      "\tspeed: 0.2263s/iter; left time: 10158.8527s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1184683\n",
      "\tspeed: 0.2265s/iter; left time: 10146.3085s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1218863\n",
      "\tspeed: 0.2273s/iter; left time: 10160.6066s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1116326\n",
      "\tspeed: 0.2274s/iter; left time: 10141.2886s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0795136\n",
      "\tspeed: 0.2310s/iter; left time: 10278.8644s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1376347\n",
      "\tspeed: 0.2253s/iter; left time: 10005.3244s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0730868\n",
      "\tspeed: 0.2278s/iter; left time: 10091.6709s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0874964\n",
      "\tspeed: 0.2278s/iter; left time: 10068.6299s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0777984\n",
      "\tspeed: 0.2253s/iter; left time: 9937.9741s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0954947\n",
      "\tspeed: 0.2214s/iter; left time: 9742.7800s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1106007\n",
      "\tspeed: 0.2194s/iter; left time: 9631.0967s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0974348\n",
      "\tspeed: 0.2264s/iter; left time: 9918.3125s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0769000\n",
      "\tspeed: 0.2264s/iter; left time: 9895.9390s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1121962\n",
      "\tspeed: 0.2289s/iter; left time: 9981.9470s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1072145\n",
      "\tspeed: 0.2267s/iter; left time: 9861.4131s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0944967\n",
      "\tspeed: 0.2299s/iter; left time: 9976.2624s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0815068\n",
      "\tspeed: 0.2264s/iter; left time: 9803.0937s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1047501\n",
      "\tspeed: 0.2282s/iter; left time: 9858.7585s\n",
      "Epoch: 4 cost time: 00h:10m:12.51s\n",
      "Epoch: 4 | Train Loss: 0.0974807 Vali Loss: 0.0837517 Test Loss: 0.0875433\n",
      "Validation loss decreased (0.085038 --> 0.083752).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1183696\n",
      "\tspeed: 2.0243s/iter; left time: 87248.0689s\n",
      "\titers: 200, epoch: 5 | loss: 0.1086652\n",
      "\tspeed: 0.2245s/iter; left time: 9655.2639s\n",
      "\titers: 300, epoch: 5 | loss: 0.1088556\n",
      "\tspeed: 0.2299s/iter; left time: 9861.3782s\n",
      "\titers: 400, epoch: 5 | loss: 0.0897718\n",
      "\tspeed: 0.2266s/iter; left time: 9700.2833s\n",
      "\titers: 500, epoch: 5 | loss: 0.0884452\n",
      "\tspeed: 0.2289s/iter; left time: 9775.9423s\n",
      "\titers: 600, epoch: 5 | loss: 0.0801521\n",
      "\tspeed: 0.2279s/iter; left time: 9709.1327s\n",
      "\titers: 700, epoch: 5 | loss: 0.0931985\n",
      "\tspeed: 0.2260s/iter; left time: 9606.7775s\n",
      "\titers: 800, epoch: 5 | loss: 0.1115374\n",
      "\tspeed: 0.2202s/iter; left time: 9337.0964s\n",
      "\titers: 900, epoch: 5 | loss: 0.1040356\n",
      "\tspeed: 0.2277s/iter; left time: 9632.8919s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0769032\n",
      "\tspeed: 0.2285s/iter; left time: 9641.9729s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1047143\n",
      "\tspeed: 0.2227s/iter; left time: 9375.3765s\n",
      "\titers: 1200, epoch: 5 | loss: 0.1091576\n",
      "\tspeed: 0.2275s/iter; left time: 9557.0408s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0880793\n",
      "\tspeed: 0.2223s/iter; left time: 9316.2491s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0877198\n",
      "\tspeed: 0.2207s/iter; left time: 9226.6172s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0895322\n",
      "\tspeed: 0.2229s/iter; left time: 9293.8234s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0865655\n",
      "\tspeed: 0.2272s/iter; left time: 9450.8858s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0878066\n",
      "\tspeed: 0.2318s/iter; left time: 9621.0397s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1145800\n",
      "\tspeed: 0.2307s/iter; left time: 9551.6527s\n",
      "\titers: 1900, epoch: 5 | loss: 0.1058033\n",
      "\tspeed: 0.2310s/iter; left time: 9538.4671s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1180890\n",
      "\tspeed: 0.2279s/iter; left time: 9388.6514s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0860528\n",
      "\tspeed: 0.2255s/iter; left time: 9266.6246s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0878760\n",
      "\tspeed: 0.2285s/iter; left time: 9369.0258s\n",
      "\titers: 2300, epoch: 5 | loss: 0.1138770\n",
      "\tspeed: 0.2281s/iter; left time: 9331.2858s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0948913\n",
      "\tspeed: 0.2272s/iter; left time: 9270.0715s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1065817\n",
      "\tspeed: 0.2219s/iter; left time: 9030.4741s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0977174\n",
      "\tspeed: 0.2219s/iter; left time: 9009.5092s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1105934\n",
      "\tspeed: 0.2257s/iter; left time: 9142.5712s\n",
      "Epoch: 5 cost time: 00h:10m:11.31s\n",
      "Epoch: 5 | Train Loss: 0.0959903 Vali Loss: 0.0838053 Test Loss: 0.0872947\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0955355\n",
      "\tspeed: 2.0239s/iter; left time: 81766.7789s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821904\n",
      "\tspeed: 0.2303s/iter; left time: 9281.0190s\n",
      "\titers: 300, epoch: 6 | loss: 0.0787664\n",
      "\tspeed: 0.2293s/iter; left time: 9216.3105s\n",
      "\titers: 400, epoch: 6 | loss: 0.0818751\n",
      "\tspeed: 0.2303s/iter; left time: 9234.1211s\n",
      "\titers: 500, epoch: 6 | loss: 0.0942815\n",
      "\tspeed: 0.2313s/iter; left time: 9251.8311s\n",
      "\titers: 600, epoch: 6 | loss: 0.0862593\n",
      "\tspeed: 0.2280s/iter; left time: 9096.0088s\n",
      "\titers: 700, epoch: 6 | loss: 0.1111859\n",
      "\tspeed: 0.2299s/iter; left time: 9148.8753s\n",
      "\titers: 800, epoch: 6 | loss: 0.1097351\n",
      "\tspeed: 0.2312s/iter; left time: 9180.1248s\n",
      "\titers: 900, epoch: 6 | loss: 0.1001970\n",
      "\tspeed: 0.2310s/iter; left time: 9147.0808s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1047172\n",
      "\tspeed: 0.2281s/iter; left time: 9009.2352s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0907897\n",
      "\tspeed: 0.2292s/iter; left time: 9032.4805s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0780309\n",
      "\tspeed: 0.2317s/iter; left time: 9105.7606s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1029468\n",
      "\tspeed: 0.2308s/iter; left time: 9046.0681s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1080264\n",
      "\tspeed: 0.2302s/iter; left time: 9002.9557s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0885816\n",
      "\tspeed: 0.2280s/iter; left time: 8891.3868s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0784927\n",
      "\tspeed: 0.2298s/iter; left time: 8938.0143s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1216173\n",
      "\tspeed: 0.2285s/iter; left time: 8867.5292s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0984994\n",
      "\tspeed: 0.2303s/iter; left time: 8913.1989s\n",
      "\titers: 1900, epoch: 6 | loss: 0.1078458\n",
      "\tspeed: 0.2302s/iter; left time: 8884.1898s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0871546\n",
      "\tspeed: 0.2264s/iter; left time: 8718.4667s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0857792\n",
      "\tspeed: 0.2315s/iter; left time: 8890.5610s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1074033\n",
      "\tspeed: 0.2301s/iter; left time: 8811.3592s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0857331\n",
      "\tspeed: 0.2292s/iter; left time: 8754.2542s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0838149\n",
      "\tspeed: 0.2266s/iter; left time: 8632.6097s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0889192\n",
      "\tspeed: 0.2321s/iter; left time: 8819.0296s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0900664\n",
      "\tspeed: 0.2283s/iter; left time: 8653.3216s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0918714\n",
      "\tspeed: 0.2306s/iter; left time: 8717.1342s\n",
      "Epoch: 6 cost time: 00h:10m:20.56s\n",
      "Epoch: 6 | Train Loss: 0.0948270 Vali Loss: 0.0828888 Test Loss: 0.0870479\n",
      "Validation loss decreased (0.083752 --> 0.082889).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0816255\n",
      "\tspeed: 2.0171s/iter; left time: 76048.4869s\n",
      "\titers: 200, epoch: 7 | loss: 0.0954379\n",
      "\tspeed: 0.2244s/iter; left time: 8436.9610s\n",
      "\titers: 300, epoch: 7 | loss: 0.0870643\n",
      "\tspeed: 0.2233s/iter; left time: 8374.1929s\n",
      "\titers: 400, epoch: 7 | loss: 0.1016541\n",
      "\tspeed: 0.2246s/iter; left time: 8398.6341s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828781\n",
      "\tspeed: 0.2309s/iter; left time: 8612.2939s\n",
      "\titers: 600, epoch: 7 | loss: 0.0796559\n",
      "\tspeed: 0.2279s/iter; left time: 8477.6422s\n",
      "\titers: 700, epoch: 7 | loss: 0.0920063\n",
      "\tspeed: 0.2266s/iter; left time: 8406.6739s\n",
      "\titers: 800, epoch: 7 | loss: 0.1047040\n",
      "\tspeed: 0.2302s/iter; left time: 8517.8821s\n",
      "\titers: 900, epoch: 7 | loss: 0.0908791\n",
      "\tspeed: 0.2251s/iter; left time: 8305.7316s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1107935\n",
      "\tspeed: 0.2293s/iter; left time: 8438.5649s\n",
      "\titers: 1100, epoch: 7 | loss: 0.1014328\n",
      "\tspeed: 0.2245s/iter; left time: 8238.4210s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0972734\n",
      "\tspeed: 0.2258s/iter; left time: 8265.4411s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0831956\n",
      "\tspeed: 0.2282s/iter; left time: 8327.7651s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0870059\n",
      "\tspeed: 0.2263s/iter; left time: 8238.4891s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1255872\n",
      "\tspeed: 0.2276s/iter; left time: 8261.3780s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0835666\n",
      "\tspeed: 0.2306s/iter; left time: 8347.6703s\n",
      "\titers: 1700, epoch: 7 | loss: 0.1056352\n",
      "\tspeed: 0.2264s/iter; left time: 8173.4987s\n",
      "\titers: 1800, epoch: 7 | loss: 0.1022090\n",
      "\tspeed: 0.2283s/iter; left time: 8218.9896s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0806270\n",
      "\tspeed: 0.2289s/iter; left time: 8217.8758s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0911232\n",
      "\tspeed: 0.2280s/iter; left time: 8161.7814s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0803255\n",
      "\tspeed: 0.2287s/iter; left time: 8163.0829s\n",
      "\titers: 2200, epoch: 7 | loss: 0.1059430\n",
      "\tspeed: 0.2291s/iter; left time: 8155.9741s\n",
      "\titers: 2300, epoch: 7 | loss: 0.1048479\n",
      "\tspeed: 0.2287s/iter; left time: 8119.0418s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0817890\n",
      "\tspeed: 0.2238s/iter; left time: 7921.9520s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1070047\n",
      "\tspeed: 0.2257s/iter; left time: 7968.2770s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0963826\n",
      "\tspeed: 0.2321s/iter; left time: 8171.8693s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0864137\n",
      "\tspeed: 0.2231s/iter; left time: 7829.4483s\n",
      "Epoch: 7 cost time: 00h:10m:13.88s\n",
      "Epoch: 7 | Train Loss: 0.0938698 Vali Loss: 0.0826781 Test Loss: 0.0873197\n",
      "Validation loss decreased (0.082889 --> 0.082678).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.1085303\n",
      "\tspeed: 2.0380s/iter; left time: 71330.5218s\n",
      "\titers: 200, epoch: 8 | loss: 0.0953173\n",
      "\tspeed: 0.2285s/iter; left time: 7976.4497s\n",
      "\titers: 300, epoch: 8 | loss: 0.0813435\n",
      "\tspeed: 0.2238s/iter; left time: 7788.1207s\n",
      "\titers: 400, epoch: 8 | loss: 0.1116159\n",
      "\tspeed: 0.2244s/iter; left time: 7787.7124s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798089\n",
      "\tspeed: 0.2255s/iter; left time: 7801.6062s\n",
      "\titers: 600, epoch: 8 | loss: 0.0843743\n",
      "\tspeed: 0.2297s/iter; left time: 7923.1865s\n",
      "\titers: 700, epoch: 8 | loss: 0.0890860\n",
      "\tspeed: 0.2287s/iter; left time: 7866.1284s\n",
      "\titers: 800, epoch: 8 | loss: 0.0885449\n",
      "\tspeed: 0.2252s/iter; left time: 7725.2798s\n",
      "\titers: 900, epoch: 8 | loss: 0.0961055\n",
      "\tspeed: 0.2244s/iter; left time: 7674.3814s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0813331\n",
      "\tspeed: 0.2205s/iter; left time: 7518.9610s\n",
      "\titers: 1100, epoch: 8 | loss: 0.1008941\n",
      "\tspeed: 0.2222s/iter; left time: 7555.4354s\n",
      "\titers: 1200, epoch: 8 | loss: 0.1052952\n",
      "\tspeed: 0.2208s/iter; left time: 7484.7716s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0871023\n",
      "\tspeed: 0.2221s/iter; left time: 7505.9316s\n",
      "\titers: 1400, epoch: 8 | loss: 0.1132193\n",
      "\tspeed: 0.2270s/iter; left time: 7650.6993s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0748523\n",
      "\tspeed: 0.2311s/iter; left time: 7765.0284s\n",
      "\titers: 1600, epoch: 8 | loss: 0.1018734\n",
      "\tspeed: 0.2323s/iter; left time: 7782.7393s\n",
      "\titers: 1700, epoch: 8 | loss: 0.1061177\n",
      "\tspeed: 0.2276s/iter; left time: 7601.7499s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1027863\n",
      "\tspeed: 0.2259s/iter; left time: 7522.9772s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0919790\n",
      "\tspeed: 0.2287s/iter; left time: 7594.5713s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0938421\n",
      "\tspeed: 0.2282s/iter; left time: 7554.7862s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0895845\n",
      "\tspeed: 0.2271s/iter; left time: 7493.2131s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0848020\n",
      "\tspeed: 0.2267s/iter; left time: 7459.9632s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0902815\n",
      "\tspeed: 0.2225s/iter; left time: 7297.8598s\n",
      "\titers: 2400, epoch: 8 | loss: 0.1007424\n",
      "\tspeed: 0.2236s/iter; left time: 7312.7129s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0965174\n",
      "\tspeed: 0.2226s/iter; left time: 7258.4244s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0783984\n",
      "\tspeed: 0.2236s/iter; left time: 7266.0926s\n",
      "\titers: 2700, epoch: 8 | loss: 0.1108488\n",
      "\tspeed: 0.2218s/iter; left time: 7187.5574s\n",
      "Epoch: 8 cost time: 00h:10m:09.64s\n",
      "Epoch: 8 | Train Loss: 0.0928020 Vali Loss: 0.0830204 Test Loss: 0.0878322\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0674535\n",
      "\tspeed: 2.0099s/iter; left time: 64922.1742s\n",
      "\titers: 200, epoch: 9 | loss: 0.0871053\n",
      "\tspeed: 0.2255s/iter; left time: 7261.9288s\n",
      "\titers: 300, epoch: 9 | loss: 0.0993334\n",
      "\tspeed: 0.2252s/iter; left time: 7229.2787s\n",
      "\titers: 400, epoch: 9 | loss: 0.1089801\n",
      "\tspeed: 0.2220s/iter; left time: 7102.6392s\n",
      "\titers: 500, epoch: 9 | loss: 0.1094398\n",
      "\tspeed: 0.2235s/iter; left time: 7128.3646s\n",
      "\titers: 600, epoch: 9 | loss: 0.1112082\n",
      "\tspeed: 0.2214s/iter; left time: 7039.4539s\n",
      "\titers: 700, epoch: 9 | loss: 0.1020051\n",
      "\tspeed: 0.2283s/iter; left time: 7237.2359s\n",
      "\titers: 800, epoch: 9 | loss: 0.0864318\n",
      "\tspeed: 0.2263s/iter; left time: 7150.6980s\n",
      "\titers: 900, epoch: 9 | loss: 0.0778542\n",
      "\tspeed: 0.2198s/iter; left time: 6925.4190s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0854332\n",
      "\tspeed: 0.2203s/iter; left time: 6916.1958s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0876614\n",
      "\tspeed: 0.2241s/iter; left time: 7014.2932s\n",
      "\titers: 1200, epoch: 9 | loss: 0.1016938\n",
      "\tspeed: 0.2289s/iter; left time: 7142.8256s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0889321\n",
      "\tspeed: 0.2291s/iter; left time: 7124.1335s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0863223\n",
      "\tspeed: 0.2263s/iter; left time: 7014.2639s\n",
      "\titers: 1500, epoch: 9 | loss: 0.1161323\n",
      "\tspeed: 0.2265s/iter; left time: 6997.7538s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0800995\n",
      "\tspeed: 0.2300s/iter; left time: 7085.0986s\n",
      "\titers: 1700, epoch: 9 | loss: 0.1195773\n",
      "\tspeed: 0.2259s/iter; left time: 6934.1221s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0966528\n",
      "\tspeed: 0.2285s/iter; left time: 6991.8982s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0949998\n",
      "\tspeed: 0.2285s/iter; left time: 6969.4727s\n",
      "\titers: 2000, epoch: 9 | loss: 0.1202210\n",
      "\tspeed: 0.2247s/iter; left time: 6832.2014s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0944687\n",
      "\tspeed: 0.2297s/iter; left time: 6960.8745s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0757319\n",
      "\tspeed: 0.2280s/iter; left time: 6886.8389s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0921957\n",
      "\tspeed: 0.2267s/iter; left time: 6824.8371s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0802909\n",
      "\tspeed: 0.2258s/iter; left time: 6773.9442s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0945185\n",
      "\tspeed: 0.2266s/iter; left time: 6775.6968s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1265403\n",
      "\tspeed: 0.2261s/iter; left time: 6738.8409s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0779288\n",
      "\tspeed: 0.2291s/iter; left time: 6804.3033s\n",
      "Epoch: 9 cost time: 00h:10m:10.91s\n",
      "Epoch: 9 | Train Loss: 0.0919118 Vali Loss: 0.0837263 Test Loss: 0.0883415\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0753204\n",
      "\tspeed: 2.0084s/iter; left time: 59450.3752s\n",
      "\titers: 200, epoch: 10 | loss: 0.0736117\n",
      "\tspeed: 0.2286s/iter; left time: 6744.0862s\n",
      "\titers: 300, epoch: 10 | loss: 0.0693009\n",
      "\tspeed: 0.2291s/iter; left time: 6734.5428s\n",
      "\titers: 400, epoch: 10 | loss: 0.0860410\n",
      "\tspeed: 0.2284s/iter; left time: 6690.9361s\n",
      "\titers: 500, epoch: 10 | loss: 0.0793824\n",
      "\tspeed: 0.2285s/iter; left time: 6673.4231s\n",
      "\titers: 600, epoch: 10 | loss: 0.0963647\n",
      "\tspeed: 0.2252s/iter; left time: 6552.6841s\n",
      "\titers: 700, epoch: 10 | loss: 0.0790278\n",
      "\tspeed: 0.2291s/iter; left time: 6645.0499s\n",
      "\titers: 800, epoch: 10 | loss: 0.1015100\n",
      "\tspeed: 0.2222s/iter; left time: 6420.9829s\n",
      "\titers: 900, epoch: 10 | loss: 0.0973332\n",
      "\tspeed: 0.2224s/iter; left time: 6406.4576s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0837862\n",
      "\tspeed: 0.2144s/iter; left time: 6152.8385s\n",
      "\titers: 1100, epoch: 10 | loss: 0.1002496\n",
      "\tspeed: 0.2239s/iter; left time: 6403.3540s\n",
      "\titers: 1200, epoch: 10 | loss: 0.1025549\n",
      "\tspeed: 0.2232s/iter; left time: 6361.4470s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0915944\n",
      "\tspeed: 0.2201s/iter; left time: 6251.4266s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0983950\n",
      "\tspeed: 0.2271s/iter; left time: 6426.5907s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0731239\n",
      "\tspeed: 0.2293s/iter; left time: 6465.2069s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0818589\n",
      "\tspeed: 0.2301s/iter; left time: 6465.8983s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0996959\n",
      "\tspeed: 0.2283s/iter; left time: 6393.5886s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0733356\n",
      "\tspeed: 0.2251s/iter; left time: 6280.2999s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0785372\n",
      "\tspeed: 0.2287s/iter; left time: 6357.7254s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0939990\n",
      "\tspeed: 0.2296s/iter; left time: 6361.5172s\n",
      "\titers: 2100, epoch: 10 | loss: 0.1070469\n",
      "\tspeed: 0.2257s/iter; left time: 6229.2929s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0910513\n",
      "\tspeed: 0.2269s/iter; left time: 6240.6237s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0813882\n",
      "\tspeed: 0.2231s/iter; left time: 6112.2919s\n",
      "\titers: 2400, epoch: 10 | loss: 0.1052957\n",
      "\tspeed: 0.2253s/iter; left time: 6151.9857s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0887714\n",
      "\tspeed: 0.2275s/iter; left time: 6188.7197s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0871348\n",
      "\tspeed: 0.2237s/iter; left time: 6062.4223s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0923712\n",
      "\tspeed: 0.2287s/iter; left time: 6173.9149s\n",
      "Epoch: 10 cost time: 00h:10m:10.33s\n",
      "Epoch: 10 | Train Loss: 0.0910228 Vali Loss: 0.0837741 Test Loss: 0.0901152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.1049092\n",
      "\tspeed: 2.0149s/iter; left time: 54203.9551s\n",
      "\titers: 200, epoch: 11 | loss: 0.1032952\n",
      "\tspeed: 0.2277s/iter; left time: 6103.2518s\n",
      "\titers: 300, epoch: 11 | loss: 0.0988838\n",
      "\tspeed: 0.2312s/iter; left time: 6173.0090s\n",
      "\titers: 400, epoch: 11 | loss: 0.0861793\n",
      "\tspeed: 0.2255s/iter; left time: 5999.0464s\n",
      "\titers: 500, epoch: 11 | loss: 0.0973450\n",
      "\tspeed: 0.2279s/iter; left time: 6038.7382s\n",
      "\titers: 600, epoch: 11 | loss: 0.0748267\n",
      "\tspeed: 0.2276s/iter; left time: 6007.7661s\n",
      "\titers: 700, epoch: 11 | loss: 0.0785801\n",
      "\tspeed: 0.2197s/iter; left time: 5777.4262s\n",
      "\titers: 800, epoch: 11 | loss: 0.0874729\n",
      "\tspeed: 0.2245s/iter; left time: 5882.6032s\n",
      "\titers: 900, epoch: 11 | loss: 0.1025733\n",
      "\tspeed: 0.2316s/iter; left time: 6045.3185s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0999429\n",
      "\tspeed: 0.2332s/iter; left time: 6064.4416s\n",
      "\titers: 1100, epoch: 11 | loss: 0.1016031\n",
      "\tspeed: 0.2290s/iter; left time: 5932.3551s\n",
      "\titers: 1200, epoch: 11 | loss: 0.1026134\n",
      "\tspeed: 0.2284s/iter; left time: 5892.5209s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0880989\n",
      "\tspeed: 0.2274s/iter; left time: 5843.2497s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0914267\n",
      "\tspeed: 0.2297s/iter; left time: 5879.6338s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0891939\n",
      "\tspeed: 0.2256s/iter; left time: 5754.0625s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0948382\n",
      "\tspeed: 0.2298s/iter; left time: 5836.8179s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0877824\n",
      "\tspeed: 0.2280s/iter; left time: 5769.1402s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0893621\n",
      "\tspeed: 0.2282s/iter; left time: 5750.0067s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0875531\n",
      "\tspeed: 0.2314s/iter; left time: 5808.5827s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0676333\n",
      "\tspeed: 0.2293s/iter; left time: 5732.8042s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0839985\n",
      "\tspeed: 0.2290s/iter; left time: 5702.5647s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0852626\n",
      "\tspeed: 0.2271s/iter; left time: 5633.4095s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0821008\n",
      "\tspeed: 0.2269s/iter; left time: 5603.7394s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0824762\n",
      "\tspeed: 0.2262s/iter; left time: 5564.2345s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0681025\n",
      "\tspeed: 0.2284s/iter; left time: 5595.0829s\n",
      "\titers: 2600, epoch: 11 | loss: 0.1037442\n",
      "\tspeed: 0.2279s/iter; left time: 5561.0692s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0815487\n",
      "\tspeed: 0.2297s/iter; left time: 5581.5495s\n",
      "Epoch: 11 cost time: 00h:10m:16.30s\n",
      "Epoch: 11 | Train Loss: 0.0899230 Vali Loss: 0.0849293 Test Loss: 0.0907041\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0755338\n",
      "\tspeed: 2.0121s/iter; left time: 48695.7283s\n",
      "\titers: 200, epoch: 12 | loss: 0.0901928\n",
      "\tspeed: 0.2274s/iter; left time: 5480.1114s\n",
      "\titers: 300, epoch: 12 | loss: 0.0833872\n",
      "\tspeed: 0.2275s/iter; left time: 5460.0788s\n",
      "\titers: 400, epoch: 12 | loss: 0.0862502\n",
      "\tspeed: 0.2285s/iter; left time: 5460.4478s\n",
      "\titers: 500, epoch: 12 | loss: 0.0779765\n",
      "\tspeed: 0.2275s/iter; left time: 5415.2163s\n",
      "\titers: 600, epoch: 12 | loss: 0.0871506\n",
      "\tspeed: 0.2288s/iter; left time: 5421.9341s\n",
      "\titers: 700, epoch: 12 | loss: 0.0837271\n",
      "\tspeed: 0.2291s/iter; left time: 5406.7735s\n",
      "\titers: 800, epoch: 12 | loss: 0.1076618\n",
      "\tspeed: 0.2264s/iter; left time: 5321.1362s\n",
      "\titers: 900, epoch: 12 | loss: 0.0995402\n",
      "\tspeed: 0.2285s/iter; left time: 5347.0045s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0968570\n",
      "\tspeed: 0.2274s/iter; left time: 5298.9445s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0851494\n",
      "\tspeed: 0.2267s/iter; left time: 5260.8074s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0753484\n",
      "\tspeed: 0.2246s/iter; left time: 5189.5687s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0723374\n",
      "\tspeed: 0.2274s/iter; left time: 5230.5069s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0772687\n",
      "\tspeed: 0.2300s/iter; left time: 5268.0363s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0696226\n",
      "\tspeed: 0.2302s/iter; left time: 5247.7502s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0875900\n",
      "\tspeed: 0.2231s/iter; left time: 5065.2503s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0988051\n",
      "\tspeed: 0.2255s/iter; left time: 5095.8991s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0820109\n",
      "\tspeed: 0.2300s/iter; left time: 5175.1120s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0820535\n",
      "\tspeed: 0.2268s/iter; left time: 5079.6665s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0826854\n",
      "\tspeed: 0.2260s/iter; left time: 5040.3931s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0852178\n",
      "\tspeed: 0.2248s/iter; left time: 4990.2175s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0828498\n",
      "\tspeed: 0.2261s/iter; left time: 4996.3994s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0874527\n",
      "\tspeed: 0.2281s/iter; left time: 5018.0891s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0985553\n",
      "\tspeed: 0.2275s/iter; left time: 4982.0378s\n",
      "\titers: 2500, epoch: 12 | loss: 0.1015688\n",
      "\tspeed: 0.2264s/iter; left time: 4934.7857s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0852190\n",
      "\tspeed: 0.2286s/iter; left time: 4959.9233s\n",
      "\titers: 2700, epoch: 12 | loss: 0.1041729\n",
      "\tspeed: 0.2231s/iter; left time: 4819.0547s\n",
      "Epoch: 12 cost time: 00h:10m:13.93s\n",
      "Epoch: 12 | Train Loss: 0.0890474 Vali Loss: 0.0845805 Test Loss: 0.0904383\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.020030096173286438, rmse:0.14152772724628448, mae:0.08731971681118011, rse:0.5354587435722351\n",
      "success delete checkpoints\n",
      "Intermediate time for IT and pred_len 168: 02h:41m:11.52s\n",
      "\n",
      "Intermediate time for IT: 07h:37m:49.44s\n",
      "\n",
      "Total time: 12h:55m:36.75s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DE 24 mae:0.09314965456724167\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'FR',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.010154812596738338,\n",
       "  'RMSE': 0.10077109187841415,\n",
       "  'MAE': 0.05653735250234604},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.019628532230854034,\n",
       "  'RMSE': 0.1401018649339676,\n",
       "  'MAE': 0.08128844946622849},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.02272237464785576,\n",
       "  'RMSE': 0.15073943138122559,\n",
       "  'MAE': 0.08884815871715546},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.010610697790980339,\n",
       "  'RMSE': 0.10300824046134949,\n",
       "  'MAE': 0.05985838919878006},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.01913185976445675,\n",
       "  'RMSE': 0.13831797242164612,\n",
       "  'MAE': 0.08287986367940903},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.020030096173286438,\n",
       "  'RMSE': 0.14152772724628448,\n",
       "  'MAE': 0.08731971681118011}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES']\n",
    "num_cols = [5, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 144725\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-06 06:29:26,702] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 06:29:27,745] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 06:29:27,745] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 06:29:27,745] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 06:29:27,829] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 06:29:27,829] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 06:29:28,975] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 06:29:28,977] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 06:29:28,977] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 06:29:28,978] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 06:29:28,978] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 06:29:28,978] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 06:29:28,978] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 06:29:28,978] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 06:29:28,978] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 06:29:28,978] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 06:29:29,356] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 06:29:29,357] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 06:29:29,357] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 155.3 GB, percent = 20.6%\n",
      "[2024-11-06 06:29:29,494] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 06:29:29,495] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 06:29:29,495] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 155.3 GB, percent = 20.6%\n",
      "[2024-11-06 06:29:29,495] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 06:29:29,617] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 06:29:29,618] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 06:29:29,618] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 155.3 GB, percent = 20.6%\n",
      "[2024-11-06 06:29:29,619] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 06:29:29,619] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 06:29:29,619] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 06:29:29,619] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 06:29:29,620] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 06:29:29,620] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 06:29:29,620] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 06:29:29,620] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 06:29:29,620] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3ded2bda90>\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 06:29:29,621] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 06:29:29,622] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 06:29:29,623] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1947690\n",
      "\tspeed: 0.2895s/iter; left time: 26153.1531s\n",
      "\titers: 200, epoch: 1 | loss: 0.1776660\n",
      "\tspeed: 0.2423s/iter; left time: 21868.6216s\n",
      "\titers: 300, epoch: 1 | loss: 0.2031042\n",
      "\tspeed: 0.2407s/iter; left time: 21700.0435s\n",
      "\titers: 400, epoch: 1 | loss: 0.1268632\n",
      "\tspeed: 0.2403s/iter; left time: 21634.2068s\n",
      "\titers: 500, epoch: 1 | loss: 0.1088823\n",
      "\tspeed: 0.2374s/iter; left time: 21347.8666s\n",
      "\titers: 600, epoch: 1 | loss: 0.1144077\n",
      "\tspeed: 0.2411s/iter; left time: 21660.5705s\n",
      "\titers: 700, epoch: 1 | loss: 0.0966870\n",
      "\tspeed: 0.2402s/iter; left time: 21556.1941s\n",
      "\titers: 800, epoch: 1 | loss: 0.1093277\n",
      "\tspeed: 0.2428s/iter; left time: 21762.2291s\n",
      "\titers: 900, epoch: 1 | loss: 0.1167056\n",
      "\tspeed: 0.2377s/iter; left time: 21282.3770s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1131352\n",
      "\tspeed: 0.2392s/iter; left time: 21392.6875s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1036213\n",
      "\tspeed: 0.2367s/iter; left time: 21151.1541s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0988475\n",
      "\tspeed: 0.2378s/iter; left time: 21217.2385s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0939249\n",
      "\tspeed: 0.2430s/iter; left time: 21661.7161s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0955220\n",
      "\tspeed: 0.2393s/iter; left time: 21309.6546s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0931107\n",
      "\tspeed: 0.2395s/iter; left time: 21301.4904s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0890629\n",
      "\tspeed: 0.2361s/iter; left time: 20971.9468s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0924412\n",
      "\tspeed: 0.2400s/iter; left time: 21296.6074s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1157074\n",
      "\tspeed: 0.2400s/iter; left time: 21275.5905s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0975632\n",
      "\tspeed: 0.2397s/iter; left time: 21218.8527s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1035111\n",
      "\tspeed: 0.2433s/iter; left time: 21513.2843s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0977217\n",
      "\tspeed: 0.2398s/iter; left time: 21187.4430s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1118598\n",
      "\tspeed: 0.2399s/iter; left time: 21171.8630s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0998903\n",
      "\tspeed: 0.2407s/iter; left time: 21218.4094s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1027703\n",
      "\tspeed: 0.2410s/iter; left time: 21215.1278s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0954065\n",
      "\tspeed: 0.2378s/iter; left time: 20911.3948s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0981262\n",
      "\tspeed: 0.2389s/iter; left time: 20984.3369s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0994042\n",
      "\tspeed: 0.2393s/iter; left time: 20992.2001s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1043663\n",
      "\tspeed: 0.2401s/iter; left time: 21041.4223s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1035542\n",
      "\tspeed: 0.2406s/iter; left time: 21063.9520s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0956209\n",
      "\tspeed: 0.2403s/iter; left time: 21012.0662s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0924766\n",
      "\tspeed: 0.2428s/iter; left time: 21209.7005s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1058226\n",
      "\tspeed: 0.2357s/iter; left time: 20559.6415s\n",
      "\titers: 3300, epoch: 1 | loss: 0.0914062\n",
      "\tspeed: 0.2412s/iter; left time: 21019.8310s\n",
      "\titers: 3400, epoch: 1 | loss: 0.0798678\n",
      "\tspeed: 0.2401s/iter; left time: 20900.5359s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0961859\n",
      "\tspeed: 0.2410s/iter; left time: 20950.5362s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1045220\n",
      "\tspeed: 0.2372s/iter; left time: 20600.6625s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0846914\n",
      "\tspeed: 0.2375s/iter; left time: 20599.6451s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0907963\n",
      "\tspeed: 0.2419s/iter; left time: 20958.6736s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1023909\n",
      "\tspeed: 0.2384s/iter; left time: 20631.7259s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0819152\n",
      "\tspeed: 0.2390s/iter; left time: 20661.4175s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0761671\n",
      "\tspeed: 0.2403s/iter; left time: 20745.8980s\n",
      "\titers: 4200, epoch: 1 | loss: 0.0829896\n",
      "\tspeed: 0.2383s/iter; left time: 20547.8382s\n",
      "\titers: 4300, epoch: 1 | loss: 0.0931894\n",
      "\tspeed: 0.2395s/iter; left time: 20632.3589s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0848889\n",
      "\tspeed: 0.2384s/iter; left time: 20516.2648s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0859744\n",
      "\tspeed: 0.2379s/iter; left time: 20441.4228s\n",
      "Epoch: 1 cost time: 00h:18m:05.40s\n",
      "Epoch: 1 | Train Loss: 0.1048770 Vali Loss: 0.0960806 Test Loss: 0.0981403\n",
      "Validation loss decreased (inf --> 0.096081).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0746083\n",
      "\tspeed: 3.5213s/iter; left time: 302190.9566s\n",
      "\titers: 200, epoch: 2 | loss: 0.1005672\n",
      "\tspeed: 0.2279s/iter; left time: 19534.6290s\n",
      "\titers: 300, epoch: 2 | loss: 0.0670380\n",
      "\tspeed: 0.2343s/iter; left time: 20061.3834s\n",
      "\titers: 400, epoch: 2 | loss: 0.0941459\n",
      "\tspeed: 0.2302s/iter; left time: 19686.5060s\n",
      "\titers: 500, epoch: 2 | loss: 0.0959441\n",
      "\tspeed: 0.2252s/iter; left time: 19240.3451s\n",
      "\titers: 600, epoch: 2 | loss: 0.0811750\n",
      "\tspeed: 0.2332s/iter; left time: 19897.2658s\n",
      "\titers: 700, epoch: 2 | loss: 0.0784631\n",
      "\tspeed: 0.2297s/iter; left time: 19572.5145s\n",
      "\titers: 800, epoch: 2 | loss: 0.1021313\n",
      "\tspeed: 0.2289s/iter; left time: 19485.5037s\n",
      "\titers: 900, epoch: 2 | loss: 0.1052926\n",
      "\tspeed: 0.2278s/iter; left time: 19369.0680s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0854664\n",
      "\tspeed: 0.2292s/iter; left time: 19466.6409s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0836618\n",
      "\tspeed: 0.2283s/iter; left time: 19363.1590s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0962946\n",
      "\tspeed: 0.2300s/iter; left time: 19487.5628s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1067337\n",
      "\tspeed: 0.2291s/iter; left time: 19388.4742s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0911453\n",
      "\tspeed: 0.2263s/iter; left time: 19129.7635s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0747394\n",
      "\tspeed: 0.2230s/iter; left time: 18826.9968s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1067635\n",
      "\tspeed: 0.2283s/iter; left time: 19253.1533s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0999277\n",
      "\tspeed: 0.2279s/iter; left time: 19197.4416s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1189041\n",
      "\tspeed: 0.2283s/iter; left time: 19201.8412s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0950528\n",
      "\tspeed: 0.2258s/iter; left time: 18970.4319s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0896823\n",
      "\tspeed: 0.2331s/iter; left time: 19558.7174s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1027068\n",
      "\tspeed: 0.2258s/iter; left time: 18922.1725s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0992241\n",
      "\tspeed: 0.2298s/iter; left time: 19240.6178s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0858788\n",
      "\tspeed: 0.2301s/iter; left time: 19244.1488s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0799289\n",
      "\tspeed: 0.2310s/iter; left time: 19294.3784s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0778574\n",
      "\tspeed: 0.2314s/iter; left time: 19303.4148s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0748872\n",
      "\tspeed: 0.2305s/iter; left time: 19203.3483s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0900917\n",
      "\tspeed: 0.2292s/iter; left time: 19071.0435s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0970166\n",
      "\tspeed: 0.2264s/iter; left time: 18815.8092s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0850864\n",
      "\tspeed: 0.2298s/iter; left time: 19081.1402s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0916244\n",
      "\tspeed: 0.2286s/iter; left time: 18954.0786s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0876987\n",
      "\tspeed: 0.2296s/iter; left time: 19013.4458s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0836273\n",
      "\tspeed: 0.2340s/iter; left time: 19353.3458s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1066847\n",
      "\tspeed: 0.2300s/iter; left time: 18999.1793s\n",
      "\titers: 3400, epoch: 2 | loss: 0.1086510\n",
      "\tspeed: 0.2316s/iter; left time: 19108.5119s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0873110\n",
      "\tspeed: 0.2308s/iter; left time: 19019.4904s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0980456\n",
      "\tspeed: 0.2333s/iter; left time: 19205.8662s\n",
      "\titers: 3700, epoch: 2 | loss: 0.0706605\n",
      "\tspeed: 0.2301s/iter; left time: 18917.7057s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0817242\n",
      "\tspeed: 0.2300s/iter; left time: 18889.8792s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0840167\n",
      "\tspeed: 0.2306s/iter; left time: 18915.8323s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0696671\n",
      "\tspeed: 0.2273s/iter; left time: 18616.5204s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0729957\n",
      "\tspeed: 0.2272s/iter; left time: 18589.4026s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0780836\n",
      "\tspeed: 0.2331s/iter; left time: 19046.3667s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0908734\n",
      "\tspeed: 0.2264s/iter; left time: 18481.2300s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0582582\n",
      "\tspeed: 0.2181s/iter; left time: 17779.7166s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0745809\n",
      "\tspeed: 0.2187s/iter; left time: 17810.3787s\n",
      "Epoch: 2 cost time: 00h:17m:14.99s\n",
      "Epoch: 2 | Train Loss: 0.0892669 Vali Loss: 0.0933206 Test Loss: 0.0965172\n",
      "Validation loss decreased (0.096081 --> 0.093321).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0871556\n",
      "\tspeed: 3.3190s/iter; left time: 269821.1840s\n",
      "\titers: 200, epoch: 3 | loss: 0.0697653\n",
      "\tspeed: 0.2241s/iter; left time: 18195.1104s\n",
      "\titers: 300, epoch: 3 | loss: 0.0795539\n",
      "\tspeed: 0.2292s/iter; left time: 18589.3565s\n",
      "\titers: 400, epoch: 3 | loss: 0.0743290\n",
      "\tspeed: 0.2310s/iter; left time: 18711.4984s\n",
      "\titers: 500, epoch: 3 | loss: 0.0799722\n",
      "\tspeed: 0.2270s/iter; left time: 18362.5187s\n",
      "\titers: 600, epoch: 3 | loss: 0.0759200\n",
      "\tspeed: 0.2249s/iter; left time: 18175.0107s\n",
      "\titers: 700, epoch: 3 | loss: 0.0977495\n",
      "\tspeed: 0.2275s/iter; left time: 18361.3934s\n",
      "\titers: 800, epoch: 3 | loss: 0.0875506\n",
      "\tspeed: 0.2267s/iter; left time: 18274.6889s\n",
      "\titers: 900, epoch: 3 | loss: 0.0689756\n",
      "\tspeed: 0.2272s/iter; left time: 18290.2741s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0757471\n",
      "\tspeed: 0.2296s/iter; left time: 18462.5572s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0810170\n",
      "\tspeed: 0.2270s/iter; left time: 18226.7291s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0929597\n",
      "\tspeed: 0.2293s/iter; left time: 18388.6624s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0961537\n",
      "\tspeed: 0.2269s/iter; left time: 18176.1046s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0888519\n",
      "\tspeed: 0.2292s/iter; left time: 18337.8205s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0874417\n",
      "\tspeed: 0.2296s/iter; left time: 18340.9897s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1099646\n",
      "\tspeed: 0.2282s/iter; left time: 18210.6515s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0925108\n",
      "\tspeed: 0.2265s/iter; left time: 18052.5342s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0890040\n",
      "\tspeed: 0.2269s/iter; left time: 18057.3774s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0790701\n",
      "\tspeed: 0.2263s/iter; left time: 17993.6031s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0651968\n",
      "\tspeed: 0.2226s/iter; left time: 17673.6980s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1082157\n",
      "\tspeed: 0.2241s/iter; left time: 17774.3758s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0968762\n",
      "\tspeed: 0.2280s/iter; left time: 18052.9874s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0970610\n",
      "\tspeed: 0.2305s/iter; left time: 18233.5012s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0647712\n",
      "\tspeed: 0.2299s/iter; left time: 18164.4754s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1001170\n",
      "\tspeed: 0.2274s/iter; left time: 17941.7013s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0802406\n",
      "\tspeed: 0.2298s/iter; left time: 18106.8850s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0692513\n",
      "\tspeed: 0.2265s/iter; left time: 17828.5199s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0910885\n",
      "\tspeed: 0.2262s/iter; left time: 17780.9119s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0902713\n",
      "\tspeed: 0.2229s/iter; left time: 17497.0468s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0826518\n",
      "\tspeed: 0.2257s/iter; left time: 17691.8451s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0795100\n",
      "\tspeed: 0.2281s/iter; left time: 17860.7462s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0791196\n",
      "\tspeed: 0.2270s/iter; left time: 17750.9748s\n",
      "\titers: 3300, epoch: 3 | loss: 0.1042820\n",
      "\tspeed: 0.2270s/iter; left time: 17728.6229s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0843149\n",
      "\tspeed: 0.2246s/iter; left time: 17519.5674s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0776667\n",
      "\tspeed: 0.2250s/iter; left time: 17526.8272s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0886175\n",
      "\tspeed: 0.2236s/iter; left time: 17397.6926s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0962268\n",
      "\tspeed: 0.2296s/iter; left time: 17841.9960s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0874587\n",
      "\tspeed: 0.2283s/iter; left time: 17717.7380s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0664445\n",
      "\tspeed: 0.2265s/iter; left time: 17553.2674s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0814978\n",
      "\tspeed: 0.2288s/iter; left time: 17710.1799s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0946361\n",
      "\tspeed: 0.2264s/iter; left time: 17501.0241s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0910919\n",
      "\tspeed: 0.2264s/iter; left time: 17476.7543s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0809774\n",
      "\tspeed: 0.2222s/iter; left time: 17133.0318s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0913589\n",
      "\tspeed: 0.2227s/iter; left time: 17149.6576s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0955876\n",
      "\tspeed: 0.2268s/iter; left time: 17439.3065s\n",
      "Epoch: 3 cost time: 00h:17m:05.67s\n",
      "Epoch: 3 | Train Loss: 0.0858089 Vali Loss: 0.0905327 Test Loss: 0.0936388\n",
      "Validation loss decreased (0.093321 --> 0.090533).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0884326\n",
      "\tspeed: 3.3255s/iter; left time: 255315.6487s\n",
      "\titers: 200, epoch: 4 | loss: 0.0843162\n",
      "\tspeed: 0.2278s/iter; left time: 17463.5912s\n",
      "\titers: 300, epoch: 4 | loss: 0.0946261\n",
      "\tspeed: 0.2284s/iter; left time: 17487.2380s\n",
      "\titers: 400, epoch: 4 | loss: 0.0899622\n",
      "\tspeed: 0.2258s/iter; left time: 17271.0510s\n",
      "\titers: 500, epoch: 4 | loss: 0.0915801\n",
      "\tspeed: 0.2289s/iter; left time: 17482.9029s\n",
      "\titers: 600, epoch: 4 | loss: 0.0838327\n",
      "\tspeed: 0.2280s/iter; left time: 17388.1255s\n",
      "\titers: 700, epoch: 4 | loss: 0.0954787\n",
      "\tspeed: 0.2276s/iter; left time: 17340.3827s\n",
      "\titers: 800, epoch: 4 | loss: 0.0881302\n",
      "\tspeed: 0.2299s/iter; left time: 17486.4713s\n",
      "\titers: 900, epoch: 4 | loss: 0.0882515\n",
      "\tspeed: 0.2281s/iter; left time: 17331.0323s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0818837\n",
      "\tspeed: 0.2254s/iter; left time: 17103.2395s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0713296\n",
      "\tspeed: 0.2261s/iter; left time: 17129.2517s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0788449\n",
      "\tspeed: 0.2277s/iter; left time: 17233.0634s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0958999\n",
      "\tspeed: 0.2280s/iter; left time: 17233.9137s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0784644\n",
      "\tspeed: 0.2257s/iter; left time: 17035.0898s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0624829\n",
      "\tspeed: 0.2258s/iter; left time: 17019.6879s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0947369\n",
      "\tspeed: 0.2294s/iter; left time: 17268.9016s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0888632\n",
      "\tspeed: 0.2264s/iter; left time: 17021.8522s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0874751\n",
      "\tspeed: 0.2275s/iter; left time: 17083.0674s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0697931\n",
      "\tspeed: 0.2290s/iter; left time: 17171.5177s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0879381\n",
      "\tspeed: 0.2297s/iter; left time: 17201.8833s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0684245\n",
      "\tspeed: 0.2270s/iter; left time: 16970.4328s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0720752\n",
      "\tspeed: 0.2280s/iter; left time: 17025.3237s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0756501\n",
      "\tspeed: 0.2276s/iter; left time: 16974.2600s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0880758\n",
      "\tspeed: 0.2297s/iter; left time: 17107.8360s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0722318\n",
      "\tspeed: 0.2294s/iter; left time: 17060.9475s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0820552\n",
      "\tspeed: 0.2265s/iter; left time: 16824.5702s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1044018\n",
      "\tspeed: 0.2310s/iter; left time: 17134.6842s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0894734\n",
      "\tspeed: 0.2282s/iter; left time: 16907.5981s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0917136\n",
      "\tspeed: 0.2269s/iter; left time: 16781.4846s\n",
      "\titers: 3000, epoch: 4 | loss: 0.1134251\n",
      "\tspeed: 0.2258s/iter; left time: 16681.8848s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1044738\n",
      "\tspeed: 0.2280s/iter; left time: 16823.4919s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0791820\n",
      "\tspeed: 0.2275s/iter; left time: 16759.8408s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0790803\n",
      "\tspeed: 0.2289s/iter; left time: 16841.3725s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0916602\n",
      "\tspeed: 0.2290s/iter; left time: 16824.4318s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0930971\n",
      "\tspeed: 0.2281s/iter; left time: 16733.2636s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0851790\n",
      "\tspeed: 0.2262s/iter; left time: 16576.6227s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1048354\n",
      "\tspeed: 0.2258s/iter; left time: 16519.3310s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0744267\n",
      "\tspeed: 0.2270s/iter; left time: 16589.2734s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0784267\n",
      "\tspeed: 0.2268s/iter; left time: 16552.2401s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0940587\n",
      "\tspeed: 0.2254s/iter; left time: 16429.2970s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0907633\n",
      "\tspeed: 0.2263s/iter; left time: 16467.9748s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0905729\n",
      "\tspeed: 0.2287s/iter; left time: 16619.3097s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0862042\n",
      "\tspeed: 0.2306s/iter; left time: 16736.8029s\n",
      "\titers: 4400, epoch: 4 | loss: 0.0809449\n",
      "\tspeed: 0.2149s/iter; left time: 15578.0561s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0766459\n",
      "\tspeed: 0.1169s/iter; left time: 8461.7112s\n",
      "Epoch: 4 cost time: 00h:16m:55.34s\n",
      "Epoch: 4 | Train Loss: 0.0839394 Vali Loss: 0.0892062 Test Loss: 0.0927070\n",
      "Validation loss decreased (0.090533 --> 0.089206).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0578179\n",
      "\tspeed: 1.6397s/iter; left time: 118471.1151s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733158\n",
      "\tspeed: 0.1189s/iter; left time: 8581.4989s\n",
      "\titers: 300, epoch: 5 | loss: 0.0730598\n",
      "\tspeed: 0.1197s/iter; left time: 8627.6616s\n",
      "\titers: 400, epoch: 5 | loss: 0.0941872\n",
      "\tspeed: 0.1188s/iter; left time: 8547.0254s\n",
      "\titers: 500, epoch: 5 | loss: 0.1001732\n",
      "\tspeed: 0.1186s/iter; left time: 8523.0867s\n",
      "\titers: 600, epoch: 5 | loss: 0.0652587\n",
      "\tspeed: 0.1193s/iter; left time: 8558.4908s\n",
      "\titers: 700, epoch: 5 | loss: 0.0919552\n",
      "\tspeed: 0.1196s/iter; left time: 8570.3543s\n",
      "\titers: 800, epoch: 5 | loss: 0.0948973\n",
      "\tspeed: 0.1204s/iter; left time: 8615.9931s\n",
      "\titers: 900, epoch: 5 | loss: 0.0691776\n",
      "\tspeed: 0.1190s/iter; left time: 8501.0647s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0772280\n",
      "\tspeed: 0.1194s/iter; left time: 8520.6479s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0763803\n",
      "\tspeed: 0.1186s/iter; left time: 8449.1736s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0956275\n",
      "\tspeed: 0.1184s/iter; left time: 8423.1288s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0688214\n",
      "\tspeed: 0.1184s/iter; left time: 8412.8657s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0765467\n",
      "\tspeed: 0.1183s/iter; left time: 8397.2314s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0993163\n",
      "\tspeed: 0.1192s/iter; left time: 8448.8477s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0760889\n",
      "\tspeed: 0.1150s/iter; left time: 8137.8706s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0600102\n",
      "\tspeed: 0.1115s/iter; left time: 7878.9791s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0865187\n",
      "\tspeed: 0.1197s/iter; left time: 8446.2029s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0782561\n",
      "\tspeed: 0.1198s/iter; left time: 8440.4575s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0911397\n",
      "\tspeed: 0.1192s/iter; left time: 8383.7466s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0802732\n",
      "\tspeed: 0.1204s/iter; left time: 8457.3949s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1024032\n",
      "\tspeed: 0.1176s/iter; left time: 8248.2217s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0897889\n",
      "\tspeed: 0.1023s/iter; left time: 7167.2592s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0852283\n",
      "\tspeed: 0.1049s/iter; left time: 7340.6923s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0973163\n",
      "\tspeed: 0.1180s/iter; left time: 8241.2938s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0730305\n",
      "\tspeed: 0.1199s/iter; left time: 8365.9455s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0598633\n",
      "\tspeed: 0.1193s/iter; left time: 8311.4604s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0952151\n",
      "\tspeed: 0.1207s/iter; left time: 8393.8878s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0760750\n",
      "\tspeed: 0.1176s/iter; left time: 8164.8126s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0773771\n",
      "\tspeed: 0.0957s/iter; left time: 6635.9874s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0908923\n",
      "\tspeed: 0.1062s/iter; left time: 7357.1767s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0718424\n",
      "\tspeed: 0.1030s/iter; left time: 7126.1892s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0940741\n",
      "\tspeed: 0.0968s/iter; left time: 6687.7165s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1020535\n",
      "\tspeed: 0.1169s/iter; left time: 8058.0027s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0712784\n",
      "\tspeed: 0.1179s/iter; left time: 8114.8340s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0806415\n",
      "\tspeed: 0.1178s/iter; left time: 8100.6431s\n",
      "\titers: 3700, epoch: 5 | loss: 0.1109851\n",
      "\tspeed: 0.1186s/iter; left time: 8139.1963s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0727358\n",
      "\tspeed: 0.1184s/iter; left time: 8116.2383s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0926790\n",
      "\tspeed: 0.1189s/iter; left time: 8139.8399s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0707512\n",
      "\tspeed: 0.1179s/iter; left time: 8056.8590s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0958885\n",
      "\tspeed: 0.1195s/iter; left time: 8157.4297s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0760552\n",
      "\tspeed: 0.1184s/iter; left time: 8069.5940s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0869788\n",
      "\tspeed: 0.1188s/iter; left time: 8083.7815s\n",
      "\titers: 4400, epoch: 5 | loss: 0.0912382\n",
      "\tspeed: 0.1159s/iter; left time: 7874.1782s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0704773\n",
      "\tspeed: 0.1170s/iter; left time: 7937.7451s\n",
      "Epoch: 5 cost time: 00h:08m:46.11s\n",
      "Epoch: 5 | Train Loss: 0.0826643 Vali Loss: 0.0890515 Test Loss: 0.0932058\n",
      "Validation loss decreased (0.089206 --> 0.089051).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0820235\n",
      "\tspeed: 1.4252s/iter; left time: 96529.0385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818281\n",
      "\tspeed: 0.1211s/iter; left time: 8189.1817s\n",
      "\titers: 300, epoch: 6 | loss: 0.0926009\n",
      "\tspeed: 0.1193s/iter; left time: 8057.6264s\n",
      "\titers: 400, epoch: 6 | loss: 0.0829912\n",
      "\tspeed: 0.1140s/iter; left time: 7688.1074s\n",
      "\titers: 500, epoch: 6 | loss: 0.0598307\n",
      "\tspeed: 0.1199s/iter; left time: 8076.1363s\n",
      "\titers: 600, epoch: 6 | loss: 0.0739386\n",
      "\tspeed: 0.1185s/iter; left time: 7965.0113s\n",
      "\titers: 700, epoch: 6 | loss: 0.0617729\n",
      "\tspeed: 0.1182s/iter; left time: 7934.8083s\n",
      "\titers: 800, epoch: 6 | loss: 0.0898340\n",
      "\tspeed: 0.1199s/iter; left time: 8039.8960s\n",
      "\titers: 900, epoch: 6 | loss: 0.0769326\n",
      "\tspeed: 0.1196s/iter; left time: 8002.6199s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0826217\n",
      "\tspeed: 0.1155s/iter; left time: 7716.2687s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0916705\n",
      "\tspeed: 0.1208s/iter; left time: 8058.0322s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0774097\n",
      "\tspeed: 0.1172s/iter; left time: 7811.6797s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0797626\n",
      "\tspeed: 0.1177s/iter; left time: 7831.5215s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0827434\n",
      "\tspeed: 0.1108s/iter; left time: 7361.6270s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0904293\n",
      "\tspeed: 0.1187s/iter; left time: 7874.4034s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0812904\n",
      "\tspeed: 0.1196s/iter; left time: 7918.9776s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0805031\n",
      "\tspeed: 0.1178s/iter; left time: 7792.6988s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0812551\n",
      "\tspeed: 0.1173s/iter; left time: 7746.3611s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0835698\n",
      "\tspeed: 0.1168s/iter; left time: 7697.7391s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0775620\n",
      "\tspeed: 0.1230s/iter; left time: 8100.3431s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0740983\n",
      "\tspeed: 0.1176s/iter; left time: 7732.7105s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0964011\n",
      "\tspeed: 0.1183s/iter; left time: 7763.1730s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0692102\n",
      "\tspeed: 0.1184s/iter; left time: 7757.5162s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0823309\n",
      "\tspeed: 0.1209s/iter; left time: 7907.9262s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0743375\n",
      "\tspeed: 0.1176s/iter; left time: 7681.2253s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0842438\n",
      "\tspeed: 0.1182s/iter; left time: 7708.9618s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0860098\n",
      "\tspeed: 0.1218s/iter; left time: 7932.8162s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0857710\n",
      "\tspeed: 0.1175s/iter; left time: 7638.1965s\n",
      "\titers: 2900, epoch: 6 | loss: 0.1070067\n",
      "\tspeed: 0.1194s/iter; left time: 7750.2978s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0758004\n",
      "\tspeed: 0.1171s/iter; left time: 7588.7056s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0911790\n",
      "\tspeed: 0.1195s/iter; left time: 7737.2940s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0842434\n",
      "\tspeed: 0.1156s/iter; left time: 7470.1440s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0842595\n",
      "\tspeed: 0.1173s/iter; left time: 7569.1583s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0878704\n",
      "\tspeed: 0.1129s/iter; left time: 7274.9424s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0693951\n",
      "\tspeed: 0.1057s/iter; left time: 6800.3089s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0686905\n",
      "\tspeed: 0.1168s/iter; left time: 7501.9329s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0920968\n",
      "\tspeed: 0.1145s/iter; left time: 7343.1026s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0746245\n",
      "\tspeed: 0.1196s/iter; left time: 7657.8652s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0900854\n",
      "\tspeed: 0.1173s/iter; left time: 7499.1731s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0966301\n",
      "\tspeed: 0.1196s/iter; left time: 7635.3161s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0768370\n",
      "\tspeed: 0.1188s/iter; left time: 7569.9234s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0834257\n",
      "\tspeed: 0.1180s/iter; left time: 7507.0802s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0865524\n",
      "\tspeed: 0.1173s/iter; left time: 7449.1966s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0804501\n",
      "\tspeed: 0.1164s/iter; left time: 7381.7203s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0942846\n",
      "\tspeed: 0.1176s/iter; left time: 7450.5386s\n",
      "Epoch: 6 cost time: 00h:08m:52.90s\n",
      "Epoch: 6 | Train Loss: 0.0817595 Vali Loss: 0.0887247 Test Loss: 0.0929518\n",
      "Validation loss decreased (0.089051 --> 0.088725).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0680448\n",
      "\tspeed: 1.4241s/iter; left time: 90014.3079s\n",
      "\titers: 200, epoch: 7 | loss: 0.0738839\n",
      "\tspeed: 0.1166s/iter; left time: 7357.1419s\n",
      "\titers: 300, epoch: 7 | loss: 0.0774487\n",
      "\tspeed: 0.1178s/iter; left time: 7420.3465s\n",
      "\titers: 400, epoch: 7 | loss: 0.0621370\n",
      "\tspeed: 0.1209s/iter; left time: 7603.5039s\n",
      "\titers: 500, epoch: 7 | loss: 0.0608166\n",
      "\tspeed: 0.1165s/iter; left time: 7319.1547s\n",
      "\titers: 600, epoch: 7 | loss: 0.0734269\n",
      "\tspeed: 0.1160s/iter; left time: 7272.3546s\n",
      "\titers: 700, epoch: 7 | loss: 0.0831945\n",
      "\tspeed: 0.1192s/iter; left time: 7461.5495s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764554\n",
      "\tspeed: 0.1179s/iter; left time: 7367.6206s\n",
      "\titers: 900, epoch: 7 | loss: 0.0709165\n",
      "\tspeed: 0.1180s/iter; left time: 7362.3696s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0700622\n",
      "\tspeed: 0.1175s/iter; left time: 7323.9836s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0749535\n",
      "\tspeed: 0.1184s/iter; left time: 7363.9921s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0777356\n",
      "\tspeed: 0.1214s/iter; left time: 7538.3675s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0810708\n",
      "\tspeed: 0.1150s/iter; left time: 7132.0023s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0749339\n",
      "\tspeed: 0.1138s/iter; left time: 7042.8004s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0992716\n",
      "\tspeed: 0.1098s/iter; left time: 6788.5397s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0756176\n",
      "\tspeed: 0.1093s/iter; left time: 6745.9232s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0991645\n",
      "\tspeed: 0.1122s/iter; left time: 6910.9571s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0821003\n",
      "\tspeed: 0.1178s/iter; left time: 7247.6458s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0765042\n",
      "\tspeed: 0.1170s/iter; left time: 7185.9390s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1043672\n",
      "\tspeed: 0.1068s/iter; left time: 6546.5730s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0987192\n",
      "\tspeed: 0.1176s/iter; left time: 7195.5859s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0757523\n",
      "\tspeed: 0.1178s/iter; left time: 7198.9221s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0709070\n",
      "\tspeed: 0.1170s/iter; left time: 7137.9751s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0724231\n",
      "\tspeed: 0.1194s/iter; left time: 7275.4163s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0922310\n",
      "\tspeed: 0.1162s/iter; left time: 7066.3312s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0905651\n",
      "\tspeed: 0.1167s/iter; left time: 7086.3379s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0751425\n",
      "\tspeed: 0.1146s/iter; left time: 6944.2410s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0812143\n",
      "\tspeed: 0.1156s/iter; left time: 6997.6936s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0870181\n",
      "\tspeed: 0.1058s/iter; left time: 6393.8574s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0632929\n",
      "\tspeed: 0.1190s/iter; left time: 7179.0648s\n",
      "\titers: 3100, epoch: 7 | loss: 0.0811382\n",
      "\tspeed: 0.1190s/iter; left time: 7167.2709s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0861575\n",
      "\tspeed: 0.1138s/iter; left time: 6840.4390s\n",
      "\titers: 3300, epoch: 7 | loss: 0.1027283\n",
      "\tspeed: 0.1143s/iter; left time: 6856.1930s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0830595\n",
      "\tspeed: 0.1201s/iter; left time: 7197.6175s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0917927\n",
      "\tspeed: 0.1146s/iter; left time: 6856.0445s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0868666\n",
      "\tspeed: 0.1163s/iter; left time: 6941.3455s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0969641\n",
      "\tspeed: 0.1125s/iter; left time: 6703.5558s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0706552\n",
      "\tspeed: 0.1123s/iter; left time: 6684.5315s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0852672\n",
      "\tspeed: 0.1102s/iter; left time: 6546.6892s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0780015\n",
      "\tspeed: 0.1160s/iter; left time: 6878.4832s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0778503\n",
      "\tspeed: 0.1123s/iter; left time: 6651.3216s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0730124\n",
      "\tspeed: 0.1091s/iter; left time: 6449.4542s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0811850\n",
      "\tspeed: 0.0920s/iter; left time: 5427.2876s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0581527\n",
      "\tspeed: 0.1018s/iter; left time: 5999.6829s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0836765\n",
      "\tspeed: 0.1227s/iter; left time: 7217.0726s\n",
      "Epoch: 7 cost time: 00h:08m:40.06s\n",
      "Epoch: 7 | Train Loss: 0.0810505 Vali Loss: 0.0884121 Test Loss: 0.0931496\n",
      "Validation loss decreased (0.088725 --> 0.088412).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0901530\n",
      "\tspeed: 1.3735s/iter; left time: 80606.5171s\n",
      "\titers: 200, epoch: 8 | loss: 0.0722257\n",
      "\tspeed: 0.0782s/iter; left time: 4579.7399s\n",
      "\titers: 300, epoch: 8 | loss: 0.0984988\n",
      "\tspeed: 0.0780s/iter; left time: 4564.6153s\n",
      "\titers: 400, epoch: 8 | loss: 0.0915425\n",
      "\tspeed: 0.1197s/iter; left time: 6988.9871s\n",
      "\titers: 500, epoch: 8 | loss: 0.0656964\n",
      "\tspeed: 0.1168s/iter; left time: 6806.7524s\n",
      "\titers: 600, epoch: 8 | loss: 0.0849185\n",
      "\tspeed: 0.1136s/iter; left time: 6609.1780s\n",
      "\titers: 700, epoch: 8 | loss: 0.0746087\n",
      "\tspeed: 0.1195s/iter; left time: 6941.3640s\n",
      "\titers: 800, epoch: 8 | loss: 0.0866634\n",
      "\tspeed: 0.1232s/iter; left time: 7142.0908s\n",
      "\titers: 900, epoch: 8 | loss: 0.0766158\n",
      "\tspeed: 0.1185s/iter; left time: 6860.1295s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0806300\n",
      "\tspeed: 0.1188s/iter; left time: 6866.4262s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0967921\n",
      "\tspeed: 0.1248s/iter; left time: 7198.6382s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0786811\n",
      "\tspeed: 0.1173s/iter; left time: 6754.9966s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0810843\n",
      "\tspeed: 0.0921s/iter; left time: 5296.7176s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0844774\n",
      "\tspeed: 0.0773s/iter; left time: 4435.4769s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0789189\n",
      "\tspeed: 0.0775s/iter; left time: 4438.3118s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0976249\n",
      "\tspeed: 0.0773s/iter; left time: 4420.5610s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0792369\n",
      "\tspeed: 0.1133s/iter; left time: 6468.8276s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0812237\n",
      "\tspeed: 0.1109s/iter; left time: 6321.9152s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0880259\n",
      "\tspeed: 0.1111s/iter; left time: 6321.6423s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0896781\n",
      "\tspeed: 0.1054s/iter; left time: 5983.6971s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0909430\n",
      "\tspeed: 0.1108s/iter; left time: 6282.9327s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0919062\n",
      "\tspeed: 0.1109s/iter; left time: 6277.0116s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0748377\n",
      "\tspeed: 0.1111s/iter; left time: 6278.0514s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0761275\n",
      "\tspeed: 0.1114s/iter; left time: 6283.7887s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0776372\n",
      "\tspeed: 0.1114s/iter; left time: 6269.7205s\n",
      "\titers: 2600, epoch: 8 | loss: 0.1059794\n",
      "\tspeed: 0.1109s/iter; left time: 6229.0675s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0675359\n",
      "\tspeed: 0.1104s/iter; left time: 6194.0083s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0870733\n",
      "\tspeed: 0.1114s/iter; left time: 6235.5622s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0686034\n",
      "\tspeed: 0.1107s/iter; left time: 6187.6512s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0939301\n",
      "\tspeed: 0.1108s/iter; left time: 6183.7742s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0826013\n",
      "\tspeed: 0.1107s/iter; left time: 6164.1072s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0869364\n",
      "\tspeed: 0.1112s/iter; left time: 6179.7203s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0901748\n",
      "\tspeed: 0.1108s/iter; left time: 6148.1154s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0666760\n",
      "\tspeed: 0.1108s/iter; left time: 6139.1878s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0802026\n",
      "\tspeed: 0.1081s/iter; left time: 5978.6170s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0590362\n",
      "\tspeed: 0.1100s/iter; left time: 6070.3353s\n",
      "\titers: 3700, epoch: 8 | loss: 0.1003851\n",
      "\tspeed: 0.1125s/iter; left time: 6195.3802s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0815668\n",
      "\tspeed: 0.1098s/iter; left time: 6039.5297s\n",
      "\titers: 3900, epoch: 8 | loss: 0.1049749\n",
      "\tspeed: 0.1113s/iter; left time: 6106.4155s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0793437\n",
      "\tspeed: 0.1111s/iter; left time: 6087.9039s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0900405\n",
      "\tspeed: 0.1110s/iter; left time: 6070.0885s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0882535\n",
      "\tspeed: 0.1107s/iter; left time: 6044.9173s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0898300\n",
      "\tspeed: 0.1075s/iter; left time: 5859.6613s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0797898\n",
      "\tspeed: 0.1113s/iter; left time: 6052.2289s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0898872\n",
      "\tspeed: 0.1108s/iter; left time: 6016.1872s\n",
      "Epoch: 8 cost time: 00h:08m:07.11s\n",
      "Epoch: 8 | Train Loss: 0.0803500 Vali Loss: 0.0890016 Test Loss: 0.0936982\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0750944\n",
      "\tspeed: 1.3361s/iter; left time: 72368.4439s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763179\n",
      "\tspeed: 0.1109s/iter; left time: 5995.2698s\n",
      "\titers: 300, epoch: 9 | loss: 0.0726737\n",
      "\tspeed: 0.1127s/iter; left time: 6079.7704s\n",
      "\titers: 400, epoch: 9 | loss: 0.0601121\n",
      "\tspeed: 0.1110s/iter; left time: 5978.1566s\n",
      "\titers: 500, epoch: 9 | loss: 0.0801954\n",
      "\tspeed: 0.1127s/iter; left time: 6058.3934s\n",
      "\titers: 600, epoch: 9 | loss: 0.0854623\n",
      "\tspeed: 0.1113s/iter; left time: 5970.7708s\n",
      "\titers: 700, epoch: 9 | loss: 0.0729199\n",
      "\tspeed: 0.1111s/iter; left time: 5952.4789s\n",
      "\titers: 800, epoch: 9 | loss: 0.0762108\n",
      "\tspeed: 0.1104s/iter; left time: 5903.7345s\n",
      "\titers: 900, epoch: 9 | loss: 0.0934547\n",
      "\tspeed: 0.1092s/iter; left time: 5829.6043s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0730119\n",
      "\tspeed: 0.1110s/iter; left time: 5912.6738s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0695131\n",
      "\tspeed: 0.1109s/iter; left time: 5897.4208s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0776559\n",
      "\tspeed: 0.1114s/iter; left time: 5913.6967s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0973340\n",
      "\tspeed: 0.1115s/iter; left time: 5903.9053s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0787839\n",
      "\tspeed: 0.1116s/iter; left time: 5898.1496s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0968190\n",
      "\tspeed: 0.1088s/iter; left time: 5738.7692s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0859813\n",
      "\tspeed: 0.1112s/iter; left time: 5854.4321s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0757573\n",
      "\tspeed: 0.1111s/iter; left time: 5840.2291s\n",
      "\titers: 1800, epoch: 9 | loss: 0.1103667\n",
      "\tspeed: 0.1108s/iter; left time: 5811.1770s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0666164\n",
      "\tspeed: 0.1112s/iter; left time: 5821.8758s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0709838\n",
      "\tspeed: 0.1114s/iter; left time: 5824.8531s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0708494\n",
      "\tspeed: 0.1112s/iter; left time: 5802.7231s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0813441\n",
      "\tspeed: 0.1110s/iter; left time: 5779.7076s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0846202\n",
      "\tspeed: 0.1108s/iter; left time: 5759.3854s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0703913\n",
      "\tspeed: 0.1084s/iter; left time: 5622.9475s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0758274\n",
      "\tspeed: 0.1112s/iter; left time: 5753.8914s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0850932\n",
      "\tspeed: 0.1110s/iter; left time: 5733.4232s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0719570\n",
      "\tspeed: 0.1118s/iter; left time: 5762.7196s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0861304\n",
      "\tspeed: 0.1110s/iter; left time: 5714.3235s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0779722\n",
      "\tspeed: 0.1112s/iter; left time: 5711.8980s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0955840\n",
      "\tspeed: 0.1116s/iter; left time: 5721.2848s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0907345\n",
      "\tspeed: 0.1107s/iter; left time: 5666.4525s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0804284\n",
      "\tspeed: 0.1110s/iter; left time: 5670.0709s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0802070\n",
      "\tspeed: 0.1087s/iter; left time: 5539.1534s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0828116\n",
      "\tspeed: 0.1108s/iter; left time: 5636.3991s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0884701\n",
      "\tspeed: 0.1121s/iter; left time: 5691.1464s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0803281\n",
      "\tspeed: 0.1111s/iter; left time: 5629.3629s\n",
      "\titers: 3700, epoch: 9 | loss: 0.1162596\n",
      "\tspeed: 0.1114s/iter; left time: 5630.4947s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0718330\n",
      "\tspeed: 0.1110s/iter; left time: 5601.0762s\n",
      "\titers: 3900, epoch: 9 | loss: 0.0722408\n",
      "\tspeed: 0.1080s/iter; left time: 5440.0392s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0860514\n",
      "\tspeed: 0.1112s/iter; left time: 5590.8186s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0887168\n",
      "\tspeed: 0.1110s/iter; left time: 5569.9902s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0674479\n",
      "\tspeed: 0.1111s/iter; left time: 5561.0757s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0751812\n",
      "\tspeed: 0.1121s/iter; left time: 5598.9817s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0800303\n",
      "\tspeed: 0.1114s/iter; left time: 5554.1224s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0791881\n",
      "\tspeed: 0.1108s/iter; left time: 5514.9316s\n",
      "Epoch: 9 cost time: 00h:08m:22.19s\n",
      "Epoch: 9 | Train Loss: 0.0797290 Vali Loss: 0.0900298 Test Loss: 0.0952606\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0653273\n",
      "\tspeed: 1.3436s/iter; left time: 66699.2915s\n",
      "\titers: 200, epoch: 10 | loss: 0.0765166\n",
      "\tspeed: 0.1108s/iter; left time: 5490.7624s\n",
      "\titers: 300, epoch: 10 | loss: 0.0779064\n",
      "\tspeed: 0.1113s/iter; left time: 5505.0625s\n",
      "\titers: 400, epoch: 10 | loss: 0.0871397\n",
      "\tspeed: 0.1114s/iter; left time: 5499.0281s\n",
      "\titers: 500, epoch: 10 | loss: 0.0518574\n",
      "\tspeed: 0.1109s/iter; left time: 5461.5460s\n",
      "\titers: 600, epoch: 10 | loss: 0.0942062\n",
      "\tspeed: 0.1116s/iter; left time: 5482.1005s\n",
      "\titers: 700, epoch: 10 | loss: 0.1073352\n",
      "\tspeed: 0.1109s/iter; left time: 5438.5217s\n",
      "\titers: 800, epoch: 10 | loss: 0.0904766\n",
      "\tspeed: 0.1112s/iter; left time: 5444.8947s\n",
      "\titers: 900, epoch: 10 | loss: 0.0699207\n",
      "\tspeed: 0.1110s/iter; left time: 5422.4952s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0915822\n",
      "\tspeed: 0.1110s/iter; left time: 5411.7648s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0749717\n",
      "\tspeed: 0.1116s/iter; left time: 5426.5748s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0770236\n",
      "\tspeed: 0.1120s/iter; left time: 5436.3593s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0780467\n",
      "\tspeed: 0.1058s/iter; left time: 5124.6938s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0802334\n",
      "\tspeed: 0.1109s/iter; left time: 5361.0089s\n",
      "\titers: 1500, epoch: 10 | loss: 0.1088436\n",
      "\tspeed: 0.1116s/iter; left time: 5385.8711s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0820000\n",
      "\tspeed: 0.1127s/iter; left time: 5426.8258s\n",
      "\titers: 1700, epoch: 10 | loss: 0.1044328\n",
      "\tspeed: 0.1113s/iter; left time: 5348.6602s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0744999\n",
      "\tspeed: 0.1108s/iter; left time: 5313.0794s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0889906\n",
      "\tspeed: 0.1109s/iter; left time: 5308.0124s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0848880\n",
      "\tspeed: 0.1108s/iter; left time: 5291.3868s\n",
      "\titers: 2100, epoch: 10 | loss: 0.1016778\n",
      "\tspeed: 0.1111s/iter; left time: 5291.2759s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0722688\n",
      "\tspeed: 0.1110s/iter; left time: 5279.2370s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0960713\n",
      "\tspeed: 0.1108s/iter; left time: 5254.5919s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0674276\n",
      "\tspeed: 0.1110s/iter; left time: 5253.2834s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0893240\n",
      "\tspeed: 0.1111s/iter; left time: 5249.8319s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0763532\n",
      "\tspeed: 0.1037s/iter; left time: 4890.8086s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0862674\n",
      "\tspeed: 0.0951s/iter; left time: 4475.2828s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0728955\n",
      "\tspeed: 0.1060s/iter; left time: 4975.8962s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0673414\n",
      "\tspeed: 0.1113s/iter; left time: 5215.8318s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0836768\n",
      "\tspeed: 0.1127s/iter; left time: 5266.0184s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0656310\n",
      "\tspeed: 0.1065s/iter; left time: 4967.4316s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0904394\n",
      "\tspeed: 0.1109s/iter; left time: 5163.3905s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.1128s/iter; left time: 5238.5651s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0984331\n",
      "\tspeed: 0.1122s/iter; left time: 5198.8149s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0799276\n",
      "\tspeed: 0.1162s/iter; left time: 5371.3752s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0763562\n",
      "\tspeed: 0.1126s/iter; left time: 5194.5611s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0833671\n",
      "\tspeed: 0.1108s/iter; left time: 5103.8471s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0809808\n",
      "\tspeed: 0.1143s/iter; left time: 5250.9207s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0779642\n",
      "\tspeed: 0.1079s/iter; left time: 4946.6691s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0903702\n",
      "\tspeed: 0.1119s/iter; left time: 5118.5073s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0747551\n",
      "\tspeed: 0.1109s/iter; left time: 5063.1755s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0766312\n",
      "\tspeed: 0.1100s/iter; left time: 5007.8775s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0774595\n",
      "\tspeed: 0.0979s/iter; left time: 4448.5658s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0845195\n",
      "\tspeed: 0.1177s/iter; left time: 5336.4086s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0594170\n",
      "\tspeed: 0.1110s/iter; left time: 5024.0828s\n",
      "Epoch: 10 cost time: 00h:08m:19.77s\n",
      "Epoch: 10 | Train Loss: 0.0790722 Vali Loss: 0.0892528 Test Loss: 0.0933100\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0825277\n",
      "\tspeed: 1.3609s/iter; left time: 61405.2187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0775655\n",
      "\tspeed: 0.1149s/iter; left time: 5174.4660s\n",
      "\titers: 300, epoch: 11 | loss: 0.0762630\n",
      "\tspeed: 0.1111s/iter; left time: 4991.1769s\n",
      "\titers: 400, epoch: 11 | loss: 0.0775945\n",
      "\tspeed: 0.1141s/iter; left time: 5112.2454s\n",
      "\titers: 500, epoch: 11 | loss: 0.0861947\n",
      "\tspeed: 0.1147s/iter; left time: 5127.3393s\n",
      "\titers: 600, epoch: 11 | loss: 0.0707057\n",
      "\tspeed: 0.1131s/iter; left time: 5044.5509s\n",
      "\titers: 700, epoch: 11 | loss: 0.0666433\n",
      "\tspeed: 0.1132s/iter; left time: 5038.4213s\n",
      "\titers: 800, epoch: 11 | loss: 0.0844187\n",
      "\tspeed: 0.1131s/iter; left time: 5025.1680s\n",
      "\titers: 900, epoch: 11 | loss: 0.0870979\n",
      "\tspeed: 0.1139s/iter; left time: 5047.0937s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0794835\n",
      "\tspeed: 0.1124s/iter; left time: 4972.5088s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0864221\n",
      "\tspeed: 0.1130s/iter; left time: 4986.4441s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0771927\n",
      "\tspeed: 0.1150s/iter; left time: 5064.0619s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0791122\n",
      "\tspeed: 0.1154s/iter; left time: 5069.9747s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0643359\n",
      "\tspeed: 0.1144s/iter; left time: 5011.3136s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0686717\n",
      "\tspeed: 0.1128s/iter; left time: 4931.3073s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0786852\n",
      "\tspeed: 0.1136s/iter; left time: 4956.9557s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0601453\n",
      "\tspeed: 0.1140s/iter; left time: 4961.4517s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0746343\n",
      "\tspeed: 0.1138s/iter; left time: 4939.3110s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0629634\n",
      "\tspeed: 0.1139s/iter; left time: 4935.8844s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0922612\n",
      "\tspeed: 0.1143s/iter; left time: 4941.7518s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0926695\n",
      "\tspeed: 0.1135s/iter; left time: 4894.0054s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0724381\n",
      "\tspeed: 0.1135s/iter; left time: 4881.1897s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0744640\n",
      "\tspeed: 0.1124s/iter; left time: 4824.9540s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0692319\n",
      "\tspeed: 0.1138s/iter; left time: 4874.4311s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0860685\n",
      "\tspeed: 0.1113s/iter; left time: 4756.3486s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0697698\n",
      "\tspeed: 0.1116s/iter; left time: 4756.4746s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0678483\n",
      "\tspeed: 0.1097s/iter; left time: 4664.1273s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0741908\n",
      "\tspeed: 0.0942s/iter; left time: 3996.6366s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0754735\n",
      "\tspeed: 0.1183s/iter; left time: 5005.5738s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0667507\n",
      "\tspeed: 0.1116s/iter; left time: 4710.1356s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0793595\n",
      "\tspeed: 0.1116s/iter; left time: 4700.5496s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0584280\n",
      "\tspeed: 0.1112s/iter; left time: 4672.1761s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0856880\n",
      "\tspeed: 0.1109s/iter; left time: 4648.4520s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0730866\n",
      "\tspeed: 0.1109s/iter; left time: 4638.9887s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0829942\n",
      "\tspeed: 0.1119s/iter; left time: 4666.6180s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0929585\n",
      "\tspeed: 0.1113s/iter; left time: 4633.0522s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0841509\n",
      "\tspeed: 0.1109s/iter; left time: 4604.4634s\n",
      "\titers: 3800, epoch: 11 | loss: 0.0727383\n",
      "\tspeed: 0.1110s/iter; left time: 4599.5010s\n",
      "\titers: 3900, epoch: 11 | loss: 0.0825637\n",
      "\tspeed: 0.1109s/iter; left time: 4584.4649s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0897021\n",
      "\tspeed: 0.1109s/iter; left time: 4571.6164s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0722802\n",
      "\tspeed: 0.1112s/iter; left time: 4573.7680s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0838798\n",
      "\tspeed: 0.1123s/iter; left time: 4608.1178s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0739125\n",
      "\tspeed: 0.1109s/iter; left time: 4539.3457s\n",
      "\titers: 4400, epoch: 11 | loss: 0.0708503\n",
      "\tspeed: 0.1109s/iter; left time: 4525.9728s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0842030\n",
      "\tspeed: 0.1111s/iter; left time: 4523.5119s\n",
      "Epoch: 11 cost time: 00h:08m:28.16s\n",
      "Epoch: 11 | Train Loss: 0.0785658 Vali Loss: 0.0902027 Test Loss: 0.0946430\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0671278\n",
      "\tspeed: 1.3876s/iter; left time: 56335.9117s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818562\n",
      "\tspeed: 0.1220s/iter; left time: 4941.6224s\n",
      "\titers: 300, epoch: 12 | loss: 0.0868929\n",
      "\tspeed: 0.1109s/iter; left time: 4481.7379s\n",
      "\titers: 400, epoch: 12 | loss: 0.0820025\n",
      "\tspeed: 0.1193s/iter; left time: 4806.4161s\n",
      "\titers: 500, epoch: 12 | loss: 0.0734881\n",
      "\tspeed: 0.1190s/iter; left time: 4784.8067s\n",
      "\titers: 600, epoch: 12 | loss: 0.0676998\n",
      "\tspeed: 0.1202s/iter; left time: 4820.3331s\n",
      "\titers: 700, epoch: 12 | loss: 0.0813532\n",
      "\tspeed: 0.1212s/iter; left time: 4849.0124s\n",
      "\titers: 800, epoch: 12 | loss: 0.0759037\n",
      "\tspeed: 0.1140s/iter; left time: 4548.6734s\n",
      "\titers: 900, epoch: 12 | loss: 0.0633736\n",
      "\tspeed: 0.1138s/iter; left time: 4530.3080s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0872487\n",
      "\tspeed: 0.1166s/iter; left time: 4629.1450s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0722900\n",
      "\tspeed: 0.1151s/iter; left time: 4558.2274s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0934101\n",
      "\tspeed: 0.1187s/iter; left time: 4687.8646s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0795377\n",
      "\tspeed: 0.1205s/iter; left time: 4748.1838s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0724210\n",
      "\tspeed: 0.1150s/iter; left time: 4520.8418s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0695695\n",
      "\tspeed: 0.1139s/iter; left time: 4462.8668s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0651198\n",
      "\tspeed: 0.1160s/iter; left time: 4535.1617s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0820826\n",
      "\tspeed: 0.1148s/iter; left time: 4478.1136s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0695625\n",
      "\tspeed: 0.1156s/iter; left time: 4496.1941s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0682952\n",
      "\tspeed: 0.1182s/iter; left time: 4586.9945s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0704926\n",
      "\tspeed: 0.1169s/iter; left time: 4524.3015s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0855359\n",
      "\tspeed: 0.1143s/iter; left time: 4411.7818s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0850420\n",
      "\tspeed: 0.1187s/iter; left time: 4571.7156s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0753119\n",
      "\tspeed: 0.1134s/iter; left time: 4355.3845s\n",
      "\titers: 2400, epoch: 12 | loss: 0.1017915\n",
      "\tspeed: 0.1132s/iter; left time: 4334.6627s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0750572\n",
      "\tspeed: 0.1178s/iter; left time: 4499.6610s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0795496\n",
      "\tspeed: 0.1167s/iter; left time: 4445.8435s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0668767\n",
      "\tspeed: 0.1205s/iter; left time: 4580.5065s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0737271\n",
      "\tspeed: 0.1188s/iter; left time: 4501.5333s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0688364\n",
      "\tspeed: 0.1176s/iter; left time: 4445.4195s\n",
      "\titers: 3000, epoch: 12 | loss: 0.1167611\n",
      "\tspeed: 0.1169s/iter; left time: 4406.7554s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0872489\n",
      "\tspeed: 0.1174s/iter; left time: 4415.3134s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0676144\n",
      "\tspeed: 0.1171s/iter; left time: 4391.3094s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0613568\n",
      "\tspeed: 0.1166s/iter; left time: 4360.8847s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0819866\n",
      "\tspeed: 0.1187s/iter; left time: 4427.6921s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0681567\n",
      "\tspeed: 0.0941s/iter; left time: 3502.1281s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0867855\n",
      "\tspeed: 0.1073s/iter; left time: 3982.4580s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0672174\n",
      "\tspeed: 0.1149s/iter; left time: 4250.2455s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0662094\n",
      "\tspeed: 0.1003s/iter; left time: 3702.1301s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0735870\n",
      "\tspeed: 0.1128s/iter; left time: 4150.9645s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0810470\n",
      "\tspeed: 0.1128s/iter; left time: 4139.2649s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0864132\n",
      "\tspeed: 0.1134s/iter; left time: 4148.5009s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0902337\n",
      "\tspeed: 0.1135s/iter; left time: 4143.2749s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0866598\n",
      "\tspeed: 0.1129s/iter; left time: 4109.2110s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0879923\n",
      "\tspeed: 0.1141s/iter; left time: 4141.0193s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0898791\n",
      "\tspeed: 0.1158s/iter; left time: 4193.1792s\n",
      "Epoch: 12 cost time: 00h:08m:42.41s\n",
      "Epoch: 12 | Train Loss: 0.0778909 Vali Loss: 0.0908114 Test Loss: 0.0971247\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.022713396698236465, rmse:0.15070964395999908, mae:0.09314965456724167, rse:0.5322779417037964\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 24: 02h:53m:42.16s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 144365\n",
      "val 30725\n",
      "test 30725\n",
      "[2024-11-06 09:23:10,129] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 09:23:10,993] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 09:23:10,993] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 09:23:10,993] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 09:23:11,086] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 09:23:11,086] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 09:23:11,777] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 09:23:11,779] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 09:23:11,779] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 09:23:11,780] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 09:23:11,780] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 09:23:11,780] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 09:23:11,780] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 09:23:11,780] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 09:23:11,780] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 09:23:11,780] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 09:23:12,112] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 09:23:12,113] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 09:23:12,113] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 282.9 GB, percent = 37.5%\n",
      "[2024-11-06 09:23:12,231] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 09:23:12,232] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 09:23:12,232] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 282.9 GB, percent = 37.5%\n",
      "[2024-11-06 09:23:12,232] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 09:23:12,344] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 09:23:12,345] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 09:23:12,346] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 282.9 GB, percent = 37.5%\n",
      "[2024-11-06 09:23:12,346] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 09:23:12,346] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 09:23:12,346] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 09:23:12,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 09:23:12,347] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc6b9878d50>\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 09:23:12,348] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 09:23:12,349] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 09:23:12,350] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1955433\n",
      "\tspeed: 0.1612s/iter; left time: 14528.9724s\n",
      "\titers: 200, epoch: 1 | loss: 0.1576913\n",
      "\tspeed: 0.1248s/iter; left time: 11237.0126s\n",
      "\titers: 300, epoch: 1 | loss: 0.1706125\n",
      "\tspeed: 0.1076s/iter; left time: 9671.8580s\n",
      "\titers: 400, epoch: 1 | loss: 0.1416292\n",
      "\tspeed: 0.1212s/iter; left time: 10890.5159s\n",
      "\titers: 500, epoch: 1 | loss: 0.1580371\n",
      "\tspeed: 0.1267s/iter; left time: 11368.2091s\n",
      "\titers: 600, epoch: 1 | loss: 0.1610549\n",
      "\tspeed: 0.1266s/iter; left time: 11346.8291s\n",
      "\titers: 700, epoch: 1 | loss: 0.1424283\n",
      "\tspeed: 0.1236s/iter; left time: 11067.7853s\n",
      "\titers: 800, epoch: 1 | loss: 0.1225299\n",
      "\tspeed: 0.1223s/iter; left time: 10934.8362s\n",
      "\titers: 900, epoch: 1 | loss: 0.1200695\n",
      "\tspeed: 0.1225s/iter; left time: 10938.2974s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1151218\n",
      "\tspeed: 0.1199s/iter; left time: 10700.3299s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1356930\n",
      "\tspeed: 0.1031s/iter; left time: 9187.8993s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1108458\n",
      "\tspeed: 0.1193s/iter; left time: 10621.3194s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0982396\n",
      "\tspeed: 0.1211s/iter; left time: 10772.7287s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1193908\n",
      "\tspeed: 0.1221s/iter; left time: 10846.1798s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1241413\n",
      "\tspeed: 0.1224s/iter; left time: 10855.0663s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1202193\n",
      "\tspeed: 0.1216s/iter; left time: 10772.6973s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1277682\n",
      "\tspeed: 0.1073s/iter; left time: 9501.6261s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0905929\n",
      "\tspeed: 0.1024s/iter; left time: 9054.1337s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1194042\n",
      "\tspeed: 0.1172s/iter; left time: 10350.5676s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1169484\n",
      "\tspeed: 0.1211s/iter; left time: 10685.8088s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1186329\n",
      "\tspeed: 0.1214s/iter; left time: 10700.9323s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1164813\n",
      "\tspeed: 0.1213s/iter; left time: 10678.6263s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1402844\n",
      "\tspeed: 0.1222s/iter; left time: 10743.2436s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1286963\n",
      "\tspeed: 0.1210s/iter; left time: 10627.7184s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1067113\n",
      "\tspeed: 0.1220s/iter; left time: 10703.6879s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1177776\n",
      "\tspeed: 0.1178s/iter; left time: 10319.2900s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1251814\n",
      "\tspeed: 0.1181s/iter; left time: 10336.9149s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1157050\n",
      "\tspeed: 0.1219s/iter; left time: 10654.1251s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1138957\n",
      "\tspeed: 0.1207s/iter; left time: 10540.4443s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1348794\n",
      "\tspeed: 0.1213s/iter; left time: 10579.8065s\n",
      "\titers: 3100, epoch: 1 | loss: 0.1457374\n",
      "\tspeed: 0.1223s/iter; left time: 10658.9637s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1248478\n",
      "\tspeed: 0.1206s/iter; left time: 10498.2897s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1205704\n",
      "\tspeed: 0.1210s/iter; left time: 10515.0306s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1124790\n",
      "\tspeed: 0.1212s/iter; left time: 10526.3648s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1241191\n",
      "\tspeed: 0.1232s/iter; left time: 10686.1925s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1247699\n",
      "\tspeed: 0.1221s/iter; left time: 10572.2510s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0854057\n",
      "\tspeed: 0.1210s/iter; left time: 10470.2557s\n",
      "\titers: 3800, epoch: 1 | loss: 0.1014010\n",
      "\tspeed: 0.1222s/iter; left time: 10562.3164s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1316951\n",
      "\tspeed: 0.1201s/iter; left time: 10366.4433s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0942671\n",
      "\tspeed: 0.1087s/iter; left time: 9375.2946s\n",
      "\titers: 4100, epoch: 1 | loss: 0.1327326\n",
      "\tspeed: 0.1293s/iter; left time: 11139.3881s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1209776\n",
      "\tspeed: 0.1252s/iter; left time: 10770.5130s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1077484\n",
      "\tspeed: 0.1233s/iter; left time: 10594.5281s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1512811\n",
      "\tspeed: 0.1229s/iter; left time: 10544.5614s\n",
      "\titers: 4500, epoch: 1 | loss: 0.1018022\n",
      "\tspeed: 0.1213s/iter; left time: 10397.0332s\n",
      "Epoch: 1 cost time: 00h:09m:03.37s\n",
      "Epoch: 1 | Train Loss: 0.1270111 Vali Loss: 0.1236339 Test Loss: 0.1337476\n",
      "Validation loss decreased (inf --> 0.123634).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1009242\n",
      "\tspeed: 1.5534s/iter; left time: 132990.2757s\n",
      "\titers: 200, epoch: 2 | loss: 0.1057041\n",
      "\tspeed: 0.1114s/iter; left time: 9522.9479s\n",
      "\titers: 300, epoch: 2 | loss: 0.1185217\n",
      "\tspeed: 0.1115s/iter; left time: 9526.7328s\n",
      "\titers: 400, epoch: 2 | loss: 0.1260917\n",
      "\tspeed: 0.1112s/iter; left time: 9483.3610s\n",
      "\titers: 500, epoch: 2 | loss: 0.1188102\n",
      "\tspeed: 0.1112s/iter; left time: 9477.7038s\n",
      "\titers: 600, epoch: 2 | loss: 0.1057341\n",
      "\tspeed: 0.1114s/iter; left time: 9477.3420s\n",
      "\titers: 700, epoch: 2 | loss: 0.1103936\n",
      "\tspeed: 0.1154s/iter; left time: 9811.5934s\n",
      "\titers: 800, epoch: 2 | loss: 0.0953739\n",
      "\tspeed: 0.1137s/iter; left time: 9656.8847s\n",
      "\titers: 900, epoch: 2 | loss: 0.1062001\n",
      "\tspeed: 0.1102s/iter; left time: 9344.8809s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1234990\n",
      "\tspeed: 0.1096s/iter; left time: 9282.8273s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1231637\n",
      "\tspeed: 0.1111s/iter; left time: 9404.3912s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1170382\n",
      "\tspeed: 0.1118s/iter; left time: 9447.4824s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1286091\n",
      "\tspeed: 0.1124s/iter; left time: 9484.5818s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1228279\n",
      "\tspeed: 0.1133s/iter; left time: 9553.2399s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1124612\n",
      "\tspeed: 0.1124s/iter; left time: 9468.8217s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1304001\n",
      "\tspeed: 0.1108s/iter; left time: 9317.4496s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0983355\n",
      "\tspeed: 0.1102s/iter; left time: 9255.3658s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1152888\n",
      "\tspeed: 0.1110s/iter; left time: 9315.9443s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1315118\n",
      "\tspeed: 0.1116s/iter; left time: 9349.9798s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1052500\n",
      "\tspeed: 0.1097s/iter; left time: 9185.9278s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1020255\n",
      "\tspeed: 0.1136s/iter; left time: 9501.8940s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1039204\n",
      "\tspeed: 0.1176s/iter; left time: 9818.4630s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1028647\n",
      "\tspeed: 0.1155s/iter; left time: 9630.5011s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0985666\n",
      "\tspeed: 0.1080s/iter; left time: 8997.4802s\n",
      "\titers: 2500, epoch: 2 | loss: 0.1200809\n",
      "\tspeed: 0.1115s/iter; left time: 9281.6355s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0959475\n",
      "\tspeed: 0.1112s/iter; left time: 9244.1100s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1078989\n",
      "\tspeed: 0.1138s/iter; left time: 9447.8890s\n",
      "\titers: 2800, epoch: 2 | loss: 0.1235621\n",
      "\tspeed: 0.1139s/iter; left time: 9442.5432s\n",
      "\titers: 2900, epoch: 2 | loss: 0.1086988\n",
      "\tspeed: 0.1158s/iter; left time: 9589.3067s\n",
      "\titers: 3000, epoch: 2 | loss: 0.1171820\n",
      "\tspeed: 0.1130s/iter; left time: 9347.0067s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1324888\n",
      "\tspeed: 0.1096s/iter; left time: 9054.5902s\n",
      "\titers: 3200, epoch: 2 | loss: 0.1025820\n",
      "\tspeed: 0.1128s/iter; left time: 9304.6021s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1180324\n",
      "\tspeed: 0.1138s/iter; left time: 9380.3068s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0918598\n",
      "\tspeed: 0.1125s/iter; left time: 9256.7677s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1146981\n",
      "\tspeed: 0.1106s/iter; left time: 9090.9371s\n",
      "\titers: 3600, epoch: 2 | loss: 0.1195523\n",
      "\tspeed: 0.1115s/iter; left time: 9154.1052s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1020174\n",
      "\tspeed: 0.1115s/iter; left time: 9147.7188s\n",
      "\titers: 3800, epoch: 2 | loss: 0.1182716\n",
      "\tspeed: 0.1119s/iter; left time: 9162.2010s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1242668\n",
      "\tspeed: 0.1122s/iter; left time: 9181.8504s\n",
      "\titers: 4000, epoch: 2 | loss: 0.1236416\n",
      "\tspeed: 0.1077s/iter; left time: 8804.0315s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0967820\n",
      "\tspeed: 0.1115s/iter; left time: 9100.9551s\n",
      "\titers: 4200, epoch: 2 | loss: 0.1161284\n",
      "\tspeed: 0.1108s/iter; left time: 9028.2388s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1170403\n",
      "\tspeed: 0.1110s/iter; left time: 9037.9990s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1146400\n",
      "\tspeed: 0.1083s/iter; left time: 8804.1387s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1269809\n",
      "\tspeed: 0.1147s/iter; left time: 9311.0995s\n",
      "Epoch: 2 cost time: 00h:08m:25.18s\n",
      "Epoch: 2 | Train Loss: 0.1137483 Vali Loss: 0.1211819 Test Loss: 0.1314770\n",
      "Validation loss decreased (0.123634 --> 0.121182).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1091224\n",
      "\tspeed: 1.3353s/iter; left time: 108290.6712s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142174\n",
      "\tspeed: 0.1119s/iter; left time: 9061.4115s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922338\n",
      "\tspeed: 0.1146s/iter; left time: 9270.5313s\n",
      "\titers: 400, epoch: 3 | loss: 0.1037165\n",
      "\tspeed: 0.1132s/iter; left time: 9150.0245s\n",
      "\titers: 500, epoch: 3 | loss: 0.1166515\n",
      "\tspeed: 0.0972s/iter; left time: 7847.4097s\n",
      "\titers: 600, epoch: 3 | loss: 0.1462486\n",
      "\tspeed: 0.1054s/iter; left time: 8497.1017s\n",
      "\titers: 700, epoch: 3 | loss: 0.0942422\n",
      "\tspeed: 0.1112s/iter; left time: 8948.3195s\n",
      "\titers: 800, epoch: 3 | loss: 0.1011169\n",
      "\tspeed: 0.1110s/iter; left time: 8928.2488s\n",
      "\titers: 900, epoch: 3 | loss: 0.0979650\n",
      "\tspeed: 0.1077s/iter; left time: 8648.0503s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1108804\n",
      "\tspeed: 0.1102s/iter; left time: 8835.8422s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1009135\n",
      "\tspeed: 0.1120s/iter; left time: 8974.3380s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1017713\n",
      "\tspeed: 0.1115s/iter; left time: 8923.1230s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0823623\n",
      "\tspeed: 0.1093s/iter; left time: 8735.0669s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1107601\n",
      "\tspeed: 0.1047s/iter; left time: 8354.9177s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1039672\n",
      "\tspeed: 0.0920s/iter; left time: 7330.1272s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1078828\n",
      "\tspeed: 0.1001s/iter; left time: 7968.5507s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1306942\n",
      "\tspeed: 0.1119s/iter; left time: 8892.7021s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1210322\n",
      "\tspeed: 0.1115s/iter; left time: 8854.4364s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1242555\n",
      "\tspeed: 0.1117s/iter; left time: 8854.3315s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1179223\n",
      "\tspeed: 0.1111s/iter; left time: 8799.8074s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0980783\n",
      "\tspeed: 0.0949s/iter; left time: 7508.6786s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0831775\n",
      "\tspeed: 0.1014s/iter; left time: 8010.2395s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1181071\n",
      "\tspeed: 0.1045s/iter; left time: 8247.7745s\n",
      "\titers: 2400, epoch: 3 | loss: 0.1032294\n",
      "\tspeed: 0.1150s/iter; left time: 9060.1275s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0963849\n",
      "\tspeed: 0.1044s/iter; left time: 8212.9088s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0986556\n",
      "\tspeed: 0.1124s/iter; left time: 8837.3751s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1111877\n",
      "\tspeed: 0.1108s/iter; left time: 8701.0274s\n",
      "\titers: 2800, epoch: 3 | loss: 0.1074994\n",
      "\tspeed: 0.1116s/iter; left time: 8751.9818s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1052452\n",
      "\tspeed: 0.1102s/iter; left time: 8631.4159s\n",
      "\titers: 3000, epoch: 3 | loss: 0.1183149\n",
      "\tspeed: 0.1117s/iter; left time: 8738.5796s\n",
      "\titers: 3100, epoch: 3 | loss: 0.1002252\n",
      "\tspeed: 0.1101s/iter; left time: 8600.4927s\n",
      "\titers: 3200, epoch: 3 | loss: 0.1177883\n",
      "\tspeed: 0.1120s/iter; left time: 8736.5244s\n",
      "\titers: 3300, epoch: 3 | loss: 0.1205603\n",
      "\tspeed: 0.1112s/iter; left time: 8665.9640s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0869977\n",
      "\tspeed: 0.1078s/iter; left time: 8384.2680s\n",
      "\titers: 3500, epoch: 3 | loss: 0.1050737\n",
      "\tspeed: 0.1093s/iter; left time: 8495.3829s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1078355\n",
      "\tspeed: 0.1109s/iter; left time: 8603.4192s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0906262\n",
      "\tspeed: 0.1105s/iter; left time: 8566.8240s\n",
      "\titers: 3800, epoch: 3 | loss: 0.1110627\n",
      "\tspeed: 0.0965s/iter; left time: 7472.3680s\n",
      "\titers: 3900, epoch: 3 | loss: 0.1002521\n",
      "\tspeed: 0.0969s/iter; left time: 7490.3745s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1271065\n",
      "\tspeed: 0.1025s/iter; left time: 7912.9695s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0983674\n",
      "\tspeed: 0.1116s/iter; left time: 8603.9610s\n",
      "\titers: 4200, epoch: 3 | loss: 0.1033843\n",
      "\tspeed: 0.1102s/iter; left time: 8482.0349s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0996929\n",
      "\tspeed: 0.1085s/iter; left time: 8342.9289s\n",
      "\titers: 4400, epoch: 3 | loss: 0.1311404\n",
      "\tspeed: 0.1118s/iter; left time: 8585.6200s\n",
      "\titers: 4500, epoch: 3 | loss: 0.1287858\n",
      "\tspeed: 0.1141s/iter; left time: 8748.6234s\n",
      "Epoch: 3 cost time: 00h:08m:08.32s\n",
      "Epoch: 3 | Train Loss: 0.1110772 Vali Loss: 0.1201832 Test Loss: 0.1312127\n",
      "Validation loss decreased (0.121182 --> 0.120183).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.1042797\n",
      "\tspeed: 1.3493s/iter; left time: 103342.3703s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056520\n",
      "\tspeed: 0.1036s/iter; left time: 7923.4705s\n",
      "\titers: 300, epoch: 4 | loss: 0.1407721\n",
      "\tspeed: 0.0996s/iter; left time: 7607.6507s\n",
      "\titers: 400, epoch: 4 | loss: 0.1103993\n",
      "\tspeed: 0.0932s/iter; left time: 7108.4724s\n",
      "\titers: 500, epoch: 4 | loss: 0.1333401\n",
      "\tspeed: 0.0970s/iter; left time: 7393.3500s\n",
      "\titers: 600, epoch: 4 | loss: 0.0823804\n",
      "\tspeed: 0.1115s/iter; left time: 8482.9587s\n",
      "\titers: 700, epoch: 4 | loss: 0.1071542\n",
      "\tspeed: 0.1029s/iter; left time: 7817.3178s\n",
      "\titers: 800, epoch: 4 | loss: 0.0928916\n",
      "\tspeed: 0.1118s/iter; left time: 8485.5466s\n",
      "\titers: 900, epoch: 4 | loss: 0.1312938\n",
      "\tspeed: 0.1114s/iter; left time: 8442.1039s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1126999\n",
      "\tspeed: 0.1113s/iter; left time: 8420.4250s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1022324\n",
      "\tspeed: 0.1114s/iter; left time: 8417.0294s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1187319\n",
      "\tspeed: 0.1076s/iter; left time: 8123.8158s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0963174\n",
      "\tspeed: 0.1124s/iter; left time: 8476.8857s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1092223\n",
      "\tspeed: 0.1111s/iter; left time: 8362.4493s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1354816\n",
      "\tspeed: 0.1102s/iter; left time: 8282.0060s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1099921\n",
      "\tspeed: 0.1096s/iter; left time: 8233.1143s\n",
      "\titers: 1700, epoch: 4 | loss: 0.1108850\n",
      "\tspeed: 0.1092s/iter; left time: 8192.1458s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1127623\n",
      "\tspeed: 0.1111s/iter; left time: 8322.6001s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1139171\n",
      "\tspeed: 0.1101s/iter; left time: 8235.3026s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0908916\n",
      "\tspeed: 0.1049s/iter; left time: 7837.2941s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1114629\n",
      "\tspeed: 0.1111s/iter; left time: 8286.8075s\n",
      "\titers: 2200, epoch: 4 | loss: 0.1177699\n",
      "\tspeed: 0.1110s/iter; left time: 8264.5557s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1413989\n",
      "\tspeed: 0.1114s/iter; left time: 8289.1713s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1044007\n",
      "\tspeed: 0.1111s/iter; left time: 8254.3422s\n",
      "\titers: 2500, epoch: 4 | loss: 0.1082040\n",
      "\tspeed: 0.1081s/iter; left time: 8018.0813s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0923625\n",
      "\tspeed: 0.1083s/iter; left time: 8021.4768s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1065988\n",
      "\tspeed: 0.1120s/iter; left time: 8284.4990s\n",
      "\titers: 2800, epoch: 4 | loss: 0.1006237\n",
      "\tspeed: 0.1116s/iter; left time: 8249.0357s\n",
      "\titers: 2900, epoch: 4 | loss: 0.1046341\n",
      "\tspeed: 0.1098s/iter; left time: 8104.5208s\n",
      "\titers: 3000, epoch: 4 | loss: 0.1012314\n",
      "\tspeed: 0.1092s/iter; left time: 8048.4366s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1112245\n",
      "\tspeed: 0.1112s/iter; left time: 8180.7375s\n",
      "\titers: 3200, epoch: 4 | loss: 0.1350303\n",
      "\tspeed: 0.1073s/iter; left time: 7884.2879s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0992441\n",
      "\tspeed: 0.1090s/iter; left time: 7996.2000s\n",
      "\titers: 3400, epoch: 4 | loss: 0.1210128\n",
      "\tspeed: 0.1072s/iter; left time: 7857.5412s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0917098\n",
      "\tspeed: 0.1131s/iter; left time: 8280.2859s\n",
      "\titers: 3600, epoch: 4 | loss: 0.1238096\n",
      "\tspeed: 0.1116s/iter; left time: 8153.8129s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1106423\n",
      "\tspeed: 0.1054s/iter; left time: 7689.7355s\n",
      "\titers: 3800, epoch: 4 | loss: 0.1008025\n",
      "\tspeed: 0.1073s/iter; left time: 7817.2431s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0933059\n",
      "\tspeed: 0.1111s/iter; left time: 8087.3552s\n",
      "\titers: 4000, epoch: 4 | loss: 0.1097155\n",
      "\tspeed: 0.1113s/iter; left time: 8086.9294s\n",
      "\titers: 4100, epoch: 4 | loss: 0.1064074\n",
      "\tspeed: 0.1080s/iter; left time: 7843.0043s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1110331\n",
      "\tspeed: 0.1068s/iter; left time: 7740.8173s\n",
      "\titers: 4300, epoch: 4 | loss: 0.1224657\n",
      "\tspeed: 0.1109s/iter; left time: 8025.5329s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1246324\n",
      "\tspeed: 0.1114s/iter; left time: 8054.9475s\n",
      "\titers: 4500, epoch: 4 | loss: 0.1105620\n",
      "\tspeed: 0.1082s/iter; left time: 7808.5807s\n",
      "Epoch: 4 cost time: 00h:08m:11.08s\n",
      "Epoch: 4 | Train Loss: 0.1091497 Vali Loss: 0.1206590 Test Loss: 0.1314602\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1278306\n",
      "\tspeed: 1.3172s/iter; left time: 94938.8159s\n",
      "\titers: 200, epoch: 5 | loss: 0.1344272\n",
      "\tspeed: 0.1115s/iter; left time: 8021.9657s\n",
      "\titers: 300, epoch: 5 | loss: 0.1116924\n",
      "\tspeed: 0.1045s/iter; left time: 7512.8750s\n",
      "\titers: 400, epoch: 5 | loss: 0.1037850\n",
      "\tspeed: 0.1021s/iter; left time: 7330.0227s\n",
      "\titers: 500, epoch: 5 | loss: 0.1070122\n",
      "\tspeed: 0.1105s/iter; left time: 7923.8181s\n",
      "\titers: 600, epoch: 5 | loss: 0.1067583\n",
      "\tspeed: 0.1112s/iter; left time: 7956.8873s\n",
      "\titers: 700, epoch: 5 | loss: 0.1108850\n",
      "\tspeed: 0.1111s/iter; left time: 7938.2219s\n",
      "\titers: 800, epoch: 5 | loss: 0.1325466\n",
      "\tspeed: 0.1105s/iter; left time: 7889.9310s\n",
      "\titers: 900, epoch: 5 | loss: 0.0944456\n",
      "\tspeed: 0.1109s/iter; left time: 7901.9460s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1015191\n",
      "\tspeed: 0.1107s/iter; left time: 7880.8296s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0933877\n",
      "\tspeed: 0.1104s/iter; left time: 7846.8047s\n",
      "\titers: 1200, epoch: 5 | loss: 0.1011759\n",
      "\tspeed: 0.1117s/iter; left time: 7925.3508s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1277377\n",
      "\tspeed: 0.1125s/iter; left time: 7970.7834s\n",
      "\titers: 1400, epoch: 5 | loss: 0.1255704\n",
      "\tspeed: 0.1059s/iter; left time: 7493.2115s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0911993\n",
      "\tspeed: 0.1124s/iter; left time: 7941.9597s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0986524\n",
      "\tspeed: 0.1091s/iter; left time: 7699.9614s\n",
      "\titers: 1700, epoch: 5 | loss: 0.1005029\n",
      "\tspeed: 0.1125s/iter; left time: 7928.7818s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1201659\n",
      "\tspeed: 0.1136s/iter; left time: 7995.2048s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0900617\n",
      "\tspeed: 0.1101s/iter; left time: 7736.3992s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1091730\n",
      "\tspeed: 0.1117s/iter; left time: 7839.9291s\n",
      "\titers: 2100, epoch: 5 | loss: 0.1365012\n",
      "\tspeed: 0.1126s/iter; left time: 7893.6360s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1245609\n",
      "\tspeed: 0.1113s/iter; left time: 7786.9198s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0878520\n",
      "\tspeed: 0.1082s/iter; left time: 7561.1675s\n",
      "\titers: 2400, epoch: 5 | loss: 0.1005398\n",
      "\tspeed: 0.1140s/iter; left time: 7953.4179s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1092527\n",
      "\tspeed: 0.1117s/iter; left time: 7784.0860s\n",
      "\titers: 2600, epoch: 5 | loss: 0.1305871\n",
      "\tspeed: 0.1094s/iter; left time: 7615.1127s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1185364\n",
      "\tspeed: 0.1116s/iter; left time: 7756.0020s\n",
      "\titers: 2800, epoch: 5 | loss: 0.1066365\n",
      "\tspeed: 0.1087s/iter; left time: 7544.3490s\n",
      "\titers: 2900, epoch: 5 | loss: 0.1218786\n",
      "\tspeed: 0.1131s/iter; left time: 7834.2489s\n",
      "\titers: 3000, epoch: 5 | loss: 0.1017481\n",
      "\tspeed: 0.1123s/iter; left time: 7769.4070s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0969404\n",
      "\tspeed: 0.1130s/iter; left time: 7808.0454s\n",
      "\titers: 3200, epoch: 5 | loss: 0.1167624\n",
      "\tspeed: 0.1113s/iter; left time: 7677.5230s\n",
      "\titers: 3300, epoch: 5 | loss: 0.1082488\n",
      "\tspeed: 0.1117s/iter; left time: 7693.0673s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1070683\n",
      "\tspeed: 0.1112s/iter; left time: 7649.4996s\n",
      "\titers: 3500, epoch: 5 | loss: 0.1007745\n",
      "\tspeed: 0.1077s/iter; left time: 7396.7585s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1218815\n",
      "\tspeed: 0.1128s/iter; left time: 7735.1226s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0932596\n",
      "\tspeed: 0.1120s/iter; left time: 7668.4920s\n",
      "\titers: 3800, epoch: 5 | loss: 0.1025150\n",
      "\tspeed: 0.1115s/iter; left time: 7625.9858s\n",
      "\titers: 3900, epoch: 5 | loss: 0.1271201\n",
      "\tspeed: 0.1114s/iter; left time: 7605.2856s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0902995\n",
      "\tspeed: 0.1110s/iter; left time: 7566.2282s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0927681\n",
      "\tspeed: 0.1129s/iter; left time: 7687.2390s\n",
      "\titers: 4200, epoch: 5 | loss: 0.1083952\n",
      "\tspeed: 0.1125s/iter; left time: 7647.5964s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0965324\n",
      "\tspeed: 0.1111s/iter; left time: 7537.8980s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1218192\n",
      "\tspeed: 0.1084s/iter; left time: 7348.9534s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0958504\n",
      "\tspeed: 0.0964s/iter; left time: 6521.4454s\n",
      "Epoch: 5 cost time: 00h:08m:18.51s\n",
      "Epoch: 5 | Train Loss: 0.1073548 Vali Loss: 0.1210494 Test Loss: 0.1315029\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0900402\n",
      "\tspeed: 1.3155s/iter; left time: 88882.8421s\n",
      "\titers: 200, epoch: 6 | loss: 0.1219658\n",
      "\tspeed: 0.1112s/iter; left time: 7502.2939s\n",
      "\titers: 300, epoch: 6 | loss: 0.1018782\n",
      "\tspeed: 0.1120s/iter; left time: 7546.3211s\n",
      "\titers: 400, epoch: 6 | loss: 0.0899999\n",
      "\tspeed: 0.1119s/iter; left time: 7524.7017s\n",
      "\titers: 500, epoch: 6 | loss: 0.0865835\n",
      "\tspeed: 0.1117s/iter; left time: 7500.4433s\n",
      "\titers: 600, epoch: 6 | loss: 0.1024893\n",
      "\tspeed: 0.1080s/iter; left time: 7243.4297s\n",
      "\titers: 700, epoch: 6 | loss: 0.1185382\n",
      "\tspeed: 0.1079s/iter; left time: 7225.1369s\n",
      "\titers: 800, epoch: 6 | loss: 0.0937191\n",
      "\tspeed: 0.1117s/iter; left time: 7465.7572s\n",
      "\titers: 900, epoch: 6 | loss: 0.1053254\n",
      "\tspeed: 0.1113s/iter; left time: 7433.8599s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1052254\n",
      "\tspeed: 0.1070s/iter; left time: 7134.3120s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0887852\n",
      "\tspeed: 0.1119s/iter; left time: 7445.9425s\n",
      "\titers: 1200, epoch: 6 | loss: 0.1183097\n",
      "\tspeed: 0.1120s/iter; left time: 7445.5412s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1087360\n",
      "\tspeed: 0.1095s/iter; left time: 7265.3724s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1243429\n",
      "\tspeed: 0.1093s/iter; left time: 7241.8984s\n",
      "\titers: 1500, epoch: 6 | loss: 0.1048982\n",
      "\tspeed: 0.1118s/iter; left time: 7398.4491s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0954086\n",
      "\tspeed: 0.1083s/iter; left time: 7154.1791s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1216552\n",
      "\tspeed: 0.1100s/iter; left time: 7258.6372s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0940970\n",
      "\tspeed: 0.1137s/iter; left time: 7486.2639s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0945160\n",
      "\tspeed: 0.1107s/iter; left time: 7278.7249s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1027974\n",
      "\tspeed: 0.1037s/iter; left time: 6809.9345s\n",
      "\titers: 2100, epoch: 6 | loss: 0.1124428\n",
      "\tspeed: 0.1101s/iter; left time: 7220.4437s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0986440\n",
      "\tspeed: 0.1113s/iter; left time: 7286.5340s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0934314\n",
      "\tspeed: 0.1080s/iter; left time: 7056.3581s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1121407\n",
      "\tspeed: 0.1118s/iter; left time: 7298.3072s\n",
      "\titers: 2500, epoch: 6 | loss: 0.1089153\n",
      "\tspeed: 0.1109s/iter; left time: 7224.6136s\n",
      "\titers: 2600, epoch: 6 | loss: 0.1122545\n",
      "\tspeed: 0.1056s/iter; left time: 6868.8576s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1032276\n",
      "\tspeed: 0.1107s/iter; left time: 7188.5076s\n",
      "\titers: 2800, epoch: 6 | loss: 0.1033332\n",
      "\tspeed: 0.1112s/iter; left time: 7215.1535s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0876504\n",
      "\tspeed: 0.1047s/iter; left time: 6783.3757s\n",
      "\titers: 3000, epoch: 6 | loss: 0.1368348\n",
      "\tspeed: 0.1104s/iter; left time: 7137.3645s\n",
      "\titers: 3100, epoch: 6 | loss: 0.1351932\n",
      "\tspeed: 0.1115s/iter; left time: 7197.8693s\n",
      "\titers: 3200, epoch: 6 | loss: 0.1066472\n",
      "\tspeed: 0.1106s/iter; left time: 7128.2898s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0860064\n",
      "\tspeed: 0.1084s/iter; left time: 6974.1049s\n",
      "\titers: 3400, epoch: 6 | loss: 0.1179315\n",
      "\tspeed: 0.1143s/iter; left time: 7343.4575s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0984892\n",
      "\tspeed: 0.1115s/iter; left time: 7155.9102s\n",
      "\titers: 3600, epoch: 6 | loss: 0.1034916\n",
      "\tspeed: 0.1099s/iter; left time: 7038.2549s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1142480\n",
      "\tspeed: 0.1102s/iter; left time: 7050.4469s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0835040\n",
      "\tspeed: 0.1128s/iter; left time: 7203.2653s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0990066\n",
      "\tspeed: 0.1101s/iter; left time: 7018.5121s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0809600\n",
      "\tspeed: 0.1079s/iter; left time: 6871.6037s\n",
      "\titers: 4100, epoch: 6 | loss: 0.1140766\n",
      "\tspeed: 0.1014s/iter; left time: 6445.7214s\n",
      "\titers: 4200, epoch: 6 | loss: 0.1205836\n",
      "\tspeed: 0.1114s/iter; left time: 7068.9696s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0969326\n",
      "\tspeed: 0.1048s/iter; left time: 6643.5517s\n",
      "\titers: 4400, epoch: 6 | loss: 0.1204569\n",
      "\tspeed: 0.1104s/iter; left time: 6983.1039s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0747524\n",
      "\tspeed: 0.1091s/iter; left time: 6892.7307s\n",
      "Epoch: 6 cost time: 00h:08m:15.98s\n",
      "Epoch: 6 | Train Loss: 0.1057336 Vali Loss: 0.1211823 Test Loss: 0.1336998\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.1101310\n",
      "\tspeed: 1.3190s/iter; left time: 83166.8536s\n",
      "\titers: 200, epoch: 7 | loss: 0.1032939\n",
      "\tspeed: 0.1112s/iter; left time: 6997.7219s\n",
      "\titers: 300, epoch: 7 | loss: 0.0892303\n",
      "\tspeed: 0.1110s/iter; left time: 6976.4312s\n",
      "\titers: 400, epoch: 7 | loss: 0.1038580\n",
      "\tspeed: 0.1099s/iter; left time: 6894.5102s\n",
      "\titers: 500, epoch: 7 | loss: 0.1017524\n",
      "\tspeed: 0.1099s/iter; left time: 6887.6219s\n",
      "\titers: 600, epoch: 7 | loss: 0.1079972\n",
      "\tspeed: 0.1016s/iter; left time: 6354.0905s\n",
      "\titers: 700, epoch: 7 | loss: 0.1230778\n",
      "\tspeed: 0.1101s/iter; left time: 6878.5831s\n",
      "\titers: 800, epoch: 7 | loss: 0.1089498\n",
      "\tspeed: 0.1131s/iter; left time: 7054.0806s\n",
      "\titers: 900, epoch: 7 | loss: 0.0847800\n",
      "\tspeed: 0.1140s/iter; left time: 7097.2786s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0966783\n",
      "\tspeed: 0.1100s/iter; left time: 6837.0666s\n",
      "\titers: 1100, epoch: 7 | loss: 0.1018307\n",
      "\tspeed: 0.1027s/iter; left time: 6372.3367s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1135214\n",
      "\tspeed: 0.1110s/iter; left time: 6874.8757s\n",
      "\titers: 1300, epoch: 7 | loss: 0.1157592\n",
      "\tspeed: 0.1103s/iter; left time: 6822.2027s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1310228\n",
      "\tspeed: 0.0962s/iter; left time: 5938.5182s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1148699\n",
      "\tspeed: 0.1108s/iter; left time: 6829.4099s\n",
      "\titers: 1600, epoch: 7 | loss: 0.1188787\n",
      "\tspeed: 0.1099s/iter; left time: 6762.2288s\n",
      "\titers: 1700, epoch: 7 | loss: 0.1201685\n",
      "\tspeed: 0.1066s/iter; left time: 6549.5705s\n",
      "\titers: 1800, epoch: 7 | loss: 0.1034473\n",
      "\tspeed: 0.0919s/iter; left time: 5636.0731s\n",
      "\titers: 1900, epoch: 7 | loss: 0.1318231\n",
      "\tspeed: 0.1109s/iter; left time: 6790.8165s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1103886\n",
      "\tspeed: 0.1081s/iter; left time: 6611.4581s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0762963\n",
      "\tspeed: 0.0980s/iter; left time: 5983.6823s\n",
      "\titers: 2200, epoch: 7 | loss: 0.1041776\n",
      "\tspeed: 0.1112s/iter; left time: 6777.2801s\n",
      "\titers: 2300, epoch: 7 | loss: 0.1331106\n",
      "\tspeed: 0.1111s/iter; left time: 6763.4535s\n",
      "\titers: 2400, epoch: 7 | loss: 0.1217078\n",
      "\tspeed: 0.1107s/iter; left time: 6726.0236s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1019260\n",
      "\tspeed: 0.1029s/iter; left time: 6240.0359s\n",
      "\titers: 2600, epoch: 7 | loss: 0.1089509\n",
      "\tspeed: 0.1118s/iter; left time: 6768.6213s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0711737\n",
      "\tspeed: 0.1102s/iter; left time: 6662.0349s\n",
      "\titers: 2800, epoch: 7 | loss: 0.1113131\n",
      "\tspeed: 0.1054s/iter; left time: 6360.9076s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0903740\n",
      "\tspeed: 0.1108s/iter; left time: 6678.4426s\n",
      "\titers: 3000, epoch: 7 | loss: 0.1105986\n",
      "\tspeed: 0.1117s/iter; left time: 6721.4345s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1091367\n",
      "\tspeed: 0.1101s/iter; left time: 6613.4604s\n",
      "\titers: 3200, epoch: 7 | loss: 0.1005980\n",
      "\tspeed: 0.1079s/iter; left time: 6470.7893s\n",
      "\titers: 3300, epoch: 7 | loss: 0.1091531\n",
      "\tspeed: 0.1123s/iter; left time: 6719.0840s\n",
      "\titers: 3400, epoch: 7 | loss: 0.1115669\n",
      "\tspeed: 0.1103s/iter; left time: 6592.5185s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0937440\n",
      "\tspeed: 0.1109s/iter; left time: 6616.4669s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0866776\n",
      "\tspeed: 0.1075s/iter; left time: 6403.4945s\n",
      "\titers: 3700, epoch: 7 | loss: 0.1017955\n",
      "\tspeed: 0.1108s/iter; left time: 6587.7622s\n",
      "\titers: 3800, epoch: 7 | loss: 0.1092188\n",
      "\tspeed: 0.1067s/iter; left time: 6334.6985s\n",
      "\titers: 3900, epoch: 7 | loss: 0.1045642\n",
      "\tspeed: 0.1067s/iter; left time: 6324.5073s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0942638\n",
      "\tspeed: 0.1107s/iter; left time: 6545.7806s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0964783\n",
      "\tspeed: 0.1107s/iter; left time: 6537.6761s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0998325\n",
      "\tspeed: 0.1082s/iter; left time: 6376.9945s\n",
      "\titers: 4300, epoch: 7 | loss: 0.1168764\n",
      "\tspeed: 0.1108s/iter; left time: 6521.4900s\n",
      "\titers: 4400, epoch: 7 | loss: 0.1004882\n",
      "\tspeed: 0.1104s/iter; left time: 6485.0501s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1068878\n",
      "\tspeed: 0.1083s/iter; left time: 6351.5684s\n",
      "Epoch: 7 cost time: 00h:08m:09.92s\n",
      "Epoch: 7 | Train Loss: 0.1041142 Vali Loss: 0.1216008 Test Loss: 0.1335807\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.1064242\n",
      "\tspeed: 1.3153s/iter; left time: 77003.5612s\n",
      "\titers: 200, epoch: 8 | loss: 0.0962368\n",
      "\tspeed: 0.1108s/iter; left time: 6477.0061s\n",
      "\titers: 300, epoch: 8 | loss: 0.0928213\n",
      "\tspeed: 0.1126s/iter; left time: 6569.5973s\n",
      "\titers: 400, epoch: 8 | loss: 0.0943208\n",
      "\tspeed: 0.1100s/iter; left time: 6404.4626s\n",
      "\titers: 500, epoch: 8 | loss: 0.0816987\n",
      "\tspeed: 0.1098s/iter; left time: 6381.9598s\n",
      "\titers: 600, epoch: 8 | loss: 0.0994938\n",
      "\tspeed: 0.1049s/iter; left time: 6091.5720s\n",
      "\titers: 700, epoch: 8 | loss: 0.1381244\n",
      "\tspeed: 0.1084s/iter; left time: 6283.7603s\n",
      "\titers: 800, epoch: 8 | loss: 0.0890225\n",
      "\tspeed: 0.1118s/iter; left time: 6466.6292s\n",
      "\titers: 900, epoch: 8 | loss: 0.0877501\n",
      "\tspeed: 0.1084s/iter; left time: 6260.6316s\n",
      "\titers: 1000, epoch: 8 | loss: 0.1082633\n",
      "\tspeed: 0.1133s/iter; left time: 6530.6678s\n",
      "\titers: 1100, epoch: 8 | loss: 0.1030926\n",
      "\tspeed: 0.1106s/iter; left time: 6365.4243s\n",
      "\titers: 1200, epoch: 8 | loss: 0.1108039\n",
      "\tspeed: 0.1097s/iter; left time: 6303.2463s\n",
      "\titers: 1300, epoch: 8 | loss: 0.1025215\n",
      "\tspeed: 0.1113s/iter; left time: 6383.6879s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0918347\n",
      "\tspeed: 0.1072s/iter; left time: 6138.2687s\n",
      "\titers: 1500, epoch: 8 | loss: 0.1050971\n",
      "\tspeed: 0.0933s/iter; left time: 5329.4269s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0993232\n",
      "\tspeed: 0.1035s/iter; left time: 5904.9177s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0785634\n",
      "\tspeed: 0.0976s/iter; left time: 5555.4186s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1135773\n",
      "\tspeed: 0.1096s/iter; left time: 6232.3795s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1094371\n",
      "\tspeed: 0.1094s/iter; left time: 6210.1545s\n",
      "\titers: 2000, epoch: 8 | loss: 0.1042004\n",
      "\tspeed: 0.1100s/iter; left time: 6229.6752s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0882604\n",
      "\tspeed: 0.1108s/iter; left time: 6267.1689s\n",
      "\titers: 2200, epoch: 8 | loss: 0.1012275\n",
      "\tspeed: 0.1118s/iter; left time: 6307.6623s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0945900\n",
      "\tspeed: 0.1111s/iter; left time: 6262.2349s\n",
      "\titers: 2400, epoch: 8 | loss: 0.1020221\n",
      "\tspeed: 0.1054s/iter; left time: 5928.8493s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0925161\n",
      "\tspeed: 0.1119s/iter; left time: 6281.4044s\n",
      "\titers: 2600, epoch: 8 | loss: 0.1061964\n",
      "\tspeed: 0.1016s/iter; left time: 5695.8285s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0998022\n",
      "\tspeed: 0.1101s/iter; left time: 6161.4914s\n",
      "\titers: 2800, epoch: 8 | loss: 0.1082182\n",
      "\tspeed: 0.1094s/iter; left time: 6108.8939s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0990991\n",
      "\tspeed: 0.1110s/iter; left time: 6189.5872s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0922022\n",
      "\tspeed: 0.1106s/iter; left time: 6155.5464s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0934881\n",
      "\tspeed: 0.1112s/iter; left time: 6178.5332s\n",
      "\titers: 3200, epoch: 8 | loss: 0.1112761\n",
      "\tspeed: 0.1109s/iter; left time: 6150.2074s\n",
      "\titers: 3300, epoch: 8 | loss: 0.1168728\n",
      "\tspeed: 0.1111s/iter; left time: 6150.0261s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1108771\n",
      "\tspeed: 0.1113s/iter; left time: 6149.6467s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0973692\n",
      "\tspeed: 0.1092s/iter; left time: 6020.5202s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0976076\n",
      "\tspeed: 0.1127s/iter; left time: 6205.3477s\n",
      "\titers: 3700, epoch: 8 | loss: 0.1008535\n",
      "\tspeed: 0.1138s/iter; left time: 6252.2141s\n",
      "\titers: 3800, epoch: 8 | loss: 0.1109234\n",
      "\tspeed: 0.1092s/iter; left time: 5986.5106s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0982573\n",
      "\tspeed: 0.1101s/iter; left time: 6028.0259s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0945133\n",
      "\tspeed: 0.1109s/iter; left time: 6062.1295s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0894407\n",
      "\tspeed: 0.1095s/iter; left time: 5974.6725s\n",
      "\titers: 4200, epoch: 8 | loss: 0.1341557\n",
      "\tspeed: 0.1073s/iter; left time: 5841.1604s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0909306\n",
      "\tspeed: 0.1031s/iter; left time: 5600.4143s\n",
      "\titers: 4400, epoch: 8 | loss: 0.1254242\n",
      "\tspeed: 0.1060s/iter; left time: 5749.7534s\n",
      "\titers: 4500, epoch: 8 | loss: 0.1086129\n",
      "\tspeed: 0.1098s/iter; left time: 5946.1556s\n",
      "Epoch: 8 cost time: 00h:08m:11.74s\n",
      "Epoch: 8 | Train Loss: 0.1026479 Vali Loss: 0.1232067 Test Loss: 0.1338327\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.03904155269265175, rmse:0.19758935272693634, mae:0.1312127262353897, rse:0.6996963024139404\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 96: 01h:24m:32.04s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "train 144005\n",
      "val 30365\n",
      "test 30365\n",
      "[2024-11-06 10:47:40,976] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 10:47:42,001] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 10:47:42,001] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 10:47:42,001] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 10:47:42,104] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 10:47:42,104] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 10:47:42,786] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 10:47:42,787] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 10:47:42,788] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 10:47:42,789] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 10:47:42,789] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 10:47:42,789] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 10:47:42,790] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 10:47:42,790] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 10:47:42,790] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 10:47:42,790] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 10:47:43,097] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 10:47:43,098] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 10:47:43,098] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 291.4 GB, percent = 38.6%\n",
      "[2024-11-06 10:47:43,215] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 10:47:43,216] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 10:47:43,216] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 291.4 GB, percent = 38.6%\n",
      "[2024-11-06 10:47:43,216] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 10:47:43,332] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 10:47:43,333] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 10:47:43,333] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 291.4 GB, percent = 38.6%\n",
      "[2024-11-06 10:47:43,334] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 10:47:43,334] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 10:47:43,334] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 10:47:43,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdf308ace50>\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 10:47:43,335] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 10:47:43,336] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 10:47:43,337] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1722415\n",
      "\tspeed: 0.1610s/iter; left time: 14476.2815s\n",
      "\titers: 200, epoch: 1 | loss: 0.1642618\n",
      "\tspeed: 0.1222s/iter; left time: 10973.4634s\n",
      "\titers: 300, epoch: 1 | loss: 0.1699650\n",
      "\tspeed: 0.1225s/iter; left time: 10988.3199s\n",
      "\titers: 400, epoch: 1 | loss: 0.1528437\n",
      "\tspeed: 0.1213s/iter; left time: 10871.1974s\n",
      "\titers: 500, epoch: 1 | loss: 0.1800710\n",
      "\tspeed: 0.1228s/iter; left time: 10993.4439s\n",
      "\titers: 600, epoch: 1 | loss: 0.1444045\n",
      "\tspeed: 0.1209s/iter; left time: 10811.8827s\n",
      "\titers: 700, epoch: 1 | loss: 0.1550112\n",
      "\tspeed: 0.1232s/iter; left time: 10998.8426s\n",
      "\titers: 800, epoch: 1 | loss: 0.1617060\n",
      "\tspeed: 0.1217s/iter; left time: 10854.5036s\n",
      "\titers: 900, epoch: 1 | loss: 0.1370434\n",
      "\tspeed: 0.1136s/iter; left time: 10120.4921s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1275058\n",
      "\tspeed: 0.1221s/iter; left time: 10863.3526s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1449558\n",
      "\tspeed: 0.1157s/iter; left time: 10282.0601s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1349236\n",
      "\tspeed: 0.1154s/iter; left time: 10245.7905s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1274116\n",
      "\tspeed: 0.1219s/iter; left time: 10808.7808s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1198728\n",
      "\tspeed: 0.1134s/iter; left time: 10043.6194s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1442495\n",
      "\tspeed: 0.1209s/iter; left time: 10701.2084s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1276560\n",
      "\tspeed: 0.1212s/iter; left time: 10713.0075s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1118672\n",
      "\tspeed: 0.1224s/iter; left time: 10809.7639s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1303812\n",
      "\tspeed: 0.1209s/iter; left time: 10660.6910s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1282517\n",
      "\tspeed: 0.1192s/iter; left time: 10497.3482s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1508993\n",
      "\tspeed: 0.1214s/iter; left time: 10681.2293s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1233600\n",
      "\tspeed: 0.1208s/iter; left time: 10622.8300s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1314864\n",
      "\tspeed: 0.1216s/iter; left time: 10675.5301s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1428589\n",
      "\tspeed: 0.1232s/iter; left time: 10801.0582s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1158170\n",
      "\tspeed: 0.1228s/iter; left time: 10758.7566s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1396438\n",
      "\tspeed: 0.1186s/iter; left time: 10375.8601s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0997480\n",
      "\tspeed: 0.1187s/iter; left time: 10374.9318s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1249997\n",
      "\tspeed: 0.1251s/iter; left time: 10922.0380s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1422246\n",
      "\tspeed: 0.1228s/iter; left time: 10706.6441s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1353679\n",
      "\tspeed: 0.1204s/iter; left time: 10487.9495s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1307514\n",
      "\tspeed: 0.1057s/iter; left time: 9199.2705s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0962288\n",
      "\tspeed: 0.1025s/iter; left time: 8906.5078s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1293473\n",
      "\tspeed: 0.1102s/iter; left time: 9564.3280s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1202497\n",
      "\tspeed: 0.1209s/iter; left time: 10484.1904s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1410805\n",
      "\tspeed: 0.1193s/iter; left time: 10335.6879s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1205750\n",
      "\tspeed: 0.1238s/iter; left time: 10707.1751s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1357457\n",
      "\tspeed: 0.1210s/iter; left time: 10454.8435s\n",
      "\titers: 3700, epoch: 1 | loss: 0.1340248\n",
      "\tspeed: 0.1130s/iter; left time: 9755.7329s\n",
      "\titers: 3800, epoch: 1 | loss: 0.1190062\n",
      "\tspeed: 0.1202s/iter; left time: 10363.1850s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1086311\n",
      "\tspeed: 0.1211s/iter; left time: 10427.2966s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1070195\n",
      "\tspeed: 0.1226s/iter; left time: 10540.8399s\n",
      "\titers: 4100, epoch: 1 | loss: 0.1272726\n",
      "\tspeed: 0.1196s/iter; left time: 10277.9133s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1223125\n",
      "\tspeed: 0.1206s/iter; left time: 10349.9496s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1125679\n",
      "\tspeed: 0.1210s/iter; left time: 10371.5038s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1199078\n",
      "\tspeed: 0.1211s/iter; left time: 10363.8922s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0987593\n",
      "\tspeed: 0.1221s/iter; left time: 10443.5742s\n",
      "Epoch: 1 cost time: 00h:08m:59.44s\n",
      "Epoch: 1 | Train Loss: 0.1351953 Vali Loss: 0.1273992 Test Loss: 0.1383202\n",
      "Validation loss decreased (inf --> 0.127399).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1084077\n",
      "\tspeed: 1.5058s/iter; left time: 128597.1904s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188691\n",
      "\tspeed: 0.1099s/iter; left time: 9376.2850s\n",
      "\titers: 300, epoch: 2 | loss: 0.1166971\n",
      "\tspeed: 0.1083s/iter; left time: 9228.1074s\n",
      "\titers: 400, epoch: 2 | loss: 0.1344358\n",
      "\tspeed: 0.1136s/iter; left time: 9667.1856s\n",
      "\titers: 500, epoch: 2 | loss: 0.1114889\n",
      "\tspeed: 0.1130s/iter; left time: 9608.6275s\n",
      "\titers: 600, epoch: 2 | loss: 0.1289746\n",
      "\tspeed: 0.1112s/iter; left time: 9438.8855s\n",
      "\titers: 700, epoch: 2 | loss: 0.1312989\n",
      "\tspeed: 0.1061s/iter; left time: 9001.2756s\n",
      "\titers: 800, epoch: 2 | loss: 0.1233555\n",
      "\tspeed: 0.1058s/iter; left time: 8962.8716s\n",
      "\titers: 900, epoch: 2 | loss: 0.1222342\n",
      "\tspeed: 0.1060s/iter; left time: 8969.7328s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1095940\n",
      "\tspeed: 0.1096s/iter; left time: 9261.4563s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1145786\n",
      "\tspeed: 0.1120s/iter; left time: 9453.2849s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0870770\n",
      "\tspeed: 0.1065s/iter; left time: 8978.0755s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1247500\n",
      "\tspeed: 0.1066s/iter; left time: 8976.9103s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1330883\n",
      "\tspeed: 0.1066s/iter; left time: 8964.5453s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1174180\n",
      "\tspeed: 0.1062s/iter; left time: 8924.4678s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1083247\n",
      "\tspeed: 0.1114s/iter; left time: 9349.4686s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0954072\n",
      "\tspeed: 0.1094s/iter; left time: 9171.8298s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1029514\n",
      "\tspeed: 0.1055s/iter; left time: 8830.7903s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1247388\n",
      "\tspeed: 0.1097s/iter; left time: 9167.0050s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1260362\n",
      "\tspeed: 0.1110s/iter; left time: 9271.4375s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1320552\n",
      "\tspeed: 0.1109s/iter; left time: 9252.3734s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1196680\n",
      "\tspeed: 0.1111s/iter; left time: 9254.8385s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1158860\n",
      "\tspeed: 0.1106s/iter; left time: 9202.6149s\n",
      "\titers: 2400, epoch: 2 | loss: 0.1317002\n",
      "\tspeed: 0.1058s/iter; left time: 8793.0211s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0968062\n",
      "\tspeed: 0.0963s/iter; left time: 7991.4986s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1376942\n",
      "\tspeed: 0.1095s/iter; left time: 9077.7718s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1336712\n",
      "\tspeed: 0.1104s/iter; left time: 9138.5608s\n",
      "\titers: 2800, epoch: 2 | loss: 0.1042031\n",
      "\tspeed: 0.1130s/iter; left time: 9345.4565s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0988843\n",
      "\tspeed: 0.1107s/iter; left time: 9141.7582s\n",
      "\titers: 3000, epoch: 2 | loss: 0.1411492\n",
      "\tspeed: 0.1079s/iter; left time: 8897.7380s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1144881\n",
      "\tspeed: 0.1087s/iter; left time: 8957.8275s\n",
      "\titers: 3200, epoch: 2 | loss: 0.1128290\n",
      "\tspeed: 0.1096s/iter; left time: 9022.1762s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0995621\n",
      "\tspeed: 0.1121s/iter; left time: 9214.6189s\n",
      "\titers: 3400, epoch: 2 | loss: 0.1062561\n",
      "\tspeed: 0.1042s/iter; left time: 8553.4239s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1157053\n",
      "\tspeed: 0.1068s/iter; left time: 8756.9434s\n",
      "\titers: 3600, epoch: 2 | loss: 0.1428359\n",
      "\tspeed: 0.1101s/iter; left time: 9018.7591s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1292468\n",
      "\tspeed: 0.1118s/iter; left time: 9147.9506s\n",
      "\titers: 3800, epoch: 2 | loss: 0.1134887\n",
      "\tspeed: 0.1102s/iter; left time: 9005.4797s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1094005\n",
      "\tspeed: 0.1016s/iter; left time: 8289.4074s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0889020\n",
      "\tspeed: 0.1106s/iter; left time: 9012.6974s\n",
      "\titers: 4100, epoch: 2 | loss: 0.1122976\n",
      "\tspeed: 0.1087s/iter; left time: 8848.0676s\n",
      "\titers: 4200, epoch: 2 | loss: 0.1154312\n",
      "\tspeed: 0.1089s/iter; left time: 8853.7683s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1136244\n",
      "\tspeed: 0.1110s/iter; left time: 9015.7921s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1491479\n",
      "\tspeed: 0.1112s/iter; left time: 9018.6597s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1123121\n",
      "\tspeed: 0.1098s/iter; left time: 8894.5964s\n",
      "Epoch: 2 cost time: 00h:08m:10.24s\n",
      "Epoch: 2 | Train Loss: 0.1194911 Vali Loss: 0.1267481 Test Loss: 0.1388662\n",
      "Validation loss decreased (0.127399 --> 0.126748).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1152794\n",
      "\tspeed: 1.3007s/iter; left time: 105225.1873s\n",
      "\titers: 200, epoch: 3 | loss: 0.1132694\n",
      "\tspeed: 0.1081s/iter; left time: 8735.1020s\n",
      "\titers: 300, epoch: 3 | loss: 0.1202083\n",
      "\tspeed: 0.1108s/iter; left time: 8938.6144s\n",
      "\titers: 400, epoch: 3 | loss: 0.1244078\n",
      "\tspeed: 0.1086s/iter; left time: 8750.1191s\n",
      "\titers: 500, epoch: 3 | loss: 0.1394506\n",
      "\tspeed: 0.1052s/iter; left time: 8469.3838s\n",
      "\titers: 600, epoch: 3 | loss: 0.1321715\n",
      "\tspeed: 0.1031s/iter; left time: 8288.8017s\n",
      "\titers: 700, epoch: 3 | loss: 0.1367380\n",
      "\tspeed: 0.1066s/iter; left time: 8560.2232s\n",
      "\titers: 800, epoch: 3 | loss: 0.1014106\n",
      "\tspeed: 0.1050s/iter; left time: 8421.5773s\n",
      "\titers: 900, epoch: 3 | loss: 0.1309359\n",
      "\tspeed: 0.1038s/iter; left time: 8314.3021s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1215169\n",
      "\tspeed: 0.1093s/iter; left time: 8747.9422s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1186935\n",
      "\tspeed: 0.1087s/iter; left time: 8687.8244s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1138864\n",
      "\tspeed: 0.1074s/iter; left time: 8571.8953s\n",
      "\titers: 1300, epoch: 3 | loss: 0.1232129\n",
      "\tspeed: 0.1057s/iter; left time: 8426.5188s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1215336\n",
      "\tspeed: 0.1087s/iter; left time: 8655.2408s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1075348\n",
      "\tspeed: 0.1053s/iter; left time: 8368.2474s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0998350\n",
      "\tspeed: 0.1032s/iter; left time: 8191.1067s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1194682\n",
      "\tspeed: 0.1088s/iter; left time: 8625.6956s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0960436\n",
      "\tspeed: 0.1108s/iter; left time: 8776.5357s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1164640\n",
      "\tspeed: 0.1067s/iter; left time: 8442.8276s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1188581\n",
      "\tspeed: 0.1047s/iter; left time: 8267.6731s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1064454\n",
      "\tspeed: 0.1074s/iter; left time: 8474.0870s\n",
      "\titers: 2200, epoch: 3 | loss: 0.1026932\n",
      "\tspeed: 0.1063s/iter; left time: 8376.0936s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1318141\n",
      "\tspeed: 0.1115s/iter; left time: 8778.1043s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0956509\n",
      "\tspeed: 0.1067s/iter; left time: 8389.2349s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1198354\n",
      "\tspeed: 0.1085s/iter; left time: 8516.1464s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1160894\n",
      "\tspeed: 0.1110s/iter; left time: 8699.9192s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1454285\n",
      "\tspeed: 0.1061s/iter; left time: 8308.3330s\n",
      "\titers: 2800, epoch: 3 | loss: 0.1207652\n",
      "\tspeed: 0.1096s/iter; left time: 8568.8149s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1268008\n",
      "\tspeed: 0.1045s/iter; left time: 8158.3527s\n",
      "\titers: 3000, epoch: 3 | loss: 0.1190474\n",
      "\tspeed: 0.0945s/iter; left time: 7374.4546s\n",
      "\titers: 3100, epoch: 3 | loss: 0.1022481\n",
      "\tspeed: 0.0917s/iter; left time: 7146.1108s\n",
      "\titers: 3200, epoch: 3 | loss: 0.1200595\n",
      "\tspeed: 0.0921s/iter; left time: 7167.8505s\n",
      "\titers: 3300, epoch: 3 | loss: 0.1058474\n",
      "\tspeed: 0.1051s/iter; left time: 8167.4699s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0970815\n",
      "\tspeed: 0.1090s/iter; left time: 8462.1528s\n",
      "\titers: 3500, epoch: 3 | loss: 0.1004426\n",
      "\tspeed: 0.1067s/iter; left time: 8270.4941s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1149215\n",
      "\tspeed: 0.1118s/iter; left time: 8653.3815s\n",
      "\titers: 3700, epoch: 3 | loss: 0.1141373\n",
      "\tspeed: 0.1074s/iter; left time: 8305.5869s\n",
      "\titers: 3800, epoch: 3 | loss: 0.1077497\n",
      "\tspeed: 0.1097s/iter; left time: 8471.2825s\n",
      "\titers: 3900, epoch: 3 | loss: 0.1131194\n",
      "\tspeed: 0.1097s/iter; left time: 8455.3016s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1044435\n",
      "\tspeed: 0.1080s/iter; left time: 8315.9301s\n",
      "\titers: 4100, epoch: 3 | loss: 0.1126936\n",
      "\tspeed: 0.1120s/iter; left time: 8609.1835s\n",
      "\titers: 4200, epoch: 3 | loss: 0.1067826\n",
      "\tspeed: 0.1109s/iter; left time: 8513.8455s\n",
      "\titers: 4300, epoch: 3 | loss: 0.1324570\n",
      "\tspeed: 0.1055s/iter; left time: 8089.4657s\n",
      "\titers: 4400, epoch: 3 | loss: 0.1183501\n",
      "\tspeed: 0.1057s/iter; left time: 8096.8442s\n",
      "\titers: 4500, epoch: 3 | loss: 0.1193333\n",
      "\tspeed: 0.1040s/iter; left time: 7952.6196s\n",
      "Epoch: 3 cost time: 00h:07m:59.15s\n",
      "Epoch: 3 | Train Loss: 0.1166655 Vali Loss: 0.1260640 Test Loss: 0.1401359\n",
      "Validation loss decreased (0.126748 --> 0.126064).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.1125568\n",
      "\tspeed: 1.4163s/iter; left time: 108209.0417s\n",
      "\titers: 200, epoch: 4 | loss: 0.1210395\n",
      "\tspeed: 0.1061s/iter; left time: 8092.8295s\n",
      "\titers: 300, epoch: 4 | loss: 0.1450989\n",
      "\tspeed: 0.1100s/iter; left time: 8378.8780s\n",
      "\titers: 400, epoch: 4 | loss: 0.1028652\n",
      "\tspeed: 0.1078s/iter; left time: 8205.7783s\n",
      "\titers: 500, epoch: 4 | loss: 0.1227606\n",
      "\tspeed: 0.1091s/iter; left time: 8291.5524s\n",
      "\titers: 600, epoch: 4 | loss: 0.1142834\n",
      "\tspeed: 0.1089s/iter; left time: 8266.2406s\n",
      "\titers: 700, epoch: 4 | loss: 0.1134773\n",
      "\tspeed: 0.1056s/iter; left time: 8005.5078s\n",
      "\titers: 800, epoch: 4 | loss: 0.1166338\n",
      "\tspeed: 0.1100s/iter; left time: 8324.2892s\n",
      "\titers: 900, epoch: 4 | loss: 0.1060759\n",
      "\tspeed: 0.1072s/iter; left time: 8104.5875s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1013023\n",
      "\tspeed: 0.1110s/iter; left time: 8376.9821s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1202505\n",
      "\tspeed: 0.1103s/iter; left time: 8315.4332s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1454062\n",
      "\tspeed: 0.1055s/iter; left time: 7940.6763s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0899547\n",
      "\tspeed: 0.1091s/iter; left time: 8202.6529s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1238946\n",
      "\tspeed: 0.1063s/iter; left time: 7980.5953s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1506326\n",
      "\tspeed: 0.1051s/iter; left time: 7885.2437s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1163052\n",
      "\tspeed: 0.1075s/iter; left time: 8048.3574s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0916244\n",
      "\tspeed: 0.1065s/iter; left time: 7968.0227s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1198172\n",
      "\tspeed: 0.1010s/iter; left time: 7547.2220s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1116062\n",
      "\tspeed: 0.1027s/iter; left time: 7662.7739s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1201215\n",
      "\tspeed: 0.1051s/iter; left time: 7828.2600s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1293983\n",
      "\tspeed: 0.1052s/iter; left time: 7824.4040s\n",
      "\titers: 2200, epoch: 4 | loss: 0.1130875\n",
      "\tspeed: 0.1063s/iter; left time: 7898.9695s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0896851\n",
      "\tspeed: 0.1090s/iter; left time: 8088.5645s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1101105\n",
      "\tspeed: 0.1029s/iter; left time: 7626.9237s\n",
      "\titers: 2500, epoch: 4 | loss: 0.1109910\n",
      "\tspeed: 0.1045s/iter; left time: 7732.5989s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1057030\n",
      "\tspeed: 0.1106s/iter; left time: 8172.1071s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1136541\n",
      "\tspeed: 0.1084s/iter; left time: 7999.8760s\n",
      "\titers: 2800, epoch: 4 | loss: 0.1251921\n",
      "\tspeed: 0.0993s/iter; left time: 7315.0226s\n",
      "\titers: 2900, epoch: 4 | loss: 0.1238812\n",
      "\tspeed: 0.1065s/iter; left time: 7838.7614s\n",
      "\titers: 3000, epoch: 4 | loss: 0.1382817\n",
      "\tspeed: 0.1097s/iter; left time: 8064.6029s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1169739\n",
      "\tspeed: 0.1103s/iter; left time: 8098.9343s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0927903\n",
      "\tspeed: 0.1058s/iter; left time: 7755.6147s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1339119\n",
      "\tspeed: 0.1032s/iter; left time: 7551.8975s\n",
      "\titers: 3400, epoch: 4 | loss: 0.1292242\n",
      "\tspeed: 0.1114s/iter; left time: 8140.5874s\n",
      "\titers: 3500, epoch: 4 | loss: 0.1444003\n",
      "\tspeed: 0.1093s/iter; left time: 7979.5536s\n",
      "\titers: 3600, epoch: 4 | loss: 0.1164075\n",
      "\tspeed: 0.1097s/iter; left time: 7993.9349s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1059806\n",
      "\tspeed: 0.1088s/iter; left time: 7923.4104s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0982874\n",
      "\tspeed: 0.0924s/iter; left time: 6719.2118s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0951767\n",
      "\tspeed: 0.1042s/iter; left time: 7564.9427s\n",
      "\titers: 4000, epoch: 4 | loss: 0.1140446\n",
      "\tspeed: 0.1001s/iter; left time: 7256.4091s\n",
      "\titers: 4100, epoch: 4 | loss: 0.1023741\n",
      "\tspeed: 0.1108s/iter; left time: 8021.0013s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1307331\n",
      "\tspeed: 0.1095s/iter; left time: 7920.3673s\n",
      "\titers: 4300, epoch: 4 | loss: 0.1040721\n",
      "\tspeed: 0.1028s/iter; left time: 7421.5885s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1119575\n",
      "\tspeed: 0.1093s/iter; left time: 7879.7135s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0985629\n",
      "\tspeed: 0.1084s/iter; left time: 7804.1815s\n",
      "Epoch: 4 cost time: 00h:08m:00.35s\n",
      "Epoch: 4 | Train Loss: 0.1148035 Vali Loss: 0.1252003 Test Loss: 0.1392046\n",
      "Validation loss decreased (0.126064 --> 0.125200).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0907658\n",
      "\tspeed: 1.3272s/iter; left time: 95429.3168s\n",
      "\titers: 200, epoch: 5 | loss: 0.1343750\n",
      "\tspeed: 0.1110s/iter; left time: 7973.4095s\n",
      "\titers: 300, epoch: 5 | loss: 0.1243243\n",
      "\tspeed: 0.1157s/iter; left time: 8297.5357s\n",
      "\titers: 400, epoch: 5 | loss: 0.1421808\n",
      "\tspeed: 0.1153s/iter; left time: 8252.7796s\n",
      "\titers: 500, epoch: 5 | loss: 0.1330000\n",
      "\tspeed: 0.1101s/iter; left time: 7872.9645s\n",
      "\titers: 600, epoch: 5 | loss: 0.1217416\n",
      "\tspeed: 0.1138s/iter; left time: 8122.5964s\n",
      "\titers: 700, epoch: 5 | loss: 0.1248774\n",
      "\tspeed: 0.1163s/iter; left time: 8295.0067s\n",
      "\titers: 800, epoch: 5 | loss: 0.0885512\n",
      "\tspeed: 0.1158s/iter; left time: 8245.3300s\n",
      "\titers: 900, epoch: 5 | loss: 0.1137830\n",
      "\tspeed: 0.1151s/iter; left time: 8181.2589s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1336963\n",
      "\tspeed: 0.1158s/iter; left time: 8222.2037s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1149920\n",
      "\tspeed: 0.1165s/iter; left time: 8257.8578s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0966749\n",
      "\tspeed: 0.1092s/iter; left time: 7733.1701s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1019445\n",
      "\tspeed: 0.1137s/iter; left time: 8037.2688s\n",
      "\titers: 1400, epoch: 5 | loss: 0.1182597\n",
      "\tspeed: 0.1106s/iter; left time: 7808.2132s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1009388\n",
      "\tspeed: 0.1173s/iter; left time: 8269.3876s\n",
      "\titers: 1600, epoch: 5 | loss: 0.1242714\n",
      "\tspeed: 0.1149s/iter; left time: 8088.9267s\n",
      "\titers: 1700, epoch: 5 | loss: 0.1016557\n",
      "\tspeed: 0.1147s/iter; left time: 8065.4658s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1111512\n",
      "\tspeed: 0.1179s/iter; left time: 8278.1999s\n",
      "\titers: 1900, epoch: 5 | loss: 0.1181145\n",
      "\tspeed: 0.1063s/iter; left time: 7452.9108s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1182202\n",
      "\tspeed: 0.1107s/iter; left time: 7748.1597s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0988766\n",
      "\tspeed: 0.1136s/iter; left time: 7938.0359s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1196963\n",
      "\tspeed: 0.1117s/iter; left time: 7797.6842s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0957005\n",
      "\tspeed: 0.1059s/iter; left time: 7378.7399s\n",
      "\titers: 2400, epoch: 5 | loss: 0.1196866\n",
      "\tspeed: 0.0911s/iter; left time: 6343.9878s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1057772\n",
      "\tspeed: 0.1124s/iter; left time: 7808.6247s\n",
      "\titers: 2600, epoch: 5 | loss: 0.1100306\n",
      "\tspeed: 0.1063s/iter; left time: 7379.3963s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1448901\n",
      "\tspeed: 0.1071s/iter; left time: 7423.0480s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0977376\n",
      "\tspeed: 0.1073s/iter; left time: 7424.9614s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0915652\n",
      "\tspeed: 0.1078s/iter; left time: 7448.9051s\n",
      "\titers: 3000, epoch: 5 | loss: 0.1317347\n",
      "\tspeed: 0.1097s/iter; left time: 7569.3716s\n",
      "\titers: 3100, epoch: 5 | loss: 0.1361701\n",
      "\tspeed: 0.1045s/iter; left time: 7199.7448s\n",
      "\titers: 3200, epoch: 5 | loss: 0.1048190\n",
      "\tspeed: 0.1084s/iter; left time: 7455.3423s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0887955\n",
      "\tspeed: 0.1048s/iter; left time: 7199.9639s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1372217\n",
      "\tspeed: 0.1050s/iter; left time: 7202.4565s\n",
      "\titers: 3500, epoch: 5 | loss: 0.1090420\n",
      "\tspeed: 0.1059s/iter; left time: 7254.6782s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1038527\n",
      "\tspeed: 0.1047s/iter; left time: 7163.5751s\n",
      "\titers: 3700, epoch: 5 | loss: 0.1343446\n",
      "\tspeed: 0.1082s/iter; left time: 7391.1597s\n",
      "\titers: 3800, epoch: 5 | loss: 0.1144945\n",
      "\tspeed: 0.1092s/iter; left time: 7448.9815s\n",
      "\titers: 3900, epoch: 5 | loss: 0.1039714\n",
      "\tspeed: 0.1084s/iter; left time: 7381.6457s\n",
      "\titers: 4000, epoch: 5 | loss: 0.1094740\n",
      "\tspeed: 0.1096s/iter; left time: 7455.0174s\n",
      "\titers: 4100, epoch: 5 | loss: 0.1005118\n",
      "\tspeed: 0.1109s/iter; left time: 7530.7117s\n",
      "\titers: 4200, epoch: 5 | loss: 0.1217957\n",
      "\tspeed: 0.1085s/iter; left time: 7353.4960s\n",
      "\titers: 4300, epoch: 5 | loss: 0.1162514\n",
      "\tspeed: 0.1106s/iter; left time: 7489.1097s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1052956\n",
      "\tspeed: 0.1070s/iter; left time: 7236.3638s\n",
      "\titers: 4500, epoch: 5 | loss: 0.1183951\n",
      "\tspeed: 0.1039s/iter; left time: 7016.0191s\n",
      "Epoch: 5 cost time: 00h:08m:15.75s\n",
      "Epoch: 5 | Train Loss: 0.1130147 Vali Loss: 0.1256293 Test Loss: 0.1388998\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0920280\n",
      "\tspeed: 1.2921s/iter; left time: 87088.9125s\n",
      "\titers: 200, epoch: 6 | loss: 0.1041093\n",
      "\tspeed: 0.1078s/iter; left time: 7257.4108s\n",
      "\titers: 300, epoch: 6 | loss: 0.1251121\n",
      "\tspeed: 0.1092s/iter; left time: 7335.5771s\n",
      "\titers: 400, epoch: 6 | loss: 0.1292235\n",
      "\tspeed: 0.1062s/iter; left time: 7124.5489s\n",
      "\titers: 500, epoch: 6 | loss: 0.1325414\n",
      "\tspeed: 0.1076s/iter; left time: 7211.5130s\n",
      "\titers: 600, epoch: 6 | loss: 0.1175012\n",
      "\tspeed: 0.1044s/iter; left time: 6981.9272s\n",
      "\titers: 700, epoch: 6 | loss: 0.1163051\n",
      "\tspeed: 0.1080s/iter; left time: 7215.8643s\n",
      "\titers: 800, epoch: 6 | loss: 0.1351548\n",
      "\tspeed: 0.1106s/iter; left time: 7380.1012s\n",
      "\titers: 900, epoch: 6 | loss: 0.1225425\n",
      "\tspeed: 0.1132s/iter; left time: 7536.1584s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1036254\n",
      "\tspeed: 0.1090s/iter; left time: 7248.2146s\n",
      "\titers: 1100, epoch: 6 | loss: 0.1094563\n",
      "\tspeed: 0.1058s/iter; left time: 7028.0771s\n",
      "\titers: 1200, epoch: 6 | loss: 0.1084416\n",
      "\tspeed: 0.1124s/iter; left time: 7452.1911s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1197710\n",
      "\tspeed: 0.1113s/iter; left time: 7371.0527s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0988175\n",
      "\tspeed: 0.1058s/iter; left time: 6996.3813s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0918562\n",
      "\tspeed: 0.1052s/iter; left time: 6946.2690s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0927158\n",
      "\tspeed: 0.1112s/iter; left time: 7325.5276s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1155516\n",
      "\tspeed: 0.1112s/iter; left time: 7317.9628s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0867080\n",
      "\tspeed: 0.1039s/iter; left time: 6828.3752s\n",
      "\titers: 1900, epoch: 6 | loss: 0.1018271\n",
      "\tspeed: 0.1075s/iter; left time: 7049.8370s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1079376\n",
      "\tspeed: 0.1086s/iter; left time: 7114.9818s\n",
      "\titers: 2100, epoch: 6 | loss: 0.1051775\n",
      "\tspeed: 0.1001s/iter; left time: 6543.6162s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0940556\n",
      "\tspeed: 0.1058s/iter; left time: 6909.4556s\n",
      "\titers: 2300, epoch: 6 | loss: 0.1276548\n",
      "\tspeed: 0.1048s/iter; left time: 6834.1317s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1021224\n",
      "\tspeed: 0.1055s/iter; left time: 6870.1281s\n",
      "\titers: 2500, epoch: 6 | loss: 0.1202948\n",
      "\tspeed: 0.1093s/iter; left time: 7102.2311s\n",
      "\titers: 2600, epoch: 6 | loss: 0.1169518\n",
      "\tspeed: 0.1056s/iter; left time: 6852.3784s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1243710\n",
      "\tspeed: 0.1060s/iter; left time: 6866.0374s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0901274\n",
      "\tspeed: 0.1078s/iter; left time: 6974.3993s\n",
      "\titers: 2900, epoch: 6 | loss: 0.1054002\n",
      "\tspeed: 0.1032s/iter; left time: 6663.8438s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0982051\n",
      "\tspeed: 0.1054s/iter; left time: 6799.5326s\n",
      "\titers: 3100, epoch: 6 | loss: 0.1149904\n",
      "\tspeed: 0.1062s/iter; left time: 6839.0701s\n",
      "\titers: 3200, epoch: 6 | loss: 0.1179913\n",
      "\tspeed: 0.1111s/iter; left time: 7141.7769s\n",
      "\titers: 3300, epoch: 6 | loss: 0.1101077\n",
      "\tspeed: 0.1082s/iter; left time: 6947.0031s\n",
      "\titers: 3400, epoch: 6 | loss: 0.1344147\n",
      "\tspeed: 0.1093s/iter; left time: 7005.1119s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1310049\n",
      "\tspeed: 0.1116s/iter; left time: 7144.9284s\n",
      "\titers: 3600, epoch: 6 | loss: 0.1063819\n",
      "\tspeed: 0.1146s/iter; left time: 7320.8256s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1139405\n",
      "\tspeed: 0.1158s/iter; left time: 7385.7578s\n",
      "\titers: 3800, epoch: 6 | loss: 0.1090242\n",
      "\tspeed: 0.1103s/iter; left time: 7025.9594s\n",
      "\titers: 3900, epoch: 6 | loss: 0.1023996\n",
      "\tspeed: 0.1150s/iter; left time: 7313.1207s\n",
      "\titers: 4000, epoch: 6 | loss: 0.1178793\n",
      "\tspeed: 0.1087s/iter; left time: 6901.9117s\n",
      "\titers: 4100, epoch: 6 | loss: 0.1196957\n",
      "\tspeed: 0.1073s/iter; left time: 6800.4484s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0903106\n",
      "\tspeed: 0.1108s/iter; left time: 7012.2191s\n",
      "\titers: 4300, epoch: 6 | loss: 0.1157856\n",
      "\tspeed: 0.1133s/iter; left time: 7162.9276s\n",
      "\titers: 4400, epoch: 6 | loss: 0.1040285\n",
      "\tspeed: 0.1182s/iter; left time: 7460.8443s\n",
      "\titers: 4500, epoch: 6 | loss: 0.1310644\n",
      "\tspeed: 0.1093s/iter; left time: 6887.8306s\n",
      "Epoch: 6 cost time: 00h:08m:09.69s\n",
      "Epoch: 6 | Train Loss: 0.1110409 Vali Loss: 0.1272356 Test Loss: 0.1386201\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0967481\n",
      "\tspeed: 1.3018s/iter; left time: 81885.3954s\n",
      "\titers: 200, epoch: 7 | loss: 0.1081944\n",
      "\tspeed: 0.1044s/iter; left time: 6554.9766s\n",
      "\titers: 300, epoch: 7 | loss: 0.1173374\n",
      "\tspeed: 0.1026s/iter; left time: 6433.8004s\n",
      "\titers: 400, epoch: 7 | loss: 0.1054463\n",
      "\tspeed: 0.1119s/iter; left time: 7006.7533s\n",
      "\titers: 500, epoch: 7 | loss: 0.1216557\n",
      "\tspeed: 0.0968s/iter; left time: 6048.1442s\n",
      "\titers: 600, epoch: 7 | loss: 0.0990924\n",
      "\tspeed: 0.1045s/iter; left time: 6518.7834s\n",
      "\titers: 700, epoch: 7 | loss: 0.1063634\n",
      "\tspeed: 0.1113s/iter; left time: 6936.1484s\n",
      "\titers: 800, epoch: 7 | loss: 0.1169149\n",
      "\tspeed: 0.1108s/iter; left time: 6893.3947s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734943\n",
      "\tspeed: 0.1044s/iter; left time: 6482.9852s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0996156\n",
      "\tspeed: 0.1101s/iter; left time: 6827.9670s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0942176\n",
      "\tspeed: 0.1087s/iter; left time: 6727.6842s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1168764\n",
      "\tspeed: 0.1093s/iter; left time: 6752.8098s\n",
      "\titers: 1300, epoch: 7 | loss: 0.1095600\n",
      "\tspeed: 0.1071s/iter; left time: 6608.9088s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1000446\n",
      "\tspeed: 0.1118s/iter; left time: 6889.4147s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1175430\n",
      "\tspeed: 0.1105s/iter; left time: 6797.9367s\n",
      "\titers: 1600, epoch: 7 | loss: 0.1104315\n",
      "\tspeed: 0.1068s/iter; left time: 6555.0445s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0912106\n",
      "\tspeed: 0.1112s/iter; left time: 6818.7825s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0969796\n",
      "\tspeed: 0.1114s/iter; left time: 6818.9471s\n",
      "\titers: 1900, epoch: 7 | loss: 0.1125553\n",
      "\tspeed: 0.1071s/iter; left time: 6544.8018s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1356782\n",
      "\tspeed: 0.1061s/iter; left time: 6474.4261s\n",
      "\titers: 2100, epoch: 7 | loss: 0.1152926\n",
      "\tspeed: 0.1092s/iter; left time: 6650.3437s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0969959\n",
      "\tspeed: 0.1110s/iter; left time: 6750.5178s\n",
      "\titers: 2300, epoch: 7 | loss: 0.1188093\n",
      "\tspeed: 0.1094s/iter; left time: 6643.6463s\n",
      "\titers: 2400, epoch: 7 | loss: 0.1142673\n",
      "\tspeed: 0.1106s/iter; left time: 6703.9845s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1321736\n",
      "\tspeed: 0.1071s/iter; left time: 6478.0039s\n",
      "\titers: 2600, epoch: 7 | loss: 0.1042083\n",
      "\tspeed: 0.1093s/iter; left time: 6603.7334s\n",
      "\titers: 2700, epoch: 7 | loss: 0.1219658\n",
      "\tspeed: 0.1020s/iter; left time: 6149.6673s\n",
      "\titers: 2800, epoch: 7 | loss: 0.1157163\n",
      "\tspeed: 0.1062s/iter; left time: 6393.3592s\n",
      "\titers: 2900, epoch: 7 | loss: 0.1091734\n",
      "\tspeed: 0.1104s/iter; left time: 6635.7865s\n",
      "\titers: 3000, epoch: 7 | loss: 0.1113467\n",
      "\tspeed: 0.1068s/iter; left time: 6406.5571s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1071882\n",
      "\tspeed: 0.1113s/iter; left time: 6667.9115s\n",
      "\titers: 3200, epoch: 7 | loss: 0.1177865\n",
      "\tspeed: 0.1046s/iter; left time: 6255.8760s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0907694\n",
      "\tspeed: 0.1085s/iter; left time: 6478.5824s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0885952\n",
      "\tspeed: 0.1111s/iter; left time: 6619.3088s\n",
      "\titers: 3500, epoch: 7 | loss: 0.1230001\n",
      "\tspeed: 0.1010s/iter; left time: 6008.0803s\n",
      "\titers: 3600, epoch: 7 | loss: 0.1072841\n",
      "\tspeed: 0.1042s/iter; left time: 6187.6636s\n",
      "\titers: 3700, epoch: 7 | loss: 0.1058028\n",
      "\tspeed: 0.1097s/iter; left time: 6504.4550s\n",
      "\titers: 3800, epoch: 7 | loss: 0.1327357\n",
      "\tspeed: 0.1117s/iter; left time: 6609.9623s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0999363\n",
      "\tspeed: 0.1021s/iter; left time: 6031.8515s\n",
      "\titers: 4000, epoch: 7 | loss: 0.1260516\n",
      "\tspeed: 0.1083s/iter; left time: 6388.6133s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0950159\n",
      "\tspeed: 0.1093s/iter; left time: 6438.3738s\n",
      "\titers: 4200, epoch: 7 | loss: 0.1063101\n",
      "\tspeed: 0.1111s/iter; left time: 6535.3812s\n",
      "\titers: 4300, epoch: 7 | loss: 0.1235141\n",
      "\tspeed: 0.1111s/iter; left time: 6524.0754s\n",
      "\titers: 4400, epoch: 7 | loss: 0.1076555\n",
      "\tspeed: 0.1101s/iter; left time: 6449.1035s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1005226\n",
      "\tspeed: 0.1093s/iter; left time: 6395.7697s\n",
      "Epoch: 7 cost time: 00h:08m:06.80s\n",
      "Epoch: 7 | Train Loss: 0.1092577 Vali Loss: 0.1278738 Test Loss: 0.1392635\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0915715\n",
      "\tspeed: 1.3362s/iter; left time: 78034.1499s\n",
      "\titers: 200, epoch: 8 | loss: 0.1015529\n",
      "\tspeed: 0.1022s/iter; left time: 5958.4717s\n",
      "\titers: 300, epoch: 8 | loss: 0.1132225\n",
      "\tspeed: 0.1050s/iter; left time: 6111.9044s\n",
      "\titers: 400, epoch: 8 | loss: 0.1191496\n",
      "\tspeed: 0.1142s/iter; left time: 6635.6124s\n",
      "\titers: 500, epoch: 8 | loss: 0.1140969\n",
      "\tspeed: 0.1102s/iter; left time: 6391.1153s\n",
      "\titers: 600, epoch: 8 | loss: 0.0999101\n",
      "\tspeed: 0.1059s/iter; left time: 6130.7098s\n",
      "\titers: 700, epoch: 8 | loss: 0.1325841\n",
      "\tspeed: 0.1107s/iter; left time: 6400.4801s\n",
      "\titers: 800, epoch: 8 | loss: 0.0886803\n",
      "\tspeed: 0.1128s/iter; left time: 6507.6597s\n",
      "\titers: 900, epoch: 8 | loss: 0.0920135\n",
      "\tspeed: 0.1133s/iter; left time: 6528.4467s\n",
      "\titers: 1000, epoch: 8 | loss: 0.1150240\n",
      "\tspeed: 0.1055s/iter; left time: 6065.3636s\n",
      "\titers: 1100, epoch: 8 | loss: 0.1149175\n",
      "\tspeed: 0.1129s/iter; left time: 6482.1392s\n",
      "\titers: 1200, epoch: 8 | loss: 0.1123206\n",
      "\tspeed: 0.1156s/iter; left time: 6621.3747s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0861293\n",
      "\tspeed: 0.1106s/iter; left time: 6326.9974s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0992516\n",
      "\tspeed: 0.1134s/iter; left time: 6472.4466s\n",
      "\titers: 1500, epoch: 8 | loss: 0.1066428\n",
      "\tspeed: 0.1113s/iter; left time: 6341.3841s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0990052\n",
      "\tspeed: 0.1121s/iter; left time: 6377.2097s\n",
      "\titers: 1700, epoch: 8 | loss: 0.1087208\n",
      "\tspeed: 0.1108s/iter; left time: 6293.7139s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1042081\n",
      "\tspeed: 0.1120s/iter; left time: 6347.8832s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1161919\n",
      "\tspeed: 0.1109s/iter; left time: 6276.6993s\n",
      "\titers: 2000, epoch: 8 | loss: 0.1235313\n",
      "\tspeed: 0.1092s/iter; left time: 6172.1969s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0890368\n",
      "\tspeed: 0.1041s/iter; left time: 5869.5764s\n",
      "\titers: 2200, epoch: 8 | loss: 0.1066861\n",
      "\tspeed: 0.1057s/iter; left time: 5950.1633s\n",
      "\titers: 2300, epoch: 8 | loss: 0.1078143\n",
      "\tspeed: 0.0954s/iter; left time: 5360.7158s\n",
      "\titers: 2400, epoch: 8 | loss: 0.1072635\n",
      "\tspeed: 0.1091s/iter; left time: 6118.0266s\n",
      "\titers: 2500, epoch: 8 | loss: 0.1298145\n",
      "\tspeed: 0.1056s/iter; left time: 5913.4536s\n",
      "\titers: 2600, epoch: 8 | loss: 0.1289732\n",
      "\tspeed: 0.1094s/iter; left time: 6115.3659s\n",
      "\titers: 2700, epoch: 8 | loss: 0.1112726\n",
      "\tspeed: 0.1046s/iter; left time: 5837.0522s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0917198\n",
      "\tspeed: 0.1111s/iter; left time: 6189.9905s\n",
      "\titers: 2900, epoch: 8 | loss: 0.1006188\n",
      "\tspeed: 0.1109s/iter; left time: 6165.3910s\n",
      "\titers: 3000, epoch: 8 | loss: 0.1024791\n",
      "\tspeed: 0.1099s/iter; left time: 6101.0955s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0927278\n",
      "\tspeed: 0.1115s/iter; left time: 6175.2678s\n",
      "\titers: 3200, epoch: 8 | loss: 0.1368911\n",
      "\tspeed: 0.1055s/iter; left time: 5835.2369s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0850423\n",
      "\tspeed: 0.1081s/iter; left time: 5968.7487s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1014561\n",
      "\tspeed: 0.1120s/iter; left time: 6168.5601s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0903239\n",
      "\tspeed: 0.1033s/iter; left time: 5684.3003s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0936095\n",
      "\tspeed: 0.1050s/iter; left time: 5763.9552s\n",
      "\titers: 3700, epoch: 8 | loss: 0.1101657\n",
      "\tspeed: 0.1088s/iter; left time: 5964.3943s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0940280\n",
      "\tspeed: 0.1064s/iter; left time: 5822.9149s\n",
      "\titers: 3900, epoch: 8 | loss: 0.1001593\n",
      "\tspeed: 0.1065s/iter; left time: 5817.5410s\n",
      "\titers: 4000, epoch: 8 | loss: 0.1202689\n",
      "\tspeed: 0.1117s/iter; left time: 6090.0684s\n",
      "\titers: 4100, epoch: 8 | loss: 0.1136457\n",
      "\tspeed: 0.1106s/iter; left time: 6015.8366s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0965941\n",
      "\tspeed: 0.1085s/iter; left time: 5893.0271s\n",
      "\titers: 4300, epoch: 8 | loss: 0.1053092\n",
      "\tspeed: 0.1063s/iter; left time: 5762.4168s\n",
      "\titers: 4400, epoch: 8 | loss: 0.1113858\n",
      "\tspeed: 0.1081s/iter; left time: 5848.0211s\n",
      "\titers: 4500, epoch: 8 | loss: 0.1179074\n",
      "\tspeed: 0.1084s/iter; left time: 5855.5451s\n",
      "Epoch: 8 cost time: 00h:08m:09.89s\n",
      "Epoch: 8 | Train Loss: 0.1075180 Vali Loss: 0.1281829 Test Loss: 0.1404810\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.1179711\n",
      "\tspeed: 1.2840s/iter; left time: 69206.6123s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990402\n",
      "\tspeed: 0.1042s/iter; left time: 5606.3605s\n",
      "\titers: 300, epoch: 9 | loss: 0.1027147\n",
      "\tspeed: 0.1025s/iter; left time: 5504.9129s\n",
      "\titers: 400, epoch: 9 | loss: 0.1185157\n",
      "\tspeed: 0.1029s/iter; left time: 5514.2551s\n",
      "\titers: 500, epoch: 9 | loss: 0.1229547\n",
      "\tspeed: 0.1090s/iter; left time: 5829.6514s\n",
      "\titers: 600, epoch: 9 | loss: 0.1194045\n",
      "\tspeed: 0.1076s/iter; left time: 5747.5667s\n",
      "\titers: 700, epoch: 9 | loss: 0.1065733\n",
      "\tspeed: 0.1016s/iter; left time: 5416.2421s\n",
      "\titers: 800, epoch: 9 | loss: 0.1045257\n",
      "\tspeed: 0.1048s/iter; left time: 5576.6915s\n",
      "\titers: 900, epoch: 9 | loss: 0.0848326\n",
      "\tspeed: 0.1088s/iter; left time: 5779.0503s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1070682\n",
      "\tspeed: 0.1041s/iter; left time: 5516.0344s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0933198\n",
      "\tspeed: 0.1079s/iter; left time: 5708.9667s\n",
      "\titers: 1200, epoch: 9 | loss: 0.1060635\n",
      "\tspeed: 0.1091s/iter; left time: 5759.5975s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0956175\n",
      "\tspeed: 0.1120s/iter; left time: 5903.5079s\n",
      "\titers: 1400, epoch: 9 | loss: 0.1284480\n",
      "\tspeed: 0.1078s/iter; left time: 5670.6602s\n",
      "\titers: 1500, epoch: 9 | loss: 0.1109397\n",
      "\tspeed: 0.1064s/iter; left time: 5586.8719s\n",
      "\titers: 1600, epoch: 9 | loss: 0.1253071\n",
      "\tspeed: 0.1024s/iter; left time: 5364.2005s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0952998\n",
      "\tspeed: 0.1088s/iter; left time: 5692.1274s\n",
      "\titers: 1800, epoch: 9 | loss: 0.1029744\n",
      "\tspeed: 0.1027s/iter; left time: 5361.7459s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0986579\n",
      "\tspeed: 0.1026s/iter; left time: 5345.6453s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0940858\n",
      "\tspeed: 0.1024s/iter; left time: 5324.5267s\n",
      "\titers: 2100, epoch: 9 | loss: 0.1204600\n",
      "\tspeed: 0.1035s/iter; left time: 5374.0094s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0905845\n",
      "\tspeed: 0.1069s/iter; left time: 5535.9164s\n",
      "\titers: 2300, epoch: 9 | loss: 0.1081740\n",
      "\tspeed: 0.1076s/iter; left time: 5562.2212s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0876146\n",
      "\tspeed: 0.1041s/iter; left time: 5372.1966s\n",
      "\titers: 2500, epoch: 9 | loss: 0.1088195\n",
      "\tspeed: 0.0989s/iter; left time: 5093.3855s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1196663\n",
      "\tspeed: 0.1095s/iter; left time: 5629.1794s\n",
      "\titers: 2700, epoch: 9 | loss: 0.1050108\n",
      "\tspeed: 0.1068s/iter; left time: 5479.5744s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0979386\n",
      "\tspeed: 0.1032s/iter; left time: 5284.7874s\n",
      "\titers: 2900, epoch: 9 | loss: 0.1122636\n",
      "\tspeed: 0.1060s/iter; left time: 5415.5311s\n",
      "\titers: 3000, epoch: 9 | loss: 0.1013051\n",
      "\tspeed: 0.1075s/iter; left time: 5482.4909s\n",
      "\titers: 3100, epoch: 9 | loss: 0.1260694\n",
      "\tspeed: 0.1083s/iter; left time: 5513.7560s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0981716\n",
      "\tspeed: 0.1098s/iter; left time: 5580.3296s\n",
      "\titers: 3300, epoch: 9 | loss: 0.1029571\n",
      "\tspeed: 0.1063s/iter; left time: 5390.9728s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0932439\n",
      "\tspeed: 0.1083s/iter; left time: 5481.0248s\n",
      "\titers: 3500, epoch: 9 | loss: 0.1111320\n",
      "\tspeed: 0.1121s/iter; left time: 5660.3891s\n",
      "\titers: 3600, epoch: 9 | loss: 0.1148212\n",
      "\tspeed: 0.1103s/iter; left time: 5560.4353s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0873963\n",
      "\tspeed: 0.1087s/iter; left time: 5468.0181s\n",
      "\titers: 3800, epoch: 9 | loss: 0.1219770\n",
      "\tspeed: 0.1092s/iter; left time: 5483.7358s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1065147\n",
      "\tspeed: 0.1106s/iter; left time: 5539.0927s\n",
      "\titers: 4000, epoch: 9 | loss: 0.1031645\n",
      "\tspeed: 0.1074s/iter; left time: 5370.2025s\n",
      "\titers: 4100, epoch: 9 | loss: 0.1122802\n",
      "\tspeed: 0.1023s/iter; left time: 5105.2649s\n",
      "\titers: 4200, epoch: 9 | loss: 0.1096221\n",
      "\tspeed: 0.1100s/iter; left time: 5477.8930s\n",
      "\titers: 4300, epoch: 9 | loss: 0.1044928\n",
      "\tspeed: 0.1034s/iter; left time: 5137.7832s\n",
      "\titers: 4400, epoch: 9 | loss: 0.1005657\n",
      "\tspeed: 0.1052s/iter; left time: 5219.4411s\n",
      "\titers: 4500, epoch: 9 | loss: 0.1307279\n",
      "\tspeed: 0.1059s/iter; left time: 5241.7388s\n",
      "Epoch: 9 cost time: 00h:07m:58.18s\n",
      "Epoch: 9 | Train Loss: 0.1058629 Vali Loss: 0.1313476 Test Loss: 0.1411668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.04313361272215843, rmse:0.20768633484840393, mae:0.13920451700687408, rse:0.7357936501502991\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 168: 01h:33m:40.43s\n",
      "\n",
      "Intermediate time for DE: 05h:51m:54.63s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 144725\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-06 12:21:20,344] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 12:21:21,224] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 12:21:21,224] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 12:21:21,224] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 12:21:21,323] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 12:21:21,323] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 12:21:22,081] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 12:21:22,083] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 12:21:22,083] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 12:21:22,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 12:21:22,085] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 12:21:22,085] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 12:21:22,085] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 12:21:22,085] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 12:21:22,085] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 12:21:22,085] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 12:21:22,430] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 12:21:22,431] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 12:21:22,432] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 299.58 GB, percent = 39.7%\n",
      "[2024-11-06 12:21:22,584] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 12:21:22,586] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 12:21:22,586] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 299.58 GB, percent = 39.7%\n",
      "[2024-11-06 12:21:22,586] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 12:21:22,746] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 12:21:22,747] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 12:21:22,747] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 299.59 GB, percent = 39.7%\n",
      "[2024-11-06 12:21:22,748] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 12:21:22,748] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 12:21:22,748] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 12:21:22,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 12:21:22,749] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2f81a8bd50>\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 12:21:22,750] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 12:21:22,751] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1598667\n",
      "\tspeed: 0.1620s/iter; left time: 14634.9452s\n",
      "\titers: 200, epoch: 1 | loss: 0.1377430\n",
      "\tspeed: 0.1152s/iter; left time: 10396.7740s\n",
      "\titers: 300, epoch: 1 | loss: 0.1681080\n",
      "\tspeed: 0.1191s/iter; left time: 10735.3281s\n",
      "\titers: 400, epoch: 1 | loss: 0.1328889\n",
      "\tspeed: 0.1191s/iter; left time: 10727.1741s\n",
      "\titers: 500, epoch: 1 | loss: 0.1109607\n",
      "\tspeed: 0.1211s/iter; left time: 10891.9444s\n",
      "\titers: 600, epoch: 1 | loss: 0.1043847\n",
      "\tspeed: 0.1179s/iter; left time: 10591.9735s\n",
      "\titers: 700, epoch: 1 | loss: 0.1016743\n",
      "\tspeed: 0.1203s/iter; left time: 10794.6546s\n",
      "\titers: 800, epoch: 1 | loss: 0.1040084\n",
      "\tspeed: 0.1189s/iter; left time: 10661.8157s\n",
      "\titers: 900, epoch: 1 | loss: 0.1079299\n",
      "\tspeed: 0.1180s/iter; left time: 10563.2029s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1005632\n",
      "\tspeed: 0.1138s/iter; left time: 10182.7435s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1033815\n",
      "\tspeed: 0.1222s/iter; left time: 10917.4053s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0799890\n",
      "\tspeed: 0.1166s/iter; left time: 10408.5745s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0838243\n",
      "\tspeed: 0.1190s/iter; left time: 10610.0383s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1020864\n",
      "\tspeed: 0.1144s/iter; left time: 10188.0841s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0848539\n",
      "\tspeed: 0.1205s/iter; left time: 10718.4936s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0838715\n",
      "\tspeed: 0.1182s/iter; left time: 10498.7599s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0974962\n",
      "\tspeed: 0.1095s/iter; left time: 9717.5597s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1318509\n",
      "\tspeed: 0.1107s/iter; left time: 9814.6853s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0946175\n",
      "\tspeed: 0.1155s/iter; left time: 10224.0734s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0932449\n",
      "\tspeed: 0.1145s/iter; left time: 10126.0935s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0996884\n",
      "\tspeed: 0.1214s/iter; left time: 10725.5364s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0934156\n",
      "\tspeed: 0.1128s/iter; left time: 9956.3223s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0972719\n",
      "\tspeed: 0.1171s/iter; left time: 10320.1587s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0774839\n",
      "\tspeed: 0.1189s/iter; left time: 10464.1050s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0788192\n",
      "\tspeed: 0.1194s/iter; left time: 10500.4018s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0745415\n",
      "\tspeed: 0.1163s/iter; left time: 10215.4077s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0826405\n",
      "\tspeed: 0.1141s/iter; left time: 10011.1906s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1033412\n",
      "\tspeed: 0.1186s/iter; left time: 10396.3175s\n",
      "\titers: 2900, epoch: 1 | loss: 0.0918123\n",
      "\tspeed: 0.1173s/iter; left time: 10272.8148s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0841753\n",
      "\tspeed: 0.1167s/iter; left time: 10206.3874s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0921415\n",
      "\tspeed: 0.1167s/iter; left time: 10191.5355s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0949597\n",
      "\tspeed: 0.1142s/iter; left time: 9965.4933s\n",
      "\titers: 3300, epoch: 1 | loss: 0.0930624\n",
      "\tspeed: 0.1150s/iter; left time: 10023.7729s\n",
      "\titers: 3400, epoch: 1 | loss: 0.0858645\n",
      "\tspeed: 0.1120s/iter; left time: 9752.4586s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0943313\n",
      "\tspeed: 0.1159s/iter; left time: 10079.5860s\n",
      "\titers: 3600, epoch: 1 | loss: 0.0909200\n",
      "\tspeed: 0.1120s/iter; left time: 9722.9476s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0663289\n",
      "\tspeed: 0.1122s/iter; left time: 9734.0799s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0831524\n",
      "\tspeed: 0.1169s/iter; left time: 10127.6719s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0844201\n",
      "\tspeed: 0.1173s/iter; left time: 10154.7888s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0823212\n",
      "\tspeed: 0.1167s/iter; left time: 10091.1850s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0958603\n",
      "\tspeed: 0.1129s/iter; left time: 9745.2977s\n",
      "\titers: 4200, epoch: 1 | loss: 0.0909668\n",
      "\tspeed: 0.1130s/iter; left time: 9748.6274s\n",
      "\titers: 4300, epoch: 1 | loss: 0.0935360\n",
      "\tspeed: 0.1112s/iter; left time: 9577.2092s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0754980\n",
      "\tspeed: 0.1205s/iter; left time: 10367.5263s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0896920\n",
      "\tspeed: 0.1149s/iter; left time: 9874.8574s\n",
      "Epoch: 1 cost time: 00h:08m:47.88s\n",
      "Epoch: 1 | Train Loss: 0.1000489 Vali Loss: 0.0938085 Test Loss: 0.1049119\n",
      "Validation loss decreased (inf --> 0.093809).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0694160\n",
      "\tspeed: 1.5632s/iter; left time: 134150.0279s\n",
      "\titers: 200, epoch: 2 | loss: 0.0976587\n",
      "\tspeed: 0.1083s/iter; left time: 9279.5183s\n",
      "\titers: 300, epoch: 2 | loss: 0.0626430\n",
      "\tspeed: 0.1092s/iter; left time: 9348.1355s\n",
      "\titers: 400, epoch: 2 | loss: 0.0859152\n",
      "\tspeed: 0.1083s/iter; left time: 9259.4815s\n",
      "\titers: 500, epoch: 2 | loss: 0.1032414\n",
      "\tspeed: 0.1086s/iter; left time: 9277.3719s\n",
      "\titers: 600, epoch: 2 | loss: 0.0906200\n",
      "\tspeed: 0.1068s/iter; left time: 9112.4256s\n",
      "\titers: 700, epoch: 2 | loss: 0.0978078\n",
      "\tspeed: 0.1089s/iter; left time: 9283.5403s\n",
      "\titers: 800, epoch: 2 | loss: 0.0817296\n",
      "\tspeed: 0.1050s/iter; left time: 8939.0727s\n",
      "\titers: 900, epoch: 2 | loss: 0.0838133\n",
      "\tspeed: 0.1088s/iter; left time: 9252.2186s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0743727\n",
      "\tspeed: 0.1127s/iter; left time: 9574.1567s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0954983\n",
      "\tspeed: 0.1094s/iter; left time: 9280.4751s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0805915\n",
      "\tspeed: 0.1102s/iter; left time: 9334.9481s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0865955\n",
      "\tspeed: 0.1091s/iter; left time: 9230.3039s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0834880\n",
      "\tspeed: 0.1064s/iter; left time: 8996.0734s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0964620\n",
      "\tspeed: 0.1106s/iter; left time: 9338.4898s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0845531\n",
      "\tspeed: 0.1151s/iter; left time: 9703.6194s\n",
      "\titers: 1700, epoch: 2 | loss: 0.1007919\n",
      "\tspeed: 0.1090s/iter; left time: 9177.9059s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0969783\n",
      "\tspeed: 0.1119s/iter; left time: 9415.6950s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0894444\n",
      "\tspeed: 0.1122s/iter; left time: 9424.6893s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0901180\n",
      "\tspeed: 0.1108s/iter; left time: 9295.1783s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0930804\n",
      "\tspeed: 0.1074s/iter; left time: 9005.8119s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0850831\n",
      "\tspeed: 0.1037s/iter; left time: 8684.4504s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0864942\n",
      "\tspeed: 0.1104s/iter; left time: 9230.8312s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0763084\n",
      "\tspeed: 0.1101s/iter; left time: 9196.2918s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0837142\n",
      "\tspeed: 0.1094s/iter; left time: 9123.5830s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0780521\n",
      "\tspeed: 0.1102s/iter; left time: 9178.4125s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0881787\n",
      "\tspeed: 0.1033s/iter; left time: 8596.7542s\n",
      "\titers: 2800, epoch: 2 | loss: 0.1037472\n",
      "\tspeed: 0.1109s/iter; left time: 9220.0779s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0857338\n",
      "\tspeed: 0.1071s/iter; left time: 8893.3612s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0706688\n",
      "\tspeed: 0.1081s/iter; left time: 8965.0748s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0902074\n",
      "\tspeed: 0.1113s/iter; left time: 9220.7158s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0826246\n",
      "\tspeed: 0.1094s/iter; left time: 9050.0306s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0800620\n",
      "\tspeed: 0.1136s/iter; left time: 9389.0204s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0813482\n",
      "\tspeed: 0.1119s/iter; left time: 9231.7893s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0865087\n",
      "\tspeed: 0.1057s/iter; left time: 8710.0879s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0787958\n",
      "\tspeed: 0.1075s/iter; left time: 8845.5213s\n",
      "\titers: 3700, epoch: 2 | loss: 0.0810037\n",
      "\tspeed: 0.1105s/iter; left time: 9081.9435s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0786126\n",
      "\tspeed: 0.1043s/iter; left time: 8565.3033s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0865223\n",
      "\tspeed: 0.1074s/iter; left time: 8805.2456s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0728925\n",
      "\tspeed: 0.1132s/iter; left time: 9270.8200s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0665913\n",
      "\tspeed: 0.1088s/iter; left time: 8902.0829s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0935941\n",
      "\tspeed: 0.1027s/iter; left time: 8393.9441s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0806775\n",
      "\tspeed: 0.1037s/iter; left time: 8460.9730s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0734350\n",
      "\tspeed: 0.1075s/iter; left time: 8766.6595s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0794493\n",
      "\tspeed: 0.1080s/iter; left time: 8793.8673s\n",
      "Epoch: 2 cost time: 00h:08m:11.47s\n",
      "Epoch: 2 | Train Loss: 0.0876393 Vali Loss: 0.0935217 Test Loss: 0.1065775\n",
      "Validation loss decreased (0.093809 --> 0.093522).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0806269\n",
      "\tspeed: 1.3587s/iter; left time: 110462.0516s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804390\n",
      "\tspeed: 0.1064s/iter; left time: 8638.0073s\n",
      "\titers: 300, epoch: 3 | loss: 0.0839080\n",
      "\tspeed: 0.1098s/iter; left time: 8901.2441s\n",
      "\titers: 400, epoch: 3 | loss: 0.0756047\n",
      "\tspeed: 0.1091s/iter; left time: 8839.3711s\n",
      "\titers: 500, epoch: 3 | loss: 0.0861968\n",
      "\tspeed: 0.1071s/iter; left time: 8662.9094s\n",
      "\titers: 600, epoch: 3 | loss: 0.0796431\n",
      "\tspeed: 0.1091s/iter; left time: 8811.0845s\n",
      "\titers: 700, epoch: 3 | loss: 0.0990476\n",
      "\tspeed: 0.1064s/iter; left time: 8589.8120s\n",
      "\titers: 800, epoch: 3 | loss: 0.0783508\n",
      "\tspeed: 0.1102s/iter; left time: 8881.1701s\n",
      "\titers: 900, epoch: 3 | loss: 0.0822550\n",
      "\tspeed: 0.1058s/iter; left time: 8514.3549s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0876101\n",
      "\tspeed: 0.1045s/iter; left time: 8400.6406s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0976478\n",
      "\tspeed: 0.1104s/iter; left time: 8866.4513s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0959653\n",
      "\tspeed: 0.1003s/iter; left time: 8043.6755s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0833485\n",
      "\tspeed: 0.1076s/iter; left time: 8616.6589s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0858261\n",
      "\tspeed: 0.1070s/iter; left time: 8560.9665s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0929304\n",
      "\tspeed: 0.1050s/iter; left time: 8388.9433s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0785439\n",
      "\tspeed: 0.1106s/iter; left time: 8827.3059s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0759937\n",
      "\tspeed: 0.1047s/iter; left time: 8340.3565s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0947664\n",
      "\tspeed: 0.1064s/iter; left time: 8471.2221s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0888601\n",
      "\tspeed: 0.1062s/iter; left time: 8444.3112s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0804047\n",
      "\tspeed: 0.1035s/iter; left time: 8219.5123s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0768411\n",
      "\tspeed: 0.1059s/iter; left time: 8397.7334s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0806046\n",
      "\tspeed: 0.1029s/iter; left time: 8149.1862s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0704709\n",
      "\tspeed: 0.1045s/iter; left time: 8268.3849s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0635164\n",
      "\tspeed: 0.1056s/iter; left time: 8344.1804s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0990984\n",
      "\tspeed: 0.1046s/iter; left time: 8254.1544s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0841963\n",
      "\tspeed: 0.1022s/iter; left time: 8056.6533s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0733169\n",
      "\tspeed: 0.1062s/iter; left time: 8355.6625s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0949243\n",
      "\tspeed: 0.1063s/iter; left time: 8353.8856s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0759923\n",
      "\tspeed: 0.1091s/iter; left time: 8562.7367s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0976739\n",
      "\tspeed: 0.1020s/iter; left time: 7998.3282s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0940530\n",
      "\tspeed: 0.1067s/iter; left time: 8356.4274s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0965124\n",
      "\tspeed: 0.1087s/iter; left time: 8502.9231s\n",
      "\titers: 3300, epoch: 3 | loss: 0.1140829\n",
      "\tspeed: 0.1093s/iter; left time: 8538.6236s\n",
      "\titers: 3400, epoch: 3 | loss: 0.1102706\n",
      "\tspeed: 0.1066s/iter; left time: 8314.3839s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0758671\n",
      "\tspeed: 0.1025s/iter; left time: 7986.3987s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0795737\n",
      "\tspeed: 0.1083s/iter; left time: 8423.2805s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0876436\n",
      "\tspeed: 0.1055s/iter; left time: 8198.9591s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0920245\n",
      "\tspeed: 0.1046s/iter; left time: 8113.2155s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0721030\n",
      "\tspeed: 0.1113s/iter; left time: 8621.5730s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0755090\n",
      "\tspeed: 0.1072s/iter; left time: 8294.7801s\n",
      "\titers: 4100, epoch: 3 | loss: 0.1058423\n",
      "\tspeed: 0.1078s/iter; left time: 8330.4390s\n",
      "\titers: 4200, epoch: 3 | loss: 0.1054360\n",
      "\tspeed: 0.1037s/iter; left time: 8008.4310s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0893770\n",
      "\tspeed: 0.1112s/iter; left time: 8569.8113s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0917597\n",
      "\tspeed: 0.1076s/iter; left time: 8287.9088s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0833671\n",
      "\tspeed: 0.1101s/iter; left time: 8467.9456s\n",
      "Epoch: 3 cost time: 00h:08m:01.96s\n",
      "Epoch: 3 | Train Loss: 0.0858558 Vali Loss: 0.0921783 Test Loss: 0.1050965\n",
      "Validation loss decreased (0.093522 --> 0.092178).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0840183\n",
      "\tspeed: 1.3675s/iter; left time: 104991.8507s\n",
      "\titers: 200, epoch: 4 | loss: 0.0914628\n",
      "\tspeed: 0.1116s/iter; left time: 8554.2095s\n",
      "\titers: 300, epoch: 4 | loss: 0.0916949\n",
      "\tspeed: 0.1082s/iter; left time: 8286.2745s\n",
      "\titers: 400, epoch: 4 | loss: 0.1054805\n",
      "\tspeed: 0.1050s/iter; left time: 8029.6823s\n",
      "\titers: 500, epoch: 4 | loss: 0.0634253\n",
      "\tspeed: 0.0966s/iter; left time: 7378.8805s\n",
      "\titers: 600, epoch: 4 | loss: 0.0834153\n",
      "\tspeed: 0.1020s/iter; left time: 7776.9398s\n",
      "\titers: 700, epoch: 4 | loss: 0.0627734\n",
      "\tspeed: 0.1078s/iter; left time: 8209.1394s\n",
      "\titers: 800, epoch: 4 | loss: 0.1005640\n",
      "\tspeed: 0.1099s/iter; left time: 8359.4527s\n",
      "\titers: 900, epoch: 4 | loss: 0.1035538\n",
      "\tspeed: 0.1109s/iter; left time: 8422.6819s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0953745\n",
      "\tspeed: 0.1102s/iter; left time: 8363.2787s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0773868\n",
      "\tspeed: 0.1082s/iter; left time: 8200.4558s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0715022\n",
      "\tspeed: 0.1065s/iter; left time: 8060.1140s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1035746\n",
      "\tspeed: 0.1118s/iter; left time: 8447.5582s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0568434\n",
      "\tspeed: 0.1123s/iter; left time: 8476.8659s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0613010\n",
      "\tspeed: 0.1022s/iter; left time: 7706.8807s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0871406\n",
      "\tspeed: 0.1100s/iter; left time: 8276.5309s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0963981\n",
      "\tspeed: 0.1103s/iter; left time: 8293.0598s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0659093\n",
      "\tspeed: 0.1068s/iter; left time: 8020.7159s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0657669\n",
      "\tspeed: 0.1127s/iter; left time: 8448.2962s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0720211\n",
      "\tspeed: 0.1121s/iter; left time: 8392.7005s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0712480\n",
      "\tspeed: 0.1065s/iter; left time: 7965.6534s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0856539\n",
      "\tspeed: 0.1094s/iter; left time: 8168.6414s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0623613\n",
      "\tspeed: 0.1119s/iter; left time: 8348.5677s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0893327\n",
      "\tspeed: 0.1111s/iter; left time: 8270.4848s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0696654\n",
      "\tspeed: 0.1097s/iter; left time: 8161.6126s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0730618\n",
      "\tspeed: 0.1054s/iter; left time: 7827.4105s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1034888\n",
      "\tspeed: 0.1018s/iter; left time: 7551.0647s\n",
      "\titers: 2800, epoch: 4 | loss: 0.1006469\n",
      "\tspeed: 0.1034s/iter; left time: 7657.0158s\n",
      "\titers: 2900, epoch: 4 | loss: 0.1005497\n",
      "\tspeed: 0.1108s/iter; left time: 8199.3256s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0935509\n",
      "\tspeed: 0.1016s/iter; left time: 7504.1857s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0753280\n",
      "\tspeed: 0.1081s/iter; left time: 7971.3943s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0706492\n",
      "\tspeed: 0.1017s/iter; left time: 7492.9908s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0906545\n",
      "\tspeed: 0.0983s/iter; left time: 7229.1329s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0924548\n",
      "\tspeed: 0.1038s/iter; left time: 7627.3184s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0942234\n",
      "\tspeed: 0.1085s/iter; left time: 7964.7289s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0775782\n",
      "\tspeed: 0.1044s/iter; left time: 7649.2491s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0990044\n",
      "\tspeed: 0.1086s/iter; left time: 7947.6685s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0739438\n",
      "\tspeed: 0.1076s/iter; left time: 7866.2005s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0741513\n",
      "\tspeed: 0.1060s/iter; left time: 7734.3064s\n",
      "\titers: 4000, epoch: 4 | loss: 0.1035634\n",
      "\tspeed: 0.1086s/iter; left time: 7915.5202s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0926756\n",
      "\tspeed: 0.1069s/iter; left time: 7779.8917s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0766873\n",
      "\tspeed: 0.1109s/iter; left time: 8057.3316s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0816468\n",
      "\tspeed: 0.1127s/iter; left time: 8179.0985s\n",
      "\titers: 4400, epoch: 4 | loss: 0.0696979\n",
      "\tspeed: 0.1113s/iter; left time: 8068.8115s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0842183\n",
      "\tspeed: 0.1100s/iter; left time: 7960.6680s\n",
      "Epoch: 4 cost time: 00h:08m:07.74s\n",
      "Epoch: 4 | Train Loss: 0.0844865 Vali Loss: 0.0915782 Test Loss: 0.1032246\n",
      "Validation loss decreased (0.092178 --> 0.091578).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0764009\n",
      "\tspeed: 1.4070s/iter; left time: 101656.8174s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730245\n",
      "\tspeed: 0.1131s/iter; left time: 8158.3488s\n",
      "\titers: 300, epoch: 5 | loss: 0.0776051\n",
      "\tspeed: 0.1112s/iter; left time: 8013.2935s\n",
      "\titers: 400, epoch: 5 | loss: 0.0946778\n",
      "\tspeed: 0.1114s/iter; left time: 8013.3086s\n",
      "\titers: 500, epoch: 5 | loss: 0.1013129\n",
      "\tspeed: 0.1042s/iter; left time: 7487.1354s\n",
      "\titers: 600, epoch: 5 | loss: 0.0676902\n",
      "\tspeed: 0.1124s/iter; left time: 8061.4662s\n",
      "\titers: 700, epoch: 5 | loss: 0.1225403\n",
      "\tspeed: 0.1106s/iter; left time: 7925.9904s\n",
      "\titers: 800, epoch: 5 | loss: 0.0980337\n",
      "\tspeed: 0.1148s/iter; left time: 8213.1138s\n",
      "\titers: 900, epoch: 5 | loss: 0.0809818\n",
      "\tspeed: 0.1172s/iter; left time: 8371.8404s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0776619\n",
      "\tspeed: 0.1144s/iter; left time: 8159.2640s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0892745\n",
      "\tspeed: 0.1089s/iter; left time: 7756.8168s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0869640\n",
      "\tspeed: 0.1138s/iter; left time: 8099.9553s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0664086\n",
      "\tspeed: 0.1057s/iter; left time: 7512.7843s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0807366\n",
      "\tspeed: 0.1091s/iter; left time: 7742.9107s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1026780\n",
      "\tspeed: 0.1116s/iter; left time: 7910.4935s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0633318\n",
      "\tspeed: 0.1162s/iter; left time: 8222.0341s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0720050\n",
      "\tspeed: 0.1174s/iter; left time: 8296.1446s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0925685\n",
      "\tspeed: 0.1159s/iter; left time: 8175.5333s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0702756\n",
      "\tspeed: 0.1143s/iter; left time: 8050.4520s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0914315\n",
      "\tspeed: 0.1153s/iter; left time: 8111.1375s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0902972\n",
      "\tspeed: 0.1058s/iter; left time: 7430.0951s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1011958\n",
      "\tspeed: 0.1115s/iter; left time: 7822.1547s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0818255\n",
      "\tspeed: 0.1169s/iter; left time: 8190.1558s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0682495\n",
      "\tspeed: 0.1154s/iter; left time: 8070.3298s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0805780\n",
      "\tspeed: 0.1142s/iter; left time: 7979.7704s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0975319\n",
      "\tspeed: 0.1146s/iter; left time: 7991.6142s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0876194\n",
      "\tspeed: 0.1145s/iter; left time: 7978.3114s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0913618\n",
      "\tspeed: 0.1154s/iter; left time: 8024.0770s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0989023\n",
      "\tspeed: 0.1150s/iter; left time: 7985.7769s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0779748\n",
      "\tspeed: 0.1146s/iter; left time: 7945.4341s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0722494\n",
      "\tspeed: 0.1113s/iter; left time: 7711.1105s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0834375\n",
      "\tspeed: 0.1125s/iter; left time: 7777.5363s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0765159\n",
      "\tspeed: 0.1132s/iter; left time: 7815.5526s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0839737\n",
      "\tspeed: 0.1145s/iter; left time: 7894.1828s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0880884\n",
      "\tspeed: 0.1152s/iter; left time: 7930.5221s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0812610\n",
      "\tspeed: 0.1114s/iter; left time: 7658.9113s\n",
      "\titers: 3700, epoch: 5 | loss: 0.1069614\n",
      "\tspeed: 0.1116s/iter; left time: 7658.6433s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0721640\n",
      "\tspeed: 0.1144s/iter; left time: 7840.0647s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0783954\n",
      "\tspeed: 0.1136s/iter; left time: 7775.7398s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0720734\n",
      "\tspeed: 0.1143s/iter; left time: 7809.6084s\n",
      "\titers: 4100, epoch: 5 | loss: 0.1003776\n",
      "\tspeed: 0.1127s/iter; left time: 7691.1803s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0942164\n",
      "\tspeed: 0.1120s/iter; left time: 7631.5791s\n",
      "\titers: 4300, epoch: 5 | loss: 0.1038001\n",
      "\tspeed: 0.1130s/iter; left time: 7692.9909s\n",
      "\titers: 4400, epoch: 5 | loss: 0.0905783\n",
      "\tspeed: 0.1131s/iter; left time: 7684.7184s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0687398\n",
      "\tspeed: 0.1072s/iter; left time: 7270.6577s\n",
      "Epoch: 5 cost time: 00h:08m:30.59s\n",
      "Epoch: 5 | Train Loss: 0.0835157 Vali Loss: 0.0904783 Test Loss: 0.1020260\n",
      "Validation loss decreased (0.091578 --> 0.090478).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0812983\n",
      "\tspeed: 1.3772s/iter; left time: 93280.1404s\n",
      "\titers: 200, epoch: 6 | loss: 0.0941398\n",
      "\tspeed: 0.1159s/iter; left time: 7839.5556s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902328\n",
      "\tspeed: 0.1150s/iter; left time: 7768.4944s\n",
      "\titers: 400, epoch: 6 | loss: 0.0871440\n",
      "\tspeed: 0.1183s/iter; left time: 7974.3248s\n",
      "\titers: 500, epoch: 6 | loss: 0.0626916\n",
      "\tspeed: 0.1170s/iter; left time: 7878.2276s\n",
      "\titers: 600, epoch: 6 | loss: 0.0868426\n",
      "\tspeed: 0.1083s/iter; left time: 7283.7016s\n",
      "\titers: 700, epoch: 6 | loss: 0.0924270\n",
      "\tspeed: 0.1066s/iter; left time: 7158.8343s\n",
      "\titers: 800, epoch: 6 | loss: 0.0896151\n",
      "\tspeed: 0.1078s/iter; left time: 7224.2728s\n",
      "\titers: 900, epoch: 6 | loss: 0.0811331\n",
      "\tspeed: 0.1214s/iter; left time: 8127.3942s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0828899\n",
      "\tspeed: 0.1177s/iter; left time: 7868.8017s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0727603\n",
      "\tspeed: 0.1185s/iter; left time: 7908.6340s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0860184\n",
      "\tspeed: 0.1148s/iter; left time: 7646.8006s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0682474\n",
      "\tspeed: 0.1149s/iter; left time: 7647.4736s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0901280\n",
      "\tspeed: 0.1213s/iter; left time: 8061.2870s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0831633\n",
      "\tspeed: 0.1185s/iter; left time: 7859.2505s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0811408\n",
      "\tspeed: 0.1120s/iter; left time: 7420.7208s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0809371\n",
      "\tspeed: 0.1156s/iter; left time: 7642.2682s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0792824\n",
      "\tspeed: 0.1187s/iter; left time: 7839.5393s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0814376\n",
      "\tspeed: 0.1131s/iter; left time: 7459.8107s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0859970\n",
      "\tspeed: 0.1175s/iter; left time: 7734.0840s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0837977\n",
      "\tspeed: 0.1205s/iter; left time: 7917.5292s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0922201\n",
      "\tspeed: 0.1142s/iter; left time: 7494.9147s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0636698\n",
      "\tspeed: 0.1152s/iter; left time: 7548.2939s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0787112\n",
      "\tspeed: 0.1155s/iter; left time: 7556.7028s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0728925\n",
      "\tspeed: 0.1168s/iter; left time: 7627.6274s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0813409\n",
      "\tspeed: 0.1156s/iter; left time: 7541.7750s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0973538\n",
      "\tspeed: 0.1134s/iter; left time: 7387.1768s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0791299\n",
      "\tspeed: 0.1147s/iter; left time: 7458.7723s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0893511\n",
      "\tspeed: 0.1156s/iter; left time: 7505.8516s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0751880\n",
      "\tspeed: 0.1137s/iter; left time: 7373.6415s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0801695\n",
      "\tspeed: 0.1049s/iter; left time: 6788.9510s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0925767\n",
      "\tspeed: 0.1051s/iter; left time: 6792.1088s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0876243\n",
      "\tspeed: 0.1099s/iter; left time: 7093.9290s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0824154\n",
      "\tspeed: 0.1108s/iter; left time: 7140.5736s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0732365\n",
      "\tspeed: 0.1118s/iter; left time: 7195.4001s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0873338\n",
      "\tspeed: 0.1143s/iter; left time: 7342.5851s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0952608\n",
      "\tspeed: 0.1094s/iter; left time: 7017.6077s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0645328\n",
      "\tspeed: 0.1117s/iter; left time: 7152.5838s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0921175\n",
      "\tspeed: 0.1092s/iter; left time: 6984.1707s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0875103\n",
      "\tspeed: 0.1078s/iter; left time: 6883.3399s\n",
      "\titers: 4100, epoch: 6 | loss: 0.1005034\n",
      "\tspeed: 0.1086s/iter; left time: 6922.7358s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0695276\n",
      "\tspeed: 0.1056s/iter; left time: 6722.1300s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0934739\n",
      "\tspeed: 0.1062s/iter; left time: 6744.2352s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0771808\n",
      "\tspeed: 0.1082s/iter; left time: 6860.2141s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0892705\n",
      "\tspeed: 0.1108s/iter; left time: 7017.3556s\n",
      "Epoch: 6 cost time: 00h:08m:32.75s\n",
      "Epoch: 6 | Train Loss: 0.0826310 Vali Loss: 0.0910091 Test Loss: 0.1025603\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0782916\n",
      "\tspeed: 1.3790s/iter; left time: 87167.1489s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737024\n",
      "\tspeed: 0.1122s/iter; left time: 7081.5277s\n",
      "\titers: 300, epoch: 7 | loss: 0.0874675\n",
      "\tspeed: 0.1104s/iter; left time: 6953.8537s\n",
      "\titers: 400, epoch: 7 | loss: 0.0594715\n",
      "\tspeed: 0.1118s/iter; left time: 7035.7538s\n",
      "\titers: 500, epoch: 7 | loss: 0.0711064\n",
      "\tspeed: 0.1152s/iter; left time: 7234.5487s\n",
      "\titers: 600, epoch: 7 | loss: 0.0591754\n",
      "\tspeed: 0.1166s/iter; left time: 7311.0476s\n",
      "\titers: 700, epoch: 7 | loss: 0.1052766\n",
      "\tspeed: 0.1155s/iter; left time: 7228.5772s\n",
      "\titers: 800, epoch: 7 | loss: 0.0879410\n",
      "\tspeed: 0.1145s/iter; left time: 7155.7652s\n",
      "\titers: 900, epoch: 7 | loss: 0.0614912\n",
      "\tspeed: 0.1120s/iter; left time: 6990.9244s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0759555\n",
      "\tspeed: 0.1068s/iter; left time: 6655.8414s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0825540\n",
      "\tspeed: 0.1087s/iter; left time: 6759.0863s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0859189\n",
      "\tspeed: 0.1116s/iter; left time: 6933.3434s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0832791\n",
      "\tspeed: 0.1084s/iter; left time: 6723.8350s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0897717\n",
      "\tspeed: 0.1124s/iter; left time: 6958.7353s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0897185\n",
      "\tspeed: 0.1126s/iter; left time: 6957.6612s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0787883\n",
      "\tspeed: 0.1157s/iter; left time: 7141.7996s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0877722\n",
      "\tspeed: 0.1107s/iter; left time: 6818.6917s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0879989\n",
      "\tspeed: 0.1086s/iter; left time: 6677.3242s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0648590\n",
      "\tspeed: 0.1099s/iter; left time: 6747.5444s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1105017\n",
      "\tspeed: 0.1107s/iter; left time: 6785.6430s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0939429\n",
      "\tspeed: 0.1117s/iter; left time: 6838.1600s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0909830\n",
      "\tspeed: 0.1158s/iter; left time: 7075.7833s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0773266\n",
      "\tspeed: 0.1111s/iter; left time: 6778.7846s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0807570\n",
      "\tspeed: 0.1070s/iter; left time: 6516.6499s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0773594\n",
      "\tspeed: 0.1141s/iter; left time: 6940.5279s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0933358\n",
      "\tspeed: 0.1076s/iter; left time: 6531.2120s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0933498\n",
      "\tspeed: 0.1135s/iter; left time: 6881.8794s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0762988\n",
      "\tspeed: 0.1091s/iter; left time: 6604.0276s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0859871\n",
      "\tspeed: 0.1151s/iter; left time: 6954.9714s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0696483\n",
      "\tspeed: 0.1067s/iter; left time: 6437.7233s\n",
      "\titers: 3100, epoch: 7 | loss: 0.0762766\n",
      "\tspeed: 0.1083s/iter; left time: 6517.7749s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0734615\n",
      "\tspeed: 0.1091s/iter; left time: 6557.5845s\n",
      "\titers: 3300, epoch: 7 | loss: 0.1136177\n",
      "\tspeed: 0.1121s/iter; left time: 6725.5906s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0692223\n",
      "\tspeed: 0.1116s/iter; left time: 6686.6950s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0927484\n",
      "\tspeed: 0.1084s/iter; left time: 6481.7896s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0883621\n",
      "\tspeed: 0.1062s/iter; left time: 6338.6684s\n",
      "\titers: 3700, epoch: 7 | loss: 0.1253040\n",
      "\tspeed: 0.1102s/iter; left time: 6567.7953s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0752309\n",
      "\tspeed: 0.1134s/iter; left time: 6748.8132s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0866888\n",
      "\tspeed: 0.1115s/iter; left time: 6622.8165s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0651958\n",
      "\tspeed: 0.1098s/iter; left time: 6511.4588s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0934881\n",
      "\tspeed: 0.1075s/iter; left time: 6366.9896s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0938249\n",
      "\tspeed: 0.1025s/iter; left time: 6057.2782s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0727635\n",
      "\tspeed: 0.1074s/iter; left time: 6338.5846s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0592286\n",
      "\tspeed: 0.1107s/iter; left time: 6520.8131s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0818531\n",
      "\tspeed: 0.1129s/iter; left time: 6642.0504s\n",
      "Epoch: 7 cost time: 00h:08m:22.20s\n",
      "Epoch: 7 | Train Loss: 0.0820117 Vali Loss: 0.0911718 Test Loss: 0.1036153\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0732152\n",
      "\tspeed: 1.3460s/iter; left time: 78992.1879s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739298\n",
      "\tspeed: 0.1073s/iter; left time: 6285.1292s\n",
      "\titers: 300, epoch: 8 | loss: 0.0996680\n",
      "\tspeed: 0.1062s/iter; left time: 6211.1262s\n",
      "\titers: 400, epoch: 8 | loss: 0.0923807\n",
      "\tspeed: 0.1068s/iter; left time: 6234.6886s\n",
      "\titers: 500, epoch: 8 | loss: 0.0671743\n",
      "\tspeed: 0.1079s/iter; left time: 6291.0267s\n",
      "\titers: 600, epoch: 8 | loss: 0.0814862\n",
      "\tspeed: 0.1084s/iter; left time: 6304.8152s\n",
      "\titers: 700, epoch: 8 | loss: 0.0712411\n",
      "\tspeed: 0.1032s/iter; left time: 5997.0270s\n",
      "\titers: 800, epoch: 8 | loss: 0.0838001\n",
      "\tspeed: 0.1109s/iter; left time: 6428.4911s\n",
      "\titers: 900, epoch: 8 | loss: 0.0888200\n",
      "\tspeed: 0.1042s/iter; left time: 6033.9348s\n",
      "\titers: 1000, epoch: 8 | loss: 0.1049284\n",
      "\tspeed: 0.1083s/iter; left time: 6259.5362s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0709342\n",
      "\tspeed: 0.1085s/iter; left time: 6261.2795s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0788523\n",
      "\tspeed: 0.1060s/iter; left time: 6105.0661s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0780780\n",
      "\tspeed: 0.1079s/iter; left time: 6204.9021s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0839201\n",
      "\tspeed: 0.1064s/iter; left time: 6105.9228s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0773714\n",
      "\tspeed: 0.1071s/iter; left time: 6135.2805s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0897230\n",
      "\tspeed: 0.1048s/iter; left time: 5991.9187s\n",
      "\titers: 1700, epoch: 8 | loss: 0.1068555\n",
      "\tspeed: 0.1087s/iter; left time: 6206.9792s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0774539\n",
      "\tspeed: 0.1084s/iter; left time: 6178.3213s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0776772\n",
      "\tspeed: 0.1023s/iter; left time: 5821.2028s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0807440\n",
      "\tspeed: 0.1120s/iter; left time: 6358.4454s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0842689\n",
      "\tspeed: 0.1095s/iter; left time: 6206.7921s\n",
      "\titers: 2200, epoch: 8 | loss: 0.1024396\n",
      "\tspeed: 0.1068s/iter; left time: 6042.0964s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0878496\n",
      "\tspeed: 0.1070s/iter; left time: 6043.5643s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0683370\n",
      "\tspeed: 0.1076s/iter; left time: 6066.2037s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0706606\n",
      "\tspeed: 0.1069s/iter; left time: 6014.6264s\n",
      "\titers: 2600, epoch: 8 | loss: 0.1013848\n",
      "\tspeed: 0.1009s/iter; left time: 5668.4666s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0744765\n",
      "\tspeed: 0.1080s/iter; left time: 6055.0133s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0909392\n",
      "\tspeed: 0.1086s/iter; left time: 6078.9574s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0746501\n",
      "\tspeed: 0.1095s/iter; left time: 6117.7719s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0783223\n",
      "\tspeed: 0.1117s/iter; left time: 6232.8557s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0928804\n",
      "\tspeed: 0.1115s/iter; left time: 6210.5991s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0792120\n",
      "\tspeed: 0.1034s/iter; left time: 5745.4475s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0992566\n",
      "\tspeed: 0.1071s/iter; left time: 5945.0167s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0902702\n",
      "\tspeed: 0.1036s/iter; left time: 5738.4978s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0801584\n",
      "\tspeed: 0.1127s/iter; left time: 6233.1764s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0814238\n",
      "\tspeed: 0.1079s/iter; left time: 5952.2151s\n",
      "\titers: 3700, epoch: 8 | loss: 0.1019752\n",
      "\tspeed: 0.1097s/iter; left time: 6043.4106s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0760639\n",
      "\tspeed: 0.1093s/iter; left time: 6010.5658s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0759647\n",
      "\tspeed: 0.1124s/iter; left time: 6171.8696s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0671872\n",
      "\tspeed: 0.1135s/iter; left time: 6219.4317s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0795580\n",
      "\tspeed: 0.1113s/iter; left time: 6085.4804s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0834507\n",
      "\tspeed: 0.1084s/iter; left time: 5918.4679s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0692395\n",
      "\tspeed: 0.1099s/iter; left time: 5989.2119s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0635808\n",
      "\tspeed: 0.1079s/iter; left time: 5866.4880s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0817286\n",
      "\tspeed: 0.1133s/iter; left time: 6153.1857s\n",
      "Epoch: 8 cost time: 00h:08m:08.57s\n",
      "Epoch: 8 | Train Loss: 0.0814783 Vali Loss: 0.0905682 Test Loss: 0.1031664\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0703099\n",
      "\tspeed: 1.3564s/iter; left time: 73469.3086s\n",
      "\titers: 200, epoch: 9 | loss: 0.0661289\n",
      "\tspeed: 0.1062s/iter; left time: 5740.8656s\n",
      "\titers: 300, epoch: 9 | loss: 0.0730006\n",
      "\tspeed: 0.1084s/iter; left time: 5847.8770s\n",
      "\titers: 400, epoch: 9 | loss: 0.0909006\n",
      "\tspeed: 0.1087s/iter; left time: 5854.3485s\n",
      "\titers: 500, epoch: 9 | loss: 0.0797747\n",
      "\tspeed: 0.1136s/iter; left time: 6105.3907s\n",
      "\titers: 600, epoch: 9 | loss: 0.0634570\n",
      "\tspeed: 0.1057s/iter; left time: 5674.9719s\n",
      "\titers: 700, epoch: 9 | loss: 0.0780361\n",
      "\tspeed: 0.1074s/iter; left time: 5754.7974s\n",
      "\titers: 800, epoch: 9 | loss: 0.0669405\n",
      "\tspeed: 0.1080s/iter; left time: 5774.5355s\n",
      "\titers: 900, epoch: 9 | loss: 0.0857686\n",
      "\tspeed: 0.1043s/iter; left time: 5565.8755s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0711497\n",
      "\tspeed: 0.1073s/iter; left time: 5713.3018s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0730886\n",
      "\tspeed: 0.1085s/iter; left time: 5766.8436s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0983064\n",
      "\tspeed: 0.1066s/iter; left time: 5658.2694s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0866826\n",
      "\tspeed: 0.1068s/iter; left time: 5656.2156s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0800513\n",
      "\tspeed: 0.1098s/iter; left time: 5802.4550s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0882934\n",
      "\tspeed: 0.1057s/iter; left time: 5579.5180s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0806662\n",
      "\tspeed: 0.1072s/iter; left time: 5644.7337s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0822634\n",
      "\tspeed: 0.1079s/iter; left time: 5671.0197s\n",
      "\titers: 1800, epoch: 9 | loss: 0.1030238\n",
      "\tspeed: 0.1073s/iter; left time: 5629.5438s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0579023\n",
      "\tspeed: 0.1031s/iter; left time: 5396.7381s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0648435\n",
      "\tspeed: 0.0995s/iter; left time: 5198.9009s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0794803\n",
      "\tspeed: 0.1057s/iter; left time: 5513.1332s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0919313\n",
      "\tspeed: 0.1108s/iter; left time: 5767.3538s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0841021\n",
      "\tspeed: 0.1091s/iter; left time: 5667.7368s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0665691\n",
      "\tspeed: 0.1040s/iter; left time: 5396.2921s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0756644\n",
      "\tspeed: 0.1068s/iter; left time: 5526.4413s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0973960\n",
      "\tspeed: 0.1081s/iter; left time: 5583.1718s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0803707\n",
      "\tspeed: 0.1062s/iter; left time: 5474.0521s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0828818\n",
      "\tspeed: 0.1077s/iter; left time: 5542.9353s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0834953\n",
      "\tspeed: 0.1100s/iter; left time: 5652.2800s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0945008\n",
      "\tspeed: 0.1114s/iter; left time: 5709.1124s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0725701\n",
      "\tspeed: 0.1095s/iter; left time: 5602.9923s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0824381\n",
      "\tspeed: 0.1086s/iter; left time: 5545.2183s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0844136\n",
      "\tspeed: 0.1076s/iter; left time: 5486.1093s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0847613\n",
      "\tspeed: 0.1062s/iter; left time: 5401.4748s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0876833\n",
      "\tspeed: 0.1044s/iter; left time: 5300.2674s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0747652\n",
      "\tspeed: 0.1050s/iter; left time: 5319.5869s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0950879\n",
      "\tspeed: 0.1117s/iter; left time: 5650.0527s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0775687\n",
      "\tspeed: 0.1106s/iter; left time: 5582.0811s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1005411\n",
      "\tspeed: 0.1096s/iter; left time: 5517.7761s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0735400\n",
      "\tspeed: 0.1078s/iter; left time: 5418.6794s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0802550\n",
      "\tspeed: 0.1115s/iter; left time: 5595.1995s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0737344\n",
      "\tspeed: 0.1070s/iter; left time: 5357.7265s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0747904\n",
      "\tspeed: 0.1118s/iter; left time: 5588.0268s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0828114\n",
      "\tspeed: 0.1070s/iter; left time: 5333.6176s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0862405\n",
      "\tspeed: 0.1016s/iter; left time: 5054.6891s\n",
      "Epoch: 9 cost time: 00h:08m:06.97s\n",
      "Epoch: 9 | Train Loss: 0.0809893 Vali Loss: 0.0916111 Test Loss: 0.1051403\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0816405\n",
      "\tspeed: 1.5056s/iter; left time: 74743.0955s\n",
      "\titers: 200, epoch: 10 | loss: 0.0766254\n",
      "\tspeed: 0.1677s/iter; left time: 8309.7338s\n",
      "\titers: 300, epoch: 10 | loss: 0.0784807\n",
      "\tspeed: 0.1788s/iter; left time: 8842.8431s\n",
      "\titers: 400, epoch: 10 | loss: 0.0739854\n",
      "\tspeed: 0.1623s/iter; left time: 8008.0572s\n",
      "\titers: 500, epoch: 10 | loss: 0.0644668\n",
      "\tspeed: 0.1732s/iter; left time: 8527.3789s\n",
      "\titers: 600, epoch: 10 | loss: 0.0927067\n",
      "\tspeed: 0.1768s/iter; left time: 8690.0646s\n",
      "\titers: 700, epoch: 10 | loss: 0.0836936\n",
      "\tspeed: 0.1725s/iter; left time: 8460.9958s\n",
      "\titers: 800, epoch: 10 | loss: 0.0681958\n",
      "\tspeed: 0.1677s/iter; left time: 8205.5260s\n",
      "\titers: 900, epoch: 10 | loss: 0.0579794\n",
      "\tspeed: 0.1765s/iter; left time: 8619.9024s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0929869\n",
      "\tspeed: 0.1644s/iter; left time: 8015.3019s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0867471\n",
      "\tspeed: 0.1702s/iter; left time: 8279.5796s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0713964\n",
      "\tspeed: 0.1728s/iter; left time: 8388.7072s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0784892\n",
      "\tspeed: 0.1680s/iter; left time: 8136.3748s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0673464\n",
      "\tspeed: 0.1655s/iter; left time: 8000.9591s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0962022\n",
      "\tspeed: 0.1739s/iter; left time: 8391.8449s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0791832\n",
      "\tspeed: 0.1676s/iter; left time: 8069.5742s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0840134\n",
      "\tspeed: 0.1704s/iter; left time: 8188.3617s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0888101\n",
      "\tspeed: 0.1680s/iter; left time: 8054.3426s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0904469\n",
      "\tspeed: 0.1701s/iter; left time: 8138.9007s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0924225\n",
      "\tspeed: 0.1656s/iter; left time: 7907.7734s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0791372\n",
      "\tspeed: 0.1691s/iter; left time: 8056.1534s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0781822\n",
      "\tspeed: 0.1691s/iter; left time: 8041.5865s\n",
      "\titers: 2300, epoch: 10 | loss: 0.1064164\n",
      "\tspeed: 0.1734s/iter; left time: 8228.6299s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0728554\n",
      "\tspeed: 0.1700s/iter; left time: 8049.0876s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0860459\n",
      "\tspeed: 0.1671s/iter; left time: 7894.5896s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0704340\n",
      "\tspeed: 0.1654s/iter; left time: 7798.2297s\n",
      "\titers: 2700, epoch: 10 | loss: 0.1034880\n",
      "\tspeed: 0.1643s/iter; left time: 7728.2023s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0835919\n",
      "\tspeed: 0.1720s/iter; left time: 8072.0363s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0828122\n",
      "\tspeed: 0.1695s/iter; left time: 7938.0909s\n",
      "\titers: 3000, epoch: 10 | loss: 0.1022225\n",
      "\tspeed: 0.1699s/iter; left time: 7940.2798s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0760711\n",
      "\tspeed: 0.1759s/iter; left time: 8206.8121s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0942224\n",
      "\tspeed: 0.1706s/iter; left time: 7939.5766s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0668895\n",
      "\tspeed: 0.1669s/iter; left time: 7752.7207s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0831018\n",
      "\tspeed: 0.1617s/iter; left time: 7494.7056s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0868632\n",
      "\tspeed: 0.1476s/iter; left time: 6823.5152s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0665198\n",
      "\tspeed: 0.1669s/iter; left time: 7702.3435s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0861763\n",
      "\tspeed: 0.1692s/iter; left time: 7791.6531s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0677366\n",
      "\tspeed: 0.1750s/iter; left time: 8039.3670s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0758316\n",
      "\tspeed: 0.1721s/iter; left time: 7887.6651s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0996817\n",
      "\tspeed: 0.1762s/iter; left time: 8057.8746s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0827505\n",
      "\tspeed: 0.1728s/iter; left time: 7888.9379s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0797417\n",
      "\tspeed: 0.1735s/iter; left time: 7902.3312s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0685679\n",
      "\tspeed: 0.1749s/iter; left time: 7950.2304s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0808612\n",
      "\tspeed: 0.1688s/iter; left time: 7655.6931s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0776486\n",
      "\tspeed: 0.1726s/iter; left time: 7809.4504s\n",
      "Epoch: 10 cost time: 00h:12m:47.72s\n",
      "Epoch: 10 | Train Loss: 0.0804342 Vali Loss: 0.0901784 Test Loss: 0.1029878\n",
      "Validation loss decreased (0.090478 --> 0.090178).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0974984\n",
      "\tspeed: 2.4543s/iter; left time: 110740.7403s\n",
      "\titers: 200, epoch: 11 | loss: 0.1084916\n",
      "\tspeed: 0.1746s/iter; left time: 7859.7574s\n",
      "\titers: 300, epoch: 11 | loss: 0.0795783\n",
      "\tspeed: 0.1728s/iter; left time: 7762.6291s\n",
      "\titers: 400, epoch: 11 | loss: 0.0906499\n",
      "\tspeed: 0.1696s/iter; left time: 7603.5808s\n",
      "\titers: 500, epoch: 11 | loss: 0.0617057\n",
      "\tspeed: 0.1709s/iter; left time: 7642.3995s\n",
      "\titers: 600, epoch: 11 | loss: 0.0844769\n",
      "\tspeed: 0.1661s/iter; left time: 7412.4329s\n",
      "\titers: 700, epoch: 11 | loss: 0.0920626\n",
      "\tspeed: 0.1761s/iter; left time: 7841.6541s\n",
      "\titers: 800, epoch: 11 | loss: 0.0758732\n",
      "\tspeed: 0.1726s/iter; left time: 7667.7183s\n",
      "\titers: 900, epoch: 11 | loss: 0.0766621\n",
      "\tspeed: 0.1698s/iter; left time: 7524.5947s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0673401\n",
      "\tspeed: 0.1734s/iter; left time: 7669.1343s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0778624\n",
      "\tspeed: 0.1412s/iter; left time: 6229.9828s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0829826\n",
      "\tspeed: 0.1708s/iter; left time: 7520.7914s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0657404\n",
      "\tspeed: 0.1748s/iter; left time: 7677.6940s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0692072\n",
      "\tspeed: 0.1726s/iter; left time: 7561.3366s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0636617\n",
      "\tspeed: 0.1725s/iter; left time: 7541.0806s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0922092\n",
      "\tspeed: 0.1712s/iter; left time: 7465.7748s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0752913\n",
      "\tspeed: 0.1697s/iter; left time: 7385.6126s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0750323\n",
      "\tspeed: 0.1746s/iter; left time: 7581.5062s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0788291\n",
      "\tspeed: 0.1702s/iter; left time: 7373.5958s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0863553\n",
      "\tspeed: 0.1691s/iter; left time: 7307.2476s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0871803\n",
      "\tspeed: 0.1720s/iter; left time: 7416.4730s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0845631\n",
      "\tspeed: 0.1723s/iter; left time: 7411.4243s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0744086\n",
      "\tspeed: 0.1726s/iter; left time: 7406.8673s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0751737\n",
      "\tspeed: 0.1715s/iter; left time: 7341.7941s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0764639\n",
      "\tspeed: 0.1707s/iter; left time: 7293.8488s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0728826\n",
      "\tspeed: 0.1669s/iter; left time: 7112.7317s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0820884\n",
      "\tspeed: 0.1699s/iter; left time: 7222.7575s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0734678\n",
      "\tspeed: 0.1724s/iter; left time: 7311.7517s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0713528\n",
      "\tspeed: 0.1725s/iter; left time: 7299.5754s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0726881\n",
      "\tspeed: 0.1684s/iter; left time: 7109.6297s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0888106\n",
      "\tspeed: 0.1708s/iter; left time: 7196.2566s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0684832\n",
      "\tspeed: 0.1738s/iter; left time: 7304.1341s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0845863\n",
      "\tspeed: 0.1729s/iter; left time: 7249.1622s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0670759\n",
      "\tspeed: 0.1733s/iter; left time: 7245.6266s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0927361\n",
      "\tspeed: 0.1689s/iter; left time: 7047.7658s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0801660\n",
      "\tspeed: 0.1696s/iter; left time: 7057.2613s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0734223\n",
      "\tspeed: 0.1706s/iter; left time: 7083.3770s\n",
      "\titers: 3800, epoch: 11 | loss: 0.0741341\n",
      "\tspeed: 0.1742s/iter; left time: 7216.0146s\n",
      "\titers: 3900, epoch: 11 | loss: 0.0760273\n",
      "\tspeed: 0.1706s/iter; left time: 7050.1548s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0829363\n",
      "\tspeed: 0.1691s/iter; left time: 6971.0959s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0770808\n",
      "\tspeed: 0.1709s/iter; left time: 7027.7615s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0720862\n",
      "\tspeed: 0.1707s/iter; left time: 7001.8157s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0673367\n",
      "\tspeed: 0.1720s/iter; left time: 7037.7272s\n",
      "\titers: 4400, epoch: 11 | loss: 0.0834634\n",
      "\tspeed: 0.1679s/iter; left time: 6855.3765s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0774424\n",
      "\tspeed: 0.1616s/iter; left time: 6581.8417s\n",
      "Epoch: 11 cost time: 00h:12m:51.30s\n",
      "Epoch: 11 | Train Loss: 0.0798544 Vali Loss: 0.0912271 Test Loss: 0.1041037\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0739109\n",
      "\tspeed: 2.4182s/iter; left time: 98177.0668s\n",
      "\titers: 200, epoch: 12 | loss: 0.0860921\n",
      "\tspeed: 0.1697s/iter; left time: 6872.5166s\n",
      "\titers: 300, epoch: 12 | loss: 0.0664674\n",
      "\tspeed: 0.1680s/iter; left time: 6786.8393s\n",
      "\titers: 400, epoch: 12 | loss: 0.0764211\n",
      "\tspeed: 0.1764s/iter; left time: 7109.8123s\n",
      "\titers: 500, epoch: 12 | loss: 0.0874369\n",
      "\tspeed: 0.1615s/iter; left time: 6494.0314s\n",
      "\titers: 600, epoch: 12 | loss: 0.0708299\n",
      "\tspeed: 0.1643s/iter; left time: 6587.1768s\n",
      "\titers: 700, epoch: 12 | loss: 0.0705044\n",
      "\tspeed: 0.1683s/iter; left time: 6730.0374s\n",
      "\titers: 800, epoch: 12 | loss: 0.0986635\n",
      "\tspeed: 0.1715s/iter; left time: 6844.1792s\n",
      "\titers: 900, epoch: 12 | loss: 0.0688188\n",
      "\tspeed: 0.1653s/iter; left time: 6579.2069s\n",
      "\titers: 1000, epoch: 12 | loss: 0.1012405\n",
      "\tspeed: 0.1713s/iter; left time: 6801.5585s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0597627\n",
      "\tspeed: 0.1670s/iter; left time: 6613.2589s\n",
      "\titers: 1200, epoch: 12 | loss: 0.1038116\n",
      "\tspeed: 0.1753s/iter; left time: 6923.8798s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0816263\n",
      "\tspeed: 0.1750s/iter; left time: 6895.0305s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0720345\n",
      "\tspeed: 0.1678s/iter; left time: 6592.6548s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0729031\n",
      "\tspeed: 0.1731s/iter; left time: 6783.9466s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0784716\n",
      "\tspeed: 0.1709s/iter; left time: 6681.0688s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0784295\n",
      "\tspeed: 0.1679s/iter; left time: 6548.2350s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0790784\n",
      "\tspeed: 0.1731s/iter; left time: 6734.7432s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0606100\n",
      "\tspeed: 0.1661s/iter; left time: 6444.9618s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0830413\n",
      "\tspeed: 0.1709s/iter; left time: 6612.6838s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0982970\n",
      "\tspeed: 0.1709s/iter; left time: 6597.6624s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0885968\n",
      "\tspeed: 0.1737s/iter; left time: 6688.1668s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0810560\n",
      "\tspeed: 0.1459s/iter; left time: 5603.5085s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0801082\n",
      "\tspeed: 0.1720s/iter; left time: 6588.7244s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0756430\n",
      "\tspeed: 0.1679s/iter; left time: 6413.4222s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0775358\n",
      "\tspeed: 0.1692s/iter; left time: 6447.5840s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0701456\n",
      "\tspeed: 0.1683s/iter; left time: 6395.6950s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0707467\n",
      "\tspeed: 0.1695s/iter; left time: 6422.5551s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0524994\n",
      "\tspeed: 0.1703s/iter; left time: 6437.3227s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0919134\n",
      "\tspeed: 0.1722s/iter; left time: 6491.2415s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0804881\n",
      "\tspeed: 0.1680s/iter; left time: 6315.4685s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0672644\n",
      "\tspeed: 0.1663s/iter; left time: 6234.8831s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0816749\n",
      "\tspeed: 0.1722s/iter; left time: 6441.3778s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0773285\n",
      "\tspeed: 0.1744s/iter; left time: 6506.6433s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0728730\n",
      "\tspeed: 0.1690s/iter; left time: 6288.0979s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0824114\n",
      "\tspeed: 0.1686s/iter; left time: 6253.9308s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0950189\n",
      "\tspeed: 0.1718s/iter; left time: 6357.0916s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0668211\n",
      "\tspeed: 0.1626s/iter; left time: 5998.2407s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0763555\n",
      "\tspeed: 0.1721s/iter; left time: 6334.6344s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0795991\n",
      "\tspeed: 0.1703s/iter; left time: 6248.3458s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0734470\n",
      "\tspeed: 0.1700s/iter; left time: 6221.0785s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0982762\n",
      "\tspeed: 0.1732s/iter; left time: 6321.2687s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0842159\n",
      "\tspeed: 0.1651s/iter; left time: 6009.1805s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0691988\n",
      "\tspeed: 0.1711s/iter; left time: 6211.8510s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0904626\n",
      "\tspeed: 0.1665s/iter; left time: 6026.8544s\n",
      "Epoch: 12 cost time: 00h:12m:45.52s\n",
      "Epoch: 12 | Train Loss: 0.0793893 Vali Loss: 0.0908461 Test Loss: 0.1042622\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0828625\n",
      "\tspeed: 2.4252s/iter; left time: 87495.1041s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761948\n",
      "\tspeed: 0.1740s/iter; left time: 6260.3003s\n",
      "\titers: 300, epoch: 13 | loss: 0.0854706\n",
      "\tspeed: 0.1689s/iter; left time: 6057.9036s\n",
      "\titers: 400, epoch: 13 | loss: 0.0830401\n",
      "\tspeed: 0.1714s/iter; left time: 6132.0188s\n",
      "\titers: 500, epoch: 13 | loss: 0.0558663\n",
      "\tspeed: 0.1702s/iter; left time: 6073.1300s\n",
      "\titers: 600, epoch: 13 | loss: 0.0797395\n",
      "\tspeed: 0.1729s/iter; left time: 6152.0690s\n",
      "\titers: 700, epoch: 13 | loss: 0.0741474\n",
      "\tspeed: 0.1769s/iter; left time: 6274.1349s\n",
      "\titers: 800, epoch: 13 | loss: 0.0685676\n",
      "\tspeed: 0.1641s/iter; left time: 5804.9373s\n",
      "\titers: 900, epoch: 13 | loss: 0.0850332\n",
      "\tspeed: 0.1656s/iter; left time: 5841.2692s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0721571\n",
      "\tspeed: 0.1664s/iter; left time: 5855.0050s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0790494\n",
      "\tspeed: 0.1662s/iter; left time: 5829.9493s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0886592\n",
      "\tspeed: 0.1680s/iter; left time: 5874.8073s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0788212\n",
      "\tspeed: 0.1658s/iter; left time: 5781.4375s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0977991\n",
      "\tspeed: 0.1695s/iter; left time: 5893.5914s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0741890\n",
      "\tspeed: 0.1696s/iter; left time: 5880.2743s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0666966\n",
      "\tspeed: 0.1665s/iter; left time: 5757.1314s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0775615\n",
      "\tspeed: 0.1683s/iter; left time: 5801.5830s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0784573\n",
      "\tspeed: 0.1754s/iter; left time: 6030.2741s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0739983\n",
      "\tspeed: 0.1729s/iter; left time: 5925.9278s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0874240\n",
      "\tspeed: 0.1713s/iter; left time: 5853.6576s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0780521\n",
      "\tspeed: 0.1636s/iter; left time: 5574.2223s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0660762\n",
      "\tspeed: 0.1648s/iter; left time: 5598.5455s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0791751\n",
      "\tspeed: 0.1662s/iter; left time: 5631.1144s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0736582\n",
      "\tspeed: 0.1687s/iter; left time: 5698.8965s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0868023\n",
      "\tspeed: 0.1689s/iter; left time: 5688.9160s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0714477\n",
      "\tspeed: 0.1717s/iter; left time: 5766.6191s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0896014\n",
      "\tspeed: 0.1728s/iter; left time: 5784.0259s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0806667\n",
      "\tspeed: 0.1698s/iter; left time: 5666.7149s\n",
      "\titers: 2900, epoch: 13 | loss: 0.0949710\n",
      "\tspeed: 0.1730s/iter; left time: 5757.3012s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0785853\n",
      "\tspeed: 0.1728s/iter; left time: 5734.3903s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0732998\n",
      "\tspeed: 0.1708s/iter; left time: 5648.6324s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0713127\n",
      "\tspeed: 0.1701s/iter; left time: 5610.2235s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0846587\n",
      "\tspeed: 0.1726s/iter; left time: 5674.4452s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0870544\n",
      "\tspeed: 0.1623s/iter; left time: 5319.2585s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0840417\n",
      "\tspeed: 0.1597s/iter; left time: 5219.1108s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0570664\n",
      "\tspeed: 0.1709s/iter; left time: 5567.6217s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0777416\n",
      "\tspeed: 0.1687s/iter; left time: 5478.0449s\n",
      "\titers: 3800, epoch: 13 | loss: 0.0890104\n",
      "\tspeed: 0.1691s/iter; left time: 5474.4358s\n",
      "\titers: 3900, epoch: 13 | loss: 0.0794047\n",
      "\tspeed: 0.1733s/iter; left time: 5594.1670s\n",
      "\titers: 4000, epoch: 13 | loss: 0.0880629\n",
      "\tspeed: 0.1722s/iter; left time: 5541.0599s\n",
      "\titers: 4100, epoch: 13 | loss: 0.0896522\n",
      "\tspeed: 0.1699s/iter; left time: 5448.8248s\n",
      "\titers: 4200, epoch: 13 | loss: 0.0959938\n",
      "\tspeed: 0.1728s/iter; left time: 5524.0507s\n",
      "\titers: 4300, epoch: 13 | loss: 0.0648573\n",
      "\tspeed: 0.1732s/iter; left time: 5520.0517s\n",
      "\titers: 4400, epoch: 13 | loss: 0.0792757\n",
      "\tspeed: 0.1705s/iter; left time: 5418.9427s\n",
      "\titers: 4500, epoch: 13 | loss: 0.0862645\n",
      "\tspeed: 0.1717s/iter; left time: 5439.9813s\n",
      "Epoch: 13 cost time: 00h:12m:47.29s\n",
      "Epoch: 13 | Train Loss: 0.0789282 Vali Loss: 0.0916574 Test Loss: 0.1043000\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0862479\n",
      "\tspeed: 2.4429s/iter; left time: 77087.1539s\n",
      "\titers: 200, epoch: 14 | loss: 0.0929791\n",
      "\tspeed: 0.1728s/iter; left time: 5434.8475s\n",
      "\titers: 300, epoch: 14 | loss: 0.0872652\n",
      "\tspeed: 0.1650s/iter; left time: 5173.2802s\n",
      "\titers: 400, epoch: 14 | loss: 0.0790730\n",
      "\tspeed: 0.1726s/iter; left time: 5393.0538s\n",
      "\titers: 500, epoch: 14 | loss: 0.0798667\n",
      "\tspeed: 0.1695s/iter; left time: 5280.2174s\n",
      "\titers: 600, epoch: 14 | loss: 0.0870462\n",
      "\tspeed: 0.1713s/iter; left time: 5321.2460s\n",
      "\titers: 700, epoch: 14 | loss: 0.0781257\n",
      "\tspeed: 0.1689s/iter; left time: 5227.2336s\n",
      "\titers: 800, epoch: 14 | loss: 0.0807388\n",
      "\tspeed: 0.1686s/iter; left time: 5202.2502s\n",
      "\titers: 900, epoch: 14 | loss: 0.0737816\n",
      "\tspeed: 0.1697s/iter; left time: 5220.6148s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0632163\n",
      "\tspeed: 0.1434s/iter; left time: 4394.5475s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0624120\n",
      "\tspeed: 0.1741s/iter; left time: 5318.9090s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0908479\n",
      "\tspeed: 0.1741s/iter; left time: 5303.2141s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0884307\n",
      "\tspeed: 0.1699s/iter; left time: 5157.9061s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0966090\n",
      "\tspeed: 0.1693s/iter; left time: 5123.2065s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0910187\n",
      "\tspeed: 0.1708s/iter; left time: 5151.4103s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0842152\n",
      "\tspeed: 0.1689s/iter; left time: 5076.6666s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0680420\n",
      "\tspeed: 0.1734s/iter; left time: 5193.7930s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0783114\n",
      "\tspeed: 0.1686s/iter; left time: 5034.7665s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0771680\n",
      "\tspeed: 0.1757s/iter; left time: 5227.8120s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0764729\n",
      "\tspeed: 0.1704s/iter; left time: 5054.2837s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0826777\n",
      "\tspeed: 0.1666s/iter; left time: 4922.7893s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0688765\n",
      "\tspeed: 0.1735s/iter; left time: 5110.9742s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0673212\n",
      "\tspeed: 0.1684s/iter; left time: 4943.9856s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0669931\n",
      "\tspeed: 0.1689s/iter; left time: 4939.8577s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0696051\n",
      "\tspeed: 0.1646s/iter; left time: 4798.2729s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0890780\n",
      "\tspeed: 0.1734s/iter; left time: 5039.4689s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0850373\n",
      "\tspeed: 0.1727s/iter; left time: 5001.4870s\n",
      "\titers: 2800, epoch: 14 | loss: 0.0627210\n",
      "\tspeed: 0.1699s/iter; left time: 4903.7129s\n",
      "\titers: 2900, epoch: 14 | loss: 0.0816607\n",
      "\tspeed: 0.1684s/iter; left time: 4841.9343s\n",
      "\titers: 3000, epoch: 14 | loss: 0.0787969\n",
      "\tspeed: 0.1707s/iter; left time: 4891.6913s\n",
      "\titers: 3100, epoch: 14 | loss: 0.0859138\n",
      "\tspeed: 0.1723s/iter; left time: 4920.2910s\n",
      "\titers: 3200, epoch: 14 | loss: 0.0655041\n",
      "\tspeed: 0.1705s/iter; left time: 4850.9386s\n",
      "\titers: 3300, epoch: 14 | loss: 0.0723302\n",
      "\tspeed: 0.1696s/iter; left time: 4809.7386s\n",
      "\titers: 3400, epoch: 14 | loss: 0.0746566\n",
      "\tspeed: 0.1727s/iter; left time: 4878.5541s\n",
      "\titers: 3500, epoch: 14 | loss: 0.0754057\n",
      "\tspeed: 0.1690s/iter; left time: 4759.0661s\n",
      "\titers: 3600, epoch: 14 | loss: 0.0662484\n",
      "\tspeed: 0.1706s/iter; left time: 4785.1637s\n",
      "\titers: 3700, epoch: 14 | loss: 0.0888090\n",
      "\tspeed: 0.1687s/iter; left time: 4716.9448s\n",
      "\titers: 3800, epoch: 14 | loss: 0.0801051\n",
      "\tspeed: 0.1727s/iter; left time: 4809.2633s\n",
      "\titers: 3900, epoch: 14 | loss: 0.0925022\n",
      "\tspeed: 0.1686s/iter; left time: 4678.9711s\n",
      "\titers: 4000, epoch: 14 | loss: 0.0810050\n",
      "\tspeed: 0.1661s/iter; left time: 4592.2544s\n",
      "\titers: 4100, epoch: 14 | loss: 0.0796938\n",
      "\tspeed: 0.1621s/iter; left time: 4465.4925s\n",
      "\titers: 4200, epoch: 14 | loss: 0.0838220\n",
      "\tspeed: 0.1683s/iter; left time: 4621.4533s\n",
      "\titers: 4300, epoch: 14 | loss: 0.0709347\n",
      "\tspeed: 0.1620s/iter; left time: 4432.5704s\n",
      "\titers: 4400, epoch: 14 | loss: 0.0886179\n",
      "\tspeed: 0.1693s/iter; left time: 4615.2776s\n",
      "\titers: 4500, epoch: 14 | loss: 0.0927915\n",
      "\tspeed: 0.1663s/iter; left time: 4516.0464s\n",
      "Epoch: 14 cost time: 00h:12m:44.92s\n",
      "Epoch: 14 | Train Loss: 0.0784303 Vali Loss: 0.0913144 Test Loss: 0.1032160\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0756961\n",
      "\tspeed: 1.3472s/iter; left time: 36418.0261s\n",
      "\titers: 200, epoch: 15 | loss: 0.0908340\n",
      "\tspeed: 0.1068s/iter; left time: 2876.5130s\n",
      "\titers: 300, epoch: 15 | loss: 0.0840369\n",
      "\tspeed: 0.1084s/iter; left time: 2908.1657s\n",
      "\titers: 400, epoch: 15 | loss: 0.0728095\n",
      "\tspeed: 0.1041s/iter; left time: 2783.7970s\n",
      "\titers: 500, epoch: 15 | loss: 0.0974264\n",
      "\tspeed: 0.1094s/iter; left time: 2913.8806s\n",
      "\titers: 600, epoch: 15 | loss: 0.0748131\n",
      "\tspeed: 0.1056s/iter; left time: 2802.7716s\n",
      "\titers: 700, epoch: 15 | loss: 0.0934618\n",
      "\tspeed: 0.1059s/iter; left time: 2799.1066s\n",
      "\titers: 800, epoch: 15 | loss: 0.0825719\n",
      "\tspeed: 0.1045s/iter; left time: 2750.8404s\n",
      "\titers: 900, epoch: 15 | loss: 0.0783047\n",
      "\tspeed: 0.1108s/iter; left time: 2906.7824s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0721981\n",
      "\tspeed: 0.1093s/iter; left time: 2855.1854s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0657327\n",
      "\tspeed: 0.1059s/iter; left time: 2758.1815s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0914479\n",
      "\tspeed: 0.1088s/iter; left time: 2821.5158s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0746830\n",
      "\tspeed: 0.1059s/iter; left time: 2736.0977s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0827060\n",
      "\tspeed: 0.1040s/iter; left time: 2675.6407s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0725726\n",
      "\tspeed: 0.1032s/iter; left time: 2645.0868s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0758337\n",
      "\tspeed: 0.1031s/iter; left time: 2633.2891s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0937937\n",
      "\tspeed: 0.1033s/iter; left time: 2627.2909s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0881181\n",
      "\tspeed: 0.1029s/iter; left time: 2607.0418s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0715219\n",
      "\tspeed: 0.1037s/iter; left time: 2617.4382s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0725022\n",
      "\tspeed: 0.1089s/iter; left time: 2737.5818s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0693211\n",
      "\tspeed: 0.1047s/iter; left time: 2621.8007s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0602588\n",
      "\tspeed: 0.1085s/iter; left time: 2704.1601s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0830197\n",
      "\tspeed: 0.1004s/iter; left time: 2493.6474s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0761788\n",
      "\tspeed: 0.1052s/iter; left time: 2602.3993s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0930502\n",
      "\tspeed: 0.1084s/iter; left time: 2671.1236s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0768251\n",
      "\tspeed: 0.1043s/iter; left time: 2559.6034s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0777380\n",
      "\tspeed: 0.1027s/iter; left time: 2510.3665s\n",
      "\titers: 2800, epoch: 15 | loss: 0.0849680\n",
      "\tspeed: 0.1010s/iter; left time: 2457.0264s\n",
      "\titers: 2900, epoch: 15 | loss: 0.0761159\n",
      "\tspeed: 0.1076s/iter; left time: 2606.8259s\n",
      "\titers: 3000, epoch: 15 | loss: 0.0833037\n",
      "\tspeed: 0.1061s/iter; left time: 2559.6482s\n",
      "\titers: 3100, epoch: 15 | loss: 0.0838155\n",
      "\tspeed: 0.1002s/iter; left time: 2407.9244s\n",
      "\titers: 3200, epoch: 15 | loss: 0.0777401\n",
      "\tspeed: 0.1048s/iter; left time: 2508.1678s\n",
      "\titers: 3300, epoch: 15 | loss: 0.0696319\n",
      "\tspeed: 0.1067s/iter; left time: 2543.0045s\n",
      "\titers: 3400, epoch: 15 | loss: 0.0610953\n",
      "\tspeed: 0.1095s/iter; left time: 2598.9736s\n",
      "\titers: 3500, epoch: 15 | loss: 0.0851496\n",
      "\tspeed: 0.1143s/iter; left time: 2701.9537s\n",
      "\titers: 3600, epoch: 15 | loss: 0.0959173\n",
      "\tspeed: 0.1179s/iter; left time: 2773.4689s\n",
      "\titers: 3700, epoch: 15 | loss: 0.0619716\n",
      "\tspeed: 0.1160s/iter; left time: 2717.8305s\n",
      "\titers: 3800, epoch: 15 | loss: 0.0799209\n",
      "\tspeed: 0.1097s/iter; left time: 2560.2253s\n",
      "\titers: 3900, epoch: 15 | loss: 0.0844750\n",
      "\tspeed: 0.1129s/iter; left time: 2622.5282s\n",
      "\titers: 4000, epoch: 15 | loss: 0.0856483\n",
      "\tspeed: 0.1082s/iter; left time: 2502.2183s\n",
      "\titers: 4100, epoch: 15 | loss: 0.0681085\n",
      "\tspeed: 0.0959s/iter; left time: 2209.9737s\n",
      "\titers: 4200, epoch: 15 | loss: 0.0749832\n",
      "\tspeed: 0.1032s/iter; left time: 2366.9222s\n",
      "\titers: 4300, epoch: 15 | loss: 0.0860602\n",
      "\tspeed: 0.1026s/iter; left time: 2343.2065s\n",
      "\titers: 4400, epoch: 15 | loss: 0.0639368\n",
      "\tspeed: 0.1048s/iter; left time: 2382.7050s\n",
      "\titers: 4500, epoch: 15 | loss: 0.0752324\n",
      "\tspeed: 0.1056s/iter; left time: 2390.3518s\n",
      "Epoch: 15 cost time: 00h:08m:01.30s\n",
      "Epoch: 15 | Train Loss: 0.0780048 Vali Loss: 0.0921507 Test Loss: 0.1048814\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.025825485587120056, rmse:0.16070309281349182, mae:0.1029878556728363, rse:0.5540986657142639\n",
      "success delete checkpoints\n",
      "Intermediate time for GB and pred_len 24: 03h:05m:58.12s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 144365\n",
      "val 30725\n",
      "test 30725\n",
      "[2024-11-06 15:27:19,649] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 15:27:20,803] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 15:27:20,803] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 15:27:20,803] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 15:27:20,896] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 15:27:20,897] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 15:27:21,559] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 15:27:21,560] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 15:27:21,560] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 15:27:21,561] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 15:27:21,561] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 15:27:21,561] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 15:27:21,561] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 15:27:21,561] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 15:27:21,561] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 15:27:21,561] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 15:27:21,893] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 15:27:21,894] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 15:27:21,894] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 298.71 GB, percent = 39.6%\n",
      "[2024-11-06 15:27:22,023] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 15:27:22,024] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 15:27:22,024] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 298.72 GB, percent = 39.6%\n",
      "[2024-11-06 15:27:22,024] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 15:27:22,142] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 15:27:22,143] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 15:27:22,143] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 298.72 GB, percent = 39.6%\n",
      "[2024-11-06 15:27:22,144] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 15:27:22,144] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 15:27:22,144] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 15:27:22,144] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 15:27:22,145] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 15:27:22,145] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 15:27:22,145] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 15:27:22,145] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 15:27:22,145] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f27f5bfb3d0>\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 15:27:22,146] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 15:27:22,147] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 15:27:22,148] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 15:27:22,148] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 15:27:22,148] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 15:27:22,148] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 15:27:22,148] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1578747\n",
      "\tspeed: 0.1658s/iter; left time: 14943.1825s\n",
      "\titers: 200, epoch: 1 | loss: 0.1483559\n",
      "\tspeed: 0.1111s/iter; left time: 9999.6229s\n",
      "\titers: 300, epoch: 1 | loss: 0.1512303\n",
      "\tspeed: 0.1175s/iter; left time: 10568.9696s\n",
      "\titers: 400, epoch: 1 | loss: 0.1303197\n",
      "\tspeed: 0.1176s/iter; left time: 10565.7986s\n",
      "\titers: 500, epoch: 1 | loss: 0.1562822\n",
      "\tspeed: 0.1185s/iter; left time: 10629.6650s\n",
      "\titers: 600, epoch: 1 | loss: 0.1543407\n",
      "\tspeed: 0.1200s/iter; left time: 10752.8884s\n",
      "\titers: 700, epoch: 1 | loss: 0.1259072\n",
      "\tspeed: 0.1212s/iter; left time: 10851.7288s\n",
      "\titers: 800, epoch: 1 | loss: 0.0986906\n",
      "\tspeed: 0.1196s/iter; left time: 10698.1184s\n",
      "\titers: 900, epoch: 1 | loss: 0.1067305\n",
      "\tspeed: 0.1164s/iter; left time: 10394.6875s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1112273\n",
      "\tspeed: 0.1194s/iter; left time: 10651.5522s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1186275\n",
      "\tspeed: 0.1169s/iter; left time: 10415.2345s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1165712\n",
      "\tspeed: 0.1188s/iter; left time: 10576.6056s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1079068\n",
      "\tspeed: 0.1171s/iter; left time: 10412.8264s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1263480\n",
      "\tspeed: 0.1144s/iter; left time: 10157.6476s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1087909\n",
      "\tspeed: 0.1185s/iter; left time: 10512.8781s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1264592\n",
      "\tspeed: 0.1216s/iter; left time: 10773.3858s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1225194\n",
      "\tspeed: 0.1209s/iter; left time: 10702.9805s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0932906\n",
      "\tspeed: 0.1190s/iter; left time: 10524.2024s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0978703\n",
      "\tspeed: 0.1155s/iter; left time: 10199.1234s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1174607\n",
      "\tspeed: 0.1179s/iter; left time: 10405.5240s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0919814\n",
      "\tspeed: 0.1164s/iter; left time: 10258.5585s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1084685\n",
      "\tspeed: 0.1189s/iter; left time: 10468.7173s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1205536\n",
      "\tspeed: 0.1136s/iter; left time: 9989.0386s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1130412\n",
      "\tspeed: 0.1134s/iter; left time: 9954.9972s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1101397\n",
      "\tspeed: 0.1187s/iter; left time: 10410.4817s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1077240\n",
      "\tspeed: 0.1222s/iter; left time: 10706.5072s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1191691\n",
      "\tspeed: 0.1171s/iter; left time: 10251.6542s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1085926\n",
      "\tspeed: 0.1146s/iter; left time: 10014.2662s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1238528\n",
      "\tspeed: 0.1179s/iter; left time: 10291.4014s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1375330\n",
      "\tspeed: 0.1203s/iter; left time: 10496.8264s\n",
      "\titers: 3100, epoch: 1 | loss: 0.1392304\n",
      "\tspeed: 0.1185s/iter; left time: 10324.1242s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1192045\n",
      "\tspeed: 0.1148s/iter; left time: 9988.8672s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1277311\n",
      "\tspeed: 0.1113s/iter; left time: 9671.2631s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1106551\n",
      "\tspeed: 0.1126s/iter; left time: 9771.8090s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1227020\n",
      "\tspeed: 0.1189s/iter; left time: 10309.4808s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1206678\n",
      "\tspeed: 0.1165s/iter; left time: 10091.9348s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0850386\n",
      "\tspeed: 0.1160s/iter; left time: 10033.6870s\n",
      "\titers: 3800, epoch: 1 | loss: 0.1003203\n",
      "\tspeed: 0.1161s/iter; left time: 10033.2219s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1264647\n",
      "\tspeed: 0.1167s/iter; left time: 10077.1306s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0900657\n",
      "\tspeed: 0.1213s/iter; left time: 10456.8792s\n",
      "\titers: 4100, epoch: 1 | loss: 0.1103826\n",
      "\tspeed: 0.1181s/iter; left time: 10174.4669s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1286094\n",
      "\tspeed: 0.1157s/iter; left time: 9948.5053s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1134891\n",
      "\tspeed: 0.1175s/iter; left time: 10093.9578s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1263199\n",
      "\tspeed: 0.1129s/iter; left time: 9689.4826s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0981153\n",
      "\tspeed: 0.1164s/iter; left time: 9976.5490s\n",
      "Epoch: 1 cost time: 00h:08m:50.33s\n",
      "Epoch: 1 | Train Loss: 0.1201085 Vali Loss: 0.1199118 Test Loss: 0.1435089\n",
      "Validation loss decreased (inf --> 0.119912).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1068584\n",
      "\tspeed: 1.5215s/iter; left time: 130255.0428s\n",
      "\titers: 200, epoch: 2 | loss: 0.1054993\n",
      "\tspeed: 0.1057s/iter; left time: 9035.4987s\n",
      "\titers: 300, epoch: 2 | loss: 0.1160948\n",
      "\tspeed: 0.1071s/iter; left time: 9148.6813s\n",
      "\titers: 400, epoch: 2 | loss: 0.1063587\n",
      "\tspeed: 0.1055s/iter; left time: 8999.7213s\n",
      "\titers: 500, epoch: 2 | loss: 0.1156852\n",
      "\tspeed: 0.1078s/iter; left time: 9188.4021s\n",
      "\titers: 600, epoch: 2 | loss: 0.0920816\n",
      "\tspeed: 0.1074s/iter; left time: 9143.0877s\n",
      "\titers: 700, epoch: 2 | loss: 0.1118872\n",
      "\tspeed: 0.1062s/iter; left time: 9028.2295s\n",
      "\titers: 800, epoch: 2 | loss: 0.1072514\n",
      "\tspeed: 0.1052s/iter; left time: 8931.9439s\n",
      "\titers: 900, epoch: 2 | loss: 0.1134854\n",
      "\tspeed: 0.1124s/iter; left time: 9531.7013s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1240677\n",
      "\tspeed: 0.1116s/iter; left time: 9449.9349s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1197729\n",
      "\tspeed: 0.1062s/iter; left time: 8985.3556s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1017799\n",
      "\tspeed: 0.1075s/iter; left time: 9087.4772s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1179697\n",
      "\tspeed: 0.1097s/iter; left time: 9255.8951s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1258223\n",
      "\tspeed: 0.0957s/iter; left time: 8064.4970s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1032963\n",
      "\tspeed: 0.0989s/iter; left time: 8326.3066s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1282105\n",
      "\tspeed: 0.1018s/iter; left time: 8562.4715s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0975740\n",
      "\tspeed: 0.1063s/iter; left time: 8933.6227s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1257129\n",
      "\tspeed: 0.1091s/iter; left time: 9154.9240s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1061594\n",
      "\tspeed: 0.1093s/iter; left time: 9160.4996s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1015071\n",
      "\tspeed: 0.1083s/iter; left time: 9068.5641s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1074817\n",
      "\tspeed: 0.1076s/iter; left time: 8998.0022s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1077646\n",
      "\tspeed: 0.1066s/iter; left time: 8905.4260s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1056566\n",
      "\tspeed: 0.1103s/iter; left time: 9196.8914s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0945622\n",
      "\tspeed: 0.1086s/iter; left time: 9043.5627s\n",
      "\titers: 2500, epoch: 2 | loss: 0.1238128\n",
      "\tspeed: 0.1044s/iter; left time: 8686.3303s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0920877\n",
      "\tspeed: 0.1064s/iter; left time: 8843.2245s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1182382\n",
      "\tspeed: 0.1080s/iter; left time: 8968.3491s\n",
      "\titers: 2800, epoch: 2 | loss: 0.1102911\n",
      "\tspeed: 0.1054s/iter; left time: 8735.2357s\n",
      "\titers: 2900, epoch: 2 | loss: 0.1129152\n",
      "\tspeed: 0.1074s/iter; left time: 8894.2921s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0990750\n",
      "\tspeed: 0.1108s/iter; left time: 9160.6352s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1422526\n",
      "\tspeed: 0.1072s/iter; left time: 8856.8412s\n",
      "\titers: 3200, epoch: 2 | loss: 0.1065452\n",
      "\tspeed: 0.1059s/iter; left time: 8735.7540s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1221989\n",
      "\tspeed: 0.1090s/iter; left time: 8980.7620s\n",
      "\titers: 3400, epoch: 2 | loss: 0.1070510\n",
      "\tspeed: 0.1101s/iter; left time: 9066.2097s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1095591\n",
      "\tspeed: 0.1071s/iter; left time: 8801.0001s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0983607\n",
      "\tspeed: 0.1047s/iter; left time: 8593.0377s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1162319\n",
      "\tspeed: 0.1110s/iter; left time: 9105.8407s\n",
      "\titers: 3800, epoch: 2 | loss: 0.1189640\n",
      "\tspeed: 0.1067s/iter; left time: 8738.1584s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1236529\n",
      "\tspeed: 0.1114s/iter; left time: 9112.7546s\n",
      "\titers: 4000, epoch: 2 | loss: 0.1346954\n",
      "\tspeed: 0.1068s/iter; left time: 8726.8186s\n",
      "\titers: 4100, epoch: 2 | loss: 0.1188537\n",
      "\tspeed: 0.1051s/iter; left time: 8580.6491s\n",
      "\titers: 4200, epoch: 2 | loss: 0.1036363\n",
      "\tspeed: 0.1104s/iter; left time: 8999.7312s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1099509\n",
      "\tspeed: 0.1066s/iter; left time: 8677.6927s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1071798\n",
      "\tspeed: 0.1103s/iter; left time: 8967.4946s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1060575\n",
      "\tspeed: 0.1037s/iter; left time: 8423.1219s\n",
      "Epoch: 2 cost time: 00h:08m:03.81s\n",
      "Epoch: 2 | Train Loss: 0.1108174 Vali Loss: 0.1193256 Test Loss: 0.1437099\n",
      "Validation loss decreased (0.119912 --> 0.119326).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1108726\n",
      "\tspeed: 1.3534s/iter; left time: 109756.1608s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028282\n",
      "\tspeed: 0.1097s/iter; left time: 8882.5518s\n",
      "\titers: 300, epoch: 3 | loss: 0.0863734\n",
      "\tspeed: 0.1087s/iter; left time: 8797.5649s\n",
      "\titers: 400, epoch: 3 | loss: 0.1141455\n",
      "\tspeed: 0.1075s/iter; left time: 8683.1994s\n",
      "\titers: 500, epoch: 3 | loss: 0.1108244\n",
      "\tspeed: 0.1048s/iter; left time: 8457.6589s\n",
      "\titers: 600, epoch: 3 | loss: 0.1196987\n",
      "\tspeed: 0.0982s/iter; left time: 7913.6699s\n",
      "\titers: 700, epoch: 3 | loss: 0.0919497\n",
      "\tspeed: 0.1082s/iter; left time: 8706.1801s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945634\n",
      "\tspeed: 0.1102s/iter; left time: 8863.9841s\n",
      "\titers: 900, epoch: 3 | loss: 0.1061330\n",
      "\tspeed: 0.1050s/iter; left time: 8431.9437s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1213995\n",
      "\tspeed: 0.1060s/iter; left time: 8504.3718s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0878855\n",
      "\tspeed: 0.1032s/iter; left time: 8269.5459s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0900434\n",
      "\tspeed: 0.1102s/iter; left time: 8817.2955s\n",
      "\titers: 1300, epoch: 3 | loss: 0.1021680\n",
      "\tspeed: 0.1087s/iter; left time: 8682.3610s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0978348\n",
      "\tspeed: 0.1101s/iter; left time: 8787.2139s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1136288\n",
      "\tspeed: 0.1090s/iter; left time: 8686.8433s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1160478\n",
      "\tspeed: 0.1120s/iter; left time: 8911.7293s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1179800\n",
      "\tspeed: 0.1103s/iter; left time: 8771.9721s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1174511\n",
      "\tspeed: 0.1077s/iter; left time: 8553.7359s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1162669\n",
      "\tspeed: 0.1086s/iter; left time: 8612.7862s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1141066\n",
      "\tspeed: 0.1135s/iter; left time: 8986.9478s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0895124\n",
      "\tspeed: 0.1132s/iter; left time: 8953.4781s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0870877\n",
      "\tspeed: 0.1083s/iter; left time: 8554.4165s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1164704\n",
      "\tspeed: 0.1048s/iter; left time: 8269.9145s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0841451\n",
      "\tspeed: 0.1092s/iter; left time: 8603.3969s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Capture and log output in real-time\u001b[39;00m\n\u001b[1;32m     54\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 55\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DE 24 mae:0.09314965456724167\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'FR',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.010154812596738338,\n",
       "  'RMSE': 0.10077109187841415,\n",
       "  'MAE': 0.05653735250234604},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.019628532230854034,\n",
       "  'RMSE': 0.1401018649339676,\n",
       "  'MAE': 0.08128844946622849},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.02272237464785576,\n",
       "  'RMSE': 0.15073943138122559,\n",
       "  'MAE': 0.08884815871715546},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.010610697790980339,\n",
       "  'RMSE': 0.10300824046134949,\n",
       "  'MAE': 0.05985838919878006},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.01913185976445675,\n",
       "  'RMSE': 0.13831797242164612,\n",
       "  'MAE': 0.08287986367940903},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.020030096173286438,\n",
       "  'RMSE': 0.14152772724628448,\n",
       "  'MAE': 0.08731971681118011},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.022713396698236465,\n",
       "  'RMSE': 0.15070964395999908,\n",
       "  'MAE': 0.09314965456724167},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.03904155269265175,\n",
       "  'RMSE': 0.19758935272693634,\n",
       "  'MAE': 0.1312127262353897},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.04313361272215843,\n",
       "  'RMSE': 0.20768633484840393,\n",
       "  'MAE': 0.13920451700687408},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.025825485587120056,\n",
       "  'RMSE': 0.16070309281349182,\n",
       "  'MAE': 0.1029878556728363}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [{'Country': 'DE',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.022713396698236465,\n",
    "  'RMSE': 0.15070964395999908,\n",
    "  'MAE': 0.09314965456724167},\n",
    " {'Country': 'DE',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.03904155269265175,\n",
    "  'RMSE': 0.19758935272693634,\n",
    "  'MAE': 0.1312127262353897},\n",
    " {'Country': 'DE',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.04313361272215843,\n",
    "  'RMSE': 0.20768633484840393,\n",
    "  'MAE': 0.13920451700687408},\n",
    " {'Country': 'GB',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.025825485587120056,\n",
    "  'RMSE': 0.16070309281349182,\n",
    "  'MAE': 0.1029878556728363},\n",
    "  {'Country': 'GB',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.04658650979399681,\n",
    "  'RMSE': 0.21583908796310425,\n",
    "  'MAE': 0.14624564349651337},\n",
    " {'Country': 'GB',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.04751771315932274,\n",
    "  'RMSE': 0.2179855853319168,\n",
    "  'MAE': 0.1499413400888443},\n",
    "{'Country': 'ES',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.01031138002872467,\n",
    "  'RMSE': 0.10154496878385544,\n",
    "  'MAE': 0.06399503350257874},\n",
    " {'Country': 'ES',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.01997840777039528,\n",
    "  'RMSE': 0.14134499430656433,\n",
    "  'MAE': 0.09172166138887405},\n",
    " {'Country': 'ES',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.022127792239189148,\n",
    "  'RMSE': 0.14875413477420807,\n",
    "  'MAE': 0.09595496952533722},\n",
    "  {'Country': 'FR',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.010154812596738338,\n",
    "  'RMSE': 0.10077109187841415,\n",
    "  'MAE': 0.05653735250234604},\n",
    " {'Country': 'FR',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.019628532230854034,\n",
    "  'RMSE': 0.1401018649339676,\n",
    "  'MAE': 0.08128844946622849},\n",
    " {'Country': 'FR',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.02272237464785576,\n",
    "  'RMSE': 0.15073943138122559,\n",
    "  'MAE': 0.08884815871715546},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.010610697790980339,\n",
    "  'RMSE': 0.10300824046134949,\n",
    "  'MAE': 0.05985838919878006},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.01913185976445675,\n",
    "  'RMSE': 0.13831797242164612,\n",
    "  'MAE': 0.08287986367940903},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.020030096173286438,\n",
    "  'RMSE': 0.14152772724628448,\n",
    "  'MAE': 0.08731971681118011}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [96, 168]\n",
    "countries = ['GB']\n",
    "num_cols = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 144365\n",
      "val 30725\n",
      "test 30725\n",
      "[2024-11-06 16:01:54,342] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 16:01:55,406] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 16:01:55,406] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 16:01:55,406] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 16:01:55,502] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 16:01:55,502] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 16:01:56,175] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 16:01:56,176] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 16:01:56,176] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 16:01:56,178] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 16:01:56,178] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 16:01:56,178] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 16:01:56,178] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 16:01:56,178] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 16:01:56,178] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 16:01:56,178] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 16:01:56,475] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 16:01:56,476] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 16:01:56,477] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 180.48 GB, percent = 23.9%\n",
      "[2024-11-06 16:01:56,604] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 16:01:56,605] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 16:01:56,606] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 180.48 GB, percent = 23.9%\n",
      "[2024-11-06 16:01:56,606] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 16:01:56,738] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 16:01:56,739] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 16:01:56,739] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 180.48 GB, percent = 23.9%\n",
      "[2024-11-06 16:01:56,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 16:01:56,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 16:01:56,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 16:01:56,740] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 16:01:56,741] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8c41377910>\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 16:01:56,742] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 16:01:56,743] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 16:01:56,744] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1578747\n",
      "\tspeed: 0.1602s/iter; left time: 14440.3914s\n",
      "\titers: 200, epoch: 1 | loss: 0.1483559\n",
      "\tspeed: 0.1219s/iter; left time: 10973.4428s\n",
      "\titers: 300, epoch: 1 | loss: 0.1512303\n",
      "\tspeed: 0.1195s/iter; left time: 10743.3548s\n",
      "\titers: 400, epoch: 1 | loss: 0.1303197\n",
      "\tspeed: 0.1139s/iter; left time: 10234.3044s\n",
      "\titers: 500, epoch: 1 | loss: 0.1562822\n",
      "\tspeed: 0.1224s/iter; left time: 10986.3197s\n",
      "\titers: 600, epoch: 1 | loss: 0.1543407\n",
      "\tspeed: 0.1254s/iter; left time: 11234.3766s\n",
      "\titers: 700, epoch: 1 | loss: 0.1259072\n",
      "\tspeed: 0.1242s/iter; left time: 11115.5567s\n",
      "\titers: 800, epoch: 1 | loss: 0.0986906\n",
      "\tspeed: 0.1212s/iter; left time: 10834.9478s\n",
      "\titers: 900, epoch: 1 | loss: 0.1067305\n",
      "\tspeed: 0.1190s/iter; left time: 10627.6977s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1112273\n",
      "\tspeed: 0.1224s/iter; left time: 10919.2947s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1186275\n",
      "\tspeed: 0.1189s/iter; left time: 10596.9674s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1165712\n",
      "\tspeed: 0.1151s/iter; left time: 10243.7606s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1079068\n",
      "\tspeed: 0.1155s/iter; left time: 10271.7484s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1263480\n",
      "\tspeed: 0.1193s/iter; left time: 10595.1089s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1087909\n",
      "\tspeed: 0.1089s/iter; left time: 9664.8996s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1264592\n",
      "\tspeed: 0.1200s/iter; left time: 10637.5981s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1225194\n",
      "\tspeed: 0.1171s/iter; left time: 10366.1749s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0932906\n",
      "\tspeed: 0.1195s/iter; left time: 10563.6078s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0978703\n",
      "\tspeed: 0.1118s/iter; left time: 9878.6339s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1174607\n",
      "\tspeed: 0.1166s/iter; left time: 10287.3907s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0919814\n",
      "\tspeed: 0.1149s/iter; left time: 10126.1387s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1084685\n",
      "\tspeed: 0.1226s/iter; left time: 10787.5121s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1205536\n",
      "\tspeed: 0.1138s/iter; left time: 10001.9302s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1130412\n",
      "\tspeed: 0.1202s/iter; left time: 10558.0875s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1101397\n",
      "\tspeed: 0.1190s/iter; left time: 10439.7511s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1077240\n",
      "\tspeed: 0.1214s/iter; left time: 10639.2564s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1191691\n",
      "\tspeed: 0.1222s/iter; left time: 10698.7354s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1085926\n",
      "\tspeed: 0.1173s/iter; left time: 10255.0319s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1238528\n",
      "\tspeed: 0.1185s/iter; left time: 10345.9920s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1375330\n",
      "\tspeed: 0.1124s/iter; left time: 9805.9254s\n",
      "\titers: 3100, epoch: 1 | loss: 0.1392304\n",
      "\tspeed: 0.1194s/iter; left time: 10402.7669s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1192045\n",
      "\tspeed: 0.1212s/iter; left time: 10546.1565s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1277311\n",
      "\tspeed: 0.1213s/iter; left time: 10547.4926s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1106551\n",
      "\tspeed: 0.1143s/iter; left time: 9925.5932s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1227020\n",
      "\tspeed: 0.1159s/iter; left time: 10049.7549s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1206678\n",
      "\tspeed: 0.1190s/iter; left time: 10303.8337s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0850386\n",
      "\tspeed: 0.1213s/iter; left time: 10494.4968s\n",
      "\titers: 3800, epoch: 1 | loss: 0.1003203\n",
      "\tspeed: 0.1183s/iter; left time: 10225.7580s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1264647\n",
      "\tspeed: 0.1181s/iter; left time: 10195.8850s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0900657\n",
      "\tspeed: 0.1123s/iter; left time: 9680.6952s\n",
      "\titers: 4100, epoch: 1 | loss: 0.1103826\n",
      "\tspeed: 0.1194s/iter; left time: 10279.2567s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1286094\n",
      "\tspeed: 0.1181s/iter; left time: 10161.8075s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1134891\n",
      "\tspeed: 0.1201s/iter; left time: 10321.8045s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1263199\n",
      "\tspeed: 0.1170s/iter; left time: 10042.3087s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0981153\n",
      "\tspeed: 0.1210s/iter; left time: 10375.5859s\n",
      "Epoch: 1 cost time: 00h:08m:55.71s\n",
      "Epoch: 1 | Train Loss: 0.1201085 Vali Loss: 0.1199118 Test Loss: 0.1435089\n",
      "Validation loss decreased (inf --> 0.119912).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1068584\n",
      "\tspeed: 1.5612s/iter; left time: 133657.3946s\n",
      "\titers: 200, epoch: 2 | loss: 0.1054993\n",
      "\tspeed: 0.1116s/iter; left time: 9538.7824s\n",
      "\titers: 300, epoch: 2 | loss: 0.1160948\n",
      "\tspeed: 0.1127s/iter; left time: 9621.6787s\n",
      "\titers: 400, epoch: 2 | loss: 0.1063587\n",
      "\tspeed: 0.1108s/iter; left time: 9455.9315s\n",
      "\titers: 500, epoch: 2 | loss: 0.1156852\n",
      "\tspeed: 0.1087s/iter; left time: 9258.9801s\n",
      "\titers: 600, epoch: 2 | loss: 0.0920816\n",
      "\tspeed: 0.1074s/iter; left time: 9138.3788s\n",
      "\titers: 700, epoch: 2 | loss: 0.1118872\n",
      "\tspeed: 0.1074s/iter; left time: 9134.1969s\n",
      "\titers: 800, epoch: 2 | loss: 0.1072514\n",
      "\tspeed: 0.1098s/iter; left time: 9326.3089s\n",
      "\titers: 900, epoch: 2 | loss: 0.1134854\n",
      "\tspeed: 0.1071s/iter; left time: 9081.9136s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1240677\n",
      "\tspeed: 0.1095s/iter; left time: 9276.0419s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1197729\n",
      "\tspeed: 0.1100s/iter; left time: 9308.4185s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1017799\n",
      "\tspeed: 0.1096s/iter; left time: 9261.2423s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1179697\n",
      "\tspeed: 0.1068s/iter; left time: 9013.3012s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1258223\n",
      "\tspeed: 0.1111s/iter; left time: 9363.4089s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1032963\n",
      "\tspeed: 0.1111s/iter; left time: 9353.1239s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1282105\n",
      "\tspeed: 0.1129s/iter; left time: 9492.6534s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0975740\n",
      "\tspeed: 0.1123s/iter; left time: 9437.5664s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1257129\n",
      "\tspeed: 0.1091s/iter; left time: 9153.5590s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1061594\n",
      "\tspeed: 0.1100s/iter; left time: 9220.0857s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1015071\n",
      "\tspeed: 0.1094s/iter; left time: 9158.7963s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1074817\n",
      "\tspeed: 0.1123s/iter; left time: 9393.3649s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1077646\n",
      "\tspeed: 0.1099s/iter; left time: 9175.8185s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1056566\n",
      "\tspeed: 0.1075s/iter; left time: 8965.0692s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0945622\n",
      "\tspeed: 0.1094s/iter; left time: 9116.7512s\n",
      "\titers: 2500, epoch: 2 | loss: 0.1238128\n",
      "\tspeed: 0.1100s/iter; left time: 9156.2536s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0920877\n",
      "\tspeed: 0.1122s/iter; left time: 9323.8031s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1182382\n",
      "\tspeed: 0.1076s/iter; left time: 8931.6902s\n",
      "\titers: 2800, epoch: 2 | loss: 0.1102911\n",
      "\tspeed: 0.1083s/iter; left time: 8981.3637s\n",
      "\titers: 2900, epoch: 2 | loss: 0.1129152\n",
      "\tspeed: 0.1072s/iter; left time: 8880.7369s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0990750\n",
      "\tspeed: 0.1051s/iter; left time: 8696.8576s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1422526\n",
      "\tspeed: 0.1121s/iter; left time: 9259.6868s\n",
      "\titers: 3200, epoch: 2 | loss: 0.1065452\n",
      "\tspeed: 0.1081s/iter; left time: 8922.0671s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1221989\n",
      "\tspeed: 0.1092s/iter; left time: 8998.3694s\n",
      "\titers: 3400, epoch: 2 | loss: 0.1070510\n",
      "\tspeed: 0.1075s/iter; left time: 8845.3211s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1095591\n",
      "\tspeed: 0.1077s/iter; left time: 8852.2463s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0983607\n",
      "\tspeed: 0.1118s/iter; left time: 9180.1884s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1162319\n",
      "\tspeed: 0.1111s/iter; left time: 9109.3447s\n",
      "\titers: 3800, epoch: 2 | loss: 0.1189640\n",
      "\tspeed: 0.1074s/iter; left time: 8797.9017s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1236529\n",
      "\tspeed: 0.1077s/iter; left time: 8809.6346s\n",
      "\titers: 4000, epoch: 2 | loss: 0.1346954\n",
      "\tspeed: 0.1115s/iter; left time: 9114.4750s\n",
      "\titers: 4100, epoch: 2 | loss: 0.1188537\n",
      "\tspeed: 0.1107s/iter; left time: 9033.9707s\n",
      "\titers: 4200, epoch: 2 | loss: 0.1036363\n",
      "\tspeed: 0.1067s/iter; left time: 8693.8138s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1099509\n",
      "\tspeed: 0.1053s/iter; left time: 8570.2698s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1071798\n",
      "\tspeed: 0.1087s/iter; left time: 8841.9959s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1060575\n",
      "\tspeed: 0.1129s/iter; left time: 9166.7057s\n",
      "Epoch: 2 cost time: 00h:08m:13.73s\n",
      "Epoch: 2 | Train Loss: 0.1108174 Vali Loss: 0.1193256 Test Loss: 0.1437099\n",
      "Validation loss decreased (0.119912 --> 0.119326).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1108726\n",
      "\tspeed: 1.3402s/iter; left time: 108691.5355s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028282\n",
      "\tspeed: 0.1028s/iter; left time: 8323.5426s\n",
      "\titers: 300, epoch: 3 | loss: 0.0863734\n",
      "\tspeed: 0.1102s/iter; left time: 8914.8399s\n",
      "\titers: 400, epoch: 3 | loss: 0.1141455\n",
      "\tspeed: 0.1038s/iter; left time: 8383.0448s\n",
      "\titers: 500, epoch: 3 | loss: 0.1108244\n",
      "\tspeed: 0.1074s/iter; left time: 8666.8352s\n",
      "\titers: 600, epoch: 3 | loss: 0.1196987\n",
      "\tspeed: 0.1089s/iter; left time: 8779.7791s\n",
      "\titers: 700, epoch: 3 | loss: 0.0919497\n",
      "\tspeed: 0.1106s/iter; left time: 8899.5816s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945634\n",
      "\tspeed: 0.1093s/iter; left time: 8787.4248s\n",
      "\titers: 900, epoch: 3 | loss: 0.1061330\n",
      "\tspeed: 0.1130s/iter; left time: 9077.3806s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1213995\n",
      "\tspeed: 0.1101s/iter; left time: 8830.0212s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0878855\n",
      "\tspeed: 0.1082s/iter; left time: 8668.2737s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0900434\n",
      "\tspeed: 0.1072s/iter; left time: 8573.7459s\n",
      "\titers: 1300, epoch: 3 | loss: 0.1021680\n",
      "\tspeed: 0.1105s/iter; left time: 8825.8133s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0978348\n",
      "\tspeed: 0.1041s/iter; left time: 8305.3914s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1136288\n",
      "\tspeed: 0.1059s/iter; left time: 8443.2291s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1160478\n",
      "\tspeed: 0.1105s/iter; left time: 8791.9466s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1179800\n",
      "\tspeed: 0.1081s/iter; left time: 8595.4554s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1174511\n",
      "\tspeed: 0.1094s/iter; left time: 8686.8922s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1162669\n",
      "\tspeed: 0.1147s/iter; left time: 9092.1472s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1141066\n",
      "\tspeed: 0.1141s/iter; left time: 9033.9044s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0895124\n",
      "\tspeed: 0.1155s/iter; left time: 9135.4349s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0870877\n",
      "\tspeed: 0.1161s/iter; left time: 9169.2483s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1164704\n",
      "\tspeed: 0.1112s/iter; left time: 8773.5132s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0841451\n",
      "\tspeed: 0.1142s/iter; left time: 8999.4576s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0910928\n",
      "\tspeed: 0.1138s/iter; left time: 8958.2193s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1019906\n",
      "\tspeed: 0.1158s/iter; left time: 9103.9820s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1138020\n",
      "\tspeed: 0.1123s/iter; left time: 8813.3174s\n",
      "\titers: 2800, epoch: 3 | loss: 0.1110866\n",
      "\tspeed: 0.1141s/iter; left time: 8941.9551s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1123566\n",
      "\tspeed: 0.1075s/iter; left time: 8417.3997s\n",
      "\titers: 3000, epoch: 3 | loss: 0.1043588\n",
      "\tspeed: 0.1115s/iter; left time: 8721.1525s\n",
      "\titers: 3100, epoch: 3 | loss: 0.1142312\n",
      "\tspeed: 0.1172s/iter; left time: 9150.4277s\n",
      "\titers: 3200, epoch: 3 | loss: 0.1101054\n",
      "\tspeed: 0.1141s/iter; left time: 8900.8343s\n",
      "\titers: 3300, epoch: 3 | loss: 0.1093999\n",
      "\tspeed: 0.1176s/iter; left time: 9162.7271s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0880000\n",
      "\tspeed: 0.1123s/iter; left time: 8738.6559s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0974474\n",
      "\tspeed: 0.1148s/iter; left time: 8921.6823s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1043726\n",
      "\tspeed: 0.1092s/iter; left time: 8472.8281s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0995193\n",
      "\tspeed: 0.1086s/iter; left time: 8419.2897s\n",
      "\titers: 3800, epoch: 3 | loss: 0.1054351\n",
      "\tspeed: 0.1036s/iter; left time: 8016.8512s\n",
      "\titers: 3900, epoch: 3 | loss: 0.1118525\n",
      "\tspeed: 0.1070s/iter; left time: 8273.6683s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1300909\n",
      "\tspeed: 0.1098s/iter; left time: 8475.4572s\n",
      "\titers: 4100, epoch: 3 | loss: 0.1020820\n",
      "\tspeed: 0.1165s/iter; left time: 8983.7896s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0916001\n",
      "\tspeed: 0.1175s/iter; left time: 9047.2713s\n",
      "\titers: 4300, epoch: 3 | loss: 0.1126798\n",
      "\tspeed: 0.1199s/iter; left time: 9216.3500s\n",
      "\titers: 4400, epoch: 3 | loss: 0.1215278\n",
      "\tspeed: 0.1121s/iter; left time: 8611.7911s\n",
      "\titers: 4500, epoch: 3 | loss: 0.1180951\n",
      "\tspeed: 0.1194s/iter; left time: 9155.1661s\n",
      "Epoch: 3 cost time: 00h:08m:22.60s\n",
      "Epoch: 3 | Train Loss: 0.1086144 Vali Loss: 0.1195246 Test Loss: 0.1440614\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.1115486\n",
      "\tspeed: 1.3346s/iter; left time: 102217.0838s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054510\n",
      "\tspeed: 0.1109s/iter; left time: 8485.0016s\n",
      "\titers: 300, epoch: 4 | loss: 0.1105782\n",
      "\tspeed: 0.1128s/iter; left time: 8617.8261s\n",
      "\titers: 400, epoch: 4 | loss: 0.1018976\n",
      "\tspeed: 0.1139s/iter; left time: 8687.4652s\n",
      "\titers: 500, epoch: 4 | loss: 0.1227020\n",
      "\tspeed: 0.1157s/iter; left time: 8811.6757s\n",
      "\titers: 600, epoch: 4 | loss: 0.0843853\n",
      "\tspeed: 0.1152s/iter; left time: 8765.5400s\n",
      "\titers: 700, epoch: 4 | loss: 0.0997685\n",
      "\tspeed: 0.1169s/iter; left time: 8885.5532s\n",
      "\titers: 800, epoch: 4 | loss: 0.1093798\n",
      "\tspeed: 0.1171s/iter; left time: 8882.8932s\n",
      "\titers: 900, epoch: 4 | loss: 0.1216254\n",
      "\tspeed: 0.1167s/iter; left time: 8843.2443s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1091604\n",
      "\tspeed: 0.1161s/iter; left time: 8787.6070s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1017933\n",
      "\tspeed: 0.1042s/iter; left time: 7874.8533s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0995877\n",
      "\tspeed: 0.1103s/iter; left time: 8323.3319s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1105650\n",
      "\tspeed: 0.1185s/iter; left time: 8931.7771s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1113909\n",
      "\tspeed: 0.1140s/iter; left time: 8584.2871s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1152363\n",
      "\tspeed: 0.1122s/iter; left time: 8432.8572s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1372924\n",
      "\tspeed: 0.1131s/iter; left time: 8495.1215s\n",
      "\titers: 1700, epoch: 4 | loss: 0.1083894\n",
      "\tspeed: 0.1128s/iter; left time: 8458.8793s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1122579\n",
      "\tspeed: 0.1105s/iter; left time: 8277.3840s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1059178\n",
      "\tspeed: 0.1175s/iter; left time: 8787.8423s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0945591\n",
      "\tspeed: 0.1157s/iter; left time: 8644.9950s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1170456\n",
      "\tspeed: 0.1176s/iter; left time: 8772.0663s\n",
      "\titers: 2200, epoch: 4 | loss: 0.1135224\n",
      "\tspeed: 0.1178s/iter; left time: 8773.8128s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1174163\n",
      "\tspeed: 0.1140s/iter; left time: 8479.8350s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1205287\n",
      "\tspeed: 0.1159s/iter; left time: 8607.9370s\n",
      "\titers: 2500, epoch: 4 | loss: 0.1128567\n",
      "\tspeed: 0.1061s/iter; left time: 7872.3229s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1036669\n",
      "\tspeed: 0.1147s/iter; left time: 8496.3879s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1118396\n",
      "\tspeed: 0.1156s/iter; left time: 8551.1411s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0988277\n",
      "\tspeed: 0.1124s/iter; left time: 8308.3468s\n",
      "\titers: 2900, epoch: 4 | loss: 0.1059632\n",
      "\tspeed: 0.1132s/iter; left time: 8351.7888s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0940083\n",
      "\tspeed: 0.1106s/iter; left time: 8147.3515s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1072702\n",
      "\tspeed: 0.1123s/iter; left time: 8261.1389s\n",
      "\titers: 3200, epoch: 4 | loss: 0.1180590\n",
      "\tspeed: 0.1142s/iter; left time: 8390.5204s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1017097\n",
      "\tspeed: 0.1162s/iter; left time: 8530.0623s\n",
      "\titers: 3400, epoch: 4 | loss: 0.1119109\n",
      "\tspeed: 0.1121s/iter; left time: 8218.4321s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0858510\n",
      "\tspeed: 0.1115s/iter; left time: 8162.6795s\n",
      "\titers: 3600, epoch: 4 | loss: 0.1130437\n",
      "\tspeed: 0.1155s/iter; left time: 8440.3093s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1014652\n",
      "\tspeed: 0.1106s/iter; left time: 8075.1599s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0955726\n",
      "\tspeed: 0.1158s/iter; left time: 8443.1243s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0986750\n",
      "\tspeed: 0.1167s/iter; left time: 8494.9287s\n",
      "\titers: 4000, epoch: 4 | loss: 0.1016065\n",
      "\tspeed: 0.1136s/iter; left time: 8258.0122s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0968433\n",
      "\tspeed: 0.1146s/iter; left time: 8320.4295s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0973178\n",
      "\tspeed: 0.1174s/iter; left time: 8509.4315s\n",
      "\titers: 4300, epoch: 4 | loss: 0.1206070\n",
      "\tspeed: 0.1149s/iter; left time: 8316.4354s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1314453\n",
      "\tspeed: 0.1194s/iter; left time: 8630.3041s\n",
      "\titers: 4500, epoch: 4 | loss: 0.1145109\n",
      "\tspeed: 0.1161s/iter; left time: 8379.2595s\n",
      "Epoch: 4 cost time: 00h:08m:34.20s\n",
      "Epoch: 4 | Train Loss: 0.1069333 Vali Loss: 0.1192441 Test Loss: 0.1462456\n",
      "Validation loss decreased (0.119326 --> 0.119244).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1106969\n",
      "\tspeed: 1.3440s/iter; left time: 96873.1366s\n",
      "\titers: 200, epoch: 5 | loss: 0.1256126\n",
      "\tspeed: 0.1175s/iter; left time: 8457.1455s\n",
      "\titers: 300, epoch: 5 | loss: 0.1229378\n",
      "\tspeed: 0.1185s/iter; left time: 8517.7007s\n",
      "\titers: 400, epoch: 5 | loss: 0.1134421\n",
      "\tspeed: 0.1169s/iter; left time: 8392.7283s\n",
      "\titers: 500, epoch: 5 | loss: 0.1038589\n",
      "\tspeed: 0.1137s/iter; left time: 8151.2388s\n",
      "\titers: 600, epoch: 5 | loss: 0.0960820\n",
      "\tspeed: 0.1156s/iter; left time: 8277.5873s\n",
      "\titers: 700, epoch: 5 | loss: 0.1359212\n",
      "\tspeed: 0.0936s/iter; left time: 6690.7124s\n",
      "\titers: 800, epoch: 5 | loss: 0.1132452\n",
      "\tspeed: 0.1179s/iter; left time: 8415.3170s\n",
      "\titers: 900, epoch: 5 | loss: 0.1043330\n",
      "\tspeed: 0.1164s/iter; left time: 8294.2253s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1233567\n",
      "\tspeed: 0.1133s/iter; left time: 8061.2139s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0950169\n",
      "\tspeed: 0.1150s/iter; left time: 8171.6137s\n",
      "\titers: 1200, epoch: 5 | loss: 0.1015104\n",
      "\tspeed: 0.1167s/iter; left time: 8284.0123s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1053259\n",
      "\tspeed: 0.1185s/iter; left time: 8395.7381s\n",
      "\titers: 1400, epoch: 5 | loss: 0.1065399\n",
      "\tspeed: 0.1186s/iter; left time: 8391.6910s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1001097\n",
      "\tspeed: 0.1152s/iter; left time: 8143.7129s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0968663\n",
      "\tspeed: 0.1108s/iter; left time: 7816.4287s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0881488\n",
      "\tspeed: 0.1151s/iter; left time: 8111.0693s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1089404\n",
      "\tspeed: 0.1173s/iter; left time: 8255.6213s\n",
      "\titers: 1900, epoch: 5 | loss: 0.1005592\n",
      "\tspeed: 0.1193s/iter; left time: 8382.4210s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1006288\n",
      "\tspeed: 0.1090s/iter; left time: 7650.1333s\n",
      "\titers: 2100, epoch: 5 | loss: 0.1245429\n",
      "\tspeed: 0.1105s/iter; left time: 7744.6735s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1213660\n",
      "\tspeed: 0.1155s/iter; left time: 8081.3613s\n",
      "\titers: 2300, epoch: 5 | loss: 0.1057281\n",
      "\tspeed: 0.1023s/iter; left time: 7149.9918s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0919473\n",
      "\tspeed: 0.1104s/iter; left time: 7702.8078s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1067942\n",
      "\tspeed: 0.1074s/iter; left time: 7483.6224s\n",
      "\titers: 2600, epoch: 5 | loss: 0.1148012\n",
      "\tspeed: 0.1158s/iter; left time: 8054.2119s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1038576\n",
      "\tspeed: 0.1189s/iter; left time: 8262.1882s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0929305\n",
      "\tspeed: 0.1101s/iter; left time: 7640.0437s\n",
      "\titers: 2900, epoch: 5 | loss: 0.1271594\n",
      "\tspeed: 0.1090s/iter; left time: 7549.3658s\n",
      "\titers: 3000, epoch: 5 | loss: 0.1021618\n",
      "\tspeed: 0.1156s/iter; left time: 7997.8963s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0944444\n",
      "\tspeed: 0.1174s/iter; left time: 8107.4542s\n",
      "\titers: 3200, epoch: 5 | loss: 0.1134251\n",
      "\tspeed: 0.1158s/iter; left time: 7990.5895s\n",
      "\titers: 3300, epoch: 5 | loss: 0.1067447\n",
      "\tspeed: 0.1149s/iter; left time: 7915.4349s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1123547\n",
      "\tspeed: 0.1120s/iter; left time: 7705.1210s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0959089\n",
      "\tspeed: 0.1177s/iter; left time: 8085.0547s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1075657\n",
      "\tspeed: 0.1189s/iter; left time: 8156.4418s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0915602\n",
      "\tspeed: 0.1195s/iter; left time: 8184.9151s\n",
      "\titers: 3800, epoch: 5 | loss: 0.1240379\n",
      "\tspeed: 0.1156s/iter; left time: 7903.6515s\n",
      "\titers: 3900, epoch: 5 | loss: 0.1303142\n",
      "\tspeed: 0.1154s/iter; left time: 7877.9185s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0953729\n",
      "\tspeed: 0.1140s/iter; left time: 7774.5613s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0935403\n",
      "\tspeed: 0.1131s/iter; left time: 7702.8282s\n",
      "\titers: 4200, epoch: 5 | loss: 0.1147307\n",
      "\tspeed: 0.1109s/iter; left time: 7537.3710s\n",
      "\titers: 4300, epoch: 5 | loss: 0.1019044\n",
      "\tspeed: 0.1187s/iter; left time: 8058.5534s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1227615\n",
      "\tspeed: 0.1181s/iter; left time: 8001.8434s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0802642\n",
      "\tspeed: 0.1148s/iter; left time: 7766.1329s\n",
      "Epoch: 5 cost time: 00h:08m:36.17s\n",
      "Epoch: 5 | Train Loss: 0.1053349 Vali Loss: 0.1209195 Test Loss: 0.1469402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0783259\n",
      "\tspeed: 1.3176s/iter; left time: 89026.5594s\n",
      "\titers: 200, epoch: 6 | loss: 0.1331674\n",
      "\tspeed: 0.1154s/iter; left time: 7784.5352s\n",
      "\titers: 300, epoch: 6 | loss: 0.1018379\n",
      "\tspeed: 0.1147s/iter; left time: 7726.9231s\n",
      "\titers: 400, epoch: 6 | loss: 0.1066878\n",
      "\tspeed: 0.1105s/iter; left time: 7435.8666s\n",
      "\titers: 500, epoch: 6 | loss: 0.0788593\n",
      "\tspeed: 0.1116s/iter; left time: 7494.7283s\n",
      "\titers: 600, epoch: 6 | loss: 0.0873911\n",
      "\tspeed: 0.1137s/iter; left time: 7626.6838s\n",
      "\titers: 700, epoch: 6 | loss: 0.1186652\n",
      "\tspeed: 0.1160s/iter; left time: 7771.0088s\n",
      "\titers: 800, epoch: 6 | loss: 0.1008608\n",
      "\tspeed: 0.1087s/iter; left time: 7271.4411s\n",
      "\titers: 900, epoch: 6 | loss: 0.1063740\n",
      "\tspeed: 0.1082s/iter; left time: 7221.0462s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1170968\n",
      "\tspeed: 0.1116s/iter; left time: 7436.8571s\n",
      "\titers: 1100, epoch: 6 | loss: 0.1081290\n",
      "\tspeed: 0.1128s/iter; left time: 7509.2226s\n",
      "\titers: 1200, epoch: 6 | loss: 0.1052492\n",
      "\tspeed: 0.1136s/iter; left time: 7552.7939s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1118191\n",
      "\tspeed: 0.1166s/iter; left time: 7740.6337s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1067080\n",
      "\tspeed: 0.1123s/iter; left time: 7438.7333s\n",
      "\titers: 1500, epoch: 6 | loss: 0.1094559\n",
      "\tspeed: 0.1105s/iter; left time: 7313.3840s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0926323\n",
      "\tspeed: 0.1158s/iter; left time: 7648.0522s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1239966\n",
      "\tspeed: 0.1171s/iter; left time: 7721.8551s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0936016\n",
      "\tspeed: 0.1159s/iter; left time: 7635.2426s\n",
      "\titers: 1900, epoch: 6 | loss: 0.1041750\n",
      "\tspeed: 0.1133s/iter; left time: 7453.1863s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0986152\n",
      "\tspeed: 0.1140s/iter; left time: 7483.4215s\n",
      "\titers: 2100, epoch: 6 | loss: 0.1168769\n",
      "\tspeed: 0.1132s/iter; left time: 7420.0995s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0953837\n",
      "\tspeed: 0.1125s/iter; left time: 7365.4741s\n",
      "\titers: 2300, epoch: 6 | loss: 0.1027972\n",
      "\tspeed: 0.1161s/iter; left time: 7589.8768s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1051797\n",
      "\tspeed: 0.1153s/iter; left time: 7527.6371s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0937551\n",
      "\tspeed: 0.1145s/iter; left time: 7463.3676s\n",
      "\titers: 2600, epoch: 6 | loss: 0.1167130\n",
      "\tspeed: 0.1143s/iter; left time: 7438.1546s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0999338\n",
      "\tspeed: 0.1136s/iter; left time: 7378.9968s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0992344\n",
      "\tspeed: 0.1164s/iter; left time: 7549.3720s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0885672\n",
      "\tspeed: 0.1152s/iter; left time: 7461.1327s\n",
      "\titers: 3000, epoch: 6 | loss: 0.1225547\n",
      "\tspeed: 0.1168s/iter; left time: 7551.3945s\n",
      "\titers: 3100, epoch: 6 | loss: 0.1192956\n",
      "\tspeed: 0.1135s/iter; left time: 7327.4462s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0954951\n",
      "\tspeed: 0.1197s/iter; left time: 7717.2147s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0822876\n",
      "\tspeed: 0.1124s/iter; left time: 7237.4140s\n",
      "\titers: 3400, epoch: 6 | loss: 0.1013655\n",
      "\tspeed: 0.1097s/iter; left time: 7047.0034s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1091341\n",
      "\tspeed: 0.1146s/iter; left time: 7353.0869s\n",
      "\titers: 3600, epoch: 6 | loss: 0.1270892\n",
      "\tspeed: 0.1056s/iter; left time: 6767.3169s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1185101\n",
      "\tspeed: 0.1120s/iter; left time: 7162.2319s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0757538\n",
      "\tspeed: 0.1157s/iter; left time: 7391.8558s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0905996\n",
      "\tspeed: 0.1144s/iter; left time: 7293.7606s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0885705\n",
      "\tspeed: 0.1119s/iter; left time: 7126.1458s\n",
      "\titers: 4100, epoch: 6 | loss: 0.1259143\n",
      "\tspeed: 0.1132s/iter; left time: 7194.1096s\n",
      "\titers: 4200, epoch: 6 | loss: 0.1061788\n",
      "\tspeed: 0.1123s/iter; left time: 7127.0946s\n",
      "\titers: 4300, epoch: 6 | loss: 0.1014180\n",
      "\tspeed: 0.1119s/iter; left time: 7088.0927s\n",
      "\titers: 4400, epoch: 6 | loss: 0.1186280\n",
      "\tspeed: 0.1144s/iter; left time: 7237.5045s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0795482\n",
      "\tspeed: 0.1119s/iter; left time: 7070.1969s\n",
      "Epoch: 6 cost time: 00h:08m:32.74s\n",
      "Epoch: 6 | Train Loss: 0.1036454 Vali Loss: 0.1218090 Test Loss: 0.1470043\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0986923\n",
      "\tspeed: 1.3494s/iter; left time: 85086.0368s\n",
      "\titers: 200, epoch: 7 | loss: 0.1147593\n",
      "\tspeed: 0.1195s/iter; left time: 7521.4623s\n",
      "\titers: 300, epoch: 7 | loss: 0.1006580\n",
      "\tspeed: 0.1174s/iter; left time: 7380.9399s\n",
      "\titers: 400, epoch: 7 | loss: 0.1024825\n",
      "\tspeed: 0.1153s/iter; left time: 7235.5951s\n",
      "\titers: 500, epoch: 7 | loss: 0.0890038\n",
      "\tspeed: 0.1180s/iter; left time: 7396.2762s\n",
      "\titers: 600, epoch: 7 | loss: 0.0962573\n",
      "\tspeed: 0.1132s/iter; left time: 7079.6116s\n",
      "\titers: 700, epoch: 7 | loss: 0.1071526\n",
      "\tspeed: 0.1117s/iter; left time: 6978.1748s\n",
      "\titers: 800, epoch: 7 | loss: 0.0988305\n",
      "\tspeed: 0.1089s/iter; left time: 6792.8504s\n",
      "\titers: 900, epoch: 7 | loss: 0.0855241\n",
      "\tspeed: 0.1130s/iter; left time: 7031.9344s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1028365\n",
      "\tspeed: 0.1176s/iter; left time: 7310.1658s\n",
      "\titers: 1100, epoch: 7 | loss: 0.1075217\n",
      "\tspeed: 0.1085s/iter; left time: 6735.6803s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1119868\n",
      "\tspeed: 0.1075s/iter; left time: 6660.0207s\n",
      "\titers: 1300, epoch: 7 | loss: 0.1108468\n",
      "\tspeed: 0.1124s/iter; left time: 6951.5164s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1048751\n",
      "\tspeed: 0.1131s/iter; left time: 6981.7660s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1180050\n",
      "\tspeed: 0.1142s/iter; left time: 7042.8081s\n",
      "\titers: 1600, epoch: 7 | loss: 0.1043866\n",
      "\tspeed: 0.1134s/iter; left time: 6982.1297s\n",
      "\titers: 1700, epoch: 7 | loss: 0.1236405\n",
      "\tspeed: 0.1100s/iter; left time: 6762.4184s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0932909\n",
      "\tspeed: 0.1076s/iter; left time: 6603.4943s\n",
      "\titers: 1900, epoch: 7 | loss: 0.1132419\n",
      "\tspeed: 0.1128s/iter; left time: 6907.3393s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1042955\n",
      "\tspeed: 0.1074s/iter; left time: 6567.3267s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0864213\n",
      "\tspeed: 0.1137s/iter; left time: 6939.5398s\n",
      "\titers: 2200, epoch: 7 | loss: 0.1086380\n",
      "\tspeed: 0.1087s/iter; left time: 6628.5579s\n",
      "\titers: 2300, epoch: 7 | loss: 0.1320028\n",
      "\tspeed: 0.1083s/iter; left time: 6589.5189s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0960228\n",
      "\tspeed: 0.1025s/iter; left time: 6226.4971s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0896331\n",
      "\tspeed: 0.1111s/iter; left time: 6736.7738s\n",
      "\titers: 2600, epoch: 7 | loss: 0.1033154\n",
      "\tspeed: 0.1148s/iter; left time: 6949.0471s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0831659\n",
      "\tspeed: 0.1107s/iter; left time: 6695.0229s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0838740\n",
      "\tspeed: 0.1110s/iter; left time: 6701.8948s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0865178\n",
      "\tspeed: 0.1060s/iter; left time: 6389.6573s\n",
      "\titers: 3000, epoch: 7 | loss: 0.1066371\n",
      "\tspeed: 0.1090s/iter; left time: 6555.3562s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1035567\n",
      "\tspeed: 0.1097s/iter; left time: 6590.7729s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0928825\n",
      "\tspeed: 0.1106s/iter; left time: 6628.3611s\n",
      "\titers: 3300, epoch: 7 | loss: 0.1013904\n",
      "\tspeed: 0.1118s/iter; left time: 6691.2957s\n",
      "\titers: 3400, epoch: 7 | loss: 0.1177498\n",
      "\tspeed: 0.1158s/iter; left time: 6922.0006s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0904561\n",
      "\tspeed: 0.1134s/iter; left time: 6767.0812s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0805334\n",
      "\tspeed: 0.1129s/iter; left time: 6725.4056s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0904435\n",
      "\tspeed: 0.1119s/iter; left time: 6653.4910s\n",
      "\titers: 3800, epoch: 7 | loss: 0.1230280\n",
      "\tspeed: 0.1116s/iter; left time: 6626.8436s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0923927\n",
      "\tspeed: 0.1125s/iter; left time: 6664.6661s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0968234\n",
      "\tspeed: 0.1134s/iter; left time: 6707.9689s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0962466\n",
      "\tspeed: 0.1013s/iter; left time: 5984.0435s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0919007\n",
      "\tspeed: 0.1074s/iter; left time: 6333.9299s\n",
      "\titers: 4300, epoch: 7 | loss: 0.1013262\n",
      "\tspeed: 0.1077s/iter; left time: 6336.2193s\n",
      "\titers: 4400, epoch: 7 | loss: 0.1191296\n",
      "\tspeed: 0.1085s/iter; left time: 6373.9591s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1035824\n",
      "\tspeed: 0.1058s/iter; left time: 6208.0685s\n",
      "Epoch: 7 cost time: 00h:08m:22.59s\n",
      "Epoch: 7 | Train Loss: 0.1018569 Vali Loss: 0.1222693 Test Loss: 0.1476857\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.1060429\n",
      "\tspeed: 1.3382s/iter; left time: 78342.3628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0912129\n",
      "\tspeed: 0.1126s/iter; left time: 6581.8739s\n",
      "\titers: 300, epoch: 8 | loss: 0.0960555\n",
      "\tspeed: 0.1081s/iter; left time: 6304.3334s\n",
      "\titers: 400, epoch: 8 | loss: 0.0987492\n",
      "\tspeed: 0.1041s/iter; left time: 6061.4774s\n",
      "\titers: 500, epoch: 8 | loss: 0.1029660\n",
      "\tspeed: 0.1151s/iter; left time: 6690.6299s\n",
      "\titers: 600, epoch: 8 | loss: 0.0926201\n",
      "\tspeed: 0.1126s/iter; left time: 6534.5099s\n",
      "\titers: 700, epoch: 8 | loss: 0.1085769\n",
      "\tspeed: 0.1099s/iter; left time: 6370.2914s\n",
      "\titers: 800, epoch: 8 | loss: 0.1079342\n",
      "\tspeed: 0.1123s/iter; left time: 6496.3755s\n",
      "\titers: 900, epoch: 8 | loss: 0.0776310\n",
      "\tspeed: 0.1045s/iter; left time: 6036.1541s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0998375\n",
      "\tspeed: 0.1063s/iter; left time: 6127.6423s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0988446\n",
      "\tspeed: 0.1127s/iter; left time: 6483.5711s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0980329\n",
      "\tspeed: 0.1089s/iter; left time: 6257.5399s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0943658\n",
      "\tspeed: 0.1063s/iter; left time: 6097.0355s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0984085\n",
      "\tspeed: 0.1107s/iter; left time: 6338.6127s\n",
      "\titers: 1500, epoch: 8 | loss: 0.1017505\n",
      "\tspeed: 0.1129s/iter; left time: 6449.3951s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0932844\n",
      "\tspeed: 0.1138s/iter; left time: 6491.3278s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0773685\n",
      "\tspeed: 0.1120s/iter; left time: 6377.2404s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1027943\n",
      "\tspeed: 0.1126s/iter; left time: 6399.1006s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1045979\n",
      "\tspeed: 0.1147s/iter; left time: 6506.9316s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0973589\n",
      "\tspeed: 0.1131s/iter; left time: 6407.2875s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0900424\n",
      "\tspeed: 0.1107s/iter; left time: 6262.2465s\n",
      "\titers: 2200, epoch: 8 | loss: 0.1104079\n",
      "\tspeed: 0.1049s/iter; left time: 5919.1544s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0935832\n",
      "\tspeed: 0.1083s/iter; left time: 6099.3889s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0887507\n",
      "\tspeed: 0.1076s/iter; left time: 6050.8807s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0894544\n",
      "\tspeed: 0.1094s/iter; left time: 6139.3620s\n",
      "\titers: 2600, epoch: 8 | loss: 0.1066496\n",
      "\tspeed: 0.1142s/iter; left time: 6399.5664s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0953815\n",
      "\tspeed: 0.1042s/iter; left time: 5829.7583s\n",
      "\titers: 2800, epoch: 8 | loss: 0.1024788\n",
      "\tspeed: 0.1108s/iter; left time: 6188.7851s\n",
      "\titers: 2900, epoch: 8 | loss: 0.1081366\n",
      "\tspeed: 0.1111s/iter; left time: 6192.0077s\n",
      "\titers: 3000, epoch: 8 | loss: 0.1036173\n",
      "\tspeed: 0.1111s/iter; left time: 6181.7441s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0838223\n",
      "\tspeed: 0.1151s/iter; left time: 6393.4080s\n",
      "\titers: 3200, epoch: 8 | loss: 0.1180102\n",
      "\tspeed: 0.1057s/iter; left time: 5860.0224s\n",
      "\titers: 3300, epoch: 8 | loss: 0.1021521\n",
      "\tspeed: 0.1128s/iter; left time: 6242.7414s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1016902\n",
      "\tspeed: 0.1111s/iter; left time: 6140.2261s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0813340\n",
      "\tspeed: 0.1085s/iter; left time: 5983.6522s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0918584\n",
      "\tspeed: 0.1123s/iter; left time: 6181.6042s\n",
      "\titers: 3700, epoch: 8 | loss: 0.1019388\n",
      "\tspeed: 0.1140s/iter; left time: 6261.2787s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0978058\n",
      "\tspeed: 0.1149s/iter; left time: 6299.1350s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0826515\n",
      "\tspeed: 0.1089s/iter; left time: 5959.9951s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0982970\n",
      "\tspeed: 0.1152s/iter; left time: 6293.6782s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0813643\n",
      "\tspeed: 0.1073s/iter; left time: 5854.6792s\n",
      "\titers: 4200, epoch: 8 | loss: 0.1204738\n",
      "\tspeed: 0.1080s/iter; left time: 5878.0480s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0881672\n",
      "\tspeed: 0.1115s/iter; left time: 6061.6552s\n",
      "\titers: 4400, epoch: 8 | loss: 0.1198891\n",
      "\tspeed: 0.1125s/iter; left time: 6100.5969s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0977004\n",
      "\tspeed: 0.1152s/iter; left time: 6238.2763s\n",
      "Epoch: 8 cost time: 00h:08m:19.85s\n",
      "Epoch: 8 | Train Loss: 0.1000848 Vali Loss: 0.1250837 Test Loss: 0.1490528\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0870742\n",
      "\tspeed: 1.3406s/iter; left time: 72435.9347s\n",
      "\titers: 200, epoch: 9 | loss: 0.0949224\n",
      "\tspeed: 0.1140s/iter; left time: 6149.2296s\n",
      "\titers: 300, epoch: 9 | loss: 0.0866150\n",
      "\tspeed: 0.1091s/iter; left time: 5875.0288s\n",
      "\titers: 400, epoch: 9 | loss: 0.0961356\n",
      "\tspeed: 0.1146s/iter; left time: 6158.1281s\n",
      "\titers: 500, epoch: 9 | loss: 0.0966119\n",
      "\tspeed: 0.1070s/iter; left time: 5737.3306s\n",
      "\titers: 600, epoch: 9 | loss: 0.0879250\n",
      "\tspeed: 0.0961s/iter; left time: 5142.6080s\n",
      "\titers: 700, epoch: 9 | loss: 0.0736213\n",
      "\tspeed: 0.1051s/iter; left time: 5617.6439s\n",
      "\titers: 800, epoch: 9 | loss: 0.1010439\n",
      "\tspeed: 0.1117s/iter; left time: 5958.0092s\n",
      "\titers: 900, epoch: 9 | loss: 0.1123951\n",
      "\tspeed: 0.1093s/iter; left time: 5819.6837s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0995345\n",
      "\tspeed: 0.1118s/iter; left time: 5940.4771s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0977169\n",
      "\tspeed: 0.1103s/iter; left time: 5849.6834s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0905486\n",
      "\tspeed: 0.1105s/iter; left time: 5846.7161s\n",
      "\titers: 1300, epoch: 9 | loss: 0.1018659\n",
      "\tspeed: 0.1077s/iter; left time: 5687.5711s\n",
      "\titers: 1400, epoch: 9 | loss: 0.1053348\n",
      "\tspeed: 0.1106s/iter; left time: 5831.7631s\n",
      "\titers: 1500, epoch: 9 | loss: 0.1031533\n",
      "\tspeed: 0.1101s/iter; left time: 5792.5984s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0952918\n",
      "\tspeed: 0.1090s/iter; left time: 5724.6924s\n",
      "\titers: 1700, epoch: 9 | loss: 0.1034756\n",
      "\tspeed: 0.1146s/iter; left time: 6008.4922s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0894023\n",
      "\tspeed: 0.1069s/iter; left time: 5595.0423s\n",
      "\titers: 1900, epoch: 9 | loss: 0.1012105\n",
      "\tspeed: 0.1065s/iter; left time: 5564.7636s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0987397\n",
      "\tspeed: 0.1049s/iter; left time: 5470.2803s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0840729\n",
      "\tspeed: 0.1102s/iter; left time: 5735.0604s\n",
      "\titers: 2200, epoch: 9 | loss: 0.1198350\n",
      "\tspeed: 0.1098s/iter; left time: 5700.8033s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0943350\n",
      "\tspeed: 0.1031s/iter; left time: 5346.1725s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0995929\n",
      "\tspeed: 0.1143s/iter; left time: 5911.7032s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0924421\n",
      "\tspeed: 0.1045s/iter; left time: 5393.6817s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1123153\n",
      "\tspeed: 0.1063s/iter; left time: 5475.9785s\n",
      "\titers: 2700, epoch: 9 | loss: 0.1018775\n",
      "\tspeed: 0.1102s/iter; left time: 5667.5261s\n",
      "\titers: 2800, epoch: 9 | loss: 0.1118076\n",
      "\tspeed: 0.1075s/iter; left time: 5519.8718s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0905782\n",
      "\tspeed: 0.1076s/iter; left time: 5513.5275s\n",
      "\titers: 3000, epoch: 9 | loss: 0.1093302\n",
      "\tspeed: 0.1127s/iter; left time: 5765.1136s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0859874\n",
      "\tspeed: 0.1049s/iter; left time: 5351.7312s\n",
      "\titers: 3200, epoch: 9 | loss: 0.1020958\n",
      "\tspeed: 0.1068s/iter; left time: 5438.5085s\n",
      "\titers: 3300, epoch: 9 | loss: 0.1043750\n",
      "\tspeed: 0.1122s/iter; left time: 5701.1254s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0918467\n",
      "\tspeed: 0.1018s/iter; left time: 5165.5883s\n",
      "\titers: 3500, epoch: 9 | loss: 0.1084657\n",
      "\tspeed: 0.1120s/iter; left time: 5671.4551s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0887780\n",
      "\tspeed: 0.1076s/iter; left time: 5437.2813s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0897469\n",
      "\tspeed: 0.1116s/iter; left time: 5626.9868s\n",
      "\titers: 3800, epoch: 9 | loss: 0.1129294\n",
      "\tspeed: 0.1105s/iter; left time: 5559.7921s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1071102\n",
      "\tspeed: 0.1055s/iter; left time: 5301.3756s\n",
      "\titers: 4000, epoch: 9 | loss: 0.1089792\n",
      "\tspeed: 0.1117s/iter; left time: 5600.6854s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0853505\n",
      "\tspeed: 0.1120s/iter; left time: 5605.3699s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0978250\n",
      "\tspeed: 0.1182s/iter; left time: 5903.1407s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0999500\n",
      "\tspeed: 0.1150s/iter; left time: 5729.1792s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0976036\n",
      "\tspeed: 0.1147s/iter; left time: 5704.5940s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0879225\n",
      "\tspeed: 0.1157s/iter; left time: 5741.8037s\n",
      "Epoch: 9 cost time: 00h:08m:14.47s\n",
      "Epoch: 9 | Train Loss: 0.0984414 Vali Loss: 0.1246871 Test Loss: 0.1517896\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.04658650979399681, rmse:0.21583908796310425, mae:0.14624564349651337, rse:0.7463670969009399\n",
      "success delete checkpoints\n",
      "Intermediate time for GB and pred_len 96: 01h:36m:07.15s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "train 144005\n",
      "val 30365\n",
      "test 30365\n",
      "[2024-11-06 17:38:01,522] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 17:38:02,423] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 17:38:02,423] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 17:38:02,423] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 17:38:02,534] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 17:38:02,534] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 17:38:03,219] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 17:38:03,221] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 17:38:03,221] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 17:38:03,223] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 17:38:03,223] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 17:38:03,223] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 17:38:03,223] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 17:38:03,223] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 17:38:03,223] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 17:38:03,223] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 17:38:03,545] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 17:38:03,546] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 17:38:03,546] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 183.88 GB, percent = 24.4%\n",
      "[2024-11-06 17:38:03,685] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 17:38:03,686] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 17:38:03,686] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 183.89 GB, percent = 24.4%\n",
      "[2024-11-06 17:38:03,686] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 17:38:03,824] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 17:38:03,825] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 17:38:03,825] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 183.89 GB, percent = 24.4%\n",
      "[2024-11-06 17:38:03,826] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 17:38:03,826] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 17:38:03,826] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 17:38:03,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 17:38:03,827] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 17:38:03,827] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 17:38:03,827] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f499d77c110>\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 17:38:03,828] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 17:38:03,829] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 17:38:03,830] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1540329\n",
      "\tspeed: 0.1668s/iter; left time: 14996.2283s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357309\n",
      "\tspeed: 0.1284s/iter; left time: 11526.6416s\n",
      "\titers: 300, epoch: 1 | loss: 0.1516978\n",
      "\tspeed: 0.1229s/iter; left time: 11023.5368s\n",
      "\titers: 400, epoch: 1 | loss: 0.1391764\n",
      "\tspeed: 0.1275s/iter; left time: 11421.2692s\n",
      "\titers: 500, epoch: 1 | loss: 0.1532612\n",
      "\tspeed: 0.1177s/iter; left time: 10534.9885s\n",
      "\titers: 600, epoch: 1 | loss: 0.1409039\n",
      "\tspeed: 0.1265s/iter; left time: 11309.2692s\n",
      "\titers: 700, epoch: 1 | loss: 0.1445390\n",
      "\tspeed: 0.1273s/iter; left time: 11370.7409s\n",
      "\titers: 800, epoch: 1 | loss: 0.1400135\n",
      "\tspeed: 0.1244s/iter; left time: 11100.0344s\n",
      "\titers: 900, epoch: 1 | loss: 0.1150665\n",
      "\tspeed: 0.1246s/iter; left time: 11103.2983s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1087360\n",
      "\tspeed: 0.1263s/iter; left time: 11240.5414s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1048246\n",
      "\tspeed: 0.1147s/iter; left time: 10195.6668s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1131434\n",
      "\tspeed: 0.1246s/iter; left time: 11065.5785s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1333088\n",
      "\tspeed: 0.1259s/iter; left time: 11168.3487s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1152227\n",
      "\tspeed: 0.1214s/iter; left time: 10754.6967s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1339801\n",
      "\tspeed: 0.1254s/iter; left time: 11096.0238s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1203204\n",
      "\tspeed: 0.1192s/iter; left time: 10541.6677s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1205707\n",
      "\tspeed: 0.1265s/iter; left time: 11171.2471s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1083024\n",
      "\tspeed: 0.1269s/iter; left time: 11194.4643s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1132364\n",
      "\tspeed: 0.1280s/iter; left time: 11279.3750s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1334987\n",
      "\tspeed: 0.1256s/iter; left time: 11054.2052s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1036163\n",
      "\tspeed: 0.1299s/iter; left time: 11421.5365s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1335068\n",
      "\tspeed: 0.1263s/iter; left time: 11088.9264s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1196966\n",
      "\tspeed: 0.1242s/iter; left time: 10890.4616s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1034356\n",
      "\tspeed: 0.1259s/iter; left time: 11031.2194s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1306169\n",
      "\tspeed: 0.1277s/iter; left time: 11170.5679s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0961077\n",
      "\tspeed: 0.1257s/iter; left time: 10985.9106s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1103864\n",
      "\tspeed: 0.1239s/iter; left time: 10818.8282s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1129941\n",
      "\tspeed: 0.1240s/iter; left time: 10816.9903s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1228432\n",
      "\tspeed: 0.1224s/iter; left time: 10660.2053s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1276519\n",
      "\tspeed: 0.1271s/iter; left time: 11056.8132s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0996391\n",
      "\tspeed: 0.1234s/iter; left time: 10724.0679s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1129984\n",
      "\tspeed: 0.1273s/iter; left time: 11050.2272s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1145744\n",
      "\tspeed: 0.1258s/iter; left time: 10908.8046s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1410760\n",
      "\tspeed: 0.1289s/iter; left time: 11158.7499s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0965136\n",
      "\tspeed: 0.1282s/iter; left time: 11090.2395s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1219075\n",
      "\tspeed: 0.1293s/iter; left time: 11169.5391s\n",
      "\titers: 3700, epoch: 1 | loss: 0.1190183\n",
      "\tspeed: 0.1247s/iter; left time: 10765.1398s\n",
      "\titers: 3800, epoch: 1 | loss: 0.1229660\n",
      "\tspeed: 0.1238s/iter; left time: 10669.3015s\n",
      "\titers: 3900, epoch: 1 | loss: 0.1016198\n",
      "\tspeed: 0.1276s/iter; left time: 10987.4559s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1242168\n",
      "\tspeed: 0.1283s/iter; left time: 11031.8056s\n",
      "\titers: 4100, epoch: 1 | loss: 0.1002906\n",
      "\tspeed: 0.1273s/iter; left time: 10939.4708s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1139623\n",
      "\tspeed: 0.1218s/iter; left time: 10453.9679s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1175053\n",
      "\tspeed: 0.1300s/iter; left time: 11142.9467s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1227515\n",
      "\tspeed: 0.1277s/iter; left time: 10931.1569s\n",
      "\titers: 4500, epoch: 1 | loss: 0.1044652\n",
      "\tspeed: 0.1258s/iter; left time: 10752.7495s\n",
      "Epoch: 1 cost time: 00h:09m:26.04s\n",
      "Epoch: 1 | Train Loss: 0.1266921 Vali Loss: 0.1263220 Test Loss: 0.1508104\n",
      "Validation loss decreased (inf --> 0.126322).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1177328\n",
      "\tspeed: 1.5811s/iter; left time: 135030.2457s\n",
      "\titers: 200, epoch: 2 | loss: 0.1167645\n",
      "\tspeed: 0.1103s/iter; left time: 9408.6079s\n",
      "\titers: 300, epoch: 2 | loss: 0.1206065\n",
      "\tspeed: 0.1145s/iter; left time: 9753.8157s\n",
      "\titers: 400, epoch: 2 | loss: 0.1280208\n",
      "\tspeed: 0.1137s/iter; left time: 9676.5525s\n",
      "\titers: 500, epoch: 2 | loss: 0.1075500\n",
      "\tspeed: 0.1123s/iter; left time: 9542.1205s\n",
      "\titers: 600, epoch: 2 | loss: 0.1105605\n",
      "\tspeed: 0.1101s/iter; left time: 9351.1930s\n",
      "\titers: 700, epoch: 2 | loss: 0.1234048\n",
      "\tspeed: 0.1092s/iter; left time: 9264.1764s\n",
      "\titers: 800, epoch: 2 | loss: 0.1339168\n",
      "\tspeed: 0.1139s/iter; left time: 9646.0471s\n",
      "\titers: 900, epoch: 2 | loss: 0.1374626\n",
      "\tspeed: 0.1113s/iter; left time: 9413.6520s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1188627\n",
      "\tspeed: 0.1143s/iter; left time: 9657.2157s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1011001\n",
      "\tspeed: 0.1085s/iter; left time: 9158.6880s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0900164\n",
      "\tspeed: 0.1177s/iter; left time: 9919.7015s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1350726\n",
      "\tspeed: 0.1158s/iter; left time: 9751.1723s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1161789\n",
      "\tspeed: 0.1097s/iter; left time: 9225.8144s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1083767\n",
      "\tspeed: 0.1069s/iter; left time: 8976.6255s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1094232\n",
      "\tspeed: 0.1047s/iter; left time: 8786.0308s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0857574\n",
      "\tspeed: 0.1116s/iter; left time: 9351.9391s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0977964\n",
      "\tspeed: 0.1134s/iter; left time: 9494.2347s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1212110\n",
      "\tspeed: 0.1146s/iter; left time: 9578.5387s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1266136\n",
      "\tspeed: 0.1118s/iter; left time: 9338.1588s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1271594\n",
      "\tspeed: 0.1101s/iter; left time: 9182.6967s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1183907\n",
      "\tspeed: 0.1121s/iter; left time: 9339.8189s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1168191\n",
      "\tspeed: 0.1136s/iter; left time: 9447.6364s\n",
      "\titers: 2400, epoch: 2 | loss: 0.1243847\n",
      "\tspeed: 0.1127s/iter; left time: 9367.0978s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0898686\n",
      "\tspeed: 0.1055s/iter; left time: 8760.6947s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1275839\n",
      "\tspeed: 0.1088s/iter; left time: 9021.7299s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1303571\n",
      "\tspeed: 0.1126s/iter; left time: 9327.0287s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0993686\n",
      "\tspeed: 0.1127s/iter; left time: 9318.6656s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0972255\n",
      "\tspeed: 0.1056s/iter; left time: 8719.1713s\n",
      "\titers: 3000, epoch: 2 | loss: 0.1088466\n",
      "\tspeed: 0.1137s/iter; left time: 9382.9700s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1201726\n",
      "\tspeed: 0.1121s/iter; left time: 9238.4136s\n",
      "\titers: 3200, epoch: 2 | loss: 0.1105142\n",
      "\tspeed: 0.1124s/iter; left time: 9249.7245s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0973794\n",
      "\tspeed: 0.1085s/iter; left time: 8915.5044s\n",
      "\titers: 3400, epoch: 2 | loss: 0.1036983\n",
      "\tspeed: 0.1108s/iter; left time: 9096.4574s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1159343\n",
      "\tspeed: 0.1030s/iter; left time: 8449.0357s\n",
      "\titers: 3600, epoch: 2 | loss: 0.1246772\n",
      "\tspeed: 0.1105s/iter; left time: 9047.6661s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1452322\n",
      "\tspeed: 0.1106s/iter; left time: 9050.3814s\n",
      "\titers: 3800, epoch: 2 | loss: 0.1067084\n",
      "\tspeed: 0.1129s/iter; left time: 9227.5468s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1103549\n",
      "\tspeed: 0.1144s/iter; left time: 9335.6114s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0926479\n",
      "\tspeed: 0.1129s/iter; left time: 9200.6761s\n",
      "\titers: 4100, epoch: 2 | loss: 0.1163101\n",
      "\tspeed: 0.1058s/iter; left time: 8608.7021s\n",
      "\titers: 4200, epoch: 2 | loss: 0.1109505\n",
      "\tspeed: 0.0991s/iter; left time: 8059.9637s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1203588\n",
      "\tspeed: 0.1135s/iter; left time: 9212.7559s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1180460\n",
      "\tspeed: 0.1132s/iter; left time: 9180.1051s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1129096\n",
      "\tspeed: 0.1146s/iter; left time: 9283.5991s\n",
      "Epoch: 2 cost time: 00h:08m:20.17s\n",
      "Epoch: 2 | Train Loss: 0.1155856 Vali Loss: 0.1246147 Test Loss: 0.1499413\n",
      "Validation loss decreased (0.126322 --> 0.124615).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1050541\n",
      "\tspeed: 1.3236s/iter; left time: 107078.2053s\n",
      "\titers: 200, epoch: 3 | loss: 0.0956762\n",
      "\tspeed: 0.1134s/iter; left time: 9159.2781s\n",
      "\titers: 300, epoch: 3 | loss: 0.1249172\n",
      "\tspeed: 0.1154s/iter; left time: 9315.8815s\n",
      "\titers: 400, epoch: 3 | loss: 0.1012338\n",
      "\tspeed: 0.1082s/iter; left time: 8717.4465s\n",
      "\titers: 500, epoch: 3 | loss: 0.1217136\n",
      "\tspeed: 0.1129s/iter; left time: 9086.7837s\n",
      "\titers: 600, epoch: 3 | loss: 0.1382750\n",
      "\tspeed: 0.1130s/iter; left time: 9082.9623s\n",
      "\titers: 700, epoch: 3 | loss: 0.1404340\n",
      "\tspeed: 0.1163s/iter; left time: 9337.1767s\n",
      "\titers: 800, epoch: 3 | loss: 0.1065825\n",
      "\tspeed: 0.1163s/iter; left time: 9327.5697s\n",
      "\titers: 900, epoch: 3 | loss: 0.1269282\n",
      "\tspeed: 0.1186s/iter; left time: 9496.2805s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1063279\n",
      "\tspeed: 0.1087s/iter; left time: 8692.5565s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1230693\n",
      "\tspeed: 0.1134s/iter; left time: 9059.9241s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0999694\n",
      "\tspeed: 0.1120s/iter; left time: 8934.0632s\n",
      "\titers: 1300, epoch: 3 | loss: 0.1136298\n",
      "\tspeed: 0.1122s/iter; left time: 8945.2108s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1340387\n",
      "\tspeed: 0.1143s/iter; left time: 9097.3114s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1142856\n",
      "\tspeed: 0.1142s/iter; left time: 9076.4146s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0954974\n",
      "\tspeed: 0.1179s/iter; left time: 9357.4997s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1058675\n",
      "\tspeed: 0.1139s/iter; left time: 9029.5950s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0863039\n",
      "\tspeed: 0.1075s/iter; left time: 8517.9717s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1170907\n",
      "\tspeed: 0.1137s/iter; left time: 8992.6240s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1134746\n",
      "\tspeed: 0.1145s/iter; left time: 9045.9605s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1019692\n",
      "\tspeed: 0.1138s/iter; left time: 8977.2375s\n",
      "\titers: 2200, epoch: 3 | loss: 0.1010195\n",
      "\tspeed: 0.1131s/iter; left time: 8911.5123s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1279088\n",
      "\tspeed: 0.1107s/iter; left time: 8714.3759s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0906017\n",
      "\tspeed: 0.1061s/iter; left time: 8338.9465s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1067194\n",
      "\tspeed: 0.1116s/iter; left time: 8761.2410s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1161840\n",
      "\tspeed: 0.1159s/iter; left time: 9087.3131s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1309958\n",
      "\tspeed: 0.1137s/iter; left time: 8906.4287s\n",
      "\titers: 2800, epoch: 3 | loss: 0.1065948\n",
      "\tspeed: 0.1139s/iter; left time: 8904.3364s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1067306\n",
      "\tspeed: 0.1117s/iter; left time: 8721.0376s\n",
      "\titers: 3000, epoch: 3 | loss: 0.1011091\n",
      "\tspeed: 0.1169s/iter; left time: 9115.3718s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0987042\n",
      "\tspeed: 0.1166s/iter; left time: 9086.1476s\n",
      "\titers: 3200, epoch: 3 | loss: 0.1085057\n",
      "\tspeed: 0.1083s/iter; left time: 8422.2634s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0853749\n",
      "\tspeed: 0.1093s/iter; left time: 8490.3327s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0887945\n",
      "\tspeed: 0.1114s/iter; left time: 8648.6237s\n",
      "\titers: 3500, epoch: 3 | loss: 0.1002370\n",
      "\tspeed: 0.1123s/iter; left time: 8699.9162s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1087316\n",
      "\tspeed: 0.1049s/iter; left time: 8123.0488s\n",
      "\titers: 3700, epoch: 3 | loss: 0.1029242\n",
      "\tspeed: 0.1034s/iter; left time: 7990.8190s\n",
      "\titers: 3800, epoch: 3 | loss: 0.1048434\n",
      "\tspeed: 0.1105s/iter; left time: 8529.9941s\n",
      "\titers: 3900, epoch: 3 | loss: 0.1091800\n",
      "\tspeed: 0.1100s/iter; left time: 8479.2878s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1154592\n",
      "\tspeed: 0.1099s/iter; left time: 8466.0851s\n",
      "\titers: 4100, epoch: 3 | loss: 0.1161003\n",
      "\tspeed: 0.1139s/iter; left time: 8760.4735s\n",
      "\titers: 4200, epoch: 3 | loss: 0.1112612\n",
      "\tspeed: 0.1080s/iter; left time: 8297.0013s\n",
      "\titers: 4300, epoch: 3 | loss: 0.1135285\n",
      "\tspeed: 0.1126s/iter; left time: 8635.8754s\n",
      "\titers: 4400, epoch: 3 | loss: 0.1116768\n",
      "\tspeed: 0.1102s/iter; left time: 8443.3531s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0981399\n",
      "\tspeed: 0.1159s/iter; left time: 8863.5771s\n",
      "Epoch: 3 cost time: 00h:08m:24.97s\n",
      "Epoch: 3 | Train Loss: 0.1132317 Vali Loss: 0.1256584 Test Loss: 0.1513926\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.1097781\n",
      "\tspeed: 1.3054s/iter; left time: 99732.5067s\n",
      "\titers: 200, epoch: 4 | loss: 0.1208098\n",
      "\tspeed: 0.1092s/iter; left time: 8333.9224s\n",
      "\titers: 300, epoch: 4 | loss: 0.1174747\n",
      "\tspeed: 0.1090s/iter; left time: 8305.5501s\n",
      "\titers: 400, epoch: 4 | loss: 0.1035395\n",
      "\tspeed: 0.1099s/iter; left time: 8362.3057s\n",
      "\titers: 500, epoch: 4 | loss: 0.1138039\n",
      "\tspeed: 0.1149s/iter; left time: 8730.2278s\n",
      "\titers: 600, epoch: 4 | loss: 0.1088052\n",
      "\tspeed: 0.1155s/iter; left time: 8766.2032s\n",
      "\titers: 700, epoch: 4 | loss: 0.1175662\n",
      "\tspeed: 0.1105s/iter; left time: 8378.5711s\n",
      "\titers: 800, epoch: 4 | loss: 0.1063344\n",
      "\tspeed: 0.1025s/iter; left time: 7757.2304s\n",
      "\titers: 900, epoch: 4 | loss: 0.1206199\n",
      "\tspeed: 0.1113s/iter; left time: 8413.5116s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1157684\n",
      "\tspeed: 0.1147s/iter; left time: 8659.8763s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1145037\n",
      "\tspeed: 0.1141s/iter; left time: 8603.7192s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1447369\n",
      "\tspeed: 0.1130s/iter; left time: 8512.5108s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0758856\n",
      "\tspeed: 0.1084s/iter; left time: 8148.4788s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1033098\n",
      "\tspeed: 0.1143s/iter; left time: 8581.0448s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1493924\n",
      "\tspeed: 0.1091s/iter; left time: 8185.3045s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1203844\n",
      "\tspeed: 0.1143s/iter; left time: 8558.8777s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0958053\n",
      "\tspeed: 0.1112s/iter; left time: 8319.8346s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1164769\n",
      "\tspeed: 0.1063s/iter; left time: 7937.5695s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1143175\n",
      "\tspeed: 0.1146s/iter; left time: 8545.6532s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1128935\n",
      "\tspeed: 0.1138s/iter; left time: 8478.9043s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1200244\n",
      "\tspeed: 0.1139s/iter; left time: 8471.9570s\n",
      "\titers: 2200, epoch: 4 | loss: 0.1108602\n",
      "\tspeed: 0.1140s/iter; left time: 8472.5070s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0981061\n",
      "\tspeed: 0.1145s/iter; left time: 8492.5535s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1134785\n",
      "\tspeed: 0.1153s/iter; left time: 8542.1243s\n",
      "\titers: 2500, epoch: 4 | loss: 0.1179355\n",
      "\tspeed: 0.1119s/iter; left time: 8280.7303s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1105055\n",
      "\tspeed: 0.1154s/iter; left time: 8530.0869s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1040550\n",
      "\tspeed: 0.1116s/iter; left time: 8237.3639s\n",
      "\titers: 2800, epoch: 4 | loss: 0.1177963\n",
      "\tspeed: 0.1077s/iter; left time: 7936.9721s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0979640\n",
      "\tspeed: 0.1103s/iter; left time: 8121.6291s\n",
      "\titers: 3000, epoch: 4 | loss: 0.1401807\n",
      "\tspeed: 0.1100s/iter; left time: 8086.1625s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1147959\n",
      "\tspeed: 0.1016s/iter; left time: 7457.8707s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0938742\n",
      "\tspeed: 0.1119s/iter; left time: 8200.7916s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1096506\n",
      "\tspeed: 0.1120s/iter; left time: 8196.4266s\n",
      "\titers: 3400, epoch: 4 | loss: 0.1296961\n",
      "\tspeed: 0.1120s/iter; left time: 8189.0437s\n",
      "\titers: 3500, epoch: 4 | loss: 0.1368353\n",
      "\tspeed: 0.1074s/iter; left time: 7836.7236s\n",
      "\titers: 3600, epoch: 4 | loss: 0.1070638\n",
      "\tspeed: 0.1114s/iter; left time: 8117.8324s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0985425\n",
      "\tspeed: 0.1139s/iter; left time: 8290.1099s\n",
      "\titers: 3800, epoch: 4 | loss: 0.1112983\n",
      "\tspeed: 0.1138s/iter; left time: 8274.6869s\n",
      "\titers: 3900, epoch: 4 | loss: 0.1040312\n",
      "\tspeed: 0.1135s/iter; left time: 8238.3025s\n",
      "\titers: 4000, epoch: 4 | loss: 0.1138435\n",
      "\tspeed: 0.1107s/iter; left time: 8024.0975s\n",
      "\titers: 4100, epoch: 4 | loss: 0.1019002\n",
      "\tspeed: 0.1103s/iter; left time: 7984.6515s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1181219\n",
      "\tspeed: 0.1130s/iter; left time: 8168.2968s\n",
      "\titers: 4300, epoch: 4 | loss: 0.1222850\n",
      "\tspeed: 0.1126s/iter; left time: 8133.1103s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1044830\n",
      "\tspeed: 0.1096s/iter; left time: 7903.8757s\n",
      "\titers: 4500, epoch: 4 | loss: 0.1061457\n",
      "\tspeed: 0.1036s/iter; left time: 7460.1685s\n",
      "Epoch: 4 cost time: 00h:08m:20.79s\n",
      "Epoch: 4 | Train Loss: 0.1113180 Vali Loss: 0.1275737 Test Loss: 0.1550181\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0999841\n",
      "\tspeed: 1.3256s/iter; left time: 95312.0770s\n",
      "\titers: 200, epoch: 5 | loss: 0.1353922\n",
      "\tspeed: 0.1172s/iter; left time: 8412.6186s\n",
      "\titers: 300, epoch: 5 | loss: 0.1225589\n",
      "\tspeed: 0.1050s/iter; left time: 7528.2958s\n",
      "\titers: 400, epoch: 5 | loss: 0.1323290\n",
      "\tspeed: 0.1149s/iter; left time: 8228.7487s\n",
      "\titers: 500, epoch: 5 | loss: 0.1322284\n",
      "\tspeed: 0.1116s/iter; left time: 7979.1025s\n",
      "\titers: 600, epoch: 5 | loss: 0.1106409\n",
      "\tspeed: 0.1100s/iter; left time: 7853.5940s\n",
      "\titers: 700, epoch: 5 | loss: 0.1095096\n",
      "\tspeed: 0.1148s/iter; left time: 8186.7250s\n",
      "\titers: 800, epoch: 5 | loss: 0.1036726\n",
      "\tspeed: 0.1120s/iter; left time: 7974.2876s\n",
      "\titers: 900, epoch: 5 | loss: 0.1086556\n",
      "\tspeed: 0.1136s/iter; left time: 8073.5747s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1213037\n",
      "\tspeed: 0.1102s/iter; left time: 7823.3263s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1027749\n",
      "\tspeed: 0.1060s/iter; left time: 7515.2990s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0968759\n",
      "\tspeed: 0.1120s/iter; left time: 7927.6763s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1079355\n",
      "\tspeed: 0.1117s/iter; left time: 7894.7859s\n",
      "\titers: 1400, epoch: 5 | loss: 0.1093184\n",
      "\tspeed: 0.1140s/iter; left time: 8049.9541s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1159560\n",
      "\tspeed: 0.1137s/iter; left time: 8019.1827s\n",
      "\titers: 1600, epoch: 5 | loss: 0.1102509\n",
      "\tspeed: 0.1146s/iter; left time: 8067.8934s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0919283\n",
      "\tspeed: 0.1133s/iter; left time: 7963.7826s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1004144\n",
      "\tspeed: 0.1107s/iter; left time: 7770.0392s\n",
      "\titers: 1900, epoch: 5 | loss: 0.1235390\n",
      "\tspeed: 0.1138s/iter; left time: 7976.2277s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1364286\n",
      "\tspeed: 0.1079s/iter; left time: 7551.7330s\n",
      "\titers: 2100, epoch: 5 | loss: 0.1040794\n",
      "\tspeed: 0.1085s/iter; left time: 7584.2368s\n",
      "\titers: 2200, epoch: 5 | loss: 0.1123590\n",
      "\tspeed: 0.1151s/iter; left time: 8037.1652s\n",
      "\titers: 2300, epoch: 5 | loss: 0.1033478\n",
      "\tspeed: 0.1145s/iter; left time: 7980.6814s\n",
      "\titers: 2400, epoch: 5 | loss: 0.1104060\n",
      "\tspeed: 0.1056s/iter; left time: 7352.3547s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1096722\n",
      "\tspeed: 0.1136s/iter; left time: 7893.4644s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0966176\n",
      "\tspeed: 0.1081s/iter; left time: 7499.9539s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1232002\n",
      "\tspeed: 0.1136s/iter; left time: 7870.7043s\n",
      "\titers: 2800, epoch: 5 | loss: 0.1106784\n",
      "\tspeed: 0.1138s/iter; left time: 7877.7181s\n",
      "\titers: 2900, epoch: 5 | loss: 0.1054593\n",
      "\tspeed: 0.1118s/iter; left time: 7727.6501s\n",
      "\titers: 3000, epoch: 5 | loss: 0.1254749\n",
      "\tspeed: 0.1093s/iter; left time: 7542.1805s\n",
      "\titers: 3100, epoch: 5 | loss: 0.1156037\n",
      "\tspeed: 0.1111s/iter; left time: 7656.8005s\n",
      "\titers: 3200, epoch: 5 | loss: 0.1030489\n",
      "\tspeed: 0.1129s/iter; left time: 7770.5858s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0855889\n",
      "\tspeed: 0.1106s/iter; left time: 7599.8373s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1169992\n",
      "\tspeed: 0.1139s/iter; left time: 7814.4175s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0977471\n",
      "\tspeed: 0.1134s/iter; left time: 7768.0140s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1109213\n",
      "\tspeed: 0.1160s/iter; left time: 7936.8059s\n",
      "\titers: 3700, epoch: 5 | loss: 0.1185672\n",
      "\tspeed: 0.1072s/iter; left time: 7323.0392s\n",
      "\titers: 3800, epoch: 5 | loss: 0.1111548\n",
      "\tspeed: 0.1089s/iter; left time: 7424.1671s\n",
      "\titers: 3900, epoch: 5 | loss: 0.1070399\n",
      "\tspeed: 0.1089s/iter; left time: 7418.0874s\n",
      "\titers: 4000, epoch: 5 | loss: 0.1066909\n",
      "\tspeed: 0.1086s/iter; left time: 7383.6757s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0901919\n",
      "\tspeed: 0.1122s/iter; left time: 7615.9360s\n",
      "\titers: 4200, epoch: 5 | loss: 0.1226699\n",
      "\tspeed: 0.1096s/iter; left time: 7433.0339s\n",
      "\titers: 4300, epoch: 5 | loss: 0.1009490\n",
      "\tspeed: 0.1035s/iter; left time: 7006.1035s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1023511\n",
      "\tspeed: 0.1027s/iter; left time: 6941.9450s\n",
      "\titers: 4500, epoch: 5 | loss: 0.1194390\n",
      "\tspeed: 0.1101s/iter; left time: 7429.2626s\n",
      "Epoch: 5 cost time: 00h:08m:20.98s\n",
      "Epoch: 5 | Train Loss: 0.1094504 Vali Loss: 0.1263070 Test Loss: 0.1532215\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0906079\n",
      "\tspeed: 1.3190s/iter; left time: 88900.7932s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130286\n",
      "\tspeed: 0.1114s/iter; left time: 7495.6995s\n",
      "\titers: 300, epoch: 6 | loss: 0.1088142\n",
      "\tspeed: 0.1124s/iter; left time: 7552.0028s\n",
      "\titers: 400, epoch: 6 | loss: 0.1227311\n",
      "\tspeed: 0.1131s/iter; left time: 7588.5433s\n",
      "\titers: 500, epoch: 6 | loss: 0.1083889\n",
      "\tspeed: 0.1065s/iter; left time: 7136.2067s\n",
      "\titers: 600, epoch: 6 | loss: 0.1077022\n",
      "\tspeed: 0.1053s/iter; left time: 7042.8239s\n",
      "\titers: 700, epoch: 6 | loss: 0.1113944\n",
      "\tspeed: 0.1046s/iter; left time: 6988.4234s\n",
      "\titers: 800, epoch: 6 | loss: 0.1187629\n",
      "\tspeed: 0.1073s/iter; left time: 7160.0708s\n",
      "\titers: 900, epoch: 6 | loss: 0.1103170\n",
      "\tspeed: 0.1148s/iter; left time: 7643.5146s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0873279\n",
      "\tspeed: 0.1179s/iter; left time: 7837.2726s\n",
      "\titers: 1100, epoch: 6 | loss: 0.1126839\n",
      "\tspeed: 0.1184s/iter; left time: 7859.3892s\n",
      "\titers: 1200, epoch: 6 | loss: 0.1170180\n",
      "\tspeed: 0.0975s/iter; left time: 6462.9947s\n",
      "\titers: 1300, epoch: 6 | loss: 0.1188661\n",
      "\tspeed: 0.1153s/iter; left time: 7632.7257s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1073676\n",
      "\tspeed: 0.1008s/iter; left time: 6664.7502s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0903108\n",
      "\tspeed: 0.0945s/iter; left time: 6237.0952s\n",
      "\titers: 1600, epoch: 6 | loss: 0.1037860\n",
      "\tspeed: 0.0956s/iter; left time: 6301.9396s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1083139\n",
      "\tspeed: 0.1156s/iter; left time: 7603.3925s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0903108\n",
      "\tspeed: 0.1127s/iter; left time: 7406.8393s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0963011\n",
      "\tspeed: 0.1152s/iter; left time: 7554.2233s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1001428\n",
      "\tspeed: 0.1162s/iter; left time: 7609.9352s\n",
      "\titers: 2100, epoch: 6 | loss: 0.1058017\n",
      "\tspeed: 0.1145s/iter; left time: 7486.4787s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0910904\n",
      "\tspeed: 0.1192s/iter; left time: 7783.4815s\n",
      "\titers: 2300, epoch: 6 | loss: 0.1329547\n",
      "\tspeed: 0.1185s/iter; left time: 7728.2700s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1076120\n",
      "\tspeed: 0.1176s/iter; left time: 7654.0065s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0998287\n",
      "\tspeed: 0.1078s/iter; left time: 7005.4508s\n",
      "\titers: 2600, epoch: 6 | loss: 0.1147073\n",
      "\tspeed: 0.1082s/iter; left time: 7021.7695s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1168943\n",
      "\tspeed: 0.1077s/iter; left time: 6980.2445s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0931223\n",
      "\tspeed: 0.1118s/iter; left time: 7230.5178s\n",
      "\titers: 2900, epoch: 6 | loss: 0.1086828\n",
      "\tspeed: 0.1116s/iter; left time: 7210.3634s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0978275\n",
      "\tspeed: 0.1092s/iter; left time: 7046.5604s\n",
      "\titers: 3100, epoch: 6 | loss: 0.1077895\n",
      "\tspeed: 0.1121s/iter; left time: 7218.6782s\n",
      "\titers: 3200, epoch: 6 | loss: 0.1113518\n",
      "\tspeed: 0.1128s/iter; left time: 7254.3875s\n",
      "\titers: 3300, epoch: 6 | loss: 0.1134609\n",
      "\tspeed: 0.1111s/iter; left time: 7134.1167s\n",
      "\titers: 3400, epoch: 6 | loss: 0.1288153\n",
      "\tspeed: 0.1114s/iter; left time: 7143.2842s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1180714\n",
      "\tspeed: 0.1058s/iter; left time: 6771.5781s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0980696\n",
      "\tspeed: 0.1116s/iter; left time: 7130.5599s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1149335\n",
      "\tspeed: 0.1129s/iter; left time: 7206.0547s\n",
      "\titers: 3800, epoch: 6 | loss: 0.1129053\n",
      "\tspeed: 0.1005s/iter; left time: 6399.9078s\n",
      "\titers: 3900, epoch: 6 | loss: 0.1119036\n",
      "\tspeed: 0.1095s/iter; left time: 6962.0326s\n",
      "\titers: 4000, epoch: 6 | loss: 0.1111732\n",
      "\tspeed: 0.1139s/iter; left time: 7233.9992s\n",
      "\titers: 4100, epoch: 6 | loss: 0.1289136\n",
      "\tspeed: 0.1140s/iter; left time: 7228.5356s\n",
      "\titers: 4200, epoch: 6 | loss: 0.1018889\n",
      "\tspeed: 0.1072s/iter; left time: 6783.9976s\n",
      "\titers: 4300, epoch: 6 | loss: 0.1140714\n",
      "\tspeed: 0.1047s/iter; left time: 6615.6260s\n",
      "\titers: 4400, epoch: 6 | loss: 0.1037209\n",
      "\tspeed: 0.1113s/iter; left time: 7024.4257s\n",
      "\titers: 4500, epoch: 6 | loss: 0.1148032\n",
      "\tspeed: 0.1076s/iter; left time: 6777.7138s\n",
      "Epoch: 6 cost time: 00h:08m:16.42s\n",
      "Epoch: 6 | Train Loss: 0.1074501 Vali Loss: 0.1282840 Test Loss: 0.1564116\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0977397\n",
      "\tspeed: 1.3188s/iter; left time: 82955.7409s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117877\n",
      "\tspeed: 0.1183s/iter; left time: 7429.9651s\n",
      "\titers: 300, epoch: 7 | loss: 0.1172542\n",
      "\tspeed: 0.1126s/iter; left time: 7057.4561s\n",
      "\titers: 400, epoch: 7 | loss: 0.1091995\n",
      "\tspeed: 0.1073s/iter; left time: 6719.4401s\n",
      "\titers: 500, epoch: 7 | loss: 0.1142104\n",
      "\tspeed: 0.1134s/iter; left time: 7089.5678s\n",
      "\titers: 600, epoch: 7 | loss: 0.0878826\n",
      "\tspeed: 0.1131s/iter; left time: 7055.0100s\n",
      "\titers: 700, epoch: 7 | loss: 0.0965149\n",
      "\tspeed: 0.1127s/iter; left time: 7023.3689s\n",
      "\titers: 800, epoch: 7 | loss: 0.0912004\n",
      "\tspeed: 0.1086s/iter; left time: 6755.4657s\n",
      "\titers: 900, epoch: 7 | loss: 0.0925269\n",
      "\tspeed: 0.1109s/iter; left time: 6886.3211s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1093408\n",
      "\tspeed: 0.1120s/iter; left time: 6946.4695s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0947380\n",
      "\tspeed: 0.1123s/iter; left time: 6949.7894s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1226743\n",
      "\tspeed: 0.1038s/iter; left time: 6415.9158s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0937739\n",
      "\tspeed: 0.1084s/iter; left time: 6686.7874s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1062241\n",
      "\tspeed: 0.1108s/iter; left time: 6824.5139s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1064417\n",
      "\tspeed: 0.1120s/iter; left time: 6890.5088s\n",
      "\titers: 1600, epoch: 7 | loss: 0.1059416\n",
      "\tspeed: 0.1140s/iter; left time: 6997.4517s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0917308\n",
      "\tspeed: 0.1124s/iter; left time: 6888.3225s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0910128\n",
      "\tspeed: 0.0951s/iter; left time: 5822.8845s\n",
      "\titers: 1900, epoch: 7 | loss: 0.1101624\n",
      "\tspeed: 0.1082s/iter; left time: 6612.6763s\n",
      "\titers: 2000, epoch: 7 | loss: 0.1144593\n",
      "\tspeed: 0.1134s/iter; left time: 6915.2380s\n",
      "\titers: 2100, epoch: 7 | loss: 0.1242342\n",
      "\tspeed: 0.1115s/iter; left time: 6791.1231s\n",
      "\titers: 2200, epoch: 7 | loss: 0.1016910\n",
      "\tspeed: 0.1124s/iter; left time: 6831.6807s\n",
      "\titers: 2300, epoch: 7 | loss: 0.1151709\n",
      "\tspeed: 0.1102s/iter; left time: 6691.1385s\n",
      "\titers: 2400, epoch: 7 | loss: 0.1156104\n",
      "\tspeed: 0.1125s/iter; left time: 6816.8019s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1242185\n",
      "\tspeed: 0.1121s/iter; left time: 6782.8580s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0862702\n",
      "\tspeed: 0.1112s/iter; left time: 6715.7576s\n",
      "\titers: 2700, epoch: 7 | loss: 0.1095023\n",
      "\tspeed: 0.1113s/iter; left time: 6709.1230s\n",
      "\titers: 2800, epoch: 7 | loss: 0.1029053\n",
      "\tspeed: 0.1111s/iter; left time: 6690.5724s\n",
      "\titers: 2900, epoch: 7 | loss: 0.1016270\n",
      "\tspeed: 0.1143s/iter; left time: 6869.7848s\n",
      "\titers: 3000, epoch: 7 | loss: 0.1072944\n",
      "\tspeed: 0.1006s/iter; left time: 6034.2024s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1058566\n",
      "\tspeed: 0.1061s/iter; left time: 6354.6750s\n",
      "\titers: 3200, epoch: 7 | loss: 0.1169777\n",
      "\tspeed: 0.1082s/iter; left time: 6472.2206s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0942002\n",
      "\tspeed: 0.1041s/iter; left time: 6212.0833s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0901347\n",
      "\tspeed: 0.0985s/iter; left time: 5872.8356s\n",
      "\titers: 3500, epoch: 7 | loss: 0.1188863\n",
      "\tspeed: 0.1127s/iter; left time: 6708.6622s\n",
      "\titers: 3600, epoch: 7 | loss: 0.1056503\n",
      "\tspeed: 0.1126s/iter; left time: 6686.3416s\n",
      "\titers: 3700, epoch: 7 | loss: 0.1001810\n",
      "\tspeed: 0.1137s/iter; left time: 6740.5881s\n",
      "\titers: 3800, epoch: 7 | loss: 0.1267574\n",
      "\tspeed: 0.1104s/iter; left time: 6538.5204s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0915294\n",
      "\tspeed: 0.1162s/iter; left time: 6865.1093s\n",
      "\titers: 4000, epoch: 7 | loss: 0.1102735\n",
      "\tspeed: 0.1148s/iter; left time: 6772.0735s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0973395\n",
      "\tspeed: 0.1117s/iter; left time: 6577.5928s\n",
      "\titers: 4200, epoch: 7 | loss: 0.1016719\n",
      "\tspeed: 0.1094s/iter; left time: 6430.0076s\n",
      "\titers: 4300, epoch: 7 | loss: 0.1117673\n",
      "\tspeed: 0.1087s/iter; left time: 6382.8942s\n",
      "\titers: 4400, epoch: 7 | loss: 0.1014791\n",
      "\tspeed: 0.1124s/iter; left time: 6589.0463s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0950480\n",
      "\tspeed: 0.1137s/iter; left time: 6651.7857s\n",
      "Epoch: 7 cost time: 00h:08m:18.23s\n",
      "Epoch: 7 | Train Loss: 0.1054989 Vali Loss: 0.1302814 Test Loss: 0.1569777\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.04751771315932274, rmse:0.2179855853319168, mae:0.1499413400888443, rse:0.7554994821548462\n",
      "success delete checkpoints\n",
      "Intermediate time for GB and pred_len 168: 01h:15m:21.20s\n",
      "\n",
      "Intermediate time for GB: 02h:51m:28.34s\n",
      "\n",
      "Total time: 02h:51m:28.35s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DE 24 mae:0.09314965456724167\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'GB',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.04658650979399681,\n",
       "  'RMSE': 0.21583908796310425,\n",
       "  'MAE': 0.14624564349651337},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.04751771315932274,\n",
       "  'RMSE': 0.2179855853319168,\n",
       "  'MAE': 0.1499413400888443}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['ES']\n",
    "num_cols = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 86835\n",
      "val 18651\n",
      "test 18651\n",
      "[2024-11-06 18:53:22,545] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 18:53:23,543] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 18:53:23,543] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 18:53:23,543] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 18:53:23,640] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 18:53:23,641] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 18:53:24,300] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 18:53:24,301] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 18:53:24,301] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 18:53:24,303] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 18:53:24,303] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 18:53:24,303] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 18:53:24,303] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 18:53:24,303] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 18:53:24,303] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 18:53:24,303] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 18:53:24,639] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 18:53:24,640] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 18:53:24,640] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 179.95 GB, percent = 23.8%\n",
      "[2024-11-06 18:53:24,780] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 18:53:24,781] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 18:53:24,782] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 179.95 GB, percent = 23.9%\n",
      "[2024-11-06 18:53:24,782] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 18:53:24,903] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 18:53:24,904] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-06 18:53:24,904] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 179.95 GB, percent = 23.9%\n",
      "[2024-11-06 18:53:24,905] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 18:53:24,905] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 18:53:24,905] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 18:53:24,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f717dab6290>\n",
      "[2024-11-06 18:53:24,906] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 18:53:24,907] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 18:53:24,908] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1684803\n",
      "\tspeed: 0.1708s/iter; left time: 9252.9837s\n",
      "\titers: 200, epoch: 1 | loss: 0.1855613\n",
      "\tspeed: 0.1298s/iter; left time: 7015.7062s\n",
      "\titers: 300, epoch: 1 | loss: 0.1358072\n",
      "\tspeed: 0.1249s/iter; left time: 6742.4102s\n",
      "\titers: 400, epoch: 1 | loss: 0.1324423\n",
      "\tspeed: 0.1284s/iter; left time: 6917.2867s\n",
      "\titers: 500, epoch: 1 | loss: 0.1378427\n",
      "\tspeed: 0.1248s/iter; left time: 6706.7698s\n",
      "\titers: 600, epoch: 1 | loss: 0.1018149\n",
      "\tspeed: 0.1184s/iter; left time: 6355.9795s\n",
      "\titers: 700, epoch: 1 | loss: 0.0824173\n",
      "\tspeed: 0.1240s/iter; left time: 6640.0681s\n",
      "\titers: 800, epoch: 1 | loss: 0.0912670\n",
      "\tspeed: 0.1241s/iter; left time: 6632.3772s\n",
      "\titers: 900, epoch: 1 | loss: 0.0983601\n",
      "\tspeed: 0.1269s/iter; left time: 6771.2037s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0922156\n",
      "\tspeed: 0.1284s/iter; left time: 6840.9459s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0857686\n",
      "\tspeed: 0.1282s/iter; left time: 6816.7834s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0961661\n",
      "\tspeed: 0.1132s/iter; left time: 6008.5624s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0977250\n",
      "\tspeed: 0.1247s/iter; left time: 6603.5801s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0796174\n",
      "\tspeed: 0.1229s/iter; left time: 6494.3348s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0973278\n",
      "\tspeed: 0.1250s/iter; left time: 6596.1430s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0905322\n",
      "\tspeed: 0.1256s/iter; left time: 6615.2623s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1056286\n",
      "\tspeed: 0.1213s/iter; left time: 6374.0285s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0722639\n",
      "\tspeed: 0.1236s/iter; left time: 6482.5753s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1023557\n",
      "\tspeed: 0.1284s/iter; left time: 6723.1214s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0937264\n",
      "\tspeed: 0.1284s/iter; left time: 6710.8930s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0866713\n",
      "\tspeed: 0.1254s/iter; left time: 6541.4460s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0977316\n",
      "\tspeed: 0.1216s/iter; left time: 6328.4687s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0838814\n",
      "\tspeed: 0.1270s/iter; left time: 6596.5647s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0810363\n",
      "\tspeed: 0.1282s/iter; left time: 6646.1520s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0720360\n",
      "\tspeed: 0.1292s/iter; left time: 6685.1142s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0685305\n",
      "\tspeed: 0.1230s/iter; left time: 6352.9452s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0628974\n",
      "\tspeed: 0.1238s/iter; left time: 6381.9694s\n",
      "Epoch: 1 cost time: 00h:05m:40.81s\n",
      "Epoch: 1 | Train Loss: 0.1014160 Vali Loss: 0.0677417 Test Loss: 0.0755981\n",
      "Validation loss decreased (inf --> 0.067742).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0874481\n",
      "\tspeed: 1.0281s/iter; left time: 52895.2976s\n",
      "\titers: 200, epoch: 2 | loss: 0.0856113\n",
      "\tspeed: 0.1145s/iter; left time: 5881.1218s\n",
      "\titers: 300, epoch: 2 | loss: 0.0839847\n",
      "\tspeed: 0.1176s/iter; left time: 6026.1950s\n",
      "\titers: 400, epoch: 2 | loss: 0.0877959\n",
      "\tspeed: 0.1176s/iter; left time: 6014.1500s\n",
      "\titers: 500, epoch: 2 | loss: 0.0880242\n",
      "\tspeed: 0.1146s/iter; left time: 5850.4997s\n",
      "\titers: 600, epoch: 2 | loss: 0.0910104\n",
      "\tspeed: 0.0984s/iter; left time: 5011.7779s\n",
      "\titers: 700, epoch: 2 | loss: 0.0794583\n",
      "\tspeed: 0.1115s/iter; left time: 5667.3106s\n",
      "\titers: 800, epoch: 2 | loss: 0.0933900\n",
      "\tspeed: 0.1109s/iter; left time: 5630.4421s\n",
      "\titers: 900, epoch: 2 | loss: 0.0730245\n",
      "\tspeed: 0.1107s/iter; left time: 5604.9941s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0846104\n",
      "\tspeed: 0.1077s/iter; left time: 5445.1066s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0889364\n",
      "\tspeed: 0.1117s/iter; left time: 5633.5234s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0826097\n",
      "\tspeed: 0.1116s/iter; left time: 5616.5846s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0815537\n",
      "\tspeed: 0.1121s/iter; left time: 5631.3862s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0718202\n",
      "\tspeed: 0.1079s/iter; left time: 5411.9492s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0686948\n",
      "\tspeed: 0.1060s/iter; left time: 5304.1230s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0760714\n",
      "\tspeed: 0.1114s/iter; left time: 5565.1314s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0801897\n",
      "\tspeed: 0.1107s/iter; left time: 5518.8316s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0933725\n",
      "\tspeed: 0.1095s/iter; left time: 5448.5531s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0777532\n",
      "\tspeed: 0.1162s/iter; left time: 5769.9395s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0700811\n",
      "\tspeed: 0.1149s/iter; left time: 5693.4205s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0857387\n",
      "\tspeed: 0.1107s/iter; left time: 5475.8343s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0711527\n",
      "\tspeed: 0.1117s/iter; left time: 5510.0655s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0692101\n",
      "\tspeed: 0.1050s/iter; left time: 5171.4499s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0793717\n",
      "\tspeed: 0.1116s/iter; left time: 5484.8068s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0687345\n",
      "\tspeed: 0.1117s/iter; left time: 5479.4497s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0780514\n",
      "\tspeed: 0.0994s/iter; left time: 4864.9801s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0638164\n",
      "\tspeed: 0.0986s/iter; left time: 4814.1783s\n",
      "Epoch: 2 cost time: 00h:04m:59.34s\n",
      "Epoch: 2 | Train Loss: 0.0801094 Vali Loss: 0.0648352 Test Loss: 0.0730028\n",
      "Validation loss decreased (0.067742 --> 0.064835).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0697693\n",
      "\tspeed: 0.8661s/iter; left time: 42207.1234s\n",
      "\titers: 200, epoch: 3 | loss: 0.0688449\n",
      "\tspeed: 0.1163s/iter; left time: 5656.7354s\n",
      "\titers: 300, epoch: 3 | loss: 0.0742522\n",
      "\tspeed: 0.1066s/iter; left time: 5175.5913s\n",
      "\titers: 400, epoch: 3 | loss: 0.0733116\n",
      "\tspeed: 0.1111s/iter; left time: 5382.9949s\n",
      "\titers: 500, epoch: 3 | loss: 0.0658655\n",
      "\tspeed: 0.0948s/iter; left time: 4580.3711s\n",
      "\titers: 600, epoch: 3 | loss: 0.0653017\n",
      "\tspeed: 0.0969s/iter; left time: 4671.7990s\n",
      "\titers: 700, epoch: 3 | loss: 0.0841913\n",
      "\tspeed: 0.0981s/iter; left time: 4720.8789s\n",
      "\titers: 800, epoch: 3 | loss: 0.0850245\n",
      "\tspeed: 0.1095s/iter; left time: 5257.5206s\n",
      "\titers: 900, epoch: 3 | loss: 0.0694511\n",
      "\tspeed: 0.1111s/iter; left time: 5327.8078s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0708938\n",
      "\tspeed: 0.1123s/iter; left time: 5370.7861s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0814913\n",
      "\tspeed: 0.0926s/iter; left time: 4420.0234s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0962020\n",
      "\tspeed: 0.1111s/iter; left time: 5290.5518s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0721687\n",
      "\tspeed: 0.1124s/iter; left time: 5343.7512s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0766067\n",
      "\tspeed: 0.1151s/iter; left time: 5459.9492s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0788675\n",
      "\tspeed: 0.1135s/iter; left time: 5370.5409s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0801212\n",
      "\tspeed: 0.1205s/iter; left time: 5692.8918s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0743026\n",
      "\tspeed: 0.1201s/iter; left time: 5659.7960s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0630387\n",
      "\tspeed: 0.1199s/iter; left time: 5640.6535s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0772883\n",
      "\tspeed: 0.1030s/iter; left time: 4833.3320s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0829042\n",
      "\tspeed: 0.1116s/iter; left time: 5226.7628s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0660748\n",
      "\tspeed: 0.1119s/iter; left time: 5230.5897s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0635244\n",
      "\tspeed: 0.1120s/iter; left time: 5225.0967s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0667960\n",
      "\tspeed: 0.1123s/iter; left time: 5224.9119s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0783037\n",
      "\tspeed: 0.1087s/iter; left time: 5046.3521s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0670115\n",
      "\tspeed: 0.1146s/iter; left time: 5309.9566s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0765368\n",
      "\tspeed: 0.1124s/iter; left time: 5199.0794s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0777779\n",
      "\tspeed: 0.1132s/iter; left time: 5223.0756s\n",
      "Epoch: 3 cost time: 00h:04m:58.14s\n",
      "Epoch: 3 | Train Loss: 0.0760780 Vali Loss: 0.0621300 Test Loss: 0.0710758\n",
      "Validation loss decreased (0.064835 --> 0.062130).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0793427\n",
      "\tspeed: 0.8838s/iter; left time: 40672.5710s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770855\n",
      "\tspeed: 0.1158s/iter; left time: 5319.6765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0756630\n",
      "\tspeed: 0.1192s/iter; left time: 5464.0131s\n",
      "\titers: 400, epoch: 4 | loss: 0.0781882\n",
      "\tspeed: 0.1190s/iter; left time: 5441.9784s\n",
      "\titers: 500, epoch: 4 | loss: 0.0652066\n",
      "\tspeed: 0.1180s/iter; left time: 5384.6796s\n",
      "\titers: 600, epoch: 4 | loss: 0.0673206\n",
      "\tspeed: 0.1130s/iter; left time: 5144.0221s\n",
      "\titers: 700, epoch: 4 | loss: 0.0919557\n",
      "\tspeed: 0.1146s/iter; left time: 5206.8609s\n",
      "\titers: 800, epoch: 4 | loss: 0.0682522\n",
      "\tspeed: 0.1128s/iter; left time: 5112.7146s\n",
      "\titers: 900, epoch: 4 | loss: 0.0665294\n",
      "\tspeed: 0.1118s/iter; left time: 5055.1918s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0794200\n",
      "\tspeed: 0.1154s/iter; left time: 5205.8936s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0966610\n",
      "\tspeed: 0.1093s/iter; left time: 4922.1938s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0837954\n",
      "\tspeed: 0.1116s/iter; left time: 5013.5973s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0733099\n",
      "\tspeed: 0.1109s/iter; left time: 4968.5751s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0617461\n",
      "\tspeed: 0.1110s/iter; left time: 4962.9013s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0672483\n",
      "\tspeed: 0.1127s/iter; left time: 5027.7630s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0745402\n",
      "\tspeed: 0.1124s/iter; left time: 5006.0849s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0869707\n",
      "\tspeed: 0.1135s/iter; left time: 5041.8396s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0750708\n",
      "\tspeed: 0.1194s/iter; left time: 5291.3866s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0733464\n",
      "\tspeed: 0.1172s/iter; left time: 5184.8956s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0619489\n",
      "\tspeed: 0.1069s/iter; left time: 4718.2396s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0597514\n",
      "\tspeed: 0.1058s/iter; left time: 4655.4931s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0818036\n",
      "\tspeed: 0.1056s/iter; left time: 4637.7373s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0787519\n",
      "\tspeed: 0.1039s/iter; left time: 4551.4738s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0665538\n",
      "\tspeed: 0.1159s/iter; left time: 5066.4477s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0759326\n",
      "\tspeed: 0.1159s/iter; left time: 5055.4371s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0779118\n",
      "\tspeed: 0.1052s/iter; left time: 4580.6835s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0714903\n",
      "\tspeed: 0.0948s/iter; left time: 4118.4609s\n",
      "Epoch: 4 cost time: 00h:05m:03.89s\n",
      "Epoch: 4 | Train Loss: 0.0734997 Vali Loss: 0.0605545 Test Loss: 0.0687684\n",
      "Validation loss decreased (0.062130 --> 0.060555).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0761915\n",
      "\tspeed: 0.8867s/iter; left time: 38402.4422s\n",
      "\titers: 200, epoch: 5 | loss: 0.0663779\n",
      "\tspeed: 0.1164s/iter; left time: 5029.2969s\n",
      "\titers: 300, epoch: 5 | loss: 0.0736244\n",
      "\tspeed: 0.1138s/iter; left time: 4904.1117s\n",
      "\titers: 400, epoch: 5 | loss: 0.0701815\n",
      "\tspeed: 0.1169s/iter; left time: 5027.7798s\n",
      "\titers: 500, epoch: 5 | loss: 0.0604065\n",
      "\tspeed: 0.1180s/iter; left time: 5063.9484s\n",
      "\titers: 600, epoch: 5 | loss: 0.0658066\n",
      "\tspeed: 0.1175s/iter; left time: 5031.7150s\n",
      "\titers: 700, epoch: 5 | loss: 0.0820851\n",
      "\tspeed: 0.1122s/iter; left time: 4792.1936s\n",
      "\titers: 800, epoch: 5 | loss: 0.0699481\n",
      "\tspeed: 0.1157s/iter; left time: 4930.5762s\n",
      "\titers: 900, epoch: 5 | loss: 0.0736197\n",
      "\tspeed: 0.1171s/iter; left time: 4978.2834s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0785851\n",
      "\tspeed: 0.1130s/iter; left time: 4792.2253s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0692036\n",
      "\tspeed: 0.1166s/iter; left time: 4934.2811s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0645397\n",
      "\tspeed: 0.1162s/iter; left time: 4903.5444s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0979708\n",
      "\tspeed: 0.1164s/iter; left time: 4902.6453s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0673110\n",
      "\tspeed: 0.1167s/iter; left time: 4902.8234s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0720462\n",
      "\tspeed: 0.1178s/iter; left time: 4936.4438s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0610949\n",
      "\tspeed: 0.1169s/iter; left time: 4887.2599s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0753150\n",
      "\tspeed: 0.1145s/iter; left time: 4775.9952s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0639090\n",
      "\tspeed: 0.1183s/iter; left time: 4920.7458s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0863830\n",
      "\tspeed: 0.1178s/iter; left time: 4889.2706s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0761659\n",
      "\tspeed: 0.1167s/iter; left time: 4831.5562s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0648316\n",
      "\tspeed: 0.1186s/iter; left time: 4899.0993s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0597344\n",
      "\tspeed: 0.1119s/iter; left time: 4610.8893s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0710222\n",
      "\tspeed: 0.1164s/iter; left time: 4784.5385s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0624651\n",
      "\tspeed: 0.1157s/iter; left time: 4745.2548s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0620616\n",
      "\tspeed: 0.1148s/iter; left time: 4697.5416s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0654412\n",
      "\tspeed: 0.1174s/iter; left time: 4791.9149s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0817377\n",
      "\tspeed: 0.1163s/iter; left time: 4735.6698s\n",
      "Epoch: 5 cost time: 00h:05m:15.70s\n",
      "Epoch: 5 | Train Loss: 0.0718805 Vali Loss: 0.0589176 Test Loss: 0.0676227\n",
      "Validation loss decreased (0.060555 --> 0.058918).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0692523\n",
      "\tspeed: 0.9041s/iter; left time: 36702.7344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0907193\n",
      "\tspeed: 0.1131s/iter; left time: 4581.8034s\n",
      "\titers: 300, epoch: 6 | loss: 0.0599897\n",
      "\tspeed: 0.1095s/iter; left time: 4421.3696s\n",
      "\titers: 400, epoch: 6 | loss: 0.0676493\n",
      "\tspeed: 0.1142s/iter; left time: 4602.6515s\n",
      "\titers: 500, epoch: 6 | loss: 0.0923754\n",
      "\tspeed: 0.1112s/iter; left time: 4469.5962s\n",
      "\titers: 600, epoch: 6 | loss: 0.0799983\n",
      "\tspeed: 0.1137s/iter; left time: 4559.7630s\n",
      "\titers: 700, epoch: 6 | loss: 0.0711934\n",
      "\tspeed: 0.1201s/iter; left time: 4805.1144s\n",
      "\titers: 800, epoch: 6 | loss: 0.0705623\n",
      "\tspeed: 0.1171s/iter; left time: 4669.9880s\n",
      "\titers: 900, epoch: 6 | loss: 0.0695895\n",
      "\tspeed: 0.1123s/iter; left time: 4467.3275s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0744466\n",
      "\tspeed: 0.1165s/iter; left time: 4623.4632s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0836409\n",
      "\tspeed: 0.1168s/iter; left time: 4624.3235s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0628448\n",
      "\tspeed: 0.1204s/iter; left time: 4753.4311s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0726608\n",
      "\tspeed: 0.1121s/iter; left time: 4416.3835s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0667616\n",
      "\tspeed: 0.1148s/iter; left time: 4509.9034s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0738199\n",
      "\tspeed: 0.1188s/iter; left time: 4656.8464s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0586685\n",
      "\tspeed: 0.1187s/iter; left time: 4639.1027s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0660565\n",
      "\tspeed: 0.1104s/iter; left time: 4304.0584s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0584954\n",
      "\tspeed: 0.1188s/iter; left time: 4619.6798s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0669977\n",
      "\tspeed: 0.1220s/iter; left time: 4734.0807s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0753259\n",
      "\tspeed: 0.1186s/iter; left time: 4591.1654s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0946087\n",
      "\tspeed: 0.1158s/iter; left time: 4469.5682s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0681137\n",
      "\tspeed: 0.1088s/iter; left time: 4189.1986s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0670456\n",
      "\tspeed: 0.1148s/iter; left time: 4408.3044s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0657711\n",
      "\tspeed: 0.1169s/iter; left time: 4476.4966s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0687529\n",
      "\tspeed: 0.1189s/iter; left time: 4540.0378s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0666756\n",
      "\tspeed: 0.1141s/iter; left time: 4347.2032s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0725692\n",
      "\tspeed: 0.1113s/iter; left time: 4229.4250s\n",
      "Epoch: 6 cost time: 00h:05m:13.49s\n",
      "Epoch: 6 | Train Loss: 0.0706786 Vali Loss: 0.0609136 Test Loss: 0.0701725\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0522558\n",
      "\tspeed: 0.8672s/iter; left time: 32851.0630s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715316\n",
      "\tspeed: 0.1117s/iter; left time: 4221.3993s\n",
      "\titers: 300, epoch: 7 | loss: 0.0736878\n",
      "\tspeed: 0.1153s/iter; left time: 4346.3083s\n",
      "\titers: 400, epoch: 7 | loss: 0.0680126\n",
      "\tspeed: 0.1078s/iter; left time: 4050.7555s\n",
      "\titers: 500, epoch: 7 | loss: 0.0705455\n",
      "\tspeed: 0.1167s/iter; left time: 4374.6209s\n",
      "\titers: 600, epoch: 7 | loss: 0.0572712\n",
      "\tspeed: 0.1165s/iter; left time: 4356.8526s\n",
      "\titers: 700, epoch: 7 | loss: 0.0644272\n",
      "\tspeed: 0.1140s/iter; left time: 4251.7191s\n",
      "\titers: 800, epoch: 7 | loss: 0.0680819\n",
      "\tspeed: 0.1162s/iter; left time: 4320.5154s\n",
      "\titers: 900, epoch: 7 | loss: 0.0637075\n",
      "\tspeed: 0.1170s/iter; left time: 4337.0609s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0697996\n",
      "\tspeed: 0.1155s/iter; left time: 4271.2939s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0682100\n",
      "\tspeed: 0.1155s/iter; left time: 4261.7381s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0912901\n",
      "\tspeed: 0.1150s/iter; left time: 4228.4305s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0632336\n",
      "\tspeed: 0.1141s/iter; left time: 4184.6120s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0708134\n",
      "\tspeed: 0.1129s/iter; left time: 4128.7546s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0573901\n",
      "\tspeed: 0.1045s/iter; left time: 3812.8130s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0816803\n",
      "\tspeed: 0.1114s/iter; left time: 4052.9123s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0627388\n",
      "\tspeed: 0.1059s/iter; left time: 3843.0019s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0664047\n",
      "\tspeed: 0.1148s/iter; left time: 4154.7299s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0795010\n",
      "\tspeed: 0.1169s/iter; left time: 4218.8308s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0685539\n",
      "\tspeed: 0.1145s/iter; left time: 4119.1800s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0666224\n",
      "\tspeed: 0.1107s/iter; left time: 3970.5015s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0712945\n",
      "\tspeed: 0.1103s/iter; left time: 3948.4550s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0677681\n",
      "\tspeed: 0.1196s/iter; left time: 4268.2041s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0613994\n",
      "\tspeed: 0.1169s/iter; left time: 4158.8456s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0612303\n",
      "\tspeed: 0.1169s/iter; left time: 4149.7330s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0720265\n",
      "\tspeed: 0.1062s/iter; left time: 3758.4429s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0573666\n",
      "\tspeed: 0.1137s/iter; left time: 4010.2933s\n",
      "Epoch: 7 cost time: 00h:05m:07.75s\n",
      "Epoch: 7 | Train Loss: 0.0696183 Vali Loss: 0.0597355 Test Loss: 0.0689392\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0684487\n",
      "\tspeed: 0.8745s/iter; left time: 30754.4222s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620032\n",
      "\tspeed: 0.1006s/iter; left time: 3526.5359s\n",
      "\titers: 300, epoch: 8 | loss: 0.0634560\n",
      "\tspeed: 0.1092s/iter; left time: 3818.0922s\n",
      "\titers: 400, epoch: 8 | loss: 0.0704165\n",
      "\tspeed: 0.1132s/iter; left time: 3948.3083s\n",
      "\titers: 500, epoch: 8 | loss: 0.0740705\n",
      "\tspeed: 0.1165s/iter; left time: 4051.6643s\n",
      "\titers: 600, epoch: 8 | loss: 0.0643420\n",
      "\tspeed: 0.1186s/iter; left time: 4113.0647s\n",
      "\titers: 700, epoch: 8 | loss: 0.0659112\n",
      "\tspeed: 0.1198s/iter; left time: 4142.3892s\n",
      "\titers: 800, epoch: 8 | loss: 0.0658860\n",
      "\tspeed: 0.1179s/iter; left time: 4064.3692s\n",
      "\titers: 900, epoch: 8 | loss: 0.0579858\n",
      "\tspeed: 0.1091s/iter; left time: 3749.4894s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0627797\n",
      "\tspeed: 0.1149s/iter; left time: 3937.5678s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0664856\n",
      "\tspeed: 0.1173s/iter; left time: 4008.3535s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0701139\n",
      "\tspeed: 0.1156s/iter; left time: 3940.1384s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0797251\n",
      "\tspeed: 0.1132s/iter; left time: 3846.7794s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0603685\n",
      "\tspeed: 0.1147s/iter; left time: 3885.6965s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0803857\n",
      "\tspeed: 0.0985s/iter; left time: 3327.5102s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0742070\n",
      "\tspeed: 0.1161s/iter; left time: 3907.9394s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0587145\n",
      "\tspeed: 0.1200s/iter; left time: 4027.4283s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0627118\n",
      "\tspeed: 0.1110s/iter; left time: 3715.8572s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0594644\n",
      "\tspeed: 0.1069s/iter; left time: 3565.7943s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0668217\n",
      "\tspeed: 0.0980s/iter; left time: 3260.2162s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0628058\n",
      "\tspeed: 0.1080s/iter; left time: 3583.4218s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0717877\n",
      "\tspeed: 0.1119s/iter; left time: 3699.3877s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0594875\n",
      "\tspeed: 0.1108s/iter; left time: 3654.2178s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0730331\n",
      "\tspeed: 0.1109s/iter; left time: 3645.6901s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0680322\n",
      "\tspeed: 0.1149s/iter; left time: 3764.0507s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0775669\n",
      "\tspeed: 0.1167s/iter; left time: 3812.9880s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0627357\n",
      "\tspeed: 0.1173s/iter; left time: 3819.0373s\n",
      "Epoch: 8 cost time: 00h:05m:05.16s\n",
      "Epoch: 8 | Train Loss: 0.0689393 Vali Loss: 0.0594135 Test Loss: 0.0684631\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0722077\n",
      "\tspeed: 0.8873s/iter; left time: 28799.2624s\n",
      "\titers: 200, epoch: 9 | loss: 0.0514309\n",
      "\tspeed: 0.1142s/iter; left time: 3695.0839s\n",
      "\titers: 300, epoch: 9 | loss: 0.0685432\n",
      "\tspeed: 0.1156s/iter; left time: 3728.4623s\n",
      "\titers: 400, epoch: 9 | loss: 0.0865207\n",
      "\tspeed: 0.1157s/iter; left time: 3720.1841s\n",
      "\titers: 500, epoch: 9 | loss: 0.0685888\n",
      "\tspeed: 0.1135s/iter; left time: 3637.8177s\n",
      "\titers: 600, epoch: 9 | loss: 0.0837286\n",
      "\tspeed: 0.1104s/iter; left time: 3527.8666s\n",
      "\titers: 700, epoch: 9 | loss: 0.0652891\n",
      "\tspeed: 0.1145s/iter; left time: 3646.2074s\n",
      "\titers: 800, epoch: 9 | loss: 0.0701287\n",
      "\tspeed: 0.1139s/iter; left time: 3615.9347s\n",
      "\titers: 900, epoch: 9 | loss: 0.0645227\n",
      "\tspeed: 0.1135s/iter; left time: 3591.8594s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0892024\n",
      "\tspeed: 0.1139s/iter; left time: 3595.4803s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0680883\n",
      "\tspeed: 0.1055s/iter; left time: 3317.7223s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0651648\n",
      "\tspeed: 0.1152s/iter; left time: 3612.0351s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0648608\n",
      "\tspeed: 0.1148s/iter; left time: 3589.2986s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0683523\n",
      "\tspeed: 0.1163s/iter; left time: 3622.2375s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0615131\n",
      "\tspeed: 0.1166s/iter; left time: 3620.0146s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0651375\n",
      "\tspeed: 0.1133s/iter; left time: 3507.7077s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0548918\n",
      "\tspeed: 0.1065s/iter; left time: 3287.0601s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0831073\n",
      "\tspeed: 0.1017s/iter; left time: 3127.4422s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0828653\n",
      "\tspeed: 0.1167s/iter; left time: 3579.1906s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0696561\n",
      "\tspeed: 0.0969s/iter; left time: 2959.8279s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0734479\n",
      "\tspeed: 0.1118s/iter; left time: 3405.5502s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0641695\n",
      "\tspeed: 0.1124s/iter; left time: 3412.6695s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0523464\n",
      "\tspeed: 0.1180s/iter; left time: 3570.2559s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0566907\n",
      "\tspeed: 0.1180s/iter; left time: 3557.4757s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0689890\n",
      "\tspeed: 0.1156s/iter; left time: 3474.4679s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0665279\n",
      "\tspeed: 0.1121s/iter; left time: 3358.7487s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0667965\n",
      "\tspeed: 0.1141s/iter; left time: 3406.9842s\n",
      "Epoch: 9 cost time: 00h:05m:06.53s\n",
      "Epoch: 9 | Train Loss: 0.0683160 Vali Loss: 0.0575166 Test Loss: 0.0659316\n",
      "Validation loss decreased (0.058918 --> 0.057517).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0798336\n",
      "\tspeed: 0.9013s/iter; left time: 26807.4283s\n",
      "\titers: 200, epoch: 10 | loss: 0.0616640\n",
      "\tspeed: 0.0985s/iter; left time: 2920.4286s\n",
      "\titers: 300, epoch: 10 | loss: 0.0662483\n",
      "\tspeed: 0.1100s/iter; left time: 3249.9554s\n",
      "\titers: 400, epoch: 10 | loss: 0.0634893\n",
      "\tspeed: 0.1146s/iter; left time: 3374.2799s\n",
      "\titers: 500, epoch: 10 | loss: 0.0701435\n",
      "\tspeed: 0.1177s/iter; left time: 3454.5779s\n",
      "\titers: 600, epoch: 10 | loss: 0.0645487\n",
      "\tspeed: 0.1153s/iter; left time: 3370.8479s\n",
      "\titers: 700, epoch: 10 | loss: 0.0682833\n",
      "\tspeed: 0.1168s/iter; left time: 3403.5039s\n",
      "\titers: 800, epoch: 10 | loss: 0.0672983\n",
      "\tspeed: 0.1163s/iter; left time: 3378.4968s\n",
      "\titers: 900, epoch: 10 | loss: 0.0814622\n",
      "\tspeed: 0.1104s/iter; left time: 3196.5940s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0808943\n",
      "\tspeed: 0.1171s/iter; left time: 3377.9644s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0629293\n",
      "\tspeed: 0.1157s/iter; left time: 3326.7927s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0711465\n",
      "\tspeed: 0.1167s/iter; left time: 3342.5814s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0868262\n",
      "\tspeed: 0.1175s/iter; left time: 3352.7331s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0719959\n",
      "\tspeed: 0.1152s/iter; left time: 3277.9872s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0607963\n",
      "\tspeed: 0.1157s/iter; left time: 3280.5574s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0638380\n",
      "\tspeed: 0.1177s/iter; left time: 3325.1264s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0571185\n",
      "\tspeed: 0.1196s/iter; left time: 3365.6487s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0731574\n",
      "\tspeed: 0.1191s/iter; left time: 3341.1158s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0590713\n",
      "\tspeed: 0.1166s/iter; left time: 3259.6418s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0568989\n",
      "\tspeed: 0.1171s/iter; left time: 3261.3404s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0534776\n",
      "\tspeed: 0.1177s/iter; left time: 3266.5861s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0653459\n",
      "\tspeed: 0.1172s/iter; left time: 3240.1857s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0649648\n",
      "\tspeed: 0.1186s/iter; left time: 3266.2067s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0735727\n",
      "\tspeed: 0.1186s/iter; left time: 3253.9172s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0638017\n",
      "\tspeed: 0.1166s/iter; left time: 3188.2639s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0597573\n",
      "\tspeed: 0.1149s/iter; left time: 3129.5583s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0693203\n",
      "\tspeed: 0.0978s/iter; left time: 2655.2464s\n",
      "Epoch: 10 cost time: 00h:05m:11.93s\n",
      "Epoch: 10 | Train Loss: 0.0677325 Vali Loss: 0.0578652 Test Loss: 0.0662273\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0790423\n",
      "\tspeed: 0.8830s/iter; left time: 23868.3680s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697260\n",
      "\tspeed: 0.1104s/iter; left time: 2971.9242s\n",
      "\titers: 300, epoch: 11 | loss: 0.0629871\n",
      "\tspeed: 0.1155s/iter; left time: 3099.2346s\n",
      "\titers: 400, epoch: 11 | loss: 0.0549151\n",
      "\tspeed: 0.1166s/iter; left time: 3116.2340s\n",
      "\titers: 500, epoch: 11 | loss: 0.0651137\n",
      "\tspeed: 0.1168s/iter; left time: 3110.1486s\n",
      "\titers: 600, epoch: 11 | loss: 0.0610926\n",
      "\tspeed: 0.1146s/iter; left time: 3041.7437s\n",
      "\titers: 700, epoch: 11 | loss: 0.0658846\n",
      "\tspeed: 0.1160s/iter; left time: 3066.1408s\n",
      "\titers: 800, epoch: 11 | loss: 0.0706357\n",
      "\tspeed: 0.1124s/iter; left time: 2960.0951s\n",
      "\titers: 900, epoch: 11 | loss: 0.0680808\n",
      "\tspeed: 0.1206s/iter; left time: 3163.0834s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0694161\n",
      "\tspeed: 0.1207s/iter; left time: 3154.6174s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0497258\n",
      "\tspeed: 0.1058s/iter; left time: 2755.1078s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0602000\n",
      "\tspeed: 0.1141s/iter; left time: 2959.3475s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0743991\n",
      "\tspeed: 0.0968s/iter; left time: 2499.6457s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0631713\n",
      "\tspeed: 0.1016s/iter; left time: 2614.5626s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0621014\n",
      "\tspeed: 0.1210s/iter; left time: 3101.7167s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0521298\n",
      "\tspeed: 0.1080s/iter; left time: 2758.1302s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0709545\n",
      "\tspeed: 0.1065s/iter; left time: 2708.5943s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0634490\n",
      "\tspeed: 0.1152s/iter; left time: 2918.5036s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0566912\n",
      "\tspeed: 0.1157s/iter; left time: 2919.4774s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0679880\n",
      "\tspeed: 0.1173s/iter; left time: 2947.4695s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0629415\n",
      "\tspeed: 0.1122s/iter; left time: 2807.4630s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0646708\n",
      "\tspeed: 0.1173s/iter; left time: 2923.8061s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0669400\n",
      "\tspeed: 0.1148s/iter; left time: 2850.8891s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0646928\n",
      "\tspeed: 0.1162s/iter; left time: 2874.5914s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0803343\n",
      "\tspeed: 0.1156s/iter; left time: 2847.3266s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0922966\n",
      "\tspeed: 0.1105s/iter; left time: 2709.7740s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0740040\n",
      "\tspeed: 0.1140s/iter; left time: 2784.8872s\n",
      "Epoch: 11 cost time: 00h:05m:08.23s\n",
      "Epoch: 11 | Train Loss: 0.0673070 Vali Loss: 0.0586048 Test Loss: 0.0677180\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0632242\n",
      "\tspeed: 0.8852s/iter; left time: 21527.4928s\n",
      "\titers: 200, epoch: 12 | loss: 0.0631999\n",
      "\tspeed: 0.1105s/iter; left time: 2677.1265s\n",
      "\titers: 300, epoch: 12 | loss: 0.0597140\n",
      "\tspeed: 0.1149s/iter; left time: 2771.9556s\n",
      "\titers: 400, epoch: 12 | loss: 0.0786450\n",
      "\tspeed: 0.1171s/iter; left time: 2812.2353s\n",
      "\titers: 500, epoch: 12 | loss: 0.0691005\n",
      "\tspeed: 0.1078s/iter; left time: 2577.3301s\n",
      "\titers: 600, epoch: 12 | loss: 0.0783729\n",
      "\tspeed: 0.0952s/iter; left time: 2267.2971s\n",
      "\titers: 700, epoch: 12 | loss: 0.0584539\n",
      "\tspeed: 0.1113s/iter; left time: 2640.0354s\n",
      "\titers: 800, epoch: 12 | loss: 0.0765261\n",
      "\tspeed: 0.1139s/iter; left time: 2689.7551s\n",
      "\titers: 900, epoch: 12 | loss: 0.0746607\n",
      "\tspeed: 0.1172s/iter; left time: 2756.6825s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0669183\n",
      "\tspeed: 0.1169s/iter; left time: 2737.6926s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0822372\n",
      "\tspeed: 0.1154s/iter; left time: 2691.1662s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0566088\n",
      "\tspeed: 0.1143s/iter; left time: 2653.4506s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0662748\n",
      "\tspeed: 0.1172s/iter; left time: 2710.0248s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0714371\n",
      "\tspeed: 0.1168s/iter; left time: 2689.2027s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0547195\n",
      "\tspeed: 0.1153s/iter; left time: 2642.7738s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0655327\n",
      "\tspeed: 0.1135s/iter; left time: 2588.7673s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0598018\n",
      "\tspeed: 0.1145s/iter; left time: 2600.7079s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0599303\n",
      "\tspeed: 0.1177s/iter; left time: 2661.9777s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0821917\n",
      "\tspeed: 0.1085s/iter; left time: 2442.6930s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0650561\n",
      "\tspeed: 0.1118s/iter; left time: 2506.0095s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0659217\n",
      "\tspeed: 0.1143s/iter; left time: 2551.5851s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0761679\n",
      "\tspeed: 0.1168s/iter; left time: 2596.0918s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0662294\n",
      "\tspeed: 0.1101s/iter; left time: 2434.6432s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0605750\n",
      "\tspeed: 0.1175s/iter; left time: 2587.1931s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0525291\n",
      "\tspeed: 0.1185s/iter; left time: 2596.2108s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0578744\n",
      "\tspeed: 0.1134s/iter; left time: 2473.9869s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0709481\n",
      "\tspeed: 0.1110s/iter; left time: 2411.7565s\n",
      "Epoch: 12 cost time: 00h:05m:08.49s\n",
      "Epoch: 12 | Train Loss: 0.0668183 Vali Loss: 0.0579758 Test Loss: 0.0667446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0654240\n",
      "\tspeed: 0.8841s/iter; left time: 19100.2819s\n",
      "\titers: 200, epoch: 13 | loss: 0.0587859\n",
      "\tspeed: 0.1154s/iter; left time: 2482.2520s\n",
      "\titers: 300, epoch: 13 | loss: 0.0626632\n",
      "\tspeed: 0.1186s/iter; left time: 2538.8845s\n",
      "\titers: 400, epoch: 13 | loss: 0.0792713\n",
      "\tspeed: 0.1177s/iter; left time: 2506.8457s\n",
      "\titers: 500, epoch: 13 | loss: 0.0664505\n",
      "\tspeed: 0.1110s/iter; left time: 2352.8996s\n",
      "\titers: 600, epoch: 13 | loss: 0.0626569\n",
      "\tspeed: 0.1092s/iter; left time: 2304.5303s\n",
      "\titers: 700, epoch: 13 | loss: 0.0606688\n",
      "\tspeed: 0.1124s/iter; left time: 2361.2549s\n",
      "\titers: 800, epoch: 13 | loss: 0.0684023\n",
      "\tspeed: 0.1192s/iter; left time: 2491.2865s\n",
      "\titers: 900, epoch: 13 | loss: 0.0761779\n",
      "\tspeed: 0.1176s/iter; left time: 2446.8619s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0657436\n",
      "\tspeed: 0.1105s/iter; left time: 2288.8998s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0587051\n",
      "\tspeed: 0.1082s/iter; left time: 2228.7987s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0459683\n",
      "\tspeed: 0.1150s/iter; left time: 2357.1243s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0709294\n",
      "\tspeed: 0.1080s/iter; left time: 2203.9521s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0675953\n",
      "\tspeed: 0.1138s/iter; left time: 2310.4867s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0633325\n",
      "\tspeed: 0.1039s/iter; left time: 2099.4372s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0718220\n",
      "\tspeed: 0.1185s/iter; left time: 2382.1556s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0573161\n",
      "\tspeed: 0.1177s/iter; left time: 2353.6898s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0687340\n",
      "\tspeed: 0.1104s/iter; left time: 2196.9049s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0701457\n",
      "\tspeed: 0.1077s/iter; left time: 2132.0552s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0774759\n",
      "\tspeed: 0.1111s/iter; left time: 2188.8735s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0700689\n",
      "\tspeed: 0.1159s/iter; left time: 2271.4952s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0777381\n",
      "\tspeed: 0.0997s/iter; left time: 1944.2695s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0539585\n",
      "\tspeed: 0.1149s/iter; left time: 2228.6861s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0581386\n",
      "\tspeed: 0.1091s/iter; left time: 2106.8005s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0864137\n",
      "\tspeed: 0.1121s/iter; left time: 2152.4913s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0778891\n",
      "\tspeed: 0.1156s/iter; left time: 2208.8066s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0720395\n",
      "\tspeed: 0.1152s/iter; left time: 2188.9034s\n",
      "Epoch: 13 cost time: 00h:05m:05.97s\n",
      "Epoch: 13 | Train Loss: 0.0663727 Vali Loss: 0.0567808 Test Loss: 0.0649504\n",
      "Validation loss decreased (0.057517 --> 0.056781).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0671866\n",
      "\tspeed: 0.8991s/iter; left time: 16986.6063s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605762\n",
      "\tspeed: 0.1164s/iter; left time: 2188.2894s\n",
      "\titers: 300, epoch: 14 | loss: 0.0743118\n",
      "\tspeed: 0.1140s/iter; left time: 2130.4884s\n",
      "\titers: 400, epoch: 14 | loss: 0.0711503\n",
      "\tspeed: 0.1078s/iter; left time: 2003.9035s\n",
      "\titers: 500, epoch: 14 | loss: 0.0874231\n",
      "\tspeed: 0.1101s/iter; left time: 2036.4545s\n",
      "\titers: 600, epoch: 14 | loss: 0.0657568\n",
      "\tspeed: 0.1126s/iter; left time: 2071.6642s\n",
      "\titers: 700, epoch: 14 | loss: 0.0722840\n",
      "\tspeed: 0.1188s/iter; left time: 2173.8604s\n",
      "\titers: 800, epoch: 14 | loss: 0.0628701\n",
      "\tspeed: 0.1193s/iter; left time: 2170.8495s\n",
      "\titers: 900, epoch: 14 | loss: 0.0634409\n",
      "\tspeed: 0.1198s/iter; left time: 2166.6026s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0657238\n",
      "\tspeed: 0.1082s/iter; left time: 1945.8829s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0595098\n",
      "\tspeed: 0.1047s/iter; left time: 1872.4288s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0549147\n",
      "\tspeed: 0.1110s/iter; left time: 1975.5770s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0726890\n",
      "\tspeed: 0.1180s/iter; left time: 2088.2774s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0730767\n",
      "\tspeed: 0.1183s/iter; left time: 2080.9383s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0642642\n",
      "\tspeed: 0.1098s/iter; left time: 1919.9089s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0745711\n",
      "\tspeed: 0.1083s/iter; left time: 1883.3814s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0792149\n",
      "\tspeed: 0.1137s/iter; left time: 1965.7431s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0776787\n",
      "\tspeed: 0.1166s/iter; left time: 2005.1267s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0597848\n",
      "\tspeed: 0.1170s/iter; left time: 1999.0448s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0723903\n",
      "\tspeed: 0.1010s/iter; left time: 1716.9724s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0655693\n",
      "\tspeed: 0.1128s/iter; left time: 1905.0252s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0764888\n",
      "\tspeed: 0.1093s/iter; left time: 1834.9808s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0704169\n",
      "\tspeed: 0.1140s/iter; left time: 1902.1600s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0581064\n",
      "\tspeed: 0.0954s/iter; left time: 1582.4951s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0691162\n",
      "\tspeed: 0.1181s/iter; left time: 1946.8902s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0659263\n",
      "\tspeed: 0.1174s/iter; left time: 1924.6095s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0651758\n",
      "\tspeed: 0.1012s/iter; left time: 1648.0490s\n",
      "Epoch: 14 cost time: 00h:05m:04.44s\n",
      "Epoch: 14 | Train Loss: 0.0660521 Vali Loss: 0.0571002 Test Loss: 0.0656509\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0613544\n",
      "\tspeed: 0.8493s/iter; left time: 13741.4088s\n",
      "\titers: 200, epoch: 15 | loss: 0.0716244\n",
      "\tspeed: 0.1005s/iter; left time: 1616.6648s\n",
      "\titers: 300, epoch: 15 | loss: 0.0577355\n",
      "\tspeed: 0.1017s/iter; left time: 1625.5714s\n",
      "\titers: 400, epoch: 15 | loss: 0.0622192\n",
      "\tspeed: 0.0988s/iter; left time: 1569.3750s\n",
      "\titers: 500, epoch: 15 | loss: 0.0731483\n",
      "\tspeed: 0.0964s/iter; left time: 1520.3818s\n",
      "\titers: 600, epoch: 15 | loss: 0.0678494\n",
      "\tspeed: 0.0942s/iter; left time: 1476.3202s\n",
      "\titers: 700, epoch: 15 | loss: 0.0622007\n",
      "\tspeed: 0.0989s/iter; left time: 1540.9800s\n",
      "\titers: 800, epoch: 15 | loss: 0.0761948\n",
      "\tspeed: 0.1002s/iter; left time: 1551.2141s\n",
      "\titers: 900, epoch: 15 | loss: 0.0646099\n",
      "\tspeed: 0.1022s/iter; left time: 1572.1139s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0503409\n",
      "\tspeed: 0.1009s/iter; left time: 1541.4324s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0749367\n",
      "\tspeed: 0.0992s/iter; left time: 1506.4093s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0746989\n",
      "\tspeed: 0.0970s/iter; left time: 1461.9642s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0596992\n",
      "\tspeed: 0.0963s/iter; left time: 1443.0699s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0765110\n",
      "\tspeed: 0.0992s/iter; left time: 1475.9736s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0709605\n",
      "\tspeed: 0.0987s/iter; left time: 1459.0510s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0623325\n",
      "\tspeed: 0.0994s/iter; left time: 1458.8429s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0694934\n",
      "\tspeed: 0.0971s/iter; left time: 1416.1366s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0564866\n",
      "\tspeed: 0.0950s/iter; left time: 1375.6717s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0520299\n",
      "\tspeed: 0.0991s/iter; left time: 1424.6424s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0581513\n",
      "\tspeed: 0.0993s/iter; left time: 1417.3338s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0649654\n",
      "\tspeed: 0.0978s/iter; left time: 1387.2299s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0654628\n",
      "\tspeed: 0.1015s/iter; left time: 1429.4360s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0739103\n",
      "\tspeed: 0.1014s/iter; left time: 1416.9746s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0690336\n",
      "\tspeed: 0.0998s/iter; left time: 1384.5432s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0729438\n",
      "\tspeed: 0.0980s/iter; left time: 1349.9095s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0577901\n",
      "\tspeed: 0.1040s/iter; left time: 1422.3671s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0659404\n",
      "\tspeed: 0.0952s/iter; left time: 1292.1001s\n",
      "Epoch: 15 cost time: 00h:04m:29.49s\n",
      "Epoch: 15 | Train Loss: 0.0657846 Vali Loss: 0.0558852 Test Loss: 0.0639950\n",
      "Validation loss decreased (0.056781 --> 0.055885).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0812111\n",
      "\tspeed: 0.9154s/iter; left time: 12326.2406s\n",
      "\titers: 200, epoch: 16 | loss: 0.0603782\n",
      "\tspeed: 0.1011s/iter; left time: 1351.5526s\n",
      "\titers: 300, epoch: 16 | loss: 0.0678609\n",
      "\tspeed: 0.1093s/iter; left time: 1449.8636s\n",
      "\titers: 400, epoch: 16 | loss: 0.0654610\n",
      "\tspeed: 0.1102s/iter; left time: 1451.2551s\n",
      "\titers: 500, epoch: 16 | loss: 0.0584168\n",
      "\tspeed: 0.1069s/iter; left time: 1397.0309s\n",
      "\titers: 600, epoch: 16 | loss: 0.0689599\n",
      "\tspeed: 0.1087s/iter; left time: 1409.0077s\n",
      "\titers: 700, epoch: 16 | loss: 0.0570968\n",
      "\tspeed: 0.1021s/iter; left time: 1312.9960s\n",
      "\titers: 800, epoch: 16 | loss: 0.0595449\n",
      "\tspeed: 0.1068s/iter; left time: 1363.1403s\n",
      "\titers: 900, epoch: 16 | loss: 0.0650445\n",
      "\tspeed: 0.1030s/iter; left time: 1304.2490s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0528608\n",
      "\tspeed: 0.1114s/iter; left time: 1400.0265s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0684160\n",
      "\tspeed: 0.1006s/iter; left time: 1253.9809s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0572649\n",
      "\tspeed: 0.1067s/iter; left time: 1319.5772s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0621478\n",
      "\tspeed: 0.0953s/iter; left time: 1169.3687s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0609206\n",
      "\tspeed: 0.1055s/iter; left time: 1283.1591s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0823299\n",
      "\tspeed: 0.1036s/iter; left time: 1250.3809s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0523159\n",
      "\tspeed: 0.1066s/iter; left time: 1275.9181s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0572315\n",
      "\tspeed: 0.0963s/iter; left time: 1143.0584s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0656652\n",
      "\tspeed: 0.1059s/iter; left time: 1245.5454s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0427415\n",
      "\tspeed: 0.1012s/iter; left time: 1180.3011s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0662633\n",
      "\tspeed: 0.1065s/iter; left time: 1231.2697s\n",
      "\titers: 2100, epoch: 16 | loss: 0.0703763\n",
      "\tspeed: 0.1042s/iter; left time: 1194.2789s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0833776\n",
      "\tspeed: 0.1000s/iter; left time: 1136.7543s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0541426\n",
      "\tspeed: 0.1056s/iter; left time: 1189.7812s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0556633\n",
      "\tspeed: 0.1050s/iter; left time: 1172.1498s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0630141\n",
      "\tspeed: 0.1081s/iter; left time: 1195.7840s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0648344\n",
      "\tspeed: 0.1051s/iter; left time: 1152.6607s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0750940\n",
      "\tspeed: 0.1089s/iter; left time: 1183.7597s\n",
      "Epoch: 16 cost time: 00h:04m:45.70s\n",
      "Epoch: 16 | Train Loss: 0.0653686 Vali Loss: 0.0568840 Test Loss: 0.0648567\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0616685\n",
      "\tspeed: 0.9481s/iter; left time: 10194.4800s\n",
      "\titers: 200, epoch: 17 | loss: 0.0657150\n",
      "\tspeed: 0.1011s/iter; left time: 1077.4357s\n",
      "\titers: 300, epoch: 17 | loss: 0.0674887\n",
      "\tspeed: 0.1058s/iter; left time: 1116.9112s\n",
      "\titers: 400, epoch: 17 | loss: 0.0675082\n",
      "\tspeed: 0.1126s/iter; left time: 1177.0324s\n",
      "\titers: 500, epoch: 17 | loss: 0.0700292\n",
      "\tspeed: 0.1035s/iter; left time: 1071.1052s\n",
      "\titers: 600, epoch: 17 | loss: 0.0791684\n",
      "\tspeed: 0.0990s/iter; left time: 1014.9842s\n",
      "\titers: 700, epoch: 17 | loss: 0.0625269\n",
      "\tspeed: 0.1051s/iter; left time: 1067.0740s\n",
      "\titers: 800, epoch: 17 | loss: 0.0663824\n",
      "\tspeed: 0.0994s/iter; left time: 999.7269s\n",
      "\titers: 900, epoch: 17 | loss: 0.0586265\n",
      "\tspeed: 0.0951s/iter; left time: 946.5443s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0727891\n",
      "\tspeed: 0.1073s/iter; left time: 1057.2753s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0603771\n",
      "\tspeed: 0.1115s/iter; left time: 1087.2177s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0759383\n",
      "\tspeed: 0.1058s/iter; left time: 1021.4092s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0580747\n",
      "\tspeed: 0.0990s/iter; left time: 945.7759s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0729085\n",
      "\tspeed: 0.1074s/iter; left time: 1015.6537s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0690563\n",
      "\tspeed: 0.1045s/iter; left time: 977.3163s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0647830\n",
      "\tspeed: 0.1048s/iter; left time: 969.2946s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0689346\n",
      "\tspeed: 0.1032s/iter; left time: 944.3158s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0688043\n",
      "\tspeed: 0.1037s/iter; left time: 938.8749s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0829549\n",
      "\tspeed: 0.1006s/iter; left time: 901.0436s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0609135\n",
      "\tspeed: 0.1000s/iter; left time: 885.6359s\n",
      "\titers: 2100, epoch: 17 | loss: 0.0561445\n",
      "\tspeed: 0.1091s/iter; left time: 955.3541s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0671463\n",
      "\tspeed: 0.1059s/iter; left time: 916.0964s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0673382\n",
      "\tspeed: 0.0974s/iter; left time: 833.4608s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0694514\n",
      "\tspeed: 0.1050s/iter; left time: 887.2780s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0660289\n",
      "\tspeed: 0.1033s/iter; left time: 862.6829s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0572225\n",
      "\tspeed: 0.1041s/iter; left time: 859.3211s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0612335\n",
      "\tspeed: 0.1045s/iter; left time: 852.0546s\n",
      "Epoch: 17 cost time: 00h:04m:42.80s\n",
      "Epoch: 17 | Train Loss: 0.0651438 Vali Loss: 0.0576047 Test Loss: 0.0661985\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0815927\n",
      "\tspeed: 0.9319s/iter; left time: 7492.1667s\n",
      "\titers: 200, epoch: 18 | loss: 0.0608827\n",
      "\tspeed: 0.1023s/iter; left time: 812.1984s\n",
      "\titers: 300, epoch: 18 | loss: 0.0648538\n",
      "\tspeed: 0.1056s/iter; left time: 827.9847s\n",
      "\titers: 400, epoch: 18 | loss: 0.0634261\n",
      "\tspeed: 0.1076s/iter; left time: 833.0358s\n",
      "\titers: 500, epoch: 18 | loss: 0.0784252\n",
      "\tspeed: 0.1001s/iter; left time: 764.9693s\n",
      "\titers: 600, epoch: 18 | loss: 0.0643976\n",
      "\tspeed: 0.1063s/iter; left time: 801.6814s\n",
      "\titers: 700, epoch: 18 | loss: 0.0537820\n",
      "\tspeed: 0.0995s/iter; left time: 740.4078s\n",
      "\titers: 800, epoch: 18 | loss: 0.0653336\n",
      "\tspeed: 0.1059s/iter; left time: 777.3539s\n",
      "\titers: 900, epoch: 18 | loss: 0.0598255\n",
      "\tspeed: 0.1003s/iter; left time: 726.4698s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0655803\n",
      "\tspeed: 0.1071s/iter; left time: 764.8577s\n",
      "\titers: 1100, epoch: 18 | loss: 0.0750549\n",
      "\tspeed: 0.1063s/iter; left time: 748.0808s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0609095\n",
      "\tspeed: 0.1055s/iter; left time: 732.4863s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0680391\n",
      "\tspeed: 0.1079s/iter; left time: 737.7826s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0628027\n",
      "\tspeed: 0.1054s/iter; left time: 710.5133s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0537185\n",
      "\tspeed: 0.1091s/iter; left time: 724.2631s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0573713\n",
      "\tspeed: 0.0960s/iter; left time: 627.7502s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0630245\n",
      "\tspeed: 0.0980s/iter; left time: 631.3823s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0656043\n",
      "\tspeed: 0.0996s/iter; left time: 631.4649s\n",
      "\titers: 1900, epoch: 18 | loss: 0.0527379\n",
      "\tspeed: 0.1017s/iter; left time: 634.7843s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0617962\n",
      "\tspeed: 0.1113s/iter; left time: 683.4849s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0645075\n",
      "\tspeed: 0.1102s/iter; left time: 665.5559s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0610552\n",
      "\tspeed: 0.1112s/iter; left time: 660.3659s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0799765\n",
      "\tspeed: 0.1082s/iter; left time: 632.1182s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0716866\n",
      "\tspeed: 0.1051s/iter; left time: 603.5111s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0533605\n",
      "\tspeed: 0.0986s/iter; left time: 556.3409s\n",
      "\titers: 2600, epoch: 18 | loss: 0.0584881\n",
      "\tspeed: 0.1122s/iter; left time: 621.8267s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0650927\n",
      "\tspeed: 0.1093s/iter; left time: 594.5556s\n",
      "Epoch: 18 cost time: 00h:04m:46.92s\n",
      "Epoch: 18 | Train Loss: 0.0647901 Vali Loss: 0.0576666 Test Loss: 0.0654137\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0661122\n",
      "\tspeed: 1.4401s/iter; left time: 7671.2759s\n",
      "\titers: 200, epoch: 19 | loss: 0.0598290\n",
      "\tspeed: 0.1689s/iter; left time: 882.9463s\n",
      "\titers: 300, epoch: 19 | loss: 0.0591050\n",
      "\tspeed: 0.1648s/iter; left time: 845.1683s\n",
      "\titers: 400, epoch: 19 | loss: 0.0696431\n",
      "\tspeed: 0.1689s/iter; left time: 848.8990s\n",
      "\titers: 500, epoch: 19 | loss: 0.0726275\n",
      "\tspeed: 0.1687s/iter; left time: 831.1224s\n",
      "\titers: 600, epoch: 19 | loss: 0.0544416\n",
      "\tspeed: 0.1667s/iter; left time: 804.4519s\n",
      "\titers: 700, epoch: 19 | loss: 0.0769312\n",
      "\tspeed: 0.1649s/iter; left time: 779.4600s\n",
      "\titers: 800, epoch: 19 | loss: 0.0680899\n",
      "\tspeed: 0.1668s/iter; left time: 771.5986s\n",
      "\titers: 900, epoch: 19 | loss: 0.0600334\n",
      "\tspeed: 0.1707s/iter; left time: 772.7996s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0600673\n",
      "\tspeed: 0.1664s/iter; left time: 736.5831s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0586962\n",
      "\tspeed: 0.1690s/iter; left time: 731.3317s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0533629\n",
      "\tspeed: 0.1795s/iter; left time: 758.8177s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0589607\n",
      "\tspeed: 0.2947s/iter; left time: 1216.3299s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0653733\n",
      "\tspeed: 0.2945s/iter; left time: 1186.0809s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0590345\n",
      "\tspeed: 0.2946s/iter; left time: 1157.0437s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0578061\n",
      "\tspeed: 0.2923s/iter; left time: 1118.5712s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0641297\n",
      "\tspeed: 0.2918s/iter; left time: 1087.4107s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0598502\n",
      "\tspeed: 0.2924s/iter; left time: 1060.6959s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0686003\n",
      "\tspeed: 0.2918s/iter; left time: 1029.0304s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0569567\n",
      "\tspeed: 0.2920s/iter; left time: 1000.7334s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0591852\n",
      "\tspeed: 0.2952s/iter; left time: 982.2965s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0672394\n",
      "\tspeed: 0.2896s/iter; left time: 934.6470s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0611066\n",
      "\tspeed: 0.2932s/iter; left time: 916.9641s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0675423\n",
      "\tspeed: 0.2666s/iter; left time: 807.1168s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0785748\n",
      "\tspeed: 0.2921s/iter; left time: 855.0479s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0645431\n",
      "\tspeed: 0.2967s/iter; left time: 838.7381s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0566461\n",
      "\tspeed: 0.2968s/iter; left time: 809.4721s\n",
      "Epoch: 19 cost time: 00h:10m:44.42s\n",
      "Epoch: 19 | Train Loss: 0.0645441 Vali Loss: 0.0573431 Test Loss: 0.0657268\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0581203\n",
      "\tspeed: 2.7187s/iter; left time: 7106.8109s\n",
      "\titers: 200, epoch: 20 | loss: 0.0696715\n",
      "\tspeed: 0.2934s/iter; left time: 737.7247s\n",
      "\titers: 300, epoch: 20 | loss: 0.0628937\n",
      "\tspeed: 0.2979s/iter; left time: 719.0728s\n",
      "\titers: 400, epoch: 20 | loss: 0.0653569\n",
      "\tspeed: 0.2942s/iter; left time: 680.6667s\n",
      "\titers: 500, epoch: 20 | loss: 0.0701173\n",
      "\tspeed: 0.2926s/iter; left time: 647.7994s\n",
      "\titers: 600, epoch: 20 | loss: 0.0638811\n",
      "\tspeed: 0.2927s/iter; left time: 618.8609s\n",
      "\titers: 700, epoch: 20 | loss: 0.0736298\n",
      "\tspeed: 0.2967s/iter; left time: 597.4905s\n",
      "\titers: 800, epoch: 20 | loss: 0.0541089\n",
      "\tspeed: 0.2913s/iter; left time: 557.5126s\n",
      "\titers: 900, epoch: 20 | loss: 0.0696355\n",
      "\tspeed: 0.2948s/iter; left time: 534.7065s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0616970\n",
      "\tspeed: 0.2952s/iter; left time: 506.0100s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0681653\n",
      "\tspeed: 0.2945s/iter; left time: 475.2546s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0574196\n",
      "\tspeed: 0.2957s/iter; left time: 447.6297s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0655745\n",
      "\tspeed: 0.2957s/iter; left time: 418.1390s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0559276\n",
      "\tspeed: 0.2957s/iter; left time: 388.5189s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0780387\n",
      "\tspeed: 0.2585s/iter; left time: 313.7586s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0584715\n",
      "\tspeed: 0.2920s/iter; left time: 325.3351s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0662125\n",
      "\tspeed: 0.2945s/iter; left time: 298.6621s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0599819\n",
      "\tspeed: 0.2909s/iter; left time: 265.8804s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0728897\n",
      "\tspeed: 0.2930s/iter; left time: 238.5049s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0773438\n",
      "\tspeed: 0.2957s/iter; left time: 211.1256s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0788598\n",
      "\tspeed: 0.2926s/iter; left time: 179.6833s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0570278\n",
      "\tspeed: 0.2931s/iter; left time: 150.6673s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0642013\n",
      "\tspeed: 0.2935s/iter; left time: 121.4931s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0573507\n",
      "\tspeed: 0.2930s/iter; left time: 91.9999s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0681319\n",
      "\tspeed: 0.2905s/iter; left time: 62.1722s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0523361\n",
      "\tspeed: 0.2927s/iter; left time: 33.3729s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0682335\n",
      "\tspeed: 0.2918s/iter; left time: 4.0847s\n",
      "Epoch: 20 cost time: 00h:13m:13.66s\n",
      "Epoch: 20 | Train Loss: 0.0641991 Vali Loss: 0.0574392 Test Loss: 0.0654879\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.01031138002872467, rmse:0.10154496878385544, mae:0.06399503350257874, rse:0.29813823103904724\n",
      "success delete checkpoints\n",
      "Intermediate time for ES and pred_len 24: 02h:29m:06.15s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "train 86619\n",
      "val 18435\n",
      "test 18435\n",
      "[2024-11-06 21:22:28,203] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 21:22:29,158] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 21:22:29,159] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 21:22:29,159] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 21:22:29,253] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 21:22:29,253] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 21:22:30,840] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 21:22:30,842] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 21:22:30,842] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 21:22:30,844] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 21:22:30,844] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 21:22:30,844] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 21:22:30,844] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 21:22:30,844] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 21:22:30,844] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 21:22:30,844] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 21:22:31,216] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 21:22:31,217] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 21:22:31,217] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 200.31 GB, percent = 26.5%\n",
      "[2024-11-06 21:22:31,349] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 21:22:31,350] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 21:22:31,350] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 200.31 GB, percent = 26.5%\n",
      "[2024-11-06 21:22:31,351] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 21:22:31,479] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 21:22:31,480] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 21:22:31,480] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 200.32 GB, percent = 26.5%\n",
      "[2024-11-06 21:22:31,481] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 21:22:31,481] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 21:22:31,481] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 21:22:31,481] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7dbd90bcd0>\n",
      "[2024-11-06 21:22:31,482] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 21:22:31,483] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 21:22:31,484] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1739196\n",
      "\tspeed: 0.3349s/iter; left time: 18089.2651s\n",
      "\titers: 200, epoch: 1 | loss: 0.2144041\n",
      "\tspeed: 0.2306s/iter; left time: 12433.3491s\n",
      "\titers: 300, epoch: 1 | loss: 0.1532565\n",
      "\tspeed: 0.1775s/iter; left time: 9553.2908s\n",
      "\titers: 400, epoch: 1 | loss: 0.1253511\n",
      "\tspeed: 0.1757s/iter; left time: 9440.2859s\n",
      "\titers: 500, epoch: 1 | loss: 0.1204773\n",
      "\tspeed: 0.1265s/iter; left time: 6784.9403s\n",
      "\titers: 600, epoch: 1 | loss: 0.1142639\n",
      "\tspeed: 0.1168s/iter; left time: 6251.8014s\n",
      "\titers: 700, epoch: 1 | loss: 0.0974596\n",
      "\tspeed: 0.1197s/iter; left time: 6393.7442s\n",
      "\titers: 800, epoch: 1 | loss: 0.1103355\n",
      "\tspeed: 0.1208s/iter; left time: 6442.0055s\n",
      "\titers: 900, epoch: 1 | loss: 0.1300370\n",
      "\tspeed: 0.1236s/iter; left time: 6578.0492s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1195645\n",
      "\tspeed: 0.1239s/iter; left time: 6582.1466s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1116992\n",
      "\tspeed: 0.1177s/iter; left time: 6239.6180s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1012533\n",
      "\tspeed: 0.1091s/iter; left time: 5774.9956s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1047686\n",
      "\tspeed: 0.1241s/iter; left time: 6556.5192s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1270810\n",
      "\tspeed: 0.1152s/iter; left time: 6070.8570s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1075406\n",
      "\tspeed: 0.1148s/iter; left time: 6042.2067s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1100129\n",
      "\tspeed: 0.1219s/iter; left time: 6402.1489s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1077081\n",
      "\tspeed: 0.1138s/iter; left time: 5964.5350s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1054141\n",
      "\tspeed: 0.1217s/iter; left time: 6368.7362s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1165149\n",
      "\tspeed: 0.1216s/iter; left time: 6349.6970s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1274147\n",
      "\tspeed: 0.1225s/iter; left time: 6386.7294s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1014276\n",
      "\tspeed: 0.1232s/iter; left time: 6408.9703s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1310587\n",
      "\tspeed: 0.1157s/iter; left time: 6009.4553s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0839444\n",
      "\tspeed: 0.1285s/iter; left time: 6658.3922s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1138526\n",
      "\tspeed: 0.1302s/iter; left time: 6736.0648s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1060143\n",
      "\tspeed: 0.1125s/iter; left time: 5806.1827s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1046387\n",
      "\tspeed: 0.1232s/iter; left time: 6348.6155s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0988716\n",
      "\tspeed: 0.1265s/iter; left time: 6502.2203s\n",
      "Epoch: 1 cost time: 00h:06m:06.26s\n",
      "Epoch: 1 | Train Loss: 0.1192877 Vali Loss: 0.0885145 Test Loss: 0.1017348\n",
      "Validation loss decreased (inf --> 0.088514).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1114161\n",
      "\tspeed: 1.0756s/iter; left time: 55194.4212s\n",
      "\titers: 200, epoch: 2 | loss: 0.0880713\n",
      "\tspeed: 0.1129s/iter; left time: 5783.6294s\n",
      "\titers: 300, epoch: 2 | loss: 0.0935926\n",
      "\tspeed: 0.1207s/iter; left time: 6167.5369s\n",
      "\titers: 400, epoch: 2 | loss: 0.1158394\n",
      "\tspeed: 0.1196s/iter; left time: 6103.6429s\n",
      "\titers: 500, epoch: 2 | loss: 0.1065506\n",
      "\tspeed: 0.1139s/iter; left time: 5796.7456s\n",
      "\titers: 600, epoch: 2 | loss: 0.1003362\n",
      "\tspeed: 0.1138s/iter; left time: 5782.5510s\n",
      "\titers: 700, epoch: 2 | loss: 0.0844919\n",
      "\tspeed: 0.1184s/iter; left time: 6005.2985s\n",
      "\titers: 800, epoch: 2 | loss: 0.1042529\n",
      "\tspeed: 0.1142s/iter; left time: 5778.3446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1094424\n",
      "\tspeed: 0.1203s/iter; left time: 6074.7599s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1038884\n",
      "\tspeed: 0.1187s/iter; left time: 5984.4252s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0869347\n",
      "\tspeed: 0.1206s/iter; left time: 6069.5790s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1003056\n",
      "\tspeed: 0.1144s/iter; left time: 5744.7679s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1251987\n",
      "\tspeed: 0.1096s/iter; left time: 5491.7749s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0849392\n",
      "\tspeed: 0.1185s/iter; left time: 5927.3832s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1105758\n",
      "\tspeed: 0.1076s/iter; left time: 5370.5067s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0899217\n",
      "\tspeed: 0.1177s/iter; left time: 5862.8533s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0867076\n",
      "\tspeed: 0.1174s/iter; left time: 5838.8530s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0814728\n",
      "\tspeed: 0.1152s/iter; left time: 5714.0127s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1087647\n",
      "\tspeed: 0.1137s/iter; left time: 5631.1269s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0885592\n",
      "\tspeed: 0.1175s/iter; left time: 5804.1780s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1136911\n",
      "\tspeed: 0.1138s/iter; left time: 5610.1530s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0726355\n",
      "\tspeed: 0.1146s/iter; left time: 5638.2385s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0935826\n",
      "\tspeed: 0.1200s/iter; left time: 5895.5986s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0964244\n",
      "\tspeed: 0.1224s/iter; left time: 6000.1768s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0998940\n",
      "\tspeed: 0.1102s/iter; left time: 5390.0090s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1029520\n",
      "\tspeed: 0.1099s/iter; left time: 5366.3611s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0968798\n",
      "\tspeed: 0.1150s/iter; left time: 5604.4234s\n",
      "Epoch: 2 cost time: 00h:05m:13.60s\n",
      "Epoch: 2 | Train Loss: 0.0978376 Vali Loss: 0.0838341 Test Loss: 0.0963197\n",
      "Validation loss decreased (0.088514 --> 0.083834).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0851207\n",
      "\tspeed: 0.8892s/iter; left time: 43221.2629s\n",
      "\titers: 200, epoch: 3 | loss: 0.1056099\n",
      "\tspeed: 0.1176s/iter; left time: 5705.3958s\n",
      "\titers: 300, epoch: 3 | loss: 0.1017982\n",
      "\tspeed: 0.1159s/iter; left time: 5609.4618s\n",
      "\titers: 400, epoch: 3 | loss: 0.1010475\n",
      "\tspeed: 0.1034s/iter; left time: 4996.9866s\n",
      "\titers: 500, epoch: 3 | loss: 0.1085900\n",
      "\tspeed: 0.1144s/iter; left time: 5512.7030s\n",
      "\titers: 600, epoch: 3 | loss: 0.0984371\n",
      "\tspeed: 0.1193s/iter; left time: 5737.2714s\n",
      "\titers: 700, epoch: 3 | loss: 0.1224850\n",
      "\tspeed: 0.1199s/iter; left time: 5757.0735s\n",
      "\titers: 800, epoch: 3 | loss: 0.0928301\n",
      "\tspeed: 0.1206s/iter; left time: 5776.0226s\n",
      "\titers: 900, epoch: 3 | loss: 0.0985246\n",
      "\tspeed: 0.1107s/iter; left time: 5292.3387s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0860857\n",
      "\tspeed: 0.1160s/iter; left time: 5534.1989s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0887125\n",
      "\tspeed: 0.1145s/iter; left time: 5450.0523s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0889664\n",
      "\tspeed: 0.1150s/iter; left time: 5464.2737s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0917966\n",
      "\tspeed: 0.1150s/iter; left time: 5453.1567s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0922156\n",
      "\tspeed: 0.1197s/iter; left time: 5662.4024s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0980079\n",
      "\tspeed: 0.1189s/iter; left time: 5611.9864s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0874681\n",
      "\tspeed: 0.1189s/iter; left time: 5602.5834s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0832537\n",
      "\tspeed: 0.1179s/iter; left time: 5543.0967s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0936476\n",
      "\tspeed: 0.1157s/iter; left time: 5427.5916s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0857114\n",
      "\tspeed: 0.1190s/iter; left time: 5571.0722s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0911580\n",
      "\tspeed: 0.1173s/iter; left time: 5479.0164s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1001031\n",
      "\tspeed: 0.1156s/iter; left time: 5387.9831s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0724582\n",
      "\tspeed: 0.1201s/iter; left time: 5585.3614s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0850698\n",
      "\tspeed: 0.1190s/iter; left time: 5521.8943s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0901520\n",
      "\tspeed: 0.1136s/iter; left time: 5260.4429s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0926558\n",
      "\tspeed: 0.1128s/iter; left time: 5212.7738s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1088238\n",
      "\tspeed: 0.1117s/iter; left time: 5148.7199s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0854340\n",
      "\tspeed: 0.1113s/iter; left time: 5119.0202s\n",
      "Epoch: 3 cost time: 00h:05m:14.01s\n",
      "Epoch: 3 | Train Loss: 0.0937830 Vali Loss: 0.0813476 Test Loss: 0.0943848\n",
      "Validation loss decreased (0.083834 --> 0.081348).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0897278\n",
      "\tspeed: 0.8875s/iter; left time: 40740.4108s\n",
      "\titers: 200, epoch: 4 | loss: 0.0963646\n",
      "\tspeed: 0.1126s/iter; left time: 5156.1645s\n",
      "\titers: 300, epoch: 4 | loss: 0.1059084\n",
      "\tspeed: 0.1060s/iter; left time: 4842.9500s\n",
      "\titers: 400, epoch: 4 | loss: 0.0840485\n",
      "\tspeed: 0.1177s/iter; left time: 5367.1062s\n",
      "\titers: 500, epoch: 4 | loss: 0.0822896\n",
      "\tspeed: 0.1182s/iter; left time: 5377.7911s\n",
      "\titers: 600, epoch: 4 | loss: 0.0996651\n",
      "\tspeed: 0.1025s/iter; left time: 4651.9100s\n",
      "\titers: 700, epoch: 4 | loss: 0.0984668\n",
      "\tspeed: 0.1093s/iter; left time: 4953.8730s\n",
      "\titers: 800, epoch: 4 | loss: 0.0931956\n",
      "\tspeed: 0.1145s/iter; left time: 5174.3336s\n",
      "\titers: 900, epoch: 4 | loss: 0.0824730\n",
      "\tspeed: 0.1116s/iter; left time: 5035.4930s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0812952\n",
      "\tspeed: 0.0974s/iter; left time: 4382.0174s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0911959\n",
      "\tspeed: 0.1050s/iter; left time: 4715.1544s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0747328\n",
      "\tspeed: 0.1099s/iter; left time: 4923.6523s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1002364\n",
      "\tspeed: 0.1135s/iter; left time: 5075.1999s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1054076\n",
      "\tspeed: 0.1145s/iter; left time: 5105.0655s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0972272\n",
      "\tspeed: 0.1100s/iter; left time: 4895.3602s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0871698\n",
      "\tspeed: 0.1101s/iter; left time: 4886.8397s\n",
      "\titers: 1700, epoch: 4 | loss: 0.1150167\n",
      "\tspeed: 0.1112s/iter; left time: 4926.5821s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0862599\n",
      "\tspeed: 0.1108s/iter; left time: 4899.6461s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0814910\n",
      "\tspeed: 0.1122s/iter; left time: 4950.4209s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0896744\n",
      "\tspeed: 0.1086s/iter; left time: 4779.9584s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1015588\n",
      "\tspeed: 0.1136s/iter; left time: 4987.3793s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0877589\n",
      "\tspeed: 0.1098s/iter; left time: 4809.7000s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0673089\n",
      "\tspeed: 0.1079s/iter; left time: 4714.2533s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0895781\n",
      "\tspeed: 0.1119s/iter; left time: 4878.0084s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0956826\n",
      "\tspeed: 0.1108s/iter; left time: 4819.9730s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1026545\n",
      "\tspeed: 0.1087s/iter; left time: 4719.8644s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0940452\n",
      "\tspeed: 0.1110s/iter; left time: 4807.8114s\n",
      "Epoch: 4 cost time: 00h:04m:59.69s\n",
      "Epoch: 4 | Train Loss: 0.0915721 Vali Loss: 0.0794971 Test Loss: 0.0927825\n",
      "Validation loss decreased (0.081348 --> 0.079497).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1073764\n",
      "\tspeed: 0.9054s/iter; left time: 39110.7071s\n",
      "\titers: 200, epoch: 5 | loss: 0.0932742\n",
      "\tspeed: 0.1655s/iter; left time: 7133.9256s\n",
      "\titers: 300, epoch: 5 | loss: 0.0888053\n",
      "\tspeed: 0.1948s/iter; left time: 8374.9554s\n",
      "\titers: 400, epoch: 5 | loss: 0.0817232\n",
      "\tspeed: 0.3014s/iter; left time: 12927.7503s\n",
      "\titers: 500, epoch: 5 | loss: 0.0967489\n",
      "\tspeed: 0.3028s/iter; left time: 12958.8298s\n",
      "\titers: 600, epoch: 5 | loss: 0.0890596\n",
      "\tspeed: 0.3014s/iter; left time: 12869.6601s\n",
      "\titers: 700, epoch: 5 | loss: 0.0845574\n",
      "\tspeed: 0.2990s/iter; left time: 12737.5137s\n",
      "\titers: 800, epoch: 5 | loss: 0.0843758\n",
      "\tspeed: 0.2994s/iter; left time: 12725.6379s\n",
      "\titers: 900, epoch: 5 | loss: 0.0996287\n",
      "\tspeed: 0.2945s/iter; left time: 12484.5675s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1013612\n",
      "\tspeed: 0.2925s/iter; left time: 12373.6407s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1058257\n",
      "\tspeed: 0.2968s/iter; left time: 12525.5678s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0811922\n",
      "\tspeed: 0.2963s/iter; left time: 12474.1398s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0874032\n",
      "\tspeed: 0.2928s/iter; left time: 12296.7000s\n",
      "\titers: 1400, epoch: 5 | loss: 0.1089877\n",
      "\tspeed: 0.2933s/iter; left time: 12289.1784s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1104313\n",
      "\tspeed: 0.2934s/iter; left time: 12264.4564s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0961720\n",
      "\tspeed: 0.2931s/iter; left time: 12221.2013s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0835320\n",
      "\tspeed: 0.2946s/iter; left time: 12254.6008s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0784791\n",
      "\tspeed: 0.2941s/iter; left time: 12203.0050s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0762402\n",
      "\tspeed: 0.2927s/iter; left time: 12115.6500s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0944968\n",
      "\tspeed: 0.2943s/iter; left time: 12155.2079s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0831788\n",
      "\tspeed: 0.2920s/iter; left time: 12029.3556s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0786426\n",
      "\tspeed: 0.2930s/iter; left time: 12043.3206s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0824194\n",
      "\tspeed: 0.2931s/iter; left time: 12017.0799s\n",
      "\titers: 2400, epoch: 5 | loss: 0.1081757\n",
      "\tspeed: 0.2933s/iter; left time: 11996.8209s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0773193\n",
      "\tspeed: 0.2971s/iter; left time: 12121.2993s\n",
      "\titers: 2600, epoch: 5 | loss: 0.1076055\n",
      "\tspeed: 0.2914s/iter; left time: 11858.0560s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0960992\n",
      "\tspeed: 0.2934s/iter; left time: 11911.6728s\n",
      "Epoch: 5 cost time: 00h:12m:40.49s\n",
      "Epoch: 5 | Train Loss: 0.0900673 Vali Loss: 0.0793153 Test Loss: 0.0923016\n",
      "Validation loss decreased (0.079497 --> 0.079315).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0948153\n",
      "\tspeed: 2.6753s/iter; left time: 108325.6905s\n",
      "\titers: 200, epoch: 6 | loss: 0.0963801\n",
      "\tspeed: 0.2972s/iter; left time: 12003.4773s\n",
      "\titers: 300, epoch: 6 | loss: 0.0778783\n",
      "\tspeed: 0.2892s/iter; left time: 11653.8090s\n",
      "\titers: 400, epoch: 6 | loss: 0.1053402\n",
      "\tspeed: 0.2878s/iter; left time: 11566.9758s\n",
      "\titers: 500, epoch: 6 | loss: 0.0865769\n",
      "\tspeed: 0.2920s/iter; left time: 11705.8494s\n",
      "\titers: 600, epoch: 6 | loss: 0.0941595\n",
      "\tspeed: 0.2960s/iter; left time: 11837.1500s\n",
      "\titers: 700, epoch: 6 | loss: 0.0981962\n",
      "\tspeed: 0.2955s/iter; left time: 11789.7374s\n",
      "\titers: 800, epoch: 6 | loss: 0.0904834\n",
      "\tspeed: 0.2930s/iter; left time: 11657.1955s\n",
      "\titers: 900, epoch: 6 | loss: 0.0994924\n",
      "\tspeed: 0.2946s/iter; left time: 11693.7742s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0878865\n",
      "\tspeed: 0.2968s/iter; left time: 11752.0047s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0779328\n",
      "\tspeed: 0.2982s/iter; left time: 11775.3860s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0983189\n",
      "\tspeed: 0.2964s/iter; left time: 11677.0744s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0984981\n",
      "\tspeed: 0.2945s/iter; left time: 11572.0584s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0972490\n",
      "\tspeed: 0.2963s/iter; left time: 11610.6705s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0893653\n",
      "\tspeed: 0.3003s/iter; left time: 11740.9207s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0740457\n",
      "\tspeed: 0.2938s/iter; left time: 11457.0532s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0813408\n",
      "\tspeed: 0.2875s/iter; left time: 11179.2839s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0727926\n",
      "\tspeed: 0.2892s/iter; left time: 11218.6063s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0734807\n",
      "\tspeed: 0.2943s/iter; left time: 11388.3229s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0868979\n",
      "\tspeed: 0.2739s/iter; left time: 10568.7772s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0836817\n",
      "\tspeed: 0.2792s/iter; left time: 10745.5354s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0901565\n",
      "\tspeed: 0.2921s/iter; left time: 11213.0510s\n",
      "\titers: 2300, epoch: 6 | loss: 0.1011339\n",
      "\tspeed: 0.2955s/iter; left time: 11315.1335s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0830473\n",
      "\tspeed: 0.2907s/iter; left time: 11103.8643s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0970495\n",
      "\tspeed: 0.2902s/iter; left time: 11054.8038s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0885822\n",
      "\tspeed: 0.2945s/iter; left time: 11188.0401s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0871678\n",
      "\tspeed: 0.2909s/iter; left time: 11022.8418s\n",
      "Epoch: 6 cost time: 00h:13m:11.94s\n",
      "Epoch: 6 | Train Loss: 0.0889386 Vali Loss: 0.0789065 Test Loss: 0.0917217\n",
      "Validation loss decreased (0.079315 --> 0.078906).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.1006990\n",
      "\tspeed: 2.7373s/iter; left time: 103428.5716s\n",
      "\titers: 200, epoch: 7 | loss: 0.0866785\n",
      "\tspeed: 0.2974s/iter; left time: 11207.2211s\n",
      "\titers: 300, epoch: 7 | loss: 0.0808898\n",
      "\tspeed: 0.2967s/iter; left time: 11150.4875s\n",
      "\titers: 400, epoch: 7 | loss: 0.0693945\n",
      "\tspeed: 0.2947s/iter; left time: 11047.7027s\n",
      "\titers: 500, epoch: 7 | loss: 0.0795408\n",
      "\tspeed: 0.2883s/iter; left time: 10779.7278s\n",
      "\titers: 600, epoch: 7 | loss: 0.0907665\n",
      "\tspeed: 0.2911s/iter; left time: 10855.1508s\n",
      "\titers: 700, epoch: 7 | loss: 0.0904735\n",
      "\tspeed: 0.2916s/iter; left time: 10842.6636s\n",
      "\titers: 800, epoch: 7 | loss: 0.0856610\n",
      "\tspeed: 0.2940s/iter; left time: 10901.7548s\n",
      "\titers: 900, epoch: 7 | loss: 0.0861461\n",
      "\tspeed: 0.2939s/iter; left time: 10868.7868s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0909739\n",
      "\tspeed: 0.2988s/iter; left time: 11021.2396s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0836673\n",
      "\tspeed: 0.2727s/iter; left time: 10032.7039s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0983244\n",
      "\tspeed: 0.2941s/iter; left time: 10787.6753s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0964693\n",
      "\tspeed: 0.2955s/iter; left time: 10811.0304s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0702755\n",
      "\tspeed: 0.2956s/iter; left time: 10783.6507s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0905479\n",
      "\tspeed: 0.2961s/iter; left time: 10774.0135s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0849930\n",
      "\tspeed: 0.2953s/iter; left time: 10713.3767s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0755247\n",
      "\tspeed: 0.2939s/iter; left time: 10635.5315s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0872301\n",
      "\tspeed: 0.2925s/iter; left time: 10556.4165s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0874058\n",
      "\tspeed: 0.2970s/iter; left time: 10686.1087s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0954485\n",
      "\tspeed: 0.2929s/iter; left time: 10509.4455s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0784412\n",
      "\tspeed: 0.2923s/iter; left time: 10459.1527s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0922952\n",
      "\tspeed: 0.2873s/iter; left time: 10253.9727s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0917726\n",
      "\tspeed: 0.2925s/iter; left time: 10410.3404s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0770104\n",
      "\tspeed: 0.2912s/iter; left time: 10333.3801s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0720009\n",
      "\tspeed: 0.2988s/iter; left time: 10571.8208s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0896353\n",
      "\tspeed: 0.2948s/iter; left time: 10402.8222s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0816492\n",
      "\tspeed: 0.2947s/iter; left time: 10367.7862s\n",
      "Epoch: 7 cost time: 00h:13m:13.90s\n",
      "Epoch: 7 | Train Loss: 0.0880339 Vali Loss: 0.0789915 Test Loss: 0.0913250\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0836011\n",
      "\tspeed: 2.6905s/iter; left time: 94381.7336s\n",
      "\titers: 200, epoch: 8 | loss: 0.0835516\n",
      "\tspeed: 0.2668s/iter; left time: 9333.2198s\n",
      "\titers: 300, epoch: 8 | loss: 0.0847515\n",
      "\tspeed: 0.2779s/iter; left time: 9691.3773s\n",
      "\titers: 400, epoch: 8 | loss: 0.0913114\n",
      "\tspeed: 0.2663s/iter; left time: 9262.2462s\n",
      "\titers: 500, epoch: 8 | loss: 0.0967694\n",
      "\tspeed: 0.2958s/iter; left time: 10256.7473s\n",
      "\titers: 600, epoch: 8 | loss: 0.0784193\n",
      "\tspeed: 0.2936s/iter; left time: 10150.7247s\n",
      "\titers: 700, epoch: 8 | loss: 0.0981805\n",
      "\tspeed: 0.2958s/iter; left time: 10198.6010s\n",
      "\titers: 800, epoch: 8 | loss: 0.0869813\n",
      "\tspeed: 0.2998s/iter; left time: 10305.2646s\n",
      "\titers: 900, epoch: 8 | loss: 0.0829331\n",
      "\tspeed: 0.2983s/iter; left time: 10224.2419s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0763810\n",
      "\tspeed: 0.2965s/iter; left time: 10132.6719s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0832453\n",
      "\tspeed: 0.2960s/iter; left time: 10086.4737s\n",
      "\titers: 1200, epoch: 8 | loss: 0.1070350\n",
      "\tspeed: 0.2967s/iter; left time: 10080.9391s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0874798\n",
      "\tspeed: 0.2916s/iter; left time: 9878.0572s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0808765\n",
      "\tspeed: 0.2971s/iter; left time: 10035.8159s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0981219\n",
      "\tspeed: 0.2975s/iter; left time: 10020.1176s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0913258\n",
      "\tspeed: 0.2965s/iter; left time: 9957.2870s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0919146\n",
      "\tspeed: 0.2965s/iter; left time: 9926.9356s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0799563\n",
      "\tspeed: 0.2935s/iter; left time: 9795.3828s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0811614\n",
      "\tspeed: 0.2937s/iter; left time: 9774.2947s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0925282\n",
      "\tspeed: 0.2976s/iter; left time: 9872.7206s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0810683\n",
      "\tspeed: 0.2926s/iter; left time: 9677.7279s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0933330\n",
      "\tspeed: 0.2948s/iter; left time: 9723.7882s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0888106\n",
      "\tspeed: 0.2957s/iter; left time: 9722.3015s\n",
      "\titers: 2400, epoch: 8 | loss: 0.1063195\n",
      "\tspeed: 0.2961s/iter; left time: 9704.7781s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0858399\n",
      "\tspeed: 0.2929s/iter; left time: 9571.9079s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0909246\n",
      "\tspeed: 0.2929s/iter; left time: 9542.3447s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0953829\n",
      "\tspeed: 0.2933s/iter; left time: 9524.8766s\n",
      "Epoch: 8 cost time: 00h:13m:11.89s\n",
      "Epoch: 8 | Train Loss: 0.0871098 Vali Loss: 0.0792107 Test Loss: 0.0921087\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0804273\n",
      "\tspeed: 2.6171s/iter; left time: 84723.5669s\n",
      "\titers: 200, epoch: 9 | loss: 0.0919585\n",
      "\tspeed: 0.2906s/iter; left time: 9378.8018s\n",
      "\titers: 300, epoch: 9 | loss: 0.0770723\n",
      "\tspeed: 0.2921s/iter; left time: 9399.1444s\n",
      "\titers: 400, epoch: 9 | loss: 0.0806350\n",
      "\tspeed: 0.2909s/iter; left time: 9329.4477s\n",
      "\titers: 500, epoch: 9 | loss: 0.0801595\n",
      "\tspeed: 0.2904s/iter; left time: 9284.5542s\n",
      "\titers: 600, epoch: 9 | loss: 0.0895307\n",
      "\tspeed: 0.2881s/iter; left time: 9183.2561s\n",
      "\titers: 700, epoch: 9 | loss: 0.0865196\n",
      "\tspeed: 0.2906s/iter; left time: 9232.0142s\n",
      "\titers: 800, epoch: 9 | loss: 0.0818526\n",
      "\tspeed: 0.2939s/iter; left time: 9308.7783s\n",
      "\titers: 900, epoch: 9 | loss: 0.0874848\n",
      "\tspeed: 0.2897s/iter; left time: 9147.5181s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0945158\n",
      "\tspeed: 0.2900s/iter; left time: 9127.2835s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0849675\n",
      "\tspeed: 0.2918s/iter; left time: 9153.6485s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0780940\n",
      "\tspeed: 0.2936s/iter; left time: 9181.1833s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0829888\n",
      "\tspeed: 0.2914s/iter; left time: 9085.2443s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0841589\n",
      "\tspeed: 0.2910s/iter; left time: 9040.9192s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0912355\n",
      "\tspeed: 0.2923s/iter; left time: 9053.6309s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0823848\n",
      "\tspeed: 0.2932s/iter; left time: 9053.0175s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0757359\n",
      "\tspeed: 0.2935s/iter; left time: 9031.8053s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0781283\n",
      "\tspeed: 0.2891s/iter; left time: 8868.8081s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0810708\n",
      "\tspeed: 0.2800s/iter; left time: 8559.8160s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0773909\n",
      "\tspeed: 0.2772s/iter; left time: 8447.6593s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0805786\n",
      "\tspeed: 0.2942s/iter; left time: 8934.3607s\n",
      "\titers: 2200, epoch: 9 | loss: 0.1005406\n",
      "\tspeed: 0.2902s/iter; left time: 8786.1972s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0954605\n",
      "\tspeed: 0.2924s/iter; left time: 8821.5749s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0892670\n",
      "\tspeed: 0.2939s/iter; left time: 8836.9618s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0709338\n",
      "\tspeed: 0.2864s/iter; left time: 8584.5901s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0761114\n",
      "\tspeed: 0.2909s/iter; left time: 8690.4636s\n",
      "\titers: 2700, epoch: 9 | loss: 0.1021582\n",
      "\tspeed: 0.2870s/iter; left time: 8544.7895s\n",
      "Epoch: 9 cost time: 00h:13m:05.46s\n",
      "Epoch: 9 | Train Loss: 0.0862821 Vali Loss: 0.0793193 Test Loss: 0.0916680\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0958142\n",
      "\tspeed: 2.6179s/iter; left time: 77663.8317s\n",
      "\titers: 200, epoch: 10 | loss: 0.0714865\n",
      "\tspeed: 0.2852s/iter; left time: 8433.8299s\n",
      "\titers: 300, epoch: 10 | loss: 0.0873062\n",
      "\tspeed: 0.2926s/iter; left time: 8623.3485s\n",
      "\titers: 400, epoch: 10 | loss: 0.0767352\n",
      "\tspeed: 0.2930s/iter; left time: 8603.3691s\n",
      "\titers: 500, epoch: 10 | loss: 0.0937819\n",
      "\tspeed: 0.2954s/iter; left time: 8644.5318s\n",
      "\titers: 600, epoch: 10 | loss: 0.0906941\n",
      "\tspeed: 0.2911s/iter; left time: 8491.6335s\n",
      "\titers: 700, epoch: 10 | loss: 0.0840840\n",
      "\tspeed: 0.2905s/iter; left time: 8444.4189s\n",
      "\titers: 800, epoch: 10 | loss: 0.0890499\n",
      "\tspeed: 0.2888s/iter; left time: 8365.7636s\n",
      "\titers: 900, epoch: 10 | loss: 0.0857239\n",
      "\tspeed: 0.2926s/iter; left time: 8445.3941s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0871620\n",
      "\tspeed: 0.2841s/iter; left time: 8172.7055s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0906965\n",
      "\tspeed: 0.2613s/iter; left time: 7491.4303s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0791534\n",
      "\tspeed: 0.2927s/iter; left time: 8362.6008s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0808941\n",
      "\tspeed: 0.2893s/iter; left time: 8234.1645s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0863850\n",
      "\tspeed: 0.2945s/iter; left time: 8353.9343s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0920919\n",
      "\tspeed: 0.2844s/iter; left time: 8040.4261s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0846921\n",
      "\tspeed: 0.2917s/iter; left time: 8217.5059s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0882378\n",
      "\tspeed: 0.2896s/iter; left time: 8128.5998s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0777712\n",
      "\tspeed: 0.2945s/iter; left time: 8235.1589s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0888049\n",
      "\tspeed: 0.2908s/iter; left time: 8103.0346s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0931280\n",
      "\tspeed: 0.2866s/iter; left time: 7958.7094s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0717681\n",
      "\tspeed: 0.2950s/iter; left time: 8161.0696s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0923332\n",
      "\tspeed: 0.2896s/iter; left time: 7983.0800s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0782755\n",
      "\tspeed: 0.2921s/iter; left time: 8022.6826s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0821969\n",
      "\tspeed: 0.2928s/iter; left time: 8014.1006s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0741531\n",
      "\tspeed: 0.2909s/iter; left time: 7933.1673s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0792409\n",
      "\tspeed: 0.2898s/iter; left time: 7874.0146s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0838837\n",
      "\tspeed: 0.2923s/iter; left time: 7912.2670s\n",
      "Epoch: 10 cost time: 00h:13m:04.62s\n",
      "Epoch: 10 | Train Loss: 0.0853745 Vali Loss: 0.0794854 Test Loss: 0.0908878\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0803921\n",
      "\tspeed: 2.6690s/iter; left time: 71958.2694s\n",
      "\titers: 200, epoch: 11 | loss: 0.0813812\n",
      "\tspeed: 0.2318s/iter; left time: 6227.6512s\n",
      "\titers: 300, epoch: 11 | loss: 0.0909247\n",
      "\tspeed: 0.1732s/iter; left time: 4635.1552s\n",
      "\titers: 400, epoch: 11 | loss: 0.0719694\n",
      "\tspeed: 0.1736s/iter; left time: 4629.6714s\n",
      "\titers: 500, epoch: 11 | loss: 0.0962602\n",
      "\tspeed: 0.1730s/iter; left time: 4595.4777s\n",
      "\titers: 600, epoch: 11 | loss: 0.0719670\n",
      "\tspeed: 0.1673s/iter; left time: 4425.8724s\n",
      "\titers: 700, epoch: 11 | loss: 0.0934583\n",
      "\tspeed: 0.1748s/iter; left time: 4609.1195s\n",
      "\titers: 800, epoch: 11 | loss: 0.0807743\n",
      "\tspeed: 0.1483s/iter; left time: 3894.6258s\n",
      "\titers: 900, epoch: 11 | loss: 0.0776519\n",
      "\tspeed: 0.1484s/iter; left time: 3883.1023s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0848232\n",
      "\tspeed: 0.1704s/iter; left time: 4439.7430s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0793040\n",
      "\tspeed: 0.1676s/iter; left time: 4349.8026s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0730033\n",
      "\tspeed: 0.1728s/iter; left time: 4469.5739s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0879046\n",
      "\tspeed: 0.1724s/iter; left time: 4441.6337s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0816234\n",
      "\tspeed: 0.1648s/iter; left time: 4229.8346s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0981955\n",
      "\tspeed: 0.1697s/iter; left time: 4338.0327s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0794534\n",
      "\tspeed: 0.1576s/iter; left time: 4011.6513s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0796687\n",
      "\tspeed: 0.1657s/iter; left time: 4202.0532s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0844484\n",
      "\tspeed: 0.1699s/iter; left time: 4290.6471s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0844356\n",
      "\tspeed: 0.1704s/iter; left time: 4288.3780s\n",
      "\titers: 2000, epoch: 11 | loss: 0.1001206\n",
      "\tspeed: 0.1667s/iter; left time: 4177.2205s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0809310\n",
      "\tspeed: 0.1745s/iter; left time: 4356.6868s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0737107\n",
      "\tspeed: 0.1685s/iter; left time: 4189.9612s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0718318\n",
      "\tspeed: 0.1739s/iter; left time: 4306.0985s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0838007\n",
      "\tspeed: 0.1737s/iter; left time: 4282.4020s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0842403\n",
      "\tspeed: 0.1716s/iter; left time: 4213.6672s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0711001\n",
      "\tspeed: 0.1730s/iter; left time: 4231.2647s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0881789\n",
      "\tspeed: 0.1753s/iter; left time: 4269.6921s\n",
      "Epoch: 11 cost time: 00h:07m:55.77s\n",
      "Epoch: 11 | Train Loss: 0.0846703 Vali Loss: 0.0797541 Test Loss: 0.0912570\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.01997840777039528, rmse:0.14134499430656433, mae:0.09172166138887405, rse:0.4151976704597473\n",
      "success delete checkpoints\n",
      "Intermediate time for ES and pred_len 96: 02h:20m:37.13s\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "train 86403\n",
      "val 18219\n",
      "test 18219\n",
      "[2024-11-06 23:43:06,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-06 23:43:07,229] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-06 23:43:07,229] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-06 23:43:07,229] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-06 23:43:07,339] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-06 23:43:07,339] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-06 23:43:08,238] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-06 23:43:08,240] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-06 23:43:08,240] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-06 23:43:08,241] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-06 23:43:08,241] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-06 23:43:08,241] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-06 23:43:08,241] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-06 23:43:08,241] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-06 23:43:08,242] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-06 23:43:08,242] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-06 23:43:08,640] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-06 23:43:08,642] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-06 23:43:08,642] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 182.37 GB, percent = 24.2%\n",
      "[2024-11-06 23:43:08,803] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-06 23:43:08,804] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 23:43:08,804] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 182.38 GB, percent = 24.2%\n",
      "[2024-11-06 23:43:08,804] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-06 23:43:08,939] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-06 23:43:08,940] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB \n",
      "[2024-11-06 23:43:08,940] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 182.38 GB, percent = 24.2%\n",
      "[2024-11-06 23:43:08,941] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-06 23:43:08,941] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-06 23:43:08,941] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-06 23:43:08,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-06 23:43:08,942] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd74a4cfb10>\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-06 23:43:08,943] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-06 23:43:08,944] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-06 23:43:08,945] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1851819\n",
      "\tspeed: 0.2340s/iter; left time: 12613.3110s\n",
      "\titers: 200, epoch: 1 | loss: 0.1743090\n",
      "\tspeed: 0.1759s/iter; left time: 9463.0023s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006680\n",
      "\tspeed: 0.1833s/iter; left time: 9842.0356s\n",
      "\titers: 400, epoch: 1 | loss: 0.1344802\n",
      "\tspeed: 0.1886s/iter; left time: 10107.5570s\n",
      "\titers: 500, epoch: 1 | loss: 0.1337005\n",
      "\tspeed: 0.1884s/iter; left time: 10077.1920s\n",
      "\titers: 600, epoch: 1 | loss: 0.1315404\n",
      "\tspeed: 0.1863s/iter; left time: 9946.8612s\n",
      "\titers: 700, epoch: 1 | loss: 0.1127672\n",
      "\tspeed: 0.1872s/iter; left time: 9975.5336s\n",
      "\titers: 800, epoch: 1 | loss: 0.1278976\n",
      "\tspeed: 0.1844s/iter; left time: 9808.0018s\n",
      "\titers: 900, epoch: 1 | loss: 0.1180915\n",
      "\tspeed: 0.1874s/iter; left time: 9951.5580s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1063907\n",
      "\tspeed: 0.1832s/iter; left time: 9711.4801s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0993800\n",
      "\tspeed: 0.1792s/iter; left time: 9481.2988s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1136014\n",
      "\tspeed: 0.1857s/iter; left time: 9806.3972s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1104253\n",
      "\tspeed: 0.1877s/iter; left time: 9892.1512s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1095924\n",
      "\tspeed: 0.1867s/iter; left time: 9818.9382s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1212372\n",
      "\tspeed: 0.1867s/iter; left time: 9802.4064s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0899614\n",
      "\tspeed: 0.1907s/iter; left time: 9994.4412s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1038205\n",
      "\tspeed: 0.1872s/iter; left time: 9792.2944s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0922705\n",
      "\tspeed: 0.1908s/iter; left time: 9959.1809s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1044681\n",
      "\tspeed: 0.1887s/iter; left time: 9829.2592s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1270979\n",
      "\tspeed: 0.1907s/iter; left time: 9918.7790s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0999113\n",
      "\tspeed: 0.1876s/iter; left time: 9738.4098s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1046995\n",
      "\tspeed: 0.1866s/iter; left time: 9667.8941s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1138638\n",
      "\tspeed: 0.1881s/iter; left time: 9725.3508s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1073276\n",
      "\tspeed: 0.1905s/iter; left time: 9827.5698s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1118304\n",
      "\tspeed: 0.1904s/iter; left time: 9805.7565s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1119261\n",
      "\tspeed: 0.1883s/iter; left time: 9679.1997s\n",
      "\titers: 2700, epoch: 1 | loss: 0.1148166\n",
      "\tspeed: 0.1902s/iter; left time: 9757.6072s\n",
      "Epoch: 1 cost time: 00h:08m:26.21s\n",
      "Epoch: 1 | Train Loss: 0.1246477 Vali Loss: 0.0955532 Test Loss: 0.1087006\n",
      "Validation loss decreased (inf --> 0.095553).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1024846\n",
      "\tspeed: 1.7217s/iter; left time: 88155.1553s\n",
      "\titers: 200, epoch: 2 | loss: 0.0993583\n",
      "\tspeed: 0.1813s/iter; left time: 9264.9763s\n",
      "\titers: 300, epoch: 2 | loss: 0.1003881\n",
      "\tspeed: 0.1767s/iter; left time: 9009.6024s\n",
      "\titers: 400, epoch: 2 | loss: 0.1097317\n",
      "\tspeed: 0.1808s/iter; left time: 9203.8808s\n",
      "\titers: 500, epoch: 2 | loss: 0.0971216\n",
      "\tspeed: 0.1709s/iter; left time: 8683.0624s\n",
      "\titers: 600, epoch: 2 | loss: 0.0926108\n",
      "\tspeed: 0.1807s/iter; left time: 9161.9605s\n",
      "\titers: 700, epoch: 2 | loss: 0.1244076\n",
      "\tspeed: 0.1813s/iter; left time: 9172.7318s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938773\n",
      "\tspeed: 0.1767s/iter; left time: 8923.8527s\n",
      "\titers: 900, epoch: 2 | loss: 0.1216315\n",
      "\tspeed: 0.1787s/iter; left time: 9007.9237s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1277159\n",
      "\tspeed: 0.1780s/iter; left time: 8954.5583s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0993671\n",
      "\tspeed: 0.1786s/iter; left time: 8968.3044s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1004644\n",
      "\tspeed: 0.1768s/iter; left time: 8858.2723s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0896644\n",
      "\tspeed: 0.1735s/iter; left time: 8675.0740s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1010016\n",
      "\tspeed: 0.1761s/iter; left time: 8788.2156s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1075276\n",
      "\tspeed: 0.1770s/iter; left time: 8815.2609s\n",
      "\titers: 1600, epoch: 2 | loss: 0.1031320\n",
      "\tspeed: 0.1752s/iter; left time: 8707.0882s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0974855\n",
      "\tspeed: 0.1693s/iter; left time: 8397.2498s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0964450\n",
      "\tspeed: 0.1724s/iter; left time: 8534.6117s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1263181\n",
      "\tspeed: 0.1761s/iter; left time: 8701.6690s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1102505\n",
      "\tspeed: 0.1737s/iter; left time: 8563.0352s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1138867\n",
      "\tspeed: 0.1768s/iter; left time: 8699.3737s\n",
      "\titers: 2200, epoch: 2 | loss: 0.1020580\n",
      "\tspeed: 0.1711s/iter; left time: 8403.5217s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1069511\n",
      "\tspeed: 0.1753s/iter; left time: 8589.6929s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0957394\n",
      "\tspeed: 0.1738s/iter; left time: 8500.8325s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0948027\n",
      "\tspeed: 0.1740s/iter; left time: 8489.9398s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0949083\n",
      "\tspeed: 0.1741s/iter; left time: 8481.1561s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0983280\n",
      "\tspeed: 0.1763s/iter; left time: 8565.9879s\n",
      "Epoch: 2 cost time: 00h:07m:56.05s\n",
      "Epoch: 2 | Train Loss: 0.1032001 Vali Loss: 0.0898996 Test Loss: 0.1025643\n",
      "Validation loss decreased (0.095553 --> 0.089900).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0959588\n",
      "\tspeed: 1.5406s/iter; left time: 74721.5573s\n",
      "\titers: 200, epoch: 3 | loss: 0.0987292\n",
      "\tspeed: 0.1783s/iter; left time: 8628.9058s\n",
      "\titers: 300, epoch: 3 | loss: 0.1000364\n",
      "\tspeed: 0.1757s/iter; left time: 8486.2380s\n",
      "\titers: 400, epoch: 3 | loss: 0.1067015\n",
      "\tspeed: 0.1761s/iter; left time: 8489.0804s\n",
      "\titers: 500, epoch: 3 | loss: 0.0980394\n",
      "\tspeed: 0.1759s/iter; left time: 8460.6040s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914616\n",
      "\tspeed: 0.1682s/iter; left time: 8075.2761s\n",
      "\titers: 700, epoch: 3 | loss: 0.1009537\n",
      "\tspeed: 0.1676s/iter; left time: 8029.5299s\n",
      "\titers: 800, epoch: 3 | loss: 0.0949225\n",
      "\tspeed: 0.1770s/iter; left time: 8460.9929s\n",
      "\titers: 900, epoch: 3 | loss: 0.1015981\n",
      "\tspeed: 0.1735s/iter; left time: 8274.1830s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0962169\n",
      "\tspeed: 0.1722s/iter; left time: 8198.3167s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0930897\n",
      "\tspeed: 0.1729s/iter; left time: 8214.5047s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0973670\n",
      "\tspeed: 0.1694s/iter; left time: 8027.6871s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0886089\n",
      "\tspeed: 0.1735s/iter; left time: 8207.1863s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0833065\n",
      "\tspeed: 0.1760s/iter; left time: 8305.9220s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1006023\n",
      "\tspeed: 0.1739s/iter; left time: 8191.5957s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0859972\n",
      "\tspeed: 0.1716s/iter; left time: 8065.8513s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1139292\n",
      "\tspeed: 0.1725s/iter; left time: 8088.6297s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1036137\n",
      "\tspeed: 0.1690s/iter; left time: 7907.5306s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0867952\n",
      "\tspeed: 0.1718s/iter; left time: 8022.0047s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0875932\n",
      "\tspeed: 0.1759s/iter; left time: 8195.1411s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0896805\n",
      "\tspeed: 0.1775s/iter; left time: 8252.2442s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0954771\n",
      "\tspeed: 0.1709s/iter; left time: 7928.4645s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1023896\n",
      "\tspeed: 0.1773s/iter; left time: 8208.4596s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0950372\n",
      "\tspeed: 0.1742s/iter; left time: 8049.1992s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0776176\n",
      "\tspeed: 0.1515s/iter; left time: 6984.8023s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1011989\n",
      "\tspeed: 0.1594s/iter; left time: 7332.9767s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0993948\n",
      "\tspeed: 0.1766s/iter; left time: 8106.1441s\n",
      "Epoch: 3 cost time: 00h:07m:45.63s\n",
      "Epoch: 3 | Train Loss: 0.0989408 Vali Loss: 0.0870166 Test Loss: 0.0995824\n",
      "Validation loss decreased (0.089900 --> 0.087017).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0868429\n",
      "\tspeed: 1.5190s/iter; left time: 69569.9844s\n",
      "\titers: 200, epoch: 4 | loss: 0.0975831\n",
      "\tspeed: 0.1757s/iter; left time: 8027.6658s\n",
      "\titers: 300, epoch: 4 | loss: 0.1014317\n",
      "\tspeed: 0.1781s/iter; left time: 8119.7035s\n",
      "\titers: 400, epoch: 4 | loss: 0.0872647\n",
      "\tspeed: 0.1732s/iter; left time: 7881.1035s\n",
      "\titers: 500, epoch: 4 | loss: 0.1017141\n",
      "\tspeed: 0.1723s/iter; left time: 7821.2808s\n",
      "\titers: 600, epoch: 4 | loss: 0.1106457\n",
      "\tspeed: 0.1769s/iter; left time: 8012.4061s\n",
      "\titers: 700, epoch: 4 | loss: 0.1069107\n",
      "\tspeed: 0.1765s/iter; left time: 7979.9194s\n",
      "\titers: 800, epoch: 4 | loss: 0.0972689\n",
      "\tspeed: 0.1764s/iter; left time: 7954.0337s\n",
      "\titers: 900, epoch: 4 | loss: 0.0996357\n",
      "\tspeed: 0.1750s/iter; left time: 7876.8083s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0985963\n",
      "\tspeed: 0.1733s/iter; left time: 7779.8944s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0944479\n",
      "\tspeed: 0.1719s/iter; left time: 7699.5485s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1091441\n",
      "\tspeed: 0.1734s/iter; left time: 7750.8354s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1069572\n",
      "\tspeed: 0.1729s/iter; left time: 7713.4433s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0886537\n",
      "\tspeed: 0.1767s/iter; left time: 7861.6610s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1035353\n",
      "\tspeed: 0.1725s/iter; left time: 7657.5712s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0780271\n",
      "\tspeed: 0.1739s/iter; left time: 7703.4449s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0998998\n",
      "\tspeed: 0.1761s/iter; left time: 7783.5522s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0875343\n",
      "\tspeed: 0.1770s/iter; left time: 7804.7130s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0835346\n",
      "\tspeed: 0.1761s/iter; left time: 7747.1747s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0952276\n",
      "\tspeed: 0.1787s/iter; left time: 7844.0835s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0923196\n",
      "\tspeed: 0.1763s/iter; left time: 7720.1490s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0897887\n",
      "\tspeed: 0.1751s/iter; left time: 7654.1851s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1020472\n",
      "\tspeed: 0.1741s/iter; left time: 7590.0816s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1060340\n",
      "\tspeed: 0.1756s/iter; left time: 7640.4576s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0940001\n",
      "\tspeed: 0.1732s/iter; left time: 7517.2279s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0833760\n",
      "\tspeed: 0.1721s/iter; left time: 7453.5904s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1011091\n",
      "\tspeed: 0.1719s/iter; left time: 7425.0781s\n",
      "Epoch: 4 cost time: 00h:07m:52.22s\n",
      "Epoch: 4 | Train Loss: 0.0965323 Vali Loss: 0.0874201 Test Loss: 0.1006205\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.1069027\n",
      "\tspeed: 1.4946s/iter; left time: 64418.8332s\n",
      "\titers: 200, epoch: 5 | loss: 0.1000663\n",
      "\tspeed: 0.1721s/iter; left time: 7399.0076s\n",
      "\titers: 300, epoch: 5 | loss: 0.0959998\n",
      "\tspeed: 0.1759s/iter; left time: 7548.2154s\n",
      "\titers: 400, epoch: 5 | loss: 0.0807062\n",
      "\tspeed: 0.1675s/iter; left time: 7170.8308s\n",
      "\titers: 500, epoch: 5 | loss: 0.0917082\n",
      "\tspeed: 0.1789s/iter; left time: 7638.1978s\n",
      "\titers: 600, epoch: 5 | loss: 0.0883687\n",
      "\tspeed: 0.1742s/iter; left time: 7419.4640s\n",
      "\titers: 700, epoch: 5 | loss: 0.0853646\n",
      "\tspeed: 0.1765s/iter; left time: 7502.5615s\n",
      "\titers: 800, epoch: 5 | loss: 0.0945630\n",
      "\tspeed: 0.1743s/iter; left time: 7388.5578s\n",
      "\titers: 900, epoch: 5 | loss: 0.0919633\n",
      "\tspeed: 0.1704s/iter; left time: 7210.1533s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0761932\n",
      "\tspeed: 0.1759s/iter; left time: 7424.6370s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1099939\n",
      "\tspeed: 0.1747s/iter; left time: 7356.9080s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0998608\n",
      "\tspeed: 0.1768s/iter; left time: 7427.4329s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0838654\n",
      "\tspeed: 0.1743s/iter; left time: 7304.0120s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0945825\n",
      "\tspeed: 0.1762s/iter; left time: 7363.9658s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1040998\n",
      "\tspeed: 0.1766s/iter; left time: 7364.6556s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0862714\n",
      "\tspeed: 0.1764s/iter; left time: 7337.4111s\n",
      "\titers: 1700, epoch: 5 | loss: 0.1077150\n",
      "\tspeed: 0.1692s/iter; left time: 7020.5624s\n",
      "\titers: 1800, epoch: 5 | loss: 0.1165144\n",
      "\tspeed: 0.1748s/iter; left time: 7237.2350s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0993859\n",
      "\tspeed: 0.1756s/iter; left time: 7252.6070s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1117576\n",
      "\tspeed: 0.1737s/iter; left time: 7158.5743s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0852741\n",
      "\tspeed: 0.1654s/iter; left time: 6796.2096s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0945594\n",
      "\tspeed: 0.1690s/iter; left time: 6928.0071s\n",
      "\titers: 2300, epoch: 5 | loss: 0.1105174\n",
      "\tspeed: 0.1776s/iter; left time: 7263.1769s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0990333\n",
      "\tspeed: 0.1761s/iter; left time: 7186.9168s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1150469\n",
      "\tspeed: 0.1711s/iter; left time: 6963.7239s\n",
      "\titers: 2600, epoch: 5 | loss: 0.1006494\n",
      "\tspeed: 0.1744s/iter; left time: 7082.1843s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1138007\n",
      "\tspeed: 0.1789s/iter; left time: 7247.4131s\n",
      "Epoch: 5 cost time: 00h:07m:50.56s\n",
      "Epoch: 5 | Train Loss: 0.0951260 Vali Loss: 0.0857452 Test Loss: 0.0980309\n",
      "Validation loss decreased (0.087017 --> 0.085745).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0974390\n",
      "\tspeed: 1.5135s/iter; left time: 61145.4766s\n",
      "\titers: 200, epoch: 6 | loss: 0.0865491\n",
      "\tspeed: 0.1727s/iter; left time: 6961.2861s\n",
      "\titers: 300, epoch: 6 | loss: 0.0859021\n",
      "\tspeed: 0.1710s/iter; left time: 6873.1096s\n",
      "\titers: 400, epoch: 6 | loss: 0.0890579\n",
      "\tspeed: 0.1690s/iter; left time: 6776.1260s\n",
      "\titers: 500, epoch: 6 | loss: 0.0983840\n",
      "\tspeed: 0.1763s/iter; left time: 7051.7873s\n",
      "\titers: 600, epoch: 6 | loss: 0.0888871\n",
      "\tspeed: 0.1796s/iter; left time: 7165.1851s\n",
      "\titers: 700, epoch: 6 | loss: 0.1052938\n",
      "\tspeed: 0.1741s/iter; left time: 6928.2823s\n",
      "\titers: 800, epoch: 6 | loss: 0.1002935\n",
      "\tspeed: 0.1715s/iter; left time: 6808.4317s\n",
      "\titers: 900, epoch: 6 | loss: 0.1078547\n",
      "\tspeed: 0.1732s/iter; left time: 6860.2210s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0947377\n",
      "\tspeed: 0.1752s/iter; left time: 6919.6123s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0851562\n",
      "\tspeed: 0.1695s/iter; left time: 6679.2120s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0817691\n",
      "\tspeed: 0.1694s/iter; left time: 6656.6965s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0958426\n",
      "\tspeed: 0.1704s/iter; left time: 6681.0814s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1075904\n",
      "\tspeed: 0.1711s/iter; left time: 6690.0922s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0815288\n",
      "\tspeed: 0.1767s/iter; left time: 6893.0258s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0951795\n",
      "\tspeed: 0.1755s/iter; left time: 6826.6653s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0974400\n",
      "\tspeed: 0.1748s/iter; left time: 6781.6504s\n",
      "\titers: 1800, epoch: 6 | loss: 0.1055532\n",
      "\tspeed: 0.1746s/iter; left time: 6756.3681s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0950109\n",
      "\tspeed: 0.1780s/iter; left time: 6871.1985s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0736938\n",
      "\tspeed: 0.1753s/iter; left time: 6748.2879s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0744801\n",
      "\tspeed: 0.1767s/iter; left time: 6787.3349s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1003133\n",
      "\tspeed: 0.1778s/iter; left time: 6808.7553s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0902120\n",
      "\tspeed: 0.1747s/iter; left time: 6674.4301s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0791276\n",
      "\tspeed: 0.1722s/iter; left time: 6560.8602s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0900056\n",
      "\tspeed: 0.1743s/iter; left time: 6622.7987s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0873969\n",
      "\tspeed: 0.1736s/iter; left time: 6581.2691s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0976356\n",
      "\tspeed: 0.1758s/iter; left time: 6645.5714s\n",
      "Epoch: 6 cost time: 00h:07m:49.33s\n",
      "Epoch: 6 | Train Loss: 0.0940954 Vali Loss: 0.0851196 Test Loss: 0.0977633\n",
      "Validation loss decreased (0.085745 --> 0.085120).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0748992\n",
      "\tspeed: 1.5185s/iter; left time: 57249.7866s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849090\n",
      "\tspeed: 0.1661s/iter; left time: 6244.5398s\n",
      "\titers: 300, epoch: 7 | loss: 0.0861886\n",
      "\tspeed: 0.1678s/iter; left time: 6291.6247s\n",
      "\titers: 400, epoch: 7 | loss: 0.1033005\n",
      "\tspeed: 0.1684s/iter; left time: 6296.7046s\n",
      "\titers: 500, epoch: 7 | loss: 0.0787096\n",
      "\tspeed: 0.1755s/iter; left time: 6546.4198s\n",
      "\titers: 600, epoch: 7 | loss: 0.0850353\n",
      "\tspeed: 0.1756s/iter; left time: 6533.0472s\n",
      "\titers: 700, epoch: 7 | loss: 0.0958885\n",
      "\tspeed: 0.1769s/iter; left time: 6561.7094s\n",
      "\titers: 800, epoch: 7 | loss: 0.1111714\n",
      "\tspeed: 0.1757s/iter; left time: 6502.4418s\n",
      "\titers: 900, epoch: 7 | loss: 0.0901243\n",
      "\tspeed: 0.1766s/iter; left time: 6515.0700s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1107189\n",
      "\tspeed: 0.1704s/iter; left time: 6270.2092s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0905602\n",
      "\tspeed: 0.1734s/iter; left time: 6362.7525s\n",
      "\titers: 1200, epoch: 7 | loss: 0.1054845\n",
      "\tspeed: 0.1693s/iter; left time: 6197.2965s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0945631\n",
      "\tspeed: 0.1700s/iter; left time: 6206.7699s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0841719\n",
      "\tspeed: 0.1758s/iter; left time: 6398.4978s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0910673\n",
      "\tspeed: 0.1712s/iter; left time: 6212.9307s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0965386\n",
      "\tspeed: 0.1473s/iter; left time: 5330.7428s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0854635\n",
      "\tspeed: 0.1511s/iter; left time: 5454.2467s\n",
      "\titers: 1800, epoch: 7 | loss: 0.1060212\n",
      "\tspeed: 0.1748s/iter; left time: 6291.6358s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0935704\n",
      "\tspeed: 0.1774s/iter; left time: 6368.0911s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0902360\n",
      "\tspeed: 0.1755s/iter; left time: 6283.6987s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0849528\n",
      "\tspeed: 0.1773s/iter; left time: 6328.8714s\n",
      "\titers: 2200, epoch: 7 | loss: 0.1176375\n",
      "\tspeed: 0.1760s/iter; left time: 6266.4727s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0906317\n",
      "\tspeed: 0.1774s/iter; left time: 6297.8752s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0828999\n",
      "\tspeed: 0.1773s/iter; left time: 6275.4236s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0965671\n",
      "\tspeed: 0.1765s/iter; left time: 6231.6429s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0985562\n",
      "\tspeed: 0.1699s/iter; left time: 5980.0174s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0943868\n",
      "\tspeed: 0.1752s/iter; left time: 6147.9925s\n",
      "Epoch: 7 cost time: 00h:07m:44.81s\n",
      "Epoch: 7 | Train Loss: 0.0931096 Vali Loss: 0.0851773 Test Loss: 0.0973776\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.1088280\n",
      "\tspeed: 1.5095s/iter; left time: 52833.0451s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941431\n",
      "\tspeed: 0.1663s/iter; left time: 5802.6323s\n",
      "\titers: 300, epoch: 8 | loss: 0.1019938\n",
      "\tspeed: 0.1719s/iter; left time: 5982.4598s\n",
      "\titers: 400, epoch: 8 | loss: 0.0912655\n",
      "\tspeed: 0.1736s/iter; left time: 6024.0444s\n",
      "\titers: 500, epoch: 8 | loss: 0.0909525\n",
      "\tspeed: 0.1795s/iter; left time: 6209.9472s\n",
      "\titers: 600, epoch: 8 | loss: 0.0872288\n",
      "\tspeed: 0.1755s/iter; left time: 6055.0799s\n",
      "\titers: 700, epoch: 8 | loss: 0.0929560\n",
      "\tspeed: 0.1750s/iter; left time: 6021.7904s\n",
      "\titers: 800, epoch: 8 | loss: 0.0908316\n",
      "\tspeed: 0.1769s/iter; left time: 6067.3140s\n",
      "\titers: 900, epoch: 8 | loss: 0.0912967\n",
      "\tspeed: 0.1714s/iter; left time: 5861.9767s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0891263\n",
      "\tspeed: 0.1728s/iter; left time: 5894.2341s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0938829\n",
      "\tspeed: 0.1739s/iter; left time: 5912.4850s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0974915\n",
      "\tspeed: 0.1739s/iter; left time: 5894.2134s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0808229\n",
      "\tspeed: 0.1712s/iter; left time: 5788.1928s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0950685\n",
      "\tspeed: 0.1759s/iter; left time: 5928.7007s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0782723\n",
      "\tspeed: 0.1740s/iter; left time: 5846.8580s\n",
      "\titers: 1600, epoch: 8 | loss: 0.1006696\n",
      "\tspeed: 0.1779s/iter; left time: 5959.7086s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0982584\n",
      "\tspeed: 0.1733s/iter; left time: 5787.4827s\n",
      "\titers: 1800, epoch: 8 | loss: 0.1108784\n",
      "\tspeed: 0.1618s/iter; left time: 5389.2027s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0824931\n",
      "\tspeed: 0.1789s/iter; left time: 5939.1816s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0948046\n",
      "\tspeed: 0.1743s/iter; left time: 5769.1743s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0864311\n",
      "\tspeed: 0.1746s/iter; left time: 5760.4414s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0807879\n",
      "\tspeed: 0.1800s/iter; left time: 5920.6404s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0836987\n",
      "\tspeed: 0.1776s/iter; left time: 5825.1837s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0926680\n",
      "\tspeed: 0.1768s/iter; left time: 5783.0213s\n",
      "\titers: 2500, epoch: 8 | loss: 0.1010987\n",
      "\tspeed: 0.1745s/iter; left time: 5689.2755s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0829144\n",
      "\tspeed: 0.1703s/iter; left time: 5535.6839s\n",
      "\titers: 2700, epoch: 8 | loss: 0.1030142\n",
      "\tspeed: 0.1773s/iter; left time: 5744.6792s\n",
      "Epoch: 8 cost time: 00h:07m:50.52s\n",
      "Epoch: 8 | Train Loss: 0.0921610 Vali Loss: 0.0850110 Test Loss: 0.0959550\n",
      "Validation loss decreased (0.085120 --> 0.085011).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0686987\n",
      "\tspeed: 1.5096s/iter; left time: 48760.4136s\n",
      "\titers: 200, epoch: 9 | loss: 0.0957026\n",
      "\tspeed: 0.1746s/iter; left time: 5623.8325s\n",
      "\titers: 300, epoch: 9 | loss: 0.0763355\n",
      "\tspeed: 0.1722s/iter; left time: 5526.1903s\n",
      "\titers: 400, epoch: 9 | loss: 0.0954390\n",
      "\tspeed: 0.1756s/iter; left time: 5619.0760s\n",
      "\titers: 500, epoch: 9 | loss: 0.1029605\n",
      "\tspeed: 0.1730s/iter; left time: 5519.9098s\n",
      "\titers: 600, epoch: 9 | loss: 0.0960330\n",
      "\tspeed: 0.1787s/iter; left time: 5683.0330s\n",
      "\titers: 700, epoch: 9 | loss: 0.0858764\n",
      "\tspeed: 0.1761s/iter; left time: 5583.1762s\n",
      "\titers: 800, epoch: 9 | loss: 0.0828786\n",
      "\tspeed: 0.1757s/iter; left time: 5553.5182s\n",
      "\titers: 900, epoch: 9 | loss: 0.0797413\n",
      "\tspeed: 0.1788s/iter; left time: 5632.9843s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0953108\n",
      "\tspeed: 0.1722s/iter; left time: 5408.7057s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0828391\n",
      "\tspeed: 0.1760s/iter; left time: 5510.3630s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0914175\n",
      "\tspeed: 0.1720s/iter; left time: 5365.0745s\n",
      "\titers: 1300, epoch: 9 | loss: 0.1033930\n",
      "\tspeed: 0.1748s/iter; left time: 5437.6976s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0864521\n",
      "\tspeed: 0.1732s/iter; left time: 5368.8556s\n",
      "\titers: 1500, epoch: 9 | loss: 0.1114930\n",
      "\tspeed: 0.1745s/iter; left time: 5391.3088s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0917253\n",
      "\tspeed: 0.1765s/iter; left time: 5436.6096s\n",
      "\titers: 1700, epoch: 9 | loss: 0.1028408\n",
      "\tspeed: 0.1726s/iter; left time: 5300.2228s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0927188\n",
      "\tspeed: 0.1755s/iter; left time: 5370.4087s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0933398\n",
      "\tspeed: 0.1733s/iter; left time: 5285.4963s\n",
      "\titers: 2000, epoch: 9 | loss: 0.1092188\n",
      "\tspeed: 0.1747s/iter; left time: 5311.6129s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0858671\n",
      "\tspeed: 0.1776s/iter; left time: 5381.8663s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0737088\n",
      "\tspeed: 0.1711s/iter; left time: 5168.0208s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0967956\n",
      "\tspeed: 0.1754s/iter; left time: 5280.9145s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0760351\n",
      "\tspeed: 0.1771s/iter; left time: 5312.4894s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0931183\n",
      "\tspeed: 0.1706s/iter; left time: 5100.7074s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1015319\n",
      "\tspeed: 0.1701s/iter; left time: 5068.5603s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0848130\n",
      "\tspeed: 0.1789s/iter; left time: 5312.3020s\n",
      "Epoch: 9 cost time: 00h:07m:51.88s\n",
      "Epoch: 9 | Train Loss: 0.0913174 Vali Loss: 0.0850265 Test Loss: 0.0962904\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0805729\n",
      "\tspeed: 1.5055s/iter; left time: 44565.1498s\n",
      "\titers: 200, epoch: 10 | loss: 0.0930470\n",
      "\tspeed: 0.1704s/iter; left time: 5027.7663s\n",
      "\titers: 300, epoch: 10 | loss: 0.0751617\n",
      "\tspeed: 0.1693s/iter; left time: 4978.5349s\n",
      "\titers: 400, epoch: 10 | loss: 0.0914247\n",
      "\tspeed: 0.1751s/iter; left time: 5129.3513s\n",
      "\titers: 500, epoch: 10 | loss: 0.0802886\n",
      "\tspeed: 0.1698s/iter; left time: 4958.5875s\n",
      "\titers: 600, epoch: 10 | loss: 0.0841696\n",
      "\tspeed: 0.1756s/iter; left time: 5109.6622s\n",
      "\titers: 700, epoch: 10 | loss: 0.0906281\n",
      "\tspeed: 0.1740s/iter; left time: 5045.8492s\n",
      "\titers: 800, epoch: 10 | loss: 0.0927118\n",
      "\tspeed: 0.1742s/iter; left time: 5034.3120s\n",
      "\titers: 900, epoch: 10 | loss: 0.0950340\n",
      "\tspeed: 0.1627s/iter; left time: 4684.9241s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0797298\n",
      "\tspeed: 0.1743s/iter; left time: 5001.5313s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0844121\n",
      "\tspeed: 0.1795s/iter; left time: 5135.0038s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0831508\n",
      "\tspeed: 0.1750s/iter; left time: 4987.8961s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0888624\n",
      "\tspeed: 0.1717s/iter; left time: 4875.5845s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0851525\n",
      "\tspeed: 0.1727s/iter; left time: 4887.2739s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0833800\n",
      "\tspeed: 0.1717s/iter; left time: 4840.7673s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0753695\n",
      "\tspeed: 0.1770s/iter; left time: 4974.8983s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0946941\n",
      "\tspeed: 0.1722s/iter; left time: 4821.0822s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0773006\n",
      "\tspeed: 0.1760s/iter; left time: 4909.8920s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0868301\n",
      "\tspeed: 0.1750s/iter; left time: 4865.7493s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0814355\n",
      "\tspeed: 0.1721s/iter; left time: 4767.3364s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0988093\n",
      "\tspeed: 0.1749s/iter; left time: 4827.0265s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0846929\n",
      "\tspeed: 0.1747s/iter; left time: 4804.4613s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0864728\n",
      "\tspeed: 0.1708s/iter; left time: 4679.4545s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0918933\n",
      "\tspeed: 0.1747s/iter; left time: 4770.6673s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0983008\n",
      "\tspeed: 0.1766s/iter; left time: 4804.2473s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0897592\n",
      "\tspeed: 0.1742s/iter; left time: 4720.0470s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0925607\n",
      "\tspeed: 0.1770s/iter; left time: 4779.7911s\n",
      "Epoch: 10 cost time: 00h:07m:49.32s\n",
      "Epoch: 10 | Train Loss: 0.0904567 Vali Loss: 0.0865034 Test Loss: 0.0976262\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0901090\n",
      "\tspeed: 1.4913s/iter; left time: 40118.4251s\n",
      "\titers: 200, epoch: 11 | loss: 0.1055969\n",
      "\tspeed: 0.1755s/iter; left time: 4704.8351s\n",
      "\titers: 300, epoch: 11 | loss: 0.0884364\n",
      "\tspeed: 0.1746s/iter; left time: 4662.1578s\n",
      "\titers: 400, epoch: 11 | loss: 0.0924864\n",
      "\tspeed: 0.1722s/iter; left time: 4580.9323s\n",
      "\titers: 500, epoch: 11 | loss: 0.0916034\n",
      "\tspeed: 0.1722s/iter; left time: 4562.9650s\n",
      "\titers: 600, epoch: 11 | loss: 0.0817506\n",
      "\tspeed: 0.1760s/iter; left time: 4645.5250s\n",
      "\titers: 700, epoch: 11 | loss: 0.0749667\n",
      "\tspeed: 0.1529s/iter; left time: 4020.8815s\n",
      "\titers: 800, epoch: 11 | loss: 0.1020811\n",
      "\tspeed: 0.1580s/iter; left time: 4140.4894s\n",
      "\titers: 900, epoch: 11 | loss: 0.0988139\n",
      "\tspeed: 0.1733s/iter; left time: 4522.5484s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0877754\n",
      "\tspeed: 0.1740s/iter; left time: 4525.0580s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0944858\n",
      "\tspeed: 0.1723s/iter; left time: 4461.9337s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0819261\n",
      "\tspeed: 0.1747s/iter; left time: 4506.2805s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0742334\n",
      "\tspeed: 0.1754s/iter; left time: 4509.2004s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0968629\n",
      "\tspeed: 0.1721s/iter; left time: 4406.8238s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0847820\n",
      "\tspeed: 0.1756s/iter; left time: 4478.6857s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0864545\n",
      "\tspeed: 0.1762s/iter; left time: 4475.5439s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0828169\n",
      "\tspeed: 0.1755s/iter; left time: 4440.1098s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0882088\n",
      "\tspeed: 0.1760s/iter; left time: 4434.8894s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0959271\n",
      "\tspeed: 0.1778s/iter; left time: 4463.9006s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0881704\n",
      "\tspeed: 0.1714s/iter; left time: 4286.0890s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0791421\n",
      "\tspeed: 0.1773s/iter; left time: 4414.1807s\n",
      "\titers: 2200, epoch: 11 | loss: 0.1049573\n",
      "\tspeed: 0.1768s/iter; left time: 4384.8297s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0903218\n",
      "\tspeed: 0.1751s/iter; left time: 4324.2423s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0854207\n",
      "\tspeed: 0.1757s/iter; left time: 4322.5933s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0734355\n",
      "\tspeed: 0.1774s/iter; left time: 4347.1446s\n",
      "\titers: 2600, epoch: 11 | loss: 0.1020553\n",
      "\tspeed: 0.1782s/iter; left time: 4347.9104s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0855231\n",
      "\tspeed: 0.1750s/iter; left time: 4252.9506s\n",
      "Epoch: 11 cost time: 00h:07m:48.19s\n",
      "Epoch: 11 | Train Loss: 0.0895145 Vali Loss: 0.0858424 Test Loss: 0.0969368\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0810077\n",
      "\tspeed: 1.5085s/iter; left time: 36506.4445s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801957\n",
      "\tspeed: 0.1722s/iter; left time: 4150.3364s\n",
      "\titers: 300, epoch: 12 | loss: 0.0754652\n",
      "\tspeed: 0.1770s/iter; left time: 4248.9893s\n",
      "\titers: 400, epoch: 12 | loss: 0.0919357\n",
      "\tspeed: 0.1780s/iter; left time: 4255.2511s\n",
      "\titers: 500, epoch: 12 | loss: 0.0812125\n",
      "\tspeed: 0.1727s/iter; left time: 4110.4066s\n",
      "\titers: 600, epoch: 12 | loss: 0.0889706\n",
      "\tspeed: 0.1722s/iter; left time: 4080.1930s\n",
      "\titers: 700, epoch: 12 | loss: 0.0849017\n",
      "\tspeed: 0.1710s/iter; left time: 4036.3102s\n",
      "\titers: 800, epoch: 12 | loss: 0.1061019\n",
      "\tspeed: 0.1704s/iter; left time: 4004.0764s\n",
      "\titers: 900, epoch: 12 | loss: 0.0939096\n",
      "\tspeed: 0.1744s/iter; left time: 4080.5233s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0936846\n",
      "\tspeed: 0.1758s/iter; left time: 4096.5665s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0866949\n",
      "\tspeed: 0.1714s/iter; left time: 3976.6096s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0832000\n",
      "\tspeed: 0.1754s/iter; left time: 4051.8511s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0851269\n",
      "\tspeed: 0.1778s/iter; left time: 4089.1474s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0886972\n",
      "\tspeed: 0.1771s/iter; left time: 4055.4710s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0761945\n",
      "\tspeed: 0.1770s/iter; left time: 4036.3039s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0869153\n",
      "\tspeed: 0.1759s/iter; left time: 3992.4062s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0863808\n",
      "\tspeed: 0.1767s/iter; left time: 3993.0266s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0840198\n",
      "\tspeed: 0.1701s/iter; left time: 3826.5151s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0916966\n",
      "\tspeed: 0.1712s/iter; left time: 3833.9928s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0901848\n",
      "\tspeed: 0.1736s/iter; left time: 3872.5047s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0835485\n",
      "\tspeed: 0.1750s/iter; left time: 3884.8860s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0859681\n",
      "\tspeed: 0.1756s/iter; left time: 3881.3561s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0803985\n",
      "\tspeed: 0.1777s/iter; left time: 3909.2098s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0871084\n",
      "\tspeed: 0.1742s/iter; left time: 3814.6493s\n",
      "\titers: 2500, epoch: 12 | loss: 0.1035713\n",
      "\tspeed: 0.1780s/iter; left time: 3880.0119s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0860254\n",
      "\tspeed: 0.1745s/iter; left time: 3787.1830s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0909394\n",
      "\tspeed: 0.1759s/iter; left time: 3799.0007s\n",
      "Epoch: 12 cost time: 00h:07m:51.97s\n",
      "Epoch: 12 | Train Loss: 0.0886794 Vali Loss: 0.0866621 Test Loss: 0.0981965\n",
      "EarlyStopping counter: 4 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0671602\n",
      "\tspeed: 1.5105s/iter; left time: 32477.5954s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833164\n",
      "\tspeed: 0.1642s/iter; left time: 3513.2482s\n",
      "\titers: 300, epoch: 13 | loss: 0.0847787\n",
      "\tspeed: 0.1754s/iter; left time: 3735.1968s\n",
      "\titers: 400, epoch: 13 | loss: 0.0948534\n",
      "\tspeed: 0.1721s/iter; left time: 3648.7747s\n",
      "\titers: 500, epoch: 13 | loss: 0.0881113\n",
      "\tspeed: 0.1725s/iter; left time: 3640.5721s\n",
      "\titers: 600, epoch: 13 | loss: 0.0745567\n",
      "\tspeed: 0.1764s/iter; left time: 3703.5528s\n",
      "\titers: 700, epoch: 13 | loss: 0.0953708\n",
      "\tspeed: 0.1751s/iter; left time: 3658.9972s\n",
      "\titers: 800, epoch: 13 | loss: 0.0965537\n",
      "\tspeed: 0.1779s/iter; left time: 3701.3045s\n",
      "\titers: 900, epoch: 13 | loss: 0.0902738\n",
      "\tspeed: 0.1752s/iter; left time: 3627.4659s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0785292\n",
      "\tspeed: 0.1780s/iter; left time: 3667.2714s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0807858\n",
      "\tspeed: 0.1726s/iter; left time: 3537.6427s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0911001\n",
      "\tspeed: 0.1771s/iter; left time: 3613.3887s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0767872\n",
      "\tspeed: 0.1728s/iter; left time: 3507.6259s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0766429\n",
      "\tspeed: 0.1747s/iter; left time: 3528.6031s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0863304\n",
      "\tspeed: 0.1743s/iter; left time: 3502.8689s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0756501\n",
      "\tspeed: 0.1766s/iter; left time: 3532.6329s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0950997\n",
      "\tspeed: 0.1745s/iter; left time: 3473.1427s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0803195\n",
      "\tspeed: 0.1676s/iter; left time: 3319.6365s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0863769\n",
      "\tspeed: 0.1736s/iter; left time: 3420.4416s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0822119\n",
      "\tspeed: 0.1743s/iter; left time: 3416.1396s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0913368\n",
      "\tspeed: 0.1695s/iter; left time: 3304.9281s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0891962\n",
      "\tspeed: 0.1697s/iter; left time: 3291.4939s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0966165\n",
      "\tspeed: 0.1708s/iter; left time: 3297.2646s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0964020\n",
      "\tspeed: 0.1708s/iter; left time: 3280.3105s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0724683\n",
      "\tspeed: 0.1745s/iter; left time: 3333.6541s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0970746\n",
      "\tspeed: 0.1741s/iter; left time: 3307.1956s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0929971\n",
      "\tspeed: 0.1786s/iter; left time: 3374.8190s\n",
      "Epoch: 13 cost time: 00h:07m:49.48s\n",
      "Epoch: 13 | Train Loss: 0.0878175 Vali Loss: 0.0868336 Test Loss: 0.0988624\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "loading model...\n",
      "Scaled mse:0.022127792239189148, rmse:0.14875413477420807, mae:0.09595496952533722, rse:0.43678224086761475\n",
      "success delete checkpoints\n",
      "Intermediate time for ES and pred_len 168: 02h:13m:10.65s\n",
      "\n",
      "Intermediate time for ES: 07h:02m:53.93s\n",
      "\n",
      "Total time: 07h:02m:53.93s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DE 24 mae:0.09314965456724167\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'GB',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.04658650979399681,\n",
       "  'RMSE': 0.21583908796310425,\n",
       "  'MAE': 0.14624564349651337},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.04751771315932274,\n",
       "  'RMSE': 0.2179855853319168,\n",
       "  'MAE': 0.1499413400888443},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 24,\n",
       "  'MSE': 0.01031138002872467,\n",
       "  'RMSE': 0.10154496878385544,\n",
       "  'MAE': 0.06399503350257874},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 96,\n",
       "  'MSE': 0.01997840777039528,\n",
       "  'RMSE': 0.14134499430656433,\n",
       "  'MAE': 0.09172166138887405},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 168,\n",
       "  'MSE': 0.022127792239189148,\n",
       "  'RMSE': 0.14875413477420807,\n",
       "  'MAE': 0.09595496952533722}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [{'Country': 'DE',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.022713396698236465,\n",
    "  'RMSE': 0.15070964395999908,\n",
    "  'MAE': 0.09314965456724167},\n",
    " {'Country': 'DE',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.03904155269265175,\n",
    "  'RMSE': 0.19758935272693634,\n",
    "  'MAE': 0.1312127262353897},\n",
    " {'Country': 'DE',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.04313361272215843,\n",
    "  'RMSE': 0.20768633484840393,\n",
    "  'MAE': 0.13920451700687408},\n",
    " {'Country': 'GB',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.025825485587120056,\n",
    "  'RMSE': 0.16070309281349182,\n",
    "  'MAE': 0.1029878556728363},\n",
    "  {'Country': 'GB',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.04658650979399681,\n",
    "  'RMSE': 0.21583908796310425,\n",
    "  'MAE': 0.14624564349651337},\n",
    " {'Country': 'GB',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.04751771315932274,\n",
    "  'RMSE': 0.2179855853319168,\n",
    "  'MAE': 0.1499413400888443},\n",
    "{'Country': 'ES',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.01031138002872467,\n",
    "  'RMSE': 0.10154496878385544,\n",
    "  'MAE': 0.06399503350257874},\n",
    " {'Country': 'ES',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.01997840777039528,\n",
    "  'RMSE': 0.14134499430656433,\n",
    "  'MAE': 0.09172166138887405},\n",
    " {'Country': 'ES',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.022127792239189148,\n",
    "  'RMSE': 0.14875413477420807,\n",
    "  'MAE': 0.09595496952533722},\n",
    "  {'Country': 'FR',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.010154812596738338,\n",
    "  'RMSE': 0.10077109187841415,\n",
    "  'MAE': 0.05653735250234604},\n",
    " {'Country': 'FR',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.019628532230854034,\n",
    "  'RMSE': 0.1401018649339676,\n",
    "  'MAE': 0.08128844946622849},\n",
    " {'Country': 'FR',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.02272237464785576,\n",
    "  'RMSE': 0.15073943138122559,\n",
    "  'MAE': 0.08884815871715546},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 24,\n",
    "  'MSE': 0.010610697790980339,\n",
    "  'RMSE': 0.10300824046134949,\n",
    "  'MAE': 0.05985838919878006},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 96,\n",
    "  'MSE': 0.01913185976445675,\n",
    "  'RMSE': 0.13831797242164612,\n",
    "  'MAE': 0.08287986367940903},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 168,\n",
    "  'MSE': 0.020030096173286438,\n",
    "  'RMSE': 0.14152772724628448,\n",
    "  'MAE': 0.08731971681118011}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM/168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.0873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM/168                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0227  0.1507  0.0931\n",
       "        96            0.0390  0.1976  0.1312\n",
       "        168           0.0431  0.2077  0.1392\n",
       "GB      24            0.0258  0.1607  0.1030\n",
       "        96            0.0466  0.2158  0.1462\n",
       "        168           0.0475  0.2180  0.1499\n",
       "ES      24            0.0103  0.1015  0.0640\n",
       "        96            0.0200  0.1413  0.0917\n",
       "        168           0.0221  0.1488  0.0960\n",
       "FR      24            0.0102  0.1008  0.0565\n",
       "        96            0.0196  0.1401  0.0813\n",
       "        168           0.0227  0.1507  0.0888\n",
       "IT      24            0.0106  0.1030  0.0599\n",
       "        96            0.0191  0.1383  0.0829\n",
       "        168           0.0200  0.1415  0.0873"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(r, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/168'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_168.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TimeLLM 336\n",
    "\n",
    "Sequence length 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "model = \"TimeLLM\"\n",
    "seq_len = 96\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_96.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 00:58:33,801] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 00:58:34,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 00:58:34,957] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 00:58:34,959] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 00:58:35,302] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.98 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,463] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.95 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,464] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 00:58:35,595] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.89 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4f91ff2f50>\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1823448\n",
      "\tspeed: 0.1567s/iter; left time: 14192.7792s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593933\n",
      "\tspeed: 0.1131s/iter; left time: 10230.2692s\n",
      "\titers: 300, epoch: 1 | loss: 0.1570632\n",
      "\tspeed: 0.1123s/iter; left time: 10143.7090s\n",
      "\titers: 400, epoch: 1 | loss: 0.1664988\n",
      "\tspeed: 0.1087s/iter; left time: 9810.8326s\n",
      "\titers: 500, epoch: 1 | loss: 0.1712038\n",
      "\tspeed: 0.1117s/iter; left time: 10073.0936s\n",
      "\titers: 600, epoch: 1 | loss: 0.1680950\n",
      "\tspeed: 0.1105s/iter; left time: 9953.8048s\n",
      "\titers: 700, epoch: 1 | loss: 0.1328567\n",
      "\tspeed: 0.1077s/iter; left time: 9689.5208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485084\n",
      "\tspeed: 0.1072s/iter; left time: 9629.3103s\n",
      "\titers: 900, epoch: 1 | loss: 0.1505876\n",
      "\tspeed: 0.1104s/iter; left time: 9911.4520s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1391718\n",
      "\tspeed: 0.1091s/iter; left time: 9781.6024s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1510044\n",
      "\tspeed: 0.1108s/iter; left time: 9927.7978s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1176484\n",
      "\tspeed: 0.1098s/iter; left time: 9823.3877s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1278661\n",
      "\tspeed: 0.1088s/iter; left time: 9724.8452s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1284621\n",
      "\tspeed: 0.1094s/iter; left time: 9765.7738s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0933571\n",
      "\tspeed: 0.1088s/iter; left time: 9698.9234s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1202643\n",
      "\tspeed: 0.1071s/iter; left time: 9540.1155s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1062317\n",
      "\tspeed: 0.1088s/iter; left time: 9675.7239s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0913426\n",
      "\tspeed: 0.1079s/iter; left time: 9585.7625s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0931644\n",
      "\tspeed: 0.1107s/iter; left time: 9829.9579s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0901813\n",
      "\tspeed: 0.1073s/iter; left time: 9512.1458s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0864648\n",
      "\tspeed: 0.1096s/iter; left time: 9701.9117s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0947707\n",
      "\tspeed: 0.1096s/iter; left time: 9691.2401s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1199264\n",
      "\tspeed: 0.1075s/iter; left time: 9494.6664s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1026568\n",
      "\tspeed: 0.1078s/iter; left time: 9513.9813s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1165116\n",
      "\tspeed: 0.1107s/iter; left time: 9763.0537s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1033131\n",
      "\tspeed: 0.1088s/iter; left time: 9581.6819s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0916886\n",
      "\tspeed: 0.1100s/iter; left time: 9677.2541s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0883022\n",
      "\tspeed: 0.1102s/iter; left time: 9683.9716s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1323129\n",
      "\tspeed: 0.1111s/iter; left time: 9754.3916s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1020587\n",
      "\tspeed: 0.1093s/iter; left time: 9583.4643s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0923530\n",
      "\tspeed: 0.1135s/iter; left time: 9937.2899s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0844439\n",
      "\tspeed: 0.1075s/iter; left time: 9399.6741s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1020005\n",
      "\tspeed: 0.1104s/iter; left time: 9643.9181s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1202909\n",
      "\tspeed: 0.1069s/iter; left time: 9329.4238s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0919176\n",
      "\tspeed: 0.1082s/iter; left time: 9429.4043s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1073375\n",
      "\tspeed: 0.1110s/iter; left time: 9664.3999s\n",
      "\titers: 3700, epoch: 1 | loss: 0.1052466\n",
      "\tspeed: 0.1101s/iter; left time: 9572.9709s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0875165\n",
      "\tspeed: 0.1063s/iter; left time: 9235.6391s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0930548\n",
      "\tspeed: 0.1081s/iter; left time: 9381.0162s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1260701\n",
      "\tspeed: 0.1123s/iter; left time: 9732.7146s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0895162\n",
      "\tspeed: 0.1114s/iter; left time: 9639.0711s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1139867\n",
      "\tspeed: 0.1107s/iter; left time: 9573.0378s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1168468\n",
      "\tspeed: 0.1118s/iter; left time: 9658.4796s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0850648\n",
      "\tspeed: 0.1137s/iter; left time: 9805.3898s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0921275\n",
      "\tspeed: 0.1121s/iter; left time: 9662.0191s\n",
      "Epoch: 1 cost time: 00h:08m:20.08s\n",
      "Epoch: 1 | Train Loss: 0.1182731 Vali Loss: 0.1048069 Test Loss: 0.1061743\n",
      "Validation loss decreased (inf --> 0.104807).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0926168\n",
      "\tspeed: 1.6075s/iter; left time: 138286.9299s\n",
      "\titers: 200, epoch: 2 | loss: 0.1175821\n",
      "\tspeed: 0.1018s/iter; left time: 8748.6040s\n",
      "\titers: 300, epoch: 2 | loss: 0.0875412\n",
      "\tspeed: 0.1005s/iter; left time: 8629.0758s\n",
      "\titers: 400, epoch: 2 | loss: 0.1002984\n",
      "\tspeed: 0.1016s/iter; left time: 8710.4225s\n",
      "\titers: 500, epoch: 2 | loss: 0.0936466\n",
      "\tspeed: 0.1012s/iter; left time: 8669.1776s\n",
      "\titers: 600, epoch: 2 | loss: 0.0745555\n",
      "\tspeed: 0.0958s/iter; left time: 8195.4123s\n",
      "\titers: 700, epoch: 2 | loss: 0.0955112\n",
      "\tspeed: 0.0995s/iter; left time: 8501.9022s\n",
      "\titers: 800, epoch: 2 | loss: 0.1059108\n",
      "\tspeed: 0.0966s/iter; left time: 8244.1258s\n",
      "\titers: 900, epoch: 2 | loss: 0.0846592\n",
      "\tspeed: 0.1003s/iter; left time: 8547.7261s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0743872\n",
      "\tspeed: 0.0997s/iter; left time: 8488.8023s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0877253\n",
      "\tspeed: 0.0973s/iter; left time: 8271.2659s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0847517\n",
      "\tspeed: 0.0982s/iter; left time: 8340.2651s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1021993\n",
      "\tspeed: 0.1003s/iter; left time: 8505.3193s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0897969\n",
      "\tspeed: 0.0983s/iter; left time: 8325.4910s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0716018\n",
      "\tspeed: 0.0987s/iter; left time: 8354.8012s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0807362\n",
      "\tspeed: 0.0984s/iter; left time: 8316.4733s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0934259\n",
      "\tspeed: 0.0973s/iter; left time: 8218.7837s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1289299\n",
      "\tspeed: 0.0973s/iter; left time: 8203.3695s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0885335\n",
      "\tspeed: 0.1022s/iter; left time: 8611.4285s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0812071\n",
      "\tspeed: 0.0986s/iter; left time: 8295.3380s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1080786\n",
      "\tspeed: 0.0976s/iter; left time: 8203.2712s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0983471\n",
      "\tspeed: 0.0973s/iter; left time: 8164.1360s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1013250\n",
      "\tspeed: 0.0968s/iter; left time: 8113.0099s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0806270\n",
      "\tspeed: 0.0995s/iter; left time: 8332.9754s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0910785\n",
      "\tspeed: 0.0975s/iter; left time: 8151.0682s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0853698\n",
      "\tspeed: 0.0976s/iter; left time: 8155.8282s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1056066\n",
      "\tspeed: 0.0991s/iter; left time: 8266.5479s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0951345\n",
      "\tspeed: 0.0963s/iter; left time: 8023.7844s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0933933\n",
      "\tspeed: 0.0973s/iter; left time: 8098.5418s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0762453\n",
      "\tspeed: 0.1005s/iter; left time: 8355.5888s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0909215\n",
      "\tspeed: 0.0980s/iter; left time: 8139.8000s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0976593\n",
      "\tspeed: 0.0974s/iter; left time: 8073.2693s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0855530\n",
      "\tspeed: 0.1000s/iter; left time: 8280.0740s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0961046\n",
      "\tspeed: 0.0976s/iter; left time: 8076.5088s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0753835\n",
      "\tspeed: 0.0985s/iter; left time: 8134.7859s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0882990\n",
      "\tspeed: 0.1015s/iter; left time: 8377.4895s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1059739\n",
      "\tspeed: 0.0999s/iter; left time: 8234.1388s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0958683\n",
      "\tspeed: 0.1041s/iter; left time: 8569.3236s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1044519\n",
      "\tspeed: 0.0973s/iter; left time: 8001.3171s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0814047\n",
      "\tspeed: 0.0980s/iter; left time: 8044.6382s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0822755\n",
      "\tspeed: 0.0988s/iter; left time: 8107.3554s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0739301\n",
      "\tspeed: 0.1024s/iter; left time: 8386.1515s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0980485\n",
      "\tspeed: 0.0992s/iter; left time: 8113.6176s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0897213\n",
      "\tspeed: 0.0942s/iter; left time: 7698.5429s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0883879\n",
      "\tspeed: 0.0945s/iter; left time: 7714.3174s\n",
      "Epoch: 2 cost time: 00h:07m:28.46s\n",
      "Epoch: 2 | Train Loss: 0.0958203 Vali Loss: 0.1006848 Test Loss: 0.1015933\n",
      "Validation loss decreased (0.104807 --> 0.100685).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0841110\n",
      "\tspeed: 1.3316s/iter; left time: 108517.9794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0894022\n",
      "\tspeed: 0.0979s/iter; left time: 7966.0863s\n",
      "\titers: 300, epoch: 3 | loss: 0.0833011\n",
      "\tspeed: 0.0978s/iter; left time: 7952.1508s\n",
      "\titers: 400, epoch: 3 | loss: 0.0866618\n",
      "\tspeed: 0.1017s/iter; left time: 8256.6719s\n",
      "\titers: 500, epoch: 3 | loss: 0.0953845\n",
      "\tspeed: 0.0981s/iter; left time: 7958.0230s\n",
      "\titers: 600, epoch: 3 | loss: 0.0896195\n",
      "\tspeed: 0.0974s/iter; left time: 7890.0073s\n",
      "\titers: 700, epoch: 3 | loss: 0.0734763\n",
      "\tspeed: 0.0993s/iter; left time: 8030.9663s\n",
      "\titers: 800, epoch: 3 | loss: 0.0991940\n",
      "\tspeed: 0.0988s/iter; left time: 7981.8519s\n",
      "\titers: 900, epoch: 3 | loss: 0.0878340\n",
      "\tspeed: 0.0974s/iter; left time: 7860.7648s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0929727\n",
      "\tspeed: 0.0971s/iter; left time: 7827.2904s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0975781\n",
      "\tspeed: 0.1043s/iter; left time: 8397.7573s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0862777\n",
      "\tspeed: 0.0984s/iter; left time: 7912.0126s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0819142\n",
      "\tspeed: 0.0976s/iter; left time: 7832.9259s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1080137\n",
      "\tspeed: 0.0992s/iter; left time: 7952.3061s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0914959\n",
      "\tspeed: 0.1000s/iter; left time: 8009.8340s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0939515\n",
      "\tspeed: 0.1009s/iter; left time: 8070.1451s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0999542\n",
      "\tspeed: 0.1011s/iter; left time: 8080.9149s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0778705\n",
      "\tspeed: 0.0950s/iter; left time: 7580.1028s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0989400\n",
      "\tspeed: 0.1046s/iter; left time: 8337.3815s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1245918\n",
      "\tspeed: 0.0985s/iter; left time: 7841.9201s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0766051\n",
      "\tspeed: 0.1012s/iter; left time: 8047.8288s\n",
      "\titers: 2200, epoch: 3 | loss: 0.1048279\n",
      "\tspeed: 0.0952s/iter; left time: 7560.7894s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1057464\n",
      "\tspeed: 0.0947s/iter; left time: 7509.9755s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0974280\n",
      "\tspeed: 0.0962s/iter; left time: 7619.2757s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0859704\n",
      "\tspeed: 0.0997s/iter; left time: 7883.8792s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0879753\n",
      "\tspeed: 0.0986s/iter; left time: 7790.8897s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0848551\n",
      "\tspeed: 0.0989s/iter; left time: 7802.5963s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0755866\n",
      "\tspeed: 0.1001s/iter; left time: 7888.9594s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1117945\n",
      "\tspeed: 0.0990s/iter; left time: 7789.9277s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0859069\n",
      "\tspeed: 0.1032s/iter; left time: 8111.8854s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0947104\n",
      "\tspeed: 0.1001s/iter; left time: 7861.1467s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0981154\n",
      "\tspeed: 0.1015s/iter; left time: 7956.8118s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0940440\n",
      "\tspeed: 0.0947s/iter; left time: 7412.2293s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0983612\n",
      "\tspeed: 0.1000s/iter; left time: 7823.2266s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0836072\n",
      "\tspeed: 0.1002s/iter; left time: 7824.1603s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0788918\n",
      "\tspeed: 0.0999s/iter; left time: 7792.9068s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0732648\n",
      "\tspeed: 0.0988s/iter; left time: 7698.6423s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0901658\n",
      "\tspeed: 0.0977s/iter; left time: 7598.8195s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0971151\n",
      "\tspeed: 0.0978s/iter; left time: 7601.7202s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0896691\n",
      "\tspeed: 0.0979s/iter; left time: 7593.3154s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0813452\n",
      "\tspeed: 0.0988s/iter; left time: 7658.9424s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0852726\n",
      "\tspeed: 0.0993s/iter; left time: 7685.7856s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0909429\n",
      "\tspeed: 0.1024s/iter; left time: 7916.7954s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956288\n",
      "\tspeed: 0.0995s/iter; left time: 7677.8155s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0904642\n",
      "\tspeed: 0.0974s/iter; left time: 7511.6010s\n",
      "Epoch: 3 cost time: 00h:07m:29.53s\n",
      "Epoch: 3 | Train Loss: 0.0920011 Vali Loss: 0.0961987 Test Loss: 0.0974472\n",
      "Validation loss decreased (0.100685 --> 0.096199).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0854296\n",
      "\tspeed: 1.3142s/iter; left time: 101141.8138s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780370\n",
      "\tspeed: 0.0996s/iter; left time: 7658.6109s\n",
      "\titers: 300, epoch: 4 | loss: 0.0826013\n",
      "\tspeed: 0.1029s/iter; left time: 7902.0616s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769120\n",
      "\tspeed: 0.1018s/iter; left time: 7801.0230s\n",
      "\titers: 500, epoch: 4 | loss: 0.0974223\n",
      "\tspeed: 0.0986s/iter; left time: 7548.5106s\n",
      "\titers: 600, epoch: 4 | loss: 0.0936587\n",
      "\tspeed: 0.0965s/iter; left time: 7381.9201s\n",
      "\titers: 700, epoch: 4 | loss: 0.0737562\n",
      "\tspeed: 0.0985s/iter; left time: 7525.3560s\n",
      "\titers: 800, epoch: 4 | loss: 0.1083352\n",
      "\tspeed: 0.0983s/iter; left time: 7496.0994s\n",
      "\titers: 900, epoch: 4 | loss: 0.0773530\n",
      "\tspeed: 0.0981s/iter; left time: 7472.3147s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0801422\n",
      "\tspeed: 0.0965s/iter; left time: 7342.2084s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0897846\n",
      "\tspeed: 0.0967s/iter; left time: 7341.8274s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1164535\n",
      "\tspeed: 0.0993s/iter; left time: 7533.1355s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0910549\n",
      "\tspeed: 0.0972s/iter; left time: 7361.4885s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0885448\n",
      "\tspeed: 0.0961s/iter; left time: 7272.9170s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1008844\n",
      "\tspeed: 0.0993s/iter; left time: 7500.6766s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0783211\n",
      "\tspeed: 0.0988s/iter; left time: 7457.4286s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0906300\n",
      "\tspeed: 0.0994s/iter; left time: 7491.3826s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0950228\n",
      "\tspeed: 0.0988s/iter; left time: 7434.0902s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0826172\n",
      "\tspeed: 0.0987s/iter; left time: 7420.0613s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0946391\n",
      "\tspeed: 0.1013s/iter; left time: 7603.5128s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0991539\n",
      "\tspeed: 0.0979s/iter; left time: 7335.9758s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0967136\n",
      "\tspeed: 0.0959s/iter; left time: 7180.0891s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0812481\n",
      "\tspeed: 0.0990s/iter; left time: 7398.1803s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0714268\n",
      "\tspeed: 0.0989s/iter; left time: 7387.6641s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0870069\n",
      "\tspeed: 0.0968s/iter; left time: 7213.9709s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1008413\n",
      "\tspeed: 0.0959s/iter; left time: 7144.2811s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0958331\n",
      "\tspeed: 0.0998s/iter; left time: 7422.6353s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0862275\n",
      "\tspeed: 0.1001s/iter; left time: 7436.5217s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0995362\n",
      "\tspeed: 0.0987s/iter; left time: 7317.1975s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0776753\n",
      "\tspeed: 0.0969s/iter; left time: 7177.2502s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0969164\n",
      "\tspeed: 0.0976s/iter; left time: 7216.0729s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0818957\n",
      "\tspeed: 0.1013s/iter; left time: 7480.6053s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1021598\n",
      "\tspeed: 0.1045s/iter; left time: 7708.6485s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0792934\n",
      "\tspeed: 0.1025s/iter; left time: 7550.8808s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0889132\n",
      "\tspeed: 0.0966s/iter; left time: 7105.1246s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0714224\n",
      "\tspeed: 0.1058s/iter; left time: 7770.6666s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1041591\n",
      "\tspeed: 0.1056s/iter; left time: 7746.5082s\n",
      "\titers: 3800, epoch: 4 | loss: 0.1012451\n",
      "\tspeed: 0.0995s/iter; left time: 7289.8450s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0812839\n",
      "\tspeed: 0.0965s/iter; left time: 7060.3051s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0673504\n",
      "\tspeed: 0.0994s/iter; left time: 7265.6753s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0983212\n",
      "\tspeed: 0.0998s/iter; left time: 7284.9942s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0892445\n",
      "\tspeed: 0.1024s/iter; left time: 7457.9601s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0736814\n",
      "\tspeed: 0.0982s/iter; left time: 7142.0700s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1024650\n",
      "\tspeed: 0.1000s/iter; left time: 7262.9893s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0878941\n",
      "\tspeed: 0.1002s/iter; left time: 7269.0189s\n",
      "Epoch: 4 cost time: 00h:07m:30.25s\n",
      "Epoch: 4 | Train Loss: 0.0894738 Vali Loss: 0.0959204 Test Loss: 0.0978855\n",
      "Validation loss decreased (0.096199 --> 0.095920).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0796165\n",
      "\tspeed: 1.3415s/iter; left time: 97165.2517s\n",
      "\titers: 200, epoch: 5 | loss: 0.0959185\n",
      "\tspeed: 0.1042s/iter; left time: 7536.7067s\n",
      "\titers: 300, epoch: 5 | loss: 0.0750006\n",
      "\tspeed: 0.1038s/iter; left time: 7498.0770s\n",
      "\titers: 400, epoch: 5 | loss: 0.0928235\n",
      "\tspeed: 0.1059s/iter; left time: 7635.1819s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928443\n",
      "\tspeed: 0.1006s/iter; left time: 7249.6675s\n",
      "\titers: 600, epoch: 5 | loss: 0.0831500\n",
      "\tspeed: 0.1000s/iter; left time: 7195.5720s\n",
      "\titers: 700, epoch: 5 | loss: 0.0872387\n",
      "\tspeed: 0.1034s/iter; left time: 7426.1119s\n",
      "\titers: 800, epoch: 5 | loss: 0.0713760\n",
      "\tspeed: 0.1018s/iter; left time: 7302.8275s\n",
      "\titers: 900, epoch: 5 | loss: 0.0977144\n",
      "\tspeed: 0.1022s/iter; left time: 7321.8485s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0899376\n",
      "\tspeed: 0.1063s/iter; left time: 7603.0771s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0909452\n",
      "\tspeed: 0.1073s/iter; left time: 7663.6423s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0850678\n",
      "\tspeed: 0.1005s/iter; left time: 7171.5266s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0866611\n",
      "\tspeed: 0.1041s/iter; left time: 7412.7031s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0814596\n",
      "\tspeed: 0.1056s/iter; left time: 7512.2304s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1011155\n",
      "\tspeed: 0.1026s/iter; left time: 7284.9512s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0806876\n",
      "\tspeed: 0.0930s/iter; left time: 6597.8508s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0924520\n",
      "\tspeed: 0.1020s/iter; left time: 7226.4722s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0869739\n",
      "\tspeed: 0.1018s/iter; left time: 7198.5440s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0844609\n",
      "\tspeed: 0.1005s/iter; left time: 7095.0675s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0788910\n",
      "\tspeed: 0.0977s/iter; left time: 6892.0472s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0919405\n",
      "\tspeed: 0.1064s/iter; left time: 7495.0567s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0726033\n",
      "\tspeed: 0.1026s/iter; left time: 7214.0181s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0916889\n",
      "\tspeed: 0.0995s/iter; left time: 6985.1730s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0683158\n",
      "\tspeed: 0.1053s/iter; left time: 7385.7452s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0925977\n",
      "\tspeed: 0.0931s/iter; left time: 6519.8642s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0985155\n",
      "\tspeed: 0.0997s/iter; left time: 6972.4979s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1006452\n",
      "\tspeed: 0.0997s/iter; left time: 6963.8701s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0845333\n",
      "\tspeed: 0.1049s/iter; left time: 7313.5824s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0966101\n",
      "\tspeed: 0.1014s/iter; left time: 7060.6279s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0780502\n",
      "\tspeed: 0.0953s/iter; left time: 6623.1762s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0809835\n",
      "\tspeed: 0.1046s/iter; left time: 7263.6035s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0696071\n",
      "\tspeed: 0.0979s/iter; left time: 6785.3214s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0723333\n",
      "\tspeed: 0.1023s/iter; left time: 7078.8098s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0702593\n",
      "\tspeed: 0.1029s/iter; left time: 7112.6566s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0938417\n",
      "\tspeed: 0.1010s/iter; left time: 6970.7326s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0951235\n",
      "\tspeed: 0.1047s/iter; left time: 7217.6933s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0845446\n",
      "\tspeed: 0.1052s/iter; left time: 7238.1443s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0840251\n",
      "\tspeed: 0.1046s/iter; left time: 7189.5553s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0870530\n",
      "\tspeed: 0.1008s/iter; left time: 6919.6613s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0931989\n",
      "\tspeed: 0.1001s/iter; left time: 6862.8567s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0680944\n",
      "\tspeed: 0.1060s/iter; left time: 7254.4370s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0768961\n",
      "\tspeed: 0.1004s/iter; left time: 6858.2873s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0758227\n",
      "\tspeed: 0.1064s/iter; left time: 7256.3985s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1047759\n",
      "\tspeed: 0.1054s/iter; left time: 7180.0354s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0782504\n",
      "\tspeed: 0.1003s/iter; left time: 6820.2225s\n",
      "Epoch: 5 cost time: 00h:07m:43.98s\n",
      "Epoch: 5 | Train Loss: 0.0879004 Vali Loss: 0.0939386 Test Loss: 0.0954783\n",
      "Validation loss decreased (0.095920 --> 0.093939).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0823750\n",
      "\tspeed: 1.3467s/iter; left time: 91432.2667s\n",
      "\titers: 200, epoch: 6 | loss: 0.1063394\n",
      "\tspeed: 0.1011s/iter; left time: 6852.1673s\n",
      "\titers: 300, epoch: 6 | loss: 0.0728738\n",
      "\tspeed: 0.1053s/iter; left time: 7128.8050s\n",
      "\titers: 400, epoch: 6 | loss: 0.0747061\n",
      "\tspeed: 0.1033s/iter; left time: 6984.8315s\n",
      "\titers: 500, epoch: 6 | loss: 0.0784984\n",
      "\tspeed: 0.0981s/iter; left time: 6624.1158s\n",
      "\titers: 600, epoch: 6 | loss: 0.0822229\n",
      "\tspeed: 0.1049s/iter; left time: 7066.7080s\n",
      "\titers: 700, epoch: 6 | loss: 0.0869800\n",
      "\tspeed: 0.0996s/iter; left time: 6702.8915s\n",
      "\titers: 800, epoch: 6 | loss: 0.0766805\n",
      "\tspeed: 0.0974s/iter; left time: 6544.9165s\n",
      "\titers: 900, epoch: 6 | loss: 0.0896778\n",
      "\tspeed: 0.1038s/iter; left time: 6962.6192s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0828632\n",
      "\tspeed: 0.1026s/iter; left time: 6874.3296s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0825213\n",
      "\tspeed: 0.0975s/iter; left time: 6520.8000s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0879269\n",
      "\tspeed: 0.0937s/iter; left time: 6258.6510s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0936004\n",
      "\tspeed: 0.1004s/iter; left time: 6698.7948s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0839023\n",
      "\tspeed: 0.1057s/iter; left time: 7042.4448s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0895705\n",
      "\tspeed: 0.1039s/iter; left time: 6907.9788s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0983923\n",
      "\tspeed: 0.1008s/iter; left time: 6692.5768s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1097069\n",
      "\tspeed: 0.1004s/iter; left time: 6655.7966s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0855282\n",
      "\tspeed: 0.1078s/iter; left time: 7135.9823s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0760626\n",
      "\tspeed: 0.1063s/iter; left time: 7028.1996s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1028426\n",
      "\tspeed: 0.1004s/iter; left time: 6629.2103s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0760202\n",
      "\tspeed: 0.1032s/iter; left time: 6802.0068s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1046149\n",
      "\tspeed: 0.1025s/iter; left time: 6745.4336s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0722455\n",
      "\tspeed: 0.1020s/iter; left time: 6699.4281s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1001926\n",
      "\tspeed: 0.1030s/iter; left time: 6757.3764s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0948031\n",
      "\tspeed: 0.1050s/iter; left time: 6879.1840s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0821364\n",
      "\tspeed: 0.1016s/iter; left time: 6646.8049s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1087020\n",
      "\tspeed: 0.1021s/iter; left time: 6663.7645s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0879368\n",
      "\tspeed: 0.1057s/iter; left time: 6889.1856s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0837349\n",
      "\tspeed: 0.1006s/iter; left time: 6549.8715s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0855312\n",
      "\tspeed: 0.1009s/iter; left time: 6556.2153s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0753525\n",
      "\tspeed: 0.0976s/iter; left time: 6330.6146s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0820278\n",
      "\tspeed: 0.1049s/iter; left time: 6797.0102s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0888730\n",
      "\tspeed: 0.0964s/iter; left time: 6237.5931s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0932008\n",
      "\tspeed: 0.1036s/iter; left time: 6691.5403s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0900321\n",
      "\tspeed: 0.1000s/iter; left time: 6446.3871s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0867740\n",
      "\tspeed: 0.1013s/iter; left time: 6525.5733s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1079047\n",
      "\tspeed: 0.1025s/iter; left time: 6593.2241s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0729139\n",
      "\tspeed: 0.0991s/iter; left time: 6359.5930s\n",
      "\titers: 3900, epoch: 6 | loss: 0.1025409\n",
      "\tspeed: 0.1046s/iter; left time: 6705.2597s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0916645\n",
      "\tspeed: 0.1020s/iter; left time: 6525.8738s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0854311\n",
      "\tspeed: 0.1047s/iter; left time: 6690.2627s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0886655\n",
      "\tspeed: 0.1016s/iter; left time: 6480.8821s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0818150\n",
      "\tspeed: 0.1003s/iter; left time: 6389.3058s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0888074\n",
      "\tspeed: 0.1036s/iter; left time: 6587.3938s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0821429\n",
      "\tspeed: 0.0965s/iter; left time: 6127.9679s\n",
      "Epoch: 6 cost time: 00h:07m:42.51s\n",
      "Epoch: 6 | Train Loss: 0.0867662 Vali Loss: 0.0923030 Test Loss: 0.0944841\n",
      "Validation loss decreased (0.093939 --> 0.092303).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0740339\n",
      "\tspeed: 1.3279s/iter; left time: 84142.3451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806055\n",
      "\tspeed: 0.1011s/iter; left time: 6397.4817s\n",
      "\titers: 300, epoch: 7 | loss: 0.0792400\n",
      "\tspeed: 0.1023s/iter; left time: 6459.3339s\n",
      "\titers: 400, epoch: 7 | loss: 0.0885487\n",
      "\tspeed: 0.1026s/iter; left time: 6470.6621s\n",
      "\titers: 500, epoch: 7 | loss: 0.0872176\n",
      "\tspeed: 0.1014s/iter; left time: 6385.0139s\n",
      "\titers: 600, epoch: 7 | loss: 0.0869710\n",
      "\tspeed: 0.1041s/iter; left time: 6542.1420s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786874\n",
      "\tspeed: 0.1020s/iter; left time: 6399.5723s\n",
      "\titers: 800, epoch: 7 | loss: 0.0897944\n",
      "\tspeed: 0.1053s/iter; left time: 6599.0058s\n",
      "\titers: 900, epoch: 7 | loss: 0.0814298\n",
      "\tspeed: 0.0958s/iter; left time: 5994.0173s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0705729\n",
      "\tspeed: 0.1023s/iter; left time: 6389.5788s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0569545\n",
      "\tspeed: 0.0955s/iter; left time: 5958.6051s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0850203\n",
      "\tspeed: 0.0976s/iter; left time: 6074.2025s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0733617\n",
      "\tspeed: 0.0945s/iter; left time: 5874.5316s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1048769\n",
      "\tspeed: 0.1002s/iter; left time: 6218.0586s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0904823\n",
      "\tspeed: 0.1018s/iter; left time: 6310.8287s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0865115\n",
      "\tspeed: 0.1024s/iter; left time: 6337.0242s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0868625\n",
      "\tspeed: 0.1012s/iter; left time: 6250.8231s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0834711\n",
      "\tspeed: 0.1003s/iter; left time: 6186.8268s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0972821\n",
      "\tspeed: 0.0981s/iter; left time: 6040.5447s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0822335\n",
      "\tspeed: 0.1007s/iter; left time: 6186.3172s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0901200\n",
      "\tspeed: 0.0978s/iter; left time: 6000.9481s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0892411\n",
      "\tspeed: 0.1023s/iter; left time: 6267.9073s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0871298\n",
      "\tspeed: 0.1040s/iter; left time: 6359.9234s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0816868\n",
      "\tspeed: 0.0998s/iter; left time: 6092.9299s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1097169\n",
      "\tspeed: 0.1034s/iter; left time: 6302.4151s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0667246\n",
      "\tspeed: 0.1003s/iter; left time: 6101.9371s\n",
      "\titers: 2700, epoch: 7 | loss: 0.1001452\n",
      "\tspeed: 0.1028s/iter; left time: 6246.1959s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0926842\n",
      "\tspeed: 0.0986s/iter; left time: 5978.4639s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0792861\n",
      "\tspeed: 0.0990s/iter; left time: 5998.3412s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0924478\n",
      "\tspeed: 0.0994s/iter; left time: 6008.8689s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061495\n",
      "\tspeed: 0.1059s/iter; left time: 6393.1014s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0846756\n",
      "\tspeed: 0.1005s/iter; left time: 6053.9868s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0878668\n",
      "\tspeed: 0.0962s/iter; left time: 5787.7234s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0904202\n",
      "\tspeed: 0.1011s/iter; left time: 6073.0991s\n",
      "\titers: 3500, epoch: 7 | loss: 0.1028529\n",
      "\tspeed: 0.1002s/iter; left time: 6009.5951s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0663122\n",
      "\tspeed: 0.0990s/iter; left time: 5924.3264s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0938098\n",
      "\tspeed: 0.1023s/iter; left time: 6114.2053s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0904512\n",
      "\tspeed: 0.0972s/iter; left time: 5801.5553s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0924167\n",
      "\tspeed: 0.1027s/iter; left time: 6118.6491s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0838463\n",
      "\tspeed: 0.0957s/iter; left time: 5689.0299s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0746771\n",
      "\tspeed: 0.0985s/iter; left time: 5844.6515s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0833501\n",
      "\tspeed: 0.0981s/iter; left time: 5815.3194s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0937628\n",
      "\tspeed: 0.1039s/iter; left time: 6149.5759s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0842075\n",
      "\tspeed: 0.1015s/iter; left time: 5993.1336s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1038213\n",
      "\tspeed: 0.1019s/iter; left time: 6005.7299s\n",
      "Epoch: 7 cost time: 00h:07m:36.00s\n",
      "Epoch: 7 | Train Loss: 0.0858412 Vali Loss: 0.0921237 Test Loss: 0.0943098\n",
      "Validation loss decreased (0.092303 --> 0.092124).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0808295\n",
      "\tspeed: 1.3484s/iter; left time: 79324.9407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0785601\n",
      "\tspeed: 0.1013s/iter; left time: 5948.3385s\n",
      "\titers: 300, epoch: 8 | loss: 0.0913709\n",
      "\tspeed: 0.1049s/iter; left time: 6150.9803s\n",
      "\titers: 400, epoch: 8 | loss: 0.0863424\n",
      "\tspeed: 0.1015s/iter; left time: 5943.1978s\n",
      "\titers: 500, epoch: 8 | loss: 0.0919085\n",
      "\tspeed: 0.1026s/iter; left time: 5995.7721s\n",
      "\titers: 600, epoch: 8 | loss: 0.0952189\n",
      "\tspeed: 0.1094s/iter; left time: 6384.0770s\n",
      "\titers: 700, epoch: 8 | loss: 0.0938345\n",
      "\tspeed: 0.1051s/iter; left time: 6118.7782s\n",
      "\titers: 800, epoch: 8 | loss: 0.0633808\n",
      "\tspeed: 0.1066s/iter; left time: 6195.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0932870\n",
      "\tspeed: 0.1001s/iter; left time: 5805.9081s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0710422\n",
      "\tspeed: 0.1059s/iter; left time: 6136.8467s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0793336\n",
      "\tspeed: 0.1107s/iter; left time: 6403.0260s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0701465\n",
      "\tspeed: 0.1109s/iter; left time: 6400.0567s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0760521\n",
      "\tspeed: 0.1001s/iter; left time: 5769.7115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0881910\n",
      "\tspeed: 0.1119s/iter; left time: 6437.5889s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0892492\n",
      "\tspeed: 0.1112s/iter; left time: 6386.6952s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0819665\n",
      "\tspeed: 0.1109s/iter; left time: 6358.0637s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0787609\n",
      "\tspeed: 0.0940s/iter; left time: 5381.0757s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0747100\n",
      "\tspeed: 0.0985s/iter; left time: 5624.7843s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1021912\n",
      "\tspeed: 0.1037s/iter; left time: 5911.1690s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0817584\n",
      "\tspeed: 0.0979s/iter; left time: 5570.9904s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0737849\n",
      "\tspeed: 0.1033s/iter; left time: 5870.7968s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0738396\n",
      "\tspeed: 0.1043s/iter; left time: 5916.2166s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0792134\n",
      "\tspeed: 0.1023s/iter; left time: 5793.2293s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0833495\n",
      "\tspeed: 0.0969s/iter; left time: 5475.1824s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0985885\n",
      "\tspeed: 0.0998s/iter; left time: 5632.6808s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0903379\n",
      "\tspeed: 0.1009s/iter; left time: 5681.0624s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0958151\n",
      "\tspeed: 0.0916s/iter; left time: 5149.8239s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0752126\n",
      "\tspeed: 0.0982s/iter; left time: 5513.6748s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0844900\n",
      "\tspeed: 0.1055s/iter; left time: 5911.9269s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0992072\n",
      "\tspeed: 0.1010s/iter; left time: 5648.5090s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0779921\n",
      "\tspeed: 0.0948s/iter; left time: 5293.3490s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0817788\n",
      "\tspeed: 0.1028s/iter; left time: 5729.8750s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0698256\n",
      "\tspeed: 0.1052s/iter; left time: 5851.0588s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1009030\n",
      "\tspeed: 0.1011s/iter; left time: 5613.4136s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0794296\n",
      "\tspeed: 0.1089s/iter; left time: 6036.6832s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0652106\n",
      "\tspeed: 0.1036s/iter; left time: 5733.3627s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0883530\n",
      "\tspeed: 0.0991s/iter; left time: 5471.9486s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0876575\n",
      "\tspeed: 0.0938s/iter; left time: 5169.8339s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0858913\n",
      "\tspeed: 0.1035s/iter; left time: 5693.3468s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0873493\n",
      "\tspeed: 0.0944s/iter; left time: 5187.3501s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0958864\n",
      "\tspeed: 0.0958s/iter; left time: 5251.1785s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0893509\n",
      "\tspeed: 0.1090s/iter; left time: 5966.4078s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0774665\n",
      "\tspeed: 0.0961s/iter; left time: 5250.4544s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0878850\n",
      "\tspeed: 0.1060s/iter; left time: 5780.8161s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0725639\n",
      "\tspeed: 0.1012s/iter; left time: 5508.9953s\n",
      "Epoch: 8 cost time: 00h:07m:45.04s\n",
      "Epoch: 8 | Train Loss: 0.0850912 Vali Loss: 0.0910974 Test Loss: 0.0931037\n",
      "Validation loss decreased (0.092124 --> 0.091097).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0839187\n",
      "\tspeed: 1.3393s/iter; left time: 72719.7064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809305\n",
      "\tspeed: 0.0985s/iter; left time: 5340.6867s\n",
      "\titers: 300, epoch: 9 | loss: 0.0818261\n",
      "\tspeed: 0.1001s/iter; left time: 5413.2822s\n",
      "\titers: 400, epoch: 9 | loss: 0.0826800\n",
      "\tspeed: 0.1054s/iter; left time: 5690.5036s\n",
      "\titers: 500, epoch: 9 | loss: 0.0678031\n",
      "\tspeed: 0.1062s/iter; left time: 5724.4040s\n",
      "\titers: 600, epoch: 9 | loss: 0.0687698\n",
      "\tspeed: 0.0947s/iter; left time: 5096.4144s\n",
      "\titers: 700, epoch: 9 | loss: 0.1053366\n",
      "\tspeed: 0.1048s/iter; left time: 5626.3520s\n",
      "\titers: 800, epoch: 9 | loss: 0.0873797\n",
      "\tspeed: 0.1019s/iter; left time: 5462.2545s\n",
      "\titers: 900, epoch: 9 | loss: 0.0993194\n",
      "\tspeed: 0.1073s/iter; left time: 5738.7548s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0958880\n",
      "\tspeed: 0.1031s/iter; left time: 5505.4965s\n",
      "\titers: 1100, epoch: 9 | loss: 0.1099369\n",
      "\tspeed: 0.1053s/iter; left time: 5609.8455s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0775966\n",
      "\tspeed: 0.1065s/iter; left time: 5664.7452s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0886414\n",
      "\tspeed: 0.1023s/iter; left time: 5429.9298s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0764013\n",
      "\tspeed: 0.0982s/iter; left time: 5203.6006s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0902908\n",
      "\tspeed: 0.1062s/iter; left time: 5620.2334s\n",
      "\titers: 1600, epoch: 9 | loss: 0.1045604\n",
      "\tspeed: 0.1032s/iter; left time: 5446.7768s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0727765\n",
      "\tspeed: 0.1031s/iter; left time: 5433.1033s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0630156\n",
      "\tspeed: 0.0991s/iter; left time: 5211.3352s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0870845\n",
      "\tspeed: 0.1059s/iter; left time: 5559.2011s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0690623\n",
      "\tspeed: 0.1020s/iter; left time: 5343.4981s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0762401\n",
      "\tspeed: 0.1029s/iter; left time: 5378.7984s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0842778\n",
      "\tspeed: 0.1055s/iter; left time: 5506.7273s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0593234\n",
      "\tspeed: 0.0989s/iter; left time: 5149.8009s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0558220\n",
      "\tspeed: 0.1029s/iter; left time: 5351.7705s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0766593\n",
      "\tspeed: 0.1043s/iter; left time: 5413.7909s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1005495\n",
      "\tspeed: 0.1078s/iter; left time: 5585.5454s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0827615\n",
      "\tspeed: 0.1037s/iter; left time: 5361.2156s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0824010\n",
      "\tspeed: 0.0998s/iter; left time: 5150.6259s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0834433\n",
      "\tspeed: 0.1104s/iter; left time: 5684.0355s\n",
      "\titers: 3000, epoch: 9 | loss: 0.1030053\n",
      "\tspeed: 0.1007s/iter; left time: 5175.0512s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0827309\n",
      "\tspeed: 0.0956s/iter; left time: 4905.6988s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0985053\n",
      "\tspeed: 0.1020s/iter; left time: 5222.4325s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0913691\n",
      "\tspeed: 0.1020s/iter; left time: 5209.3681s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0674509\n",
      "\tspeed: 0.1025s/iter; left time: 5225.3279s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0651387\n",
      "\tspeed: 0.1120s/iter; left time: 5700.8219s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0786256\n",
      "\tspeed: 0.1069s/iter; left time: 5430.1683s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0702851\n",
      "\tspeed: 0.1056s/iter; left time: 5352.5572s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0919049\n",
      "\tspeed: 0.1059s/iter; left time: 5356.1552s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1030596\n",
      "\tspeed: 0.1029s/iter; left time: 5198.5737s\n",
      "\titers: 4000, epoch: 9 | loss: 0.1027514\n",
      "\tspeed: 0.1025s/iter; left time: 5163.8451s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0780454\n",
      "\tspeed: 0.1002s/iter; left time: 5037.6974s\n",
      "\titers: 4200, epoch: 9 | loss: 0.1132283\n",
      "\tspeed: 0.1056s/iter; left time: 5299.3248s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0697139\n",
      "\tspeed: 0.1034s/iter; left time: 5178.2915s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0739302\n",
      "\tspeed: 0.1013s/iter; left time: 5065.2817s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0807885\n",
      "\tspeed: 0.1038s/iter; left time: 5179.2621s\n",
      "Epoch: 9 cost time: 00h:07m:48.76s\n",
      "Epoch: 9 | Train Loss: 0.0844597 Vali Loss: 0.0919761 Test Loss: 0.0936041\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.1010430\n",
      "\tspeed: 1.3346s/iter; left time: 66416.5087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0755394\n",
      "\tspeed: 0.1040s/iter; left time: 5166.6819s\n",
      "\titers: 300, epoch: 10 | loss: 0.0786103\n",
      "\tspeed: 0.1036s/iter; left time: 5135.9702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0899143\n",
      "\tspeed: 0.1051s/iter; left time: 5197.7291s\n",
      "\titers: 500, epoch: 10 | loss: 0.0636813\n",
      "\tspeed: 0.1041s/iter; left time: 5136.9201s\n",
      "\titers: 600, epoch: 10 | loss: 0.0777985\n",
      "\tspeed: 0.1002s/iter; left time: 4937.8216s\n",
      "\titers: 700, epoch: 10 | loss: 0.0812854\n",
      "\tspeed: 0.1027s/iter; left time: 5047.7730s\n",
      "\titers: 800, epoch: 10 | loss: 0.0824201\n",
      "\tspeed: 0.1019s/iter; left time: 4998.2648s\n",
      "\titers: 900, epoch: 10 | loss: 0.0969159\n",
      "\tspeed: 0.0977s/iter; left time: 4782.6161s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0650369\n",
      "\tspeed: 0.1116s/iter; left time: 5452.5445s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0965921\n",
      "\tspeed: 0.1048s/iter; left time: 5112.7270s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0686363\n",
      "\tspeed: 0.1007s/iter; left time: 4902.0690s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0707972\n",
      "\tspeed: 0.1103s/iter; left time: 5356.6364s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0846506\n",
      "\tspeed: 0.1042s/iter; left time: 5051.8875s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0771418\n",
      "\tspeed: 0.1023s/iter; left time: 4947.0735s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0756956\n",
      "\tspeed: 0.1023s/iter; left time: 4937.4101s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0902093\n",
      "\tspeed: 0.1056s/iter; left time: 5086.7251s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0785837\n",
      "\tspeed: 0.1014s/iter; left time: 4875.0373s\n",
      "\titers: 1900, epoch: 10 | loss: 0.1091566\n",
      "\tspeed: 0.1062s/iter; left time: 5092.8788s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0851738\n",
      "\tspeed: 0.1011s/iter; left time: 4840.8315s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0617394\n",
      "\tspeed: 0.1004s/iter; left time: 4793.4138s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0630960\n",
      "\tspeed: 0.1062s/iter; left time: 5062.1527s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0792385\n",
      "\tspeed: 0.1075s/iter; left time: 5114.0433s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0815424\n",
      "\tspeed: 0.1021s/iter; left time: 4847.8636s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0834371\n",
      "\tspeed: 0.1003s/iter; left time: 4751.5089s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0859960\n",
      "\tspeed: 0.1043s/iter; left time: 4930.6460s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0943459\n",
      "\tspeed: 0.1014s/iter; left time: 4781.8720s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0859495\n",
      "\tspeed: 0.0961s/iter; left time: 4524.2340s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0788042\n",
      "\tspeed: 0.1023s/iter; left time: 4802.3900s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0783276\n",
      "\tspeed: 0.1028s/iter; left time: 4817.8440s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0720328\n",
      "\tspeed: 0.0935s/iter; left time: 4372.6421s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0770221\n",
      "\tspeed: 0.1070s/iter; left time: 4993.5091s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0816277\n",
      "\tspeed: 0.1020s/iter; left time: 4748.6206s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0734417\n",
      "\tspeed: 0.1047s/iter; left time: 4865.7704s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0925057\n",
      "\tspeed: 0.0959s/iter; left time: 4448.4863s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0732646\n",
      "\tspeed: 0.1029s/iter; left time: 4761.7844s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0714871\n",
      "\tspeed: 0.0950s/iter; left time: 4383.2843s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0829047\n",
      "\tspeed: 0.1033s/iter; left time: 4756.3233s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0768411\n",
      "\tspeed: 0.1053s/iter; left time: 4839.7838s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0718129\n",
      "\tspeed: 0.0958s/iter; left time: 4391.5425s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0926463\n",
      "\tspeed: 0.1017s/iter; left time: 4654.4916s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0805132\n",
      "\tspeed: 0.1010s/iter; left time: 4609.8388s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0772594\n",
      "\tspeed: 0.1059s/iter; left time: 4825.7171s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0775610\n",
      "\tspeed: 0.1026s/iter; left time: 4663.3316s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0796847\n",
      "\tspeed: 0.0989s/iter; left time: 4488.3419s\n",
      "Epoch: 10 cost time: 00h:07m:45.98s\n",
      "Epoch: 10 | Train Loss: 0.0838264 Vali Loss: 0.0909270 Test Loss: 0.0934180\n",
      "Validation loss decreased (0.091097 --> 0.090927).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0868814\n",
      "\tspeed: 1.3530s/iter; left time: 61195.7743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0833030\n",
      "\tspeed: 0.1028s/iter; left time: 4638.8924s\n",
      "\titers: 300, epoch: 11 | loss: 0.0659933\n",
      "\tspeed: 0.1062s/iter; left time: 4781.5714s\n",
      "\titers: 400, epoch: 11 | loss: 0.0918775\n",
      "\tspeed: 0.0975s/iter; left time: 4380.8138s\n",
      "\titers: 500, epoch: 11 | loss: 0.0899109\n",
      "\tspeed: 0.1013s/iter; left time: 4542.9191s\n",
      "\titers: 600, epoch: 11 | loss: 0.0993830\n",
      "\tspeed: 0.1029s/iter; left time: 4603.1110s\n",
      "\titers: 700, epoch: 11 | loss: 0.0819754\n",
      "\tspeed: 0.1035s/iter; left time: 4619.2550s\n",
      "\titers: 800, epoch: 11 | loss: 0.0924889\n",
      "\tspeed: 0.1063s/iter; left time: 4733.0434s\n",
      "\titers: 900, epoch: 11 | loss: 0.0992053\n",
      "\tspeed: 0.1055s/iter; left time: 4686.5319s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0837300\n",
      "\tspeed: 0.1015s/iter; left time: 4500.3296s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0934541\n",
      "\tspeed: 0.0986s/iter; left time: 4362.1410s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0743836\n",
      "\tspeed: 0.1009s/iter; left time: 4452.3462s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0676240\n",
      "\tspeed: 0.1067s/iter; left time: 4698.3471s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0818041\n",
      "\tspeed: 0.1027s/iter; left time: 4509.9466s\n",
      "\titers: 1500, epoch: 11 | loss: 0.1061748\n",
      "\tspeed: 0.1008s/iter; left time: 4417.7841s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0742621\n",
      "\tspeed: 0.1059s/iter; left time: 4632.5696s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0765426\n",
      "\tspeed: 0.0977s/iter; left time: 4261.9754s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0633865\n",
      "\tspeed: 0.1004s/iter; left time: 4370.3637s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0719905\n",
      "\tspeed: 0.1036s/iter; left time: 4497.5792s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0846679\n",
      "\tspeed: 0.0987s/iter; left time: 4276.0389s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0660811\n",
      "\tspeed: 0.1049s/iter; left time: 4535.5453s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0933878\n",
      "\tspeed: 0.1022s/iter; left time: 4407.1591s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0863511\n",
      "\tspeed: 0.1039s/iter; left time: 4471.8153s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0862527\n",
      "\tspeed: 0.0982s/iter; left time: 4217.8503s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0868275\n",
      "\tspeed: 0.0992s/iter; left time: 4249.6541s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0819848\n",
      "\tspeed: 0.1020s/iter; left time: 4359.7169s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0776399\n",
      "\tspeed: 0.1049s/iter; left time: 4470.5936s\n",
      "\titers: 2800, epoch: 11 | loss: 0.1002442\n",
      "\tspeed: 0.1003s/iter; left time: 4264.1523s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0772504\n",
      "\tspeed: 0.1051s/iter; left time: 4457.6660s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0814845\n",
      "\tspeed: 0.1022s/iter; left time: 4327.1347s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0988288\n",
      "\tspeed: 0.0996s/iter; left time: 4204.4656s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0900506\n",
      "\tspeed: 0.1018s/iter; left time: 4287.1075s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0772932\n",
      "\tspeed: 0.1056s/iter; left time: 4438.8326s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0745195\n",
      "\tspeed: 0.0993s/iter; left time: 4162.6894s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0994061\n",
      "\tspeed: 0.1038s/iter; left time: 4342.0000s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0809238\n",
      "\tspeed: 0.1025s/iter; left time: 4277.6527s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0847667\n",
      "\tspeed: 0.0977s/iter; left time: 4065.7991s\n",
      "\titers: 3800, epoch: 11 | loss: 0.0905470\n",
      "\tspeed: 0.1051s/iter; left time: 4362.8507s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1020130\n",
      "\tspeed: 0.0958s/iter; left time: 3969.3467s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0703370\n",
      "\tspeed: 0.1018s/iter; left time: 4207.0264s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0917754\n",
      "\tspeed: 0.1018s/iter; left time: 4196.2700s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0985425\n",
      "\tspeed: 0.1031s/iter; left time: 4239.0728s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0730693\n",
      "\tspeed: 0.1041s/iter; left time: 4273.2968s\n",
      "\titers: 4400, epoch: 11 | loss: 0.0959341\n",
      "\tspeed: 0.1032s/iter; left time: 4223.2262s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0771418\n",
      "\tspeed: 0.1011s/iter; left time: 4129.3341s\n",
      "Epoch: 11 cost time: 00h:07m:43.67s\n",
      "Epoch: 11 | Train Loss: 0.0834381 Vali Loss: 0.0909066 Test Loss: 0.0931787\n",
      "Validation loss decreased (0.090927 --> 0.090907).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0886225\n",
      "\tspeed: 1.3803s/iter; left time: 56173.7156s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704846\n",
      "\tspeed: 0.1109s/iter; left time: 4503.3354s\n",
      "\titers: 300, epoch: 12 | loss: 0.0843104\n",
      "\tspeed: 0.1131s/iter; left time: 4578.4616s\n",
      "\titers: 400, epoch: 12 | loss: 0.0762128\n",
      "\tspeed: 0.0966s/iter; left time: 3900.9972s\n",
      "\titers: 500, epoch: 12 | loss: 0.0877431\n",
      "\tspeed: 0.0898s/iter; left time: 3619.8648s\n",
      "\titers: 600, epoch: 12 | loss: 0.0772243\n",
      "\tspeed: 0.0976s/iter; left time: 3922.9558s\n",
      "\titers: 700, epoch: 12 | loss: 0.0802122\n",
      "\tspeed: 0.1115s/iter; left time: 4471.3897s\n",
      "\titers: 800, epoch: 12 | loss: 0.0783113\n",
      "\tspeed: 0.1018s/iter; left time: 4073.2087s\n",
      "\titers: 900, epoch: 12 | loss: 0.0922541\n",
      "\tspeed: 0.0910s/iter; left time: 3630.3006s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0961081\n",
      "\tspeed: 0.1046s/iter; left time: 4161.5621s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0833521\n",
      "\tspeed: 0.1108s/iter; left time: 4398.7509s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0738913\n",
      "\tspeed: 0.1108s/iter; left time: 4388.5681s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0856553\n",
      "\tspeed: 0.1114s/iter; left time: 4400.9010s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0767801\n",
      "\tspeed: 0.1115s/iter; left time: 4391.3045s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0789911\n",
      "\tspeed: 0.1122s/iter; left time: 4407.6882s\n",
      "\titers: 1600, epoch: 12 | loss: 0.1014416\n",
      "\tspeed: 0.1125s/iter; left time: 4411.6716s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0787071\n",
      "\tspeed: 0.1127s/iter; left time: 4404.5828s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0898735\n",
      "\tspeed: 0.1114s/iter; left time: 4342.8016s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0726669\n",
      "\tspeed: 0.1109s/iter; left time: 4314.4575s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0864183\n",
      "\tspeed: 0.1114s/iter; left time: 4320.3633s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0647909\n",
      "\tspeed: 0.1117s/iter; left time: 4324.4055s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0833790\n",
      "\tspeed: 0.1118s/iter; left time: 4316.1799s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0672993\n",
      "\tspeed: 0.1104s/iter; left time: 4250.7136s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0770334\n",
      "\tspeed: 0.1140s/iter; left time: 4379.2232s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0722176\n",
      "\tspeed: 0.1175s/iter; left time: 4499.6213s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0794186\n",
      "\tspeed: 0.1131s/iter; left time: 4321.0988s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0768241\n",
      "\tspeed: 0.1122s/iter; left time: 4272.7457s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0862142\n",
      "\tspeed: 0.1113s/iter; left time: 4230.8027s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0829330\n",
      "\tspeed: 0.1113s/iter; left time: 4219.5043s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0871102\n",
      "\tspeed: 0.1110s/iter; left time: 4193.7760s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0841428\n",
      "\tspeed: 0.1109s/iter; left time: 4179.8843s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0871388\n",
      "\tspeed: 0.1108s/iter; left time: 4167.0181s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0876352\n",
      "\tspeed: 0.1117s/iter; left time: 4187.0873s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0692153\n",
      "\tspeed: 0.1111s/iter; left time: 4153.5511s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0942930\n",
      "\tspeed: 0.1113s/iter; left time: 4152.1312s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0974538\n",
      "\tspeed: 0.1109s/iter; left time: 4124.2492s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0789281\n",
      "\tspeed: 0.1108s/iter; left time: 4111.4908s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0951056\n",
      "\tspeed: 0.1108s/iter; left time: 4099.9487s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0798555\n",
      "\tspeed: 0.1110s/iter; left time: 4093.8582s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0776716\n",
      "\tspeed: 0.1110s/iter; left time: 4085.7079s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0741630\n",
      "\tspeed: 0.1112s/iter; left time: 4079.3293s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0646463\n",
      "\tspeed: 0.1130s/iter; left time: 4137.0240s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0909856\n",
      "\tspeed: 0.1144s/iter; left time: 4174.2874s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0871067\n",
      "\tspeed: 0.1165s/iter; left time: 4240.1633s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0992545\n",
      "\tspeed: 0.1170s/iter; left time: 4246.8881s\n",
      "Epoch: 12 cost time: 00h:08m:19.65s\n",
      "Epoch: 12 | Train Loss: 0.0829866 Vali Loss: 0.0906585 Test Loss: 0.0937089\n",
      "Validation loss decreased (0.090907 --> 0.090658).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0791249\n",
      "\tspeed: 1.3686s/iter; left time: 49494.4113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0801380\n",
      "\tspeed: 0.1176s/iter; left time: 4240.9751s\n",
      "\titers: 300, epoch: 13 | loss: 0.0883047\n",
      "\tspeed: 0.1201s/iter; left time: 4320.6687s\n",
      "\titers: 400, epoch: 13 | loss: 0.0885546\n",
      "\tspeed: 0.1132s/iter; left time: 4059.8484s\n",
      "\titers: 500, epoch: 13 | loss: 0.0820055\n",
      "\tspeed: 0.1117s/iter; left time: 3994.1113s\n",
      "\titers: 600, epoch: 13 | loss: 0.0886124\n",
      "\tspeed: 0.1128s/iter; left time: 4024.6045s\n",
      "\titers: 700, epoch: 13 | loss: 0.0714438\n",
      "\tspeed: 0.1156s/iter; left time: 4110.3409s\n",
      "\titers: 800, epoch: 13 | loss: 0.1015169\n",
      "\tspeed: 0.1172s/iter; left time: 4157.3575s\n",
      "\titers: 900, epoch: 13 | loss: 0.0811925\n",
      "\tspeed: 0.1167s/iter; left time: 4126.6244s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0657136\n",
      "\tspeed: 0.1122s/iter; left time: 3956.2513s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0817874\n",
      "\tspeed: 0.1112s/iter; left time: 3908.8363s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0827836\n",
      "\tspeed: 0.1065s/iter; left time: 3735.8571s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0906617\n",
      "\tspeed: 0.1134s/iter; left time: 3965.2034s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0743353\n",
      "\tspeed: 0.1108s/iter; left time: 3864.5048s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0843722\n",
      "\tspeed: 0.1130s/iter; left time: 3927.1964s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0961763\n",
      "\tspeed: 0.1164s/iter; left time: 4036.3358s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0756035\n",
      "\tspeed: 0.1163s/iter; left time: 4019.9631s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0759710\n",
      "\tspeed: 0.1164s/iter; left time: 4012.3950s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0960970\n",
      "\tspeed: 0.1160s/iter; left time: 3985.9931s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0852554\n",
      "\tspeed: 0.1153s/iter; left time: 3949.7180s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0826193\n",
      "\tspeed: 0.1107s/iter; left time: 3783.4062s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0701863\n",
      "\tspeed: 0.1107s/iter; left time: 3771.1392s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0795562\n",
      "\tspeed: 0.1109s/iter; left time: 3768.1809s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0949270\n",
      "\tspeed: 0.1109s/iter; left time: 3756.7527s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0853140\n",
      "\tspeed: 0.1110s/iter; left time: 3746.5461s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0787078\n",
      "\tspeed: 0.1113s/iter; left time: 3747.9117s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0833492\n",
      "\tspeed: 0.1113s/iter; left time: 3736.4199s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0813542\n",
      "\tspeed: 0.1108s/iter; left time: 3708.9582s\n",
      "\titers: 2900, epoch: 13 | loss: 0.1056878\n",
      "\tspeed: 0.1111s/iter; left time: 3705.5921s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0806301\n",
      "\tspeed: 0.1109s/iter; left time: 3689.5989s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0857160\n",
      "\tspeed: 0.1110s/iter; left time: 3680.1804s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0664781\n",
      "\tspeed: 0.1109s/iter; left time: 3666.4144s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0840124\n",
      "\tspeed: 0.1110s/iter; left time: 3657.5803s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0705491\n",
      "\tspeed: 0.1108s/iter; left time: 3641.5789s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0935380\n",
      "\tspeed: 0.1149s/iter; left time: 3763.5672s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0906575\n",
      "\tspeed: 0.1126s/iter; left time: 3678.9123s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0968636\n",
      "\tspeed: 0.1108s/iter; left time: 3606.6664s\n",
      "\titers: 3800, epoch: 13 | loss: 0.0919440\n",
      "\tspeed: 0.1153s/iter; left time: 3742.8749s\n",
      "\titers: 3900, epoch: 13 | loss: 0.0788422\n",
      "\tspeed: 0.1112s/iter; left time: 3600.5200s\n",
      "\titers: 4000, epoch: 13 | loss: 0.0863206\n",
      "\tspeed: 0.1111s/iter; left time: 3583.5639s\n",
      "\titers: 4100, epoch: 13 | loss: 0.0730646\n",
      "\tspeed: 0.1108s/iter; left time: 3565.3403s\n",
      "\titers: 4200, epoch: 13 | loss: 0.0905983\n",
      "\tspeed: 0.1143s/iter; left time: 3664.4059s\n",
      "\titers: 4300, epoch: 13 | loss: 0.0929489\n",
      "\tspeed: 0.1143s/iter; left time: 3654.7118s\n",
      "\titers: 4400, epoch: 13 | loss: 0.0747109\n",
      "\tspeed: 0.1124s/iter; left time: 3581.2646s\n",
      "\titers: 4500, epoch: 13 | loss: 0.0708904\n",
      "\tspeed: 0.1111s/iter; left time: 3527.7849s\n",
      "Epoch: 13 cost time: 00h:08m:32.35s\n",
      "Epoch: 13 | Train Loss: 0.0825152 Vali Loss: 0.0904522 Test Loss: 0.0932098\n",
      "Validation loss decreased (0.090658 --> 0.090452).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0660638\n",
      "\tspeed: 1.3859s/iter; left time: 43839.3476s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745506\n",
      "\tspeed: 0.1121s/iter; left time: 3534.6208s\n",
      "\titers: 300, epoch: 14 | loss: 0.0715450\n",
      "\tspeed: 0.0973s/iter; left time: 3056.7949s\n",
      "\titers: 400, epoch: 14 | loss: 0.0766391\n",
      "\tspeed: 0.1168s/iter; left time: 3660.8783s\n",
      "\titers: 500, epoch: 14 | loss: 0.0950110\n",
      "\tspeed: 0.1161s/iter; left time: 3626.3020s\n",
      "\titers: 600, epoch: 14 | loss: 0.0777599\n",
      "\tspeed: 0.1142s/iter; left time: 3555.9614s\n",
      "\titers: 700, epoch: 14 | loss: 0.0903370\n",
      "\tspeed: 0.1160s/iter; left time: 3600.6101s\n",
      "\titers: 800, epoch: 14 | loss: 0.0700843\n",
      "\tspeed: 0.1163s/iter; left time: 3596.8290s\n",
      "\titers: 900, epoch: 14 | loss: 0.0727566\n",
      "\tspeed: 0.1163s/iter; left time: 3585.2722s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0758147\n",
      "\tspeed: 0.1118s/iter; left time: 3435.2970s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0972789\n",
      "\tspeed: 0.1163s/iter; left time: 3561.4343s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0837456\n",
      "\tspeed: 0.1154s/iter; left time: 3523.6903s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0850364\n",
      "\tspeed: 0.1158s/iter; left time: 3524.2120s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0846834\n",
      "\tspeed: 0.1161s/iter; left time: 3522.6790s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0751023\n",
      "\tspeed: 0.1159s/iter; left time: 3503.7232s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0751074\n",
      "\tspeed: 0.1163s/iter; left time: 3504.3758s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0639160\n",
      "\tspeed: 0.1175s/iter; left time: 3530.1114s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0911648\n",
      "\tspeed: 0.1161s/iter; left time: 3473.8712s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0872721\n",
      "\tspeed: 0.1185s/iter; left time: 3534.2849s\n",
      "\titers: 2000, epoch: 14 | loss: 0.1031610\n",
      "\tspeed: 0.1161s/iter; left time: 3451.0559s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0678420\n",
      "\tspeed: 0.1161s/iter; left time: 3440.9047s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0803739\n",
      "\tspeed: 0.1187s/iter; left time: 3506.5313s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0830740\n",
      "\tspeed: 0.1170s/iter; left time: 3444.3197s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0877171\n",
      "\tspeed: 0.1175s/iter; left time: 3447.0706s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0903826\n",
      "\tspeed: 0.1154s/iter; left time: 3372.8699s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0659819\n",
      "\tspeed: 0.1173s/iter; left time: 3416.7058s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0935967\n",
      "\tspeed: 0.1173s/iter; left time: 3404.4416s\n",
      "\titers: 2800, epoch: 14 | loss: 0.0878704\n",
      "\tspeed: 0.1159s/iter; left time: 3353.0340s\n",
      "\titers: 2900, epoch: 14 | loss: 0.1039079\n",
      "\tspeed: 0.1180s/iter; left time: 3403.2731s\n",
      "\titers: 3000, epoch: 14 | loss: 0.0661499\n",
      "\tspeed: 0.1169s/iter; left time: 3359.0228s\n",
      "\titers: 3100, epoch: 14 | loss: 0.0741001\n",
      "\tspeed: 0.1170s/iter; left time: 3348.6389s\n",
      "\titers: 3200, epoch: 14 | loss: 0.0819949\n",
      "\tspeed: 0.1123s/iter; left time: 3203.8603s\n",
      "\titers: 3300, epoch: 14 | loss: 0.0826454\n",
      "\tspeed: 0.1056s/iter; left time: 3002.4439s\n",
      "\titers: 3400, epoch: 14 | loss: 0.0878785\n",
      "\tspeed: 0.1002s/iter; left time: 2838.1174s\n",
      "\titers: 3500, epoch: 14 | loss: 0.0842458\n",
      "\tspeed: 0.1091s/iter; left time: 3081.2243s\n",
      "\titers: 3600, epoch: 14 | loss: 0.0751131\n",
      "\tspeed: 0.1157s/iter; left time: 3255.4836s\n",
      "\titers: 3700, epoch: 14 | loss: 0.0962623\n",
      "\tspeed: 0.1110s/iter; left time: 3112.8241s\n",
      "\titers: 3800, epoch: 14 | loss: 0.0715155\n",
      "\tspeed: 0.1150s/iter; left time: 3211.9123s\n",
      "\titers: 3900, epoch: 14 | loss: 0.0696548\n",
      "\tspeed: 0.1142s/iter; left time: 3177.4661s\n",
      "\titers: 4000, epoch: 14 | loss: 0.0932395\n",
      "\tspeed: 0.1043s/iter; left time: 2892.2692s\n",
      "\titers: 4100, epoch: 14 | loss: 0.0887267\n",
      "\tspeed: 0.1020s/iter; left time: 2817.4186s\n",
      "\titers: 4200, epoch: 14 | loss: 0.0927753\n",
      "\tspeed: 0.1067s/iter; left time: 2936.5083s\n",
      "\titers: 4300, epoch: 14 | loss: 0.0820033\n",
      "\tspeed: 0.1059s/iter; left time: 2904.5411s\n",
      "\titers: 4400, epoch: 14 | loss: 0.0966658\n",
      "\tspeed: 0.1029s/iter; left time: 2811.1885s\n",
      "\titers: 4500, epoch: 14 | loss: 0.0918710\n",
      "\tspeed: 0.1504s/iter; left time: 4096.4239s\n",
      "Epoch: 14 cost time: 00h:08m:41.24s\n",
      "Epoch: 14 | Train Loss: 0.0821637 Vali Loss: 0.0901667 Test Loss: 0.0932900\n",
      "Validation loss decreased (0.090452 --> 0.090167).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0781592\n",
      "\tspeed: 2.8223s/iter; left time: 76482.0644s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817208\n",
      "\tspeed: 0.2120s/iter; left time: 5723.8413s\n",
      "\titers: 300, epoch: 15 | loss: 0.0733876\n",
      "\tspeed: 0.2091s/iter; left time: 5625.0584s\n",
      "\titers: 400, epoch: 15 | loss: 0.1039848\n",
      "\tspeed: 0.2054s/iter; left time: 5504.5373s\n",
      "\titers: 500, epoch: 15 | loss: 0.0775597\n",
      "\tspeed: 0.2084s/iter; left time: 5565.1773s\n",
      "\titers: 600, epoch: 15 | loss: 0.0997102\n",
      "\tspeed: 0.2066s/iter; left time: 5496.0954s\n",
      "\titers: 700, epoch: 15 | loss: 0.0608641\n",
      "\tspeed: 0.2041s/iter; left time: 5407.3185s\n",
      "\titers: 800, epoch: 15 | loss: 0.1097342\n",
      "\tspeed: 0.2023s/iter; left time: 5341.8230s\n",
      "\titers: 900, epoch: 15 | loss: 0.0934608\n",
      "\tspeed: 0.2119s/iter; left time: 5572.8130s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0922303\n",
      "\tspeed: 0.2064s/iter; left time: 5407.4919s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0907400\n",
      "\tspeed: 0.2079s/iter; left time: 5426.9764s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0798248\n",
      "\tspeed: 0.2045s/iter; left time: 5316.9901s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0796295\n",
      "\tspeed: 0.2043s/iter; left time: 5291.0223s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0715901\n",
      "\tspeed: 0.2115s/iter; left time: 5457.2872s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0915216\n",
      "\tspeed: 0.2109s/iter; left time: 5420.5268s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0679636\n",
      "\tspeed: 0.2092s/iter; left time: 5356.3357s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0982192\n",
      "\tspeed: 0.2106s/iter; left time: 5370.2612s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0891062\n",
      "\tspeed: 0.2149s/iter; left time: 5457.5333s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0957525\n",
      "\tspeed: 0.2107s/iter; left time: 5330.9234s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0853636\n",
      "\tspeed: 0.2123s/iter; left time: 5350.3660s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0831941\n",
      "\tspeed: 0.2128s/iter; left time: 5341.3730s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0627448\n",
      "\tspeed: 0.2039s/iter; left time: 5096.9805s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0774590\n",
      "\tspeed: 0.2027s/iter; left time: 5048.1416s\n",
      "\titers: 2400, epoch: 15 | loss: 0.1005073\n",
      "\tspeed: 0.2048s/iter; left time: 5077.8762s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0733369\n",
      "\tspeed: 0.2032s/iter; left time: 5020.0269s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0717259\n",
      "\tspeed: 0.2107s/iter; left time: 5183.1453s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0817308\n",
      "\tspeed: 0.2066s/iter; left time: 5060.4979s\n",
      "\titers: 2800, epoch: 15 | loss: 0.0867810\n",
      "\tspeed: 0.2053s/iter; left time: 5009.8421s\n",
      "\titers: 2900, epoch: 15 | loss: 0.0729885\n",
      "\tspeed: 0.2042s/iter; left time: 4961.4739s\n",
      "\titers: 3000, epoch: 15 | loss: 0.0958132\n",
      "\tspeed: 0.2001s/iter; left time: 4841.2194s\n",
      "\titers: 3100, epoch: 15 | loss: 0.0956142\n",
      "\tspeed: 0.2031s/iter; left time: 4893.6308s\n",
      "\titers: 3200, epoch: 15 | loss: 0.0817815\n",
      "\tspeed: 0.2058s/iter; left time: 4937.9433s\n",
      "\titers: 3300, epoch: 15 | loss: 0.0741010\n",
      "\tspeed: 0.2110s/iter; left time: 5041.7216s\n",
      "\titers: 3400, epoch: 15 | loss: 0.0857117\n",
      "\tspeed: 0.2063s/iter; left time: 4908.7933s\n",
      "\titers: 3500, epoch: 15 | loss: 0.0769775\n",
      "\tspeed: 0.2056s/iter; left time: 4873.5452s\n",
      "\titers: 3600, epoch: 15 | loss: 0.0921145\n",
      "\tspeed: 0.2051s/iter; left time: 4841.1853s\n",
      "\titers: 3700, epoch: 15 | loss: 0.0749342\n",
      "\tspeed: 0.2005s/iter; left time: 4710.4518s\n",
      "\titers: 3800, epoch: 15 | loss: 0.0706256\n",
      "\tspeed: 0.2044s/iter; left time: 4783.7027s\n",
      "\titers: 3900, epoch: 15 | loss: 0.0814783\n",
      "\tspeed: 0.2074s/iter; left time: 4832.5463s\n",
      "\titers: 4000, epoch: 15 | loss: 0.0876609\n",
      "\tspeed: 0.2053s/iter; left time: 4761.8819s\n",
      "\titers: 4100, epoch: 15 | loss: 0.0729776\n",
      "\tspeed: 0.2054s/iter; left time: 4745.6866s\n",
      "\titers: 4200, epoch: 15 | loss: 0.0701113\n",
      "\tspeed: 0.2089s/iter; left time: 4804.1412s\n",
      "\titers: 4300, epoch: 15 | loss: 0.0847608\n",
      "\tspeed: 0.2095s/iter; left time: 4797.8228s\n",
      "\titers: 4400, epoch: 15 | loss: 0.0657880\n",
      "\tspeed: 0.2073s/iter; left time: 4725.3065s\n",
      "\titers: 4500, epoch: 15 | loss: 0.0572933\n",
      "\tspeed: 0.2061s/iter; left time: 4677.9496s\n",
      "Epoch: 15 cost time: 00h:15m:38.93s\n",
      "Epoch: 15 | Train Loss: 0.0819345 Vali Loss: 0.0900722 Test Loss: 0.0930771\n",
      "Validation loss decreased (0.090167 --> 0.090072).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0724645\n",
      "\tspeed: 2.8432s/iter; left time: 64158.8405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0767992\n",
      "\tspeed: 0.2079s/iter; left time: 4670.3308s\n",
      "\titers: 300, epoch: 16 | loss: 0.0709932\n",
      "\tspeed: 0.2068s/iter; left time: 4626.0887s\n",
      "\titers: 400, epoch: 16 | loss: 0.0831184\n",
      "\tspeed: 0.2060s/iter; left time: 4586.4097s\n",
      "\titers: 500, epoch: 16 | loss: 0.0966128\n",
      "\tspeed: 0.2034s/iter; left time: 4508.8265s\n",
      "\titers: 600, epoch: 16 | loss: 0.0895692\n",
      "\tspeed: 0.2073s/iter; left time: 4575.3632s\n",
      "\titers: 700, epoch: 16 | loss: 0.0863161\n",
      "\tspeed: 0.1983s/iter; left time: 4356.6491s\n",
      "\titers: 800, epoch: 16 | loss: 0.0756211\n",
      "\tspeed: 0.2050s/iter; left time: 4482.5904s\n",
      "\titers: 900, epoch: 16 | loss: 0.0764739\n",
      "\tspeed: 0.2092s/iter; left time: 4552.5830s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0625793\n",
      "\tspeed: 0.2033s/iter; left time: 4405.7471s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0810612\n",
      "\tspeed: 0.2096s/iter; left time: 4520.4336s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0767624\n",
      "\tspeed: 0.2099s/iter; left time: 4505.1103s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0753944\n",
      "\tspeed: 0.2261s/iter; left time: 4829.9879s\n",
      "\titers: 1400, epoch: 16 | loss: 0.1056277\n",
      "\tspeed: 0.2113s/iter; left time: 4493.9029s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0988726\n",
      "\tspeed: 0.2050s/iter; left time: 4339.6184s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0924941\n",
      "\tspeed: 0.1992s/iter; left time: 4196.0328s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0742520\n",
      "\tspeed: 0.2005s/iter; left time: 4204.2425s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0763841\n",
      "\tspeed: 0.2055s/iter; left time: 4288.9494s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0803828\n",
      "\tspeed: 0.2053s/iter; left time: 4262.2218s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0858300\n",
      "\tspeed: 0.2081s/iter; left time: 4300.9927s\n",
      "\titers: 2100, epoch: 16 | loss: 0.1063153\n",
      "\tspeed: 0.2060s/iter; left time: 4235.9114s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0874704\n",
      "\tspeed: 0.2082s/iter; left time: 4260.4045s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0813350\n",
      "\tspeed: 0.2088s/iter; left time: 4253.2919s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0635194\n",
      "\tspeed: 0.2006s/iter; left time: 4065.5371s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0828632\n",
      "\tspeed: 0.2080s/iter; left time: 4195.1115s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0861115\n",
      "\tspeed: 0.2107s/iter; left time: 4228.1337s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0758510\n",
      "\tspeed: 0.2032s/iter; left time: 4056.4580s\n",
      "\titers: 2800, epoch: 16 | loss: 0.0841146\n",
      "\tspeed: 0.2007s/iter; left time: 3986.2553s\n",
      "\titers: 2900, epoch: 16 | loss: 0.0860678\n",
      "\tspeed: 0.2042s/iter; left time: 4036.6045s\n",
      "\titers: 3000, epoch: 16 | loss: 0.0766806\n",
      "\tspeed: 0.1981s/iter; left time: 3895.3242s\n",
      "\titers: 3100, epoch: 16 | loss: 0.0732827\n",
      "\tspeed: 0.2047s/iter; left time: 4005.8632s\n",
      "\titers: 3200, epoch: 16 | loss: 0.0707445\n",
      "\tspeed: 0.1998s/iter; left time: 3889.9151s\n",
      "\titers: 3300, epoch: 16 | loss: 0.0873484\n",
      "\tspeed: 0.2016s/iter; left time: 3903.3641s\n",
      "\titers: 3400, epoch: 16 | loss: 0.0758336\n",
      "\tspeed: 0.1937s/iter; left time: 3730.8910s\n",
      "\titers: 3500, epoch: 16 | loss: 0.0919489\n",
      "\tspeed: 0.1988s/iter; left time: 3809.7119s\n",
      "\titers: 3600, epoch: 16 | loss: 0.0717335\n",
      "\tspeed: 0.1965s/iter; left time: 3745.7750s\n",
      "\titers: 3700, epoch: 16 | loss: 0.0677496\n",
      "\tspeed: 0.2005s/iter; left time: 3801.9967s\n",
      "\titers: 3800, epoch: 16 | loss: 0.0932850\n",
      "\tspeed: 0.2034s/iter; left time: 3837.5194s\n",
      "\titers: 3900, epoch: 16 | loss: 0.0753954\n",
      "\tspeed: 0.1967s/iter; left time: 3690.3947s\n",
      "\titers: 4000, epoch: 16 | loss: 0.0843962\n",
      "\tspeed: 0.2013s/iter; left time: 3757.8746s\n",
      "\titers: 4100, epoch: 16 | loss: 0.0828186\n",
      "\tspeed: 0.1992s/iter; left time: 3698.4082s\n",
      "\titers: 4200, epoch: 16 | loss: 0.0648547\n",
      "\tspeed: 0.1951s/iter; left time: 3602.4349s\n",
      "\titers: 4300, epoch: 16 | loss: 0.0725025\n",
      "\tspeed: 0.2016s/iter; left time: 3703.4556s\n",
      "\titers: 4400, epoch: 16 | loss: 0.0648678\n",
      "\tspeed: 0.2099s/iter; left time: 3834.2663s\n",
      "\titers: 4500, epoch: 16 | loss: 0.0682965\n",
      "\tspeed: 0.2090s/iter; left time: 3795.9003s\n",
      "Epoch: 16 cost time: 00h:15m:26.99s\n",
      "Epoch: 16 | Train Loss: 0.0814862 Vali Loss: 0.0900890 Test Loss: 0.0928981\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0779907\n",
      "\tspeed: 2.8336s/iter; left time: 51098.5405s\n",
      "\titers: 200, epoch: 17 | loss: 0.0804352\n",
      "\tspeed: 0.2036s/iter; left time: 3651.9649s\n",
      "\titers: 300, epoch: 17 | loss: 0.0810385\n",
      "\tspeed: 0.2085s/iter; left time: 3718.7163s\n",
      "\titers: 400, epoch: 17 | loss: 0.0795031\n",
      "\tspeed: 0.2053s/iter; left time: 3640.1134s\n",
      "\titers: 500, epoch: 17 | loss: 0.0691069\n",
      "\tspeed: 0.2082s/iter; left time: 3670.9166s\n",
      "\titers: 600, epoch: 17 | loss: 0.0998175\n",
      "\tspeed: 0.2103s/iter; left time: 3687.7238s\n",
      "\titers: 700, epoch: 17 | loss: 0.0868025\n",
      "\tspeed: 0.2083s/iter; left time: 3630.5217s\n",
      "\titers: 800, epoch: 17 | loss: 0.0653060\n",
      "\tspeed: 0.2044s/iter; left time: 3543.2673s\n",
      "\titers: 900, epoch: 17 | loss: 0.0652221\n",
      "\tspeed: 0.2112s/iter; left time: 3638.8770s\n",
      "\titers: 1000, epoch: 17 | loss: 0.1059849\n",
      "\tspeed: 0.2070s/iter; left time: 3546.5671s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0640589\n",
      "\tspeed: 0.2054s/iter; left time: 3498.1711s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0844095\n",
      "\tspeed: 0.2092s/iter; left time: 3542.7772s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0829859\n",
      "\tspeed: 0.2079s/iter; left time: 3499.3629s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0754173\n",
      "\tspeed: 0.2081s/iter; left time: 3482.4673s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0830839\n",
      "\tspeed: 0.2082s/iter; left time: 3463.4556s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0756477\n",
      "\tspeed: 0.2103s/iter; left time: 3476.3702s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0747706\n",
      "\tspeed: 0.2117s/iter; left time: 3478.7441s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0718630\n",
      "\tspeed: 0.2074s/iter; left time: 3387.7211s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0996768\n",
      "\tspeed: 0.2020s/iter; left time: 3279.4076s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0655960\n",
      "\tspeed: 0.2011s/iter; left time: 3244.7255s\n",
      "\titers: 2100, epoch: 17 | loss: 0.1009256\n",
      "\tspeed: 0.2104s/iter; left time: 3374.0252s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0617915\n",
      "\tspeed: 0.2047s/iter; left time: 3261.7863s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0757957\n",
      "\tspeed: 0.2080s/iter; left time: 3293.2961s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0729246\n",
      "\tspeed: 0.2056s/iter; left time: 3235.3514s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0803725\n",
      "\tspeed: 0.2055s/iter; left time: 3212.3184s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0918309\n",
      "\tspeed: 0.2104s/iter; left time: 3267.7813s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0632335\n",
      "\tspeed: 0.2044s/iter; left time: 3153.9923s\n",
      "\titers: 2800, epoch: 17 | loss: 0.0943785\n",
      "\tspeed: 0.2067s/iter; left time: 3169.0661s\n",
      "\titers: 2900, epoch: 17 | loss: 0.0760062\n",
      "\tspeed: 0.2097s/iter; left time: 3193.7571s\n",
      "\titers: 3000, epoch: 17 | loss: 0.0784810\n",
      "\tspeed: 0.2106s/iter; left time: 3186.5442s\n",
      "\titers: 3100, epoch: 17 | loss: 0.1016624\n",
      "\tspeed: 0.2089s/iter; left time: 3140.0077s\n",
      "\titers: 3200, epoch: 17 | loss: 0.0930956\n",
      "\tspeed: 0.1992s/iter; left time: 2975.0185s\n",
      "\titers: 3300, epoch: 17 | loss: 0.0864676\n",
      "\tspeed: 0.2146s/iter; left time: 3182.6882s\n",
      "\titers: 3400, epoch: 17 | loss: 0.1175842\n",
      "\tspeed: 0.2141s/iter; left time: 3154.6536s\n",
      "\titers: 3500, epoch: 17 | loss: 0.0861637\n",
      "\tspeed: 0.2090s/iter; left time: 3057.6854s\n",
      "\titers: 3600, epoch: 17 | loss: 0.0755142\n",
      "\tspeed: 0.2074s/iter; left time: 3014.4588s\n",
      "\titers: 3700, epoch: 17 | loss: 0.0779291\n",
      "\tspeed: 0.2050s/iter; left time: 2959.3447s\n",
      "\titers: 3800, epoch: 17 | loss: 0.0678985\n",
      "\tspeed: 0.2100s/iter; left time: 3010.5441s\n",
      "\titers: 3900, epoch: 17 | loss: 0.0767063\n",
      "\tspeed: 0.2067s/iter; left time: 2941.8799s\n",
      "\titers: 4000, epoch: 17 | loss: 0.0977842\n",
      "\tspeed: 0.2091s/iter; left time: 2954.8832s\n",
      "\titers: 4100, epoch: 17 | loss: 0.0707132\n",
      "\tspeed: 0.2186s/iter; left time: 3067.0416s\n",
      "\titers: 4200, epoch: 17 | loss: 0.0659148\n",
      "\tspeed: 0.2256s/iter; left time: 3143.2843s\n",
      "\titers: 4300, epoch: 17 | loss: 0.0854227\n",
      "\tspeed: 0.2073s/iter; left time: 2868.1639s\n",
      "\titers: 4400, epoch: 17 | loss: 0.0686285\n",
      "\tspeed: 0.2109s/iter; left time: 2896.4402s\n",
      "\titers: 4500, epoch: 17 | loss: 0.0824729\n",
      "\tspeed: 0.2091s/iter; left time: 2851.2364s\n",
      "Epoch: 17 cost time: 00h:15m:44.61s\n",
      "Epoch: 17 | Train Loss: 0.0812407 Vali Loss: 0.0900395 Test Loss: 0.0928835\n",
      "Validation loss decreased (0.090072 --> 0.090040).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0795694\n",
      "\tspeed: 2.9009s/iter; left time: 39162.1895s\n",
      "\titers: 200, epoch: 18 | loss: 0.0838256\n",
      "\tspeed: 0.2086s/iter; left time: 2795.5966s\n",
      "\titers: 300, epoch: 18 | loss: 0.0811552\n",
      "\tspeed: 0.2036s/iter; left time: 2707.2805s\n",
      "\titers: 400, epoch: 18 | loss: 0.0848344\n",
      "\tspeed: 0.2011s/iter; left time: 2654.4536s\n",
      "\titers: 500, epoch: 18 | loss: 0.0849858\n",
      "\tspeed: 0.2107s/iter; left time: 2759.9852s\n",
      "\titers: 600, epoch: 18 | loss: 0.1082629\n",
      "\tspeed: 0.2046s/iter; left time: 2659.7627s\n",
      "\titers: 700, epoch: 18 | loss: 0.0725619\n",
      "\tspeed: 0.2071s/iter; left time: 2671.4557s\n",
      "\titers: 800, epoch: 18 | loss: 0.0965610\n",
      "\tspeed: 0.2076s/iter; left time: 2656.9527s\n",
      "\titers: 900, epoch: 18 | loss: 0.0722590\n",
      "\tspeed: 0.2098s/iter; left time: 2664.5000s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0755065\n",
      "\tspeed: 0.2118s/iter; left time: 2668.7763s\n",
      "\titers: 1100, epoch: 18 | loss: 0.1057993\n",
      "\tspeed: 0.2077s/iter; left time: 2596.6814s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0953928\n",
      "\tspeed: 0.2061s/iter; left time: 2555.4371s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0883500\n",
      "\tspeed: 0.2075s/iter; left time: 2551.7381s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0757185\n",
      "\tspeed: 0.2083s/iter; left time: 2541.2731s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0573659\n",
      "\tspeed: 0.2122s/iter; left time: 2568.1037s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0921795\n",
      "\tspeed: 0.2088s/iter; left time: 2506.0242s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0920135\n",
      "\tspeed: 0.2089s/iter; left time: 2485.9251s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0972895\n",
      "\tspeed: 0.2049s/iter; left time: 2418.2577s\n",
      "\titers: 1900, epoch: 18 | loss: 0.1059940\n",
      "\tspeed: 0.2045s/iter; left time: 2393.1070s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0868188\n",
      "\tspeed: 0.2082s/iter; left time: 2415.0229s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0829052\n",
      "\tspeed: 0.2059s/iter; left time: 2367.6520s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0690750\n",
      "\tspeed: 0.2045s/iter; left time: 2331.1394s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0917492\n",
      "\tspeed: 0.2042s/iter; left time: 2307.6904s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0779928\n",
      "\tspeed: 0.2039s/iter; left time: 2284.0471s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0669884\n",
      "\tspeed: 0.2084s/iter; left time: 2312.8528s\n",
      "\titers: 2600, epoch: 18 | loss: 0.1034114\n",
      "\tspeed: 0.2071s/iter; left time: 2278.0434s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0774817\n",
      "\tspeed: 0.2041s/iter; left time: 2224.9345s\n",
      "\titers: 2800, epoch: 18 | loss: 0.1134784\n",
      "\tspeed: 0.2062s/iter; left time: 2226.8521s\n",
      "\titers: 2900, epoch: 18 | loss: 0.0700959\n",
      "\tspeed: 0.2083s/iter; left time: 2229.2835s\n",
      "\titers: 3000, epoch: 18 | loss: 0.0714843\n",
      "\tspeed: 0.2094s/iter; left time: 2219.3680s\n",
      "\titers: 3100, epoch: 18 | loss: 0.0604120\n",
      "\tspeed: 0.2001s/iter; left time: 2100.6559s\n",
      "\titers: 3200, epoch: 18 | loss: 0.0796753\n",
      "\tspeed: 0.1967s/iter; left time: 2045.8406s\n",
      "\titers: 3300, epoch: 18 | loss: 0.0790297\n",
      "\tspeed: 0.2042s/iter; left time: 2102.8270s\n",
      "\titers: 3400, epoch: 18 | loss: 0.0765088\n",
      "\tspeed: 0.1921s/iter; left time: 1959.0332s\n",
      "\titers: 3500, epoch: 18 | loss: 0.0811823\n",
      "\tspeed: 0.2033s/iter; left time: 2053.4265s\n",
      "\titers: 3600, epoch: 18 | loss: 0.0719975\n",
      "\tspeed: 0.2044s/iter; left time: 2044.1146s\n",
      "\titers: 3700, epoch: 18 | loss: 0.0851909\n",
      "\tspeed: 0.2109s/iter; left time: 2088.3015s\n",
      "\titers: 3800, epoch: 18 | loss: 0.0555599\n",
      "\tspeed: 0.2112s/iter; left time: 2070.1878s\n",
      "\titers: 3900, epoch: 18 | loss: 0.0767860\n",
      "\tspeed: 0.2089s/iter; left time: 2026.0258s\n",
      "\titers: 4000, epoch: 18 | loss: 0.0693482\n",
      "\tspeed: 0.2009s/iter; left time: 1928.8345s\n",
      "\titers: 4100, epoch: 18 | loss: 0.0781907\n",
      "\tspeed: 0.2102s/iter; left time: 1997.2952s\n",
      "\titers: 4200, epoch: 18 | loss: 0.1100252\n",
      "\tspeed: 0.2051s/iter; left time: 1928.0051s\n",
      "\titers: 4300, epoch: 18 | loss: 0.0990154\n",
      "\tspeed: 0.2101s/iter; left time: 1953.7715s\n",
      "\titers: 4400, epoch: 18 | loss: 0.0885110\n",
      "\tspeed: 0.2044s/iter; left time: 1880.2665s\n",
      "\titers: 4500, epoch: 18 | loss: 0.0706306\n",
      "\tspeed: 0.2129s/iter; left time: 1937.6158s\n",
      "Epoch: 18 cost time: 00h:15m:36.12s\n",
      "Epoch: 18 | Train Loss: 0.0809277 Vali Loss: 0.0905383 Test Loss: 0.0940927\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0678311\n",
      "\tspeed: 2.8291s/iter; left time: 25368.0979s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636820\n",
      "\tspeed: 0.2058s/iter; left time: 1824.5938s\n",
      "\titers: 300, epoch: 19 | loss: 0.0705757\n",
      "\tspeed: 0.2093s/iter; left time: 1835.0891s\n",
      "\titers: 400, epoch: 19 | loss: 0.0886685\n",
      "\tspeed: 0.2105s/iter; left time: 1824.3555s\n",
      "\titers: 500, epoch: 19 | loss: 0.0733912\n",
      "\tspeed: 0.2157s/iter; left time: 1848.0562s\n",
      "\titers: 600, epoch: 19 | loss: 0.0603996\n",
      "\tspeed: 0.2040s/iter; left time: 1727.0098s\n",
      "\titers: 700, epoch: 19 | loss: 0.0834332\n",
      "\tspeed: 0.2028s/iter; left time: 1696.4689s\n",
      "\titers: 800, epoch: 19 | loss: 0.0668500\n",
      "\tspeed: 0.2047s/iter; left time: 1692.3785s\n",
      "\titers: 900, epoch: 19 | loss: 0.0698706\n",
      "\tspeed: 0.1954s/iter; left time: 1595.6778s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0701428\n",
      "\tspeed: 0.2040s/iter; left time: 1646.0556s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0967482\n",
      "\tspeed: 0.2234s/iter; left time: 1779.9832s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0881656\n",
      "\tspeed: 0.2114s/iter; left time: 1663.1216s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0794173\n",
      "\tspeed: 0.2035s/iter; left time: 1580.4837s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0853789\n",
      "\tspeed: 0.1992s/iter; left time: 1527.6462s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0708005\n",
      "\tspeed: 0.2021s/iter; left time: 1529.4352s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0919588\n",
      "\tspeed: 0.2018s/iter; left time: 1506.5494s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0928475\n",
      "\tspeed: 0.2037s/iter; left time: 1500.9408s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0829979\n",
      "\tspeed: 0.1955s/iter; left time: 1420.5680s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0985053\n",
      "\tspeed: 0.2010s/iter; left time: 1440.8036s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0800848\n",
      "\tspeed: 0.2002s/iter; left time: 1415.0442s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0809004\n",
      "\tspeed: 0.2015s/iter; left time: 1403.9233s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0806112\n",
      "\tspeed: 0.2001s/iter; left time: 1373.9345s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0761665\n",
      "\tspeed: 0.1971s/iter; left time: 1333.7263s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0870542\n",
      "\tspeed: 0.1988s/iter; left time: 1325.3090s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0851789\n",
      "\tspeed: 0.2069s/iter; left time: 1358.4801s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0812989\n",
      "\tspeed: 0.2059s/iter; left time: 1331.5937s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0844561\n",
      "\tspeed: 0.2068s/iter; left time: 1316.6312s\n",
      "\titers: 2800, epoch: 19 | loss: 0.0822394\n",
      "\tspeed: 0.2086s/iter; left time: 1307.5242s\n",
      "\titers: 2900, epoch: 19 | loss: 0.0910384\n",
      "\tspeed: 0.2064s/iter; left time: 1273.0267s\n",
      "\titers: 3000, epoch: 19 | loss: 0.0712404\n",
      "\tspeed: 0.2090s/iter; left time: 1268.2191s\n",
      "\titers: 3100, epoch: 19 | loss: 0.0772290\n",
      "\tspeed: 0.2059s/iter; left time: 1228.7986s\n",
      "\titers: 3200, epoch: 19 | loss: 0.0868724\n",
      "\tspeed: 0.2016s/iter; left time: 1183.0231s\n",
      "\titers: 3300, epoch: 19 | loss: 0.0636199\n",
      "\tspeed: 0.2023s/iter; left time: 1166.9013s\n",
      "\titers: 3400, epoch: 19 | loss: 0.0758771\n",
      "\tspeed: 0.2002s/iter; left time: 1134.6117s\n",
      "\titers: 3500, epoch: 19 | loss: 0.1098609\n",
      "\tspeed: 0.1993s/iter; left time: 1109.3235s\n",
      "\titers: 3600, epoch: 19 | loss: 0.0684652\n",
      "\tspeed: 0.2043s/iter; left time: 1116.8297s\n",
      "\titers: 3700, epoch: 19 | loss: 0.0755343\n",
      "\tspeed: 0.2024s/iter; left time: 1086.2647s\n",
      "\titers: 3800, epoch: 19 | loss: 0.0831554\n",
      "\tspeed: 0.2001s/iter; left time: 1053.8952s\n",
      "\titers: 3900, epoch: 19 | loss: 0.0682368\n",
      "\tspeed: 0.2000s/iter; left time: 1033.4583s\n",
      "\titers: 4000, epoch: 19 | loss: 0.0710025\n",
      "\tspeed: 0.2007s/iter; left time: 1016.7533s\n",
      "\titers: 4100, epoch: 19 | loss: 0.0701880\n",
      "\tspeed: 0.2037s/iter; left time: 1011.6413s\n",
      "\titers: 4200, epoch: 19 | loss: 0.0823526\n",
      "\tspeed: 0.1979s/iter; left time: 963.2654s\n",
      "\titers: 4300, epoch: 19 | loss: 0.0952930\n",
      "\tspeed: 0.2056s/iter; left time: 980.0332s\n",
      "\titers: 4400, epoch: 19 | loss: 0.1095706\n",
      "\tspeed: 0.2009s/iter; left time: 937.5569s\n",
      "\titers: 4500, epoch: 19 | loss: 0.0967065\n",
      "\tspeed: 0.1933s/iter; left time: 882.7541s\n",
      "Epoch: 19 cost time: 00h:15m:23.36s\n",
      "Epoch: 19 | Train Loss: 0.0806650 Vali Loss: 0.0901411 Test Loss: 0.0933280\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0760543\n",
      "\tspeed: 2.8271s/iter; left time: 12535.2177s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744823\n",
      "\tspeed: 0.2029s/iter; left time: 879.1754s\n",
      "\titers: 300, epoch: 20 | loss: 0.0709615\n",
      "\tspeed: 0.2118s/iter; left time: 896.7642s\n",
      "\titers: 400, epoch: 20 | loss: 0.0833951\n",
      "\tspeed: 0.2103s/iter; left time: 869.5154s\n",
      "\titers: 500, epoch: 20 | loss: 0.0606842\n",
      "\tspeed: 0.2085s/iter; left time: 841.1313s\n",
      "\titers: 600, epoch: 20 | loss: 0.0635488\n",
      "\tspeed: 0.2060s/iter; left time: 810.5230s\n",
      "\titers: 700, epoch: 20 | loss: 0.0798145\n",
      "\tspeed: 0.2016s/iter; left time: 772.7893s\n",
      "\titers: 800, epoch: 20 | loss: 0.0853463\n",
      "\tspeed: 0.2062s/iter; left time: 770.1007s\n",
      "\titers: 900, epoch: 20 | loss: 0.0578192\n",
      "\tspeed: 0.2108s/iter; left time: 766.0542s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0921262\n",
      "\tspeed: 0.2064s/iter; left time: 729.3396s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0867362\n",
      "\tspeed: 0.2096s/iter; left time: 719.6436s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0892997\n",
      "\tspeed: 0.2078s/iter; left time: 692.7852s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0832107\n",
      "\tspeed: 0.2015s/iter; left time: 651.5240s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0918721\n",
      "\tspeed: 0.2131s/iter; left time: 667.7509s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0806802\n",
      "\tspeed: 0.2074s/iter; left time: 629.1552s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0931721\n",
      "\tspeed: 0.2089s/iter; left time: 612.9422s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0625069\n",
      "\tspeed: 0.2089s/iter; left time: 591.9393s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0801823\n",
      "\tspeed: 0.2081s/iter; left time: 569.0584s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0904002\n",
      "\tspeed: 0.2047s/iter; left time: 539.2312s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0669209\n",
      "\tspeed: 0.2103s/iter; left time: 532.7918s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0685574\n",
      "\tspeed: 0.2053s/iter; left time: 499.7197s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0820071\n",
      "\tspeed: 0.2023s/iter; left time: 472.0549s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0823876\n",
      "\tspeed: 0.2063s/iter; left time: 460.8569s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0704435\n",
      "\tspeed: 0.2083s/iter; left time: 444.5805s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0991650\n",
      "\tspeed: 0.2052s/iter; left time: 417.3092s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0949979\n",
      "\tspeed: 0.2070s/iter; left time: 400.4148s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0615428\n",
      "\tspeed: 0.2060s/iter; left time: 377.8297s\n",
      "\titers: 2800, epoch: 20 | loss: 0.0940507\n",
      "\tspeed: 0.2083s/iter; left time: 361.1888s\n",
      "\titers: 2900, epoch: 20 | loss: 0.1000341\n",
      "\tspeed: 0.2112s/iter; left time: 345.0975s\n",
      "\titers: 3000, epoch: 20 | loss: 0.0742691\n",
      "\tspeed: 0.2128s/iter; left time: 326.4433s\n",
      "\titers: 3100, epoch: 20 | loss: 0.0858070\n",
      "\tspeed: 0.2054s/iter; left time: 294.5184s\n",
      "\titers: 3200, epoch: 20 | loss: 0.0774105\n",
      "\tspeed: 0.2063s/iter; left time: 275.1544s\n",
      "\titers: 3300, epoch: 20 | loss: 0.0847270\n",
      "\tspeed: 0.2076s/iter; left time: 256.1494s\n",
      "\titers: 3400, epoch: 20 | loss: 0.0793911\n",
      "\tspeed: 0.1992s/iter; left time: 225.9193s\n",
      "\titers: 3500, epoch: 20 | loss: 0.0810547\n",
      "\tspeed: 0.2029s/iter; left time: 209.7782s\n",
      "\titers: 3600, epoch: 20 | loss: 0.0906097\n",
      "\tspeed: 0.1948s/iter; left time: 181.9836s\n",
      "\titers: 3700, epoch: 20 | loss: 0.0921640\n",
      "\tspeed: 0.2034s/iter; left time: 169.6410s\n",
      "\titers: 3800, epoch: 20 | loss: 0.0885331\n",
      "\tspeed: 0.2057s/iter; left time: 150.9737s\n",
      "\titers: 3900, epoch: 20 | loss: 0.0753125\n",
      "\tspeed: 0.2033s/iter; left time: 128.8854s\n",
      "\titers: 4000, epoch: 20 | loss: 0.0635969\n",
      "\tspeed: 0.2251s/iter; left time: 120.2038s\n",
      "\titers: 4100, epoch: 20 | loss: 0.0736005\n",
      "\tspeed: 0.2192s/iter; left time: 95.1326s\n",
      "\titers: 4200, epoch: 20 | loss: 0.0756893\n",
      "\tspeed: 0.2069s/iter; left time: 69.1063s\n",
      "\titers: 4300, epoch: 20 | loss: 0.0709732\n",
      "\tspeed: 0.2072s/iter; left time: 48.4940s\n",
      "\titers: 4400, epoch: 20 | loss: 0.0741631\n",
      "\tspeed: 0.1969s/iter; left time: 26.3822s\n",
      "\titers: 4500, epoch: 20 | loss: 0.0897707\n",
      "\tspeed: 0.2057s/iter; left time: 6.9946s\n",
      "Epoch: 20 cost time: 00h:15m:37.85s\n",
      "Epoch: 20 | Train Loss: 0.0803315 Vali Loss: 0.0891302 Test Loss: 0.0921191\n",
      "Validation loss decreased (0.090040 --> 0.089130).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.022726772353053093, rmse:0.15075401961803436, mae:0.09211910516023636, rse:0.5324346423149109\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 24: 04h:22m:42.83s\n",
      "\n",
      "Intermediate time for DE: 04h:22m:42.83s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 05:21:21,820] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 05:21:22,942] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 05:21:24,017] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 05:21:24,021] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 05:21:24,388] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,519] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,521] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 05:21:24,687] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.34 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 05:21:24,689] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1c6d0db6d0>\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1546985\n",
      "\tspeed: 0.2596s/iter; left time: 23513.6039s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291576\n",
      "\tspeed: 0.2112s/iter; left time: 19107.4209s\n",
      "\titers: 300, epoch: 1 | loss: 0.1251203\n",
      "\tspeed: 0.2173s/iter; left time: 19632.7933s\n",
      "\titers: 400, epoch: 1 | loss: 0.1450771\n",
      "\tspeed: 0.2129s/iter; left time: 19217.7231s\n",
      "\titers: 500, epoch: 1 | loss: 0.1154369\n",
      "\tspeed: 0.2128s/iter; left time: 19190.4734s\n",
      "\titers: 600, epoch: 1 | loss: 0.1156310\n",
      "\tspeed: 0.2168s/iter; left time: 19521.3204s\n",
      "\titers: 700, epoch: 1 | loss: 0.0748791\n",
      "\tspeed: 0.2180s/iter; left time: 19609.8554s\n",
      "\titers: 800, epoch: 1 | loss: 0.0951292\n",
      "\tspeed: 0.2105s/iter; left time: 18911.7193s\n",
      "\titers: 900, epoch: 1 | loss: 0.0913136\n",
      "\tspeed: 0.2157s/iter; left time: 19357.6229s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0939970\n",
      "\tspeed: 0.2104s/iter; left time: 18864.9255s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1140969\n",
      "\tspeed: 0.2136s/iter; left time: 19126.0187s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1022235\n",
      "\tspeed: 0.2160s/iter; left time: 19323.3010s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1111957\n",
      "\tspeed: 0.2104s/iter; left time: 18797.3674s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0884303\n",
      "\tspeed: 0.2082s/iter; left time: 18584.9150s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0778883\n",
      "\tspeed: 0.2110s/iter; left time: 18815.6921s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0953508\n",
      "\tspeed: 0.2122s/iter; left time: 18902.2907s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0806738\n",
      "\tspeed: 0.2096s/iter; left time: 18649.7251s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1003466\n",
      "\tspeed: 0.2133s/iter; left time: 18957.9592s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0863623\n",
      "\tspeed: 0.2215s/iter; left time: 19663.8832s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0829440\n",
      "\tspeed: 0.2146s/iter; left time: 19030.7614s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0841652\n",
      "\tspeed: 0.2099s/iter; left time: 18588.2588s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0827532\n",
      "\tspeed: 0.2146s/iter; left time: 18983.2339s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0860752\n",
      "\tspeed: 0.2138s/iter; left time: 18892.4743s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0947314\n",
      "\tspeed: 0.2123s/iter; left time: 18736.8141s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1185496\n",
      "\tspeed: 0.2159s/iter; left time: 19031.1048s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1035847\n",
      "\tspeed: 0.2222s/iter; left time: 19568.5601s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0843291\n",
      "\tspeed: 0.2135s/iter; left time: 18775.7073s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0796181\n",
      "\tspeed: 0.2109s/iter; left time: 18527.3093s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1128176\n",
      "\tspeed: 0.2083s/iter; left time: 18277.6396s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0965046\n",
      "\tspeed: 0.2138s/iter; left time: 18740.1358s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0985267\n",
      "\tspeed: 0.2158s/iter; left time: 18898.2363s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0976374\n",
      "\tspeed: 0.2127s/iter; left time: 18603.3204s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1047641\n",
      "\tspeed: 0.2155s/iter; left time: 18827.4525s\n",
      "\titers: 3400, epoch: 1 | loss: 0.0967885\n",
      "\tspeed: 0.2118s/iter; left time: 18482.1399s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1069563\n",
      "\tspeed: 0.2097s/iter; left time: 18277.4770s\n",
      "\titers: 3600, epoch: 1 | loss: 0.0921024\n",
      "\tspeed: 0.2117s/iter; left time: 18433.2546s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0950448\n",
      "\tspeed: 0.2166s/iter; left time: 18838.3472s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0770328\n",
      "\tspeed: 0.2239s/iter; left time: 19444.9302s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0866609\n",
      "\tspeed: 0.2177s/iter; left time: 18888.8326s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1140960\n",
      "\tspeed: 0.2150s/iter; left time: 18634.6285s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0745960\n",
      "\tspeed: 0.2126s/iter; left time: 18403.7787s\n",
      "\titers: 4200, epoch: 1 | loss: 0.0948094\n",
      "\tspeed: 0.2160s/iter; left time: 18672.9990s\n",
      "\titers: 4300, epoch: 1 | loss: 0.0925089\n",
      "\tspeed: 0.2164s/iter; left time: 18690.5643s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0839602\n",
      "\tspeed: 0.2203s/iter; left time: 19001.7579s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0861143\n",
      "\tspeed: 0.2183s/iter; left time: 18808.0370s\n",
      "Epoch: 1 cost time: 00h:16m:12.46s\n",
      "Epoch: 1 | Train Loss: 0.1012164 Vali Loss: 0.0977652 Test Loss: 0.1118243\n",
      "Validation loss decreased (inf --> 0.097765).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0937784\n",
      "\tspeed: 3.1437s/iter; left time: 270449.9509s\n",
      "\titers: 200, epoch: 2 | loss: 0.0925049\n",
      "\tspeed: 0.2042s/iter; left time: 17547.8746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0792080\n",
      "\tspeed: 0.2054s/iter; left time: 17633.3070s\n",
      "\titers: 400, epoch: 2 | loss: 0.1067672\n",
      "\tspeed: 0.2102s/iter; left time: 18020.7759s\n",
      "\titers: 500, epoch: 2 | loss: 0.0805422\n",
      "\tspeed: 0.2076s/iter; left time: 17778.1836s\n",
      "\titers: 600, epoch: 2 | loss: 0.0674901\n",
      "\tspeed: 0.2049s/iter; left time: 17528.9570s\n",
      "\titers: 700, epoch: 2 | loss: 0.0926194\n",
      "\tspeed: 0.2104s/iter; left time: 17970.9439s\n",
      "\titers: 800, epoch: 2 | loss: 0.0842856\n",
      "\tspeed: 0.2088s/iter; left time: 17813.8312s\n",
      "\titers: 900, epoch: 2 | loss: 0.0672636\n",
      "\tspeed: 0.2050s/iter; left time: 17472.1212s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0877642\n",
      "\tspeed: 0.2079s/iter; left time: 17694.7509s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0978035\n",
      "\tspeed: 0.2097s/iter; left time: 17826.8112s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0698678\n",
      "\tspeed: 0.2059s/iter; left time: 17486.0444s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0882811\n",
      "\tspeed: 0.2050s/iter; left time: 17385.9232s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0911639\n",
      "\tspeed: 0.2088s/iter; left time: 17693.4504s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0743035\n",
      "\tspeed: 0.2045s/iter; left time: 17307.9439s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0864886\n",
      "\tspeed: 0.2051s/iter; left time: 17340.5950s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0971036\n",
      "\tspeed: 0.2081s/iter; left time: 17567.2209s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0993157\n",
      "\tspeed: 0.2041s/iter; left time: 17213.8291s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0668235\n",
      "\tspeed: 0.2090s/iter; left time: 17605.6554s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0908750\n",
      "\tspeed: 0.2090s/iter; left time: 17586.0225s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0931186\n",
      "\tspeed: 0.2036s/iter; left time: 17108.0480s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0834960\n",
      "\tspeed: 0.2127s/iter; left time: 17851.3031s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0740703\n",
      "\tspeed: 0.2062s/iter; left time: 17287.2931s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0833978\n",
      "\tspeed: 0.2071s/iter; left time: 17342.7146s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0961250\n",
      "\tspeed: 0.2071s/iter; left time: 17319.5875s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1048870\n",
      "\tspeed: 0.2068s/iter; left time: 17277.2299s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0799315\n",
      "\tspeed: 0.2021s/iter; left time: 16862.5321s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0876554\n",
      "\tspeed: 0.1995s/iter; left time: 16628.0431s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0985768\n",
      "\tspeed: 0.1961s/iter; left time: 16319.7431s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0851371\n",
      "\tspeed: 0.2087s/iter; left time: 17348.0643s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0835325\n",
      "\tspeed: 0.2039s/iter; left time: 16929.3412s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0846814\n",
      "\tspeed: 0.2032s/iter; left time: 16853.4020s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1017231\n",
      "\tspeed: 0.2067s/iter; left time: 17116.8465s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0944130\n",
      "\tspeed: 0.2054s/iter; left time: 16990.1746s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0778886\n",
      "\tspeed: 0.2026s/iter; left time: 16744.3527s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0969510\n",
      "\tspeed: 0.2104s/iter; left time: 17361.0954s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1037317\n",
      "\tspeed: 0.2130s/iter; left time: 17557.4597s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0846262\n",
      "\tspeed: 0.2078s/iter; left time: 17110.1884s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0849839\n",
      "\tspeed: 0.2077s/iter; left time: 17077.5685s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0747749\n",
      "\tspeed: 0.2093s/iter; left time: 17192.3186s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0879758\n",
      "\tspeed: 0.2073s/iter; left time: 17001.2923s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0780901\n",
      "\tspeed: 0.2062s/iter; left time: 16897.2507s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0768861\n",
      "\tspeed: 0.2032s/iter; left time: 16626.1937s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0925877\n",
      "\tspeed: 0.2075s/iter; left time: 16959.7075s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1027337\n",
      "\tspeed: 0.2075s/iter; left time: 16938.6186s\n",
      "Epoch: 2 cost time: 00h:15m:36.14s\n",
      "Epoch: 2 | Train Loss: 0.0897730 Vali Loss: 0.0947562 Test Loss: 0.1064046\n",
      "Validation loss decreased (0.097765 --> 0.094756).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0810658\n",
      "\tspeed: 2.8829s/iter; left time: 234943.0725s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800776\n",
      "\tspeed: 0.2065s/iter; left time: 16808.2880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0864822\n",
      "\tspeed: 0.2107s/iter; left time: 17130.5311s\n",
      "\titers: 400, epoch: 3 | loss: 0.0833262\n",
      "\tspeed: 0.2081s/iter; left time: 16896.7296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1016066\n",
      "\tspeed: 0.2066s/iter; left time: 16751.8452s\n",
      "\titers: 600, epoch: 3 | loss: 0.0743249\n",
      "\tspeed: 0.2081s/iter; left time: 16856.4713s\n",
      "\titers: 700, epoch: 3 | loss: 0.0947935\n",
      "\tspeed: 0.2041s/iter; left time: 16506.9052s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972273\n",
      "\tspeed: 0.2015s/iter; left time: 16283.4889s\n",
      "\titers: 900, epoch: 3 | loss: 0.0753759\n",
      "\tspeed: 0.2080s/iter; left time: 16783.1574s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0977198\n",
      "\tspeed: 0.2078s/iter; left time: 16749.1853s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0708147\n",
      "\tspeed: 0.2123s/iter; left time: 17085.5556s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1041960\n",
      "\tspeed: 0.2047s/iter; left time: 16458.2318s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0813768\n",
      "\tspeed: 0.2037s/iter; left time: 16358.0012s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0833640\n",
      "\tspeed: 0.2057s/iter; left time: 16498.0856s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0912660\n",
      "\tspeed: 0.2052s/iter; left time: 16432.8780s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0964458\n",
      "\tspeed: 0.2025s/iter; left time: 16197.2866s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0746260\n",
      "\tspeed: 0.2082s/iter; left time: 16634.3750s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0821514\n",
      "\tspeed: 0.2079s/iter; left time: 16586.5981s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0930947\n",
      "\tspeed: 0.2083s/iter; left time: 16600.2893s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0983000\n",
      "\tspeed: 0.2039s/iter; left time: 16232.1842s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0888522\n",
      "\tspeed: 0.2121s/iter; left time: 16863.4827s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0999592\n",
      "\tspeed: 0.2072s/iter; left time: 16453.4128s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0848825\n",
      "\tspeed: 0.2047s/iter; left time: 16235.5531s\n",
      "\titers: 2400, epoch: 3 | loss: 0.1003277\n",
      "\tspeed: 0.2079s/iter; left time: 16462.0069s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1023490\n",
      "\tspeed: 0.2165s/iter; left time: 17123.3664s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0994273\n",
      "\tspeed: 0.2198s/iter; left time: 17363.5078s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0884067\n",
      "\tspeed: 0.2086s/iter; left time: 16458.3750s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0817370\n",
      "\tspeed: 0.2113s/iter; left time: 16647.8347s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0865126\n",
      "\tspeed: 0.2073s/iter; left time: 16310.8194s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0781461\n",
      "\tspeed: 0.2094s/iter; left time: 16456.1587s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0961022\n",
      "\tspeed: 0.2073s/iter; left time: 16273.9645s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0833025\n",
      "\tspeed: 0.2039s/iter; left time: 15981.1719s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0868474\n",
      "\tspeed: 0.2071s/iter; left time: 16213.4939s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0948126\n",
      "\tspeed: 0.2097s/iter; left time: 16401.3564s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0747255\n",
      "\tspeed: 0.2048s/iter; left time: 15990.0912s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0783070\n",
      "\tspeed: 0.2028s/iter; left time: 15816.6193s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0824283\n",
      "\tspeed: 0.2073s/iter; left time: 16144.4528s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0840960\n",
      "\tspeed: 0.2041s/iter; left time: 15874.1738s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0793464\n",
      "\tspeed: 0.2061s/iter; left time: 16015.1940s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1106913\n",
      "\tspeed: 0.2043s/iter; left time: 15850.1320s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0804906\n",
      "\tspeed: 0.2063s/iter; left time: 15985.3942s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0840885\n",
      "\tspeed: 0.2087s/iter; left time: 16150.6999s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0973125\n",
      "\tspeed: 0.2041s/iter; left time: 15777.5095s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956219\n",
      "\tspeed: 0.2078s/iter; left time: 16043.9459s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0949254\n",
      "\tspeed: 0.2013s/iter; left time: 15521.4229s\n",
      "Epoch: 3 cost time: 00h:15m:39.38s\n",
      "Epoch: 3 | Train Loss: 0.0880390 Vali Loss: 0.0942308 Test Loss: 0.1069798\n",
      "Validation loss decreased (0.094756 --> 0.094231).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0629435\n",
      "\tspeed: 2.8681s/iter; left time: 220738.1901s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817626\n",
      "\tspeed: 0.2044s/iter; left time: 15713.9321s\n",
      "\titers: 300, epoch: 4 | loss: 0.0863294\n",
      "\tspeed: 0.2145s/iter; left time: 16465.9000s\n",
      "\titers: 400, epoch: 4 | loss: 0.0795554\n",
      "\tspeed: 0.2070s/iter; left time: 15868.4153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0831481\n",
      "\tspeed: 0.2064s/iter; left time: 15801.3037s\n",
      "\titers: 600, epoch: 4 | loss: 0.0922075\n",
      "\tspeed: 0.2068s/iter; left time: 15816.1630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0939702\n",
      "\tspeed: 0.2019s/iter; left time: 15420.2685s\n",
      "\titers: 800, epoch: 4 | loss: 0.1038905\n",
      "\tspeed: 0.2087s/iter; left time: 15914.4344s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906302\n",
      "\tspeed: 0.2063s/iter; left time: 15711.4453s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0878862\n",
      "\tspeed: 0.2116s/iter; left time: 16091.3031s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0860731\n",
      "\tspeed: 0.2078s/iter; left time: 15782.9574s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0774423\n",
      "\tspeed: 0.2087s/iter; left time: 15832.6079s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0769600\n",
      "\tspeed: 0.2072s/iter; left time: 15698.5154s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0720468\n",
      "\tspeed: 0.2087s/iter; left time: 15787.4081s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0859341\n",
      "\tspeed: 0.2079s/iter; left time: 15709.5172s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0894901\n",
      "\tspeed: 0.2063s/iter; left time: 15567.5086s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0890460\n",
      "\tspeed: 0.2056s/iter; left time: 15493.3883s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1076474\n",
      "\tspeed: 0.2044s/iter; left time: 15383.1545s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0765705\n",
      "\tspeed: 0.2093s/iter; left time: 15734.6450s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0851438\n",
      "\tspeed: 0.2086s/iter; left time: 15660.6367s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1141284\n",
      "\tspeed: 0.2090s/iter; left time: 15670.2835s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0862813\n",
      "\tspeed: 0.2055s/iter; left time: 15385.4751s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1139401\n",
      "\tspeed: 0.2002s/iter; left time: 14967.7757s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0752189\n",
      "\tspeed: 0.2099s/iter; left time: 15672.1886s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0758349\n",
      "\tspeed: 0.2134s/iter; left time: 15911.7240s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0949885\n",
      "\tspeed: 0.2142s/iter; left time: 15951.0429s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0871932\n",
      "\tspeed: 0.2085s/iter; left time: 15504.4323s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0932991\n",
      "\tspeed: 0.2045s/iter; left time: 15185.7253s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0893083\n",
      "\tspeed: 0.2119s/iter; left time: 15716.6822s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0879167\n",
      "\tspeed: 0.2083s/iter; left time: 15425.7544s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1030891\n",
      "\tspeed: 0.2106s/iter; left time: 15574.3678s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0765157\n",
      "\tspeed: 0.2074s/iter; left time: 15321.3984s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0882305\n",
      "\tspeed: 0.2110s/iter; left time: 15561.7669s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0930053\n",
      "\tspeed: 0.2085s/iter; left time: 15356.6312s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0871002\n",
      "\tspeed: 0.2130s/iter; left time: 15666.8357s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0690684\n",
      "\tspeed: 0.2110s/iter; left time: 15499.5806s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0998551\n",
      "\tspeed: 0.2034s/iter; left time: 14924.0017s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0960040\n",
      "\tspeed: 0.2043s/iter; left time: 14964.2663s\n",
      "\titers: 3900, epoch: 4 | loss: 0.1019153\n",
      "\tspeed: 0.2079s/iter; left time: 15210.7189s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0860887\n",
      "\tspeed: 0.2067s/iter; left time: 15099.5227s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0949487\n",
      "\tspeed: 0.2011s/iter; left time: 14671.3155s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1033828\n",
      "\tspeed: 0.2100s/iter; left time: 15298.9955s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0717965\n",
      "\tspeed: 0.2068s/iter; left time: 15044.0467s\n",
      "\titers: 4400, epoch: 4 | loss: 0.0878067\n",
      "\tspeed: 0.2067s/iter; left time: 15017.9687s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0918676\n",
      "\tspeed: 0.2032s/iter; left time: 14743.3131s\n",
      "Epoch: 4 cost time: 00h:15m:42.27s\n",
      "Epoch: 4 | Train Loss: 0.0868472 Vali Loss: 0.0933003 Test Loss: 0.1048385\n",
      "Validation loss decreased (0.094231 --> 0.093300).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0741384\n",
      "\tspeed: 3.0208s/iter; left time: 218794.2469s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076432\n",
      "\tspeed: 0.2059s/iter; left time: 14893.4791s\n",
      "\titers: 300, epoch: 5 | loss: 0.0760020\n",
      "\tspeed: 0.2065s/iter; left time: 14913.9063s\n",
      "\titers: 400, epoch: 5 | loss: 0.0853055\n",
      "\tspeed: 0.2079s/iter; left time: 14992.0139s\n",
      "\titers: 500, epoch: 5 | loss: 0.0548117\n",
      "\tspeed: 0.2100s/iter; left time: 15126.9888s\n",
      "\titers: 600, epoch: 5 | loss: 0.1007220\n",
      "\tspeed: 0.2071s/iter; left time: 14897.5417s\n",
      "\titers: 700, epoch: 5 | loss: 0.0747483\n",
      "\tspeed: 0.2058s/iter; left time: 14781.0316s\n",
      "\titers: 800, epoch: 5 | loss: 0.0905776\n",
      "\tspeed: 0.2094s/iter; left time: 15017.5738s\n",
      "\titers: 900, epoch: 5 | loss: 0.0860225\n",
      "\tspeed: 0.2055s/iter; left time: 14716.4011s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0738990\n",
      "\tspeed: 0.2039s/iter; left time: 14583.4945s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0933961\n",
      "\tspeed: 0.2038s/iter; left time: 14554.6116s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0883273\n",
      "\tspeed: 0.2103s/iter; left time: 14997.0152s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0698245\n",
      "\tspeed: 0.2066s/iter; left time: 14718.0606s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0771358\n",
      "\tspeed: 0.2088s/iter; left time: 14850.0622s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0988944\n",
      "\tspeed: 0.2052s/iter; left time: 14575.3074s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0769319\n",
      "\tspeed: 0.2078s/iter; left time: 14737.6505s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0906119\n",
      "\tspeed: 0.2100s/iter; left time: 14871.9827s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0767788\n",
      "\tspeed: 0.2077s/iter; left time: 14689.9590s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0871070\n",
      "\tspeed: 0.2076s/iter; left time: 14661.8704s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0943331\n",
      "\tspeed: 0.2070s/iter; left time: 14601.3388s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0935991\n",
      "\tspeed: 0.2056s/iter; left time: 14480.3503s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0794097\n",
      "\tspeed: 0.2056s/iter; left time: 14457.5957s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0865870\n",
      "\tspeed: 0.2038s/iter; left time: 14312.2838s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0800633\n",
      "\tspeed: 0.2057s/iter; left time: 14423.5427s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1094643\n",
      "\tspeed: 0.2040s/iter; left time: 14288.6274s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0919437\n",
      "\tspeed: 0.2071s/iter; left time: 14480.3289s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0853646\n",
      "\tspeed: 0.2092s/iter; left time: 14610.1158s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0692050\n",
      "\tspeed: 0.2061s/iter; left time: 14367.8777s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0830063\n",
      "\tspeed: 0.2056s/iter; left time: 14314.8213s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0872543\n",
      "\tspeed: 0.2085s/iter; left time: 14500.0672s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0803247\n",
      "\tspeed: 0.2118s/iter; left time: 14707.0644s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0736554\n",
      "\tspeed: 0.2069s/iter; left time: 14344.9226s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0921012\n",
      "\tspeed: 0.2056s/iter; left time: 14236.4392s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0835762\n",
      "\tspeed: 0.2044s/iter; left time: 14128.3308s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0950097\n",
      "\tspeed: 0.2093s/iter; left time: 14449.9958s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1110827\n",
      "\tspeed: 0.2088s/iter; left time: 14389.0822s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0821992\n",
      "\tspeed: 0.2090s/iter; left time: 14387.8506s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0676025\n",
      "\tspeed: 0.2057s/iter; left time: 14135.6071s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0814962\n",
      "\tspeed: 0.2069s/iter; left time: 14197.1448s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0887165\n",
      "\tspeed: 0.2081s/iter; left time: 14257.5858s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0728875\n",
      "\tspeed: 0.2102s/iter; left time: 14382.3587s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0656401\n",
      "\tspeed: 0.2015s/iter; left time: 13771.1031s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0732421\n",
      "\tspeed: 0.1986s/iter; left time: 13551.3038s\n",
      "\titers: 4400, epoch: 5 | loss: 0.0835454\n",
      "\tspeed: 0.2059s/iter; left time: 14024.9159s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0843670\n",
      "\tspeed: 0.2040s/iter; left time: 13876.0773s\n",
      "Epoch: 5 cost time: 00h:15m:37.22s\n",
      "Epoch: 5 | Train Loss: 0.0859530 Vali Loss: 0.0931037 Test Loss: 0.1048710\n",
      "Validation loss decreased (0.093300 --> 0.093104).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0801860\n",
      "\tspeed: 2.8737s/iter; left time: 195111.3389s\n",
      "\titers: 200, epoch: 6 | loss: 0.1101087\n",
      "\tspeed: 0.1975s/iter; left time: 13390.7818s\n",
      "\titers: 300, epoch: 6 | loss: 0.0762284\n",
      "\tspeed: 0.2055s/iter; left time: 13913.0098s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788697\n",
      "\tspeed: 0.2142s/iter; left time: 14480.3936s\n",
      "\titers: 500, epoch: 6 | loss: 0.0804758\n",
      "\tspeed: 0.2040s/iter; left time: 13770.7405s\n",
      "\titers: 600, epoch: 6 | loss: 0.0990776\n",
      "\tspeed: 0.2051s/iter; left time: 13825.7709s\n",
      "\titers: 700, epoch: 6 | loss: 0.0806546\n",
      "\tspeed: 0.2084s/iter; left time: 14025.7677s\n",
      "\titers: 800, epoch: 6 | loss: 0.0906101\n",
      "\tspeed: 0.2085s/iter; left time: 14007.3173s\n",
      "\titers: 900, epoch: 6 | loss: 0.0941866\n",
      "\tspeed: 0.2097s/iter; left time: 14069.0933s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0684057\n",
      "\tspeed: 0.2112s/iter; left time: 14152.7443s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0810384\n",
      "\tspeed: 0.2071s/iter; left time: 13851.6608s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0821972\n",
      "\tspeed: 0.2061s/iter; left time: 13764.2379s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0927051\n",
      "\tspeed: 0.2051s/iter; left time: 13676.7886s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0708853\n",
      "\tspeed: 0.2095s/iter; left time: 13951.3347s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0932269\n",
      "\tspeed: 0.2032s/iter; left time: 13511.2427s\n",
      "\titers: 1600, epoch: 6 | loss: 0.1037990\n",
      "\tspeed: 0.2132s/iter; left time: 14155.8141s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0954990\n",
      "\tspeed: 0.2113s/iter; left time: 14009.8887s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0848894\n",
      "\tspeed: 0.2128s/iter; left time: 14089.0052s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0855536\n",
      "\tspeed: 0.2159s/iter; left time: 14269.0809s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0943525\n",
      "\tspeed: 0.2289s/iter; left time: 15105.8938s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0667500\n",
      "\tspeed: 0.2082s/iter; left time: 13720.9368s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0840006\n",
      "\tspeed: 0.2030s/iter; left time: 13353.5205s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0643740\n",
      "\tspeed: 0.2079s/iter; left time: 13655.4606s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0742748\n",
      "\tspeed: 0.2097s/iter; left time: 13754.3743s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0909706\n",
      "\tspeed: 0.2064s/iter; left time: 13519.7340s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0844907\n",
      "\tspeed: 0.2115s/iter; left time: 13830.4778s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0878555\n",
      "\tspeed: 0.1953s/iter; left time: 12752.9357s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0970411\n",
      "\tspeed: 0.2000s/iter; left time: 13036.8062s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0734473\n",
      "\tspeed: 0.2022s/iter; left time: 13159.1833s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0836401\n",
      "\tspeed: 0.2024s/iter; left time: 13153.1787s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0964884\n",
      "\tspeed: 0.1983s/iter; left time: 12871.5985s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0760528\n",
      "\tspeed: 0.2089s/iter; left time: 13534.0938s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0759267\n",
      "\tspeed: 0.2076s/iter; left time: 13433.2749s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0775311\n",
      "\tspeed: 0.2033s/iter; left time: 13135.2763s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1126537\n",
      "\tspeed: 0.1980s/iter; left time: 12767.3191s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0685594\n",
      "\tspeed: 0.1995s/iter; left time: 12847.3320s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0926302\n",
      "\tspeed: 0.2017s/iter; left time: 12968.6101s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0759674\n",
      "\tspeed: 0.1989s/iter; left time: 12770.8511s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0886815\n",
      "\tspeed: 0.1997s/iter; left time: 12797.5558s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0981110\n",
      "\tspeed: 0.1990s/iter; left time: 12736.9493s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0808471\n",
      "\tspeed: 0.1954s/iter; left time: 12486.0146s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0831465\n",
      "\tspeed: 0.2033s/iter; left time: 12967.4624s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0743688\n",
      "\tspeed: 0.2068s/iter; left time: 13171.3811s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0812875\n",
      "\tspeed: 0.2004s/iter; left time: 12742.0970s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0805463\n",
      "\tspeed: 0.2080s/iter; left time: 13204.2397s\n",
      "Epoch: 6 cost time: 00h:15m:32.46s\n",
      "Epoch: 6 | Train Loss: 0.0852381 Vali Loss: 0.0928212 Test Loss: 0.1050314\n",
      "Validation loss decreased (0.093104 --> 0.092821).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.1047151\n",
      "\tspeed: 2.8811s/iter; left time: 182552.0419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953454\n",
      "\tspeed: 0.2083s/iter; left time: 13176.4326s\n",
      "\titers: 300, epoch: 7 | loss: 0.0660141\n",
      "\tspeed: 0.2037s/iter; left time: 12863.9467s\n",
      "\titers: 400, epoch: 7 | loss: 0.0820844\n",
      "\tspeed: 0.2087s/iter; left time: 13160.8212s\n",
      "\titers: 500, epoch: 7 | loss: 0.0738224\n",
      "\tspeed: 0.2077s/iter; left time: 13078.4402s\n",
      "\titers: 600, epoch: 7 | loss: 0.0880774\n",
      "\tspeed: 0.2033s/iter; left time: 12777.8105s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794524\n",
      "\tspeed: 0.2063s/iter; left time: 12948.4159s\n",
      "\titers: 800, epoch: 7 | loss: 0.0785445\n",
      "\tspeed: 0.2057s/iter; left time: 12888.7997s\n",
      "\titers: 900, epoch: 7 | loss: 0.0827400\n",
      "\tspeed: 0.2071s/iter; left time: 12957.8705s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0876613\n",
      "\tspeed: 0.2084s/iter; left time: 13015.7919s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0604013\n",
      "\tspeed: 0.2037s/iter; left time: 12701.1737s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0944318\n",
      "\tspeed: 0.2066s/iter; left time: 12864.6877s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0725799\n",
      "\tspeed: 0.2003s/iter; left time: 12452.0728s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0708223\n",
      "\tspeed: 0.1944s/iter; left time: 12067.4824s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0984242\n",
      "\tspeed: 0.1997s/iter; left time: 12371.3325s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0892823\n",
      "\tspeed: 0.2068s/iter; left time: 12790.8313s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0822393\n",
      "\tspeed: 0.2038s/iter; left time: 12587.3085s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0994398\n",
      "\tspeed: 0.2089s/iter; left time: 12881.3839s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0783563\n",
      "\tspeed: 0.2128s/iter; left time: 13102.9007s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0797199\n",
      "\tspeed: 0.2112s/iter; left time: 12980.4427s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0682478\n",
      "\tspeed: 0.2055s/iter; left time: 12611.0825s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0854917\n",
      "\tspeed: 0.2112s/iter; left time: 12936.7978s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0815612\n",
      "\tspeed: 0.2117s/iter; left time: 12947.0108s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0776256\n",
      "\tspeed: 0.2068s/iter; left time: 12625.8607s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0890070\n",
      "\tspeed: 0.2126s/iter; left time: 12958.3575s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0713369\n",
      "\tspeed: 0.2070s/iter; left time: 12600.4614s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0917580\n",
      "\tspeed: 0.2044s/iter; left time: 12421.1305s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0853298\n",
      "\tspeed: 0.2092s/iter; left time: 12690.9202s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0683254\n",
      "\tspeed: 0.2034s/iter; left time: 12320.2604s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0674208\n",
      "\tspeed: 0.1999s/iter; left time: 12088.0291s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061399\n",
      "\tspeed: 0.2043s/iter; left time: 12332.9736s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0806480\n",
      "\tspeed: 0.2022s/iter; left time: 12185.1757s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0896547\n",
      "\tspeed: 0.2063s/iter; left time: 12412.6946s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0737791\n",
      "\tspeed: 0.2067s/iter; left time: 12416.4516s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0934617\n",
      "\tspeed: 0.2093s/iter; left time: 12551.3680s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0644973\n",
      "\tspeed: 0.2144s/iter; left time: 12835.2340s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0979190\n",
      "\tspeed: 0.2066s/iter; left time: 12344.9806s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0881604\n",
      "\tspeed: 0.2069s/iter; left time: 12342.0743s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0841230\n",
      "\tspeed: 0.2043s/iter; left time: 12169.2925s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0985560\n",
      "\tspeed: 0.2058s/iter; left time: 12239.0234s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0721457\n",
      "\tspeed: 0.2107s/iter; left time: 12506.1717s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0912469\n",
      "\tspeed: 0.2099s/iter; left time: 12441.9679s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0834451\n",
      "\tspeed: 0.2091s/iter; left time: 12371.3268s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0763505\n",
      "\tspeed: 0.2079s/iter; left time: 12282.0368s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0864378\n",
      "\tspeed: 0.2088s/iter; left time: 12311.4423s\n",
      "Epoch: 7 cost time: 00h:15m:37.79s\n",
      "Epoch: 7 | Train Loss: 0.0846115 Vali Loss: 0.0920109 Test Loss: 0.1030820\n",
      "Validation loss decreased (0.092821 --> 0.092011).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0959323\n",
      "\tspeed: 2.9705s/iter; left time: 174757.1464s\n",
      "\titers: 200, epoch: 8 | loss: 0.0614587\n",
      "\tspeed: 0.2147s/iter; left time: 12607.9893s\n",
      "\titers: 300, epoch: 8 | loss: 0.1047958\n",
      "\tspeed: 0.2045s/iter; left time: 11987.6007s\n",
      "\titers: 400, epoch: 8 | loss: 0.0672435\n",
      "\tspeed: 0.2023s/iter; left time: 11837.9279s\n",
      "\titers: 500, epoch: 8 | loss: 0.0932711\n",
      "\tspeed: 0.2015s/iter; left time: 11772.5302s\n",
      "\titers: 600, epoch: 8 | loss: 0.0958791\n",
      "\tspeed: 0.2063s/iter; left time: 12036.3643s\n",
      "\titers: 700, epoch: 8 | loss: 0.0793360\n",
      "\tspeed: 0.2047s/iter; left time: 11918.9334s\n",
      "\titers: 800, epoch: 8 | loss: 0.0753882\n",
      "\tspeed: 0.1990s/iter; left time: 11566.7016s\n",
      "\titers: 900, epoch: 8 | loss: 0.0943302\n",
      "\tspeed: 0.2074s/iter; left time: 12036.4248s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0702697\n",
      "\tspeed: 0.2045s/iter; left time: 11844.1021s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0750135\n",
      "\tspeed: 0.2100s/iter; left time: 12141.6900s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0680853\n",
      "\tspeed: 0.2055s/iter; left time: 11864.1696s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0832931\n",
      "\tspeed: 0.2077s/iter; left time: 11971.1115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0833303\n",
      "\tspeed: 0.2096s/iter; left time: 12056.4310s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0828459\n",
      "\tspeed: 0.2167s/iter; left time: 12445.6579s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0849369\n",
      "\tspeed: 0.2099s/iter; left time: 12033.3152s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0814050\n",
      "\tspeed: 0.2043s/iter; left time: 11690.5031s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0743382\n",
      "\tspeed: 0.2078s/iter; left time: 11869.8021s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0840637\n",
      "\tspeed: 0.2080s/iter; left time: 11859.5128s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0879681\n",
      "\tspeed: 0.2114s/iter; left time: 12035.5906s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0817242\n",
      "\tspeed: 0.2090s/iter; left time: 11875.9685s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0798136\n",
      "\tspeed: 0.2056s/iter; left time: 11662.5593s\n",
      "\titers: 2300, epoch: 8 | loss: 0.1019480\n",
      "\tspeed: 0.2025s/iter; left time: 11468.0164s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0801811\n",
      "\tspeed: 0.2083s/iter; left time: 11772.7732s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0829113\n",
      "\tspeed: 0.2023s/iter; left time: 11413.5219s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0967366\n",
      "\tspeed: 0.2028s/iter; left time: 11424.3856s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0840562\n",
      "\tspeed: 0.2042s/iter; left time: 11480.6080s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0779026\n",
      "\tspeed: 0.2084s/iter; left time: 11697.0390s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0962122\n",
      "\tspeed: 0.2061s/iter; left time: 11548.1397s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0935820\n",
      "\tspeed: 0.2160s/iter; left time: 12081.8666s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0829191\n",
      "\tspeed: 0.2094s/iter; left time: 11690.5081s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0710387\n",
      "\tspeed: 0.2087s/iter; left time: 11630.4804s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0894845\n",
      "\tspeed: 0.2124s/iter; left time: 11817.3435s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0926941\n",
      "\tspeed: 0.2059s/iter; left time: 11433.9536s\n",
      "\titers: 3500, epoch: 8 | loss: 0.1105087\n",
      "\tspeed: 0.1943s/iter; left time: 10767.8637s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0872025\n",
      "\tspeed: 0.2024s/iter; left time: 11197.3750s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0861788\n",
      "\tspeed: 0.2108s/iter; left time: 11643.3364s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0885966\n",
      "\tspeed: 0.2090s/iter; left time: 11521.3090s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0713039\n",
      "\tspeed: 0.2019s/iter; left time: 11109.2651s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0886188\n",
      "\tspeed: 0.2030s/iter; left time: 11148.1414s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0810110\n",
      "\tspeed: 0.2022s/iter; left time: 11085.0714s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0742318\n",
      "\tspeed: 0.1941s/iter; left time: 10622.7644s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0750491\n",
      "\tspeed: 0.2049s/iter; left time: 11196.2452s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0823885\n",
      "\tspeed: 0.2116s/iter; left time: 11540.6292s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0682080\n",
      "\tspeed: 0.2089s/iter; left time: 11371.7167s\n",
      "Epoch: 8 cost time: 00h:15m:36.23s\n",
      "Epoch: 8 | Train Loss: 0.0840220 Vali Loss: 0.0924658 Test Loss: 0.1032606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.1014510\n",
      "\tspeed: 2.8537s/iter; left time: 154947.4982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0732115\n",
      "\tspeed: 0.2032s/iter; left time: 11013.3979s\n",
      "\titers: 300, epoch: 9 | loss: 0.0672111\n",
      "\tspeed: 0.2135s/iter; left time: 11547.5595s\n",
      "\titers: 400, epoch: 9 | loss: 0.0704000\n",
      "\tspeed: 0.2128s/iter; left time: 11491.8370s\n",
      "\titers: 500, epoch: 9 | loss: 0.0818704\n",
      "\tspeed: 0.2048s/iter; left time: 11037.3855s\n",
      "\titers: 600, epoch: 9 | loss: 0.0715541\n",
      "\tspeed: 0.2051s/iter; left time: 11035.8301s\n",
      "\titers: 700, epoch: 9 | loss: 0.1105956\n",
      "\tspeed: 0.2095s/iter; left time: 11250.5845s\n",
      "\titers: 800, epoch: 9 | loss: 0.0845100\n",
      "\tspeed: 0.2104s/iter; left time: 11278.5344s\n",
      "\titers: 900, epoch: 9 | loss: 0.0731403\n",
      "\tspeed: 0.2030s/iter; left time: 10860.9777s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0902069\n",
      "\tspeed: 0.2052s/iter; left time: 10959.6923s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0874258\n",
      "\tspeed: 0.2048s/iter; left time: 10914.0901s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0794950\n",
      "\tspeed: 0.2048s/iter; left time: 10893.1266s\n",
      "\titers: 1300, epoch: 9 | loss: 0.1164204\n",
      "\tspeed: 0.2101s/iter; left time: 11153.6165s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0773649\n",
      "\tspeed: 0.2090s/iter; left time: 11074.0395s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0806947\n",
      "\tspeed: 0.2295s/iter; left time: 12139.5612s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0846206\n",
      "\tspeed: 0.2093s/iter; left time: 11049.5450s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0888354\n",
      "\tspeed: 0.2126s/iter; left time: 11203.2563s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0787957\n",
      "\tspeed: 0.2070s/iter; left time: 10887.3510s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0875736\n",
      "\tspeed: 0.2063s/iter; left time: 10832.7090s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0798719\n",
      "\tspeed: 0.2107s/iter; left time: 11041.0365s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0696464\n",
      "\tspeed: 0.2105s/iter; left time: 11009.0840s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0806052\n",
      "\tspeed: 0.2097s/iter; left time: 10946.9617s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0751054\n",
      "\tspeed: 0.2076s/iter; left time: 10812.9726s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0679254\n",
      "\tspeed: 0.2100s/iter; left time: 10920.0388s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0896055\n",
      "\tspeed: 0.2087s/iter; left time: 10830.7340s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0963080\n",
      "\tspeed: 0.2115s/iter; left time: 10954.3016s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0976607\n",
      "\tspeed: 0.2101s/iter; left time: 10861.8111s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0960976\n",
      "\tspeed: 0.2073s/iter; left time: 10697.8326s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0740882\n",
      "\tspeed: 0.2041s/iter; left time: 10509.9026s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0925232\n",
      "\tspeed: 0.2073s/iter; left time: 10656.8542s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0872741\n",
      "\tspeed: 0.2091s/iter; left time: 10728.4834s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0927054\n",
      "\tspeed: 0.2125s/iter; left time: 10880.2444s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0926027\n",
      "\tspeed: 0.2049s/iter; left time: 10468.7964s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0748180\n",
      "\tspeed: 0.2070s/iter; left time: 10558.8309s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0865958\n",
      "\tspeed: 0.2093s/iter; left time: 10651.8763s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0942663\n",
      "\tspeed: 0.2105s/iter; left time: 10693.4518s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0669860\n",
      "\tspeed: 0.2112s/iter; left time: 10709.4440s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0851723\n",
      "\tspeed: 0.2055s/iter; left time: 10398.6932s\n",
      "\titers: 3900, epoch: 9 | loss: 0.0820740\n",
      "\tspeed: 0.2023s/iter; left time: 10213.4391s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0780144\n",
      "\tspeed: 0.2069s/iter; left time: 10425.2287s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0814089\n",
      "\tspeed: 0.2089s/iter; left time: 10507.8837s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0962178\n",
      "\tspeed: 0.2070s/iter; left time: 10389.6826s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0851158\n",
      "\tspeed: 0.2086s/iter; left time: 10449.8671s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0686529\n",
      "\tspeed: 0.2062s/iter; left time: 10311.8181s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.2002s/iter; left time: 9987.7916s\n",
      "Epoch: 9 cost time: 00h:15m:44.34s\n",
      "Epoch: 9 | Train Loss: 0.0836118 Vali Loss: 0.0916400 Test Loss: 0.1035914\n",
      "Validation loss decreased (0.092011 --> 0.091640).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0922346\n",
      "\tspeed: 2.8582s/iter; left time: 142237.5401s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827963\n",
      "\tspeed: 0.2100s/iter; left time: 10431.1019s\n",
      "\titers: 300, epoch: 10 | loss: 0.0725681\n",
      "\tspeed: 0.2117s/iter; left time: 10491.4324s\n",
      "\titers: 400, epoch: 10 | loss: 0.0845144\n",
      "\tspeed: 0.2062s/iter; left time: 10197.1332s\n",
      "\titers: 500, epoch: 10 | loss: 0.0973951\n",
      "\tspeed: 0.2051s/iter; left time: 10122.9933s\n",
      "\titers: 600, epoch: 10 | loss: 0.0669774\n",
      "\tspeed: 0.2115s/iter; left time: 10417.2510s\n",
      "\titers: 700, epoch: 10 | loss: 0.0811357\n",
      "\tspeed: 0.2078s/iter; left time: 10216.2978s\n",
      "\titers: 800, epoch: 10 | loss: 0.0769972\n",
      "\tspeed: 0.2086s/iter; left time: 10233.3081s\n",
      "\titers: 900, epoch: 10 | loss: 0.0785766\n",
      "\tspeed: 0.2060s/iter; left time: 10085.1869s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0721540\n",
      "\tspeed: 0.2079s/iter; left time: 10157.5177s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0780357\n",
      "\tspeed: 0.2051s/iter; left time: 10000.1983s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0628892\n",
      "\tspeed: 0.2028s/iter; left time: 9869.3829s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0867144\n",
      "\tspeed: 0.2027s/iter; left time: 9845.6505s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0705752\n",
      "\tspeed: 0.2079s/iter; left time: 10077.8918s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0764625\n",
      "\tspeed: 0.2131s/iter; left time: 10305.6577s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0668899\n",
      "\tspeed: 0.2099s/iter; left time: 10129.1452s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0745432\n",
      "\tspeed: 0.1985s/iter; left time: 9559.4946s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0846424\n",
      "\tspeed: 0.1999s/iter; left time: 9606.2629s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0850989\n",
      "\tspeed: 0.1995s/iter; left time: 9567.8076s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0688419\n",
      "\tspeed: 0.2059s/iter; left time: 9853.2287s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0732007\n",
      "\tspeed: 0.1921s/iter; left time: 9174.4169s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0551585\n",
      "\tspeed: 0.2001s/iter; left time: 9537.2863s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0780649\n",
      "\tspeed: 0.2023s/iter; left time: 9623.7304s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0777197\n",
      "\tspeed: 0.2074s/iter; left time: 9844.1685s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0629792\n",
      "\tspeed: 0.2088s/iter; left time: 9887.6228s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0627633\n",
      "\tspeed: 0.2082s/iter; left time: 9840.6308s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0915789\n",
      "\tspeed: 0.2106s/iter; left time: 9934.9471s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0956732\n",
      "\tspeed: 0.2080s/iter; left time: 9790.2877s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0978506\n",
      "\tspeed: 0.2011s/iter; left time: 9442.4463s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0958144\n",
      "\tspeed: 0.2105s/iter; left time: 9866.6382s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0634759\n",
      "\tspeed: 0.2070s/iter; left time: 9679.0685s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0850318\n",
      "\tspeed: 0.2119s/iter; left time: 9888.1211s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0951718\n",
      "\tspeed: 0.2069s/iter; left time: 9632.4278s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0604331\n",
      "\tspeed: 0.2161s/iter; left time: 10041.8519s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0863831\n",
      "\tspeed: 0.2086s/iter; left time: 9669.8258s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0834125\n",
      "\tspeed: 0.2059s/iter; left time: 9525.5533s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0860748\n",
      "\tspeed: 0.2138s/iter; left time: 9871.6050s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0807017\n",
      "\tspeed: 0.2099s/iter; left time: 9668.1149s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0948860\n",
      "\tspeed: 0.2066s/iter; left time: 9496.2855s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0667045\n",
      "\tspeed: 0.2054s/iter; left time: 9418.3610s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0953892\n",
      "\tspeed: 0.2083s/iter; left time: 9533.4707s\n",
      "\titers: 4200, epoch: 10 | loss: 0.1057899\n",
      "\tspeed: 0.2285s/iter; left time: 10432.9748s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0854646\n",
      "\tspeed: 0.2115s/iter; left time: 9635.5818s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0952444\n",
      "\tspeed: 0.2067s/iter; left time: 9398.9828s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0909593\n",
      "\tspeed: 0.2076s/iter; left time: 9419.3097s\n",
      "Epoch: 10 cost time: 00h:15m:40.41s\n",
      "Epoch: 10 | Train Loss: 0.0831709 Vali Loss: 0.0917714 Test Loss: 0.1027734\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0831171\n",
      "\tspeed: 2.8817s/iter; left time: 130342.9083s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760654\n",
      "\tspeed: 0.2087s/iter; left time: 9418.2588s\n",
      "\titers: 300, epoch: 11 | loss: 0.0676253\n",
      "\tspeed: 0.2065s/iter; left time: 9298.5589s\n",
      "\titers: 400, epoch: 11 | loss: 0.1150495\n",
      "\tspeed: 0.2069s/iter; left time: 9295.3398s\n",
      "\titers: 500, epoch: 11 | loss: 0.0861939\n",
      "\tspeed: 0.2066s/iter; left time: 9263.6129s\n",
      "\titers: 600, epoch: 11 | loss: 0.1202399\n",
      "\tspeed: 0.2121s/iter; left time: 9486.0471s\n",
      "\titers: 700, epoch: 11 | loss: 0.0713722\n",
      "\tspeed: 0.2123s/iter; left time: 9474.7945s\n",
      "\titers: 800, epoch: 11 | loss: 0.0841707\n",
      "\tspeed: 0.2088s/iter; left time: 9296.2961s\n",
      "\titers: 900, epoch: 11 | loss: 0.0706428\n",
      "\tspeed: 0.2032s/iter; left time: 9026.7012s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0783792\n",
      "\tspeed: 0.2100s/iter; left time: 9308.6294s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0755092\n",
      "\tspeed: 0.2072s/iter; left time: 9164.5589s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0712842\n",
      "\tspeed: 0.2102s/iter; left time: 9275.6769s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0775973\n",
      "\tspeed: 0.2039s/iter; left time: 8977.7339s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0768260\n",
      "\tspeed: 0.2083s/iter; left time: 9151.9148s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0978865\n",
      "\tspeed: 0.2103s/iter; left time: 9216.5358s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0887017\n",
      "\tspeed: 0.2104s/iter; left time: 9201.6183s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0848004\n",
      "\tspeed: 0.2086s/iter; left time: 9102.4207s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0720866\n",
      "\tspeed: 0.2006s/iter; left time: 8732.7789s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0970763\n",
      "\tspeed: 0.2020s/iter; left time: 8772.5618s\n",
      "\titers: 2000, epoch: 11 | loss: 0.1055982\n",
      "\tspeed: 0.2028s/iter; left time: 8786.9344s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0810075\n",
      "\tspeed: 0.2052s/iter; left time: 8871.1912s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0754189\n",
      "\tspeed: 0.2091s/iter; left time: 9018.6253s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0723282\n",
      "\tspeed: 0.1987s/iter; left time: 8551.6666s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0780134\n",
      "\tspeed: 0.1997s/iter; left time: 8573.6291s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0767258\n",
      "\tspeed: 0.1976s/iter; left time: 8462.0010s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0836462\n",
      "\tspeed: 0.2066s/iter; left time: 8827.9592s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0815188\n",
      "\tspeed: 0.2051s/iter; left time: 8743.1324s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0932637\n",
      "\tspeed: 0.2019s/iter; left time: 8587.2621s\n",
      "\titers: 2900, epoch: 11 | loss: 0.1080622\n",
      "\tspeed: 0.1999s/iter; left time: 8481.8730s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0838806\n",
      "\tspeed: 0.2037s/iter; left time: 8623.5369s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0917139\n",
      "\tspeed: 0.2058s/iter; left time: 8691.8585s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0728604\n",
      "\tspeed: 0.2087s/iter; left time: 8794.6896s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0765374\n",
      "\tspeed: 0.2089s/iter; left time: 8779.8091s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0869917\n",
      "\tspeed: 0.2073s/iter; left time: 8691.9496s\n",
      "\titers: 3500, epoch: 11 | loss: 0.1024831\n",
      "\tspeed: 0.2130s/iter; left time: 8908.1749s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0874722\n",
      "\tspeed: 0.2082s/iter; left time: 8690.1439s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0937591\n",
      "\tspeed: 0.2048s/iter; left time: 8524.0244s\n",
      "\titers: 3800, epoch: 11 | loss: 0.1035393\n",
      "\tspeed: 0.2102s/iter; left time: 8728.3784s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1090173\n",
      "\tspeed: 0.2062s/iter; left time: 8542.7912s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0618905\n",
      "\tspeed: 0.2053s/iter; left time: 8484.7243s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0943761\n",
      "\tspeed: 0.2034s/iter; left time: 8386.7505s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0912680\n",
      "\tspeed: 0.2072s/iter; left time: 8522.4293s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0760508\n",
      "\tspeed: 0.2002s/iter; left time: 8213.3524s\n",
      "\titers: 4400, epoch: 11 | loss: 0.1074579\n",
      "\tspeed: 0.2010s/iter; left time: 8226.3412s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0892026\n",
      "\tspeed: 0.2083s/iter; left time: 8506.9017s\n",
      "Epoch: 11 cost time: 00h:15m:35.54s\n",
      "Epoch: 11 | Train Loss: 0.0828589 Vali Loss: 0.0916625 Test Loss: 0.1039719\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.1107441\n",
      "\tspeed: 2.9255s/iter; left time: 119062.3005s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788576\n",
      "\tspeed: 0.2046s/iter; left time: 8304.8388s\n",
      "\titers: 300, epoch: 12 | loss: 0.0659967\n",
      "\tspeed: 0.2059s/iter; left time: 8337.9879s\n",
      "\titers: 400, epoch: 12 | loss: 0.0706586\n",
      "\tspeed: 0.2074s/iter; left time: 8378.1466s\n",
      "\titers: 500, epoch: 12 | loss: 0.0756243\n",
      "\tspeed: 0.2068s/iter; left time: 8332.8156s\n",
      "\titers: 600, epoch: 12 | loss: 0.0702241\n",
      "\tspeed: 0.2114s/iter; left time: 8497.5896s\n",
      "\titers: 700, epoch: 12 | loss: 0.0794594\n",
      "\tspeed: 0.2074s/iter; left time: 8317.2887s\n",
      "\titers: 800, epoch: 12 | loss: 0.0771929\n",
      "\tspeed: 0.2023s/iter; left time: 8090.8364s\n",
      "\titers: 900, epoch: 12 | loss: 0.0743011\n",
      "\tspeed: 0.2199s/iter; left time: 8773.2326s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0905746\n",
      "\tspeed: 0.2251s/iter; left time: 8959.5643s\n",
      "\titers: 1100, epoch: 12 | loss: 0.1068195\n",
      "\tspeed: 0.2082s/iter; left time: 8264.4714s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0629381\n",
      "\tspeed: 0.2121s/iter; left time: 8400.5335s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0803293\n",
      "\tspeed: 0.2098s/iter; left time: 8285.2291s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0934114\n",
      "\tspeed: 0.2094s/iter; left time: 8250.1952s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0726073\n",
      "\tspeed: 0.2078s/iter; left time: 8165.8378s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0928714\n",
      "\tspeed: 0.2117s/iter; left time: 8299.6592s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0842601\n",
      "\tspeed: 0.2090s/iter; left time: 8169.8199s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0871204\n",
      "\tspeed: 0.2067s/iter; left time: 8061.5385s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0869684\n",
      "\tspeed: 0.2053s/iter; left time: 7987.3525s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0896044\n",
      "\tspeed: 0.2042s/iter; left time: 7924.1125s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0892930\n",
      "\tspeed: 0.2102s/iter; left time: 8134.4180s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0785727\n",
      "\tspeed: 0.2053s/iter; left time: 7925.2022s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0655281\n",
      "\tspeed: 0.2068s/iter; left time: 7961.3379s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0941407\n",
      "\tspeed: 0.2052s/iter; left time: 7879.3166s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0824777\n",
      "\tspeed: 0.2081s/iter; left time: 7969.6767s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0843000\n",
      "\tspeed: 0.2072s/iter; left time: 7916.3379s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0749287\n",
      "\tspeed: 0.2067s/iter; left time: 7876.7516s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0777160\n",
      "\tspeed: 0.2097s/iter; left time: 7969.2220s\n",
      "\titers: 2900, epoch: 12 | loss: 0.1096275\n",
      "\tspeed: 0.2090s/iter; left time: 7920.7917s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0781749\n",
      "\tspeed: 0.2019s/iter; left time: 7630.3932s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0840687\n",
      "\tspeed: 0.2085s/iter; left time: 7861.7842s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0815316\n",
      "\tspeed: 0.2134s/iter; left time: 8021.9205s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0798401\n",
      "\tspeed: 0.2068s/iter; left time: 7755.3049s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0896733\n",
      "\tspeed: 0.2079s/iter; left time: 7774.0832s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0939660\n",
      "\tspeed: 0.2096s/iter; left time: 7816.4147s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0806810\n",
      "\tspeed: 0.2080s/iter; left time: 7735.3458s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0831135\n",
      "\tspeed: 0.2068s/iter; left time: 7673.0408s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0972236\n",
      "\tspeed: 0.2040s/iter; left time: 7546.7665s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0667614\n",
      "\tspeed: 0.2108s/iter; left time: 7777.5438s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0731204\n",
      "\tspeed: 0.2106s/iter; left time: 7750.9609s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0678291\n",
      "\tspeed: 0.2061s/iter; left time: 7561.9346s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0690682\n",
      "\tspeed: 0.2083s/iter; left time: 7624.8098s\n",
      "\titers: 4300, epoch: 12 | loss: 0.1088947\n",
      "\tspeed: 0.2121s/iter; left time: 7741.9932s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0743459\n",
      "\tspeed: 0.2052s/iter; left time: 7467.3271s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0860502\n",
      "\tspeed: 0.2021s/iter; left time: 7336.8973s\n",
      "Epoch: 12 cost time: 00h:15m:43.96s\n",
      "Epoch: 12 | Train Loss: 0.0825203 Vali Loss: 0.0916567 Test Loss: 0.1027902\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0783379\n",
      "\tspeed: 2.8986s/iter; left time: 104829.4755s\n",
      "\titers: 200, epoch: 13 | loss: 0.0738363\n",
      "\tspeed: 0.2037s/iter; left time: 7348.0087s\n",
      "\titers: 300, epoch: 13 | loss: 0.0749852\n",
      "\tspeed: 0.2038s/iter; left time: 7329.8585s\n",
      "\titers: 400, epoch: 13 | loss: 0.0879915\n",
      "\tspeed: 0.2112s/iter; left time: 7573.5920s\n",
      "\titers: 500, epoch: 13 | loss: 0.1001487\n",
      "\tspeed: 0.2057s/iter; left time: 7358.0682s\n",
      "\titers: 600, epoch: 13 | loss: 0.0878043\n",
      "\tspeed: 0.2106s/iter; left time: 7509.5530s\n",
      "\titers: 700, epoch: 13 | loss: 0.0682022\n",
      "\tspeed: 0.2020s/iter; left time: 7184.9157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0907041\n",
      "\tspeed: 0.2028s/iter; left time: 7193.5316s\n",
      "\titers: 900, epoch: 13 | loss: 0.0719263\n",
      "\tspeed: 0.2003s/iter; left time: 7084.6013s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0821333\n",
      "\tspeed: 0.2021s/iter; left time: 7127.7967s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0916378\n",
      "\tspeed: 0.2078s/iter; left time: 7307.2581s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0779572\n",
      "\tspeed: 0.2098s/iter; left time: 7355.7181s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0896925\n",
      "\tspeed: 0.2061s/iter; left time: 7205.3371s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0888662\n",
      "\tspeed: 0.2112s/iter; left time: 7362.9053s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0672289\n",
      "\tspeed: 0.2101s/iter; left time: 7303.3775s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0743646\n",
      "\tspeed: 0.2045s/iter; left time: 7087.5901s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0798930\n",
      "\tspeed: 0.2028s/iter; left time: 7009.7953s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0719059\n",
      "\tspeed: 0.1994s/iter; left time: 6871.7587s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0909283\n",
      "\tspeed: 0.2120s/iter; left time: 7285.5241s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0848830\n",
      "\tspeed: 0.2096s/iter; left time: 7181.8074s\n",
      "\titers: 2100, epoch: 13 | loss: 0.1008925\n",
      "\tspeed: 0.2058s/iter; left time: 7032.7138s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0732174\n",
      "\tspeed: 0.2049s/iter; left time: 6979.1657s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0867420\n",
      "\tspeed: 0.2065s/iter; left time: 7012.5722s\n",
      "\titers: 2400, epoch: 13 | loss: 0.1244981\n",
      "\tspeed: 0.2054s/iter; left time: 6954.5250s\n",
      "\titers: 2500, epoch: 13 | loss: 0.1019368\n",
      "\tspeed: 0.2097s/iter; left time: 7080.3613s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0934693\n",
      "\tspeed: 0.2051s/iter; left time: 6905.2862s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0734084\n",
      "\tspeed: 0.2082s/iter; left time: 6987.0629s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0933964\n",
      "\tspeed: 0.2053s/iter; left time: 6869.4792s\n",
      "\titers: 2900, epoch: 13 | loss: 0.0927303\n",
      "\tspeed: 0.2028s/iter; left time: 6767.3623s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0820297\n",
      "\tspeed: 0.1950s/iter; left time: 6485.3066s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0925897\n",
      "\tspeed: 0.2006s/iter; left time: 6651.4775s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0724766\n",
      "\tspeed: 0.2045s/iter; left time: 6761.9935s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0795591\n",
      "\tspeed: 0.2144s/iter; left time: 7069.2097s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0698357\n",
      "\tspeed: 0.2094s/iter; left time: 6883.5561s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0791542\n",
      "\tspeed: 0.2078s/iter; left time: 6809.2753s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0944202\n",
      "\tspeed: 0.2257s/iter; left time: 7371.9854s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0822768\n",
      "\tspeed: 0.2192s/iter; left time: 7137.6408s\n",
      "\titers: 3800, epoch: 13 | loss: 0.1007117\n",
      "\tspeed: 0.2084s/iter; left time: 6766.2169s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Capture and log output in real-time\u001b[39;00m\n\u001b[1;32m     56\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 57\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1474  0.0920\n",
       "        96        0.0395  0.1989  0.1324\n",
       "        168       0.0395  0.1988  0.1348\n",
       "GB      24        0.0252  0.1588  0.1012\n",
       "        96        0.0437  0.2091  0.1434\n",
       "        168       0.0469  0.2166  0.1487\n",
       "ES      24        0.0108  0.1039  0.0672\n",
       "        96        0.0198  0.1409  0.0941\n",
       "        168       0.0217  0.1472  0.0970\n",
       "FR      24        0.0104  0.1017  0.0586\n",
       "        96        0.0186  0.1365  0.0824\n",
       "        168       0.0205  0.1430  0.0878\n",
       "IT      24        0.0104  0.1022  0.0607\n",
       "        96        0.0188  0.1370  0.0839\n",
       "        168       0.0204  0.1428  0.0892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(timellm_results, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/96'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_96.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
