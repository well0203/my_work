{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0368s/iter; left time: 820.5752s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0158s/iter; left time: 350.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0429s/iter; left time: 948.0775s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0204s/iter; left time: 449.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0403s/iter; left time: 880.4904s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0231s/iter; left time: 502.2227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0390s/iter; left time: 843.0845s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0175s/iter; left time: 375.6987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0396s/iter; left time: 847.8896s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0179s/iter; left time: 380.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0407s/iter; left time: 862.1221s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0196s/iter; left time: 413.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0377s/iter; left time: 789.9388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0182s/iter; left time: 380.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0371s/iter; left time: 768.3335s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0183s/iter; left time: 377.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0378s/iter; left time: 775.0813s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0172s/iter; left time: 351.6282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0402s/iter; left time: 815.0057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0191s/iter; left time: 385.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0400s/iter; left time: 802.3540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0190s/iter; left time: 378.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0380s/iter; left time: 754.6358s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0166s/iter; left time: 326.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0349s/iter; left time: 683.9538s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0173s/iter; left time: 338.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0365s/iter; left time: 707.6938s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0216s/iter; left time: 416.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0397s/iter; left time: 760.7060s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0201s/iter; left time: 383.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0383s/iter; left time: 725.6309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0184s/iter; left time: 347.0850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0362s/iter; left time: 678.4106s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0162s/iter; left time: 302.4925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0358s/iter; left time: 661.4998s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0162s/iter; left time: 298.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0357s/iter; left time: 652.3112s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0162s/iter; left time: 294.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0351s/iter; left time: 633.4396s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0169s/iter; left time: 302.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0754218\n",
      "\tspeed: 0.0406s/iter; left time: 723.4465s\n",
      "\titers: 200, epoch: 21 | loss: 0.0769159\n",
      "\tspeed: 0.0198s/iter; left time: 351.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0778717 Vali Loss: 0.0905973 Test Loss: 0.0927691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0722155\n",
      "\tspeed: 0.0385s/iter; left time: 677.3028s\n",
      "\titers: 200, epoch: 22 | loss: 0.0763010\n",
      "\tspeed: 0.0186s/iter; left time: 324.8486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0778838 Vali Loss: 0.0902790 Test Loss: 0.0928775\n",
      "Validation loss decreased (0.090461 --> 0.090279).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0840008\n",
      "\tspeed: 0.0451s/iter; left time: 784.0892s\n",
      "\titers: 200, epoch: 23 | loss: 0.0815538\n",
      "\tspeed: 0.0173s/iter; left time: 299.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0776099 Vali Loss: 0.0901982 Test Loss: 0.0925049\n",
      "Validation loss decreased (0.090279 --> 0.090198).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761470\n",
      "\tspeed: 0.0394s/iter; left time: 675.7500s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754500\n",
      "\tspeed: 0.0183s/iter; left time: 312.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0774545 Vali Loss: 0.0899673 Test Loss: 0.0924277\n",
      "Validation loss decreased (0.090198 --> 0.089967).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0775773\n",
      "\tspeed: 0.0352s/iter; left time: 596.5230s\n",
      "\titers: 200, epoch: 25 | loss: 0.0774031\n",
      "\tspeed: 0.0168s/iter; left time: 282.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0773735 Vali Loss: 0.0899634 Test Loss: 0.0922804\n",
      "Validation loss decreased (0.089967 --> 0.089963).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0793764\n",
      "\tspeed: 0.0393s/iter; left time: 656.0848s\n",
      "\titers: 200, epoch: 26 | loss: 0.0849619\n",
      "\tspeed: 0.0232s/iter; left time: 384.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0774353 Vali Loss: 0.0902629 Test Loss: 0.0924093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0784349\n",
      "\tspeed: 0.0437s/iter; left time: 720.2482s\n",
      "\titers: 200, epoch: 27 | loss: 0.0804014\n",
      "\tspeed: 0.0235s/iter; left time: 385.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0771873 Vali Loss: 0.0902476 Test Loss: 0.0924189\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0754124\n",
      "\tspeed: 0.0431s/iter; left time: 700.2752s\n",
      "\titers: 200, epoch: 28 | loss: 0.0748610\n",
      "\tspeed: 0.0153s/iter; left time: 247.5385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0771039 Vali Loss: 0.0900546 Test Loss: 0.0922958\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0792774\n",
      "\tspeed: 0.0395s/iter; left time: 632.9614s\n",
      "\titers: 200, epoch: 29 | loss: 0.0796077\n",
      "\tspeed: 0.0184s/iter; left time: 293.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0770707 Vali Loss: 0.0897811 Test Loss: 0.0920447\n",
      "Validation loss decreased (0.089963 --> 0.089781).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0762779\n",
      "\tspeed: 0.0437s/iter; left time: 690.0718s\n",
      "\titers: 200, epoch: 30 | loss: 0.0747327\n",
      "\tspeed: 0.0231s/iter; left time: 362.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0769739 Vali Loss: 0.0902239 Test Loss: 0.0923670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0780120\n",
      "\tspeed: 0.0372s/iter; left time: 578.9943s\n",
      "\titers: 200, epoch: 31 | loss: 0.0750840\n",
      "\tspeed: 0.0159s/iter; left time: 246.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0769016 Vali Loss: 0.0895654 Test Loss: 0.0921225\n",
      "Validation loss decreased (0.089781 --> 0.089565).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0800933\n",
      "\tspeed: 0.0375s/iter; left time: 575.6800s\n",
      "\titers: 200, epoch: 32 | loss: 0.0767201\n",
      "\tspeed: 0.0166s/iter; left time: 253.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0769158 Vali Loss: 0.0899132 Test Loss: 0.0921777\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0769815\n",
      "\tspeed: 0.0355s/iter; left time: 537.6752s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741093\n",
      "\tspeed: 0.0172s/iter; left time: 259.1477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0767384 Vali Loss: 0.0897739 Test Loss: 0.0922752\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0793075\n",
      "\tspeed: 0.0374s/iter; left time: 557.4439s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709558\n",
      "\tspeed: 0.0172s/iter; left time: 254.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0767915 Vali Loss: 0.0895388 Test Loss: 0.0919821\n",
      "Validation loss decreased (0.089565 --> 0.089539).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0770702\n",
      "\tspeed: 0.0375s/iter; left time: 550.9576s\n",
      "\titers: 200, epoch: 35 | loss: 0.0845928\n",
      "\tspeed: 0.0178s/iter; left time: 259.1727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0768886 Vali Loss: 0.0895880 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0722219\n",
      "\tspeed: 0.0430s/iter; left time: 621.2184s\n",
      "\titers: 200, epoch: 36 | loss: 0.0776174\n",
      "\tspeed: 0.0188s/iter; left time: 270.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0768114 Vali Loss: 0.0900146 Test Loss: 0.0922739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0778614\n",
      "\tspeed: 0.0360s/iter; left time: 511.8297s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751549\n",
      "\tspeed: 0.0178s/iter; left time: 252.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0767441 Vali Loss: 0.0894062 Test Loss: 0.0918953\n",
      "Validation loss decreased (0.089539 --> 0.089406).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0742013\n",
      "\tspeed: 0.0357s/iter; left time: 500.5191s\n",
      "\titers: 200, epoch: 38 | loss: 0.0728804\n",
      "\tspeed: 0.0168s/iter; left time: 233.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0766412 Vali Loss: 0.0896684 Test Loss: 0.0921262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720863\n",
      "\tspeed: 0.0369s/iter; left time: 508.6297s\n",
      "\titers: 200, epoch: 39 | loss: 0.0745677\n",
      "\tspeed: 0.0173s/iter; left time: 236.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0766759 Vali Loss: 0.0898184 Test Loss: 0.0921254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0768512\n",
      "\tspeed: 0.0361s/iter; left time: 489.1576s\n",
      "\titers: 200, epoch: 40 | loss: 0.0695771\n",
      "\tspeed: 0.0159s/iter; left time: 214.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0766491 Vali Loss: 0.0900104 Test Loss: 0.0922310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0744775\n",
      "\tspeed: 0.0361s/iter; left time: 481.8075s\n",
      "\titers: 200, epoch: 41 | loss: 0.0816218\n",
      "\tspeed: 0.0166s/iter; left time: 219.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0766678 Vali Loss: 0.0896019 Test Loss: 0.0919775\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0793130\n",
      "\tspeed: 0.0363s/iter; left time: 475.5269s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831729\n",
      "\tspeed: 0.0177s/iter; left time: 230.6644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0765614 Vali Loss: 0.0896606 Test Loss: 0.0919400\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755343\n",
      "\tspeed: 0.0375s/iter; left time: 484.1262s\n",
      "\titers: 200, epoch: 43 | loss: 0.0812308\n",
      "\tspeed: 0.0170s/iter; left time: 216.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0766105 Vali Loss: 0.0897262 Test Loss: 0.0920330\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0762576\n",
      "\tspeed: 0.0360s/iter; left time: 456.4423s\n",
      "\titers: 200, epoch: 44 | loss: 0.0749513\n",
      "\tspeed: 0.0187s/iter; left time: 234.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0765386 Vali Loss: 0.0894904 Test Loss: 0.0918714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0822986\n",
      "\tspeed: 0.0362s/iter; left time: 450.6639s\n",
      "\titers: 200, epoch: 45 | loss: 0.0793362\n",
      "\tspeed: 0.0184s/iter; left time: 227.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0765737 Vali Loss: 0.0899103 Test Loss: 0.0921595\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0774861\n",
      "\tspeed: 0.0361s/iter; left time: 440.8905s\n",
      "\titers: 200, epoch: 46 | loss: 0.0801331\n",
      "\tspeed: 0.0167s/iter; left time: 202.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0765671 Vali Loss: 0.0894596 Test Loss: 0.0918659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0829733\n",
      "\tspeed: 0.0351s/iter; left time: 421.2095s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730344\n",
      "\tspeed: 0.0178s/iter; left time: 211.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0765457 Vali Loss: 0.0899148 Test Loss: 0.0922697\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021877428516745567, rmse:0.1479102075099945, mae:0.09189533442258835, rse:0.5219956040382385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2795793\n",
      "\tspeed: 0.0236s/iter; left time: 526.3734s\n",
      "\titers: 200, epoch: 1 | loss: 0.2581289\n",
      "\tspeed: 0.0217s/iter; left time: 481.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.2717099 Vali Loss: 0.2311239 Test Loss: 0.2326769\n",
      "Validation loss decreased (inf --> 0.231124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1460241\n",
      "\tspeed: 0.0425s/iter; left time: 938.0821s\n",
      "\titers: 200, epoch: 2 | loss: 0.1226775\n",
      "\tspeed: 0.0192s/iter; left time: 422.3220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1535573 Vali Loss: 0.1255880 Test Loss: 0.1287646\n",
      "Validation loss decreased (0.231124 --> 0.125588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1006170\n",
      "\tspeed: 0.0401s/iter; left time: 875.9828s\n",
      "\titers: 200, epoch: 3 | loss: 0.1042795\n",
      "\tspeed: 0.0226s/iter; left time: 491.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.1066906 Vali Loss: 0.1052246 Test Loss: 0.1056530\n",
      "Validation loss decreased (0.125588 --> 0.105225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985685\n",
      "\tspeed: 0.0438s/iter; left time: 948.3535s\n",
      "\titers: 200, epoch: 4 | loss: 0.0950993\n",
      "\tspeed: 0.0168s/iter; left time: 362.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0947283 Vali Loss: 0.1006377 Test Loss: 0.1017516\n",
      "Validation loss decreased (0.105225 --> 0.100638).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0910783\n",
      "\tspeed: 0.0356s/iter; left time: 762.1383s\n",
      "\titers: 200, epoch: 5 | loss: 0.0909245\n",
      "\tspeed: 0.0176s/iter; left time: 374.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0898671 Vali Loss: 0.0980647 Test Loss: 0.0996634\n",
      "Validation loss decreased (0.100638 --> 0.098065).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0873396\n",
      "\tspeed: 0.0363s/iter; left time: 767.9855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838316\n",
      "\tspeed: 0.0179s/iter; left time: 377.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0869142 Vali Loss: 0.0961922 Test Loss: 0.0982261\n",
      "Validation loss decreased (0.098065 --> 0.096192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815935\n",
      "\tspeed: 0.0387s/iter; left time: 811.5966s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819990\n",
      "\tspeed: 0.0170s/iter; left time: 355.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0850223 Vali Loss: 0.0963149 Test Loss: 0.0987874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0845545\n",
      "\tspeed: 0.0346s/iter; left time: 717.0393s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827005\n",
      "\tspeed: 0.0148s/iter; left time: 306.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0835324 Vali Loss: 0.0940600 Test Loss: 0.0957685\n",
      "Validation loss decreased (0.096192 --> 0.094060).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804912\n",
      "\tspeed: 0.0393s/iter; left time: 805.3207s\n",
      "\titers: 200, epoch: 9 | loss: 0.0806583\n",
      "\tspeed: 0.0166s/iter; left time: 338.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0823066 Vali Loss: 0.0936993 Test Loss: 0.0953462\n",
      "Validation loss decreased (0.094060 --> 0.093699).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0770288\n",
      "\tspeed: 0.0341s/iter; left time: 692.6652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785382\n",
      "\tspeed: 0.0148s/iter; left time: 297.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0816374 Vali Loss: 0.0943467 Test Loss: 0.0953491\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0793969\n",
      "\tspeed: 0.0356s/iter; left time: 714.0697s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852954\n",
      "\tspeed: 0.0200s/iter; left time: 400.0897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0807893 Vali Loss: 0.0924223 Test Loss: 0.0939639\n",
      "Validation loss decreased (0.093699 --> 0.092422).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0816043\n",
      "\tspeed: 0.0380s/iter; left time: 753.2372s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799592\n",
      "\tspeed: 0.0171s/iter; left time: 337.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0803146 Vali Loss: 0.0924737 Test Loss: 0.0938121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751553\n",
      "\tspeed: 0.0422s/iter; left time: 826.7760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0823086\n",
      "\tspeed: 0.0163s/iter; left time: 318.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0796810 Vali Loss: 0.0924237 Test Loss: 0.0939455\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0760754\n",
      "\tspeed: 0.0343s/iter; left time: 664.2436s\n",
      "\titers: 200, epoch: 14 | loss: 0.0758581\n",
      "\tspeed: 0.0148s/iter; left time: 284.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 224 | Train Loss: 0.0793448 Vali Loss: 0.0924458 Test Loss: 0.0940503\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0748765\n",
      "\tspeed: 0.0406s/iter; left time: 778.2156s\n",
      "\titers: 200, epoch: 15 | loss: 0.0785758\n",
      "\tspeed: 0.0230s/iter; left time: 438.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0790329 Vali Loss: 0.0913572 Test Loss: 0.0932310\n",
      "Validation loss decreased (0.092422 --> 0.091357).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0833294\n",
      "\tspeed: 0.0463s/iter; left time: 876.0320s\n",
      "\titers: 200, epoch: 16 | loss: 0.0770179\n",
      "\tspeed: 0.0273s/iter; left time: 515.0274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0787568 Vali Loss: 0.0910991 Test Loss: 0.0928352\n",
      "Validation loss decreased (0.091357 --> 0.091099).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777185\n",
      "\tspeed: 0.0456s/iter; left time: 852.6459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0779669\n",
      "\tspeed: 0.0190s/iter; left time: 354.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0785381 Vali Loss: 0.0908517 Test Loss: 0.0928423\n",
      "Validation loss decreased (0.091099 --> 0.090852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787854\n",
      "\tspeed: 0.0377s/iter; left time: 697.7656s\n",
      "\titers: 200, epoch: 18 | loss: 0.0840955\n",
      "\tspeed: 0.0181s/iter; left time: 332.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0784308 Vali Loss: 0.0921700 Test Loss: 0.0934294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0801536\n",
      "\tspeed: 0.0388s/iter; left time: 709.1814s\n",
      "\titers: 200, epoch: 19 | loss: 0.0787770\n",
      "\tspeed: 0.0210s/iter; left time: 381.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0780323 Vali Loss: 0.0908994 Test Loss: 0.0926545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0759411\n",
      "\tspeed: 0.0387s/iter; left time: 698.5205s\n",
      "\titers: 200, epoch: 20 | loss: 0.0778539\n",
      "\tspeed: 0.0188s/iter; left time: 337.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0778663 Vali Loss: 0.0916306 Test Loss: 0.0933820\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0819615\n",
      "\tspeed: 0.0430s/iter; left time: 767.1432s\n",
      "\titers: 200, epoch: 21 | loss: 0.0806742\n",
      "\tspeed: 0.0212s/iter; left time: 374.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0777724 Vali Loss: 0.0910355 Test Loss: 0.0926646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0842379\n",
      "\tspeed: 0.0403s/iter; left time: 709.6877s\n",
      "\titers: 200, epoch: 22 | loss: 0.0749566\n",
      "\tspeed: 0.0171s/iter; left time: 299.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0775101 Vali Loss: 0.0903652 Test Loss: 0.0923590\n",
      "Validation loss decreased (0.090852 --> 0.090365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0770355\n",
      "\tspeed: 0.0356s/iter; left time: 618.7612s\n",
      "\titers: 200, epoch: 23 | loss: 0.0765068\n",
      "\tspeed: 0.0154s/iter; left time: 265.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0774336 Vali Loss: 0.0915347 Test Loss: 0.0931197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0748078\n",
      "\tspeed: 0.0389s/iter; left time: 667.6700s\n",
      "\titers: 200, epoch: 24 | loss: 0.0763243\n",
      "\tspeed: 0.0200s/iter; left time: 340.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0774180 Vali Loss: 0.0904829 Test Loss: 0.0922597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0794534\n",
      "\tspeed: 0.0369s/iter; left time: 624.1969s\n",
      "\titers: 200, epoch: 25 | loss: 0.0773389\n",
      "\tspeed: 0.0222s/iter; left time: 374.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0772832 Vali Loss: 0.0909832 Test Loss: 0.0926450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0775157\n",
      "\tspeed: 0.0361s/iter; left time: 602.3169s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738235\n",
      "\tspeed: 0.0148s/iter; left time: 244.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0771211 Vali Loss: 0.0908386 Test Loss: 0.0925390\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0717765\n",
      "\tspeed: 0.0367s/iter; left time: 604.7950s\n",
      "\titers: 200, epoch: 27 | loss: 0.0745081\n",
      "\tspeed: 0.0163s/iter; left time: 266.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0772324 Vali Loss: 0.0899216 Test Loss: 0.0921636\n",
      "Validation loss decreased (0.090365 --> 0.089922).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0791755\n",
      "\tspeed: 0.0403s/iter; left time: 655.3859s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777192\n",
      "\tspeed: 0.0173s/iter; left time: 279.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0771157 Vali Loss: 0.0900271 Test Loss: 0.0919820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744445\n",
      "\tspeed: 0.0455s/iter; left time: 729.9270s\n",
      "\titers: 200, epoch: 29 | loss: 0.0746980\n",
      "\tspeed: 0.0204s/iter; left time: 324.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0771550 Vali Loss: 0.0908405 Test Loss: 0.0926438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0756679\n",
      "\tspeed: 0.0421s/iter; left time: 665.3647s\n",
      "\titers: 200, epoch: 30 | loss: 0.0718184\n",
      "\tspeed: 0.0208s/iter; left time: 326.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0770201 Vali Loss: 0.0900961 Test Loss: 0.0920187\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778587\n",
      "\tspeed: 0.0420s/iter; left time: 653.7629s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729986\n",
      "\tspeed: 0.0219s/iter; left time: 338.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0770441 Vali Loss: 0.0899777 Test Loss: 0.0918684\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0768104\n",
      "\tspeed: 0.0401s/iter; left time: 615.1384s\n",
      "\titers: 200, epoch: 32 | loss: 0.0763993\n",
      "\tspeed: 0.0203s/iter; left time: 310.1277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0768499 Vali Loss: 0.0910889 Test Loss: 0.0927245\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0730918\n",
      "\tspeed: 0.0383s/iter; left time: 578.9354s\n",
      "\titers: 200, epoch: 33 | loss: 0.0787223\n",
      "\tspeed: 0.0170s/iter; left time: 254.9871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0768298 Vali Loss: 0.0903262 Test Loss: 0.0922530\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0800109\n",
      "\tspeed: 0.0334s/iter; left time: 497.2794s\n",
      "\titers: 200, epoch: 34 | loss: 0.0745068\n",
      "\tspeed: 0.0184s/iter; left time: 271.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0769069 Vali Loss: 0.0905272 Test Loss: 0.0923126\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0742564\n",
      "\tspeed: 0.0392s/iter; left time: 576.1113s\n",
      "\titers: 200, epoch: 35 | loss: 0.0726635\n",
      "\tspeed: 0.0230s/iter; left time: 335.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0768160 Vali Loss: 0.0902332 Test Loss: 0.0921869\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0787445\n",
      "\tspeed: 0.0380s/iter; left time: 549.6520s\n",
      "\titers: 200, epoch: 36 | loss: 0.0738677\n",
      "\tspeed: 0.0152s/iter; left time: 218.7823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0767147 Vali Loss: 0.0902117 Test Loss: 0.0920638\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0791762\n",
      "\tspeed: 0.0337s/iter; left time: 480.2793s\n",
      "\titers: 200, epoch: 37 | loss: 0.0752761\n",
      "\tspeed: 0.0149s/iter; left time: 210.4859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0768540 Vali Loss: 0.0899249 Test Loss: 0.0918227\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021809319034218788, rmse:0.14767979085445404, mae:0.0921635851264, rse:0.5211824178695679\n",
      "Intermediate time for DE and pred_len 24: 00h:08m:08.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0386s/iter; left time: 861.8472s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0150s/iter; left time: 332.2779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0360s/iter; left time: 794.2010s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0167s/iter; left time: 366.0428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0365s/iter; left time: 797.6013s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0166s/iter; left time: 360.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0368s/iter; left time: 796.4620s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0162s/iter; left time: 348.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0356s/iter; left time: 761.7323s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0167s/iter; left time: 356.8095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0357s/iter; left time: 756.9383s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0150s/iter; left time: 316.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0367s/iter; left time: 768.5269s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0158s/iter; left time: 328.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0426s/iter; left time: 882.6305s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0171s/iter; left time: 353.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0418s/iter; left time: 857.6565s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0160s/iter; left time: 325.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0411s/iter; left time: 834.5929s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0238s/iter; left time: 480.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0411s/iter; left time: 823.7195s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0160s/iter; left time: 318.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0362s/iter; left time: 718.5524s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0159s/iter; left time: 314.2081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0354s/iter; left time: 693.9780s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0164s/iter; left time: 320.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0361s/iter; left time: 699.6760s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0154s/iter; left time: 297.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0377s/iter; left time: 722.8265s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0168s/iter; left time: 320.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0398s/iter; left time: 754.0254s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0200s/iter; left time: 376.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0368s/iter; left time: 687.9826s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0160s/iter; left time: 298.3146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0410s/iter; left time: 758.5240s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0204s/iter; left time: 375.1843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0396s/iter; left time: 722.8853s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0228s/iter; left time: 413.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0398s/iter; left time: 719.0230s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0195s/iter; left time: 349.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1045079\n",
      "\tspeed: 0.0395s/iter; left time: 703.0804s\n",
      "\titers: 200, epoch: 21 | loss: 0.1000956\n",
      "\tspeed: 0.0182s/iter; left time: 321.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1033260 Vali Loss: 0.1208959 Test Loss: 0.1334440\n",
      "Validation loss decreased (0.121249 --> 0.120896).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1021652\n",
      "\tspeed: 0.0389s/iter; left time: 685.0509s\n",
      "\titers: 200, epoch: 22 | loss: 0.1037833\n",
      "\tspeed: 0.0150s/iter; left time: 262.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1031657 Vali Loss: 0.1230096 Test Loss: 0.1364084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1002888\n",
      "\tspeed: 0.0406s/iter; left time: 705.3005s\n",
      "\titers: 200, epoch: 23 | loss: 0.1008182\n",
      "\tspeed: 0.0194s/iter; left time: 335.4528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1030714 Vali Loss: 0.1216729 Test Loss: 0.1350957\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1028795\n",
      "\tspeed: 0.0409s/iter; left time: 701.9342s\n",
      "\titers: 200, epoch: 24 | loss: 0.1033020\n",
      "\tspeed: 0.0202s/iter; left time: 343.8436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.1029641 Vali Loss: 0.1219696 Test Loss: 0.1347010\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1043725\n",
      "\tspeed: 0.0403s/iter; left time: 682.5998s\n",
      "\titers: 200, epoch: 25 | loss: 0.1000242\n",
      "\tspeed: 0.0176s/iter; left time: 296.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.1028489 Vali Loss: 0.1215873 Test Loss: 0.1350457\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1063728\n",
      "\tspeed: 0.0388s/iter; left time: 647.6230s\n",
      "\titers: 200, epoch: 26 | loss: 0.1050431\n",
      "\tspeed: 0.0160s/iter; left time: 264.9969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1026818 Vali Loss: 0.1212678 Test Loss: 0.1344839\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1011360\n",
      "\tspeed: 0.0360s/iter; left time: 593.1095s\n",
      "\titers: 200, epoch: 27 | loss: 0.1029830\n",
      "\tspeed: 0.0195s/iter; left time: 319.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1026702 Vali Loss: 0.1209463 Test Loss: 0.1342177\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1002764\n",
      "\tspeed: 0.0371s/iter; left time: 603.0135s\n",
      "\titers: 200, epoch: 28 | loss: 0.1004969\n",
      "\tspeed: 0.0164s/iter; left time: 264.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1026155 Vali Loss: 0.1208756 Test Loss: 0.1341508\n",
      "Validation loss decreased (0.120896 --> 0.120876).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0999793\n",
      "\tspeed: 0.0363s/iter; left time: 582.2018s\n",
      "\titers: 200, epoch: 29 | loss: 0.1064663\n",
      "\tspeed: 0.0180s/iter; left time: 287.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1025044 Vali Loss: 0.1214741 Test Loss: 0.1346115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1090808\n",
      "\tspeed: 0.0352s/iter; left time: 556.3268s\n",
      "\titers: 200, epoch: 30 | loss: 0.1034467\n",
      "\tspeed: 0.0174s/iter; left time: 272.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1024307 Vali Loss: 0.1210201 Test Loss: 0.1342574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1024209\n",
      "\tspeed: 0.0406s/iter; left time: 632.6446s\n",
      "\titers: 200, epoch: 31 | loss: 0.0992074\n",
      "\tspeed: 0.0189s/iter; left time: 292.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.1023812 Vali Loss: 0.1208797 Test Loss: 0.1342156\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1037238\n",
      "\tspeed: 0.0365s/iter; left time: 560.7188s\n",
      "\titers: 200, epoch: 32 | loss: 0.1089858\n",
      "\tspeed: 0.0164s/iter; left time: 250.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1023219 Vali Loss: 0.1209639 Test Loss: 0.1341527\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1005650\n",
      "\tspeed: 0.0377s/iter; left time: 570.7121s\n",
      "\titers: 200, epoch: 33 | loss: 0.1019282\n",
      "\tspeed: 0.0196s/iter; left time: 295.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.1023162 Vali Loss: 0.1213068 Test Loss: 0.1349990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1046999\n",
      "\tspeed: 0.0372s/iter; left time: 554.5564s\n",
      "\titers: 200, epoch: 34 | loss: 0.1053817\n",
      "\tspeed: 0.0173s/iter; left time: 256.5038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1022506 Vali Loss: 0.1213841 Test Loss: 0.1349961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1020544\n",
      "\tspeed: 0.0355s/iter; left time: 520.7793s\n",
      "\titers: 200, epoch: 35 | loss: 0.1053065\n",
      "\tspeed: 0.0173s/iter; left time: 251.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1022157 Vali Loss: 0.1207118 Test Loss: 0.1340811\n",
      "Validation loss decreased (0.120876 --> 0.120712).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0981926\n",
      "\tspeed: 0.0416s/iter; left time: 601.2769s\n",
      "\titers: 200, epoch: 36 | loss: 0.0985543\n",
      "\tspeed: 0.0178s/iter; left time: 255.4880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1021788 Vali Loss: 0.1213771 Test Loss: 0.1348851\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1025196\n",
      "\tspeed: 0.0356s/iter; left time: 507.1578s\n",
      "\titers: 200, epoch: 37 | loss: 0.1011424\n",
      "\tspeed: 0.0171s/iter; left time: 241.3504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1022137 Vali Loss: 0.1207183 Test Loss: 0.1340209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1000994\n",
      "\tspeed: 0.0359s/iter; left time: 503.6450s\n",
      "\titers: 200, epoch: 38 | loss: 0.1024460\n",
      "\tspeed: 0.0152s/iter; left time: 212.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1021722 Vali Loss: 0.1208874 Test Loss: 0.1342676\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0992368\n",
      "\tspeed: 0.0385s/iter; left time: 530.3256s\n",
      "\titers: 200, epoch: 39 | loss: 0.1020988\n",
      "\tspeed: 0.0204s/iter; left time: 279.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1022097 Vali Loss: 0.1210484 Test Loss: 0.1343632\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1060569\n",
      "\tspeed: 0.0404s/iter; left time: 548.2400s\n",
      "\titers: 200, epoch: 40 | loss: 0.0973268\n",
      "\tspeed: 0.0185s/iter; left time: 248.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1021335 Vali Loss: 0.1211180 Test Loss: 0.1345849\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0997518\n",
      "\tspeed: 0.0347s/iter; left time: 463.1519s\n",
      "\titers: 200, epoch: 41 | loss: 0.0987781\n",
      "\tspeed: 0.0167s/iter; left time: 220.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1020881 Vali Loss: 0.1210136 Test Loss: 0.1346023\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1037596\n",
      "\tspeed: 0.0419s/iter; left time: 549.8865s\n",
      "\titers: 200, epoch: 42 | loss: 0.0988206\n",
      "\tspeed: 0.0183s/iter; left time: 238.5543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1019838 Vali Loss: 0.1208392 Test Loss: 0.1343173\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1050432\n",
      "\tspeed: 0.0369s/iter; left time: 476.0364s\n",
      "\titers: 200, epoch: 43 | loss: 0.0999807\n",
      "\tspeed: 0.0167s/iter; left time: 213.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1020803 Vali Loss: 0.1214528 Test Loss: 0.1353297\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1015238\n",
      "\tspeed: 0.0389s/iter; left time: 492.6111s\n",
      "\titers: 200, epoch: 44 | loss: 0.1047472\n",
      "\tspeed: 0.0151s/iter; left time: 189.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1021086 Vali Loss: 0.1205994 Test Loss: 0.1340761\n",
      "Validation loss decreased (0.120712 --> 0.120599).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1003289\n",
      "\tspeed: 0.0443s/iter; left time: 550.8615s\n",
      "\titers: 200, epoch: 45 | loss: 0.1018850\n",
      "\tspeed: 0.0202s/iter; left time: 249.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.1019150 Vali Loss: 0.1211080 Test Loss: 0.1347190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1009540\n",
      "\tspeed: 0.0350s/iter; left time: 428.1320s\n",
      "\titers: 200, epoch: 46 | loss: 0.1023479\n",
      "\tspeed: 0.0153s/iter; left time: 185.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1020184 Vali Loss: 0.1209162 Test Loss: 0.1344623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1061343\n",
      "\tspeed: 0.0347s/iter; left time: 416.0660s\n",
      "\titers: 200, epoch: 47 | loss: 0.0957267\n",
      "\tspeed: 0.0157s/iter; left time: 187.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1020653 Vali Loss: 0.1209101 Test Loss: 0.1344125\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0963322\n",
      "\tspeed: 0.0383s/iter; left time: 451.4098s\n",
      "\titers: 200, epoch: 48 | loss: 0.1003411\n",
      "\tspeed: 0.0161s/iter; left time: 188.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1020388 Vali Loss: 0.1212396 Test Loss: 0.1348047\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1040895\n",
      "\tspeed: 0.0371s/iter; left time: 428.4823s\n",
      "\titers: 200, epoch: 49 | loss: 0.0982405\n",
      "\tspeed: 0.0180s/iter; left time: 206.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1019909 Vali Loss: 0.1211116 Test Loss: 0.1349357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1047723\n",
      "\tspeed: 0.0351s/iter; left time: 397.5709s\n",
      "\titers: 200, epoch: 50 | loss: 0.1010813\n",
      "\tspeed: 0.0165s/iter; left time: 185.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1018974 Vali Loss: 0.1210461 Test Loss: 0.1346528\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0971058\n",
      "\tspeed: 0.0387s/iter; left time: 430.0573s\n",
      "\titers: 200, epoch: 51 | loss: 0.0997062\n",
      "\tspeed: 0.0166s/iter; left time: 182.4412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1019620 Vali Loss: 0.1212331 Test Loss: 0.1348697\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1007300\n",
      "\tspeed: 0.0347s/iter; left time: 377.7645s\n",
      "\titers: 200, epoch: 52 | loss: 0.1036818\n",
      "\tspeed: 0.0151s/iter; left time: 162.7222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1019240 Vali Loss: 0.1208338 Test Loss: 0.1343024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1008643\n",
      "\tspeed: 0.0399s/iter; left time: 425.5165s\n",
      "\titers: 200, epoch: 53 | loss: 0.1102143\n",
      "\tspeed: 0.0189s/iter; left time: 199.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1019292 Vali Loss: 0.1215294 Test Loss: 0.1354873\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1017581\n",
      "\tspeed: 0.0406s/iter; left time: 423.4259s\n",
      "\titers: 200, epoch: 54 | loss: 0.1050068\n",
      "\tspeed: 0.0187s/iter; left time: 192.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1019801 Vali Loss: 0.1208065 Test Loss: 0.1343537\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04197017848491669, rmse:0.20486624538898468, mae:0.13407617807388306, rse:0.7254727482795715\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2828640\n",
      "\tspeed: 0.0182s/iter; left time: 405.0286s\n",
      "\titers: 200, epoch: 1 | loss: 0.2573094\n",
      "\tspeed: 0.0167s/iter; left time: 370.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.2776463 Vali Loss: 0.2348661 Test Loss: 0.2387750\n",
      "Validation loss decreased (inf --> 0.234866).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1563323\n",
      "\tspeed: 0.0379s/iter; left time: 837.6381s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390097\n",
      "\tspeed: 0.0214s/iter; left time: 470.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1660178 Vali Loss: 0.1412951 Test Loss: 0.1474896\n",
      "Validation loss decreased (0.234866 --> 0.141295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1279419\n",
      "\tspeed: 0.0387s/iter; left time: 845.2143s\n",
      "\titers: 200, epoch: 3 | loss: 0.1227518\n",
      "\tspeed: 0.0180s/iter; left time: 391.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1267834 Vali Loss: 0.1325603 Test Loss: 0.1417641\n",
      "Validation loss decreased (0.141295 --> 0.132560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1186758\n",
      "\tspeed: 0.0363s/iter; left time: 784.8733s\n",
      "\titers: 200, epoch: 4 | loss: 0.1187081\n",
      "\tspeed: 0.0150s/iter; left time: 322.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.1176218 Vali Loss: 0.1300932 Test Loss: 0.1413481\n",
      "Validation loss decreased (0.132560 --> 0.130093).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1111984\n",
      "\tspeed: 0.0398s/iter; left time: 852.7802s\n",
      "\titers: 200, epoch: 5 | loss: 0.1145495\n",
      "\tspeed: 0.0186s/iter; left time: 395.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.1137421 Vali Loss: 0.1287800 Test Loss: 0.1390819\n",
      "Validation loss decreased (0.130093 --> 0.128780).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116873\n",
      "\tspeed: 0.0354s/iter; left time: 750.1321s\n",
      "\titers: 200, epoch: 6 | loss: 0.1175381\n",
      "\tspeed: 0.0150s/iter; left time: 316.8095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1111889 Vali Loss: 0.1264265 Test Loss: 0.1354961\n",
      "Validation loss decreased (0.128780 --> 0.126427).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1079407\n",
      "\tspeed: 0.0352s/iter; left time: 738.6855s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075527\n",
      "\tspeed: 0.0150s/iter; left time: 313.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1093955 Vali Loss: 0.1237439 Test Loss: 0.1325990\n",
      "Validation loss decreased (0.126427 --> 0.123744).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1147573\n",
      "\tspeed: 0.0350s/iter; left time: 725.2179s\n",
      "\titers: 200, epoch: 8 | loss: 0.1143442\n",
      "\tspeed: 0.0150s/iter; left time: 310.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1084551 Vali Loss: 0.1263838 Test Loss: 0.1361008\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1061101\n",
      "\tspeed: 0.0364s/iter; left time: 745.8395s\n",
      "\titers: 200, epoch: 9 | loss: 0.1074078\n",
      "\tspeed: 0.0173s/iter; left time: 353.4508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1071809 Vali Loss: 0.1259529 Test Loss: 0.1362873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1103988\n",
      "\tspeed: 0.0357s/iter; left time: 724.5278s\n",
      "\titers: 200, epoch: 10 | loss: 0.1080133\n",
      "\tspeed: 0.0154s/iter; left time: 309.9724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1067869 Vali Loss: 0.1244481 Test Loss: 0.1345298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1045449\n",
      "\tspeed: 0.0372s/iter; left time: 745.5951s\n",
      "\titers: 200, epoch: 11 | loss: 0.1056255\n",
      "\tspeed: 0.0170s/iter; left time: 339.0164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1059381 Vali Loss: 0.1233591 Test Loss: 0.1340503\n",
      "Validation loss decreased (0.123744 --> 0.123359).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1026241\n",
      "\tspeed: 0.0372s/iter; left time: 737.2249s\n",
      "\titers: 200, epoch: 12 | loss: 0.1058688\n",
      "\tspeed: 0.0178s/iter; left time: 350.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1052782 Vali Loss: 0.1242864 Test Loss: 0.1365494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0983861\n",
      "\tspeed: 0.0437s/iter; left time: 857.5790s\n",
      "\titers: 200, epoch: 13 | loss: 0.1053534\n",
      "\tspeed: 0.0193s/iter; left time: 375.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.1049482 Vali Loss: 0.1240996 Test Loss: 0.1361582\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023027\n",
      "\tspeed: 0.0371s/iter; left time: 718.6730s\n",
      "\titers: 200, epoch: 14 | loss: 0.1065905\n",
      "\tspeed: 0.0153s/iter; left time: 294.8512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1046526 Vali Loss: 0.1252274 Test Loss: 0.1388291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1057217\n",
      "\tspeed: 0.0378s/iter; left time: 724.8215s\n",
      "\titers: 200, epoch: 15 | loss: 0.1015313\n",
      "\tspeed: 0.0189s/iter; left time: 359.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1043697 Vali Loss: 0.1244436 Test Loss: 0.1367521\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1101613\n",
      "\tspeed: 0.0373s/iter; left time: 705.8522s\n",
      "\titers: 200, epoch: 16 | loss: 0.1031625\n",
      "\tspeed: 0.0167s/iter; left time: 314.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1040357 Vali Loss: 0.1240630 Test Loss: 0.1371671\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068942\n",
      "\tspeed: 0.0382s/iter; left time: 715.5962s\n",
      "\titers: 200, epoch: 17 | loss: 0.1008125\n",
      "\tspeed: 0.0181s/iter; left time: 336.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1039329 Vali Loss: 0.1243129 Test Loss: 0.1372844\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1050479\n",
      "\tspeed: 0.0399s/iter; left time: 737.2287s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003110\n",
      "\tspeed: 0.0157s/iter; left time: 289.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1036200 Vali Loss: 0.1230102 Test Loss: 0.1364042\n",
      "Validation loss decreased (0.123359 --> 0.123010).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1040429\n",
      "\tspeed: 0.0416s/iter; left time: 760.1322s\n",
      "\titers: 200, epoch: 19 | loss: 0.0986811\n",
      "\tspeed: 0.0171s/iter; left time: 310.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.1034381 Vali Loss: 0.1230585 Test Loss: 0.1366643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1045177\n",
      "\tspeed: 0.0365s/iter; left time: 658.2951s\n",
      "\titers: 200, epoch: 20 | loss: 0.1002315\n",
      "\tspeed: 0.0151s/iter; left time: 270.6062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.1032201 Vali Loss: 0.1232348 Test Loss: 0.1364671\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1003440\n",
      "\tspeed: 0.0356s/iter; left time: 633.7406s\n",
      "\titers: 200, epoch: 21 | loss: 0.1079771\n",
      "\tspeed: 0.0176s/iter; left time: 311.4710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1032409 Vali Loss: 0.1229962 Test Loss: 0.1363579\n",
      "Validation loss decreased (0.123010 --> 0.122996).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0974193\n",
      "\tspeed: 0.0408s/iter; left time: 717.2477s\n",
      "\titers: 200, epoch: 22 | loss: 0.1055632\n",
      "\tspeed: 0.0153s/iter; left time: 268.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1030024 Vali Loss: 0.1236867 Test Loss: 0.1368668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1045842\n",
      "\tspeed: 0.0369s/iter; left time: 641.3730s\n",
      "\titers: 200, epoch: 23 | loss: 0.1001791\n",
      "\tspeed: 0.0188s/iter; left time: 325.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1028071 Vali Loss: 0.1229351 Test Loss: 0.1367407\n",
      "Validation loss decreased (0.122996 --> 0.122935).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1028660\n",
      "\tspeed: 0.0392s/iter; left time: 671.4293s\n",
      "\titers: 200, epoch: 24 | loss: 0.1030678\n",
      "\tspeed: 0.0173s/iter; left time: 294.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1027307 Vali Loss: 0.1231981 Test Loss: 0.1369780\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1079043\n",
      "\tspeed: 0.0394s/iter; left time: 666.9331s\n",
      "\titers: 200, epoch: 25 | loss: 0.0997485\n",
      "\tspeed: 0.0185s/iter; left time: 310.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.1025618 Vali Loss: 0.1228432 Test Loss: 0.1368074\n",
      "Validation loss decreased (0.122935 --> 0.122843).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1013136\n",
      "\tspeed: 0.0372s/iter; left time: 622.0861s\n",
      "\titers: 200, epoch: 26 | loss: 0.1003264\n",
      "\tspeed: 0.0169s/iter; left time: 281.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1024874 Vali Loss: 0.1222836 Test Loss: 0.1360325\n",
      "Validation loss decreased (0.122843 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1001908\n",
      "\tspeed: 0.0384s/iter; left time: 633.5256s\n",
      "\titers: 200, epoch: 27 | loss: 0.1024758\n",
      "\tspeed: 0.0166s/iter; left time: 271.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1024857 Vali Loss: 0.1232072 Test Loss: 0.1375727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1050656\n",
      "\tspeed: 0.0389s/iter; left time: 632.1202s\n",
      "\titers: 200, epoch: 28 | loss: 0.0989919\n",
      "\tspeed: 0.0161s/iter; left time: 260.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1023387 Vali Loss: 0.1223971 Test Loss: 0.1358186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0992189\n",
      "\tspeed: 0.0367s/iter; left time: 589.0458s\n",
      "\titers: 200, epoch: 29 | loss: 0.0997473\n",
      "\tspeed: 0.0178s/iter; left time: 283.7512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1023556 Vali Loss: 0.1223976 Test Loss: 0.1356400\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1027533\n",
      "\tspeed: 0.0365s/iter; left time: 577.3939s\n",
      "\titers: 200, epoch: 30 | loss: 0.1043150\n",
      "\tspeed: 0.0171s/iter; left time: 268.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1023500 Vali Loss: 0.1224043 Test Loss: 0.1359883\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0997440\n",
      "\tspeed: 0.0408s/iter; left time: 635.1035s\n",
      "\titers: 200, epoch: 31 | loss: 0.1029905\n",
      "\tspeed: 0.0182s/iter; left time: 281.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1021641 Vali Loss: 0.1223458 Test Loss: 0.1359386\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1053476\n",
      "\tspeed: 0.0353s/iter; left time: 541.8460s\n",
      "\titers: 200, epoch: 32 | loss: 0.0999263\n",
      "\tspeed: 0.0150s/iter; left time: 229.1082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1022238 Vali Loss: 0.1222648 Test Loss: 0.1357422\n",
      "Validation loss decreased (0.122284 --> 0.122265).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1003921\n",
      "\tspeed: 0.0393s/iter; left time: 594.1285s\n",
      "\titers: 200, epoch: 33 | loss: 0.1012147\n",
      "\tspeed: 0.0158s/iter; left time: 237.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1020617 Vali Loss: 0.1225676 Test Loss: 0.1362886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1035976\n",
      "\tspeed: 0.0380s/iter; left time: 566.8674s\n",
      "\titers: 200, epoch: 34 | loss: 0.0986196\n",
      "\tspeed: 0.0179s/iter; left time: 264.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1020378 Vali Loss: 0.1226296 Test Loss: 0.1365600\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1064013\n",
      "\tspeed: 0.0370s/iter; left time: 543.6242s\n",
      "\titers: 200, epoch: 35 | loss: 0.1000919\n",
      "\tspeed: 0.0163s/iter; left time: 237.9048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1020877 Vali Loss: 0.1224432 Test Loss: 0.1362459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1011138\n",
      "\tspeed: 0.0440s/iter; left time: 635.9453s\n",
      "\titers: 200, epoch: 36 | loss: 0.1072276\n",
      "\tspeed: 0.0197s/iter; left time: 283.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.1020631 Vali Loss: 0.1221538 Test Loss: 0.1357708\n",
      "Validation loss decreased (0.122265 --> 0.122154).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1004174\n",
      "\tspeed: 0.0368s/iter; left time: 523.2933s\n",
      "\titers: 200, epoch: 37 | loss: 0.0974741\n",
      "\tspeed: 0.0151s/iter; left time: 212.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1019782 Vali Loss: 0.1221450 Test Loss: 0.1356951\n",
      "Validation loss decreased (0.122154 --> 0.122145).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1009666\n",
      "\tspeed: 0.0403s/iter; left time: 565.2086s\n",
      "\titers: 200, epoch: 38 | loss: 0.0958814\n",
      "\tspeed: 0.0170s/iter; left time: 236.3400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1020305 Vali Loss: 0.1218969 Test Loss: 0.1350510\n",
      "Validation loss decreased (0.122145 --> 0.121897).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1072502\n",
      "\tspeed: 0.0380s/iter; left time: 524.2014s\n",
      "\titers: 200, epoch: 39 | loss: 0.1015734\n",
      "\tspeed: 0.0150s/iter; left time: 204.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1019427 Vali Loss: 0.1223282 Test Loss: 0.1358555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1020058\n",
      "\tspeed: 0.0392s/iter; left time: 531.5505s\n",
      "\titers: 200, epoch: 40 | loss: 0.0996480\n",
      "\tspeed: 0.0194s/iter; left time: 261.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.1019052 Vali Loss: 0.1224128 Test Loss: 0.1357289\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1092607\n",
      "\tspeed: 0.0384s/iter; left time: 512.6191s\n",
      "\titers: 200, epoch: 41 | loss: 0.1032982\n",
      "\tspeed: 0.0168s/iter; left time: 222.4329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1018248 Vali Loss: 0.1219604 Test Loss: 0.1354129\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1021474\n",
      "\tspeed: 0.0354s/iter; left time: 464.0011s\n",
      "\titers: 200, epoch: 42 | loss: 0.1040739\n",
      "\tspeed: 0.0151s/iter; left time: 196.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1018259 Vali Loss: 0.1223762 Test Loss: 0.1359084\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1060762\n",
      "\tspeed: 0.0352s/iter; left time: 454.0660s\n",
      "\titers: 200, epoch: 43 | loss: 0.1048280\n",
      "\tspeed: 0.0150s/iter; left time: 191.7680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1018107 Vali Loss: 0.1225776 Test Loss: 0.1364729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1029061\n",
      "\tspeed: 0.0387s/iter; left time: 490.8172s\n",
      "\titers: 200, epoch: 44 | loss: 0.0994365\n",
      "\tspeed: 0.0201s/iter; left time: 252.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1018751 Vali Loss: 0.1224436 Test Loss: 0.1361720\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0998201\n",
      "\tspeed: 0.0371s/iter; left time: 462.1158s\n",
      "\titers: 200, epoch: 45 | loss: 0.1050539\n",
      "\tspeed: 0.0161s/iter; left time: 198.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1018009 Vali Loss: 0.1221234 Test Loss: 0.1355880\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0982425\n",
      "\tspeed: 0.0350s/iter; left time: 428.2124s\n",
      "\titers: 200, epoch: 46 | loss: 0.1004094\n",
      "\tspeed: 0.0150s/iter; left time: 181.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1018462 Vali Loss: 0.1224753 Test Loss: 0.1361422\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1004537\n",
      "\tspeed: 0.0369s/iter; left time: 442.1484s\n",
      "\titers: 200, epoch: 47 | loss: 0.0961077\n",
      "\tspeed: 0.0183s/iter; left time: 217.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1018180 Vali Loss: 0.1223693 Test Loss: 0.1359236\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1002767\n",
      "\tspeed: 0.0388s/iter; left time: 457.3260s\n",
      "\titers: 200, epoch: 48 | loss: 0.1010218\n",
      "\tspeed: 0.0166s/iter; left time: 193.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1018113 Vali Loss: 0.1223205 Test Loss: 0.1361200\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04309926554560661, rmse:0.20760363340377808, mae:0.13505104184150696, rse:0.7351664304733276\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:34.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0382s/iter; left time: 848.8174s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0156s/iter; left time: 344.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0372s/iter; left time: 818.3546s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0155s/iter; left time: 339.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0382s/iter; left time: 830.8239s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0162s/iter; left time: 350.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0385s/iter; left time: 828.3529s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0183s/iter; left time: 392.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0420s/iter; left time: 895.0981s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0165s/iter; left time: 350.0126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0384s/iter; left time: 809.6195s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0180s/iter; left time: 378.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0397s/iter; left time: 827.5598s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0180s/iter; left time: 373.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0413s/iter; left time: 851.4673s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0177s/iter; left time: 363.5561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0385s/iter; left time: 787.0536s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0174s/iter; left time: 353.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0385s/iter; left time: 778.4035s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0178s/iter; left time: 358.0489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0358s/iter; left time: 714.3567s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0151s/iter; left time: 300.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0418s/iter; left time: 825.8704s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0167s/iter; left time: 327.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0355s/iter; left time: 692.2577s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0152s/iter; left time: 294.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0413s/iter; left time: 797.1496s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0224s/iter; left time: 429.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0409s/iter; left time: 779.6283s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0204s/iter; left time: 387.5559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0392s/iter; left time: 738.2500s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0199s/iter; left time: 373.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0399s/iter; left time: 744.1097s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0189s/iter; left time: 350.2800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0419s/iter; left time: 771.1488s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0207s/iter; left time: 378.8567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0406s/iter; left time: 737.8984s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0202s/iter; left time: 364.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1128351\n",
      "\tspeed: 0.0411s/iter; left time: 738.8429s\n",
      "\titers: 200, epoch: 20 | loss: 0.1115036\n",
      "\tspeed: 0.0226s/iter; left time: 403.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.1088133 Vali Loss: 0.1296562 Test Loss: 0.1430260\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1089209\n",
      "\tspeed: 0.0428s/iter; left time: 760.0056s\n",
      "\titers: 200, epoch: 21 | loss: 0.1049455\n",
      "\tspeed: 0.0182s/iter; left time: 320.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1087389 Vali Loss: 0.1280911 Test Loss: 0.1400650\n",
      "Validation loss decreased (0.128590 --> 0.128091).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1089510\n",
      "\tspeed: 0.0391s/iter; left time: 684.7425s\n",
      "\titers: 200, epoch: 22 | loss: 0.1118146\n",
      "\tspeed: 0.0170s/iter; left time: 296.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1085359 Vali Loss: 0.1289085 Test Loss: 0.1414145\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1127648\n",
      "\tspeed: 0.0366s/iter; left time: 632.6790s\n",
      "\titers: 200, epoch: 23 | loss: 0.1073037\n",
      "\tspeed: 0.0183s/iter; left time: 314.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1083876 Vali Loss: 0.1286885 Test Loss: 0.1415340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1052145\n",
      "\tspeed: 0.0399s/iter; left time: 680.4464s\n",
      "\titers: 200, epoch: 24 | loss: 0.1095430\n",
      "\tspeed: 0.0187s/iter; left time: 316.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1081785 Vali Loss: 0.1283687 Test Loss: 0.1406554\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1106745\n",
      "\tspeed: 0.0395s/iter; left time: 665.7148s\n",
      "\titers: 200, epoch: 25 | loss: 0.1078078\n",
      "\tspeed: 0.0167s/iter; left time: 279.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1080985 Vali Loss: 0.1285096 Test Loss: 0.1409658\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1090272\n",
      "\tspeed: 0.0376s/iter; left time: 625.5190s\n",
      "\titers: 200, epoch: 26 | loss: 0.1082668\n",
      "\tspeed: 0.0182s/iter; left time: 300.2094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1080526 Vali Loss: 0.1276924 Test Loss: 0.1404647\n",
      "Validation loss decreased (0.128091 --> 0.127692).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1094660\n",
      "\tspeed: 0.0390s/iter; left time: 639.2888s\n",
      "\titers: 200, epoch: 27 | loss: 0.1094127\n",
      "\tspeed: 0.0167s/iter; left time: 272.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1079262 Vali Loss: 0.1288600 Test Loss: 0.1418495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1063156\n",
      "\tspeed: 0.0427s/iter; left time: 690.3855s\n",
      "\titers: 200, epoch: 28 | loss: 0.1129479\n",
      "\tspeed: 0.0202s/iter; left time: 325.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.1077841 Vali Loss: 0.1282874 Test Loss: 0.1410196\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1066447\n",
      "\tspeed: 0.0369s/iter; left time: 589.4292s\n",
      "\titers: 200, epoch: 29 | loss: 0.1012538\n",
      "\tspeed: 0.0192s/iter; left time: 304.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1077484 Vali Loss: 0.1283567 Test Loss: 0.1414497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1091326\n",
      "\tspeed: 0.0411s/iter; left time: 647.2593s\n",
      "\titers: 200, epoch: 30 | loss: 0.1057610\n",
      "\tspeed: 0.0195s/iter; left time: 304.5488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.1076596 Vali Loss: 0.1288015 Test Loss: 0.1421737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1129125\n",
      "\tspeed: 0.0388s/iter; left time: 601.6093s\n",
      "\titers: 200, epoch: 31 | loss: 0.1121067\n",
      "\tspeed: 0.0174s/iter; left time: 268.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1076513 Vali Loss: 0.1288997 Test Loss: 0.1427089\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1074071\n",
      "\tspeed: 0.0371s/iter; left time: 566.4617s\n",
      "\titers: 200, epoch: 32 | loss: 0.1050972\n",
      "\tspeed: 0.0187s/iter; left time: 284.2687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1075939 Vali Loss: 0.1285509 Test Loss: 0.1420687\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1064574\n",
      "\tspeed: 0.0383s/iter; left time: 576.8595s\n",
      "\titers: 200, epoch: 33 | loss: 0.1079464\n",
      "\tspeed: 0.0183s/iter; left time: 274.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.1075518 Vali Loss: 0.1277073 Test Loss: 0.1409436\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1094171\n",
      "\tspeed: 0.0376s/iter; left time: 557.8062s\n",
      "\titers: 200, epoch: 34 | loss: 0.1012441\n",
      "\tspeed: 0.0181s/iter; left time: 266.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1075745 Vali Loss: 0.1284703 Test Loss: 0.1418752\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1087584\n",
      "\tspeed: 0.0385s/iter; left time: 562.4644s\n",
      "\titers: 200, epoch: 35 | loss: 0.1107625\n",
      "\tspeed: 0.0196s/iter; left time: 284.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1074390 Vali Loss: 0.1280550 Test Loss: 0.1412895\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1054707\n",
      "\tspeed: 0.0394s/iter; left time: 566.9974s\n",
      "\titers: 200, epoch: 36 | loss: 0.1052480\n",
      "\tspeed: 0.0172s/iter; left time: 246.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1074146 Vali Loss: 0.1279779 Test Loss: 0.1416783\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.044552285224199295, rmse:0.2110741287469864, mae:0.14046476781368256, rse:0.7476415038108826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2744991\n",
      "\tspeed: 0.0206s/iter; left time: 456.9277s\n",
      "\titers: 200, epoch: 1 | loss: 0.2641147\n",
      "\tspeed: 0.0172s/iter; left time: 380.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.2783999 Vali Loss: 0.2379947 Test Loss: 0.2423942\n",
      "Validation loss decreased (inf --> 0.237995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1556567\n",
      "\tspeed: 0.0406s/iter; left time: 891.8201s\n",
      "\titers: 200, epoch: 2 | loss: 0.1396492\n",
      "\tspeed: 0.0171s/iter; left time: 373.0223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1671781 Vali Loss: 0.1447358 Test Loss: 0.1522740\n",
      "Validation loss decreased (0.237995 --> 0.144736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1281172\n",
      "\tspeed: 0.0386s/iter; left time: 839.4217s\n",
      "\titers: 200, epoch: 3 | loss: 0.1312603\n",
      "\tspeed: 0.0161s/iter; left time: 347.7618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1311306 Vali Loss: 0.1353014 Test Loss: 0.1466275\n",
      "Validation loss decreased (0.144736 --> 0.135301).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1211887\n",
      "\tspeed: 0.0393s/iter; left time: 846.7988s\n",
      "\titers: 200, epoch: 4 | loss: 0.1183547\n",
      "\tspeed: 0.0213s/iter; left time: 456.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1229378 Vali Loss: 0.1342717 Test Loss: 0.1467632\n",
      "Validation loss decreased (0.135301 --> 0.134272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1239808\n",
      "\tspeed: 0.0436s/iter; left time: 928.7595s\n",
      "\titers: 200, epoch: 5 | loss: 0.1168796\n",
      "\tspeed: 0.0196s/iter; left time: 414.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1192592 Vali Loss: 0.1300050 Test Loss: 0.1415242\n",
      "Validation loss decreased (0.134272 --> 0.130005).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1182984\n",
      "\tspeed: 0.0404s/iter; left time: 851.0708s\n",
      "\titers: 200, epoch: 6 | loss: 0.1171903\n",
      "\tspeed: 0.0169s/iter; left time: 355.6899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1166339 Vali Loss: 0.1296393 Test Loss: 0.1407897\n",
      "Validation loss decreased (0.130005 --> 0.129639).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1194612\n",
      "\tspeed: 0.0423s/iter; left time: 882.7807s\n",
      "\titers: 200, epoch: 7 | loss: 0.1164228\n",
      "\tspeed: 0.0192s/iter; left time: 399.2528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.1154953 Vali Loss: 0.1325710 Test Loss: 0.1433164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1124757\n",
      "\tspeed: 0.0382s/iter; left time: 789.3227s\n",
      "\titers: 200, epoch: 8 | loss: 0.1162293\n",
      "\tspeed: 0.0151s/iter; left time: 309.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1143113 Vali Loss: 0.1291094 Test Loss: 0.1404415\n",
      "Validation loss decreased (0.129639 --> 0.129109).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1146200\n",
      "\tspeed: 0.0373s/iter; left time: 760.6379s\n",
      "\titers: 200, epoch: 9 | loss: 0.1169974\n",
      "\tspeed: 0.0173s/iter; left time: 350.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1132893 Vali Loss: 0.1273294 Test Loss: 0.1382572\n",
      "Validation loss decreased (0.129109 --> 0.127329).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1129709\n",
      "\tspeed: 0.0379s/iter; left time: 764.7611s\n",
      "\titers: 200, epoch: 10 | loss: 0.1146486\n",
      "\tspeed: 0.0286s/iter; left time: 574.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.1127601 Vali Loss: 0.1269920 Test Loss: 0.1385130\n",
      "Validation loss decreased (0.127329 --> 0.126992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1098697\n",
      "\tspeed: 0.0438s/iter; left time: 874.7056s\n",
      "\titers: 200, epoch: 11 | loss: 0.1127002\n",
      "\tspeed: 0.0226s/iter; left time: 448.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.1122303 Vali Loss: 0.1296180 Test Loss: 0.1411653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1178860\n",
      "\tspeed: 0.0534s/iter; left time: 1053.5905s\n",
      "\titers: 200, epoch: 12 | loss: 0.1080562\n",
      "\tspeed: 0.0204s/iter; left time: 400.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.1117056 Vali Loss: 0.1294848 Test Loss: 0.1418801\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1112355\n",
      "\tspeed: 0.0397s/iter; left time: 775.6883s\n",
      "\titers: 200, epoch: 13 | loss: 0.1111286\n",
      "\tspeed: 0.0190s/iter; left time: 368.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1112279 Vali Loss: 0.1293019 Test Loss: 0.1417095\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1033714\n",
      "\tspeed: 0.0489s/iter; left time: 944.7335s\n",
      "\titers: 200, epoch: 14 | loss: 0.1122320\n",
      "\tspeed: 0.0261s/iter; left time: 501.9400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.1108339 Vali Loss: 0.1286721 Test Loss: 0.1407368\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1146212\n",
      "\tspeed: 0.0380s/iter; left time: 724.0625s\n",
      "\titers: 200, epoch: 15 | loss: 0.1127912\n",
      "\tspeed: 0.0151s/iter; left time: 286.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.1104134 Vali Loss: 0.1296972 Test Loss: 0.1427345\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1112949\n",
      "\tspeed: 0.0381s/iter; left time: 718.0151s\n",
      "\titers: 200, epoch: 16 | loss: 0.1096983\n",
      "\tspeed: 0.0174s/iter; left time: 325.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.1101559 Vali Loss: 0.1271977 Test Loss: 0.1399690\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1107738\n",
      "\tspeed: 0.0436s/iter; left time: 812.9675s\n",
      "\titers: 200, epoch: 17 | loss: 0.1145247\n",
      "\tspeed: 0.0230s/iter; left time: 425.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.1098280 Vali Loss: 0.1279991 Test Loss: 0.1410300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1091873\n",
      "\tspeed: 0.0421s/iter; left time: 775.8550s\n",
      "\titers: 200, epoch: 18 | loss: 0.1066963\n",
      "\tspeed: 0.0186s/iter; left time: 340.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.1097318 Vali Loss: 0.1293264 Test Loss: 0.1422503\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1057076\n",
      "\tspeed: 0.0419s/iter; left time: 761.4071s\n",
      "\titers: 200, epoch: 19 | loss: 0.1163264\n",
      "\tspeed: 0.0171s/iter; left time: 309.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1094545 Vali Loss: 0.1284010 Test Loss: 0.1421688\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1145523\n",
      "\tspeed: 0.0426s/iter; left time: 765.5492s\n",
      "\titers: 200, epoch: 20 | loss: 0.1089584\n",
      "\tspeed: 0.0184s/iter; left time: 329.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.1092729 Vali Loss: 0.1282443 Test Loss: 0.1419774\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04232504218816757, rmse:0.20573051273822784, mae:0.1385130137205124, rse:0.7287139892578125\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:41.48s\n",
      "Intermediate time for DE: 00h:23m:24.14s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0370s/iter; left time: 824.5282s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0150s/iter; left time: 333.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0345s/iter; left time: 761.8591s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0161s/iter; left time: 353.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0394s/iter; left time: 861.6083s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0153s/iter; left time: 332.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0349s/iter; left time: 754.3360s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0163s/iter; left time: 351.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0348s/iter; left time: 745.7010s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0149s/iter; left time: 318.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0419s/iter; left time: 886.7013s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0223s/iter; left time: 469.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0383s/iter; left time: 802.1478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0173s/iter; left time: 360.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0414s/iter; left time: 858.1037s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0231s/iter; left time: 477.0760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0387s/iter; left time: 794.1059s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0178s/iter; left time: 362.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0375s/iter; left time: 761.2224s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0184s/iter; left time: 372.3176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0381s/iter; left time: 764.6219s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0157s/iter; left time: 312.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0413s/iter; left time: 819.6811s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0183s/iter; left time: 361.6709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0433s/iter; left time: 848.7114s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0202s/iter; left time: 393.4633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0393s/iter; left time: 762.7934s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0222s/iter; left time: 428.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0353s/iter; left time: 677.0284s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0150s/iter; left time: 285.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0447s/iter; left time: 845.9144s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0255s/iter; left time: 479.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0362s/iter; left time: 676.6326s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0188s/iter; left time: 349.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0380s/iter; left time: 703.1697s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0161s/iter; left time: 295.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0381s/iter; left time: 695.4125s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0170s/iter; left time: 308.1008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0430s/iter; left time: 775.5576s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0248s/iter; left time: 445.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0764413\n",
      "\tspeed: 0.0428s/iter; left time: 763.4639s\n",
      "\titers: 200, epoch: 21 | loss: 0.0775579\n",
      "\tspeed: 0.0171s/iter; left time: 302.4760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0794832 Vali Loss: 0.0922160 Test Loss: 0.1059103\n",
      "Validation loss decreased (0.092648 --> 0.092216).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0750777\n",
      "\tspeed: 0.0396s/iter; left time: 697.4965s\n",
      "\titers: 200, epoch: 22 | loss: 0.0767003\n",
      "\tspeed: 0.0150s/iter; left time: 261.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0793035 Vali Loss: 0.0922287 Test Loss: 0.1062462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0774668\n",
      "\tspeed: 0.0386s/iter; left time: 669.8839s\n",
      "\titers: 200, epoch: 23 | loss: 0.0764778\n",
      "\tspeed: 0.0201s/iter; left time: 347.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0791268 Vali Loss: 0.0925499 Test Loss: 0.1060301\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0832801\n",
      "\tspeed: 0.0409s/iter; left time: 701.5546s\n",
      "\titers: 200, epoch: 24 | loss: 0.0814398\n",
      "\tspeed: 0.0162s/iter; left time: 276.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0789638 Vali Loss: 0.0924772 Test Loss: 0.1064283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0800643\n",
      "\tspeed: 0.0383s/iter; left time: 648.5225s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791814\n",
      "\tspeed: 0.0173s/iter; left time: 290.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0789486 Vali Loss: 0.0930298 Test Loss: 0.1066121\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796904\n",
      "\tspeed: 0.0372s/iter; left time: 621.3590s\n",
      "\titers: 200, epoch: 26 | loss: 0.0771316\n",
      "\tspeed: 0.0164s/iter; left time: 272.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0790268 Vali Loss: 0.0925604 Test Loss: 0.1061667\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0826450\n",
      "\tspeed: 0.0367s/iter; left time: 604.2840s\n",
      "\titers: 200, epoch: 27 | loss: 0.0831101\n",
      "\tspeed: 0.0178s/iter; left time: 290.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0788740 Vali Loss: 0.0926468 Test Loss: 0.1061734\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819598\n",
      "\tspeed: 0.0361s/iter; left time: 587.1653s\n",
      "\titers: 200, epoch: 28 | loss: 0.0791325\n",
      "\tspeed: 0.0178s/iter; left time: 288.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0787329 Vali Loss: 0.0931808 Test Loss: 0.1070156\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0808779\n",
      "\tspeed: 0.0358s/iter; left time: 573.4745s\n",
      "\titers: 200, epoch: 29 | loss: 0.0794952\n",
      "\tspeed: 0.0170s/iter; left time: 270.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0787373 Vali Loss: 0.0925326 Test Loss: 0.1062035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0786930\n",
      "\tspeed: 0.0383s/iter; left time: 605.7836s\n",
      "\titers: 200, epoch: 30 | loss: 0.0793163\n",
      "\tspeed: 0.0162s/iter; left time: 254.7686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0786670 Vali Loss: 0.0929713 Test Loss: 0.1066934\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0800112\n",
      "\tspeed: 0.0344s/iter; left time: 535.6936s\n",
      "\titers: 200, epoch: 31 | loss: 0.0791296\n",
      "\tspeed: 0.0152s/iter; left time: 234.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0786878 Vali Loss: 0.0922258 Test Loss: 0.1064776\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02694176509976387, rmse:0.16413946449756622, mae:0.10591025650501251, rse:0.5662346482276917\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2908871\n",
      "\tspeed: 0.0221s/iter; left time: 492.7939s\n",
      "\titers: 200, epoch: 1 | loss: 0.2730023\n",
      "\tspeed: 0.0185s/iter; left time: 410.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.2871942 Vali Loss: 0.2444913 Test Loss: 0.2645374\n",
      "Validation loss decreased (inf --> 0.244491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410559\n",
      "\tspeed: 0.0463s/iter; left time: 1022.1986s\n",
      "\titers: 200, epoch: 2 | loss: 0.1104743\n",
      "\tspeed: 0.0173s/iter; left time: 380.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.1550662 Vali Loss: 0.1082898 Test Loss: 0.1234926\n",
      "Validation loss decreased (0.244491 --> 0.108290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023160\n",
      "\tspeed: 0.0420s/iter; left time: 916.8042s\n",
      "\titers: 200, epoch: 3 | loss: 0.0967745\n",
      "\tspeed: 0.0189s/iter; left time: 412.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1025424 Vali Loss: 0.0974422 Test Loss: 0.1096326\n",
      "Validation loss decreased (0.108290 --> 0.097442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971604\n",
      "\tspeed: 0.0376s/iter; left time: 814.1259s\n",
      "\titers: 200, epoch: 4 | loss: 0.0899035\n",
      "\tspeed: 0.0159s/iter; left time: 342.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0924125 Vali Loss: 0.0978540 Test Loss: 0.1130235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0846692\n",
      "\tspeed: 0.0360s/iter; left time: 771.1934s\n",
      "\titers: 200, epoch: 5 | loss: 0.0906144\n",
      "\tspeed: 0.0184s/iter; left time: 392.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0882784 Vali Loss: 0.0959395 Test Loss: 0.1097864\n",
      "Validation loss decreased (0.097442 --> 0.095939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0848261\n",
      "\tspeed: 0.0395s/iter; left time: 837.5436s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811776\n",
      "\tspeed: 0.0198s/iter; left time: 416.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0862749 Vali Loss: 0.0952228 Test Loss: 0.1090894\n",
      "Validation loss decreased (0.095939 --> 0.095223).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828368\n",
      "\tspeed: 0.0420s/iter; left time: 880.8816s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865732\n",
      "\tspeed: 0.0227s/iter; left time: 472.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0847028 Vali Loss: 0.0939569 Test Loss: 0.1076050\n",
      "Validation loss decreased (0.095223 --> 0.093957).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0787013\n",
      "\tspeed: 0.0417s/iter; left time: 865.2214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0853842\n",
      "\tspeed: 0.0200s/iter; left time: 411.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0837123 Vali Loss: 0.0937281 Test Loss: 0.1069735\n",
      "Validation loss decreased (0.093957 --> 0.093728).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0831238\n",
      "\tspeed: 0.0420s/iter; left time: 860.6982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0829130\n",
      "\tspeed: 0.0193s/iter; left time: 393.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0831108 Vali Loss: 0.0937356 Test Loss: 0.1065833\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833643\n",
      "\tspeed: 0.0375s/iter; left time: 760.1743s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843041\n",
      "\tspeed: 0.0226s/iter; left time: 456.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0823158 Vali Loss: 0.0933490 Test Loss: 0.1061504\n",
      "Validation loss decreased (0.093728 --> 0.093349).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775133\n",
      "\tspeed: 0.0371s/iter; left time: 743.6221s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786133\n",
      "\tspeed: 0.0214s/iter; left time: 428.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0816524 Vali Loss: 0.0931040 Test Loss: 0.1061128\n",
      "Validation loss decreased (0.093349 --> 0.093104).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781198\n",
      "\tspeed: 0.0348s/iter; left time: 690.8861s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837125\n",
      "\tspeed: 0.0167s/iter; left time: 328.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0814042 Vali Loss: 0.0932580 Test Loss: 0.1064448\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783289\n",
      "\tspeed: 0.0397s/iter; left time: 778.0110s\n",
      "\titers: 200, epoch: 13 | loss: 0.0794865\n",
      "\tspeed: 0.0179s/iter; left time: 348.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0810518 Vali Loss: 0.0928836 Test Loss: 0.1061874\n",
      "Validation loss decreased (0.093104 --> 0.092884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0789644\n",
      "\tspeed: 0.0368s/iter; left time: 714.0465s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794672\n",
      "\tspeed: 0.0209s/iter; left time: 403.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0806366 Vali Loss: 0.0932994 Test Loss: 0.1063543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803705\n",
      "\tspeed: 0.0397s/iter; left time: 761.7666s\n",
      "\titers: 200, epoch: 15 | loss: 0.0816594\n",
      "\tspeed: 0.0171s/iter; left time: 325.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0804825 Vali Loss: 0.0927894 Test Loss: 0.1060549\n",
      "Validation loss decreased (0.092884 --> 0.092789).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0874846\n",
      "\tspeed: 0.0369s/iter; left time: 698.0849s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787541\n",
      "\tspeed: 0.0163s/iter; left time: 307.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0802071 Vali Loss: 0.0927323 Test Loss: 0.1055353\n",
      "Validation loss decreased (0.092789 --> 0.092732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0764223\n",
      "\tspeed: 0.0372s/iter; left time: 696.2161s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876672\n",
      "\tspeed: 0.0175s/iter; left time: 325.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0799835 Vali Loss: 0.0934802 Test Loss: 0.1060668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0816835\n",
      "\tspeed: 0.0389s/iter; left time: 718.4657s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795193\n",
      "\tspeed: 0.0175s/iter; left time: 321.3703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0797706 Vali Loss: 0.0924805 Test Loss: 0.1056486\n",
      "Validation loss decreased (0.092732 --> 0.092481).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758096\n",
      "\tspeed: 0.0365s/iter; left time: 667.6746s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759346\n",
      "\tspeed: 0.0174s/iter; left time: 316.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0795556 Vali Loss: 0.0926971 Test Loss: 0.1054964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764526\n",
      "\tspeed: 0.0376s/iter; left time: 677.6381s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820286\n",
      "\tspeed: 0.0174s/iter; left time: 311.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0795062 Vali Loss: 0.0923530 Test Loss: 0.1052698\n",
      "Validation loss decreased (0.092481 --> 0.092353).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799056\n",
      "\tspeed: 0.0363s/iter; left time: 647.6149s\n",
      "\titers: 200, epoch: 21 | loss: 0.0803694\n",
      "\tspeed: 0.0157s/iter; left time: 277.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0794412 Vali Loss: 0.0931432 Test Loss: 0.1060107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0748962\n",
      "\tspeed: 0.0420s/iter; left time: 738.5753s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796375\n",
      "\tspeed: 0.0231s/iter; left time: 403.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0792102 Vali Loss: 0.0926149 Test Loss: 0.1056100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758943\n",
      "\tspeed: 0.0434s/iter; left time: 754.6469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753200\n",
      "\tspeed: 0.0201s/iter; left time: 346.8913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0790810 Vali Loss: 0.0926582 Test Loss: 0.1055936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778612\n",
      "\tspeed: 0.0365s/iter; left time: 626.6173s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780891\n",
      "\tspeed: 0.0170s/iter; left time: 290.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0790612 Vali Loss: 0.0927992 Test Loss: 0.1057558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0871981\n",
      "\tspeed: 0.0379s/iter; left time: 641.1117s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760559\n",
      "\tspeed: 0.0232s/iter; left time: 389.7310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0789873 Vali Loss: 0.0921219 Test Loss: 0.1052446\n",
      "Validation loss decreased (0.092353 --> 0.092122).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0782320\n",
      "\tspeed: 0.0424s/iter; left time: 707.5859s\n",
      "\titers: 200, epoch: 26 | loss: 0.0788959\n",
      "\tspeed: 0.0221s/iter; left time: 367.3914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0788905 Vali Loss: 0.0928220 Test Loss: 0.1057923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0744453\n",
      "\tspeed: 0.0416s/iter; left time: 685.7626s\n",
      "\titers: 200, epoch: 27 | loss: 0.0798820\n",
      "\tspeed: 0.0203s/iter; left time: 331.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0787206 Vali Loss: 0.0923934 Test Loss: 0.1054663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0831386\n",
      "\tspeed: 0.0355s/iter; left time: 576.8405s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728892\n",
      "\tspeed: 0.0155s/iter; left time: 249.9144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0786545 Vali Loss: 0.0922845 Test Loss: 0.1054097\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0778653\n",
      "\tspeed: 0.0398s/iter; left time: 637.8742s\n",
      "\titers: 200, epoch: 29 | loss: 0.0719146\n",
      "\tspeed: 0.0216s/iter; left time: 343.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0787976 Vali Loss: 0.0923579 Test Loss: 0.1054754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0685690\n",
      "\tspeed: 0.0417s/iter; left time: 659.5133s\n",
      "\titers: 200, epoch: 30 | loss: 0.0806209\n",
      "\tspeed: 0.0225s/iter; left time: 352.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0786865 Vali Loss: 0.0927233 Test Loss: 0.1057628\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0726656\n",
      "\tspeed: 0.0365s/iter; left time: 568.5230s\n",
      "\titers: 200, epoch: 31 | loss: 0.0773063\n",
      "\tspeed: 0.0187s/iter; left time: 290.2385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0785973 Vali Loss: 0.0921454 Test Loss: 0.1053599\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816479\n",
      "\tspeed: 0.0363s/iter; left time: 556.8488s\n",
      "\titers: 200, epoch: 32 | loss: 0.0817126\n",
      "\tspeed: 0.0231s/iter; left time: 351.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0786178 Vali Loss: 0.0923548 Test Loss: 0.1056355\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0773016\n",
      "\tspeed: 0.0379s/iter; left time: 573.2286s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803075\n",
      "\tspeed: 0.0160s/iter; left time: 240.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0786045 Vali Loss: 0.0921716 Test Loss: 0.1053509\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754239\n",
      "\tspeed: 0.0375s/iter; left time: 558.7915s\n",
      "\titers: 200, epoch: 34 | loss: 0.0827927\n",
      "\tspeed: 0.0175s/iter; left time: 258.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0784336 Vali Loss: 0.0923538 Test Loss: 0.1054920\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0799392\n",
      "\tspeed: 0.0415s/iter; left time: 609.5608s\n",
      "\titers: 200, epoch: 35 | loss: 0.0800448\n",
      "\tspeed: 0.0178s/iter; left time: 259.9136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0785155 Vali Loss: 0.0923782 Test Loss: 0.1055542\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026500752195715904, rmse:0.16279052197933197, mae:0.10524464398622513, rse:0.5615811347961426\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:28.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0398s/iter; left time: 886.6959s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0189s/iter; left time: 419.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0378s/iter; left time: 834.7479s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0165s/iter; left time: 363.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0366s/iter; left time: 799.2570s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0152s/iter; left time: 330.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0365s/iter; left time: 788.8688s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0152s/iter; left time: 326.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0388s/iter; left time: 830.3841s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0197s/iter; left time: 419.5733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0396s/iter; left time: 838.9470s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0233s/iter; left time: 491.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0376s/iter; left time: 788.6372s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0157s/iter; left time: 328.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0408s/iter; left time: 845.1591s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0178s/iter; left time: 368.2739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0362s/iter; left time: 743.1145s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0152s/iter; left time: 310.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0371s/iter; left time: 752.5210s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0192s/iter; left time: 387.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0365s/iter; left time: 731.9378s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0151s/iter; left time: 301.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0378s/iter; left time: 749.8593s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0152s/iter; left time: 300.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0378s/iter; left time: 740.8573s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0169s/iter; left time: 329.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0382s/iter; left time: 739.8559s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0178s/iter; left time: 342.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0382s/iter; left time: 731.9471s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0172s/iter; left time: 328.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0382s/iter; left time: 724.4724s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0184s/iter; left time: 346.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1045979\n",
      "\tspeed: 0.0371s/iter; left time: 695.1403s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060435\n",
      "\tspeed: 0.0178s/iter; left time: 331.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1029846 Vali Loss: 0.1258308 Test Loss: 0.1572115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1049089\n",
      "\tspeed: 0.0396s/iter; left time: 732.6263s\n",
      "\titers: 200, epoch: 18 | loss: 0.1004239\n",
      "\tspeed: 0.0163s/iter; left time: 299.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1027992 Vali Loss: 0.1261423 Test Loss: 0.1578836\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1043303\n",
      "\tspeed: 0.0441s/iter; left time: 805.6231s\n",
      "\titers: 200, epoch: 19 | loss: 0.1018612\n",
      "\tspeed: 0.0214s/iter; left time: 388.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.1026257 Vali Loss: 0.1258573 Test Loss: 0.1567056\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1031136\n",
      "\tspeed: 0.0358s/iter; left time: 645.3945s\n",
      "\titers: 200, epoch: 20 | loss: 0.1018248\n",
      "\tspeed: 0.0153s/iter; left time: 274.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1024617 Vali Loss: 0.1246465 Test Loss: 0.1569057\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1018606\n",
      "\tspeed: 0.0398s/iter; left time: 710.0420s\n",
      "\titers: 200, epoch: 21 | loss: 0.0991599\n",
      "\tspeed: 0.0206s/iter; left time: 364.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1023430 Vali Loss: 0.1247049 Test Loss: 0.1567344\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2915673\n",
      "\tspeed: 0.0246s/iter; left time: 549.4115s\n",
      "\titers: 200, epoch: 1 | loss: 0.2674311\n",
      "\tspeed: 0.0225s/iter; left time: 499.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.2916491 Vali Loss: 0.2483680 Test Loss: 0.2712487\n",
      "Validation loss decreased (inf --> 0.248368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456207\n",
      "\tspeed: 0.0385s/iter; left time: 849.0615s\n",
      "\titers: 200, epoch: 2 | loss: 0.1379834\n",
      "\tspeed: 0.0177s/iter; left time: 387.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1630503 Vali Loss: 0.1345576 Test Loss: 0.1575292\n",
      "Validation loss decreased (0.248368 --> 0.134558).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1188209\n",
      "\tspeed: 0.0406s/iter; left time: 886.3766s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203921\n",
      "\tspeed: 0.0185s/iter; left time: 402.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1200628 Vali Loss: 0.1257125 Test Loss: 0.1526250\n",
      "Validation loss decreased (0.134558 --> 0.125713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1143665\n",
      "\tspeed: 0.0448s/iter; left time: 968.1767s\n",
      "\titers: 200, epoch: 4 | loss: 0.1150253\n",
      "\tspeed: 0.0216s/iter; left time: 465.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.1123677 Vali Loss: 0.1259064 Test Loss: 0.1581046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095381\n",
      "\tspeed: 0.0368s/iter; left time: 786.8088s\n",
      "\titers: 200, epoch: 5 | loss: 0.1060184\n",
      "\tspeed: 0.0149s/iter; left time: 318.4479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1096526 Vali Loss: 0.1241158 Test Loss: 0.1530023\n",
      "Validation loss decreased (0.125713 --> 0.124116).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060926\n",
      "\tspeed: 0.0388s/iter; left time: 821.1399s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084698\n",
      "\tspeed: 0.0196s/iter; left time: 414.0967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1080182 Vali Loss: 0.1248462 Test Loss: 0.1527426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1090836\n",
      "\tspeed: 0.0408s/iter; left time: 855.2230s\n",
      "\titers: 200, epoch: 7 | loss: 0.1050917\n",
      "\tspeed: 0.0198s/iter; left time: 413.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1067462 Vali Loss: 0.1260519 Test Loss: 0.1557394\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1026927\n",
      "\tspeed: 0.0408s/iter; left time: 845.8527s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051408\n",
      "\tspeed: 0.0176s/iter; left time: 364.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1059064 Vali Loss: 0.1233336 Test Loss: 0.1507457\n",
      "Validation loss decreased (0.124116 --> 0.123334).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1041532\n",
      "\tspeed: 0.0385s/iter; left time: 790.2504s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069562\n",
      "\tspeed: 0.0172s/iter; left time: 350.5477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1053053 Vali Loss: 0.1256639 Test Loss: 0.1549997\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047203\n",
      "\tspeed: 0.0381s/iter; left time: 772.6840s\n",
      "\titers: 200, epoch: 10 | loss: 0.1056637\n",
      "\tspeed: 0.0162s/iter; left time: 327.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1047988 Vali Loss: 0.1245097 Test Loss: 0.1523917\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0963618\n",
      "\tspeed: 0.0368s/iter; left time: 738.7627s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000071\n",
      "\tspeed: 0.0167s/iter; left time: 334.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1044075 Vali Loss: 0.1244897 Test Loss: 0.1538499\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996287\n",
      "\tspeed: 0.0374s/iter; left time: 741.4271s\n",
      "\titers: 200, epoch: 12 | loss: 0.1009973\n",
      "\tspeed: 0.0179s/iter; left time: 353.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1041731 Vali Loss: 0.1247110 Test Loss: 0.1516322\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1045526\n",
      "\tspeed: 0.0390s/iter; left time: 765.4270s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058753\n",
      "\tspeed: 0.0161s/iter; left time: 314.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1037614 Vali Loss: 0.1245964 Test Loss: 0.1535005\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981016\n",
      "\tspeed: 0.0379s/iter; left time: 735.5389s\n",
      "\titers: 200, epoch: 14 | loss: 0.1059557\n",
      "\tspeed: 0.0170s/iter; left time: 327.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1035623 Vali Loss: 0.1259414 Test Loss: 0.1559952\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1032800\n",
      "\tspeed: 0.0357s/iter; left time: 684.7531s\n",
      "\titers: 200, epoch: 15 | loss: 0.1087450\n",
      "\tspeed: 0.0149s/iter; left time: 284.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.1034006 Vali Loss: 0.1240164 Test Loss: 0.1517604\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076163\n",
      "\tspeed: 0.0369s/iter; left time: 698.6520s\n",
      "\titers: 200, epoch: 16 | loss: 0.0996509\n",
      "\tspeed: 0.0170s/iter; left time: 320.3535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.1030843 Vali Loss: 0.1236664 Test Loss: 0.1521370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0992341\n",
      "\tspeed: 0.0351s/iter; left time: 657.4369s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039612\n",
      "\tspeed: 0.0149s/iter; left time: 276.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1028798 Vali Loss: 0.1244692 Test Loss: 0.1526084\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041440\n",
      "\tspeed: 0.0413s/iter; left time: 762.8721s\n",
      "\titers: 200, epoch: 18 | loss: 0.1025722\n",
      "\tspeed: 0.0226s/iter; left time: 415.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.1027069 Vali Loss: 0.1248132 Test Loss: 0.1531992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051235370337963104, rmse:0.22635231912136078, mae:0.15074577927589417, rse:0.7827578186988831\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:51.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0386s/iter; left time: 856.7507s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0153s/iter; left time: 337.6028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0373s/iter; left time: 819.7671s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0169s/iter; left time: 369.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0407s/iter; left time: 885.1042s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0183s/iter; left time: 395.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0375s/iter; left time: 806.8340s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0173s/iter; left time: 371.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0404s/iter; left time: 860.7643s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0190s/iter; left time: 403.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0455s/iter; left time: 959.9376s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0227s/iter; left time: 475.3381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0382s/iter; left time: 797.5936s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0196s/iter; left time: 407.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0358s/iter; left time: 737.9386s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0152s/iter; left time: 312.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0379s/iter; left time: 774.4932s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0164s/iter; left time: 333.0879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0359s/iter; left time: 724.3849s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0153s/iter; left time: 306.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0389s/iter; left time: 777.6616s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0178s/iter; left time: 354.6611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0359s/iter; left time: 708.3817s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0185s/iter; left time: 363.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0361s/iter; left time: 705.3059s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0160s/iter; left time: 310.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1064795\n",
      "\tspeed: 0.0374s/iter; left time: 722.1422s\n",
      "\titers: 200, epoch: 14 | loss: 0.1044248\n",
      "\tspeed: 0.0184s/iter; left time: 352.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1079363 Vali Loss: 0.1284752 Test Loss: 0.1583262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1090524\n",
      "\tspeed: 0.0379s/iter; left time: 722.6541s\n",
      "\titers: 200, epoch: 15 | loss: 0.1080710\n",
      "\tspeed: 0.0174s/iter; left time: 331.1519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1076277 Vali Loss: 0.1299890 Test Loss: 0.1589850\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1078600\n",
      "\tspeed: 0.0382s/iter; left time: 719.7213s\n",
      "\titers: 200, epoch: 16 | loss: 0.1045698\n",
      "\tspeed: 0.0167s/iter; left time: 313.9997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1073363 Vali Loss: 0.1290679 Test Loss: 0.1590714\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1044126\n",
      "\tspeed: 0.0387s/iter; left time: 722.0199s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068518\n",
      "\tspeed: 0.0190s/iter; left time: 352.8750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1071260 Vali Loss: 0.1287172 Test Loss: 0.1593278\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1058048\n",
      "\tspeed: 0.0397s/iter; left time: 730.4163s\n",
      "\titers: 200, epoch: 18 | loss: 0.1047655\n",
      "\tspeed: 0.0158s/iter; left time: 289.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1071445 Vali Loss: 0.1295316 Test Loss: 0.1593569\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2923186\n",
      "\tspeed: 0.0196s/iter; left time: 434.6615s\n",
      "\titers: 200, epoch: 1 | loss: 0.2762249\n",
      "\tspeed: 0.0169s/iter; left time: 373.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.2933771 Vali Loss: 0.2526797 Test Loss: 0.2736033\n",
      "Validation loss decreased (inf --> 0.252680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551580\n",
      "\tspeed: 0.0395s/iter; left time: 867.6436s\n",
      "\titers: 200, epoch: 2 | loss: 0.1352695\n",
      "\tspeed: 0.0163s/iter; left time: 355.7786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.1652988 Vali Loss: 0.1362184 Test Loss: 0.1586260\n",
      "Validation loss decreased (0.252680 --> 0.136218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1243433\n",
      "\tspeed: 0.0424s/iter; left time: 923.3897s\n",
      "\titers: 200, epoch: 3 | loss: 0.1164440\n",
      "\tspeed: 0.0174s/iter; left time: 376.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.1235833 Vali Loss: 0.1302298 Test Loss: 0.1581837\n",
      "Validation loss decreased (0.136218 --> 0.130230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153650\n",
      "\tspeed: 0.0390s/iter; left time: 839.8370s\n",
      "\titers: 200, epoch: 4 | loss: 0.1093810\n",
      "\tspeed: 0.0160s/iter; left time: 343.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1165450 Vali Loss: 0.1327701 Test Loss: 0.1657872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1114925\n",
      "\tspeed: 0.0405s/iter; left time: 862.8280s\n",
      "\titers: 200, epoch: 5 | loss: 0.1166446\n",
      "\tspeed: 0.0174s/iter; left time: 368.6003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.1142123 Vali Loss: 0.1384112 Test Loss: 0.1725486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1159245\n",
      "\tspeed: 0.0408s/iter; left time: 860.0512s\n",
      "\titers: 200, epoch: 6 | loss: 0.1144330\n",
      "\tspeed: 0.0164s/iter; left time: 343.1843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1128792 Vali Loss: 0.1327941 Test Loss: 0.1649415\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1111590\n",
      "\tspeed: 0.0376s/iter; left time: 783.9075s\n",
      "\titers: 200, epoch: 7 | loss: 0.1099538\n",
      "\tspeed: 0.0163s/iter; left time: 338.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.1114473 Vali Loss: 0.1319743 Test Loss: 0.1646918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1125822\n",
      "\tspeed: 0.0356s/iter; left time: 734.0529s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070650\n",
      "\tspeed: 0.0153s/iter; left time: 314.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.1105803 Vali Loss: 0.1306519 Test Loss: 0.1608720\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1134858\n",
      "\tspeed: 0.0387s/iter; left time: 790.0747s\n",
      "\titers: 200, epoch: 9 | loss: 0.1098845\n",
      "\tspeed: 0.0165s/iter; left time: 336.0821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1098493 Vali Loss: 0.1315106 Test Loss: 0.1636475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1113448\n",
      "\tspeed: 0.0386s/iter; left time: 778.7903s\n",
      "\titers: 200, epoch: 10 | loss: 0.1081774\n",
      "\tspeed: 0.0159s/iter; left time: 319.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.1093590 Vali Loss: 0.1321909 Test Loss: 0.1632495\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1055759\n",
      "\tspeed: 0.0384s/iter; left time: 766.7667s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067710\n",
      "\tspeed: 0.0153s/iter; left time: 303.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.1088795 Vali Loss: 0.1319298 Test Loss: 0.1639058\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1088536\n",
      "\tspeed: 0.0350s/iter; left time: 690.4196s\n",
      "\titers: 200, epoch: 12 | loss: 0.1071380\n",
      "\tspeed: 0.0153s/iter; left time: 300.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.1083560 Vali Loss: 0.1304587 Test Loss: 0.1632485\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1050788\n",
      "\tspeed: 0.0390s/iter; left time: 761.5628s\n",
      "\titers: 200, epoch: 13 | loss: 0.1077113\n",
      "\tspeed: 0.0197s/iter; left time: 382.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.1081560 Vali Loss: 0.1302897 Test Loss: 0.1620840\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05474921688437462, rmse:0.23398549854755402, mae:0.15818369388580322, rse:0.8112613558769226\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:06.76s\n",
      "Intermediate time for GB: 00h:13m:26.75s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0363s/iter; left time: 808.4462s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0163s/iter; left time: 361.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0326s/iter; left time: 718.7075s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0170s/iter; left time: 373.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0319s/iter; left time: 697.3985s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0155s/iter; left time: 338.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0361s/iter; left time: 781.4624s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0209s/iter; left time: 449.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0307s/iter; left time: 657.6057s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0155s/iter; left time: 329.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0319s/iter; left time: 675.8901s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0159s/iter; left time: 335.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0266s/iter; left time: 556.9209s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0159s/iter; left time: 330.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0324s/iter; left time: 671.0858s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0174s/iter; left time: 358.2281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0329s/iter; left time: 675.5330s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0174s/iter; left time: 355.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0305s/iter; left time: 618.5558s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0153s/iter; left time: 309.0413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0357s/iter; left time: 716.3263s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0183s/iter; left time: 364.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0320s/iter; left time: 633.9423s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0153s/iter; left time: 301.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0362s/iter; left time: 710.6692s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0189s/iter; left time: 368.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0367s/iter; left time: 711.8999s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0183s/iter; left time: 353.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0325s/iter; left time: 622.3596s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0183s/iter; left time: 349.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0340s/iter; left time: 643.0979s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0103s/iter; left time: 193.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0314s/iter; left time: 588.2478s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0171s/iter; left time: 318.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0340s/iter; left time: 628.0182s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0174s/iter; left time: 320.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0347s/iter; left time: 634.5103s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0141s/iter; left time: 255.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0328s/iter; left time: 592.3231s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0161s/iter; left time: 289.4330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0648402\n",
      "\tspeed: 0.0330s/iter; left time: 588.7783s\n",
      "\titers: 200, epoch: 21 | loss: 0.0659379\n",
      "\tspeed: 0.0171s/iter; left time: 303.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0639698 Vali Loss: 0.0608919 Test Loss: 0.0778968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0637138\n",
      "\tspeed: 0.0345s/iter; left time: 606.9722s\n",
      "\titers: 200, epoch: 22 | loss: 0.0635084\n",
      "\tspeed: 0.0189s/iter; left time: 331.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0637860 Vali Loss: 0.0606405 Test Loss: 0.0837043\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0631013\n",
      "\tspeed: 0.0342s/iter; left time: 593.3934s\n",
      "\titers: 200, epoch: 23 | loss: 0.0647522\n",
      "\tspeed: 0.0174s/iter; left time: 300.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0632991 Vali Loss: 0.0600661 Test Loss: 0.0856460\n",
      "Validation loss decreased (0.060550 --> 0.060066).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0609565\n",
      "\tspeed: 0.0334s/iter; left time: 572.0468s\n",
      "\titers: 200, epoch: 24 | loss: 0.0638104\n",
      "\tspeed: 0.0168s/iter; left time: 285.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0633592 Vali Loss: 0.0603217 Test Loss: 0.0811601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0567263\n",
      "\tspeed: 0.0329s/iter; left time: 557.0560s\n",
      "\titers: 200, epoch: 25 | loss: 0.0636959\n",
      "\tspeed: 0.0153s/iter; left time: 257.3506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0634488 Vali Loss: 0.0603399 Test Loss: 0.0805059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0653335\n",
      "\tspeed: 0.0354s/iter; left time: 591.0807s\n",
      "\titers: 200, epoch: 26 | loss: 0.0610906\n",
      "\tspeed: 0.0200s/iter; left time: 332.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0630774 Vali Loss: 0.0601113 Test Loss: 0.0808194\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0637621\n",
      "\tspeed: 0.0364s/iter; left time: 599.0597s\n",
      "\titers: 200, epoch: 27 | loss: 0.0624986\n",
      "\tspeed: 0.0179s/iter; left time: 293.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0631169 Vali Loss: 0.0599364 Test Loss: 0.0802414\n",
      "Validation loss decreased (0.060066 --> 0.059936).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0626996\n",
      "\tspeed: 0.0330s/iter; left time: 536.9023s\n",
      "\titers: 200, epoch: 28 | loss: 0.0650475\n",
      "\tspeed: 0.0163s/iter; left time: 263.2413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0630036 Vali Loss: 0.0599976 Test Loss: 0.0798610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0650523\n",
      "\tspeed: 0.0362s/iter; left time: 580.6407s\n",
      "\titers: 200, epoch: 29 | loss: 0.0648407\n",
      "\tspeed: 0.0199s/iter; left time: 316.4641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0631537 Vali Loss: 0.0601693 Test Loss: 0.0790092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0616945\n",
      "\tspeed: 0.0327s/iter; left time: 517.4371s\n",
      "\titers: 200, epoch: 30 | loss: 0.0640166\n",
      "\tspeed: 0.0152s/iter; left time: 238.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0627853 Vali Loss: 0.0597060 Test Loss: 0.0790351\n",
      "Validation loss decreased (0.059936 --> 0.059706).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0632247\n",
      "\tspeed: 0.0323s/iter; left time: 503.9357s\n",
      "\titers: 200, epoch: 31 | loss: 0.0642793\n",
      "\tspeed: 0.0155s/iter; left time: 239.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0626874 Vali Loss: 0.0596988 Test Loss: 0.0799922\n",
      "Validation loss decreased (0.059706 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0618795\n",
      "\tspeed: 0.0329s/iter; left time: 504.5302s\n",
      "\titers: 200, epoch: 32 | loss: 0.0638621\n",
      "\tspeed: 0.0184s/iter; left time: 280.6687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0626309 Vali Loss: 0.0600133 Test Loss: 0.0793648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0613759\n",
      "\tspeed: 0.0348s/iter; left time: 526.4098s\n",
      "\titers: 200, epoch: 33 | loss: 0.0650249\n",
      "\tspeed: 0.0170s/iter; left time: 256.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0626958 Vali Loss: 0.0597566 Test Loss: 0.0829300\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0625083\n",
      "\tspeed: 0.0316s/iter; left time: 470.4297s\n",
      "\titers: 200, epoch: 34 | loss: 0.0649817\n",
      "\tspeed: 0.0156s/iter; left time: 230.5997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0626086 Vali Loss: 0.0595278 Test Loss: 0.0785535\n",
      "Validation loss decreased (0.059699 --> 0.059528).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0618905\n",
      "\tspeed: 0.0331s/iter; left time: 485.3928s\n",
      "\titers: 200, epoch: 35 | loss: 0.0594872\n",
      "\tspeed: 0.0164s/iter; left time: 238.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0625302 Vali Loss: 0.0598271 Test Loss: 0.0774672\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0628262\n",
      "\tspeed: 0.0314s/iter; left time: 454.4646s\n",
      "\titers: 200, epoch: 36 | loss: 0.0613497\n",
      "\tspeed: 0.0159s/iter; left time: 228.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0629912 Vali Loss: 0.0594929 Test Loss: 0.0812049\n",
      "Validation loss decreased (0.059528 --> 0.059493).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0603207\n",
      "\tspeed: 0.0373s/iter; left time: 531.2537s\n",
      "\titers: 200, epoch: 37 | loss: 0.0618328\n",
      "\tspeed: 0.0187s/iter; left time: 263.8434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0624442 Vali Loss: 0.0599277 Test Loss: 0.0808704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0623976\n",
      "\tspeed: 0.0347s/iter; left time: 485.7830s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618199\n",
      "\tspeed: 0.0181s/iter; left time: 252.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0623962 Vali Loss: 0.0596360 Test Loss: 0.0795271\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0588883\n",
      "\tspeed: 0.0322s/iter; left time: 444.3054s\n",
      "\titers: 200, epoch: 39 | loss: 0.0610459\n",
      "\tspeed: 0.0162s/iter; left time: 221.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0623432 Vali Loss: 0.0594202 Test Loss: 0.0799924\n",
      "Validation loss decreased (0.059493 --> 0.059420).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0598964\n",
      "\tspeed: 0.0317s/iter; left time: 430.5022s\n",
      "\titers: 200, epoch: 40 | loss: 0.0590530\n",
      "\tspeed: 0.0169s/iter; left time: 228.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0626194 Vali Loss: 0.0593982 Test Loss: 0.0784466\n",
      "Validation loss decreased (0.059420 --> 0.059398).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0659376\n",
      "\tspeed: 0.0369s/iter; left time: 492.4054s\n",
      "\titers: 200, epoch: 41 | loss: 0.0624791\n",
      "\tspeed: 0.0170s/iter; left time: 225.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0623992 Vali Loss: 0.0596976 Test Loss: 0.0798948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0641973\n",
      "\tspeed: 0.0327s/iter; left time: 429.4324s\n",
      "\titers: 200, epoch: 42 | loss: 0.0649498\n",
      "\tspeed: 0.0178s/iter; left time: 231.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0623876 Vali Loss: 0.0597047 Test Loss: 0.0779574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0603804\n",
      "\tspeed: 0.0324s/iter; left time: 417.2136s\n",
      "\titers: 200, epoch: 43 | loss: 0.0657060\n",
      "\tspeed: 0.0159s/iter; left time: 202.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0622967 Vali Loss: 0.0595325 Test Loss: 0.0775056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0661049\n",
      "\tspeed: 0.0346s/iter; left time: 438.1587s\n",
      "\titers: 200, epoch: 44 | loss: 0.0636315\n",
      "\tspeed: 0.0166s/iter; left time: 208.3646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0623053 Vali Loss: 0.0593446 Test Loss: 0.0787060\n",
      "Validation loss decreased (0.059398 --> 0.059345).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0670810\n",
      "\tspeed: 0.0311s/iter; left time: 387.4865s\n",
      "\titers: 200, epoch: 45 | loss: 0.0628282\n",
      "\tspeed: 0.0166s/iter; left time: 204.7174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0624146 Vali Loss: 0.0595850 Test Loss: 0.0776185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0668972\n",
      "\tspeed: 0.0328s/iter; left time: 400.5874s\n",
      "\titers: 200, epoch: 46 | loss: 0.0657387\n",
      "\tspeed: 0.0158s/iter; left time: 191.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0624402 Vali Loss: 0.0597573 Test Loss: 0.0789046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0605890\n",
      "\tspeed: 0.0332s/iter; left time: 398.4702s\n",
      "\titers: 200, epoch: 47 | loss: 0.0628887\n",
      "\tspeed: 0.0168s/iter; left time: 200.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0621471 Vali Loss: 0.0595367 Test Loss: 0.0784753\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642688\n",
      "\tspeed: 0.0354s/iter; left time: 416.6094s\n",
      "\titers: 200, epoch: 48 | loss: 0.0593611\n",
      "\tspeed: 0.0178s/iter; left time: 207.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0623013 Vali Loss: 0.0593974 Test Loss: 0.0798472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0635834\n",
      "\tspeed: 0.0333s/iter; left time: 385.0036s\n",
      "\titers: 200, epoch: 49 | loss: 0.0619003\n",
      "\tspeed: 0.0171s/iter; left time: 196.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0625203 Vali Loss: 0.0595282 Test Loss: 0.0791877\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0609761\n",
      "\tspeed: 0.0341s/iter; left time: 385.8394s\n",
      "\titers: 200, epoch: 50 | loss: 0.0622208\n",
      "\tspeed: 0.0163s/iter; left time: 182.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0622423 Vali Loss: 0.0596158 Test Loss: 0.0792489\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0619520\n",
      "\tspeed: 0.0304s/iter; left time: 337.2908s\n",
      "\titers: 200, epoch: 51 | loss: 0.0628265\n",
      "\tspeed: 0.0145s/iter; left time: 159.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0622624 Vali Loss: 0.0594051 Test Loss: 0.0773887\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0612404\n",
      "\tspeed: 0.0341s/iter; left time: 370.8401s\n",
      "\titers: 200, epoch: 52 | loss: 0.0628188\n",
      "\tspeed: 0.0161s/iter; left time: 173.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0623996 Vali Loss: 0.0594793 Test Loss: 0.0774014\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0643009\n",
      "\tspeed: 0.0316s/iter; left time: 336.8066s\n",
      "\titers: 200, epoch: 53 | loss: 0.0634064\n",
      "\tspeed: 0.0154s/iter; left time: 162.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0622669 Vali Loss: 0.0596862 Test Loss: 0.0778411\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0614927\n",
      "\tspeed: 0.0332s/iter; left time: 346.1428s\n",
      "\titers: 200, epoch: 54 | loss: 0.0631441\n",
      "\tspeed: 0.0195s/iter; left time: 201.6204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0622740 Vali Loss: 0.0595357 Test Loss: 0.0777481\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.016271354630589485, rmse:0.12755921483039856, mae:0.07870597392320633, rse:0.3753913640975952\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2892122\n",
      "\tspeed: 0.0170s/iter; left time: 378.7603s\n",
      "\titers: 200, epoch: 1 | loss: 0.2660992\n",
      "\tspeed: 0.0168s/iter; left time: 372.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.2965279 Vali Loss: 0.2202346 Test Loss: 0.2370768\n",
      "Validation loss decreased (inf --> 0.220235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1539855\n",
      "\tspeed: 0.0325s/iter; left time: 717.6002s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143376\n",
      "\tspeed: 0.0153s/iter; left time: 336.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1615120 Vali Loss: 0.0888261 Test Loss: 0.0968157\n",
      "Validation loss decreased (0.220235 --> 0.088826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0979644\n",
      "\tspeed: 0.0322s/iter; left time: 704.6626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927927\n",
      "\tspeed: 0.0155s/iter; left time: 336.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0995892 Vali Loss: 0.0764636 Test Loss: 0.0847130\n",
      "Validation loss decreased (0.088826 --> 0.076464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897991\n",
      "\tspeed: 0.0335s/iter; left time: 723.7206s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827181\n",
      "\tspeed: 0.0171s/iter; left time: 368.5268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0869733 Vali Loss: 0.0734729 Test Loss: 0.0810101\n",
      "Validation loss decreased (0.076464 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815627\n",
      "\tspeed: 0.0368s/iter; left time: 788.0821s\n",
      "\titers: 200, epoch: 5 | loss: 0.0739117\n",
      "\tspeed: 0.0207s/iter; left time: 440.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0803262 Vali Loss: 0.0700490 Test Loss: 0.0803528\n",
      "Validation loss decreased (0.073473 --> 0.070049).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777595\n",
      "\tspeed: 0.0355s/iter; left time: 752.1276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752439\n",
      "\tspeed: 0.0189s/iter; left time: 398.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0772147 Vali Loss: 0.0690502 Test Loss: 0.0800061\n",
      "Validation loss decreased (0.070049 --> 0.069050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741698\n",
      "\tspeed: 0.0351s/iter; left time: 735.7055s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786026\n",
      "\tspeed: 0.0168s/iter; left time: 350.2540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0746004 Vali Loss: 0.0662944 Test Loss: 0.0831919\n",
      "Validation loss decreased (0.069050 --> 0.066294).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0720962\n",
      "\tspeed: 0.0346s/iter; left time: 716.8669s\n",
      "\titers: 200, epoch: 8 | loss: 0.0674486\n",
      "\tspeed: 0.0172s/iter; left time: 355.8562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0723453 Vali Loss: 0.0655117 Test Loss: 0.0828428\n",
      "Validation loss decreased (0.066294 --> 0.065512).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749420\n",
      "\tspeed: 0.0332s/iter; left time: 680.5189s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707552\n",
      "\tspeed: 0.0168s/iter; left time: 343.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0709444 Vali Loss: 0.0649825 Test Loss: 0.0820810\n",
      "Validation loss decreased (0.065512 --> 0.064982).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0653492\n",
      "\tspeed: 0.0332s/iter; left time: 674.0319s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728749\n",
      "\tspeed: 0.0161s/iter; left time: 325.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0694805 Vali Loss: 0.0637436 Test Loss: 0.0805136\n",
      "Validation loss decreased (0.064982 --> 0.063744).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0654753\n",
      "\tspeed: 0.0345s/iter; left time: 691.6020s\n",
      "\titers: 200, epoch: 11 | loss: 0.0646911\n",
      "\tspeed: 0.0175s/iter; left time: 349.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0686186 Vali Loss: 0.0641838 Test Loss: 0.0822113\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0649198\n",
      "\tspeed: 0.0318s/iter; left time: 630.2612s\n",
      "\titers: 200, epoch: 12 | loss: 0.0646746\n",
      "\tspeed: 0.0154s/iter; left time: 304.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0679764 Vali Loss: 0.0641024 Test Loss: 0.0817276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0697122\n",
      "\tspeed: 0.0352s/iter; left time: 689.4483s\n",
      "\titers: 200, epoch: 13 | loss: 0.0700299\n",
      "\tspeed: 0.0170s/iter; left time: 332.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0673256 Vali Loss: 0.0622702 Test Loss: 0.0806944\n",
      "Validation loss decreased (0.063744 --> 0.062270).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0658208\n",
      "\tspeed: 0.0337s/iter; left time: 652.8636s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666625\n",
      "\tspeed: 0.0189s/iter; left time: 365.1428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0666473 Vali Loss: 0.0622615 Test Loss: 0.0788437\n",
      "Validation loss decreased (0.062270 --> 0.062262).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662519\n",
      "\tspeed: 0.0341s/iter; left time: 653.3132s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660783\n",
      "\tspeed: 0.0156s/iter; left time: 297.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0663878 Vali Loss: 0.0617795 Test Loss: 0.0770767\n",
      "Validation loss decreased (0.062262 --> 0.061779).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652738\n",
      "\tspeed: 0.0357s/iter; left time: 676.6017s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645800\n",
      "\tspeed: 0.0196s/iter; left time: 369.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0657017 Vali Loss: 0.0615699 Test Loss: 0.0756564\n",
      "Validation loss decreased (0.061779 --> 0.061570).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0623387\n",
      "\tspeed: 0.0344s/iter; left time: 644.3908s\n",
      "\titers: 200, epoch: 17 | loss: 0.0682290\n",
      "\tspeed: 0.0170s/iter; left time: 315.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0653807 Vali Loss: 0.0609969 Test Loss: 0.0759708\n",
      "Validation loss decreased (0.061570 --> 0.060997).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0629665\n",
      "\tspeed: 0.0357s/iter; left time: 660.4971s\n",
      "\titers: 200, epoch: 18 | loss: 0.0660909\n",
      "\tspeed: 0.0176s/iter; left time: 324.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0650203 Vali Loss: 0.0611630 Test Loss: 0.0762600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0647769\n",
      "\tspeed: 0.0325s/iter; left time: 593.7151s\n",
      "\titers: 200, epoch: 19 | loss: 0.0643299\n",
      "\tspeed: 0.0155s/iter; left time: 281.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0648261 Vali Loss: 0.0609118 Test Loss: 0.0763575\n",
      "Validation loss decreased (0.060997 --> 0.060912).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0626265\n",
      "\tspeed: 0.0336s/iter; left time: 606.2073s\n",
      "\titers: 200, epoch: 20 | loss: 0.0649455\n",
      "\tspeed: 0.0186s/iter; left time: 334.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0646050 Vali Loss: 0.0608533 Test Loss: 0.0770059\n",
      "Validation loss decreased (0.060912 --> 0.060853).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0618789\n",
      "\tspeed: 0.0305s/iter; left time: 543.5180s\n",
      "\titers: 200, epoch: 21 | loss: 0.0675359\n",
      "\tspeed: 0.0101s/iter; left time: 179.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0644248 Vali Loss: 0.0606882 Test Loss: 0.0761549\n",
      "Validation loss decreased (0.060853 --> 0.060688).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0643762\n",
      "\tspeed: 0.0311s/iter; left time: 547.7802s\n",
      "\titers: 200, epoch: 22 | loss: 0.0665079\n",
      "\tspeed: 0.0170s/iter; left time: 298.1771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0641298 Vali Loss: 0.0605414 Test Loss: 0.0749995\n",
      "Validation loss decreased (0.060688 --> 0.060541).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0626361\n",
      "\tspeed: 0.0314s/iter; left time: 544.6964s\n",
      "\titers: 200, epoch: 23 | loss: 0.0619444\n",
      "\tspeed: 0.0159s/iter; left time: 274.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0640495 Vali Loss: 0.0600125 Test Loss: 0.0751412\n",
      "Validation loss decreased (0.060541 --> 0.060012).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0668678\n",
      "\tspeed: 0.0342s/iter; left time: 586.9863s\n",
      "\titers: 200, epoch: 24 | loss: 0.0629791\n",
      "\tspeed: 0.0184s/iter; left time: 314.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0638809 Vali Loss: 0.0602886 Test Loss: 0.0745161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0644174\n",
      "\tspeed: 0.0359s/iter; left time: 607.6941s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646280\n",
      "\tspeed: 0.0151s/iter; left time: 253.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0637914 Vali Loss: 0.0599894 Test Loss: 0.0751399\n",
      "Validation loss decreased (0.060012 --> 0.059989).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0615174\n",
      "\tspeed: 0.0341s/iter; left time: 569.9586s\n",
      "\titers: 200, epoch: 26 | loss: 0.0625327\n",
      "\tspeed: 0.0157s/iter; left time: 260.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0636017 Vali Loss: 0.0598450 Test Loss: 0.0747057\n",
      "Validation loss decreased (0.059989 --> 0.059845).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0655383\n",
      "\tspeed: 0.0334s/iter; left time: 550.4729s\n",
      "\titers: 200, epoch: 27 | loss: 0.0614031\n",
      "\tspeed: 0.0156s/iter; left time: 256.0257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0633817 Vali Loss: 0.0599251 Test Loss: 0.0746622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0626174\n",
      "\tspeed: 0.0313s/iter; left time: 509.1954s\n",
      "\titers: 200, epoch: 28 | loss: 0.0628177\n",
      "\tspeed: 0.0157s/iter; left time: 254.0226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0635918 Vali Loss: 0.0596987 Test Loss: 0.0741641\n",
      "Validation loss decreased (0.059845 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0661405\n",
      "\tspeed: 0.0347s/iter; left time: 555.8244s\n",
      "\titers: 200, epoch: 29 | loss: 0.0686575\n",
      "\tspeed: 0.0153s/iter; left time: 243.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0635368 Vali Loss: 0.0600278 Test Loss: 0.0744089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0627493\n",
      "\tspeed: 0.0319s/iter; left time: 504.7486s\n",
      "\titers: 200, epoch: 30 | loss: 0.0637090\n",
      "\tspeed: 0.0152s/iter; left time: 239.0789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0634227 Vali Loss: 0.0599569 Test Loss: 0.0740244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0647104\n",
      "\tspeed: 0.0327s/iter; left time: 509.9982s\n",
      "\titers: 200, epoch: 31 | loss: 0.0634678\n",
      "\tspeed: 0.0159s/iter; left time: 246.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0631139 Vali Loss: 0.0599802 Test Loss: 0.0741277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0605536\n",
      "\tspeed: 0.0361s/iter; left time: 554.3837s\n",
      "\titers: 200, epoch: 32 | loss: 0.0625743\n",
      "\tspeed: 0.0170s/iter; left time: 259.0576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0631250 Vali Loss: 0.0596394 Test Loss: 0.0736590\n",
      "Validation loss decreased (0.059699 --> 0.059639).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0637135\n",
      "\tspeed: 0.0313s/iter; left time: 473.6436s\n",
      "\titers: 200, epoch: 33 | loss: 0.0634592\n",
      "\tspeed: 0.0196s/iter; left time: 295.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0629441 Vali Loss: 0.0595979 Test Loss: 0.0739759\n",
      "Validation loss decreased (0.059639 --> 0.059598).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0637110\n",
      "\tspeed: 0.0365s/iter; left time: 543.4480s\n",
      "\titers: 200, epoch: 34 | loss: 0.0658683\n",
      "\tspeed: 0.0186s/iter; left time: 275.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0629368 Vali Loss: 0.0595017 Test Loss: 0.0735492\n",
      "Validation loss decreased (0.059598 --> 0.059502).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0641423\n",
      "\tspeed: 0.0334s/iter; left time: 490.7464s\n",
      "\titers: 200, epoch: 35 | loss: 0.0604577\n",
      "\tspeed: 0.0171s/iter; left time: 249.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0630385 Vali Loss: 0.0598842 Test Loss: 0.0740244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0683392\n",
      "\tspeed: 0.0333s/iter; left time: 481.5791s\n",
      "\titers: 200, epoch: 36 | loss: 0.0654246\n",
      "\tspeed: 0.0193s/iter; left time: 277.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0629729 Vali Loss: 0.0594444 Test Loss: 0.0734302\n",
      "Validation loss decreased (0.059502 --> 0.059444).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0643754\n",
      "\tspeed: 0.0341s/iter; left time: 485.5416s\n",
      "\titers: 200, epoch: 37 | loss: 0.0624843\n",
      "\tspeed: 0.0171s/iter; left time: 241.5506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0628177 Vali Loss: 0.0594962 Test Loss: 0.0734705\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0627216\n",
      "\tspeed: 0.0343s/iter; left time: 480.8925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0634602\n",
      "\tspeed: 0.0181s/iter; left time: 252.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0627659 Vali Loss: 0.0594407 Test Loss: 0.0741697\n",
      "Validation loss decreased (0.059444 --> 0.059441).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0627414\n",
      "\tspeed: 0.0361s/iter; left time: 498.2366s\n",
      "\titers: 200, epoch: 39 | loss: 0.0655835\n",
      "\tspeed: 0.0189s/iter; left time: 258.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0628943 Vali Loss: 0.0593417 Test Loss: 0.0725542\n",
      "Validation loss decreased (0.059441 --> 0.059342).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0648856\n",
      "\tspeed: 0.0281s/iter; left time: 381.5409s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608795\n",
      "\tspeed: 0.0098s/iter; left time: 132.1396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0628501 Vali Loss: 0.0595566 Test Loss: 0.0731153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673042\n",
      "\tspeed: 0.0291s/iter; left time: 388.2767s\n",
      "\titers: 200, epoch: 41 | loss: 0.0609992\n",
      "\tspeed: 0.0165s/iter; left time: 218.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0628100 Vali Loss: 0.0594376 Test Loss: 0.0731614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0636128\n",
      "\tspeed: 0.0339s/iter; left time: 444.7466s\n",
      "\titers: 200, epoch: 42 | loss: 0.0640302\n",
      "\tspeed: 0.0156s/iter; left time: 203.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0627291 Vali Loss: 0.0594023 Test Loss: 0.0730519\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0644562\n",
      "\tspeed: 0.0313s/iter; left time: 404.1088s\n",
      "\titers: 200, epoch: 43 | loss: 0.0621497\n",
      "\tspeed: 0.0159s/iter; left time: 202.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0627906 Vali Loss: 0.0593885 Test Loss: 0.0738827\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0639315\n",
      "\tspeed: 0.0371s/iter; left time: 469.5652s\n",
      "\titers: 200, epoch: 44 | loss: 0.0616424\n",
      "\tspeed: 0.0180s/iter; left time: 225.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0628448 Vali Loss: 0.0594930 Test Loss: 0.0731448\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0629060\n",
      "\tspeed: 0.0358s/iter; left time: 445.3865s\n",
      "\titers: 200, epoch: 45 | loss: 0.0593640\n",
      "\tspeed: 0.0187s/iter; left time: 230.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0628275 Vali Loss: 0.0595377 Test Loss: 0.0730518\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0619585\n",
      "\tspeed: 0.0356s/iter; left time: 435.3595s\n",
      "\titers: 200, epoch: 46 | loss: 0.0605217\n",
      "\tspeed: 0.0157s/iter; left time: 190.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0625891 Vali Loss: 0.0592900 Test Loss: 0.0728881\n",
      "Validation loss decreased (0.059342 --> 0.059290).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0584388\n",
      "\tspeed: 0.0339s/iter; left time: 406.1096s\n",
      "\titers: 200, epoch: 47 | loss: 0.0590488\n",
      "\tspeed: 0.0173s/iter; left time: 206.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0627148 Vali Loss: 0.0592724 Test Loss: 0.0737006\n",
      "Validation loss decreased (0.059290 --> 0.059272).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0608841\n",
      "\tspeed: 0.0357s/iter; left time: 420.6228s\n",
      "\titers: 200, epoch: 48 | loss: 0.0631235\n",
      "\tspeed: 0.0156s/iter; left time: 181.8365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0627695 Vali Loss: 0.0597309 Test Loss: 0.0744821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0642522\n",
      "\tspeed: 0.0330s/iter; left time: 381.1933s\n",
      "\titers: 200, epoch: 49 | loss: 0.0623665\n",
      "\tspeed: 0.0175s/iter; left time: 200.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0626723 Vali Loss: 0.0593464 Test Loss: 0.0724346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0612011\n",
      "\tspeed: 0.0350s/iter; left time: 396.6043s\n",
      "\titers: 200, epoch: 50 | loss: 0.0623087\n",
      "\tspeed: 0.0163s/iter; left time: 182.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0626347 Vali Loss: 0.0594473 Test Loss: 0.0730431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0632982\n",
      "\tspeed: 0.0345s/iter; left time: 383.4062s\n",
      "\titers: 200, epoch: 51 | loss: 0.0651604\n",
      "\tspeed: 0.0239s/iter; left time: 262.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0626562 Vali Loss: 0.0597073 Test Loss: 0.0732586\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0607229\n",
      "\tspeed: 0.0398s/iter; left time: 433.2684s\n",
      "\titers: 200, epoch: 52 | loss: 0.0605967\n",
      "\tspeed: 0.0169s/iter; left time: 182.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0626114 Vali Loss: 0.0594380 Test Loss: 0.0729210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0633354\n",
      "\tspeed: 0.0334s/iter; left time: 355.8595s\n",
      "\titers: 200, epoch: 53 | loss: 0.0660769\n",
      "\tspeed: 0.0153s/iter; left time: 161.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0624637 Vali Loss: 0.0592723 Test Loss: 0.0730626\n",
      "Validation loss decreased (0.059272 --> 0.059272).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0615535\n",
      "\tspeed: 0.0335s/iter; left time: 349.3084s\n",
      "\titers: 200, epoch: 54 | loss: 0.0637485\n",
      "\tspeed: 0.0178s/iter; left time: 184.0200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0626284 Vali Loss: 0.0593004 Test Loss: 0.0733065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0591436\n",
      "\tspeed: 0.0331s/iter; left time: 338.1735s\n",
      "\titers: 200, epoch: 55 | loss: 0.0630315\n",
      "\tspeed: 0.0160s/iter; left time: 161.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0625872 Vali Loss: 0.0594360 Test Loss: 0.0730221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0612531\n",
      "\tspeed: 0.0328s/iter; left time: 327.6538s\n",
      "\titers: 200, epoch: 56 | loss: 0.0676546\n",
      "\tspeed: 0.0170s/iter; left time: 167.5543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0628035 Vali Loss: 0.0596989 Test Loss: 0.0732868\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0631388\n",
      "\tspeed: 0.0325s/iter; left time: 317.2834s\n",
      "\titers: 200, epoch: 57 | loss: 0.0645748\n",
      "\tspeed: 0.0183s/iter; left time: 176.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0626519 Vali Loss: 0.0592509 Test Loss: 0.0726471\n",
      "Validation loss decreased (0.059272 --> 0.059251).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0647347\n",
      "\tspeed: 0.0337s/iter; left time: 321.0586s\n",
      "\titers: 200, epoch: 58 | loss: 0.0597751\n",
      "\tspeed: 0.0157s/iter; left time: 147.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0626362 Vali Loss: 0.0595850 Test Loss: 0.0732047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0642236\n",
      "\tspeed: 0.0278s/iter; left time: 258.8768s\n",
      "\titers: 200, epoch: 59 | loss: 0.0616029\n",
      "\tspeed: 0.0148s/iter; left time: 136.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 224 | Train Loss: 0.0626267 Vali Loss: 0.0595027 Test Loss: 0.0740201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0653087\n",
      "\tspeed: 0.0351s/iter; left time: 318.6002s\n",
      "\titers: 200, epoch: 60 | loss: 0.0641650\n",
      "\tspeed: 0.0187s/iter; left time: 168.4339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0625558 Vali Loss: 0.0596241 Test Loss: 0.0735977\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0621469\n",
      "\tspeed: 0.0369s/iter; left time: 326.9014s\n",
      "\titers: 200, epoch: 61 | loss: 0.0642872\n",
      "\tspeed: 0.0198s/iter; left time: 173.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0625605 Vali Loss: 0.0594029 Test Loss: 0.0732548\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0598915\n",
      "\tspeed: 0.0336s/iter; left time: 290.4769s\n",
      "\titers: 200, epoch: 62 | loss: 0.0624310\n",
      "\tspeed: 0.0165s/iter; left time: 140.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0626801 Vali Loss: 0.0592205 Test Loss: 0.0734248\n",
      "Validation loss decreased (0.059251 --> 0.059220).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0634078\n",
      "\tspeed: 0.0340s/iter; left time: 286.2036s\n",
      "\titers: 200, epoch: 63 | loss: 0.0655695\n",
      "\tspeed: 0.0100s/iter; left time: 83.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0624523 Vali Loss: 0.0593583 Test Loss: 0.0735325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0594155\n",
      "\tspeed: 0.0326s/iter; left time: 266.8582s\n",
      "\titers: 200, epoch: 64 | loss: 0.0609248\n",
      "\tspeed: 0.0155s/iter; left time: 125.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0625074 Vali Loss: 0.0592355 Test Loss: 0.0730888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0620877\n",
      "\tspeed: 0.0320s/iter; left time: 254.5776s\n",
      "\titers: 200, epoch: 65 | loss: 0.0662895\n",
      "\tspeed: 0.0165s/iter; left time: 129.6952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0625421 Vali Loss: 0.0593002 Test Loss: 0.0739252\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0629772\n",
      "\tspeed: 0.0306s/iter; left time: 236.8427s\n",
      "\titers: 200, epoch: 66 | loss: 0.0667751\n",
      "\tspeed: 0.0196s/iter; left time: 149.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0625571 Vali Loss: 0.0592030 Test Loss: 0.0735998\n",
      "Validation loss decreased (0.059220 --> 0.059203).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0616824\n",
      "\tspeed: 0.0357s/iter; left time: 268.2880s\n",
      "\titers: 200, epoch: 67 | loss: 0.0595338\n",
      "\tspeed: 0.0161s/iter; left time: 119.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0624756 Vali Loss: 0.0594555 Test Loss: 0.0732474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0635912\n",
      "\tspeed: 0.0320s/iter; left time: 233.0155s\n",
      "\titers: 200, epoch: 68 | loss: 0.0627736\n",
      "\tspeed: 0.0153s/iter; left time: 110.1197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0625410 Vali Loss: 0.0594626 Test Loss: 0.0734125\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0628619\n",
      "\tspeed: 0.0271s/iter; left time: 191.7725s\n",
      "\titers: 200, epoch: 69 | loss: 0.0656136\n",
      "\tspeed: 0.0180s/iter; left time: 125.7886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0625695 Vali Loss: 0.0592243 Test Loss: 0.0731613\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0632257\n",
      "\tspeed: 0.0335s/iter; left time: 229.2279s\n",
      "\titers: 200, epoch: 70 | loss: 0.0592294\n",
      "\tspeed: 0.0162s/iter; left time: 109.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0624855 Vali Loss: 0.0591872 Test Loss: 0.0734162\n",
      "Validation loss decreased (0.059203 --> 0.059187).  Saving model ...\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0568094\n",
      "\tspeed: 0.0331s/iter; left time: 219.0911s\n",
      "\titers: 200, epoch: 71 | loss: 0.0638159\n",
      "\tspeed: 0.0154s/iter; left time: 100.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0625757 Vali Loss: 0.0593466 Test Loss: 0.0738181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0681661\n",
      "\tspeed: 0.0371s/iter; left time: 237.3655s\n",
      "\titers: 200, epoch: 72 | loss: 0.0637419\n",
      "\tspeed: 0.0200s/iter; left time: 126.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0626029 Vali Loss: 0.0593822 Test Loss: 0.0733891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0624777\n",
      "\tspeed: 0.0371s/iter; left time: 229.1565s\n",
      "\titers: 200, epoch: 73 | loss: 0.0605845\n",
      "\tspeed: 0.0170s/iter; left time: 102.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0625847 Vali Loss: 0.0592924 Test Loss: 0.0728329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0611291\n",
      "\tspeed: 0.0310s/iter; left time: 184.1576s\n",
      "\titers: 200, epoch: 74 | loss: 0.0594107\n",
      "\tspeed: 0.0097s/iter; left time: 56.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0624167 Vali Loss: 0.0593401 Test Loss: 0.0737229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0633699\n",
      "\tspeed: 0.0310s/iter; left time: 177.2244s\n",
      "\titers: 200, epoch: 75 | loss: 0.0642549\n",
      "\tspeed: 0.0166s/iter; left time: 93.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0625491 Vali Loss: 0.0594092 Test Loss: 0.0737538\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0590176\n",
      "\tspeed: 0.0357s/iter; left time: 196.3222s\n",
      "\titers: 200, epoch: 76 | loss: 0.0610032\n",
      "\tspeed: 0.0188s/iter; left time: 101.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0626779 Vali Loss: 0.0594338 Test Loss: 0.0729458\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0648241\n",
      "\tspeed: 0.0340s/iter; left time: 179.5588s\n",
      "\titers: 200, epoch: 77 | loss: 0.0645060\n",
      "\tspeed: 0.0183s/iter; left time: 94.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0625217 Vali Loss: 0.0594396 Test Loss: 0.0738457\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0643508\n",
      "\tspeed: 0.0334s/iter; left time: 168.9958s\n",
      "\titers: 200, epoch: 78 | loss: 0.0603013\n",
      "\tspeed: 0.0167s/iter; left time: 82.5644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0626750 Vali Loss: 0.0599028 Test Loss: 0.0742438\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0645236\n",
      "\tspeed: 0.0348s/iter; left time: 168.1261s\n",
      "\titers: 200, epoch: 79 | loss: 0.0626074\n",
      "\tspeed: 0.0186s/iter; left time: 88.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0626009 Vali Loss: 0.0596587 Test Loss: 0.0732343\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0632685\n",
      "\tspeed: 0.0350s/iter; left time: 161.3761s\n",
      "\titers: 200, epoch: 80 | loss: 0.0679443\n",
      "\tspeed: 0.0198s/iter; left time: 89.1858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0626053 Vali Loss: 0.0595695 Test Loss: 0.0735726\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012944619171321392, rmse:0.11377441883087158, mae:0.07341622561216354, rse:0.3348243534564972\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:24.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0341s/iter; left time: 760.7620s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0131s/iter; left time: 291.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0383s/iter; left time: 846.6292s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0126s/iter; left time: 276.2210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0354s/iter; left time: 773.8974s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0201s/iter; left time: 437.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0388s/iter; left time: 839.6383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0240s/iter; left time: 516.6130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0436s/iter; left time: 934.0192s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0200s/iter; left time: 427.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0382s/iter; left time: 810.0186s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0221s/iter; left time: 466.9412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0388s/iter; left time: 812.0863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0232s/iter; left time: 484.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0399s/iter; left time: 827.0849s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0219s/iter; left time: 452.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0411s/iter; left time: 841.8962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0212s/iter; left time: 433.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0396s/iter; left time: 803.9126s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0205s/iter; left time: 412.8774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0380s/iter; left time: 762.0887s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0180s/iter; left time: 359.3609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0378s/iter; left time: 749.0450s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0187s/iter; left time: 368.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0345s/iter; left time: 676.7309s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0187s/iter; left time: 364.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0410s/iter; left time: 794.3867s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0226s/iter; left time: 436.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0378s/iter; left time: 725.0042s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0190s/iter; left time: 363.1412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0363s/iter; left time: 688.1396s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0212s/iter; left time: 399.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0410s/iter; left time: 767.1221s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0206s/iter; left time: 383.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0373s/iter; left time: 689.7224s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0182s/iter; left time: 334.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0388s/iter; left time: 709.5086s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0190s/iter; left time: 345.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0369s/iter; left time: 666.3920s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0217s/iter; left time: 388.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801600\n",
      "\tspeed: 0.0373s/iter; left time: 665.2318s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823245\n",
      "\tspeed: 0.0180s/iter; left time: 319.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0818866 Vali Loss: 0.0792850 Test Loss: 0.1079874\n",
      "Validation loss decreased (0.079559 --> 0.079285).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0804956\n",
      "\tspeed: 0.0377s/iter; left time: 663.9854s\n",
      "\titers: 200, epoch: 22 | loss: 0.0824744\n",
      "\tspeed: 0.0196s/iter; left time: 342.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0819721 Vali Loss: 0.0796621 Test Loss: 0.1085374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0789200\n",
      "\tspeed: 0.0359s/iter; left time: 623.7316s\n",
      "\titers: 200, epoch: 23 | loss: 0.0837181\n",
      "\tspeed: 0.0179s/iter; left time: 309.7956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0820333 Vali Loss: 0.0794220 Test Loss: 0.1072117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0796378\n",
      "\tspeed: 0.0388s/iter; left time: 666.0144s\n",
      "\titers: 200, epoch: 24 | loss: 0.0776479\n",
      "\tspeed: 0.0174s/iter; left time: 296.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0815369 Vali Loss: 0.0793501 Test Loss: 0.1082661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0819355\n",
      "\tspeed: 0.0349s/iter; left time: 591.0632s\n",
      "\titers: 200, epoch: 25 | loss: 0.0820402\n",
      "\tspeed: 0.0173s/iter; left time: 290.6609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0814421 Vali Loss: 0.0792631 Test Loss: 0.1074659\n",
      "Validation loss decreased (0.079285 --> 0.079263).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0819095\n",
      "\tspeed: 0.0365s/iter; left time: 609.1208s\n",
      "\titers: 200, epoch: 26 | loss: 0.0826016\n",
      "\tspeed: 0.0203s/iter; left time: 336.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0814282 Vali Loss: 0.0793992 Test Loss: 0.1077555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0814544\n",
      "\tspeed: 0.0352s/iter; left time: 580.2740s\n",
      "\titers: 200, epoch: 27 | loss: 0.0890747\n",
      "\tspeed: 0.0178s/iter; left time: 292.2718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0814238 Vali Loss: 0.0793065 Test Loss: 0.1090543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0771820\n",
      "\tspeed: 0.0380s/iter; left time: 618.1641s\n",
      "\titers: 200, epoch: 28 | loss: 0.0793767\n",
      "\tspeed: 0.0180s/iter; left time: 291.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0811177 Vali Loss: 0.0790487 Test Loss: 0.1071326\n",
      "Validation loss decreased (0.079263 --> 0.079049).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0828157\n",
      "\tspeed: 0.0342s/iter; left time: 547.9755s\n",
      "\titers: 200, epoch: 29 | loss: 0.0837944\n",
      "\tspeed: 0.0168s/iter; left time: 268.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0811892 Vali Loss: 0.0792537 Test Loss: 0.1088195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0804581\n",
      "\tspeed: 0.0350s/iter; left time: 553.1531s\n",
      "\titers: 200, epoch: 30 | loss: 0.0849867\n",
      "\tspeed: 0.0231s/iter; left time: 362.8642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0811638 Vali Loss: 0.0790258 Test Loss: 0.1075138\n",
      "Validation loss decreased (0.079049 --> 0.079026).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0799334\n",
      "\tspeed: 0.0390s/iter; left time: 607.0233s\n",
      "\titers: 200, epoch: 31 | loss: 0.0820784\n",
      "\tspeed: 0.0200s/iter; left time: 309.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0811456 Vali Loss: 0.0791238 Test Loss: 0.1083240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0828095\n",
      "\tspeed: 0.0387s/iter; left time: 594.6045s\n",
      "\titers: 200, epoch: 32 | loss: 0.0822255\n",
      "\tspeed: 0.0143s/iter; left time: 218.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0812526 Vali Loss: 0.0790749 Test Loss: 0.1071283\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0796983\n",
      "\tspeed: 0.0344s/iter; left time: 520.6548s\n",
      "\titers: 200, epoch: 33 | loss: 0.0805068\n",
      "\tspeed: 0.0201s/iter; left time: 301.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0810100 Vali Loss: 0.0791240 Test Loss: 0.1081686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0837967\n",
      "\tspeed: 0.0397s/iter; left time: 591.8776s\n",
      "\titers: 200, epoch: 34 | loss: 0.0864583\n",
      "\tspeed: 0.0176s/iter; left time: 261.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0810124 Vali Loss: 0.0791251 Test Loss: 0.1072538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0832718\n",
      "\tspeed: 0.0359s/iter; left time: 526.8667s\n",
      "\titers: 200, epoch: 35 | loss: 0.0830791\n",
      "\tspeed: 0.0191s/iter; left time: 278.5079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0808145 Vali Loss: 0.0791186 Test Loss: 0.1076243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0757619\n",
      "\tspeed: 0.0342s/iter; left time: 493.9889s\n",
      "\titers: 200, epoch: 36 | loss: 0.0762362\n",
      "\tspeed: 0.0168s/iter; left time: 241.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0810010 Vali Loss: 0.0790066 Test Loss: 0.1079348\n",
      "Validation loss decreased (0.079026 --> 0.079007).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0788083\n",
      "\tspeed: 0.0374s/iter; left time: 532.8858s\n",
      "\titers: 200, epoch: 37 | loss: 0.0795329\n",
      "\tspeed: 0.0178s/iter; left time: 252.1367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0809631 Vali Loss: 0.0789814 Test Loss: 0.1069180\n",
      "Validation loss decreased (0.079007 --> 0.078981).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0809431\n",
      "\tspeed: 0.0396s/iter; left time: 554.8224s\n",
      "\titers: 200, epoch: 38 | loss: 0.0811129\n",
      "\tspeed: 0.0217s/iter; left time: 302.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0808095 Vali Loss: 0.0791114 Test Loss: 0.1077315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0796580\n",
      "\tspeed: 0.0366s/iter; left time: 505.3000s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785968\n",
      "\tspeed: 0.0207s/iter; left time: 283.4992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0806671 Vali Loss: 0.0789793 Test Loss: 0.1070785\n",
      "Validation loss decreased (0.078981 --> 0.078979).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0822391\n",
      "\tspeed: 0.0401s/iter; left time: 543.7597s\n",
      "\titers: 200, epoch: 40 | loss: 0.0774362\n",
      "\tspeed: 0.0197s/iter; left time: 265.5422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0807148 Vali Loss: 0.0789665 Test Loss: 0.1076642\n",
      "Validation loss decreased (0.078979 --> 0.078967).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0792845\n",
      "\tspeed: 0.0299s/iter; left time: 398.7385s\n",
      "\titers: 200, epoch: 41 | loss: 0.0770996\n",
      "\tspeed: 0.0138s/iter; left time: 183.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 224 | Train Loss: 0.0808222 Vali Loss: 0.0790066 Test Loss: 0.1067579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0786893\n",
      "\tspeed: 0.0367s/iter; left time: 481.7622s\n",
      "\titers: 200, epoch: 42 | loss: 0.0815302\n",
      "\tspeed: 0.0190s/iter; left time: 247.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0809124 Vali Loss: 0.0789820 Test Loss: 0.1074727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0803642\n",
      "\tspeed: 0.0346s/iter; left time: 446.1896s\n",
      "\titers: 200, epoch: 43 | loss: 0.0818448\n",
      "\tspeed: 0.0182s/iter; left time: 233.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0807880 Vali Loss: 0.0790211 Test Loss: 0.1074443\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0829713\n",
      "\tspeed: 0.0368s/iter; left time: 465.8452s\n",
      "\titers: 200, epoch: 44 | loss: 0.0775464\n",
      "\tspeed: 0.0184s/iter; left time: 231.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0807208 Vali Loss: 0.0790137 Test Loss: 0.1075019\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0803836\n",
      "\tspeed: 0.0373s/iter; left time: 464.6072s\n",
      "\titers: 200, epoch: 45 | loss: 0.0817756\n",
      "\tspeed: 0.0215s/iter; left time: 265.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0809599 Vali Loss: 0.0788184 Test Loss: 0.1062304\n",
      "Validation loss decreased (0.078967 --> 0.078818).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788488\n",
      "\tspeed: 0.0365s/iter; left time: 446.1500s\n",
      "\titers: 200, epoch: 46 | loss: 0.0796075\n",
      "\tspeed: 0.0191s/iter; left time: 231.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0807397 Vali Loss: 0.0789614 Test Loss: 0.1072604\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0782363\n",
      "\tspeed: 0.0353s/iter; left time: 422.9634s\n",
      "\titers: 200, epoch: 47 | loss: 0.0816190\n",
      "\tspeed: 0.0170s/iter; left time: 202.7785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0806389 Vali Loss: 0.0791179 Test Loss: 0.1081125\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0823858\n",
      "\tspeed: 0.0334s/iter; left time: 393.0883s\n",
      "\titers: 200, epoch: 48 | loss: 0.0794778\n",
      "\tspeed: 0.0161s/iter; left time: 187.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0806543 Vali Loss: 0.0789456 Test Loss: 0.1075629\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0785191\n",
      "\tspeed: 0.0345s/iter; left time: 398.3813s\n",
      "\titers: 200, epoch: 49 | loss: 0.0791071\n",
      "\tspeed: 0.0176s/iter; left time: 201.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0806385 Vali Loss: 0.0789092 Test Loss: 0.1076234\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0773607\n",
      "\tspeed: 0.0372s/iter; left time: 421.2063s\n",
      "\titers: 200, epoch: 50 | loss: 0.0794940\n",
      "\tspeed: 0.0164s/iter; left time: 183.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0808311 Vali Loss: 0.0789006 Test Loss: 0.1068063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0820763\n",
      "\tspeed: 0.0342s/iter; left time: 380.1082s\n",
      "\titers: 200, epoch: 51 | loss: 0.0798580\n",
      "\tspeed: 0.0198s/iter; left time: 217.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0806921 Vali Loss: 0.0789968 Test Loss: 0.1068897\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0813597\n",
      "\tspeed: 0.0343s/iter; left time: 372.9764s\n",
      "\titers: 200, epoch: 52 | loss: 0.0792496\n",
      "\tspeed: 0.0163s/iter; left time: 175.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0805982 Vali Loss: 0.0788836 Test Loss: 0.1067426\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0833251\n",
      "\tspeed: 0.0349s/iter; left time: 371.9053s\n",
      "\titers: 200, epoch: 53 | loss: 0.0797060\n",
      "\tspeed: 0.0162s/iter; left time: 171.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0806178 Vali Loss: 0.0788674 Test Loss: 0.1072988\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0768501\n",
      "\tspeed: 0.0343s/iter; left time: 357.9597s\n",
      "\titers: 200, epoch: 54 | loss: 0.0811910\n",
      "\tspeed: 0.0179s/iter; left time: 184.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0806418 Vali Loss: 0.0789365 Test Loss: 0.1070738\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0768826\n",
      "\tspeed: 0.0364s/iter; left time: 371.4810s\n",
      "\titers: 200, epoch: 55 | loss: 0.0777496\n",
      "\tspeed: 0.0179s/iter; left time: 180.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0806218 Vali Loss: 0.0789265 Test Loss: 0.1077000\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02482021600008011, rmse:0.1575443297624588, mae:0.10623040050268173, rse:0.46281781792640686\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2949701\n",
      "\tspeed: 0.0214s/iter; left time: 477.0226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2738535\n",
      "\tspeed: 0.0177s/iter; left time: 393.4781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.2943460 Vali Loss: 0.2228722 Test Loss: 0.2429076\n",
      "Validation loss decreased (inf --> 0.222872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1516856\n",
      "\tspeed: 0.0385s/iter; left time: 849.3704s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205032\n",
      "\tspeed: 0.0174s/iter; left time: 381.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1615071 Vali Loss: 0.1064732 Test Loss: 0.1207890\n",
      "Validation loss decreased (0.222872 --> 0.106473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1121301\n",
      "\tspeed: 0.0361s/iter; left time: 788.2299s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061030\n",
      "\tspeed: 0.0171s/iter; left time: 371.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1100943 Vali Loss: 0.0948281 Test Loss: 0.1183062\n",
      "Validation loss decreased (0.106473 --> 0.094828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0978006\n",
      "\tspeed: 0.0370s/iter; left time: 801.2565s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954229\n",
      "\tspeed: 0.0184s/iter; left time: 396.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0970733 Vali Loss: 0.0896294 Test Loss: 0.1343081\n",
      "Validation loss decreased (0.094828 --> 0.089629).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0915815\n",
      "\tspeed: 0.0344s/iter; left time: 736.4958s\n",
      "\titers: 200, epoch: 5 | loss: 0.0912736\n",
      "\tspeed: 0.0175s/iter; left time: 373.1874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0920308 Vali Loss: 0.0861538 Test Loss: 0.1335911\n",
      "Validation loss decreased (0.089629 --> 0.086154).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856224\n",
      "\tspeed: 0.0357s/iter; left time: 755.8734s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884811\n",
      "\tspeed: 0.0194s/iter; left time: 408.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0892304 Vali Loss: 0.0844599 Test Loss: 0.1357906\n",
      "Validation loss decreased (0.086154 --> 0.084460).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0945793\n",
      "\tspeed: 0.0389s/iter; left time: 816.2046s\n",
      "\titers: 200, epoch: 7 | loss: 0.0873152\n",
      "\tspeed: 0.0102s/iter; left time: 213.5639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0882241 Vali Loss: 0.0833441 Test Loss: 0.1325197\n",
      "Validation loss decreased (0.084460 --> 0.083344).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843527\n",
      "\tspeed: 0.0357s/iter; left time: 740.8999s\n",
      "\titers: 200, epoch: 8 | loss: 0.0852545\n",
      "\tspeed: 0.0200s/iter; left time: 413.5441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0867391 Vali Loss: 0.0826206 Test Loss: 0.1371923\n",
      "Validation loss decreased (0.083344 --> 0.082621).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867780\n",
      "\tspeed: 0.0356s/iter; left time: 729.2157s\n",
      "\titers: 200, epoch: 9 | loss: 0.0851954\n",
      "\tspeed: 0.0176s/iter; left time: 359.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0855968 Vali Loss: 0.0819841 Test Loss: 0.1273202\n",
      "Validation loss decreased (0.082621 --> 0.081984).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0851445\n",
      "\tspeed: 0.0375s/iter; left time: 760.8264s\n",
      "\titers: 200, epoch: 10 | loss: 0.0842952\n",
      "\tspeed: 0.0183s/iter; left time: 369.7434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0847394 Vali Loss: 0.0815754 Test Loss: 0.1295356\n",
      "Validation loss decreased (0.081984 --> 0.081575).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0827668\n",
      "\tspeed: 0.0363s/iter; left time: 728.7344s\n",
      "\titers: 200, epoch: 11 | loss: 0.0849487\n",
      "\tspeed: 0.0173s/iter; left time: 345.9538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0847392 Vali Loss: 0.0812731 Test Loss: 0.1272998\n",
      "Validation loss decreased (0.081575 --> 0.081273).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0852151\n",
      "\tspeed: 0.0400s/iter; left time: 793.1776s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807062\n",
      "\tspeed: 0.0175s/iter; left time: 345.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0852808 Vali Loss: 0.0811117 Test Loss: 0.1152925\n",
      "Validation loss decreased (0.081273 --> 0.081112).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842783\n",
      "\tspeed: 0.0350s/iter; left time: 686.4051s\n",
      "\titers: 200, epoch: 13 | loss: 0.0827053\n",
      "\tspeed: 0.0173s/iter; left time: 336.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0835776 Vali Loss: 0.0807043 Test Loss: 0.1232046\n",
      "Validation loss decreased (0.081112 --> 0.080704).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841696\n",
      "\tspeed: 0.0353s/iter; left time: 684.5492s\n",
      "\titers: 200, epoch: 14 | loss: 0.0816784\n",
      "\tspeed: 0.0156s/iter; left time: 301.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0830525 Vali Loss: 0.0803488 Test Loss: 0.1258540\n",
      "Validation loss decreased (0.080704 --> 0.080349).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843562\n",
      "\tspeed: 0.0351s/iter; left time: 672.2247s\n",
      "\titers: 200, epoch: 15 | loss: 0.0866401\n",
      "\tspeed: 0.0185s/iter; left time: 352.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0826786 Vali Loss: 0.0800034 Test Loss: 0.1245869\n",
      "Validation loss decreased (0.080349 --> 0.080003).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0874645\n",
      "\tspeed: 0.0360s/iter; left time: 681.0782s\n",
      "\titers: 200, epoch: 16 | loss: 0.0806157\n",
      "\tspeed: 0.0177s/iter; left time: 334.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0825226 Vali Loss: 0.0799668 Test Loss: 0.1231041\n",
      "Validation loss decreased (0.080003 --> 0.079967).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0779536\n",
      "\tspeed: 0.0381s/iter; left time: 712.6518s\n",
      "\titers: 200, epoch: 17 | loss: 0.0826323\n",
      "\tspeed: 0.0186s/iter; left time: 347.0604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0822895 Vali Loss: 0.0798155 Test Loss: 0.1189573\n",
      "Validation loss decreased (0.079967 --> 0.079816).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0801349\n",
      "\tspeed: 0.0364s/iter; left time: 673.1364s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788892\n",
      "\tspeed: 0.0176s/iter; left time: 323.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0819632 Vali Loss: 0.0795002 Test Loss: 0.1211235\n",
      "Validation loss decreased (0.079816 --> 0.079500).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0831867\n",
      "\tspeed: 0.0398s/iter; left time: 727.6228s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855634\n",
      "\tspeed: 0.0196s/iter; left time: 356.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0819039 Vali Loss: 0.0795896 Test Loss: 0.1136663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806163\n",
      "\tspeed: 0.0416s/iter; left time: 750.0262s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826579\n",
      "\tspeed: 0.0228s/iter; left time: 408.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0815371 Vali Loss: 0.0793281 Test Loss: 0.1178989\n",
      "Validation loss decreased (0.079500 --> 0.079328).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801518\n",
      "\tspeed: 0.0373s/iter; left time: 665.1061s\n",
      "\titers: 200, epoch: 21 | loss: 0.0802585\n",
      "\tspeed: 0.0121s/iter; left time: 214.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 224 | Train Loss: 0.0816553 Vali Loss: 0.0794146 Test Loss: 0.1150296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0819045\n",
      "\tspeed: 0.0364s/iter; left time: 640.3391s\n",
      "\titers: 200, epoch: 22 | loss: 0.0835017\n",
      "\tspeed: 0.0161s/iter; left time: 281.1451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0813633 Vali Loss: 0.0791247 Test Loss: 0.1185968\n",
      "Validation loss decreased (0.079328 --> 0.079125).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0771334\n",
      "\tspeed: 0.0358s/iter; left time: 622.0577s\n",
      "\titers: 200, epoch: 23 | loss: 0.0831374\n",
      "\tspeed: 0.0165s/iter; left time: 285.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0811816 Vali Loss: 0.0792441 Test Loss: 0.1194242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0799311\n",
      "\tspeed: 0.0382s/iter; left time: 655.4032s\n",
      "\titers: 200, epoch: 24 | loss: 0.0833221\n",
      "\tspeed: 0.0179s/iter; left time: 304.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0814226 Vali Loss: 0.0791263 Test Loss: 0.1155721\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0803420\n",
      "\tspeed: 0.0374s/iter; left time: 632.1532s\n",
      "\titers: 200, epoch: 25 | loss: 0.0859437\n",
      "\tspeed: 0.0180s/iter; left time: 302.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0810550 Vali Loss: 0.0790411 Test Loss: 0.1178999\n",
      "Validation loss decreased (0.079125 --> 0.079041).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0814237\n",
      "\tspeed: 0.0380s/iter; left time: 634.8886s\n",
      "\titers: 200, epoch: 26 | loss: 0.0782807\n",
      "\tspeed: 0.0194s/iter; left time: 321.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0810974 Vali Loss: 0.0790298 Test Loss: 0.1171177\n",
      "Validation loss decreased (0.079041 --> 0.079030).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0820360\n",
      "\tspeed: 0.0387s/iter; left time: 638.3706s\n",
      "\titers: 200, epoch: 27 | loss: 0.0814562\n",
      "\tspeed: 0.0197s/iter; left time: 323.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0809683 Vali Loss: 0.0789331 Test Loss: 0.1153629\n",
      "Validation loss decreased (0.079030 --> 0.078933).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0824465\n",
      "\tspeed: 0.0377s/iter; left time: 613.3998s\n",
      "\titers: 200, epoch: 28 | loss: 0.0807360\n",
      "\tspeed: 0.0172s/iter; left time: 277.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0806947 Vali Loss: 0.0789500 Test Loss: 0.1206281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796398\n",
      "\tspeed: 0.0348s/iter; left time: 557.3572s\n",
      "\titers: 200, epoch: 29 | loss: 0.0812451\n",
      "\tspeed: 0.0201s/iter; left time: 320.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0807283 Vali Loss: 0.0788620 Test Loss: 0.1161380\n",
      "Validation loss decreased (0.078933 --> 0.078862).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792317\n",
      "\tspeed: 0.0391s/iter; left time: 617.4968s\n",
      "\titers: 200, epoch: 30 | loss: 0.0796323\n",
      "\tspeed: 0.0172s/iter; left time: 270.8606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0805884 Vali Loss: 0.0787869 Test Loss: 0.1190568\n",
      "Validation loss decreased (0.078862 --> 0.078787).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0825548\n",
      "\tspeed: 0.0410s/iter; left time: 639.2071s\n",
      "\titers: 200, epoch: 31 | loss: 0.0785023\n",
      "\tspeed: 0.0223s/iter; left time: 345.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0808213 Vali Loss: 0.0789125 Test Loss: 0.1160532\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0826512\n",
      "\tspeed: 0.0361s/iter; left time: 554.0721s\n",
      "\titers: 200, epoch: 32 | loss: 0.0771616\n",
      "\tspeed: 0.0189s/iter; left time: 288.6761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0804920 Vali Loss: 0.0787618 Test Loss: 0.1174321\n",
      "Validation loss decreased (0.078787 --> 0.078762).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0789443\n",
      "\tspeed: 0.0375s/iter; left time: 568.2268s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803010\n",
      "\tspeed: 0.0175s/iter; left time: 262.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0806825 Vali Loss: 0.0787459 Test Loss: 0.1134941\n",
      "Validation loss decreased (0.078762 --> 0.078746).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0789445\n",
      "\tspeed: 0.0404s/iter; left time: 602.7331s\n",
      "\titers: 200, epoch: 34 | loss: 0.0812439\n",
      "\tspeed: 0.0226s/iter; left time: 334.4972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0804169 Vali Loss: 0.0789054 Test Loss: 0.1152394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0839198\n",
      "\tspeed: 0.0362s/iter; left time: 532.0272s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819243\n",
      "\tspeed: 0.0181s/iter; left time: 264.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0804650 Vali Loss: 0.0786934 Test Loss: 0.1144127\n",
      "Validation loss decreased (0.078746 --> 0.078693).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0802629\n",
      "\tspeed: 0.0391s/iter; left time: 565.3692s\n",
      "\titers: 200, epoch: 36 | loss: 0.0781854\n",
      "\tspeed: 0.0199s/iter; left time: 285.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0804494 Vali Loss: 0.0787799 Test Loss: 0.1149971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0785369\n",
      "\tspeed: 0.0376s/iter; left time: 535.1866s\n",
      "\titers: 200, epoch: 37 | loss: 0.0791697\n",
      "\tspeed: 0.0103s/iter; left time: 145.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0803865 Vali Loss: 0.0788539 Test Loss: 0.1158440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0820786\n",
      "\tspeed: 0.0362s/iter; left time: 507.0343s\n",
      "\titers: 200, epoch: 38 | loss: 0.0810464\n",
      "\tspeed: 0.0225s/iter; left time: 312.9638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0803231 Vali Loss: 0.0787525 Test Loss: 0.1153972\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0808926\n",
      "\tspeed: 0.0301s/iter; left time: 415.1695s\n",
      "\titers: 200, epoch: 39 | loss: 0.0804156\n",
      "\tspeed: 0.0101s/iter; left time: 138.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.52s\n",
      "Steps: 224 | Train Loss: 0.0803351 Vali Loss: 0.0788614 Test Loss: 0.1145321\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0813855\n",
      "\tspeed: 0.0400s/iter; left time: 542.8018s\n",
      "\titers: 200, epoch: 40 | loss: 0.0745288\n",
      "\tspeed: 0.0224s/iter; left time: 300.9433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0805143 Vali Loss: 0.0787251 Test Loss: 0.1136237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0766422\n",
      "\tspeed: 0.0402s/iter; left time: 535.7198s\n",
      "\titers: 200, epoch: 41 | loss: 0.0802586\n",
      "\tspeed: 0.0191s/iter; left time: 252.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0803362 Vali Loss: 0.0786872 Test Loss: 0.1146974\n",
      "Validation loss decreased (0.078693 --> 0.078687).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0831676\n",
      "\tspeed: 0.0375s/iter; left time: 491.7998s\n",
      "\titers: 200, epoch: 42 | loss: 0.0803144\n",
      "\tspeed: 0.0198s/iter; left time: 257.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0803085 Vali Loss: 0.0786738 Test Loss: 0.1136685\n",
      "Validation loss decreased (0.078687 --> 0.078674).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0776655\n",
      "\tspeed: 0.0402s/iter; left time: 517.6957s\n",
      "\titers: 200, epoch: 43 | loss: 0.0748830\n",
      "\tspeed: 0.0184s/iter; left time: 235.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0802602 Vali Loss: 0.0787125 Test Loss: 0.1163979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0814612\n",
      "\tspeed: 0.0362s/iter; left time: 458.9155s\n",
      "\titers: 200, epoch: 44 | loss: 0.0819359\n",
      "\tspeed: 0.0194s/iter; left time: 243.4861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0802522 Vali Loss: 0.0787630 Test Loss: 0.1159265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0778814\n",
      "\tspeed: 0.0412s/iter; left time: 512.9451s\n",
      "\titers: 200, epoch: 45 | loss: 0.0820323\n",
      "\tspeed: 0.0185s/iter; left time: 228.6590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0802462 Vali Loss: 0.0787794 Test Loss: 0.1148303\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788297\n",
      "\tspeed: 0.0357s/iter; left time: 435.7329s\n",
      "\titers: 200, epoch: 46 | loss: 0.0800137\n",
      "\tspeed: 0.0185s/iter; left time: 224.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0802375 Vali Loss: 0.0787176 Test Loss: 0.1158337\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0804135\n",
      "\tspeed: 0.0356s/iter; left time: 427.2991s\n",
      "\titers: 200, epoch: 47 | loss: 0.0826335\n",
      "\tspeed: 0.0204s/iter; left time: 242.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0802282 Vali Loss: 0.0786863 Test Loss: 0.1181947\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0770466\n",
      "\tspeed: 0.0400s/iter; left time: 470.8219s\n",
      "\titers: 200, epoch: 48 | loss: 0.0773087\n",
      "\tspeed: 0.0197s/iter; left time: 229.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0802870 Vali Loss: 0.0786488 Test Loss: 0.1158384\n",
      "Validation loss decreased (0.078674 --> 0.078649).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0772750\n",
      "\tspeed: 0.0360s/iter; left time: 415.4354s\n",
      "\titers: 200, epoch: 49 | loss: 0.0812847\n",
      "\tspeed: 0.0165s/iter; left time: 188.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0804005 Vali Loss: 0.0786252 Test Loss: 0.1148006\n",
      "Validation loss decreased (0.078649 --> 0.078625).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0819748\n",
      "\tspeed: 0.0380s/iter; left time: 429.7961s\n",
      "\titers: 200, epoch: 50 | loss: 0.0831465\n",
      "\tspeed: 0.0233s/iter; left time: 262.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0805817 Vali Loss: 0.0787522 Test Loss: 0.1136936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0818774\n",
      "\tspeed: 0.0384s/iter; left time: 426.2538s\n",
      "\titers: 200, epoch: 51 | loss: 0.0814776\n",
      "\tspeed: 0.0222s/iter; left time: 243.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0803361 Vali Loss: 0.0787344 Test Loss: 0.1140809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0815157\n",
      "\tspeed: 0.0422s/iter; left time: 458.9261s\n",
      "\titers: 200, epoch: 52 | loss: 0.0760650\n",
      "\tspeed: 0.0238s/iter; left time: 256.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0802124 Vali Loss: 0.0787321 Test Loss: 0.1143213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800943\n",
      "\tspeed: 0.0416s/iter; left time: 443.0007s\n",
      "\titers: 200, epoch: 53 | loss: 0.0805059\n",
      "\tspeed: 0.0200s/iter; left time: 211.3093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0801604 Vali Loss: 0.0787110 Test Loss: 0.1153583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0835793\n",
      "\tspeed: 0.0413s/iter; left time: 431.0967s\n",
      "\titers: 200, epoch: 54 | loss: 0.0840597\n",
      "\tspeed: 0.0219s/iter; left time: 226.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0801659 Vali Loss: 0.0787169 Test Loss: 0.1157073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0787593\n",
      "\tspeed: 0.0389s/iter; left time: 397.3428s\n",
      "\titers: 200, epoch: 55 | loss: 0.0782121\n",
      "\tspeed: 0.0180s/iter; left time: 181.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0801970 Vali Loss: 0.0786564 Test Loss: 0.1157790\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0776901\n",
      "\tspeed: 0.0402s/iter; left time: 401.5801s\n",
      "\titers: 200, epoch: 56 | loss: 0.0820478\n",
      "\tspeed: 0.0202s/iter; left time: 199.5538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802963 Vali Loss: 0.0787426 Test Loss: 0.1163280\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0794644\n",
      "\tspeed: 0.0369s/iter; left time: 359.7499s\n",
      "\titers: 200, epoch: 57 | loss: 0.0812776\n",
      "\tspeed: 0.0205s/iter; left time: 198.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0801635 Vali Loss: 0.0787768 Test Loss: 0.1162051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0781011\n",
      "\tspeed: 0.0380s/iter; left time: 362.3696s\n",
      "\titers: 200, epoch: 58 | loss: 0.0803022\n",
      "\tspeed: 0.0185s/iter; left time: 174.6745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0801390 Vali Loss: 0.0786844 Test Loss: 0.1173877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0816328\n",
      "\tspeed: 0.0383s/iter; left time: 356.9836s\n",
      "\titers: 200, epoch: 59 | loss: 0.0806974\n",
      "\tspeed: 0.0225s/iter; left time: 207.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0803725 Vali Loss: 0.0786231 Test Loss: 0.1158899\n",
      "Validation loss decreased (0.078625 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0798175\n",
      "\tspeed: 0.0376s/iter; left time: 341.2687s\n",
      "\titers: 200, epoch: 60 | loss: 0.0841747\n",
      "\tspeed: 0.0187s/iter; left time: 168.4539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0801562 Vali Loss: 0.0787353 Test Loss: 0.1151237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0808385\n",
      "\tspeed: 0.0357s/iter; left time: 316.0352s\n",
      "\titers: 200, epoch: 61 | loss: 0.0819121\n",
      "\tspeed: 0.0167s/iter; left time: 146.3453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0801061 Vali Loss: 0.0786935 Test Loss: 0.1148166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0789861\n",
      "\tspeed: 0.0349s/iter; left time: 301.2917s\n",
      "\titers: 200, epoch: 62 | loss: 0.0809398\n",
      "\tspeed: 0.0157s/iter; left time: 133.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0801172 Vali Loss: 0.0786713 Test Loss: 0.1164873\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0836691\n",
      "\tspeed: 0.0345s/iter; left time: 290.3974s\n",
      "\titers: 200, epoch: 63 | loss: 0.0823292\n",
      "\tspeed: 0.0167s/iter; left time: 138.7787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0802999 Vali Loss: 0.0786390 Test Loss: 0.1152086\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0749281\n",
      "\tspeed: 0.0383s/iter; left time: 313.6434s\n",
      "\titers: 200, epoch: 64 | loss: 0.0802662\n",
      "\tspeed: 0.0204s/iter; left time: 164.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0802207 Vali Loss: 0.0787605 Test Loss: 0.1149963\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0825867\n",
      "\tspeed: 0.0366s/iter; left time: 291.6395s\n",
      "\titers: 200, epoch: 65 | loss: 0.0778804\n",
      "\tspeed: 0.0159s/iter; left time: 125.2883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0801056 Vali Loss: 0.0786383 Test Loss: 0.1165857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0803034\n",
      "\tspeed: 0.0363s/iter; left time: 281.1824s\n",
      "\titers: 200, epoch: 66 | loss: 0.0810269\n",
      "\tspeed: 0.0170s/iter; left time: 130.0205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0801883 Vali Loss: 0.0787476 Test Loss: 0.1161576\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0825353\n",
      "\tspeed: 0.0390s/iter; left time: 292.9024s\n",
      "\titers: 200, epoch: 67 | loss: 0.0824786\n",
      "\tspeed: 0.0174s/iter; left time: 129.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0801582 Vali Loss: 0.0787648 Test Loss: 0.1165231\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0824737\n",
      "\tspeed: 0.0380s/iter; left time: 277.3749s\n",
      "\titers: 200, epoch: 68 | loss: 0.0820768\n",
      "\tspeed: 0.0201s/iter; left time: 144.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0800938 Vali Loss: 0.0786233 Test Loss: 0.1150988\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0814223\n",
      "\tspeed: 0.0375s/iter; left time: 265.0158s\n",
      "\titers: 200, epoch: 69 | loss: 0.0758541\n",
      "\tspeed: 0.0176s/iter; left time: 122.6835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0803286 Vali Loss: 0.0786767 Test Loss: 0.1181150\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.034349095076322556, rmse:0.18533508479595184, mae:0.11588998138904572, rse:0.5444587469100952\n",
      "Intermediate time for ES and pred_len 96: 00h:11m:44.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0383s/iter; left time: 849.4162s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0137s/iter; left time: 303.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0373s/iter; left time: 819.5653s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0163s/iter; left time: 356.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0373s/iter; left time: 812.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0175s/iter; left time: 379.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0348s/iter; left time: 749.9537s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0166s/iter; left time: 355.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0364s/iter; left time: 775.6177s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0194s/iter; left time: 410.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0354s/iter; left time: 746.8566s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0165s/iter; left time: 346.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0336s/iter; left time: 700.1759s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0167s/iter; left time: 347.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0346s/iter; left time: 714.8079s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0161s/iter; left time: 329.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0351s/iter; left time: 715.7005s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0169s/iter; left time: 343.9593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0370s/iter; left time: 747.7284s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0161s/iter; left time: 324.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0320s/iter; left time: 638.5682s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0159s/iter; left time: 315.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0351s/iter; left time: 693.0523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0173s/iter; left time: 340.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0326s/iter; left time: 636.7985s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0155s/iter; left time: 300.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0383s/iter; left time: 738.6382s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0188s/iter; left time: 360.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0310s/iter; left time: 591.3387s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0222s/iter; left time: 420.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0321s/iter; left time: 606.1936s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0160s/iter; left time: 299.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0367s/iter; left time: 684.3646s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0184s/iter; left time: 340.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0334s/iter; left time: 614.6725s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0171s/iter; left time: 312.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0349s/iter; left time: 634.8837s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0167s/iter; left time: 302.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0382s/iter; left time: 685.4929s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0192s/iter; left time: 342.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0877162\n",
      "\tspeed: 0.0357s/iter; left time: 633.1227s\n",
      "\titers: 200, epoch: 21 | loss: 0.0856693\n",
      "\tspeed: 0.0158s/iter; left time: 278.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0858356 Vali Loss: 0.0850625 Test Loss: 0.1181478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0853307\n",
      "\tspeed: 0.0345s/iter; left time: 604.8849s\n",
      "\titers: 200, epoch: 22 | loss: 0.0857101\n",
      "\tspeed: 0.0154s/iter; left time: 268.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0858141 Vali Loss: 0.0848711 Test Loss: 0.1179698\n",
      "Validation loss decreased (0.085052 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0836513\n",
      "\tspeed: 0.0327s/iter; left time: 565.0363s\n",
      "\titers: 200, epoch: 23 | loss: 0.0845700\n",
      "\tspeed: 0.0179s/iter; left time: 307.7281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0857552 Vali Loss: 0.0851099 Test Loss: 0.1169337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0853104\n",
      "\tspeed: 0.0364s/iter; left time: 622.0109s\n",
      "\titers: 200, epoch: 24 | loss: 0.0847234\n",
      "\tspeed: 0.0156s/iter; left time: 265.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0854539 Vali Loss: 0.0847695 Test Loss: 0.1189011\n",
      "Validation loss decreased (0.084871 --> 0.084769).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0877929\n",
      "\tspeed: 0.0350s/iter; left time: 589.5867s\n",
      "\titers: 200, epoch: 25 | loss: 0.0859289\n",
      "\tspeed: 0.0189s/iter; left time: 317.1705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0854330 Vali Loss: 0.0852000 Test Loss: 0.1200379\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0872629\n",
      "\tspeed: 0.0344s/iter; left time: 572.7254s\n",
      "\titers: 200, epoch: 26 | loss: 0.0873879\n",
      "\tspeed: 0.0196s/iter; left time: 323.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0853350 Vali Loss: 0.0850407 Test Loss: 0.1206776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0884665\n",
      "\tspeed: 0.0384s/iter; left time: 629.1749s\n",
      "\titers: 200, epoch: 27 | loss: 0.0884702\n",
      "\tspeed: 0.0210s/iter; left time: 341.8618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0851529 Vali Loss: 0.0848730 Test Loss: 0.1198020\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0833811\n",
      "\tspeed: 0.0332s/iter; left time: 537.4540s\n",
      "\titers: 200, epoch: 28 | loss: 0.0875286\n",
      "\tspeed: 0.0162s/iter; left time: 260.8488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0851438 Vali Loss: 0.0848251 Test Loss: 0.1189873\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0854217\n",
      "\tspeed: 0.0332s/iter; left time: 530.3283s\n",
      "\titers: 200, epoch: 29 | loss: 0.0837402\n",
      "\tspeed: 0.0156s/iter; left time: 247.8726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0849345 Vali Loss: 0.0846815 Test Loss: 0.1183914\n",
      "Validation loss decreased (0.084769 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0870486\n",
      "\tspeed: 0.0329s/iter; left time: 517.0152s\n",
      "\titers: 200, epoch: 30 | loss: 0.0877254\n",
      "\tspeed: 0.0164s/iter; left time: 255.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0850217 Vali Loss: 0.0848136 Test Loss: 0.1178944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0841421\n",
      "\tspeed: 0.0358s/iter; left time: 555.8696s\n",
      "\titers: 200, epoch: 31 | loss: 0.0857176\n",
      "\tspeed: 0.0187s/iter; left time: 288.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0854421 Vali Loss: 0.0847439 Test Loss: 0.1170233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0852246\n",
      "\tspeed: 0.0273s/iter; left time: 417.3389s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857008\n",
      "\tspeed: 0.0190s/iter; left time: 288.9417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.0848933 Vali Loss: 0.0847940 Test Loss: 0.1198182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0841194\n",
      "\tspeed: 0.0330s/iter; left time: 496.5999s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834450\n",
      "\tspeed: 0.0190s/iter; left time: 284.5772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0851093 Vali Loss: 0.0847722 Test Loss: 0.1174044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0847829\n",
      "\tspeed: 0.0323s/iter; left time: 479.3560s\n",
      "\titers: 200, epoch: 34 | loss: 0.0847453\n",
      "\tspeed: 0.0173s/iter; left time: 254.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0849649 Vali Loss: 0.0849032 Test Loss: 0.1175446\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0862751\n",
      "\tspeed: 0.0334s/iter; left time: 488.3782s\n",
      "\titers: 200, epoch: 35 | loss: 0.0876660\n",
      "\tspeed: 0.0149s/iter; left time: 216.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.0849581 Vali Loss: 0.0847439 Test Loss: 0.1175975\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0852168\n",
      "\tspeed: 0.0311s/iter; left time: 448.0201s\n",
      "\titers: 200, epoch: 36 | loss: 0.0829864\n",
      "\tspeed: 0.0163s/iter; left time: 233.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0847706 Vali Loss: 0.0847675 Test Loss: 0.1177053\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0865465\n",
      "\tspeed: 0.0358s/iter; left time: 507.9573s\n",
      "\titers: 200, epoch: 37 | loss: 0.0843475\n",
      "\tspeed: 0.0186s/iter; left time: 261.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0850028 Vali Loss: 0.0848001 Test Loss: 0.1175573\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0879359\n",
      "\tspeed: 0.0336s/iter; left time: 469.0670s\n",
      "\titers: 200, epoch: 38 | loss: 0.0862375\n",
      "\tspeed: 0.0193s/iter; left time: 267.1417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0847905 Vali Loss: 0.0845725 Test Loss: 0.1166489\n",
      "Validation loss decreased (0.084681 --> 0.084572).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0824188\n",
      "\tspeed: 0.0370s/iter; left time: 507.9463s\n",
      "\titers: 200, epoch: 39 | loss: 0.0815600\n",
      "\tspeed: 0.0180s/iter; left time: 245.3163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0847708 Vali Loss: 0.0846998 Test Loss: 0.1175155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0860271\n",
      "\tspeed: 0.0363s/iter; left time: 489.9145s\n",
      "\titers: 200, epoch: 40 | loss: 0.0826182\n",
      "\tspeed: 0.0166s/iter; left time: 222.6624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0848839 Vali Loss: 0.0847723 Test Loss: 0.1176447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0843057\n",
      "\tspeed: 0.0337s/iter; left time: 447.7400s\n",
      "\titers: 200, epoch: 41 | loss: 0.0847831\n",
      "\tspeed: 0.0188s/iter; left time: 248.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0846794 Vali Loss: 0.0846801 Test Loss: 0.1177645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0818505\n",
      "\tspeed: 0.0365s/iter; left time: 476.4972s\n",
      "\titers: 200, epoch: 42 | loss: 0.0846436\n",
      "\tspeed: 0.0170s/iter; left time: 219.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0848426 Vali Loss: 0.0846002 Test Loss: 0.1167957\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0865419\n",
      "\tspeed: 0.0321s/iter; left time: 412.1288s\n",
      "\titers: 200, epoch: 43 | loss: 0.0864775\n",
      "\tspeed: 0.0158s/iter; left time: 201.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0848241 Vali Loss: 0.0847245 Test Loss: 0.1173143\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0819034\n",
      "\tspeed: 0.0346s/iter; left time: 436.4216s\n",
      "\titers: 200, epoch: 44 | loss: 0.0881165\n",
      "\tspeed: 0.0169s/iter; left time: 211.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0847846 Vali Loss: 0.0846492 Test Loss: 0.1165506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0834732\n",
      "\tspeed: 0.0381s/iter; left time: 472.2354s\n",
      "\titers: 200, epoch: 45 | loss: 0.0909516\n",
      "\tspeed: 0.0146s/iter; left time: 179.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0847154 Vali Loss: 0.0847688 Test Loss: 0.1180594\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0832654\n",
      "\tspeed: 0.0348s/iter; left time: 423.9716s\n",
      "\titers: 200, epoch: 46 | loss: 0.0856518\n",
      "\tspeed: 0.0145s/iter; left time: 175.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0847128 Vali Loss: 0.0847007 Test Loss: 0.1177146\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0841189\n",
      "\tspeed: 0.0311s/iter; left time: 371.4549s\n",
      "\titers: 200, epoch: 47 | loss: 0.0849763\n",
      "\tspeed: 0.0188s/iter; left time: 222.8807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0849872 Vali Loss: 0.0846938 Test Loss: 0.1181525\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0812110\n",
      "\tspeed: 0.0319s/iter; left time: 373.9266s\n",
      "\titers: 200, epoch: 48 | loss: 0.0827201\n",
      "\tspeed: 0.0157s/iter; left time: 182.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0852178 Vali Loss: 0.0847629 Test Loss: 0.1171869\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030208632349967957, rmse:0.1738063097000122, mae:0.11664891242980957, rse:0.510627269744873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936766\n",
      "\tspeed: 0.0195s/iter; left time: 433.7390s\n",
      "\titers: 200, epoch: 1 | loss: 0.2709541\n",
      "\tspeed: 0.0174s/iter; left time: 384.8771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.2959534 Vali Loss: 0.2266825 Test Loss: 0.2452377\n",
      "Validation loss decreased (inf --> 0.226683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1484248\n",
      "\tspeed: 0.0367s/iter; left time: 807.1139s\n",
      "\titers: 200, epoch: 2 | loss: 0.1285656\n",
      "\tspeed: 0.0190s/iter; left time: 415.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.1607786 Vali Loss: 0.1127445 Test Loss: 0.1281586\n",
      "Validation loss decreased (0.226683 --> 0.112745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1119089\n",
      "\tspeed: 0.0357s/iter; left time: 776.2039s\n",
      "\titers: 200, epoch: 3 | loss: 0.1075492\n",
      "\tspeed: 0.0161s/iter; left time: 349.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.1122907 Vali Loss: 0.0982934 Test Loss: 0.1443596\n",
      "Validation loss decreased (0.112745 --> 0.098293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1015103\n",
      "\tspeed: 0.0360s/iter; left time: 774.1818s\n",
      "\titers: 200, epoch: 4 | loss: 0.0995555\n",
      "\tspeed: 0.0160s/iter; left time: 342.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.1016863 Vali Loss: 0.0950136 Test Loss: 0.1475585\n",
      "Validation loss decreased (0.098293 --> 0.095014).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1016375\n",
      "\tspeed: 0.0288s/iter; left time: 613.0182s\n",
      "\titers: 200, epoch: 5 | loss: 0.0967942\n",
      "\tspeed: 0.0220s/iter; left time: 466.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0967306 Vali Loss: 0.0911453 Test Loss: 0.1389572\n",
      "Validation loss decreased (0.095014 --> 0.091145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932338\n",
      "\tspeed: 0.0345s/iter; left time: 727.3113s\n",
      "\titers: 200, epoch: 6 | loss: 0.0947476\n",
      "\tspeed: 0.0156s/iter; left time: 327.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0941155 Vali Loss: 0.0897755 Test Loss: 0.1342266\n",
      "Validation loss decreased (0.091145 --> 0.089775).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0948261\n",
      "\tspeed: 0.0340s/iter; left time: 709.6834s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915033\n",
      "\tspeed: 0.0160s/iter; left time: 331.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0928360 Vali Loss: 0.0888792 Test Loss: 0.1301373\n",
      "Validation loss decreased (0.089775 --> 0.088879).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927390\n",
      "\tspeed: 0.0365s/iter; left time: 752.8957s\n",
      "\titers: 200, epoch: 8 | loss: 0.0897678\n",
      "\tspeed: 0.0180s/iter; left time: 369.8563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0908630 Vali Loss: 0.0870882 Test Loss: 0.1283409\n",
      "Validation loss decreased (0.088879 --> 0.087088).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0898859\n",
      "\tspeed: 0.0355s/iter; left time: 725.5595s\n",
      "\titers: 200, epoch: 9 | loss: 0.0944866\n",
      "\tspeed: 0.0191s/iter; left time: 387.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0899931 Vali Loss: 0.0873392 Test Loss: 0.1296829\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0860589\n",
      "\tspeed: 0.0387s/iter; left time: 782.2680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0880826\n",
      "\tspeed: 0.0188s/iter; left time: 378.0694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0890320 Vali Loss: 0.0880023 Test Loss: 0.1252401\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891895\n",
      "\tspeed: 0.0360s/iter; left time: 717.9930s\n",
      "\titers: 200, epoch: 11 | loss: 0.0849690\n",
      "\tspeed: 0.0167s/iter; left time: 331.8000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0884293 Vali Loss: 0.0866960 Test Loss: 0.1264054\n",
      "Validation loss decreased (0.087088 --> 0.086696).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0861983\n",
      "\tspeed: 0.0370s/iter; left time: 731.4701s\n",
      "\titers: 200, epoch: 12 | loss: 0.0884704\n",
      "\tspeed: 0.0180s/iter; left time: 354.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0879964 Vali Loss: 0.0858562 Test Loss: 0.1244201\n",
      "Validation loss decreased (0.086696 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872771\n",
      "\tspeed: 0.0342s/iter; left time: 667.9649s\n",
      "\titers: 200, epoch: 13 | loss: 0.0859470\n",
      "\tspeed: 0.0171s/iter; left time: 333.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0874375 Vali Loss: 0.0861715 Test Loss: 0.1191061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0909802\n",
      "\tspeed: 0.0343s/iter; left time: 661.3701s\n",
      "\titers: 200, epoch: 14 | loss: 0.0893463\n",
      "\tspeed: 0.0186s/iter; left time: 357.0788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0872263 Vali Loss: 0.0857841 Test Loss: 0.1219740\n",
      "Validation loss decreased (0.085856 --> 0.085784).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0821355\n",
      "\tspeed: 0.0385s/iter; left time: 733.9615s\n",
      "\titers: 200, epoch: 15 | loss: 0.0835384\n",
      "\tspeed: 0.0165s/iter; left time: 314.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0867242 Vali Loss: 0.0856983 Test Loss: 0.1216373\n",
      "Validation loss decreased (0.085784 --> 0.085698).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0841138\n",
      "\tspeed: 0.0331s/iter; left time: 623.5755s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816607\n",
      "\tspeed: 0.0172s/iter; left time: 322.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0865612 Vali Loss: 0.0855602 Test Loss: 0.1210224\n",
      "Validation loss decreased (0.085698 --> 0.085560).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0860154\n",
      "\tspeed: 0.0353s/iter; left time: 657.4088s\n",
      "\titers: 200, epoch: 17 | loss: 0.0875701\n",
      "\tspeed: 0.0179s/iter; left time: 331.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0863345 Vali Loss: 0.0855349 Test Loss: 0.1227551\n",
      "Validation loss decreased (0.085560 --> 0.085535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0845458\n",
      "\tspeed: 0.0366s/iter; left time: 673.8634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0840099\n",
      "\tspeed: 0.0179s/iter; left time: 327.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0860312 Vali Loss: 0.0856903 Test Loss: 0.1203355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0868545\n",
      "\tspeed: 0.0336s/iter; left time: 610.6870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866249\n",
      "\tspeed: 0.0159s/iter; left time: 287.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0859594 Vali Loss: 0.0854916 Test Loss: 0.1243568\n",
      "Validation loss decreased (0.085535 --> 0.085492).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0862166\n",
      "\tspeed: 0.0340s/iter; left time: 611.3516s\n",
      "\titers: 200, epoch: 20 | loss: 0.0874774\n",
      "\tspeed: 0.0160s/iter; left time: 285.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0860435 Vali Loss: 0.0858084 Test Loss: 0.1183013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0850150\n",
      "\tspeed: 0.0353s/iter; left time: 625.6077s\n",
      "\titers: 200, epoch: 21 | loss: 0.0864394\n",
      "\tspeed: 0.0163s/iter; left time: 287.4778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0856368 Vali Loss: 0.0854388 Test Loss: 0.1230027\n",
      "Validation loss decreased (0.085492 --> 0.085439).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0877366\n",
      "\tspeed: 0.0342s/iter; left time: 599.7834s\n",
      "\titers: 200, epoch: 22 | loss: 0.0863515\n",
      "\tspeed: 0.0128s/iter; left time: 222.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 223 | Train Loss: 0.0855459 Vali Loss: 0.0853280 Test Loss: 0.1221737\n",
      "Validation loss decreased (0.085439 --> 0.085328).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0841257\n",
      "\tspeed: 0.0376s/iter; left time: 649.5542s\n",
      "\titers: 200, epoch: 23 | loss: 0.0909050\n",
      "\tspeed: 0.0202s/iter; left time: 347.5737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0859897 Vali Loss: 0.0850827 Test Loss: 0.1209199\n",
      "Validation loss decreased (0.085328 --> 0.085083).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0865453\n",
      "\tspeed: 0.0380s/iter; left time: 648.5133s\n",
      "\titers: 200, epoch: 24 | loss: 0.0817557\n",
      "\tspeed: 0.0180s/iter; left time: 305.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0852483 Vali Loss: 0.0851978 Test Loss: 0.1221247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0881088\n",
      "\tspeed: 0.0336s/iter; left time: 565.9926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0845777\n",
      "\tspeed: 0.0166s/iter; left time: 278.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0852810 Vali Loss: 0.0851420 Test Loss: 0.1218498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0853654\n",
      "\tspeed: 0.0331s/iter; left time: 549.7960s\n",
      "\titers: 200, epoch: 26 | loss: 0.0871913\n",
      "\tspeed: 0.0166s/iter; left time: 274.5801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0852549 Vali Loss: 0.0853089 Test Loss: 0.1178274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0828175\n",
      "\tspeed: 0.0341s/iter; left time: 559.9754s\n",
      "\titers: 200, epoch: 27 | loss: 0.0835795\n",
      "\tspeed: 0.0157s/iter; left time: 256.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0851044 Vali Loss: 0.0852497 Test Loss: 0.1212532\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0812769\n",
      "\tspeed: 0.0352s/iter; left time: 569.9113s\n",
      "\titers: 200, epoch: 28 | loss: 0.0857387\n",
      "\tspeed: 0.0168s/iter; left time: 270.1382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0849103 Vali Loss: 0.0851154 Test Loss: 0.1210589\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0882356\n",
      "\tspeed: 0.0393s/iter; left time: 626.5245s\n",
      "\titers: 200, epoch: 29 | loss: 0.0865537\n",
      "\tspeed: 0.0220s/iter; left time: 348.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0849218 Vali Loss: 0.0852312 Test Loss: 0.1212687\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0853896\n",
      "\tspeed: 0.0384s/iter; left time: 603.4518s\n",
      "\titers: 200, epoch: 30 | loss: 0.0860251\n",
      "\tspeed: 0.0175s/iter; left time: 274.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0849076 Vali Loss: 0.0850290 Test Loss: 0.1206462\n",
      "Validation loss decreased (0.085083 --> 0.085029).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0797477\n",
      "\tspeed: 0.0376s/iter; left time: 582.4983s\n",
      "\titers: 200, epoch: 31 | loss: 0.0851969\n",
      "\tspeed: 0.0194s/iter; left time: 299.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0846795 Vali Loss: 0.0850434 Test Loss: 0.1210503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0870848\n",
      "\tspeed: 0.0368s/iter; left time: 562.0830s\n",
      "\titers: 200, epoch: 32 | loss: 0.0842670\n",
      "\tspeed: 0.0165s/iter; left time: 251.3086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0847752 Vali Loss: 0.0848986 Test Loss: 0.1220104\n",
      "Validation loss decreased (0.085029 --> 0.084899).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0898801\n",
      "\tspeed: 0.0327s/iter; left time: 492.4006s\n",
      "\titers: 200, epoch: 33 | loss: 0.0836809\n",
      "\tspeed: 0.0158s/iter; left time: 235.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0847292 Vali Loss: 0.0852259 Test Loss: 0.1219195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0837929\n",
      "\tspeed: 0.0351s/iter; left time: 521.4885s\n",
      "\titers: 200, epoch: 34 | loss: 0.0836860\n",
      "\tspeed: 0.0161s/iter; left time: 236.8359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0847673 Vali Loss: 0.0849829 Test Loss: 0.1205885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0791291\n",
      "\tspeed: 0.0353s/iter; left time: 516.6121s\n",
      "\titers: 200, epoch: 35 | loss: 0.0867016\n",
      "\tspeed: 0.0173s/iter; left time: 250.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0846931 Vali Loss: 0.0847738 Test Loss: 0.1200557\n",
      "Validation loss decreased (0.084899 --> 0.084774).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0825419\n",
      "\tspeed: 0.0364s/iter; left time: 523.8405s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818884\n",
      "\tspeed: 0.0168s/iter; left time: 240.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0847716 Vali Loss: 0.0851145 Test Loss: 0.1205825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0842333\n",
      "\tspeed: 0.0331s/iter; left time: 469.1586s\n",
      "\titers: 200, epoch: 37 | loss: 0.0840733\n",
      "\tspeed: 0.0179s/iter; left time: 251.6887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0847814 Vali Loss: 0.0850427 Test Loss: 0.1206309\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0844751\n",
      "\tspeed: 0.0352s/iter; left time: 490.9539s\n",
      "\titers: 200, epoch: 38 | loss: 0.0847934\n",
      "\tspeed: 0.0181s/iter; left time: 250.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0846022 Vali Loss: 0.0850175 Test Loss: 0.1210655\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0868304\n",
      "\tspeed: 0.0346s/iter; left time: 475.2749s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850215\n",
      "\tspeed: 0.0153s/iter; left time: 208.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.0846205 Vali Loss: 0.0848845 Test Loss: 0.1202597\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0842630\n",
      "\tspeed: 0.0345s/iter; left time: 465.5187s\n",
      "\titers: 200, epoch: 40 | loss: 0.0834212\n",
      "\tspeed: 0.0182s/iter; left time: 244.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0848620 Vali Loss: 0.0848508 Test Loss: 0.1195751\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0840192\n",
      "\tspeed: 0.0337s/iter; left time: 447.9296s\n",
      "\titers: 200, epoch: 41 | loss: 0.0870575\n",
      "\tspeed: 0.0162s/iter; left time: 214.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0848115 Vali Loss: 0.0849902 Test Loss: 0.1198146\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0841808\n",
      "\tspeed: 0.0340s/iter; left time: 444.0658s\n",
      "\titers: 200, epoch: 42 | loss: 0.0868494\n",
      "\tspeed: 0.0159s/iter; left time: 205.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0845862 Vali Loss: 0.0849694 Test Loss: 0.1206443\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0820462\n",
      "\tspeed: 0.0357s/iter; left time: 458.6183s\n",
      "\titers: 200, epoch: 43 | loss: 0.0855732\n",
      "\tspeed: 0.0185s/iter; left time: 235.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0846324 Vali Loss: 0.0848957 Test Loss: 0.1199307\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0842967\n",
      "\tspeed: 0.0415s/iter; left time: 522.9000s\n",
      "\titers: 200, epoch: 44 | loss: 0.0861039\n",
      "\tspeed: 0.0202s/iter; left time: 253.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0845637 Vali Loss: 0.0851495 Test Loss: 0.1212666\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0880421\n",
      "\tspeed: 0.0357s/iter; left time: 441.9097s\n",
      "\titers: 200, epoch: 45 | loss: 0.0826582\n",
      "\tspeed: 0.0148s/iter; left time: 181.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.0844917 Vali Loss: 0.0848732 Test Loss: 0.1199118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.034120410680770874, rmse:0.1847171038389206, mae:0.1200556606054306, rse:0.5426822304725647\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:18.44s\n",
      "Intermediate time for ES: 00h:31m:26.60s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0364s/iter; left time: 811.5746s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0152s/iter; left time: 337.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0348s/iter; left time: 768.1979s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0161s/iter; left time: 354.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0314s/iter; left time: 685.8746s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0188s/iter; left time: 409.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0364s/iter; left time: 787.2711s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0177s/iter; left time: 380.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0324s/iter; left time: 693.5169s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0162s/iter; left time: 344.2447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0327s/iter; left time: 692.6802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0157s/iter; left time: 330.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0366s/iter; left time: 766.3874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0181s/iter; left time: 376.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0348s/iter; left time: 722.1879s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0168s/iter; left time: 346.4565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0264s/iter; left time: 540.4740s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0120s/iter; left time: 245.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0349s/iter; left time: 708.4593s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0175s/iter; left time: 352.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0335s/iter; left time: 671.8071s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0178s/iter; left time: 355.4825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0329s/iter; left time: 652.8421s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0154s/iter; left time: 304.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0343s/iter; left time: 673.5114s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0176s/iter; left time: 343.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0326s/iter; left time: 631.7426s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0172s/iter; left time: 332.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0320s/iter; left time: 613.5947s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0157s/iter; left time: 298.9474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0341s/iter; left time: 646.6263s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0205s/iter; left time: 385.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0395s/iter; left time: 739.3276s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0202s/iter; left time: 376.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0373s/iter; left time: 689.8153s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0171s/iter; left time: 313.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0354s/iter; left time: 647.3843s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0161s/iter; left time: 293.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0334s/iter; left time: 602.1900s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0155s/iter; left time: 277.7131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0500307\n",
      "\tspeed: 0.0379s/iter; left time: 674.5867s\n",
      "\titers: 200, epoch: 21 | loss: 0.0490154\n",
      "\tspeed: 0.0188s/iter; left time: 333.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0510271 Vali Loss: 0.0585692 Test Loss: 0.0614969\n",
      "Validation loss decreased (0.058856 --> 0.058569).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0487849\n",
      "\tspeed: 0.0333s/iter; left time: 586.3702s\n",
      "\titers: 200, epoch: 22 | loss: 0.0499946\n",
      "\tspeed: 0.0142s/iter; left time: 248.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0509135 Vali Loss: 0.0583646 Test Loss: 0.0612312\n",
      "Validation loss decreased (0.058569 --> 0.058365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511933\n",
      "\tspeed: 0.0340s/iter; left time: 590.4854s\n",
      "\titers: 200, epoch: 23 | loss: 0.0494870\n",
      "\tspeed: 0.0167s/iter; left time: 287.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0507191 Vali Loss: 0.0584055 Test Loss: 0.0613245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0491849\n",
      "\tspeed: 0.0361s/iter; left time: 618.5315s\n",
      "\titers: 200, epoch: 24 | loss: 0.0487800\n",
      "\tspeed: 0.0198s/iter; left time: 337.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0509352 Vali Loss: 0.0585210 Test Loss: 0.0614635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0493839\n",
      "\tspeed: 0.0340s/iter; left time: 575.3153s\n",
      "\titers: 200, epoch: 25 | loss: 0.0514642\n",
      "\tspeed: 0.0178s/iter; left time: 299.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0506817 Vali Loss: 0.0584098 Test Loss: 0.0612296\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0499401\n",
      "\tspeed: 0.0314s/iter; left time: 524.5447s\n",
      "\titers: 200, epoch: 26 | loss: 0.0537204\n",
      "\tspeed: 0.0151s/iter; left time: 249.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0504769 Vali Loss: 0.0582367 Test Loss: 0.0610654\n",
      "Validation loss decreased (0.058365 --> 0.058237).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0544665\n",
      "\tspeed: 0.0354s/iter; left time: 582.8643s\n",
      "\titers: 200, epoch: 27 | loss: 0.0464305\n",
      "\tspeed: 0.0218s/iter; left time: 357.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0507225 Vali Loss: 0.0584667 Test Loss: 0.0613662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0510654\n",
      "\tspeed: 0.0334s/iter; left time: 542.7082s\n",
      "\titers: 200, epoch: 28 | loss: 0.0489795\n",
      "\tspeed: 0.0186s/iter; left time: 300.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0504315 Vali Loss: 0.0583163 Test Loss: 0.0612576\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0505894\n",
      "\tspeed: 0.0352s/iter; left time: 563.6586s\n",
      "\titers: 200, epoch: 29 | loss: 0.0509785\n",
      "\tspeed: 0.0191s/iter; left time: 304.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0504090 Vali Loss: 0.0582874 Test Loss: 0.0612145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0510114\n",
      "\tspeed: 0.0332s/iter; left time: 525.2881s\n",
      "\titers: 200, epoch: 30 | loss: 0.0490248\n",
      "\tspeed: 0.0157s/iter; left time: 245.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0503936 Vali Loss: 0.0581573 Test Loss: 0.0610772\n",
      "Validation loss decreased (0.058237 --> 0.058157).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0496442\n",
      "\tspeed: 0.0335s/iter; left time: 521.9809s\n",
      "\titers: 200, epoch: 31 | loss: 0.0525338\n",
      "\tspeed: 0.0197s/iter; left time: 304.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0502830 Vali Loss: 0.0582156 Test Loss: 0.0611820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0478567\n",
      "\tspeed: 0.0325s/iter; left time: 498.5152s\n",
      "\titers: 200, epoch: 32 | loss: 0.0482991\n",
      "\tspeed: 0.0163s/iter; left time: 248.3758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0502242 Vali Loss: 0.0581192 Test Loss: 0.0610652\n",
      "Validation loss decreased (0.058157 --> 0.058119).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0482565\n",
      "\tspeed: 0.0313s/iter; left time: 474.0346s\n",
      "\titers: 200, epoch: 33 | loss: 0.0504164\n",
      "\tspeed: 0.0164s/iter; left time: 246.0203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0501112 Vali Loss: 0.0580270 Test Loss: 0.0608346\n",
      "Validation loss decreased (0.058119 --> 0.058027).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0502544\n",
      "\tspeed: 0.0343s/iter; left time: 511.5849s\n",
      "\titers: 200, epoch: 34 | loss: 0.0484893\n",
      "\tspeed: 0.0165s/iter; left time: 243.6155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0499967 Vali Loss: 0.0579108 Test Loss: 0.0607200\n",
      "Validation loss decreased (0.058027 --> 0.057911).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510540\n",
      "\tspeed: 0.0356s/iter; left time: 522.1898s\n",
      "\titers: 200, epoch: 35 | loss: 0.0495207\n",
      "\tspeed: 0.0200s/iter; left time: 292.1834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0501554 Vali Loss: 0.0580440 Test Loss: 0.0608846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0460694\n",
      "\tspeed: 0.0361s/iter; left time: 521.7529s\n",
      "\titers: 200, epoch: 36 | loss: 0.0490633\n",
      "\tspeed: 0.0184s/iter; left time: 264.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0499619 Vali Loss: 0.0581870 Test Loss: 0.0610619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0493442\n",
      "\tspeed: 0.0331s/iter; left time: 470.8161s\n",
      "\titers: 200, epoch: 37 | loss: 0.0520324\n",
      "\tspeed: 0.0179s/iter; left time: 253.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0500377 Vali Loss: 0.0579085 Test Loss: 0.0607732\n",
      "Validation loss decreased (0.057911 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0495058\n",
      "\tspeed: 0.0317s/iter; left time: 444.3579s\n",
      "\titers: 200, epoch: 38 | loss: 0.0469532\n",
      "\tspeed: 0.0161s/iter; left time: 224.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0499961 Vali Loss: 0.0579373 Test Loss: 0.0607163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0499609\n",
      "\tspeed: 0.0352s/iter; left time: 485.6928s\n",
      "\titers: 200, epoch: 39 | loss: 0.0492594\n",
      "\tspeed: 0.0188s/iter; left time: 256.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0498864 Vali Loss: 0.0580742 Test Loss: 0.0609236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0493156\n",
      "\tspeed: 0.0340s/iter; left time: 460.5502s\n",
      "\titers: 200, epoch: 40 | loss: 0.0476659\n",
      "\tspeed: 0.0161s/iter; left time: 216.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0500837 Vali Loss: 0.0582142 Test Loss: 0.0610824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0488396\n",
      "\tspeed: 0.0308s/iter; left time: 410.9392s\n",
      "\titers: 200, epoch: 41 | loss: 0.0483784\n",
      "\tspeed: 0.0156s/iter; left time: 205.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0499609 Vali Loss: 0.0579718 Test Loss: 0.0607426\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0522610\n",
      "\tspeed: 0.0354s/iter; left time: 464.5353s\n",
      "\titers: 200, epoch: 42 | loss: 0.0530269\n",
      "\tspeed: 0.0174s/iter; left time: 226.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0498560 Vali Loss: 0.0579498 Test Loss: 0.0607294\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0493973\n",
      "\tspeed: 0.0340s/iter; left time: 438.7859s\n",
      "\titers: 200, epoch: 43 | loss: 0.0526842\n",
      "\tspeed: 0.0202s/iter; left time: 258.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0499097 Vali Loss: 0.0578594 Test Loss: 0.0606453\n",
      "Validation loss decreased (0.057909 --> 0.057859).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0515855\n",
      "\tspeed: 0.0350s/iter; left time: 443.3847s\n",
      "\titers: 200, epoch: 44 | loss: 0.0481943\n",
      "\tspeed: 0.0186s/iter; left time: 234.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0498872 Vali Loss: 0.0578712 Test Loss: 0.0607137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0520111\n",
      "\tspeed: 0.0339s/iter; left time: 421.9038s\n",
      "\titers: 200, epoch: 45 | loss: 0.0519452\n",
      "\tspeed: 0.0179s/iter; left time: 220.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0499239 Vali Loss: 0.0579881 Test Loss: 0.0608724\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0476939\n",
      "\tspeed: 0.0354s/iter; left time: 432.9084s\n",
      "\titers: 200, epoch: 46 | loss: 0.0521748\n",
      "\tspeed: 0.0189s/iter; left time: 229.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0498292 Vali Loss: 0.0580555 Test Loss: 0.0609686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0484655\n",
      "\tspeed: 0.0346s/iter; left time: 414.5181s\n",
      "\titers: 200, epoch: 47 | loss: 0.0480573\n",
      "\tspeed: 0.0188s/iter; left time: 223.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0499865 Vali Loss: 0.0583157 Test Loss: 0.0612470\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0510940\n",
      "\tspeed: 0.0345s/iter; left time: 405.6405s\n",
      "\titers: 200, epoch: 48 | loss: 0.0530471\n",
      "\tspeed: 0.0174s/iter; left time: 202.8786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0497833 Vali Loss: 0.0579604 Test Loss: 0.0608368\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0501904\n",
      "\tspeed: 0.0363s/iter; left time: 419.7043s\n",
      "\titers: 200, epoch: 49 | loss: 0.0487544\n",
      "\tspeed: 0.0177s/iter; left time: 202.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0497741 Vali Loss: 0.0577866 Test Loss: 0.0606853\n",
      "Validation loss decreased (0.057859 --> 0.057787).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0508748\n",
      "\tspeed: 0.0343s/iter; left time: 388.1568s\n",
      "\titers: 200, epoch: 50 | loss: 0.0485370\n",
      "\tspeed: 0.0124s/iter; left time: 139.1616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 224 | Train Loss: 0.0498600 Vali Loss: 0.0578839 Test Loss: 0.0606901\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0541600\n",
      "\tspeed: 0.0302s/iter; left time: 335.6662s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510142\n",
      "\tspeed: 0.0157s/iter; left time: 172.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0497815 Vali Loss: 0.0579270 Test Loss: 0.0607067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0498654\n",
      "\tspeed: 0.0355s/iter; left time: 386.0776s\n",
      "\titers: 200, epoch: 52 | loss: 0.0535375\n",
      "\tspeed: 0.0213s/iter; left time: 229.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0498009 Vali Loss: 0.0578123 Test Loss: 0.0606300\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0521141\n",
      "\tspeed: 0.0324s/iter; left time: 345.0800s\n",
      "\titers: 200, epoch: 53 | loss: 0.0494763\n",
      "\tspeed: 0.0190s/iter; left time: 200.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0497956 Vali Loss: 0.0577853 Test Loss: 0.0606052\n",
      "Validation loss decreased (0.057787 --> 0.057785).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0518647\n",
      "\tspeed: 0.0346s/iter; left time: 361.0512s\n",
      "\titers: 200, epoch: 54 | loss: 0.0501313\n",
      "\tspeed: 0.0163s/iter; left time: 168.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0497809 Vali Loss: 0.0579372 Test Loss: 0.0607195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0496054\n",
      "\tspeed: 0.0302s/iter; left time: 308.2633s\n",
      "\titers: 200, epoch: 55 | loss: 0.0486854\n",
      "\tspeed: 0.0189s/iter; left time: 190.4872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0497393 Vali Loss: 0.0578342 Test Loss: 0.0605182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0485080\n",
      "\tspeed: 0.0380s/iter; left time: 379.5286s\n",
      "\titers: 200, epoch: 56 | loss: 0.0464521\n",
      "\tspeed: 0.0155s/iter; left time: 152.8191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0498971 Vali Loss: 0.0578821 Test Loss: 0.0606105\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0527421\n",
      "\tspeed: 0.0336s/iter; left time: 327.5818s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523424\n",
      "\tspeed: 0.0200s/iter; left time: 192.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0498499 Vali Loss: 0.0578462 Test Loss: 0.0606600\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0476605\n",
      "\tspeed: 0.0361s/iter; left time: 344.3484s\n",
      "\titers: 200, epoch: 58 | loss: 0.0482116\n",
      "\tspeed: 0.0199s/iter; left time: 188.0726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0497194 Vali Loss: 0.0577791 Test Loss: 0.0605505\n",
      "Validation loss decreased (0.057785 --> 0.057779).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0505652\n",
      "\tspeed: 0.0333s/iter; left time: 309.9329s\n",
      "\titers: 200, epoch: 59 | loss: 0.0538413\n",
      "\tspeed: 0.0161s/iter; left time: 148.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0497615 Vali Loss: 0.0579725 Test Loss: 0.0608881\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0523902\n",
      "\tspeed: 0.0319s/iter; left time: 289.9245s\n",
      "\titers: 200, epoch: 60 | loss: 0.0489338\n",
      "\tspeed: 0.0173s/iter; left time: 155.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0497763 Vali Loss: 0.0577925 Test Loss: 0.0605517\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0532521\n",
      "\tspeed: 0.0314s/iter; left time: 278.5102s\n",
      "\titers: 200, epoch: 61 | loss: 0.0454659\n",
      "\tspeed: 0.0166s/iter; left time: 145.5520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0498417 Vali Loss: 0.0578000 Test Loss: 0.0605808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0490412\n",
      "\tspeed: 0.0331s/iter; left time: 286.1881s\n",
      "\titers: 200, epoch: 62 | loss: 0.0466805\n",
      "\tspeed: 0.0194s/iter; left time: 165.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0496877 Vali Loss: 0.0580046 Test Loss: 0.0608975\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0493944\n",
      "\tspeed: 0.0338s/iter; left time: 284.0057s\n",
      "\titers: 200, epoch: 63 | loss: 0.0473165\n",
      "\tspeed: 0.0172s/iter; left time: 142.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0497746 Vali Loss: 0.0578258 Test Loss: 0.0607631\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0499734\n",
      "\tspeed: 0.0330s/iter; left time: 270.5718s\n",
      "\titers: 200, epoch: 64 | loss: 0.0489092\n",
      "\tspeed: 0.0178s/iter; left time: 144.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0497661 Vali Loss: 0.0577920 Test Loss: 0.0605248\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0476629\n",
      "\tspeed: 0.0329s/iter; left time: 262.3760s\n",
      "\titers: 200, epoch: 65 | loss: 0.0475802\n",
      "\tspeed: 0.0154s/iter; left time: 121.4726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0497550 Vali Loss: 0.0577449 Test Loss: 0.0606460\n",
      "Validation loss decreased (0.057779 --> 0.057745).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0496131\n",
      "\tspeed: 0.0320s/iter; left time: 247.8547s\n",
      "\titers: 200, epoch: 66 | loss: 0.0514756\n",
      "\tspeed: 0.0173s/iter; left time: 132.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0497879 Vali Loss: 0.0578677 Test Loss: 0.0606613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0534090\n",
      "\tspeed: 0.0349s/iter; left time: 262.0350s\n",
      "\titers: 200, epoch: 67 | loss: 0.0471433\n",
      "\tspeed: 0.0176s/iter; left time: 130.2227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0498299 Vali Loss: 0.0578383 Test Loss: 0.0607215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0482797\n",
      "\tspeed: 0.0332s/iter; left time: 242.0368s\n",
      "\titers: 200, epoch: 68 | loss: 0.0527938\n",
      "\tspeed: 0.0158s/iter; left time: 113.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0498227 Vali Loss: 0.0578183 Test Loss: 0.0606315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0529874\n",
      "\tspeed: 0.0344s/iter; left time: 242.9513s\n",
      "\titers: 200, epoch: 69 | loss: 0.0479324\n",
      "\tspeed: 0.0174s/iter; left time: 121.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0498894 Vali Loss: 0.0577414 Test Loss: 0.0606067\n",
      "Validation loss decreased (0.057745 --> 0.057741).  Saving model ...\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0520114\n",
      "\tspeed: 0.0322s/iter; left time: 220.4005s\n",
      "\titers: 200, epoch: 70 | loss: 0.0495122\n",
      "\tspeed: 0.0126s/iter; left time: 85.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 224 | Train Loss: 0.0497955 Vali Loss: 0.0576698 Test Loss: 0.0605525\n",
      "Validation loss decreased (0.057741 --> 0.057670).  Saving model ...\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0490391\n",
      "\tspeed: 0.0304s/iter; left time: 201.4482s\n",
      "\titers: 200, epoch: 71 | loss: 0.0496808\n",
      "\tspeed: 0.0161s/iter; left time: 105.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0496891 Vali Loss: 0.0578580 Test Loss: 0.0607717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0504889\n",
      "\tspeed: 0.0344s/iter; left time: 220.0847s\n",
      "\titers: 200, epoch: 72 | loss: 0.0489570\n",
      "\tspeed: 0.0185s/iter; left time: 116.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0498359 Vali Loss: 0.0578459 Test Loss: 0.0606254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0496917\n",
      "\tspeed: 0.0342s/iter; left time: 211.1219s\n",
      "\titers: 200, epoch: 73 | loss: 0.0486437\n",
      "\tspeed: 0.0150s/iter; left time: 91.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0497904 Vali Loss: 0.0578623 Test Loss: 0.0606682\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0502861\n",
      "\tspeed: 0.0319s/iter; left time: 189.5269s\n",
      "\titers: 200, epoch: 74 | loss: 0.0482049\n",
      "\tspeed: 0.0185s/iter; left time: 108.3138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0498100 Vali Loss: 0.0577250 Test Loss: 0.0606257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0496599\n",
      "\tspeed: 0.0336s/iter; left time: 192.3722s\n",
      "\titers: 200, epoch: 75 | loss: 0.0485606\n",
      "\tspeed: 0.0131s/iter; left time: 73.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0497395 Vali Loss: 0.0578765 Test Loss: 0.0607232\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0489640\n",
      "\tspeed: 0.0314s/iter; left time: 172.8167s\n",
      "\titers: 200, epoch: 76 | loss: 0.0500719\n",
      "\tspeed: 0.0176s/iter; left time: 95.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0497012 Vali Loss: 0.0578201 Test Loss: 0.0606754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0562747\n",
      "\tspeed: 0.0324s/iter; left time: 170.7688s\n",
      "\titers: 200, epoch: 77 | loss: 0.0470544\n",
      "\tspeed: 0.0166s/iter; left time: 86.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0496969 Vali Loss: 0.0577695 Test Loss: 0.0605956\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0477906\n",
      "\tspeed: 0.0349s/iter; left time: 176.3502s\n",
      "\titers: 200, epoch: 78 | loss: 0.0496063\n",
      "\tspeed: 0.0191s/iter; left time: 94.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0498004 Vali Loss: 0.0579858 Test Loss: 0.0608449\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0492227\n",
      "\tspeed: 0.0311s/iter; left time: 150.4149s\n",
      "\titers: 200, epoch: 79 | loss: 0.0496928\n",
      "\tspeed: 0.0167s/iter; left time: 78.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0497735 Vali Loss: 0.0578129 Test Loss: 0.0606371\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0483101\n",
      "\tspeed: 0.0340s/iter; left time: 156.5560s\n",
      "\titers: 200, epoch: 80 | loss: 0.0474963\n",
      "\tspeed: 0.0182s/iter; left time: 82.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0497277 Vali Loss: 0.0579814 Test Loss: 0.0608682\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010923855006694794, rmse:0.10451724380254745, mae:0.060552507638931274, rse:0.4032246470451355\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2416472\n",
      "\tspeed: 0.0223s/iter; left time: 496.5605s\n",
      "\titers: 200, epoch: 1 | loss: 0.2157288\n",
      "\tspeed: 0.0160s/iter; left time: 354.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.2390083 Vali Loss: 0.1850636 Test Loss: 0.1906125\n",
      "Validation loss decreased (inf --> 0.185064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1321534\n",
      "\tspeed: 0.0347s/iter; left time: 765.1894s\n",
      "\titers: 200, epoch: 2 | loss: 0.0980146\n",
      "\tspeed: 0.0178s/iter; left time: 391.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1389367 Vali Loss: 0.0845335 Test Loss: 0.0928966\n",
      "Validation loss decreased (0.185064 --> 0.084534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0873793\n",
      "\tspeed: 0.0330s/iter; left time: 721.2210s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807172\n",
      "\tspeed: 0.0165s/iter; left time: 359.1415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0858602 Vali Loss: 0.0766271 Test Loss: 0.0801685\n",
      "Validation loss decreased (0.084534 --> 0.076627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0747777\n",
      "\tspeed: 0.0321s/iter; left time: 693.4468s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713048\n",
      "\tspeed: 0.0165s/iter; left time: 354.7525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0727825 Vali Loss: 0.0689248 Test Loss: 0.0718431\n",
      "Validation loss decreased (0.076627 --> 0.068925).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0664114\n",
      "\tspeed: 0.0346s/iter; left time: 740.0460s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626735\n",
      "\tspeed: 0.0176s/iter; left time: 375.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0665844 Vali Loss: 0.0659335 Test Loss: 0.0688953\n",
      "Validation loss decreased (0.068925 --> 0.065934).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640696\n",
      "\tspeed: 0.0373s/iter; left time: 789.9279s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583320\n",
      "\tspeed: 0.0185s/iter; left time: 390.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0631395 Vali Loss: 0.0637366 Test Loss: 0.0662843\n",
      "Validation loss decreased (0.065934 --> 0.063737).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611526\n",
      "\tspeed: 0.0332s/iter; left time: 695.6691s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601704\n",
      "\tspeed: 0.0127s/iter; left time: 265.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 224 | Train Loss: 0.0600838 Vali Loss: 0.0636623 Test Loss: 0.0658088\n",
      "Validation loss decreased (0.063737 --> 0.063662).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0638688\n",
      "\tspeed: 0.0326s/iter; left time: 676.5235s\n",
      "\titers: 200, epoch: 8 | loss: 0.0564657\n",
      "\tspeed: 0.0155s/iter; left time: 320.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0582559 Vali Loss: 0.0636032 Test Loss: 0.0659900\n",
      "Validation loss decreased (0.063662 --> 0.063603).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0594054\n",
      "\tspeed: 0.0321s/iter; left time: 657.7188s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544079\n",
      "\tspeed: 0.0166s/iter; left time: 339.1764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0566816 Vali Loss: 0.0611874 Test Loss: 0.0644945\n",
      "Validation loss decreased (0.063603 --> 0.061187).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0531490\n",
      "\tspeed: 0.0359s/iter; left time: 728.9152s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550409\n",
      "\tspeed: 0.0177s/iter; left time: 356.4827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0556962 Vali Loss: 0.0607619 Test Loss: 0.0637574\n",
      "Validation loss decreased (0.061187 --> 0.060762).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0540955\n",
      "\tspeed: 0.0343s/iter; left time: 687.6507s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529300\n",
      "\tspeed: 0.0133s/iter; left time: 265.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0546806 Vali Loss: 0.0601323 Test Loss: 0.0631922\n",
      "Validation loss decreased (0.060762 --> 0.060132).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549707\n",
      "\tspeed: 0.0318s/iter; left time: 630.5135s\n",
      "\titers: 200, epoch: 12 | loss: 0.0538874\n",
      "\tspeed: 0.0112s/iter; left time: 220.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0541219 Vali Loss: 0.0603495 Test Loss: 0.0632753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556391\n",
      "\tspeed: 0.0311s/iter; left time: 609.5842s\n",
      "\titers: 200, epoch: 13 | loss: 0.0565307\n",
      "\tspeed: 0.0105s/iter; left time: 204.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 224 | Train Loss: 0.0537329 Vali Loss: 0.0602877 Test Loss: 0.0631722\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507059\n",
      "\tspeed: 0.0340s/iter; left time: 659.6177s\n",
      "\titers: 200, epoch: 14 | loss: 0.0497007\n",
      "\tspeed: 0.0172s/iter; left time: 331.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0535748 Vali Loss: 0.0596906 Test Loss: 0.0627980\n",
      "Validation loss decreased (0.060132 --> 0.059691).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0525676\n",
      "\tspeed: 0.0346s/iter; left time: 663.5514s\n",
      "\titers: 200, epoch: 15 | loss: 0.0544337\n",
      "\tspeed: 0.0202s/iter; left time: 385.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0528798 Vali Loss: 0.0596838 Test Loss: 0.0626478\n",
      "Validation loss decreased (0.059691 --> 0.059684).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0518733\n",
      "\tspeed: 0.0359s/iter; left time: 680.1385s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502742\n",
      "\tspeed: 0.0203s/iter; left time: 382.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0523913 Vali Loss: 0.0595967 Test Loss: 0.0625617\n",
      "Validation loss decreased (0.059684 --> 0.059597).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0526551\n",
      "\tspeed: 0.0330s/iter; left time: 617.7874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0533199\n",
      "\tspeed: 0.0185s/iter; left time: 344.4487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0521800 Vali Loss: 0.0591736 Test Loss: 0.0620432\n",
      "Validation loss decreased (0.059597 --> 0.059174).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0531408\n",
      "\tspeed: 0.0356s/iter; left time: 657.4889s\n",
      "\titers: 200, epoch: 18 | loss: 0.0512082\n",
      "\tspeed: 0.0185s/iter; left time: 339.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0518041 Vali Loss: 0.0590653 Test Loss: 0.0620126\n",
      "Validation loss decreased (0.059174 --> 0.059065).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0508133\n",
      "\tspeed: 0.0334s/iter; left time: 610.0976s\n",
      "\titers: 200, epoch: 19 | loss: 0.0508652\n",
      "\tspeed: 0.0178s/iter; left time: 323.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0516297 Vali Loss: 0.0590433 Test Loss: 0.0620764\n",
      "Validation loss decreased (0.059065 --> 0.059043).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0503310\n",
      "\tspeed: 0.0335s/iter; left time: 604.6233s\n",
      "\titers: 200, epoch: 20 | loss: 0.0477689\n",
      "\tspeed: 0.0160s/iter; left time: 286.3294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0516755 Vali Loss: 0.0588695 Test Loss: 0.0618976\n",
      "Validation loss decreased (0.059043 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0502275\n",
      "\tspeed: 0.0328s/iter; left time: 583.7439s\n",
      "\titers: 200, epoch: 21 | loss: 0.0473861\n",
      "\tspeed: 0.0172s/iter; left time: 305.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0513905 Vali Loss: 0.0589136 Test Loss: 0.0618429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0501105\n",
      "\tspeed: 0.0317s/iter; left time: 558.6450s\n",
      "\titers: 200, epoch: 22 | loss: 0.0505043\n",
      "\tspeed: 0.0164s/iter; left time: 286.6638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0512485 Vali Loss: 0.0587117 Test Loss: 0.0616255\n",
      "Validation loss decreased (0.058869 --> 0.058712).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0516095\n",
      "\tspeed: 0.0340s/iter; left time: 590.0227s\n",
      "\titers: 200, epoch: 23 | loss: 0.0515190\n",
      "\tspeed: 0.0193s/iter; left time: 333.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0511317 Vali Loss: 0.0588214 Test Loss: 0.0617099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492050\n",
      "\tspeed: 0.0372s/iter; left time: 637.8509s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538395\n",
      "\tspeed: 0.0203s/iter; left time: 346.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0510162 Vali Loss: 0.0590029 Test Loss: 0.0619497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0478245\n",
      "\tspeed: 0.0340s/iter; left time: 575.9198s\n",
      "\titers: 200, epoch: 25 | loss: 0.0501745\n",
      "\tspeed: 0.0176s/iter; left time: 296.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0508491 Vali Loss: 0.0588119 Test Loss: 0.0616985\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0482835\n",
      "\tspeed: 0.0334s/iter; left time: 558.2063s\n",
      "\titers: 200, epoch: 26 | loss: 0.0496864\n",
      "\tspeed: 0.0206s/iter; left time: 341.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0507353 Vali Loss: 0.0590678 Test Loss: 0.0619756\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0505852\n",
      "\tspeed: 0.0347s/iter; left time: 571.4671s\n",
      "\titers: 200, epoch: 27 | loss: 0.0507914\n",
      "\tspeed: 0.0179s/iter; left time: 292.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0505978 Vali Loss: 0.0586039 Test Loss: 0.0615524\n",
      "Validation loss decreased (0.058712 --> 0.058604).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0502958\n",
      "\tspeed: 0.0330s/iter; left time: 536.6304s\n",
      "\titers: 200, epoch: 28 | loss: 0.0489078\n",
      "\tspeed: 0.0199s/iter; left time: 321.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0505392 Vali Loss: 0.0587085 Test Loss: 0.0615680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0505078\n",
      "\tspeed: 0.0371s/iter; left time: 594.4562s\n",
      "\titers: 200, epoch: 29 | loss: 0.0474629\n",
      "\tspeed: 0.0218s/iter; left time: 346.8326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0506125 Vali Loss: 0.0583189 Test Loss: 0.0612263\n",
      "Validation loss decreased (0.058604 --> 0.058319).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523297\n",
      "\tspeed: 0.0364s/iter; left time: 575.0965s\n",
      "\titers: 200, epoch: 30 | loss: 0.0533438\n",
      "\tspeed: 0.0193s/iter; left time: 302.8766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0505089 Vali Loss: 0.0584156 Test Loss: 0.0612568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0503295\n",
      "\tspeed: 0.0356s/iter; left time: 555.2663s\n",
      "\titers: 200, epoch: 31 | loss: 0.0504319\n",
      "\tspeed: 0.0174s/iter; left time: 269.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0503712 Vali Loss: 0.0588283 Test Loss: 0.0617319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506263\n",
      "\tspeed: 0.0323s/iter; left time: 495.7047s\n",
      "\titers: 200, epoch: 32 | loss: 0.0477929\n",
      "\tspeed: 0.0162s/iter; left time: 246.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0502545 Vali Loss: 0.0583562 Test Loss: 0.0611734\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0504393\n",
      "\tspeed: 0.0329s/iter; left time: 497.5200s\n",
      "\titers: 200, epoch: 33 | loss: 0.0489511\n",
      "\tspeed: 0.0169s/iter; left time: 254.5390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0502463 Vali Loss: 0.0585476 Test Loss: 0.0613365\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0483616\n",
      "\tspeed: 0.0361s/iter; left time: 538.4718s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519027\n",
      "\tspeed: 0.0180s/iter; left time: 266.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0503158 Vali Loss: 0.0582609 Test Loss: 0.0612222\n",
      "Validation loss decreased (0.058319 --> 0.058261).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0488857\n",
      "\tspeed: 0.0323s/iter; left time: 474.2831s\n",
      "\titers: 200, epoch: 35 | loss: 0.0538403\n",
      "\tspeed: 0.0211s/iter; left time: 307.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0501319 Vali Loss: 0.0586195 Test Loss: 0.0615450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0495875\n",
      "\tspeed: 0.0349s/iter; left time: 504.9217s\n",
      "\titers: 200, epoch: 36 | loss: 0.0497248\n",
      "\tspeed: 0.0158s/iter; left time: 226.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0501083 Vali Loss: 0.0586764 Test Loss: 0.0616085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0526582\n",
      "\tspeed: 0.0313s/iter; left time: 446.2386s\n",
      "\titers: 200, epoch: 37 | loss: 0.0501021\n",
      "\tspeed: 0.0159s/iter; left time: 225.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0501694 Vali Loss: 0.0581614 Test Loss: 0.0610229\n",
      "Validation loss decreased (0.058261 --> 0.058161).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0500558\n",
      "\tspeed: 0.0338s/iter; left time: 473.3929s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513457\n",
      "\tspeed: 0.0170s/iter; left time: 236.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0500217 Vali Loss: 0.0582170 Test Loss: 0.0611187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503623\n",
      "\tspeed: 0.0300s/iter; left time: 413.4976s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528996\n",
      "\tspeed: 0.0173s/iter; left time: 236.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0501734 Vali Loss: 0.0582744 Test Loss: 0.0611718\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0508711\n",
      "\tspeed: 0.0350s/iter; left time: 474.9946s\n",
      "\titers: 200, epoch: 40 | loss: 0.0498356\n",
      "\tspeed: 0.0188s/iter; left time: 253.6247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0500942 Vali Loss: 0.0584468 Test Loss: 0.0614264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0534200\n",
      "\tspeed: 0.0330s/iter; left time: 439.9046s\n",
      "\titers: 200, epoch: 41 | loss: 0.0495634\n",
      "\tspeed: 0.0174s/iter; left time: 230.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0500160 Vali Loss: 0.0583306 Test Loss: 0.0612324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0527063\n",
      "\tspeed: 0.0370s/iter; left time: 485.3224s\n",
      "\titers: 200, epoch: 42 | loss: 0.0480693\n",
      "\tspeed: 0.0171s/iter; left time: 222.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0500439 Vali Loss: 0.0586539 Test Loss: 0.0615852\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0521657\n",
      "\tspeed: 0.0315s/iter; left time: 406.6204s\n",
      "\titers: 200, epoch: 43 | loss: 0.0497351\n",
      "\tspeed: 0.0155s/iter; left time: 198.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0501407 Vali Loss: 0.0582708 Test Loss: 0.0611153\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0491388\n",
      "\tspeed: 0.0355s/iter; left time: 450.2121s\n",
      "\titers: 200, epoch: 44 | loss: 0.0484253\n",
      "\tspeed: 0.0170s/iter; left time: 214.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0500195 Vali Loss: 0.0582583 Test Loss: 0.0611036\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0473987\n",
      "\tspeed: 0.0360s/iter; left time: 448.3633s\n",
      "\titers: 200, epoch: 45 | loss: 0.0518590\n",
      "\tspeed: 0.0191s/iter; left time: 235.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0499404 Vali Loss: 0.0584004 Test Loss: 0.0613419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0509252\n",
      "\tspeed: 0.0340s/iter; left time: 414.9321s\n",
      "\titers: 200, epoch: 46 | loss: 0.0509868\n",
      "\tspeed: 0.0176s/iter; left time: 213.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0500175 Vali Loss: 0.0583170 Test Loss: 0.0611765\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0507299\n",
      "\tspeed: 0.0339s/iter; left time: 406.6399s\n",
      "\titers: 200, epoch: 47 | loss: 0.0480615\n",
      "\tspeed: 0.0148s/iter; left time: 176.2715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0500566 Vali Loss: 0.0583913 Test Loss: 0.0613157\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011083848774433136, rmse:0.10527986288070679, mae:0.061022911220788956, rse:0.40616676211357117\n",
      "Intermediate time for FR and pred_len 24: 00h:10m:58.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0405s/iter; left time: 902.1581s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0179s/iter; left time: 396.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0411s/iter; left time: 906.5146s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0201s/iter; left time: 441.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0371s/iter; left time: 811.5590s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0198s/iter; left time: 429.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0375s/iter; left time: 810.8239s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0198s/iter; left time: 425.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0343s/iter; left time: 734.7665s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0210s/iter; left time: 446.8579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0393s/iter; left time: 832.2982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0208s/iter; left time: 439.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0346s/iter; left time: 724.6520s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0165s/iter; left time: 344.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0361s/iter; left time: 748.7273s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0216s/iter; left time: 444.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0415s/iter; left time: 851.0759s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0212s/iter; left time: 432.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0387s/iter; left time: 785.4695s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0202s/iter; left time: 408.3752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0401s/iter; left time: 804.5746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0231s/iter; left time: 460.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0361s/iter; left time: 716.4403s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0184s/iter; left time: 363.2633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0396s/iter; left time: 777.2856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0217s/iter; left time: 423.8979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0356s/iter; left time: 690.7282s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0188s/iter; left time: 362.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0361s/iter; left time: 692.4365s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0173s/iter; left time: 328.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0360s/iter; left time: 681.9205s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0228s/iter; left time: 430.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0374s/iter; left time: 699.3301s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0226s/iter; left time: 420.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0369s/iter; left time: 682.9423s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0194s/iter; left time: 356.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0376s/iter; left time: 686.1629s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0234s/iter; left time: 425.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0403s/iter; left time: 726.7620s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0211s/iter; left time: 378.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0612366\n",
      "\tspeed: 0.0403s/iter; left time: 717.8373s\n",
      "\titers: 200, epoch: 21 | loss: 0.0611458\n",
      "\tspeed: 0.0207s/iter; left time: 367.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0645373 Vali Loss: 0.0751285 Test Loss: 0.0847554\n",
      "Validation loss decreased (0.075269 --> 0.075128).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0651569\n",
      "\tspeed: 0.0385s/iter; left time: 677.3997s\n",
      "\titers: 200, epoch: 22 | loss: 0.0639169\n",
      "\tspeed: 0.0224s/iter; left time: 391.4280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0643803 Vali Loss: 0.0751306 Test Loss: 0.0848329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0624616\n",
      "\tspeed: 0.0364s/iter; left time: 633.0462s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664957\n",
      "\tspeed: 0.0172s/iter; left time: 296.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0642933 Vali Loss: 0.0750855 Test Loss: 0.0847189\n",
      "Validation loss decreased (0.075128 --> 0.075086).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0623684\n",
      "\tspeed: 0.0364s/iter; left time: 624.9435s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610922\n",
      "\tspeed: 0.0202s/iter; left time: 343.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0642667 Vali Loss: 0.0750529 Test Loss: 0.0847872\n",
      "Validation loss decreased (0.075086 --> 0.075053).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0652105\n",
      "\tspeed: 0.0408s/iter; left time: 690.5915s\n",
      "\titers: 200, epoch: 25 | loss: 0.0639769\n",
      "\tspeed: 0.0230s/iter; left time: 387.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0642460 Vali Loss: 0.0751374 Test Loss: 0.0846082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625939\n",
      "\tspeed: 0.0376s/iter; left time: 627.2202s\n",
      "\titers: 200, epoch: 26 | loss: 0.0640413\n",
      "\tspeed: 0.0206s/iter; left time: 342.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0640232 Vali Loss: 0.0749121 Test Loss: 0.0845331\n",
      "Validation loss decreased (0.075053 --> 0.074912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0642469\n",
      "\tspeed: 0.0369s/iter; left time: 608.3770s\n",
      "\titers: 200, epoch: 27 | loss: 0.0613592\n",
      "\tspeed: 0.0207s/iter; left time: 338.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0638458 Vali Loss: 0.0749898 Test Loss: 0.0846806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0614823\n",
      "\tspeed: 0.0361s/iter; left time: 587.0220s\n",
      "\titers: 200, epoch: 28 | loss: 0.0616128\n",
      "\tspeed: 0.0189s/iter; left time: 305.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0638617 Vali Loss: 0.0749273 Test Loss: 0.0846279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0627873\n",
      "\tspeed: 0.0369s/iter; left time: 591.1725s\n",
      "\titers: 200, epoch: 29 | loss: 0.0679921\n",
      "\tspeed: 0.0201s/iter; left time: 320.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0638065 Vali Loss: 0.0749684 Test Loss: 0.0847077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0666346\n",
      "\tspeed: 0.0356s/iter; left time: 562.2273s\n",
      "\titers: 200, epoch: 30 | loss: 0.0670567\n",
      "\tspeed: 0.0183s/iter; left time: 288.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0637055 Vali Loss: 0.0749422 Test Loss: 0.0846726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0660578\n",
      "\tspeed: 0.0337s/iter; left time: 525.2310s\n",
      "\titers: 200, epoch: 31 | loss: 0.0668724\n",
      "\tspeed: 0.0180s/iter; left time: 278.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0639426 Vali Loss: 0.0749136 Test Loss: 0.0845153\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0656317\n",
      "\tspeed: 0.0349s/iter; left time: 535.2449s\n",
      "\titers: 200, epoch: 32 | loss: 0.0668339\n",
      "\tspeed: 0.0178s/iter; left time: 271.3507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0636324 Vali Loss: 0.0750255 Test Loss: 0.0847232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671994\n",
      "\tspeed: 0.0338s/iter; left time: 511.7629s\n",
      "\titers: 200, epoch: 33 | loss: 0.0623513\n",
      "\tspeed: 0.0226s/iter; left time: 339.4387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0640435 Vali Loss: 0.0749408 Test Loss: 0.0844788\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0638304\n",
      "\tspeed: 0.0370s/iter; left time: 552.3163s\n",
      "\titers: 200, epoch: 34 | loss: 0.0659373\n",
      "\tspeed: 0.0181s/iter; left time: 267.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0636193 Vali Loss: 0.0749466 Test Loss: 0.0845033\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0619262\n",
      "\tspeed: 0.0344s/iter; left time: 504.7220s\n",
      "\titers: 200, epoch: 35 | loss: 0.0638632\n",
      "\tspeed: 0.0184s/iter; left time: 268.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0636754 Vali Loss: 0.0748628 Test Loss: 0.0844507\n",
      "Validation loss decreased (0.074912 --> 0.074863).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618416\n",
      "\tspeed: 0.0350s/iter; left time: 505.7053s\n",
      "\titers: 200, epoch: 36 | loss: 0.0602060\n",
      "\tspeed: 0.0189s/iter; left time: 271.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0635923 Vali Loss: 0.0748915 Test Loss: 0.0844548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0620921\n",
      "\tspeed: 0.0376s/iter; left time: 535.0799s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619549\n",
      "\tspeed: 0.0207s/iter; left time: 292.2365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0635743 Vali Loss: 0.0748421 Test Loss: 0.0845368\n",
      "Validation loss decreased (0.074863 --> 0.074842).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0627876\n",
      "\tspeed: 0.0398s/iter; left time: 558.1322s\n",
      "\titers: 200, epoch: 38 | loss: 0.0594055\n",
      "\tspeed: 0.0233s/iter; left time: 323.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0636778 Vali Loss: 0.0749182 Test Loss: 0.0845077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0634855\n",
      "\tspeed: 0.0352s/iter; left time: 485.6643s\n",
      "\titers: 200, epoch: 39 | loss: 0.0651536\n",
      "\tspeed: 0.0176s/iter; left time: 241.0320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0637075 Vali Loss: 0.0748838 Test Loss: 0.0845183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0661026\n",
      "\tspeed: 0.0391s/iter; left time: 530.2549s\n",
      "\titers: 200, epoch: 40 | loss: 0.0572510\n",
      "\tspeed: 0.0217s/iter; left time: 291.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0635356 Vali Loss: 0.0748458 Test Loss: 0.0844856\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0611172\n",
      "\tspeed: 0.0367s/iter; left time: 489.5553s\n",
      "\titers: 200, epoch: 41 | loss: 0.0627527\n",
      "\tspeed: 0.0165s/iter; left time: 218.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0637003 Vali Loss: 0.0748669 Test Loss: 0.0844824\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0648655\n",
      "\tspeed: 0.0343s/iter; left time: 449.4683s\n",
      "\titers: 200, epoch: 42 | loss: 0.0644647\n",
      "\tspeed: 0.0178s/iter; left time: 231.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0634609 Vali Loss: 0.0748767 Test Loss: 0.0845775\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0628619\n",
      "\tspeed: 0.0357s/iter; left time: 459.7856s\n",
      "\titers: 200, epoch: 43 | loss: 0.0639417\n",
      "\tspeed: 0.0166s/iter; left time: 212.3480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0636445 Vali Loss: 0.0749155 Test Loss: 0.0845783\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0661944\n",
      "\tspeed: 0.0337s/iter; left time: 427.4378s\n",
      "\titers: 200, epoch: 44 | loss: 0.0659364\n",
      "\tspeed: 0.0186s/iter; left time: 233.5504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0639953 Vali Loss: 0.0748791 Test Loss: 0.0844123\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636500\n",
      "\tspeed: 0.0298s/iter; left time: 370.6192s\n",
      "\titers: 200, epoch: 45 | loss: 0.0604052\n",
      "\tspeed: 0.0100s/iter; left time: 123.6892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0635161 Vali Loss: 0.0748828 Test Loss: 0.0845705\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0625768\n",
      "\tspeed: 0.0304s/iter; left time: 371.9596s\n",
      "\titers: 200, epoch: 46 | loss: 0.0619401\n",
      "\tspeed: 0.0176s/iter; left time: 213.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0635319 Vali Loss: 0.0748403 Test Loss: 0.0844395\n",
      "Validation loss decreased (0.074842 --> 0.074840).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0650877\n",
      "\tspeed: 0.0345s/iter; left time: 414.0067s\n",
      "\titers: 200, epoch: 47 | loss: 0.0635316\n",
      "\tspeed: 0.0205s/iter; left time: 243.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0635355 Vali Loss: 0.0748786 Test Loss: 0.0844128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0650298\n",
      "\tspeed: 0.0390s/iter; left time: 459.5415s\n",
      "\titers: 200, epoch: 48 | loss: 0.0657075\n",
      "\tspeed: 0.0209s/iter; left time: 244.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0635475 Vali Loss: 0.0748775 Test Loss: 0.0844445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0649474\n",
      "\tspeed: 0.0350s/iter; left time: 404.0443s\n",
      "\titers: 200, epoch: 49 | loss: 0.0600979\n",
      "\tspeed: 0.0197s/iter; left time: 225.9999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0635202 Vali Loss: 0.0748605 Test Loss: 0.0845111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0639095\n",
      "\tspeed: 0.0348s/iter; left time: 394.0680s\n",
      "\titers: 200, epoch: 50 | loss: 0.0624497\n",
      "\tspeed: 0.0101s/iter; left time: 113.8581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0636276 Vali Loss: 0.0748693 Test Loss: 0.0844540\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0624300\n",
      "\tspeed: 0.0339s/iter; left time: 376.2764s\n",
      "\titers: 200, epoch: 51 | loss: 0.0634616\n",
      "\tspeed: 0.0229s/iter; left time: 252.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0635002 Vali Loss: 0.0748973 Test Loss: 0.0845749\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0620393\n",
      "\tspeed: 0.0411s/iter; left time: 446.9334s\n",
      "\titers: 200, epoch: 52 | loss: 0.0645444\n",
      "\tspeed: 0.0226s/iter; left time: 243.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0633845 Vali Loss: 0.0748605 Test Loss: 0.0845031\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0619776\n",
      "\tspeed: 0.0351s/iter; left time: 374.0600s\n",
      "\titers: 200, epoch: 53 | loss: 0.0661225\n",
      "\tspeed: 0.0173s/iter; left time: 183.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0634164 Vali Loss: 0.0748804 Test Loss: 0.0845459\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0633279\n",
      "\tspeed: 0.0361s/iter; left time: 376.3147s\n",
      "\titers: 200, epoch: 54 | loss: 0.0645414\n",
      "\tspeed: 0.0180s/iter; left time: 185.9286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0634517 Vali Loss: 0.0748712 Test Loss: 0.0845036\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0650333\n",
      "\tspeed: 0.0362s/iter; left time: 369.4977s\n",
      "\titers: 200, epoch: 55 | loss: 0.0611133\n",
      "\tspeed: 0.0171s/iter; left time: 173.2368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0634390 Vali Loss: 0.0748915 Test Loss: 0.0845454\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0641902\n",
      "\tspeed: 0.0347s/iter; left time: 346.4271s\n",
      "\titers: 200, epoch: 56 | loss: 0.0604664\n",
      "\tspeed: 0.0167s/iter; left time: 165.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0635355 Vali Loss: 0.0748537 Test Loss: 0.0843582\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02091984450817108, rmse:0.14463694393634796, mae:0.0844394713640213, rse:0.559494137763977\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2446093\n",
      "\tspeed: 0.0225s/iter; left time: 501.5815s\n",
      "\titers: 200, epoch: 1 | loss: 0.2217702\n",
      "\tspeed: 0.0206s/iter; left time: 457.9923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.2449674 Vali Loss: 0.1815714 Test Loss: 0.1897557\n",
      "Validation loss decreased (inf --> 0.181571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1313936\n",
      "\tspeed: 0.0377s/iter; left time: 832.4490s\n",
      "\titers: 200, epoch: 2 | loss: 0.1012539\n",
      "\tspeed: 0.0200s/iter; left time: 440.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1350062 Vali Loss: 0.0968014 Test Loss: 0.1073580\n",
      "Validation loss decreased (0.181571 --> 0.096801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0867328\n",
      "\tspeed: 0.0386s/iter; left time: 843.5518s\n",
      "\titers: 200, epoch: 3 | loss: 0.0862665\n",
      "\tspeed: 0.0213s/iter; left time: 464.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0897080 Vali Loss: 0.0874246 Test Loss: 0.0945556\n",
      "Validation loss decreased (0.096801 --> 0.087425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0819778\n",
      "\tspeed: 0.0359s/iter; left time: 776.0313s\n",
      "\titers: 200, epoch: 4 | loss: 0.0843108\n",
      "\tspeed: 0.0176s/iter; left time: 378.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0816666 Vali Loss: 0.0834707 Test Loss: 0.0928928\n",
      "Validation loss decreased (0.087425 --> 0.083471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759629\n",
      "\tspeed: 0.0394s/iter; left time: 843.3258s\n",
      "\titers: 200, epoch: 5 | loss: 0.0718963\n",
      "\tspeed: 0.0177s/iter; left time: 376.7163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0767960 Vali Loss: 0.0799672 Test Loss: 0.0924122\n",
      "Validation loss decreased (0.083471 --> 0.079967).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0746661\n",
      "\tspeed: 0.0363s/iter; left time: 769.2078s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739022\n",
      "\tspeed: 0.0177s/iter; left time: 373.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0734231 Vali Loss: 0.0790923 Test Loss: 0.0913114\n",
      "Validation loss decreased (0.079967 --> 0.079092).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694684\n",
      "\tspeed: 0.0401s/iter; left time: 840.5853s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759875\n",
      "\tspeed: 0.0238s/iter; left time: 496.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0712908 Vali Loss: 0.0781400 Test Loss: 0.0877073\n",
      "Validation loss decreased (0.079092 --> 0.078140).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0733793\n",
      "\tspeed: 0.0380s/iter; left time: 788.4739s\n",
      "\titers: 200, epoch: 8 | loss: 0.0696252\n",
      "\tspeed: 0.0211s/iter; left time: 436.1824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0696699 Vali Loss: 0.0776174 Test Loss: 0.0866298\n",
      "Validation loss decreased (0.078140 --> 0.077617).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690542\n",
      "\tspeed: 0.0387s/iter; left time: 793.1242s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675303\n",
      "\tspeed: 0.0208s/iter; left time: 423.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0685719 Vali Loss: 0.0774060 Test Loss: 0.0864485\n",
      "Validation loss decreased (0.077617 --> 0.077406).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0678312\n",
      "\tspeed: 0.0347s/iter; left time: 703.9250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0711859\n",
      "\tspeed: 0.0181s/iter; left time: 366.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0677425 Vali Loss: 0.0771071 Test Loss: 0.0855391\n",
      "Validation loss decreased (0.077406 --> 0.077107).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0650157\n",
      "\tspeed: 0.0352s/iter; left time: 705.5103s\n",
      "\titers: 200, epoch: 11 | loss: 0.0657995\n",
      "\tspeed: 0.0167s/iter; left time: 333.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0673803 Vali Loss: 0.0770425 Test Loss: 0.0861407\n",
      "Validation loss decreased (0.077107 --> 0.077042).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0680712\n",
      "\tspeed: 0.0415s/iter; left time: 823.7965s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690869\n",
      "\tspeed: 0.0246s/iter; left time: 485.5542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0667022 Vali Loss: 0.0766534 Test Loss: 0.0858711\n",
      "Validation loss decreased (0.077042 --> 0.076653).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0706065\n",
      "\tspeed: 0.0476s/iter; left time: 933.9483s\n",
      "\titers: 200, epoch: 13 | loss: 0.0691158\n",
      "\tspeed: 0.0224s/iter; left time: 436.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0662631 Vali Loss: 0.0766493 Test Loss: 0.0857974\n",
      "Validation loss decreased (0.076653 --> 0.076649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650391\n",
      "\tspeed: 0.0419s/iter; left time: 813.3607s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663259\n",
      "\tspeed: 0.0204s/iter; left time: 393.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0657481 Vali Loss: 0.0766774 Test Loss: 0.0856799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0691288\n",
      "\tspeed: 0.0384s/iter; left time: 736.4671s\n",
      "\titers: 200, epoch: 15 | loss: 0.0636347\n",
      "\tspeed: 0.0200s/iter; left time: 380.7682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0657803 Vali Loss: 0.0765203 Test Loss: 0.0855134\n",
      "Validation loss decreased (0.076649 --> 0.076520).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0623043\n",
      "\tspeed: 0.0383s/iter; left time: 725.8905s\n",
      "\titers: 200, epoch: 16 | loss: 0.0647576\n",
      "\tspeed: 0.0177s/iter; left time: 333.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0654336 Vali Loss: 0.0769812 Test Loss: 0.0863409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0640645\n",
      "\tspeed: 0.0374s/iter; left time: 699.8543s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624860\n",
      "\tspeed: 0.0191s/iter; left time: 356.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0653116 Vali Loss: 0.0767633 Test Loss: 0.0858200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0630177\n",
      "\tspeed: 0.0362s/iter; left time: 668.9163s\n",
      "\titers: 200, epoch: 18 | loss: 0.0639060\n",
      "\tspeed: 0.0233s/iter; left time: 427.8576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0648783 Vali Loss: 0.0761723 Test Loss: 0.0851316\n",
      "Validation loss decreased (0.076520 --> 0.076172).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0627690\n",
      "\tspeed: 0.0351s/iter; left time: 640.5944s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683923\n",
      "\tspeed: 0.0174s/iter; left time: 316.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0648472 Vali Loss: 0.0760337 Test Loss: 0.0852844\n",
      "Validation loss decreased (0.076172 --> 0.076034).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0623018\n",
      "\tspeed: 0.0403s/iter; left time: 727.4341s\n",
      "\titers: 200, epoch: 20 | loss: 0.0657438\n",
      "\tspeed: 0.0214s/iter; left time: 383.6726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0646764 Vali Loss: 0.0762291 Test Loss: 0.0855199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0665043\n",
      "\tspeed: 0.0343s/iter; left time: 611.0962s\n",
      "\titers: 200, epoch: 21 | loss: 0.0653400\n",
      "\tspeed: 0.0182s/iter; left time: 323.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0646404 Vali Loss: 0.0759536 Test Loss: 0.0852054\n",
      "Validation loss decreased (0.076034 --> 0.075954).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0636809\n",
      "\tspeed: 0.0346s/iter; left time: 608.6513s\n",
      "\titers: 200, epoch: 22 | loss: 0.0667308\n",
      "\tspeed: 0.0173s/iter; left time: 303.5122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0643446 Vali Loss: 0.0760542 Test Loss: 0.0853412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0678711\n",
      "\tspeed: 0.0354s/iter; left time: 615.5215s\n",
      "\titers: 200, epoch: 23 | loss: 0.0616475\n",
      "\tspeed: 0.0165s/iter; left time: 284.7988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0642238 Vali Loss: 0.0761785 Test Loss: 0.0853315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0623842\n",
      "\tspeed: 0.0297s/iter; left time: 509.3224s\n",
      "\titers: 200, epoch: 24 | loss: 0.0603101\n",
      "\tspeed: 0.0135s/iter; left time: 230.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0641477 Vali Loss: 0.0759779 Test Loss: 0.0853329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0616180\n",
      "\tspeed: 0.0348s/iter; left time: 588.2522s\n",
      "\titers: 200, epoch: 25 | loss: 0.0644377\n",
      "\tspeed: 0.0208s/iter; left time: 349.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0638871 Vali Loss: 0.0760421 Test Loss: 0.0853012\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0667616\n",
      "\tspeed: 0.0343s/iter; left time: 572.5160s\n",
      "\titers: 200, epoch: 26 | loss: 0.0601611\n",
      "\tspeed: 0.0186s/iter; left time: 308.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0642054 Vali Loss: 0.0758871 Test Loss: 0.0851538\n",
      "Validation loss decreased (0.075954 --> 0.075887).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0618366\n",
      "\tspeed: 0.0344s/iter; left time: 567.2174s\n",
      "\titers: 200, epoch: 27 | loss: 0.0629379\n",
      "\tspeed: 0.0199s/iter; left time: 325.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0639449 Vali Loss: 0.0758402 Test Loss: 0.0850552\n",
      "Validation loss decreased (0.075887 --> 0.075840).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0643823\n",
      "\tspeed: 0.0326s/iter; left time: 529.3053s\n",
      "\titers: 200, epoch: 28 | loss: 0.0676356\n",
      "\tspeed: 0.0138s/iter; left time: 222.8959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0639708 Vali Loss: 0.0758775 Test Loss: 0.0851740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0639481\n",
      "\tspeed: 0.0329s/iter; left time: 527.1563s\n",
      "\titers: 200, epoch: 29 | loss: 0.0630168\n",
      "\tspeed: 0.0174s/iter; left time: 277.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0637855 Vali Loss: 0.0758397 Test Loss: 0.0850368\n",
      "Validation loss decreased (0.075840 --> 0.075840).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0698281\n",
      "\tspeed: 0.0344s/iter; left time: 542.9369s\n",
      "\titers: 200, epoch: 30 | loss: 0.0636687\n",
      "\tspeed: 0.0171s/iter; left time: 268.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0637639 Vali Loss: 0.0759107 Test Loss: 0.0851402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0621104\n",
      "\tspeed: 0.0336s/iter; left time: 522.9302s\n",
      "\titers: 200, epoch: 31 | loss: 0.0663121\n",
      "\tspeed: 0.0171s/iter; left time: 265.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0636354 Vali Loss: 0.0759704 Test Loss: 0.0852528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0638244\n",
      "\tspeed: 0.0363s/iter; left time: 558.1685s\n",
      "\titers: 200, epoch: 32 | loss: 0.0607384\n",
      "\tspeed: 0.0188s/iter; left time: 286.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0636515 Vali Loss: 0.0758884 Test Loss: 0.0852065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630194\n",
      "\tspeed: 0.0400s/iter; left time: 606.0612s\n",
      "\titers: 200, epoch: 33 | loss: 0.0616903\n",
      "\tspeed: 0.0200s/iter; left time: 300.0724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0636816 Vali Loss: 0.0758252 Test Loss: 0.0850444\n",
      "Validation loss decreased (0.075840 --> 0.075825).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0629164\n",
      "\tspeed: 0.0369s/iter; left time: 550.8492s\n",
      "\titers: 200, epoch: 34 | loss: 0.0672251\n",
      "\tspeed: 0.0154s/iter; left time: 228.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0636950 Vali Loss: 0.0758219 Test Loss: 0.0850294\n",
      "Validation loss decreased (0.075825 --> 0.075822).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0605771\n",
      "\tspeed: 0.0383s/iter; left time: 562.9092s\n",
      "\titers: 200, epoch: 35 | loss: 0.0618750\n",
      "\tspeed: 0.0171s/iter; left time: 248.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0635444 Vali Loss: 0.0757740 Test Loss: 0.0849731\n",
      "Validation loss decreased (0.075822 --> 0.075774).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0659335\n",
      "\tspeed: 0.0375s/iter; left time: 542.3134s\n",
      "\titers: 200, epoch: 36 | loss: 0.0606605\n",
      "\tspeed: 0.0174s/iter; left time: 249.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0634962 Vali Loss: 0.0757112 Test Loss: 0.0848368\n",
      "Validation loss decreased (0.075774 --> 0.075711).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0652772\n",
      "\tspeed: 0.0415s/iter; left time: 590.4813s\n",
      "\titers: 200, epoch: 37 | loss: 0.0653140\n",
      "\tspeed: 0.0159s/iter; left time: 224.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0634813 Vali Loss: 0.0757189 Test Loss: 0.0849072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0617919\n",
      "\tspeed: 0.0350s/iter; left time: 490.5246s\n",
      "\titers: 200, epoch: 38 | loss: 0.0637520\n",
      "\tspeed: 0.0159s/iter; left time: 221.2071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0637473 Vali Loss: 0.0756917 Test Loss: 0.0848916\n",
      "Validation loss decreased (0.075711 --> 0.075692).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0670029\n",
      "\tspeed: 0.0347s/iter; left time: 478.8564s\n",
      "\titers: 200, epoch: 39 | loss: 0.0629004\n",
      "\tspeed: 0.0173s/iter; left time: 236.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0635198 Vali Loss: 0.0758105 Test Loss: 0.0851737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0631152\n",
      "\tspeed: 0.0381s/iter; left time: 516.9635s\n",
      "\titers: 200, epoch: 40 | loss: 0.0627993\n",
      "\tspeed: 0.0181s/iter; left time: 243.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0635541 Vali Loss: 0.0757038 Test Loss: 0.0848737\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0634758\n",
      "\tspeed: 0.0415s/iter; left time: 554.1873s\n",
      "\titers: 200, epoch: 41 | loss: 0.0632113\n",
      "\tspeed: 0.0193s/iter; left time: 256.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0634345 Vali Loss: 0.0757468 Test Loss: 0.0849318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0663945\n",
      "\tspeed: 0.0398s/iter; left time: 521.5022s\n",
      "\titers: 200, epoch: 42 | loss: 0.0643766\n",
      "\tspeed: 0.0198s/iter; left time: 257.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0635677 Vali Loss: 0.0757172 Test Loss: 0.0849929\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0620287\n",
      "\tspeed: 0.0367s/iter; left time: 473.3203s\n",
      "\titers: 200, epoch: 43 | loss: 0.0614852\n",
      "\tspeed: 0.0180s/iter; left time: 230.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0634826 Vali Loss: 0.0756523 Test Loss: 0.0847933\n",
      "Validation loss decreased (0.075692 --> 0.075652).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0605435\n",
      "\tspeed: 0.0374s/iter; left time: 473.7204s\n",
      "\titers: 200, epoch: 44 | loss: 0.0622243\n",
      "\tspeed: 0.0199s/iter; left time: 249.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0634996 Vali Loss: 0.0758664 Test Loss: 0.0852352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0618589\n",
      "\tspeed: 0.0361s/iter; left time: 448.9811s\n",
      "\titers: 200, epoch: 45 | loss: 0.0589205\n",
      "\tspeed: 0.0172s/iter; left time: 212.1224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0634105 Vali Loss: 0.0756402 Test Loss: 0.0847735\n",
      "Validation loss decreased (0.075652 --> 0.075640).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0646047\n",
      "\tspeed: 0.0377s/iter; left time: 460.9990s\n",
      "\titers: 200, epoch: 46 | loss: 0.0651090\n",
      "\tspeed: 0.0184s/iter; left time: 223.4386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0633994 Vali Loss: 0.0756826 Test Loss: 0.0849173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0663008\n",
      "\tspeed: 0.0344s/iter; left time: 413.0295s\n",
      "\titers: 200, epoch: 47 | loss: 0.0584326\n",
      "\tspeed: 0.0179s/iter; left time: 213.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0634844 Vali Loss: 0.0757100 Test Loss: 0.0849540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0621919\n",
      "\tspeed: 0.0339s/iter; left time: 398.9395s\n",
      "\titers: 200, epoch: 48 | loss: 0.0654387\n",
      "\tspeed: 0.0188s/iter; left time: 219.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0634977 Vali Loss: 0.0757150 Test Loss: 0.0849744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0600066\n",
      "\tspeed: 0.0373s/iter; left time: 431.2149s\n",
      "\titers: 200, epoch: 49 | loss: 0.0632528\n",
      "\tspeed: 0.0213s/iter; left time: 244.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0634089 Vali Loss: 0.0756841 Test Loss: 0.0849358\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0641938\n",
      "\tspeed: 0.0349s/iter; left time: 395.4170s\n",
      "\titers: 200, epoch: 50 | loss: 0.0615548\n",
      "\tspeed: 0.0181s/iter; left time: 202.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0634583 Vali Loss: 0.0758243 Test Loss: 0.0851934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0612334\n",
      "\tspeed: 0.0348s/iter; left time: 386.1724s\n",
      "\titers: 200, epoch: 51 | loss: 0.0604240\n",
      "\tspeed: 0.0177s/iter; left time: 194.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0634429 Vali Loss: 0.0756985 Test Loss: 0.0849937\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0625399\n",
      "\tspeed: 0.0384s/iter; left time: 417.1622s\n",
      "\titers: 200, epoch: 52 | loss: 0.0663606\n",
      "\tspeed: 0.0179s/iter; left time: 193.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0633854 Vali Loss: 0.0756513 Test Loss: 0.0848157\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0633682\n",
      "\tspeed: 0.0341s/iter; left time: 363.6492s\n",
      "\titers: 200, epoch: 53 | loss: 0.0631271\n",
      "\tspeed: 0.0193s/iter; left time: 204.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0634585 Vali Loss: 0.0759790 Test Loss: 0.0852910\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0662492\n",
      "\tspeed: 0.0363s/iter; left time: 378.2142s\n",
      "\titers: 200, epoch: 54 | loss: 0.0609465\n",
      "\tspeed: 0.0192s/iter; left time: 197.8735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0633902 Vali Loss: 0.0756668 Test Loss: 0.0847899\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0648204\n",
      "\tspeed: 0.0356s/iter; left time: 363.2358s\n",
      "\titers: 200, epoch: 55 | loss: 0.0598931\n",
      "\tspeed: 0.0174s/iter; left time: 175.4048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0633780 Vali Loss: 0.0757443 Test Loss: 0.0848874\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02117375284433365, rmse:0.14551202952861786, mae:0.084773488342762, rse:0.5628792643547058\n",
      "Intermediate time for FR and pred_len 96: 00h:10m:29.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0384s/iter; left time: 852.2598s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0157s/iter; left time: 346.7744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0348s/iter; left time: 765.6929s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0163s/iter; left time: 356.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0369s/iter; left time: 802.0211s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0188s/iter; left time: 407.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0381s/iter; left time: 820.5190s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0176s/iter; left time: 378.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0378s/iter; left time: 805.0726s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0160s/iter; left time: 339.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0337s/iter; left time: 711.0989s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0156s/iter; left time: 327.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0425s/iter; left time: 885.9508s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0180s/iter; left time: 374.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0382s/iter; left time: 788.7540s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0189s/iter; left time: 388.7627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0339s/iter; left time: 692.5736s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0168s/iter; left time: 341.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0337s/iter; left time: 679.7854s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0172s/iter; left time: 345.4883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0368s/iter; left time: 734.4454s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0175s/iter; left time: 348.3361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0346s/iter; left time: 683.5050s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0152s/iter; left time: 299.4939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0368s/iter; left time: 718.5987s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0168s/iter; left time: 326.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0382s/iter; left time: 738.0345s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0174s/iter; left time: 334.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0364s/iter; left time: 695.2408s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0195s/iter; left time: 369.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0390s/iter; left time: 735.8924s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0215s/iter; left time: 402.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0421s/iter; left time: 784.7542s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0223s/iter; left time: 413.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0380s/iter; left time: 699.6809s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0177s/iter; left time: 324.1787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0388s/iter; left time: 705.4963s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0156s/iter; left time: 281.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0362s/iter; left time: 649.8497s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0203s/iter; left time: 362.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0663677\n",
      "\tspeed: 0.0355s/iter; left time: 630.3747s\n",
      "\titers: 200, epoch: 21 | loss: 0.0669994\n",
      "\tspeed: 0.0162s/iter; left time: 285.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0678149 Vali Loss: 0.0784798 Test Loss: 0.0897868\n",
      "Validation loss decreased (0.078623 --> 0.078480).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0672283\n",
      "\tspeed: 0.0335s/iter; left time: 587.5905s\n",
      "\titers: 200, epoch: 22 | loss: 0.0673161\n",
      "\tspeed: 0.0171s/iter; left time: 298.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0678036 Vali Loss: 0.0785779 Test Loss: 0.0904526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0700305\n",
      "\tspeed: 0.0337s/iter; left time: 583.3408s\n",
      "\titers: 200, epoch: 23 | loss: 0.0637901\n",
      "\tspeed: 0.0193s/iter; left time: 331.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0676334 Vali Loss: 0.0785729 Test Loss: 0.0898357\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0653326\n",
      "\tspeed: 0.0332s/iter; left time: 567.1248s\n",
      "\titers: 200, epoch: 24 | loss: 0.0694274\n",
      "\tspeed: 0.0166s/iter; left time: 282.0106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0675952 Vali Loss: 0.0787265 Test Loss: 0.0903373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0644151\n",
      "\tspeed: 0.0369s/iter; left time: 621.5892s\n",
      "\titers: 200, epoch: 25 | loss: 0.0662949\n",
      "\tspeed: 0.0203s/iter; left time: 340.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0675093 Vali Loss: 0.0784429 Test Loss: 0.0896569\n",
      "Validation loss decreased (0.078480 --> 0.078443).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0658729\n",
      "\tspeed: 0.0386s/iter; left time: 641.9079s\n",
      "\titers: 200, epoch: 26 | loss: 0.0694567\n",
      "\tspeed: 0.0173s/iter; left time: 285.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0674292 Vali Loss: 0.0784964 Test Loss: 0.0899409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0686192\n",
      "\tspeed: 0.0315s/iter; left time: 517.3697s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672854\n",
      "\tspeed: 0.0155s/iter; left time: 252.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0673598 Vali Loss: 0.0786052 Test Loss: 0.0905234\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0641365\n",
      "\tspeed: 0.0350s/iter; left time: 565.4946s\n",
      "\titers: 200, epoch: 28 | loss: 0.0674382\n",
      "\tspeed: 0.0186s/iter; left time: 298.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0673135 Vali Loss: 0.0783556 Test Loss: 0.0900815\n",
      "Validation loss decreased (0.078443 --> 0.078356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0679455\n",
      "\tspeed: 0.0325s/iter; left time: 519.2198s\n",
      "\titers: 200, epoch: 29 | loss: 0.0644956\n",
      "\tspeed: 0.0154s/iter; left time: 244.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0672827 Vali Loss: 0.0783653 Test Loss: 0.0900080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0676180\n",
      "\tspeed: 0.0345s/iter; left time: 542.3417s\n",
      "\titers: 200, epoch: 30 | loss: 0.0679972\n",
      "\tspeed: 0.0169s/iter; left time: 264.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0672445 Vali Loss: 0.0784439 Test Loss: 0.0901915\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0669693\n",
      "\tspeed: 0.0335s/iter; left time: 519.2283s\n",
      "\titers: 200, epoch: 31 | loss: 0.0719308\n",
      "\tspeed: 0.0166s/iter; left time: 256.2536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0671927 Vali Loss: 0.0783952 Test Loss: 0.0902039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0655053\n",
      "\tspeed: 0.0347s/iter; left time: 530.9169s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652533\n",
      "\tspeed: 0.0169s/iter; left time: 257.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0670878 Vali Loss: 0.0784049 Test Loss: 0.0900689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0668145\n",
      "\tspeed: 0.0359s/iter; left time: 540.6545s\n",
      "\titers: 200, epoch: 33 | loss: 0.0658785\n",
      "\tspeed: 0.0178s/iter; left time: 266.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0673694 Vali Loss: 0.0783459 Test Loss: 0.0896429\n",
      "Validation loss decreased (0.078356 --> 0.078346).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0639815\n",
      "\tspeed: 0.0334s/iter; left time: 495.3880s\n",
      "\titers: 200, epoch: 34 | loss: 0.0678246\n",
      "\tspeed: 0.0202s/iter; left time: 298.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0671238 Vali Loss: 0.0783610 Test Loss: 0.0902388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0683998\n",
      "\tspeed: 0.0340s/iter; left time: 497.0957s\n",
      "\titers: 200, epoch: 35 | loss: 0.0657174\n",
      "\tspeed: 0.0170s/iter; left time: 246.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0670835 Vali Loss: 0.0783434 Test Loss: 0.0900946\n",
      "Validation loss decreased (0.078346 --> 0.078343).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697847\n",
      "\tspeed: 0.0341s/iter; left time: 490.6668s\n",
      "\titers: 200, epoch: 36 | loss: 0.0661649\n",
      "\tspeed: 0.0163s/iter; left time: 233.7374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0669770 Vali Loss: 0.0783992 Test Loss: 0.0897999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0981122\n",
      "\tspeed: 0.0338s/iter; left time: 479.6582s\n",
      "\titers: 200, epoch: 37 | loss: 0.0664383\n",
      "\tspeed: 0.0166s/iter; left time: 233.8709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0671933 Vali Loss: 0.0784283 Test Loss: 0.0900075\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677373\n",
      "\tspeed: 0.0363s/iter; left time: 506.8683s\n",
      "\titers: 200, epoch: 38 | loss: 0.0638908\n",
      "\tspeed: 0.0177s/iter; left time: 244.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0670454 Vali Loss: 0.0784088 Test Loss: 0.0903903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0651423\n",
      "\tspeed: 0.0379s/iter; left time: 519.6209s\n",
      "\titers: 200, epoch: 39 | loss: 0.0655890\n",
      "\tspeed: 0.0199s/iter; left time: 270.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0669028 Vali Loss: 0.0783724 Test Loss: 0.0902622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0717114\n",
      "\tspeed: 0.0360s/iter; left time: 485.7632s\n",
      "\titers: 200, epoch: 40 | loss: 0.0640477\n",
      "\tspeed: 0.0171s/iter; left time: 229.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0670078 Vali Loss: 0.0785387 Test Loss: 0.0906313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0667479\n",
      "\tspeed: 0.0366s/iter; left time: 485.4321s\n",
      "\titers: 200, epoch: 41 | loss: 0.0649812\n",
      "\tspeed: 0.0181s/iter; left time: 238.5125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0669177 Vali Loss: 0.0783095 Test Loss: 0.0899186\n",
      "Validation loss decreased (0.078343 --> 0.078309).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0654942\n",
      "\tspeed: 0.0377s/iter; left time: 492.3692s\n",
      "\titers: 200, epoch: 42 | loss: 0.0644555\n",
      "\tspeed: 0.0179s/iter; left time: 231.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0669488 Vali Loss: 0.0783080 Test Loss: 0.0899542\n",
      "Validation loss decreased (0.078309 --> 0.078308).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0666401\n",
      "\tspeed: 0.0350s/iter; left time: 448.9668s\n",
      "\titers: 200, epoch: 43 | loss: 0.0648314\n",
      "\tspeed: 0.0165s/iter; left time: 209.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0669090 Vali Loss: 0.0783652 Test Loss: 0.0899487\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682370\n",
      "\tspeed: 0.0326s/iter; left time: 411.3019s\n",
      "\titers: 200, epoch: 44 | loss: 0.0707746\n",
      "\tspeed: 0.0101s/iter; left time: 125.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 223 | Train Loss: 0.0669577 Vali Loss: 0.0783356 Test Loss: 0.0898627\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0680339\n",
      "\tspeed: 0.0320s/iter; left time: 396.9902s\n",
      "\titers: 200, epoch: 45 | loss: 0.0697346\n",
      "\tspeed: 0.0156s/iter; left time: 191.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0668898 Vali Loss: 0.0784230 Test Loss: 0.0903625\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0658358\n",
      "\tspeed: 0.0396s/iter; left time: 481.8089s\n",
      "\titers: 200, epoch: 46 | loss: 0.0662285\n",
      "\tspeed: 0.0168s/iter; left time: 203.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0670128 Vali Loss: 0.0783513 Test Loss: 0.0899156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0658982\n",
      "\tspeed: 0.0347s/iter; left time: 414.1147s\n",
      "\titers: 200, epoch: 47 | loss: 0.0626831\n",
      "\tspeed: 0.0191s/iter; left time: 226.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0669430 Vali Loss: 0.0782698 Test Loss: 0.0896646\n",
      "Validation loss decreased (0.078308 --> 0.078270).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642926\n",
      "\tspeed: 0.0369s/iter; left time: 432.0202s\n",
      "\titers: 200, epoch: 48 | loss: 0.0680426\n",
      "\tspeed: 0.0197s/iter; left time: 229.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0669282 Vali Loss: 0.0782521 Test Loss: 0.0898390\n",
      "Validation loss decreased (0.078270 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0623542\n",
      "\tspeed: 0.0353s/iter; left time: 405.8623s\n",
      "\titers: 200, epoch: 49 | loss: 0.0640966\n",
      "\tspeed: 0.0155s/iter; left time: 176.5293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0668709 Vali Loss: 0.0783011 Test Loss: 0.0900403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0661973\n",
      "\tspeed: 0.0350s/iter; left time: 394.7085s\n",
      "\titers: 200, epoch: 50 | loss: 0.0680641\n",
      "\tspeed: 0.0191s/iter; left time: 212.9691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0668440 Vali Loss: 0.0785972 Test Loss: 0.0904424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0662638\n",
      "\tspeed: 0.0353s/iter; left time: 389.6729s\n",
      "\titers: 200, epoch: 51 | loss: 0.0670776\n",
      "\tspeed: 0.0156s/iter; left time: 171.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0669221 Vali Loss: 0.0783211 Test Loss: 0.0898956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0667211\n",
      "\tspeed: 0.0366s/iter; left time: 395.9962s\n",
      "\titers: 200, epoch: 52 | loss: 0.0690121\n",
      "\tspeed: 0.0158s/iter; left time: 169.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0668981 Vali Loss: 0.0783196 Test Loss: 0.0901165\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0746985\n",
      "\tspeed: 0.0344s/iter; left time: 365.2806s\n",
      "\titers: 200, epoch: 53 | loss: 0.0683838\n",
      "\tspeed: 0.0160s/iter; left time: 167.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0668889 Vali Loss: 0.0783335 Test Loss: 0.0899625\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0674382\n",
      "\tspeed: 0.0350s/iter; left time: 363.1277s\n",
      "\titers: 200, epoch: 54 | loss: 0.0625900\n",
      "\tspeed: 0.0178s/iter; left time: 183.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0668223 Vali Loss: 0.0783967 Test Loss: 0.0901315\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0636814\n",
      "\tspeed: 0.0364s/iter; left time: 369.9951s\n",
      "\titers: 200, epoch: 55 | loss: 0.0693940\n",
      "\tspeed: 0.0168s/iter; left time: 169.4214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0668968 Vali Loss: 0.0782941 Test Loss: 0.0899220\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0679491\n",
      "\tspeed: 0.0354s/iter; left time: 351.4033s\n",
      "\titers: 200, epoch: 56 | loss: 0.0683673\n",
      "\tspeed: 0.0171s/iter; left time: 167.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0669053 Vali Loss: 0.0783098 Test Loss: 0.0900202\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0712342\n",
      "\tspeed: 0.0339s/iter; left time: 328.9676s\n",
      "\titers: 200, epoch: 57 | loss: 0.0715479\n",
      "\tspeed: 0.0164s/iter; left time: 157.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0668513 Vali Loss: 0.0783565 Test Loss: 0.0901037\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0657454\n",
      "\tspeed: 0.0276s/iter; left time: 261.8399s\n",
      "\titers: 200, epoch: 58 | loss: 0.0662007\n",
      "\tspeed: 0.0131s/iter; left time: 122.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0669398 Vali Loss: 0.0783188 Test Loss: 0.0900327\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022931568324565887, rmse:0.15143172442913055, mae:0.08983904868364334, rse:0.5865094661712646\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2406601\n",
      "\tspeed: 0.0196s/iter; left time: 434.4787s\n",
      "\titers: 200, epoch: 1 | loss: 0.2214315\n",
      "\tspeed: 0.0178s/iter; left time: 394.4337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.2439416 Vali Loss: 0.1837158 Test Loss: 0.1905165\n",
      "Validation loss decreased (inf --> 0.183716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1252717\n",
      "\tspeed: 0.0353s/iter; left time: 776.6274s\n",
      "\titers: 200, epoch: 2 | loss: 0.0997196\n",
      "\tspeed: 0.0163s/iter; left time: 356.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1329702 Vali Loss: 0.1005373 Test Loss: 0.1107586\n",
      "Validation loss decreased (0.183716 --> 0.100537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0938255\n",
      "\tspeed: 0.0388s/iter; left time: 844.7078s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915489\n",
      "\tspeed: 0.0196s/iter; left time: 424.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0920519 Vali Loss: 0.0898683 Test Loss: 0.0971306\n",
      "Validation loss decreased (0.100537 --> 0.089868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0844332\n",
      "\tspeed: 0.0390s/iter; left time: 840.1318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0842204\n",
      "\tspeed: 0.0180s/iter; left time: 385.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0845753 Vali Loss: 0.0862688 Test Loss: 0.0969242\n",
      "Validation loss decreased (0.089868 --> 0.086269).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0763465\n",
      "\tspeed: 0.0367s/iter; left time: 781.8940s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791691\n",
      "\tspeed: 0.0200s/iter; left time: 423.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0797177 Vali Loss: 0.0844352 Test Loss: 0.0976003\n",
      "Validation loss decreased (0.086269 --> 0.084435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713951\n",
      "\tspeed: 0.0419s/iter; left time: 884.3778s\n",
      "\titers: 200, epoch: 6 | loss: 0.0679805\n",
      "\tspeed: 0.0192s/iter; left time: 403.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0764203 Vali Loss: 0.0827516 Test Loss: 0.0963793\n",
      "Validation loss decreased (0.084435 --> 0.082752).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0725202\n",
      "\tspeed: 0.0401s/iter; left time: 836.6305s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791608\n",
      "\tspeed: 0.0195s/iter; left time: 405.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0741157 Vali Loss: 0.0822265 Test Loss: 0.0931080\n",
      "Validation loss decreased (0.082752 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0727222\n",
      "\tspeed: 0.0400s/iter; left time: 825.2810s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776284\n",
      "\tspeed: 0.0188s/iter; left time: 385.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0728996 Vali Loss: 0.0819361 Test Loss: 0.0931618\n",
      "Validation loss decreased (0.082226 --> 0.081936).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722199\n",
      "\tspeed: 0.0434s/iter; left time: 886.6785s\n",
      "\titers: 200, epoch: 9 | loss: 0.0721218\n",
      "\tspeed: 0.0226s/iter; left time: 459.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0719492 Vali Loss: 0.0817230 Test Loss: 0.0941015\n",
      "Validation loss decreased (0.081936 --> 0.081723).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692011\n",
      "\tspeed: 0.0392s/iter; left time: 792.6042s\n",
      "\titers: 200, epoch: 10 | loss: 0.0684454\n",
      "\tspeed: 0.0186s/iter; left time: 374.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0710706 Vali Loss: 0.0811354 Test Loss: 0.0919947\n",
      "Validation loss decreased (0.081723 --> 0.081135).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0705062\n",
      "\tspeed: 0.0379s/iter; left time: 756.8310s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720357\n",
      "\tspeed: 0.0167s/iter; left time: 332.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0706808 Vali Loss: 0.0811571 Test Loss: 0.0935414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0677823\n",
      "\tspeed: 0.0373s/iter; left time: 736.2444s\n",
      "\titers: 200, epoch: 12 | loss: 0.0713468\n",
      "\tspeed: 0.0206s/iter; left time: 405.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0702094 Vali Loss: 0.0805435 Test Loss: 0.0918307\n",
      "Validation loss decreased (0.081135 --> 0.080543).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0672536\n",
      "\tspeed: 0.0398s/iter; left time: 777.3795s\n",
      "\titers: 200, epoch: 13 | loss: 0.0710736\n",
      "\tspeed: 0.0198s/iter; left time: 384.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0696859 Vali Loss: 0.0800864 Test Loss: 0.0917039\n",
      "Validation loss decreased (0.080543 --> 0.080086).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689039\n",
      "\tspeed: 0.0417s/iter; left time: 804.5364s\n",
      "\titers: 200, epoch: 14 | loss: 0.0638955\n",
      "\tspeed: 0.0210s/iter; left time: 402.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0694748 Vali Loss: 0.0803578 Test Loss: 0.0913581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0727906\n",
      "\tspeed: 0.0404s/iter; left time: 770.8913s\n",
      "\titers: 200, epoch: 15 | loss: 0.0683623\n",
      "\tspeed: 0.0184s/iter; left time: 349.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0692489 Vali Loss: 0.0800969 Test Loss: 0.0916660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659739\n",
      "\tspeed: 0.0375s/iter; left time: 707.2260s\n",
      "\titers: 200, epoch: 16 | loss: 0.0716897\n",
      "\tspeed: 0.0213s/iter; left time: 399.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0689950 Vali Loss: 0.0796784 Test Loss: 0.0917495\n",
      "Validation loss decreased (0.080086 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0680219\n",
      "\tspeed: 0.0395s/iter; left time: 735.1707s\n",
      "\titers: 200, epoch: 17 | loss: 0.0684547\n",
      "\tspeed: 0.0192s/iter; left time: 356.0137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0686040 Vali Loss: 0.0797242 Test Loss: 0.0915967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649704\n",
      "\tspeed: 0.0406s/iter; left time: 746.9086s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645268\n",
      "\tspeed: 0.0189s/iter; left time: 345.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0684679 Vali Loss: 0.0793499 Test Loss: 0.0909014\n",
      "Validation loss decreased (0.079678 --> 0.079350).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725169\n",
      "\tspeed: 0.0364s/iter; left time: 662.1664s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669255\n",
      "\tspeed: 0.0196s/iter; left time: 354.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0683734 Vali Loss: 0.0794145 Test Loss: 0.0911406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0636134\n",
      "\tspeed: 0.0399s/iter; left time: 716.9458s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710221\n",
      "\tspeed: 0.0204s/iter; left time: 364.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0681078 Vali Loss: 0.0794197 Test Loss: 0.0915060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0663622\n",
      "\tspeed: 0.0436s/iter; left time: 774.3176s\n",
      "\titers: 200, epoch: 21 | loss: 0.0706636\n",
      "\tspeed: 0.0200s/iter; left time: 352.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0679490 Vali Loss: 0.0791660 Test Loss: 0.0913030\n",
      "Validation loss decreased (0.079350 --> 0.079166).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0672757\n",
      "\tspeed: 0.0373s/iter; left time: 654.2221s\n",
      "\titers: 200, epoch: 22 | loss: 0.0654413\n",
      "\tspeed: 0.0168s/iter; left time: 292.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0679040 Vali Loss: 0.0790691 Test Loss: 0.0911685\n",
      "Validation loss decreased (0.079166 --> 0.079069).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0705021\n",
      "\tspeed: 0.0354s/iter; left time: 612.8038s\n",
      "\titers: 200, epoch: 23 | loss: 0.0658691\n",
      "\tspeed: 0.0176s/iter; left time: 302.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0676912 Vali Loss: 0.0789885 Test Loss: 0.0913348\n",
      "Validation loss decreased (0.079069 --> 0.078988).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0680787\n",
      "\tspeed: 0.0378s/iter; left time: 645.1778s\n",
      "\titers: 200, epoch: 24 | loss: 0.0676106\n",
      "\tspeed: 0.0104s/iter; left time: 176.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0676924 Vali Loss: 0.0789628 Test Loss: 0.0912996\n",
      "Validation loss decreased (0.078988 --> 0.078963).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0630342\n",
      "\tspeed: 0.0353s/iter; left time: 594.5885s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705554\n",
      "\tspeed: 0.0162s/iter; left time: 270.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0676622 Vali Loss: 0.0789210 Test Loss: 0.0909457\n",
      "Validation loss decreased (0.078963 --> 0.078921).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0685104\n",
      "\tspeed: 0.0354s/iter; left time: 588.8003s\n",
      "\titers: 200, epoch: 26 | loss: 0.0672015\n",
      "\tspeed: 0.0163s/iter; left time: 268.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0674808 Vali Loss: 0.0789927 Test Loss: 0.0912139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0692352\n",
      "\tspeed: 0.0378s/iter; left time: 619.7054s\n",
      "\titers: 200, epoch: 27 | loss: 0.0706252\n",
      "\tspeed: 0.0109s/iter; left time: 177.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 223 | Train Loss: 0.0674995 Vali Loss: 0.0791205 Test Loss: 0.0914404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0684496\n",
      "\tspeed: 0.0378s/iter; left time: 611.2516s\n",
      "\titers: 200, epoch: 28 | loss: 0.0698841\n",
      "\tspeed: 0.0188s/iter; left time: 302.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0672856 Vali Loss: 0.0788523 Test Loss: 0.0913232\n",
      "Validation loss decreased (0.078921 --> 0.078852).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0706654\n",
      "\tspeed: 0.0339s/iter; left time: 541.0261s\n",
      "\titers: 200, epoch: 29 | loss: 0.0647682\n",
      "\tspeed: 0.0174s/iter; left time: 275.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0673149 Vali Loss: 0.0787194 Test Loss: 0.0911718\n",
      "Validation loss decreased (0.078852 --> 0.078719).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0651648\n",
      "\tspeed: 0.0392s/iter; left time: 617.0011s\n",
      "\titers: 200, epoch: 30 | loss: 0.0686515\n",
      "\tspeed: 0.0167s/iter; left time: 260.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0672983 Vali Loss: 0.0787156 Test Loss: 0.0909932\n",
      "Validation loss decreased (0.078719 --> 0.078716).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0687478\n",
      "\tspeed: 0.0367s/iter; left time: 568.8887s\n",
      "\titers: 200, epoch: 31 | loss: 0.0687590\n",
      "\tspeed: 0.0161s/iter; left time: 247.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0672880 Vali Loss: 0.0787718 Test Loss: 0.0911326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0660623\n",
      "\tspeed: 0.0362s/iter; left time: 553.1338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0671192\n",
      "\tspeed: 0.0179s/iter; left time: 272.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0672749 Vali Loss: 0.0785819 Test Loss: 0.0910790\n",
      "Validation loss decreased (0.078716 --> 0.078582).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0639599\n",
      "\tspeed: 0.0380s/iter; left time: 571.9591s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655206\n",
      "\tspeed: 0.0164s/iter; left time: 246.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0672561 Vali Loss: 0.0786775 Test Loss: 0.0909472\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0664486\n",
      "\tspeed: 0.0365s/iter; left time: 541.4179s\n",
      "\titers: 200, epoch: 34 | loss: 0.0684379\n",
      "\tspeed: 0.0202s/iter; left time: 297.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0671589 Vali Loss: 0.0786497 Test Loss: 0.0912211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0703295\n",
      "\tspeed: 0.0323s/iter; left time: 471.7044s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643381\n",
      "\tspeed: 0.0153s/iter; left time: 222.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.0670801 Vali Loss: 0.0785995 Test Loss: 0.0909137\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0691360\n",
      "\tspeed: 0.0359s/iter; left time: 517.4167s\n",
      "\titers: 200, epoch: 36 | loss: 0.0669846\n",
      "\tspeed: 0.0167s/iter; left time: 238.7737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0670677 Vali Loss: 0.0786263 Test Loss: 0.0911508\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0679790\n",
      "\tspeed: 0.0387s/iter; left time: 548.5583s\n",
      "\titers: 200, epoch: 37 | loss: 0.0700472\n",
      "\tspeed: 0.0189s/iter; left time: 266.4105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0670516 Vali Loss: 0.0786052 Test Loss: 0.0908096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677164\n",
      "\tspeed: 0.0338s/iter; left time: 471.4835s\n",
      "\titers: 200, epoch: 38 | loss: 0.0702569\n",
      "\tspeed: 0.0157s/iter; left time: 217.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0670006 Vali Loss: 0.0785800 Test Loss: 0.0908754\n",
      "Validation loss decreased (0.078582 --> 0.078580).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0678545\n",
      "\tspeed: 0.0375s/iter; left time: 514.3320s\n",
      "\titers: 200, epoch: 39 | loss: 0.0676408\n",
      "\tspeed: 0.0167s/iter; left time: 227.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0670695 Vali Loss: 0.0787155 Test Loss: 0.0909989\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0641628\n",
      "\tspeed: 0.0338s/iter; left time: 456.7447s\n",
      "\titers: 200, epoch: 40 | loss: 0.0706587\n",
      "\tspeed: 0.0190s/iter; left time: 254.1526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0669401 Vali Loss: 0.0786649 Test Loss: 0.0912266\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0686898\n",
      "\tspeed: 0.0340s/iter; left time: 451.2815s\n",
      "\titers: 200, epoch: 41 | loss: 0.0689687\n",
      "\tspeed: 0.0172s/iter; left time: 227.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0669939 Vali Loss: 0.0785778 Test Loss: 0.0910469\n",
      "Validation loss decreased (0.078580 --> 0.078578).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0621686\n",
      "\tspeed: 0.0314s/iter; left time: 409.4772s\n",
      "\titers: 200, epoch: 42 | loss: 0.0651772\n",
      "\tspeed: 0.0101s/iter; left time: 131.0030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0669335 Vali Loss: 0.0784854 Test Loss: 0.0907716\n",
      "Validation loss decreased (0.078578 --> 0.078485).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0713836\n",
      "\tspeed: 0.0335s/iter; left time: 429.8505s\n",
      "\titers: 200, epoch: 43 | loss: 0.0724558\n",
      "\tspeed: 0.0159s/iter; left time: 202.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0668876 Vali Loss: 0.0784920 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0673730\n",
      "\tspeed: 0.0347s/iter; left time: 437.3072s\n",
      "\titers: 200, epoch: 44 | loss: 0.0659128\n",
      "\tspeed: 0.0164s/iter; left time: 205.6382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0670680 Vali Loss: 0.0785726 Test Loss: 0.0908339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0656723\n",
      "\tspeed: 0.0346s/iter; left time: 428.7056s\n",
      "\titers: 200, epoch: 45 | loss: 0.0675536\n",
      "\tspeed: 0.0171s/iter; left time: 210.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0669346 Vali Loss: 0.0786157 Test Loss: 0.0910247\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0690194\n",
      "\tspeed: 0.0355s/iter; left time: 431.6312s\n",
      "\titers: 200, epoch: 46 | loss: 0.0691908\n",
      "\tspeed: 0.0173s/iter; left time: 208.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0669033 Vali Loss: 0.0785442 Test Loss: 0.0909548\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0697375\n",
      "\tspeed: 0.0339s/iter; left time: 405.1871s\n",
      "\titers: 200, epoch: 47 | loss: 0.0653293\n",
      "\tspeed: 0.0185s/iter; left time: 219.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0669054 Vali Loss: 0.0786002 Test Loss: 0.0910236\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0703278\n",
      "\tspeed: 0.0363s/iter; left time: 425.6903s\n",
      "\titers: 200, epoch: 48 | loss: 0.0693457\n",
      "\tspeed: 0.0179s/iter; left time: 208.0452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0668152 Vali Loss: 0.0785441 Test Loss: 0.0911383\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0684838\n",
      "\tspeed: 0.0364s/iter; left time: 418.6347s\n",
      "\titers: 200, epoch: 49 | loss: 0.0639397\n",
      "\tspeed: 0.0170s/iter; left time: 193.5762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0668930 Vali Loss: 0.0787233 Test Loss: 0.0915537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0667185\n",
      "\tspeed: 0.0341s/iter; left time: 384.4137s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669038\n",
      "\tspeed: 0.0123s/iter; left time: 137.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 223 | Train Loss: 0.0669799 Vali Loss: 0.0785361 Test Loss: 0.0908527\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0674652\n",
      "\tspeed: 0.0354s/iter; left time: 391.6912s\n",
      "\titers: 200, epoch: 51 | loss: 0.0662912\n",
      "\tspeed: 0.0182s/iter; left time: 198.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0668049 Vali Loss: 0.0785372 Test Loss: 0.0910803\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0629704\n",
      "\tspeed: 0.0359s/iter; left time: 388.7170s\n",
      "\titers: 200, epoch: 52 | loss: 0.0659054\n",
      "\tspeed: 0.0191s/iter; left time: 204.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0668427 Vali Loss: 0.0785661 Test Loss: 0.0911044\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02374291978776455, rmse:0.1540873795747757, mae:0.09077159315347672, rse:0.5967950224876404\n",
      "Intermediate time for FR and pred_len 168: 00h:10m:02.50s\n",
      "Intermediate time for FR: 00h:31m:31.08s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0372s/iter; left time: 829.6776s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0150s/iter; left time: 333.8581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0317s/iter; left time: 699.0774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0156s/iter; left time: 343.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0317s/iter; left time: 692.7216s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0152s/iter; left time: 330.2687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0323s/iter; left time: 697.7453s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0159s/iter; left time: 343.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0337s/iter; left time: 721.1713s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0151s/iter; left time: 322.7324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0301s/iter; left time: 637.2388s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0097s/iter; left time: 205.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0333s/iter; left time: 697.4879s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0190s/iter; left time: 396.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0315s/iter; left time: 653.2988s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0153s/iter; left time: 314.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0319s/iter; left time: 653.9330s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0097s/iter; left time: 198.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0298s/iter; left time: 604.0068s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0187s/iter; left time: 377.9464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0362s/iter; left time: 727.0195s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0199s/iter; left time: 396.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0364s/iter; left time: 722.0892s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0204s/iter; left time: 402.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0390s/iter; left time: 764.2364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0183s/iter; left time: 356.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0316s/iter; left time: 613.0217s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0155s/iter; left time: 298.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0363s/iter; left time: 695.6022s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0197s/iter; left time: 374.9147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0335s/iter; left time: 633.8865s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0176s/iter; left time: 331.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0336s/iter; left time: 628.2196s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0167s/iter; left time: 311.1636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0336s/iter; left time: 621.2202s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0187s/iter; left time: 344.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0341s/iter; left time: 623.1785s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0162s/iter; left time: 294.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0365s/iter; left time: 657.8588s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0173s/iter; left time: 309.9172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0636579\n",
      "\tspeed: 0.0307s/iter; left time: 546.5692s\n",
      "\titers: 200, epoch: 21 | loss: 0.0684156\n",
      "\tspeed: 0.0153s/iter; left time: 270.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0633922 Vali Loss: 0.0604795 Test Loss: 0.0628369\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0617232\n",
      "\tspeed: 0.0359s/iter; left time: 632.1517s\n",
      "\titers: 200, epoch: 22 | loss: 0.0608547\n",
      "\tspeed: 0.0137s/iter; left time: 239.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0631224 Vali Loss: 0.0599889 Test Loss: 0.0626463\n",
      "Validation loss decreased (0.060343 --> 0.059989).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592435\n",
      "\tspeed: 0.0288s/iter; left time: 500.0491s\n",
      "\titers: 200, epoch: 23 | loss: 0.0632939\n",
      "\tspeed: 0.0151s/iter; left time: 260.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0629821 Vali Loss: 0.0600816 Test Loss: 0.0626648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0598919\n",
      "\tspeed: 0.0327s/iter; left time: 561.1720s\n",
      "\titers: 200, epoch: 24 | loss: 0.0626087\n",
      "\tspeed: 0.0175s/iter; left time: 298.8617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0628714 Vali Loss: 0.0598187 Test Loss: 0.0625466\n",
      "Validation loss decreased (0.059989 --> 0.059819).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0609628\n",
      "\tspeed: 0.0356s/iter; left time: 602.0827s\n",
      "\titers: 200, epoch: 25 | loss: 0.0664621\n",
      "\tspeed: 0.0197s/iter; left time: 331.4096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0628192 Vali Loss: 0.0597902 Test Loss: 0.0625925\n",
      "Validation loss decreased (0.059819 --> 0.059790).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0608600\n",
      "\tspeed: 0.0313s/iter; left time: 522.5030s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600900\n",
      "\tspeed: 0.0155s/iter; left time: 258.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0625666 Vali Loss: 0.0595580 Test Loss: 0.0623209\n",
      "Validation loss decreased (0.059790 --> 0.059558).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0646851\n",
      "\tspeed: 0.0324s/iter; left time: 533.6408s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633536\n",
      "\tspeed: 0.0157s/iter; left time: 257.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0625305 Vali Loss: 0.0596706 Test Loss: 0.0622908\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0621080\n",
      "\tspeed: 0.0343s/iter; left time: 557.3171s\n",
      "\titers: 200, epoch: 28 | loss: 0.0643726\n",
      "\tspeed: 0.0166s/iter; left time: 268.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0626719 Vali Loss: 0.0595797 Test Loss: 0.0623563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0635776\n",
      "\tspeed: 0.0341s/iter; left time: 546.3265s\n",
      "\titers: 200, epoch: 29 | loss: 0.0622601\n",
      "\tspeed: 0.0181s/iter; left time: 288.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0623069 Vali Loss: 0.0596973 Test Loss: 0.0623452\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0631619\n",
      "\tspeed: 0.0337s/iter; left time: 532.5009s\n",
      "\titers: 200, epoch: 30 | loss: 0.0598195\n",
      "\tspeed: 0.0163s/iter; left time: 256.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0623270 Vali Loss: 0.0594776 Test Loss: 0.0621852\n",
      "Validation loss decreased (0.059558 --> 0.059478).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0625057\n",
      "\tspeed: 0.0308s/iter; left time: 479.7582s\n",
      "\titers: 200, epoch: 31 | loss: 0.0638103\n",
      "\tspeed: 0.0160s/iter; left time: 247.2758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0620483 Vali Loss: 0.0594568 Test Loss: 0.0621827\n",
      "Validation loss decreased (0.059478 --> 0.059457).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628317\n",
      "\tspeed: 0.0353s/iter; left time: 541.6458s\n",
      "\titers: 200, epoch: 32 | loss: 0.0585777\n",
      "\tspeed: 0.0195s/iter; left time: 297.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0620746 Vali Loss: 0.0594897 Test Loss: 0.0620980\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0628268\n",
      "\tspeed: 0.0264s/iter; left time: 398.8964s\n",
      "\titers: 200, epoch: 33 | loss: 0.0614122\n",
      "\tspeed: 0.0116s/iter; left time: 174.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0619883 Vali Loss: 0.0593070 Test Loss: 0.0620515\n",
      "Validation loss decreased (0.059457 --> 0.059307).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0656993\n",
      "\tspeed: 0.0327s/iter; left time: 487.1355s\n",
      "\titers: 200, epoch: 34 | loss: 0.0583804\n",
      "\tspeed: 0.0117s/iter; left time: 173.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0621983 Vali Loss: 0.0592014 Test Loss: 0.0620528\n",
      "Validation loss decreased (0.059307 --> 0.059201).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0630521\n",
      "\tspeed: 0.0309s/iter; left time: 454.2923s\n",
      "\titers: 200, epoch: 35 | loss: 0.0647735\n",
      "\tspeed: 0.0153s/iter; left time: 223.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0621645 Vali Loss: 0.0592880 Test Loss: 0.0621266\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0605291\n",
      "\tspeed: 0.0322s/iter; left time: 466.1592s\n",
      "\titers: 200, epoch: 36 | loss: 0.0630355\n",
      "\tspeed: 0.0164s/iter; left time: 235.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0619489 Vali Loss: 0.0592510 Test Loss: 0.0620053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628529\n",
      "\tspeed: 0.0332s/iter; left time: 472.3093s\n",
      "\titers: 200, epoch: 37 | loss: 0.0633543\n",
      "\tspeed: 0.0167s/iter; left time: 235.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0619418 Vali Loss: 0.0592681 Test Loss: 0.0620028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0632918\n",
      "\tspeed: 0.0354s/iter; left time: 495.4270s\n",
      "\titers: 200, epoch: 38 | loss: 0.0604434\n",
      "\tspeed: 0.0178s/iter; left time: 247.5633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0618719 Vali Loss: 0.0592907 Test Loss: 0.0619844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0609300\n",
      "\tspeed: 0.0302s/iter; left time: 416.5441s\n",
      "\titers: 200, epoch: 39 | loss: 0.0603718\n",
      "\tspeed: 0.0163s/iter; left time: 223.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0618833 Vali Loss: 0.0591956 Test Loss: 0.0619580\n",
      "Validation loss decreased (0.059201 --> 0.059196).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0595688\n",
      "\tspeed: 0.0355s/iter; left time: 481.9386s\n",
      "\titers: 200, epoch: 40 | loss: 0.0539876\n",
      "\tspeed: 0.0173s/iter; left time: 232.8810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0619276 Vali Loss: 0.0590186 Test Loss: 0.0618840\n",
      "Validation loss decreased (0.059196 --> 0.059019).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0608221\n",
      "\tspeed: 0.0336s/iter; left time: 447.8007s\n",
      "\titers: 200, epoch: 41 | loss: 0.0619081\n",
      "\tspeed: 0.0106s/iter; left time: 140.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 224 | Train Loss: 0.0619062 Vali Loss: 0.0592204 Test Loss: 0.0619333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0609454\n",
      "\tspeed: 0.0313s/iter; left time: 410.0920s\n",
      "\titers: 200, epoch: 42 | loss: 0.0601154\n",
      "\tspeed: 0.0185s/iter; left time: 240.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0618338 Vali Loss: 0.0591389 Test Loss: 0.0618955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0613626\n",
      "\tspeed: 0.0352s/iter; left time: 453.2439s\n",
      "\titers: 200, epoch: 43 | loss: 0.0631115\n",
      "\tspeed: 0.0122s/iter; left time: 156.6280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0618957 Vali Loss: 0.0590800 Test Loss: 0.0618907\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0629008\n",
      "\tspeed: 0.0318s/iter; left time: 403.1037s\n",
      "\titers: 200, epoch: 44 | loss: 0.0581203\n",
      "\tspeed: 0.0178s/iter; left time: 223.9509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0617152 Vali Loss: 0.0591108 Test Loss: 0.0618826\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636551\n",
      "\tspeed: 0.0351s/iter; left time: 437.3267s\n",
      "\titers: 200, epoch: 45 | loss: 0.0600598\n",
      "\tspeed: 0.0189s/iter; left time: 233.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0617799 Vali Loss: 0.0591952 Test Loss: 0.0619276\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0595757\n",
      "\tspeed: 0.0329s/iter; left time: 401.8606s\n",
      "\titers: 200, epoch: 46 | loss: 0.0658892\n",
      "\tspeed: 0.0165s/iter; left time: 199.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0618534 Vali Loss: 0.0592182 Test Loss: 0.0619470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0637597\n",
      "\tspeed: 0.0333s/iter; left time: 399.3799s\n",
      "\titers: 200, epoch: 47 | loss: 0.0567419\n",
      "\tspeed: 0.0168s/iter; left time: 200.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0617180 Vali Loss: 0.0591394 Test Loss: 0.0618530\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0655076\n",
      "\tspeed: 0.0339s/iter; left time: 398.7497s\n",
      "\titers: 200, epoch: 48 | loss: 0.0621627\n",
      "\tspeed: 0.0174s/iter; left time: 203.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0616754 Vali Loss: 0.0591051 Test Loss: 0.0618874\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0585296\n",
      "\tspeed: 0.0297s/iter; left time: 342.4929s\n",
      "\titers: 200, epoch: 49 | loss: 0.0647142\n",
      "\tspeed: 0.0099s/iter; left time: 113.6950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0616484 Vali Loss: 0.0590416 Test Loss: 0.0618605\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0597669\n",
      "\tspeed: 0.0302s/iter; left time: 342.0265s\n",
      "\titers: 200, epoch: 50 | loss: 0.0630897\n",
      "\tspeed: 0.0183s/iter; left time: 205.0283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0621644 Vali Loss: 0.0590834 Test Loss: 0.0618355\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010859525762498379, rmse:0.1042090505361557, mae:0.06188397854566574, rse:0.39375466108322144\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2800024\n",
      "\tspeed: 0.0177s/iter; left time: 394.4046s\n",
      "\titers: 200, epoch: 1 | loss: 0.2565308\n",
      "\tspeed: 0.0172s/iter; left time: 381.3323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.2769537 Vali Loss: 0.1967411 Test Loss: 0.2045412\n",
      "Validation loss decreased (inf --> 0.196741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471140\n",
      "\tspeed: 0.0379s/iter; left time: 836.8337s\n",
      "\titers: 200, epoch: 2 | loss: 0.1187794\n",
      "\tspeed: 0.0196s/iter; left time: 429.7812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1558379 Vali Loss: 0.0886813 Test Loss: 0.0902449\n",
      "Validation loss decreased (0.196741 --> 0.088681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994043\n",
      "\tspeed: 0.0326s/iter; left time: 712.8470s\n",
      "\titers: 200, epoch: 3 | loss: 0.0909980\n",
      "\tspeed: 0.0151s/iter; left time: 327.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0989681 Vali Loss: 0.0795341 Test Loss: 0.0814914\n",
      "Validation loss decreased (0.088681 --> 0.079534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0899246\n",
      "\tspeed: 0.0352s/iter; left time: 762.0704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844858\n",
      "\tspeed: 0.0189s/iter; left time: 406.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0877668 Vali Loss: 0.0763881 Test Loss: 0.0789538\n",
      "Validation loss decreased (0.079534 --> 0.076388).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0789782\n",
      "\tspeed: 0.0387s/iter; left time: 828.2215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0776984\n",
      "\tspeed: 0.0184s/iter; left time: 392.3846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0813410 Vali Loss: 0.0742040 Test Loss: 0.0753333\n",
      "Validation loss decreased (0.076388 --> 0.074204).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817973\n",
      "\tspeed: 0.0321s/iter; left time: 679.5854s\n",
      "\titers: 200, epoch: 6 | loss: 0.0777035\n",
      "\tspeed: 0.0164s/iter; left time: 346.0962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0777122 Vali Loss: 0.0707489 Test Loss: 0.0715350\n",
      "Validation loss decreased (0.074204 --> 0.070749).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783837\n",
      "\tspeed: 0.0388s/iter; left time: 812.3681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0750453\n",
      "\tspeed: 0.0209s/iter; left time: 436.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0744820 Vali Loss: 0.0677601 Test Loss: 0.0687978\n",
      "Validation loss decreased (0.070749 --> 0.067760).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782167\n",
      "\tspeed: 0.0367s/iter; left time: 760.5999s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762185\n",
      "\tspeed: 0.0173s/iter; left time: 356.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0723486 Vali Loss: 0.0665194 Test Loss: 0.0681631\n",
      "Validation loss decreased (0.067760 --> 0.066519).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0719319\n",
      "\tspeed: 0.0350s/iter; left time: 718.0431s\n",
      "\titers: 200, epoch: 9 | loss: 0.0729036\n",
      "\tspeed: 0.0187s/iter; left time: 380.6478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0707993 Vali Loss: 0.0652852 Test Loss: 0.0671969\n",
      "Validation loss decreased (0.066519 --> 0.065285).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0697719\n",
      "\tspeed: 0.0344s/iter; left time: 697.3813s\n",
      "\titers: 200, epoch: 10 | loss: 0.0669461\n",
      "\tspeed: 0.0184s/iter; left time: 371.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0695666 Vali Loss: 0.0644584 Test Loss: 0.0664166\n",
      "Validation loss decreased (0.065285 --> 0.064458).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657162\n",
      "\tspeed: 0.0342s/iter; left time: 686.1571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708782\n",
      "\tspeed: 0.0163s/iter; left time: 325.7935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0685621 Vali Loss: 0.0636904 Test Loss: 0.0658297\n",
      "Validation loss decreased (0.064458 --> 0.063690).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0681091\n",
      "\tspeed: 0.0332s/iter; left time: 659.4752s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657380\n",
      "\tspeed: 0.0156s/iter; left time: 308.4917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0673740 Vali Loss: 0.0629184 Test Loss: 0.0653686\n",
      "Validation loss decreased (0.063690 --> 0.062918).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0648409\n",
      "\tspeed: 0.0366s/iter; left time: 718.3665s\n",
      "\titers: 200, epoch: 13 | loss: 0.0676044\n",
      "\tspeed: 0.0174s/iter; left time: 339.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0664828 Vali Loss: 0.0624158 Test Loss: 0.0646993\n",
      "Validation loss decreased (0.062918 --> 0.062416).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0625931\n",
      "\tspeed: 0.0354s/iter; left time: 685.6556s\n",
      "\titers: 200, epoch: 14 | loss: 0.0675450\n",
      "\tspeed: 0.0098s/iter; left time: 188.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0661881 Vali Loss: 0.0624158 Test Loss: 0.0645311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0642792\n",
      "\tspeed: 0.0297s/iter; left time: 569.6898s\n",
      "\titers: 200, epoch: 15 | loss: 0.0630810\n",
      "\tspeed: 0.0172s/iter; left time: 327.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0654435 Vali Loss: 0.0616787 Test Loss: 0.0638697\n",
      "Validation loss decreased (0.062416 --> 0.061679).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659622\n",
      "\tspeed: 0.0327s/iter; left time: 619.0508s\n",
      "\titers: 200, epoch: 16 | loss: 0.0648140\n",
      "\tspeed: 0.0154s/iter; left time: 291.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0650331 Vali Loss: 0.0611787 Test Loss: 0.0635631\n",
      "Validation loss decreased (0.061679 --> 0.061179).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632138\n",
      "\tspeed: 0.0366s/iter; left time: 684.4762s\n",
      "\titers: 200, epoch: 17 | loss: 0.0657867\n",
      "\tspeed: 0.0200s/iter; left time: 373.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0648311 Vali Loss: 0.0618507 Test Loss: 0.0641396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631447\n",
      "\tspeed: 0.0346s/iter; left time: 640.3081s\n",
      "\titers: 200, epoch: 18 | loss: 0.0629477\n",
      "\tspeed: 0.0173s/iter; left time: 318.6573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0644778 Vali Loss: 0.0618359 Test Loss: 0.0640122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0666737\n",
      "\tspeed: 0.0288s/iter; left time: 525.4421s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644217\n",
      "\tspeed: 0.0099s/iter; left time: 180.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0642466 Vali Loss: 0.0605997 Test Loss: 0.0629325\n",
      "Validation loss decreased (0.061179 --> 0.060600).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0658719\n",
      "\tspeed: 0.0325s/iter; left time: 586.0754s\n",
      "\titers: 200, epoch: 20 | loss: 0.0618839\n",
      "\tspeed: 0.0184s/iter; left time: 329.3096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0637577 Vali Loss: 0.0605858 Test Loss: 0.0627764\n",
      "Validation loss decreased (0.060600 --> 0.060586).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0653563\n",
      "\tspeed: 0.0360s/iter; left time: 640.7762s\n",
      "\titers: 200, epoch: 21 | loss: 0.0624877\n",
      "\tspeed: 0.0198s/iter; left time: 350.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0636068 Vali Loss: 0.0604504 Test Loss: 0.0628039\n",
      "Validation loss decreased (0.060586 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0683355\n",
      "\tspeed: 0.0358s/iter; left time: 630.7388s\n",
      "\titers: 200, epoch: 22 | loss: 0.0639780\n",
      "\tspeed: 0.0172s/iter; left time: 301.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0633847 Vali Loss: 0.0601827 Test Loss: 0.0624981\n",
      "Validation loss decreased (0.060450 --> 0.060183).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618977\n",
      "\tspeed: 0.0362s/iter; left time: 629.2228s\n",
      "\titers: 200, epoch: 23 | loss: 0.0635058\n",
      "\tspeed: 0.0188s/iter; left time: 325.5360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0632648 Vali Loss: 0.0601221 Test Loss: 0.0624841\n",
      "Validation loss decreased (0.060183 --> 0.060122).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0685568\n",
      "\tspeed: 0.0341s/iter; left time: 585.2757s\n",
      "\titers: 200, epoch: 24 | loss: 0.0617276\n",
      "\tspeed: 0.0183s/iter; left time: 312.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0631657 Vali Loss: 0.0599461 Test Loss: 0.0623289\n",
      "Validation loss decreased (0.060122 --> 0.059946).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0612943\n",
      "\tspeed: 0.0320s/iter; left time: 542.2811s\n",
      "\titers: 200, epoch: 25 | loss: 0.0613715\n",
      "\tspeed: 0.0156s/iter; left time: 262.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0630194 Vali Loss: 0.0598214 Test Loss: 0.0622472\n",
      "Validation loss decreased (0.059946 --> 0.059821).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0616365\n",
      "\tspeed: 0.0353s/iter; left time: 589.7227s\n",
      "\titers: 200, epoch: 26 | loss: 0.0625531\n",
      "\tspeed: 0.0169s/iter; left time: 279.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0629436 Vali Loss: 0.0600481 Test Loss: 0.0624270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0595656\n",
      "\tspeed: 0.0340s/iter; left time: 560.4524s\n",
      "\titers: 200, epoch: 27 | loss: 0.0580215\n",
      "\tspeed: 0.0211s/iter; left time: 345.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0629101 Vali Loss: 0.0599677 Test Loss: 0.0624291\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0595673\n",
      "\tspeed: 0.0387s/iter; left time: 628.5840s\n",
      "\titers: 200, epoch: 28 | loss: 0.0604597\n",
      "\tspeed: 0.0195s/iter; left time: 315.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0627764 Vali Loss: 0.0597563 Test Loss: 0.0620716\n",
      "Validation loss decreased (0.059821 --> 0.059756).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0610145\n",
      "\tspeed: 0.0351s/iter; left time: 562.1179s\n",
      "\titers: 200, epoch: 29 | loss: 0.0678734\n",
      "\tspeed: 0.0178s/iter; left time: 284.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0628354 Vali Loss: 0.0596368 Test Loss: 0.0620405\n",
      "Validation loss decreased (0.059756 --> 0.059637).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0604661\n",
      "\tspeed: 0.0355s/iter; left time: 561.2686s\n",
      "\titers: 200, epoch: 30 | loss: 0.0575804\n",
      "\tspeed: 0.0200s/iter; left time: 313.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0626474 Vali Loss: 0.0598288 Test Loss: 0.0621470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0618770\n",
      "\tspeed: 0.0370s/iter; left time: 576.8099s\n",
      "\titers: 200, epoch: 31 | loss: 0.0584592\n",
      "\tspeed: 0.0200s/iter; left time: 310.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0625613 Vali Loss: 0.0598233 Test Loss: 0.0622778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0607475\n",
      "\tspeed: 0.0327s/iter; left time: 501.4801s\n",
      "\titers: 200, epoch: 32 | loss: 0.0630998\n",
      "\tspeed: 0.0173s/iter; left time: 264.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0624705 Vali Loss: 0.0598062 Test Loss: 0.0621475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0629692\n",
      "\tspeed: 0.0327s/iter; left time: 495.3877s\n",
      "\titers: 200, epoch: 33 | loss: 0.0629765\n",
      "\tspeed: 0.0182s/iter; left time: 273.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0624585 Vali Loss: 0.0595935 Test Loss: 0.0619383\n",
      "Validation loss decreased (0.059637 --> 0.059593).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0619376\n",
      "\tspeed: 0.0374s/iter; left time: 558.3414s\n",
      "\titers: 200, epoch: 34 | loss: 0.0628307\n",
      "\tspeed: 0.0189s/iter; left time: 279.4343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0623878 Vali Loss: 0.0596400 Test Loss: 0.0620877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0625874\n",
      "\tspeed: 0.0340s/iter; left time: 499.6294s\n",
      "\titers: 200, epoch: 35 | loss: 0.0600728\n",
      "\tspeed: 0.0201s/iter; left time: 292.6040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0622915 Vali Loss: 0.0595726 Test Loss: 0.0619388\n",
      "Validation loss decreased (0.059593 --> 0.059573).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0589112\n",
      "\tspeed: 0.0334s/iter; left time: 482.6419s\n",
      "\titers: 200, epoch: 36 | loss: 0.0629685\n",
      "\tspeed: 0.0172s/iter; left time: 247.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0622441 Vali Loss: 0.0594508 Test Loss: 0.0618298\n",
      "Validation loss decreased (0.059573 --> 0.059451).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0596345\n",
      "\tspeed: 0.0366s/iter; left time: 521.7190s\n",
      "\titers: 200, epoch: 37 | loss: 0.0658240\n",
      "\tspeed: 0.0154s/iter; left time: 217.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0621255 Vali Loss: 0.0594057 Test Loss: 0.0618365\n",
      "Validation loss decreased (0.059451 --> 0.059406).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0586868\n",
      "\tspeed: 0.0356s/iter; left time: 499.4256s\n",
      "\titers: 200, epoch: 38 | loss: 0.0643889\n",
      "\tspeed: 0.0205s/iter; left time: 285.4489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0621273 Vali Loss: 0.0592569 Test Loss: 0.0617459\n",
      "Validation loss decreased (0.059406 --> 0.059257).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0636054\n",
      "\tspeed: 0.0359s/iter; left time: 494.7004s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607086\n",
      "\tspeed: 0.0182s/iter; left time: 249.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0620737 Vali Loss: 0.0593783 Test Loss: 0.0617540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0611944\n",
      "\tspeed: 0.0348s/iter; left time: 472.6682s\n",
      "\titers: 200, epoch: 40 | loss: 0.0638018\n",
      "\tspeed: 0.0159s/iter; left time: 213.5873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0621858 Vali Loss: 0.0594381 Test Loss: 0.0618958\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0621031\n",
      "\tspeed: 0.0322s/iter; left time: 429.9915s\n",
      "\titers: 200, epoch: 41 | loss: 0.0670178\n",
      "\tspeed: 0.0165s/iter; left time: 217.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0622197 Vali Loss: 0.0595200 Test Loss: 0.0618521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0614138\n",
      "\tspeed: 0.0385s/iter; left time: 505.5598s\n",
      "\titers: 200, epoch: 42 | loss: 0.0640670\n",
      "\tspeed: 0.0201s/iter; left time: 261.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0620228 Vali Loss: 0.0593863 Test Loss: 0.0617962\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0599074\n",
      "\tspeed: 0.0327s/iter; left time: 421.6159s\n",
      "\titers: 200, epoch: 43 | loss: 0.0657019\n",
      "\tspeed: 0.0160s/iter; left time: 205.0798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0620586 Vali Loss: 0.0593569 Test Loss: 0.0617540\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0636532\n",
      "\tspeed: 0.0317s/iter; left time: 401.6434s\n",
      "\titers: 200, epoch: 44 | loss: 0.0665709\n",
      "\tspeed: 0.0153s/iter; left time: 192.7011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0622552 Vali Loss: 0.0594424 Test Loss: 0.0618573\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0624063\n",
      "\tspeed: 0.0335s/iter; left time: 416.6671s\n",
      "\titers: 200, epoch: 45 | loss: 0.0637858\n",
      "\tspeed: 0.0152s/iter; left time: 187.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0619498 Vali Loss: 0.0593369 Test Loss: 0.0617740\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0607949\n",
      "\tspeed: 0.0350s/iter; left time: 427.3467s\n",
      "\titers: 200, epoch: 46 | loss: 0.0609457\n",
      "\tspeed: 0.0163s/iter; left time: 197.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0621098 Vali Loss: 0.0594001 Test Loss: 0.0618141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0665860\n",
      "\tspeed: 0.0314s/iter; left time: 376.4471s\n",
      "\titers: 200, epoch: 47 | loss: 0.0645591\n",
      "\tspeed: 0.0153s/iter; left time: 181.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0621447 Vali Loss: 0.0593360 Test Loss: 0.0617443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0594761\n",
      "\tspeed: 0.0356s/iter; left time: 419.6952s\n",
      "\titers: 200, epoch: 48 | loss: 0.0645299\n",
      "\tspeed: 0.0097s/iter; left time: 113.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 224 | Train Loss: 0.0619675 Vali Loss: 0.0593532 Test Loss: 0.0618188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010799581184983253, rmse:0.10392103344202042, mae:0.06174592673778534, rse:0.39266642928123474\n",
      "Intermediate time for IT and pred_len 24: 00h:08m:24.53s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0361s/iter; left time: 804.0497s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0138s/iter; left time: 305.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0362s/iter; left time: 798.9360s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0182s/iter; left time: 400.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0426s/iter; left time: 931.3964s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0201s/iter; left time: 437.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0382s/iter; left time: 825.3833s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0171s/iter; left time: 368.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0389s/iter; left time: 833.4232s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0186s/iter; left time: 395.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0414s/iter; left time: 876.2037s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0241s/iter; left time: 508.9199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0434s/iter; left time: 908.9610s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0213s/iter; left time: 443.3638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0400s/iter; left time: 828.7045s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0210s/iter; left time: 432.6433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0386s/iter; left time: 791.5798s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0186s/iter; left time: 380.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0411s/iter; left time: 833.4227s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0187s/iter; left time: 376.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0394s/iter; left time: 790.4986s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0194s/iter; left time: 387.3174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0368s/iter; left time: 729.3041s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0190s/iter; left time: 375.6557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0380s/iter; left time: 745.5510s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0192s/iter; left time: 375.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0362s/iter; left time: 701.8662s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0181s/iter; left time: 349.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0348s/iter; left time: 667.8900s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0165s/iter; left time: 315.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0346s/iter; left time: 655.3520s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0215s/iter; left time: 404.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0390s/iter; left time: 730.4829s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0189s/iter; left time: 351.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0378s/iter; left time: 698.1736s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0104s/iter; left time: 190.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0357s/iter; left time: 652.2719s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0219s/iter; left time: 397.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0398s/iter; left time: 717.9071s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0194s/iter; left time: 348.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0763154\n",
      "\tspeed: 0.0363s/iter; left time: 646.6103s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777684\n",
      "\tspeed: 0.0201s/iter; left time: 356.3276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0809238 Vali Loss: 0.0789384 Test Loss: 0.0843812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0852907\n",
      "\tspeed: 0.0384s/iter; left time: 676.2352s\n",
      "\titers: 200, epoch: 22 | loss: 0.0795436\n",
      "\tspeed: 0.0215s/iter; left time: 376.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0807206 Vali Loss: 0.0788067 Test Loss: 0.0840699\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0787717\n",
      "\tspeed: 0.0386s/iter; left time: 670.9653s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802156\n",
      "\tspeed: 0.0220s/iter; left time: 380.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0806322 Vali Loss: 0.0787457 Test Loss: 0.0841000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0797972\n",
      "\tspeed: 0.0405s/iter; left time: 694.0046s\n",
      "\titers: 200, epoch: 24 | loss: 0.0778857\n",
      "\tspeed: 0.0233s/iter; left time: 396.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0805527 Vali Loss: 0.0787727 Test Loss: 0.0841434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0807684\n",
      "\tspeed: 0.0393s/iter; left time: 665.9542s\n",
      "\titers: 200, epoch: 25 | loss: 0.0813613\n",
      "\tspeed: 0.0197s/iter; left time: 332.2894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0804330 Vali Loss: 0.0782987 Test Loss: 0.0837620\n",
      "Validation loss decreased (0.078444 --> 0.078299).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0792543\n",
      "\tspeed: 0.0386s/iter; left time: 645.0047s\n",
      "\titers: 200, epoch: 26 | loss: 0.0843703\n",
      "\tspeed: 0.0198s/iter; left time: 328.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0805406 Vali Loss: 0.0788216 Test Loss: 0.0842155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819269\n",
      "\tspeed: 0.0365s/iter; left time: 601.7160s\n",
      "\titers: 200, epoch: 27 | loss: 0.0808097\n",
      "\tspeed: 0.0190s/iter; left time: 311.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0801705 Vali Loss: 0.0781294 Test Loss: 0.0835582\n",
      "Validation loss decreased (0.078299 --> 0.078129).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751514\n",
      "\tspeed: 0.0361s/iter; left time: 587.2327s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783330\n",
      "\tspeed: 0.0184s/iter; left time: 297.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0800339 Vali Loss: 0.0781661 Test Loss: 0.0836645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818948\n",
      "\tspeed: 0.0395s/iter; left time: 633.6423s\n",
      "\titers: 200, epoch: 29 | loss: 0.0784700\n",
      "\tspeed: 0.0195s/iter; left time: 311.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0803651 Vali Loss: 0.0783299 Test Loss: 0.0838469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0800727\n",
      "\tspeed: 0.0384s/iter; left time: 607.6391s\n",
      "\titers: 200, epoch: 30 | loss: 0.0784400\n",
      "\tspeed: 0.0193s/iter; left time: 302.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0800930 Vali Loss: 0.0782181 Test Loss: 0.0836337\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0822492\n",
      "\tspeed: 0.0400s/iter; left time: 623.9120s\n",
      "\titers: 200, epoch: 31 | loss: 0.0791047\n",
      "\tspeed: 0.0239s/iter; left time: 369.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0803353 Vali Loss: 0.0781956 Test Loss: 0.0836943\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776482\n",
      "\tspeed: 0.0386s/iter; left time: 593.5173s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857207\n",
      "\tspeed: 0.0196s/iter; left time: 298.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0799039 Vali Loss: 0.0781738 Test Loss: 0.0835756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0832403\n",
      "\tspeed: 0.0365s/iter; left time: 553.0107s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803201\n",
      "\tspeed: 0.0193s/iter; left time: 290.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0802236 Vali Loss: 0.0782661 Test Loss: 0.0837127\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0800152\n",
      "\tspeed: 0.0409s/iter; left time: 609.6672s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801739\n",
      "\tspeed: 0.0244s/iter; left time: 361.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0799593 Vali Loss: 0.0782292 Test Loss: 0.0838448\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0809886\n",
      "\tspeed: 0.0373s/iter; left time: 547.3101s\n",
      "\titers: 200, epoch: 35 | loss: 0.0803972\n",
      "\tspeed: 0.0185s/iter; left time: 270.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0799808 Vali Loss: 0.0781636 Test Loss: 0.0836660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0812298\n",
      "\tspeed: 0.0358s/iter; left time: 518.3137s\n",
      "\titers: 200, epoch: 36 | loss: 0.0776353\n",
      "\tspeed: 0.0192s/iter; left time: 275.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0798419 Vali Loss: 0.0780852 Test Loss: 0.0836261\n",
      "Validation loss decreased (0.078129 --> 0.078085).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0789606\n",
      "\tspeed: 0.0360s/iter; left time: 512.9772s\n",
      "\titers: 200, epoch: 37 | loss: 0.0793518\n",
      "\tspeed: 0.0193s/iter; left time: 272.7763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0798107 Vali Loss: 0.0780603 Test Loss: 0.0835447\n",
      "Validation loss decreased (0.078085 --> 0.078060).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0815707\n",
      "\tspeed: 0.0397s/iter; left time: 556.2046s\n",
      "\titers: 200, epoch: 38 | loss: 0.0814658\n",
      "\tspeed: 0.0231s/iter; left time: 320.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0798724 Vali Loss: 0.0779505 Test Loss: 0.0835769\n",
      "Validation loss decreased (0.078060 --> 0.077950).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0809439\n",
      "\tspeed: 0.0389s/iter; left time: 536.0045s\n",
      "\titers: 200, epoch: 39 | loss: 0.0798386\n",
      "\tspeed: 0.0181s/iter; left time: 247.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0799884 Vali Loss: 0.0781336 Test Loss: 0.0835738\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0818783\n",
      "\tspeed: 0.0372s/iter; left time: 504.2260s\n",
      "\titers: 200, epoch: 40 | loss: 0.0758224\n",
      "\tspeed: 0.0193s/iter; left time: 260.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0797947 Vali Loss: 0.0780988 Test Loss: 0.0836096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0778328\n",
      "\tspeed: 0.0369s/iter; left time: 492.2149s\n",
      "\titers: 200, epoch: 41 | loss: 0.0801140\n",
      "\tspeed: 0.0192s/iter; left time: 253.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0796954 Vali Loss: 0.0780624 Test Loss: 0.0836007\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0805493\n",
      "\tspeed: 0.0392s/iter; left time: 514.7884s\n",
      "\titers: 200, epoch: 42 | loss: 0.0836331\n",
      "\tspeed: 0.0200s/iter; left time: 259.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0797554 Vali Loss: 0.0781244 Test Loss: 0.0836102\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0791316\n",
      "\tspeed: 0.0360s/iter; left time: 463.9825s\n",
      "\titers: 200, epoch: 43 | loss: 0.0795564\n",
      "\tspeed: 0.0201s/iter; left time: 257.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0797895 Vali Loss: 0.0779153 Test Loss: 0.0835645\n",
      "Validation loss decreased (0.077950 --> 0.077915).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0786589\n",
      "\tspeed: 0.0385s/iter; left time: 487.6957s\n",
      "\titers: 200, epoch: 44 | loss: 0.0807176\n",
      "\tspeed: 0.0216s/iter; left time: 271.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0798394 Vali Loss: 0.0781401 Test Loss: 0.0836471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0777596\n",
      "\tspeed: 0.0359s/iter; left time: 446.2947s\n",
      "\titers: 200, epoch: 45 | loss: 0.0773379\n",
      "\tspeed: 0.0190s/iter; left time: 235.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0797040 Vali Loss: 0.0781044 Test Loss: 0.0836482\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788197\n",
      "\tspeed: 0.0393s/iter; left time: 479.8020s\n",
      "\titers: 200, epoch: 46 | loss: 0.0752097\n",
      "\tspeed: 0.0203s/iter; left time: 245.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0797753 Vali Loss: 0.0781600 Test Loss: 0.0837251\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0798940\n",
      "\tspeed: 0.0365s/iter; left time: 438.1977s\n",
      "\titers: 200, epoch: 47 | loss: 0.0833324\n",
      "\tspeed: 0.0166s/iter; left time: 197.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0797246 Vali Loss: 0.0781052 Test Loss: 0.0836800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0797039\n",
      "\tspeed: 0.0351s/iter; left time: 412.7997s\n",
      "\titers: 200, epoch: 48 | loss: 0.0782020\n",
      "\tspeed: 0.0180s/iter; left time: 210.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0796517 Vali Loss: 0.0781125 Test Loss: 0.0837428\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0794461\n",
      "\tspeed: 0.0369s/iter; left time: 426.1332s\n",
      "\titers: 200, epoch: 49 | loss: 0.0769461\n",
      "\tspeed: 0.0176s/iter; left time: 201.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0795811 Vali Loss: 0.0780420 Test Loss: 0.0835775\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0785138\n",
      "\tspeed: 0.0362s/iter; left time: 409.7345s\n",
      "\titers: 200, epoch: 50 | loss: 0.0787498\n",
      "\tspeed: 0.0228s/iter; left time: 255.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0798084 Vali Loss: 0.0779912 Test Loss: 0.0835695\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0770917\n",
      "\tspeed: 0.0360s/iter; left time: 399.6869s\n",
      "\titers: 200, epoch: 51 | loss: 0.0809504\n",
      "\tspeed: 0.0178s/iter; left time: 195.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0797521 Vali Loss: 0.0780165 Test Loss: 0.0837333\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0788252\n",
      "\tspeed: 0.0416s/iter; left time: 453.0057s\n",
      "\titers: 200, epoch: 52 | loss: 0.0810328\n",
      "\tspeed: 0.0237s/iter; left time: 254.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0795092 Vali Loss: 0.0780881 Test Loss: 0.0835610\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0805817\n",
      "\tspeed: 0.0355s/iter; left time: 378.6025s\n",
      "\titers: 200, epoch: 53 | loss: 0.0836180\n",
      "\tspeed: 0.0197s/iter; left time: 207.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0795245 Vali Loss: 0.0779938 Test Loss: 0.0836681\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018397541716694832, rmse:0.1356375366449356, mae:0.08356448262929916, rse:0.5128601789474487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2867312\n",
      "\tspeed: 0.0232s/iter; left time: 516.4120s\n",
      "\titers: 200, epoch: 1 | loss: 0.2570210\n",
      "\tspeed: 0.0218s/iter; left time: 483.5354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.2844855 Vali Loss: 0.1995277 Test Loss: 0.2053783\n",
      "Validation loss decreased (inf --> 0.199528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503679\n",
      "\tspeed: 0.0367s/iter; left time: 809.6951s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246687\n",
      "\tspeed: 0.0219s/iter; left time: 481.8786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1605966 Vali Loss: 0.1068684 Test Loss: 0.1116115\n",
      "Validation loss decreased (0.199528 --> 0.106868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108144\n",
      "\tspeed: 0.0378s/iter; left time: 826.8868s\n",
      "\titers: 200, epoch: 3 | loss: 0.1062904\n",
      "\tspeed: 0.0182s/iter; left time: 396.7409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1122626 Vali Loss: 0.0963096 Test Loss: 0.0993764\n",
      "Validation loss decreased (0.106868 --> 0.096310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1009487\n",
      "\tspeed: 0.0381s/iter; left time: 824.6683s\n",
      "\titers: 200, epoch: 4 | loss: 0.0928750\n",
      "\tspeed: 0.0188s/iter; left time: 405.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.1004968 Vali Loss: 0.0902124 Test Loss: 0.0933175\n",
      "Validation loss decreased (0.096310 --> 0.090212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0915100\n",
      "\tspeed: 0.0367s/iter; left time: 784.9711s\n",
      "\titers: 200, epoch: 5 | loss: 0.0918914\n",
      "\tspeed: 0.0190s/iter; left time: 405.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0939580 Vali Loss: 0.0866327 Test Loss: 0.0903473\n",
      "Validation loss decreased (0.090212 --> 0.086633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0892767\n",
      "\tspeed: 0.0379s/iter; left time: 802.1199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0921808\n",
      "\tspeed: 0.0203s/iter; left time: 427.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0905779 Vali Loss: 0.0834123 Test Loss: 0.0880758\n",
      "Validation loss decreased (0.086633 --> 0.083412).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844191\n",
      "\tspeed: 0.0377s/iter; left time: 790.3454s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835324\n",
      "\tspeed: 0.0196s/iter; left time: 408.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0879606 Vali Loss: 0.0820798 Test Loss: 0.0869449\n",
      "Validation loss decreased (0.083412 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0874267\n",
      "\tspeed: 0.0390s/iter; left time: 807.7568s\n",
      "\titers: 200, epoch: 8 | loss: 0.0814885\n",
      "\tspeed: 0.0196s/iter; left time: 403.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0867589 Vali Loss: 0.0809498 Test Loss: 0.0858281\n",
      "Validation loss decreased (0.082080 --> 0.080950).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0933920\n",
      "\tspeed: 0.0385s/iter; left time: 790.1610s\n",
      "\titers: 200, epoch: 9 | loss: 0.0827512\n",
      "\tspeed: 0.0222s/iter; left time: 452.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0853610 Vali Loss: 0.0807581 Test Loss: 0.0854261\n",
      "Validation loss decreased (0.080950 --> 0.080758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817664\n",
      "\tspeed: 0.0367s/iter; left time: 743.8360s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848463\n",
      "\tspeed: 0.0178s/iter; left time: 359.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0847431 Vali Loss: 0.0806087 Test Loss: 0.0856584\n",
      "Validation loss decreased (0.080758 --> 0.080609).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0824439\n",
      "\tspeed: 0.0379s/iter; left time: 760.8934s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791895\n",
      "\tspeed: 0.0200s/iter; left time: 399.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0839303 Vali Loss: 0.0802963 Test Loss: 0.0848606\n",
      "Validation loss decreased (0.080609 --> 0.080296).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835976\n",
      "\tspeed: 0.0384s/iter; left time: 761.7840s\n",
      "\titers: 200, epoch: 12 | loss: 0.0808127\n",
      "\tspeed: 0.0197s/iter; left time: 388.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0834124 Vali Loss: 0.0795981 Test Loss: 0.0842632\n",
      "Validation loss decreased (0.080296 --> 0.079598).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0824150\n",
      "\tspeed: 0.0394s/iter; left time: 772.5143s\n",
      "\titers: 200, epoch: 13 | loss: 0.0812877\n",
      "\tspeed: 0.0180s/iter; left time: 350.3658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0829858 Vali Loss: 0.0795164 Test Loss: 0.0844229\n",
      "Validation loss decreased (0.079598 --> 0.079516).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0832805\n",
      "\tspeed: 0.0378s/iter; left time: 733.8661s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815113\n",
      "\tspeed: 0.0224s/iter; left time: 432.1096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0823462 Vali Loss: 0.0795052 Test Loss: 0.0847822\n",
      "Validation loss decreased (0.079516 --> 0.079505).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0814073\n",
      "\tspeed: 0.0397s/iter; left time: 760.3557s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834194\n",
      "\tspeed: 0.0195s/iter; left time: 372.5080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0820061 Vali Loss: 0.0791578 Test Loss: 0.0840789\n",
      "Validation loss decreased (0.079505 --> 0.079158).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823351\n",
      "\tspeed: 0.0427s/iter; left time: 809.4795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0828680\n",
      "\tspeed: 0.0217s/iter; left time: 409.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0816752 Vali Loss: 0.0791164 Test Loss: 0.0843509\n",
      "Validation loss decreased (0.079158 --> 0.079116).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0830026\n",
      "\tspeed: 0.0397s/iter; left time: 743.6971s\n",
      "\titers: 200, epoch: 17 | loss: 0.0819204\n",
      "\tspeed: 0.0201s/iter; left time: 374.6631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0815755 Vali Loss: 0.0789322 Test Loss: 0.0840984\n",
      "Validation loss decreased (0.079116 --> 0.078932).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0848534\n",
      "\tspeed: 0.0413s/iter; left time: 764.2368s\n",
      "\titers: 200, epoch: 18 | loss: 0.0779436\n",
      "\tspeed: 0.0189s/iter; left time: 348.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0814463 Vali Loss: 0.0784320 Test Loss: 0.0839459\n",
      "Validation loss decreased (0.078932 --> 0.078432).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0805601\n",
      "\tspeed: 0.0364s/iter; left time: 665.2645s\n",
      "\titers: 200, epoch: 19 | loss: 0.0789471\n",
      "\tspeed: 0.0227s/iter; left time: 412.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0809985 Vali Loss: 0.0785255 Test Loss: 0.0838930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0769660\n",
      "\tspeed: 0.0418s/iter; left time: 754.9679s\n",
      "\titers: 200, epoch: 20 | loss: 0.0833839\n",
      "\tspeed: 0.0207s/iter; left time: 372.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0809090 Vali Loss: 0.0787016 Test Loss: 0.0841642\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0833840\n",
      "\tspeed: 0.0380s/iter; left time: 676.3728s\n",
      "\titers: 200, epoch: 21 | loss: 0.0803781\n",
      "\tspeed: 0.0189s/iter; left time: 335.4680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0807736 Vali Loss: 0.0784016 Test Loss: 0.0842215\n",
      "Validation loss decreased (0.078432 --> 0.078402).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0785309\n",
      "\tspeed: 0.0390s/iter; left time: 686.1752s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797698\n",
      "\tspeed: 0.0196s/iter; left time: 343.2572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0805394 Vali Loss: 0.0780352 Test Loss: 0.0837218\n",
      "Validation loss decreased (0.078402 --> 0.078035).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0778489\n",
      "\tspeed: 0.0390s/iter; left time: 677.5954s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768977\n",
      "\tspeed: 0.0189s/iter; left time: 327.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0805633 Vali Loss: 0.0782534 Test Loss: 0.0839194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0790288\n",
      "\tspeed: 0.0362s/iter; left time: 620.6249s\n",
      "\titers: 200, epoch: 24 | loss: 0.0825477\n",
      "\tspeed: 0.0162s/iter; left time: 275.3796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0802575 Vali Loss: 0.0784502 Test Loss: 0.0844122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0778832\n",
      "\tspeed: 0.0391s/iter; left time: 662.3289s\n",
      "\titers: 200, epoch: 25 | loss: 0.0806138\n",
      "\tspeed: 0.0200s/iter; left time: 335.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0802751 Vali Loss: 0.0780333 Test Loss: 0.0839632\n",
      "Validation loss decreased (0.078035 --> 0.078033).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0834948\n",
      "\tspeed: 0.0410s/iter; left time: 684.3263s\n",
      "\titers: 200, epoch: 26 | loss: 0.0784085\n",
      "\tspeed: 0.0207s/iter; left time: 343.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0800483 Vali Loss: 0.0782701 Test Loss: 0.0841734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0825519\n",
      "\tspeed: 0.0385s/iter; left time: 635.0617s\n",
      "\titers: 200, epoch: 27 | loss: 0.0767762\n",
      "\tspeed: 0.0203s/iter; left time: 332.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0801905 Vali Loss: 0.0780979 Test Loss: 0.0839003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0778611\n",
      "\tspeed: 0.0386s/iter; left time: 626.5828s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783410\n",
      "\tspeed: 0.0185s/iter; left time: 299.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0801838 Vali Loss: 0.0780545 Test Loss: 0.0840371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0814524\n",
      "\tspeed: 0.0399s/iter; left time: 639.2591s\n",
      "\titers: 200, epoch: 29 | loss: 0.0768164\n",
      "\tspeed: 0.0207s/iter; left time: 329.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0802098 Vali Loss: 0.0779728 Test Loss: 0.0839870\n",
      "Validation loss decreased (0.078033 --> 0.077973).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789401\n",
      "\tspeed: 0.0389s/iter; left time: 615.5476s\n",
      "\titers: 200, epoch: 30 | loss: 0.0806723\n",
      "\tspeed: 0.0197s/iter; left time: 309.8175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0800947 Vali Loss: 0.0779029 Test Loss: 0.0837974\n",
      "Validation loss decreased (0.077973 --> 0.077903).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807305\n",
      "\tspeed: 0.0407s/iter; left time: 633.6627s\n",
      "\titers: 200, epoch: 31 | loss: 0.0782476\n",
      "\tspeed: 0.0155s/iter; left time: 239.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0798499 Vali Loss: 0.0779676 Test Loss: 0.0839404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0785601\n",
      "\tspeed: 0.0362s/iter; left time: 556.6908s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811478\n",
      "\tspeed: 0.0164s/iter; left time: 249.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0796981 Vali Loss: 0.0780462 Test Loss: 0.0840805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0804480\n",
      "\tspeed: 0.0376s/iter; left time: 568.3690s\n",
      "\titers: 200, epoch: 33 | loss: 0.0752403\n",
      "\tspeed: 0.0202s/iter; left time: 303.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0798107 Vali Loss: 0.0781049 Test Loss: 0.0839160\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0790258\n",
      "\tspeed: 0.0410s/iter; left time: 611.2793s\n",
      "\titers: 200, epoch: 34 | loss: 0.0790331\n",
      "\tspeed: 0.0199s/iter; left time: 295.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0797612 Vali Loss: 0.0779342 Test Loss: 0.0839198\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0816821\n",
      "\tspeed: 0.0388s/iter; left time: 570.4610s\n",
      "\titers: 200, epoch: 35 | loss: 0.0776742\n",
      "\tspeed: 0.0184s/iter; left time: 268.8913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0796725 Vali Loss: 0.0779767 Test Loss: 0.0840265\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0808088\n",
      "\tspeed: 0.0363s/iter; left time: 525.3112s\n",
      "\titers: 200, epoch: 36 | loss: 0.0797651\n",
      "\tspeed: 0.0173s/iter; left time: 249.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0794678 Vali Loss: 0.0777583 Test Loss: 0.0838494\n",
      "Validation loss decreased (0.077903 --> 0.077758).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0819605\n",
      "\tspeed: 0.0402s/iter; left time: 571.7281s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833865\n",
      "\tspeed: 0.0171s/iter; left time: 241.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0797223 Vali Loss: 0.0779314 Test Loss: 0.0838622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0792774\n",
      "\tspeed: 0.0401s/iter; left time: 562.4308s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777663\n",
      "\tspeed: 0.0191s/iter; left time: 265.2201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0795968 Vali Loss: 0.0777408 Test Loss: 0.0837811\n",
      "Validation loss decreased (0.077758 --> 0.077741).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765365\n",
      "\tspeed: 0.0361s/iter; left time: 497.6471s\n",
      "\titers: 200, epoch: 39 | loss: 0.0834238\n",
      "\tspeed: 0.0158s/iter; left time: 216.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0796541 Vali Loss: 0.0779488 Test Loss: 0.0839596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0825785\n",
      "\tspeed: 0.0371s/iter; left time: 503.2770s\n",
      "\titers: 200, epoch: 40 | loss: 0.0816366\n",
      "\tspeed: 0.0198s/iter; left time: 267.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0795348 Vali Loss: 0.0778374 Test Loss: 0.0840134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0794839\n",
      "\tspeed: 0.0367s/iter; left time: 489.2668s\n",
      "\titers: 200, epoch: 41 | loss: 0.0791382\n",
      "\tspeed: 0.0187s/iter; left time: 247.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0793831 Vali Loss: 0.0779585 Test Loss: 0.0839527\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0772628\n",
      "\tspeed: 0.0384s/iter; left time: 503.9061s\n",
      "\titers: 200, epoch: 42 | loss: 0.0762821\n",
      "\tspeed: 0.0191s/iter; left time: 248.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0794449 Vali Loss: 0.0779490 Test Loss: 0.0840200\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0802017\n",
      "\tspeed: 0.0345s/iter; left time: 444.9848s\n",
      "\titers: 200, epoch: 43 | loss: 0.0798228\n",
      "\tspeed: 0.0152s/iter; left time: 194.9517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0795483 Vali Loss: 0.0778165 Test Loss: 0.0839348\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0792961\n",
      "\tspeed: 0.0341s/iter; left time: 431.8193s\n",
      "\titers: 200, epoch: 44 | loss: 0.0813237\n",
      "\tspeed: 0.0155s/iter; left time: 194.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0794504 Vali Loss: 0.0777908 Test Loss: 0.0839736\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0743389\n",
      "\tspeed: 0.0369s/iter; left time: 458.7803s\n",
      "\titers: 200, epoch: 45 | loss: 0.0790860\n",
      "\tspeed: 0.0172s/iter; left time: 211.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0795811 Vali Loss: 0.0776809 Test Loss: 0.0839838\n",
      "Validation loss decreased (0.077741 --> 0.077681).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0809471\n",
      "\tspeed: 0.0402s/iter; left time: 490.8349s\n",
      "\titers: 200, epoch: 46 | loss: 0.0831727\n",
      "\tspeed: 0.0200s/iter; left time: 241.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0794175 Vali Loss: 0.0778423 Test Loss: 0.0839245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0821231\n",
      "\tspeed: 0.0401s/iter; left time: 480.9708s\n",
      "\titers: 200, epoch: 47 | loss: 0.0828227\n",
      "\tspeed: 0.0200s/iter; left time: 238.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0794707 Vali Loss: 0.0778999 Test Loss: 0.0840461\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0751237\n",
      "\tspeed: 0.0376s/iter; left time: 442.9402s\n",
      "\titers: 200, epoch: 48 | loss: 0.0766488\n",
      "\tspeed: 0.0184s/iter; left time: 214.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0794241 Vali Loss: 0.0778052 Test Loss: 0.0839567\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0748905\n",
      "\tspeed: 0.0394s/iter; left time: 454.5001s\n",
      "\titers: 200, epoch: 49 | loss: 0.0808240\n",
      "\tspeed: 0.0164s/iter; left time: 188.0700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0794316 Vali Loss: 0.0777261 Test Loss: 0.0839457\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0789147\n",
      "\tspeed: 0.0352s/iter; left time: 398.8161s\n",
      "\titers: 200, epoch: 50 | loss: 0.0775464\n",
      "\tspeed: 0.0162s/iter; left time: 182.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0794408 Vali Loss: 0.0778124 Test Loss: 0.0839672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0750288\n",
      "\tspeed: 0.0363s/iter; left time: 403.0799s\n",
      "\titers: 200, epoch: 51 | loss: 0.0759603\n",
      "\tspeed: 0.0176s/iter; left time: 194.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0793937 Vali Loss: 0.0778719 Test Loss: 0.0840028\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0808131\n",
      "\tspeed: 0.0360s/iter; left time: 391.8367s\n",
      "\titers: 200, epoch: 52 | loss: 0.0777459\n",
      "\tspeed: 0.0192s/iter; left time: 206.7179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0794048 Vali Loss: 0.0778212 Test Loss: 0.0839871\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0793615\n",
      "\tspeed: 0.0303s/iter; left time: 322.3504s\n",
      "\titers: 200, epoch: 53 | loss: 0.0792381\n",
      "\tspeed: 0.0102s/iter; left time: 107.9776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0796601 Vali Loss: 0.0778423 Test Loss: 0.0840481\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0764310\n",
      "\tspeed: 0.0339s/iter; left time: 353.6181s\n",
      "\titers: 200, epoch: 54 | loss: 0.0797180\n",
      "\tspeed: 0.0179s/iter; left time: 184.6034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0794165 Vali Loss: 0.0780442 Test Loss: 0.0840546\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0832862\n",
      "\tspeed: 0.0381s/iter; left time: 388.8589s\n",
      "\titers: 200, epoch: 55 | loss: 0.0806227\n",
      "\tspeed: 0.0178s/iter; left time: 179.6638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0794011 Vali Loss: 0.0777452 Test Loss: 0.0840179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678180873394012, rmse:0.1366681456565857, mae:0.08398380130529404, rse:0.5167570114135742\n",
      "Intermediate time for IT and pred_len 96: 00h:10m:28.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0387s/iter; left time: 860.0369s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0153s/iter; left time: 337.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0321s/iter; left time: 705.4843s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0171s/iter; left time: 373.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0354s/iter; left time: 770.1293s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0156s/iter; left time: 337.1486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0351s/iter; left time: 756.3412s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0165s/iter; left time: 354.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0336s/iter; left time: 715.4244s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0157s/iter; left time: 333.6111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0352s/iter; left time: 741.4228s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0214s/iter; left time: 449.5136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0347s/iter; left time: 724.9670s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0175s/iter; left time: 363.3260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0360s/iter; left time: 744.0292s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0176s/iter; left time: 362.1051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0338s/iter; left time: 689.1327s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0174s/iter; left time: 354.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0381s/iter; left time: 768.5262s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0198s/iter; left time: 398.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0355s/iter; left time: 708.6465s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0179s/iter; left time: 354.9227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0377s/iter; left time: 743.7910s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0202s/iter; left time: 396.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0354s/iter; left time: 691.2475s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0178s/iter; left time: 345.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0350s/iter; left time: 674.9448s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0183s/iter; left time: 351.1359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0368s/iter; left time: 701.5895s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0187s/iter; left time: 354.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0347s/iter; left time: 654.7602s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0165s/iter; left time: 309.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0369s/iter; left time: 687.5591s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0187s/iter; left time: 346.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0352s/iter; left time: 648.5963s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0184s/iter; left time: 337.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0319s/iter; left time: 580.0092s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0108s/iter; left time: 195.7815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0336s/iter; left time: 603.0313s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0181s/iter; left time: 324.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0872286\n",
      "\tspeed: 0.0409s/iter; left time: 724.9928s\n",
      "\titers: 200, epoch: 21 | loss: 0.0831704\n",
      "\tspeed: 0.0161s/iter; left time: 284.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0844322 Vali Loss: 0.0829054 Test Loss: 0.0884945\n",
      "Validation loss decreased (0.082979 --> 0.082905).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0867223\n",
      "\tspeed: 0.0328s/iter; left time: 574.0130s\n",
      "\titers: 200, epoch: 22 | loss: 0.0876466\n",
      "\tspeed: 0.0167s/iter; left time: 290.2002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0842149 Vali Loss: 0.0827185 Test Loss: 0.0886369\n",
      "Validation loss decreased (0.082905 --> 0.082718).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0849737\n",
      "\tspeed: 0.0340s/iter; left time: 588.0963s\n",
      "\titers: 200, epoch: 23 | loss: 0.0807684\n",
      "\tspeed: 0.0184s/iter; left time: 315.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0843792 Vali Loss: 0.0829772 Test Loss: 0.0889734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0820991\n",
      "\tspeed: 0.0334s/iter; left time: 570.7538s\n",
      "\titers: 200, epoch: 24 | loss: 0.0875308\n",
      "\tspeed: 0.0171s/iter; left time: 290.1032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0840422 Vali Loss: 0.0827549 Test Loss: 0.0886977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0830779\n",
      "\tspeed: 0.0333s/iter; left time: 561.4869s\n",
      "\titers: 200, epoch: 25 | loss: 0.0835033\n",
      "\tspeed: 0.0172s/iter; left time: 288.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0839247 Vali Loss: 0.0831602 Test Loss: 0.0891277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0838137\n",
      "\tspeed: 0.0327s/iter; left time: 543.2947s\n",
      "\titers: 200, epoch: 26 | loss: 0.0828986\n",
      "\tspeed: 0.0168s/iter; left time: 277.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0838142 Vali Loss: 0.0831872 Test Loss: 0.0890525\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0886685\n",
      "\tspeed: 0.0334s/iter; left time: 547.5839s\n",
      "\titers: 200, epoch: 27 | loss: 0.0831004\n",
      "\tspeed: 0.0164s/iter; left time: 267.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0837475 Vali Loss: 0.0827102 Test Loss: 0.0889502\n",
      "Validation loss decreased (0.082718 --> 0.082710).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0842732\n",
      "\tspeed: 0.0336s/iter; left time: 543.2986s\n",
      "\titers: 200, epoch: 28 | loss: 0.0843552\n",
      "\tspeed: 0.0154s/iter; left time: 247.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0835873 Vali Loss: 0.0828040 Test Loss: 0.0888971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0808670\n",
      "\tspeed: 0.0335s/iter; left time: 534.9079s\n",
      "\titers: 200, epoch: 29 | loss: 0.0816149\n",
      "\tspeed: 0.0167s/iter; left time: 264.1920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0837281 Vali Loss: 0.0828219 Test Loss: 0.0887696\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0834296\n",
      "\tspeed: 0.0337s/iter; left time: 530.6304s\n",
      "\titers: 200, epoch: 30 | loss: 0.0883300\n",
      "\tspeed: 0.0156s/iter; left time: 243.7387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0837617 Vali Loss: 0.0831965 Test Loss: 0.0890788\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0833962\n",
      "\tspeed: 0.0328s/iter; left time: 509.1602s\n",
      "\titers: 200, epoch: 31 | loss: 0.0828488\n",
      "\tspeed: 0.0167s/iter; left time: 257.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0835490 Vali Loss: 0.0828670 Test Loss: 0.0891433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0821873\n",
      "\tspeed: 0.0348s/iter; left time: 531.7460s\n",
      "\titers: 200, epoch: 32 | loss: 0.0837600\n",
      "\tspeed: 0.0171s/iter; left time: 259.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0834862 Vali Loss: 0.0826908 Test Loss: 0.0889840\n",
      "Validation loss decreased (0.082710 --> 0.082691).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0862068\n",
      "\tspeed: 0.0347s/iter; left time: 522.7459s\n",
      "\titers: 200, epoch: 33 | loss: 0.0837822\n",
      "\tspeed: 0.0184s/iter; left time: 275.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0837413 Vali Loss: 0.0832900 Test Loss: 0.0891910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0799349\n",
      "\tspeed: 0.0367s/iter; left time: 544.7403s\n",
      "\titers: 200, epoch: 34 | loss: 0.0856708\n",
      "\tspeed: 0.0169s/iter; left time: 248.4535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0834411 Vali Loss: 0.0829075 Test Loss: 0.0890537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0834171\n",
      "\tspeed: 0.0349s/iter; left time: 510.6638s\n",
      "\titers: 200, epoch: 35 | loss: 0.0852624\n",
      "\tspeed: 0.0157s/iter; left time: 227.2281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0835157 Vali Loss: 0.0826568 Test Loss: 0.0888614\n",
      "Validation loss decreased (0.082691 --> 0.082657).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0848151\n",
      "\tspeed: 0.0369s/iter; left time: 531.6443s\n",
      "\titers: 200, epoch: 36 | loss: 0.0836477\n",
      "\tspeed: 0.0188s/iter; left time: 268.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0834534 Vali Loss: 0.0828287 Test Loss: 0.0890043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0874976\n",
      "\tspeed: 0.0356s/iter; left time: 505.0859s\n",
      "\titers: 200, epoch: 37 | loss: 0.0843695\n",
      "\tspeed: 0.0185s/iter; left time: 260.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0833446 Vali Loss: 0.0827532 Test Loss: 0.0886072\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0841727\n",
      "\tspeed: 0.0370s/iter; left time: 516.3419s\n",
      "\titers: 200, epoch: 38 | loss: 0.0829164\n",
      "\tspeed: 0.0194s/iter; left time: 268.2223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0832881 Vali Loss: 0.0826775 Test Loss: 0.0891268\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0832476\n",
      "\tspeed: 0.0350s/iter; left time: 479.8633s\n",
      "\titers: 200, epoch: 39 | loss: 0.0828707\n",
      "\tspeed: 0.0109s/iter; left time: 148.8087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 223 | Train Loss: 0.0832982 Vali Loss: 0.0825662 Test Loss: 0.0888992\n",
      "Validation loss decreased (0.082657 --> 0.082566).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824681\n",
      "\tspeed: 0.0357s/iter; left time: 482.2865s\n",
      "\titers: 200, epoch: 40 | loss: 0.0842423\n",
      "\tspeed: 0.0188s/iter; left time: 252.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0833420 Vali Loss: 0.0828394 Test Loss: 0.0891806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0862637\n",
      "\tspeed: 0.0352s/iter; left time: 467.0571s\n",
      "\titers: 200, epoch: 41 | loss: 0.0811936\n",
      "\tspeed: 0.0169s/iter; left time: 222.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0832356 Vali Loss: 0.0828865 Test Loss: 0.0889896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0822184\n",
      "\tspeed: 0.0350s/iter; left time: 457.0692s\n",
      "\titers: 200, epoch: 42 | loss: 0.0822396\n",
      "\tspeed: 0.0160s/iter; left time: 207.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0832139 Vali Loss: 0.0827310 Test Loss: 0.0889593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0891320\n",
      "\tspeed: 0.0350s/iter; left time: 449.1892s\n",
      "\titers: 200, epoch: 43 | loss: 0.0880181\n",
      "\tspeed: 0.0182s/iter; left time: 231.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0831549 Vali Loss: 0.0825689 Test Loss: 0.0887844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0825391\n",
      "\tspeed: 0.0342s/iter; left time: 431.3189s\n",
      "\titers: 200, epoch: 44 | loss: 0.0846757\n",
      "\tspeed: 0.0153s/iter; left time: 191.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0833335 Vali Loss: 0.0827998 Test Loss: 0.0888575\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0863253\n",
      "\tspeed: 0.0362s/iter; left time: 447.8842s\n",
      "\titers: 200, epoch: 45 | loss: 0.0848708\n",
      "\tspeed: 0.0187s/iter; left time: 229.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0831190 Vali Loss: 0.0826926 Test Loss: 0.0888961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0859408\n",
      "\tspeed: 0.0361s/iter; left time: 438.7621s\n",
      "\titers: 200, epoch: 46 | loss: 0.0854433\n",
      "\tspeed: 0.0174s/iter; left time: 209.5152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0831968 Vali Loss: 0.0827597 Test Loss: 0.0888974\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0827757\n",
      "\tspeed: 0.0354s/iter; left time: 422.8736s\n",
      "\titers: 200, epoch: 47 | loss: 0.0812759\n",
      "\tspeed: 0.0179s/iter; left time: 212.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0833034 Vali Loss: 0.0827946 Test Loss: 0.0890244\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0819633\n",
      "\tspeed: 0.0329s/iter; left time: 385.3488s\n",
      "\titers: 200, epoch: 48 | loss: 0.0808631\n",
      "\tspeed: 0.0179s/iter; left time: 207.9168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0831767 Vali Loss: 0.0826941 Test Loss: 0.0888983\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0814836\n",
      "\tspeed: 0.0327s/iter; left time: 375.8652s\n",
      "\titers: 200, epoch: 49 | loss: 0.0853858\n",
      "\tspeed: 0.0182s/iter; left time: 207.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0831401 Vali Loss: 0.0826110 Test Loss: 0.0886734\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020383721217513084, rmse:0.14277157187461853, mae:0.08889921009540558, rse:0.5403363704681396\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2783174\n",
      "\tspeed: 0.0206s/iter; left time: 458.1211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2561924\n",
      "\tspeed: 0.0165s/iter; left time: 364.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.2809654 Vali Loss: 0.1980512 Test Loss: 0.2045336\n",
      "Validation loss decreased (inf --> 0.198051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1434797\n",
      "\tspeed: 0.0348s/iter; left time: 763.7576s\n",
      "\titers: 200, epoch: 2 | loss: 0.1269314\n",
      "\tspeed: 0.0180s/iter; left time: 394.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1565996 Vali Loss: 0.1076144 Test Loss: 0.1134702\n",
      "Validation loss decreased (0.198051 --> 0.107614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089100\n",
      "\tspeed: 0.0382s/iter; left time: 830.4564s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123186\n",
      "\tspeed: 0.0185s/iter; left time: 400.7321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.1130273 Vali Loss: 0.0991176 Test Loss: 0.1023243\n",
      "Validation loss decreased (0.107614 --> 0.099118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1033121\n",
      "\tspeed: 0.0381s/iter; left time: 819.4229s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008542\n",
      "\tspeed: 0.0191s/iter; left time: 410.3949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1024947 Vali Loss: 0.0934884 Test Loss: 0.0957750\n",
      "Validation loss decreased (0.099118 --> 0.093488).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0962598\n",
      "\tspeed: 0.0369s/iter; left time: 785.4057s\n",
      "\titers: 200, epoch: 5 | loss: 0.0895119\n",
      "\tspeed: 0.0188s/iter; left time: 399.4257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0966106 Vali Loss: 0.0892825 Test Loss: 0.0922814\n",
      "Validation loss decreased (0.093488 --> 0.089283).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0915172\n",
      "\tspeed: 0.0361s/iter; left time: 760.4935s\n",
      "\titers: 200, epoch: 6 | loss: 0.0938353\n",
      "\tspeed: 0.0190s/iter; left time: 398.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0934706 Vali Loss: 0.0887328 Test Loss: 0.0932004\n",
      "Validation loss decreased (0.089283 --> 0.088733).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0929474\n",
      "\tspeed: 0.0367s/iter; left time: 764.6646s\n",
      "\titers: 200, epoch: 7 | loss: 0.0888825\n",
      "\tspeed: 0.0158s/iter; left time: 328.9838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0911639 Vali Loss: 0.0854874 Test Loss: 0.0899703\n",
      "Validation loss decreased (0.088733 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0920395\n",
      "\tspeed: 0.0346s/iter; left time: 713.4796s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905043\n",
      "\tspeed: 0.0164s/iter; left time: 336.5075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0895095 Vali Loss: 0.0845426 Test Loss: 0.0890754\n",
      "Validation loss decreased (0.085487 --> 0.084543).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0904310\n",
      "\tspeed: 0.0361s/iter; left time: 737.0105s\n",
      "\titers: 200, epoch: 9 | loss: 0.0930630\n",
      "\tspeed: 0.0188s/iter; left time: 381.2153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0884846 Vali Loss: 0.0844463 Test Loss: 0.0889952\n",
      "Validation loss decreased (0.084543 --> 0.084446).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0904131\n",
      "\tspeed: 0.0375s/iter; left time: 757.3688s\n",
      "\titers: 200, epoch: 10 | loss: 0.0884226\n",
      "\tspeed: 0.0180s/iter; left time: 362.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0876480 Vali Loss: 0.0838550 Test Loss: 0.0882083\n",
      "Validation loss decreased (0.084446 --> 0.083855).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0856049\n",
      "\tspeed: 0.0381s/iter; left time: 760.2589s\n",
      "\titers: 200, epoch: 11 | loss: 0.0874932\n",
      "\tspeed: 0.0175s/iter; left time: 348.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0871118 Vali Loss: 0.0848591 Test Loss: 0.0893165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0897286\n",
      "\tspeed: 0.0346s/iter; left time: 682.9436s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851763\n",
      "\tspeed: 0.0185s/iter; left time: 362.8002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0866424 Vali Loss: 0.0835382 Test Loss: 0.0883652\n",
      "Validation loss decreased (0.083855 --> 0.083538).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0867814\n",
      "\tspeed: 0.0350s/iter; left time: 683.1414s\n",
      "\titers: 200, epoch: 13 | loss: 0.0884583\n",
      "\tspeed: 0.0191s/iter; left time: 370.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0861231 Vali Loss: 0.0830504 Test Loss: 0.0883958\n",
      "Validation loss decreased (0.083538 --> 0.083050).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0836019\n",
      "\tspeed: 0.0378s/iter; left time: 730.0331s\n",
      "\titers: 200, epoch: 14 | loss: 0.0828435\n",
      "\tspeed: 0.0192s/iter; left time: 367.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0855190 Vali Loss: 0.0833236 Test Loss: 0.0886185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0838300\n",
      "\tspeed: 0.0334s/iter; left time: 636.7458s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792961\n",
      "\tspeed: 0.0186s/iter; left time: 353.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0854537 Vali Loss: 0.0836695 Test Loss: 0.0885660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0842091\n",
      "\tspeed: 0.0352s/iter; left time: 663.8804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0849975\n",
      "\tspeed: 0.0160s/iter; left time: 299.8568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0849980 Vali Loss: 0.0830298 Test Loss: 0.0883334\n",
      "Validation loss decreased (0.083050 --> 0.083030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0841620\n",
      "\tspeed: 0.0356s/iter; left time: 663.2951s\n",
      "\titers: 200, epoch: 17 | loss: 0.0822852\n",
      "\tspeed: 0.0206s/iter; left time: 381.3465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0848464 Vali Loss: 0.0830064 Test Loss: 0.0890276\n",
      "Validation loss decreased (0.083030 --> 0.083006).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0883274\n",
      "\tspeed: 0.0388s/iter; left time: 715.1719s\n",
      "\titers: 200, epoch: 18 | loss: 0.0860604\n",
      "\tspeed: 0.0191s/iter; left time: 349.5502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0845813 Vali Loss: 0.0828156 Test Loss: 0.0883796\n",
      "Validation loss decreased (0.083006 --> 0.082816).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0873203\n",
      "\tspeed: 0.0389s/iter; left time: 707.3403s\n",
      "\titers: 200, epoch: 19 | loss: 0.0868140\n",
      "\tspeed: 0.0176s/iter; left time: 317.7973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0846028 Vali Loss: 0.0832311 Test Loss: 0.0883496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0840057\n",
      "\tspeed: 0.0347s/iter; left time: 622.5857s\n",
      "\titers: 200, epoch: 20 | loss: 0.0849428\n",
      "\tspeed: 0.0171s/iter; left time: 305.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0843181 Vali Loss: 0.0831828 Test Loss: 0.0887545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0851120\n",
      "\tspeed: 0.0355s/iter; left time: 629.0861s\n",
      "\titers: 200, epoch: 21 | loss: 0.0872402\n",
      "\tspeed: 0.0158s/iter; left time: 278.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0840459 Vali Loss: 0.0823513 Test Loss: 0.0880426\n",
      "Validation loss decreased (0.082816 --> 0.082351).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0816963\n",
      "\tspeed: 0.0340s/iter; left time: 595.4828s\n",
      "\titers: 200, epoch: 22 | loss: 0.0857470\n",
      "\tspeed: 0.0157s/iter; left time: 272.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0839276 Vali Loss: 0.0829745 Test Loss: 0.0887041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0824122\n",
      "\tspeed: 0.0372s/iter; left time: 643.2194s\n",
      "\titers: 200, epoch: 23 | loss: 0.0832235\n",
      "\tspeed: 0.0202s/iter; left time: 347.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0837476 Vali Loss: 0.0830357 Test Loss: 0.0885183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0851167\n",
      "\tspeed: 0.0371s/iter; left time: 633.2868s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829545\n",
      "\tspeed: 0.0178s/iter; left time: 302.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0841662 Vali Loss: 0.0828512 Test Loss: 0.0883809\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0812404\n",
      "\tspeed: 0.0378s/iter; left time: 636.5021s\n",
      "\titers: 200, epoch: 25 | loss: 0.0869651\n",
      "\tspeed: 0.0188s/iter; left time: 314.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0835585 Vali Loss: 0.0829310 Test Loss: 0.0885424\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0795238\n",
      "\tspeed: 0.0358s/iter; left time: 595.7320s\n",
      "\titers: 200, epoch: 26 | loss: 0.0831725\n",
      "\tspeed: 0.0181s/iter; left time: 298.3546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0834923 Vali Loss: 0.0825120 Test Loss: 0.0883233\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789952\n",
      "\tspeed: 0.0331s/iter; left time: 543.3127s\n",
      "\titers: 200, epoch: 27 | loss: 0.0814784\n",
      "\tspeed: 0.0152s/iter; left time: 246.9942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0834275 Vali Loss: 0.0827407 Test Loss: 0.0885099\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819797\n",
      "\tspeed: 0.0350s/iter; left time: 565.9647s\n",
      "\titers: 200, epoch: 28 | loss: 0.0810981\n",
      "\tspeed: 0.0172s/iter; left time: 276.8829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0833911 Vali Loss: 0.0823007 Test Loss: 0.0884802\n",
      "Validation loss decreased (0.082351 --> 0.082301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796609\n",
      "\tspeed: 0.0353s/iter; left time: 562.8821s\n",
      "\titers: 200, epoch: 29 | loss: 0.0869515\n",
      "\tspeed: 0.0161s/iter; left time: 255.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0832785 Vali Loss: 0.0829458 Test Loss: 0.0884927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0782483\n",
      "\tspeed: 0.0359s/iter; left time: 564.5757s\n",
      "\titers: 200, epoch: 30 | loss: 0.0846682\n",
      "\tspeed: 0.0195s/iter; left time: 304.1448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0832658 Vali Loss: 0.0824568 Test Loss: 0.0882537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0836183\n",
      "\tspeed: 0.0362s/iter; left time: 561.5799s\n",
      "\titers: 200, epoch: 31 | loss: 0.0839608\n",
      "\tspeed: 0.0165s/iter; left time: 254.9385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0831332 Vali Loss: 0.0825714 Test Loss: 0.0884771\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0875373\n",
      "\tspeed: 0.0346s/iter; left time: 528.6634s\n",
      "\titers: 200, epoch: 32 | loss: 0.0825453\n",
      "\tspeed: 0.0167s/iter; left time: 254.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0832398 Vali Loss: 0.0825711 Test Loss: 0.0883840\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0852051\n",
      "\tspeed: 0.0332s/iter; left time: 500.1138s\n",
      "\titers: 200, epoch: 33 | loss: 0.0831327\n",
      "\tspeed: 0.0166s/iter; left time: 248.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0831097 Vali Loss: 0.0824194 Test Loss: 0.0884880\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0785666\n",
      "\tspeed: 0.0348s/iter; left time: 516.9032s\n",
      "\titers: 200, epoch: 34 | loss: 0.0842522\n",
      "\tspeed: 0.0159s/iter; left time: 234.2619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0829975 Vali Loss: 0.0823412 Test Loss: 0.0881475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825979\n",
      "\tspeed: 0.0335s/iter; left time: 489.8410s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819061\n",
      "\tspeed: 0.0161s/iter; left time: 233.2826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0831025 Vali Loss: 0.0829548 Test Loss: 0.0885586\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0854784\n",
      "\tspeed: 0.0348s/iter; left time: 501.0269s\n",
      "\titers: 200, epoch: 36 | loss: 0.0833845\n",
      "\tspeed: 0.0198s/iter; left time: 282.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0832238 Vali Loss: 0.0823038 Test Loss: 0.0883680\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0848935\n",
      "\tspeed: 0.0364s/iter; left time: 516.2651s\n",
      "\titers: 200, epoch: 37 | loss: 0.0834535\n",
      "\tspeed: 0.0161s/iter; left time: 226.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0830064 Vali Loss: 0.0823186 Test Loss: 0.0882934\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0849575\n",
      "\tspeed: 0.0411s/iter; left time: 573.5509s\n",
      "\titers: 200, epoch: 38 | loss: 0.0846332\n",
      "\tspeed: 0.0214s/iter; left time: 296.5201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0830837 Vali Loss: 0.0825377 Test Loss: 0.0883402\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020050713792443275, rmse:0.14160054922103882, mae:0.08848021179437637, rse:0.5359044671058655\n",
      "Intermediate time for IT and pred_len 168: 00h:07m:51.62s\n",
      "Intermediate time for IT: 00h:26m:45.05s\n",
      "Total time: 02h:06m:33.65s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2062</td>\n",
       "      <td>0.1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>0.1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.0608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0218  0.1478  0.0920\n",
       "        96        0.0425  0.2062  0.1346\n",
       "        168       0.0434  0.2084  0.1395\n",
       "ES      24        0.0146  0.1207  0.0761\n",
       "        96        0.0296  0.1714  0.1111\n",
       "        168       0.0322  0.1793  0.1184\n",
       "FR      24        0.0110  0.1049  0.0608\n",
       "        96        0.0210  0.1451  0.0846\n",
       "        168       0.0233  0.1528  0.0903\n",
       "GB      24        0.0267  0.1635  0.1056\n",
       "        96        0.0514  0.2267  0.1514\n",
       "        168       0.0543  0.2330  0.1576\n",
       "IT      24        0.0108  0.1041  0.0618\n",
       "        96        0.0185  0.1362  0.0838\n",
       "        168       0.0202  0.1422  0.0887"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1554952\n",
      "\tspeed: 0.0380s/iter; left time: 848.4347s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357202\n",
      "\tspeed: 0.0150s/iter; left time: 333.1600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.1541195 Vali Loss: 0.1402045 Test Loss: 0.1497520\n",
      "Validation loss decreased (inf --> 0.140205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869676\n",
      "\tspeed: 0.0348s/iter; left time: 767.2834s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847717\n",
      "\tspeed: 0.0150s/iter; left time: 329.7199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0921203 Vali Loss: 0.0949045 Test Loss: 0.0956562\n",
      "Validation loss decreased (0.140205 --> 0.094904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0774624\n",
      "\tspeed: 0.0347s/iter; left time: 757.4015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822205\n",
      "\tspeed: 0.0151s/iter; left time: 328.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0812834 Vali Loss: 0.0916223 Test Loss: 0.0926683\n",
      "Validation loss decreased (0.094904 --> 0.091622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0761068\n",
      "\tspeed: 0.0352s/iter; left time: 760.9509s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788112\n",
      "\tspeed: 0.0168s/iter; left time: 360.9400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0784736 Vali Loss: 0.0895640 Test Loss: 0.0912961\n",
      "Validation loss decreased (0.091622 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777103\n",
      "\tspeed: 0.0339s/iter; left time: 725.8892s\n",
      "\titers: 200, epoch: 5 | loss: 0.0786942\n",
      "\tspeed: 0.0150s/iter; left time: 319.4224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0769159 Vali Loss: 0.0888526 Test Loss: 0.0907485\n",
      "Validation loss decreased (0.089564 --> 0.088853).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802427\n",
      "\tspeed: 0.0363s/iter; left time: 768.5250s\n",
      "\titers: 200, epoch: 6 | loss: 0.0740417\n",
      "\tspeed: 0.0172s/iter; left time: 361.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0758447 Vali Loss: 0.0882284 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.088853 --> 0.088228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748348\n",
      "\tspeed: 0.0343s/iter; left time: 718.2850s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769684\n",
      "\tspeed: 0.0151s/iter; left time: 314.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0751689 Vali Loss: 0.0878075 Test Loss: 0.0892610\n",
      "Validation loss decreased (0.088228 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0768212\n",
      "\tspeed: 0.0356s/iter; left time: 737.9250s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734301\n",
      "\tspeed: 0.0168s/iter; left time: 345.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0745465 Vali Loss: 0.0876324 Test Loss: 0.0891513\n",
      "Validation loss decreased (0.087807 --> 0.087632).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738977\n",
      "\tspeed: 0.0368s/iter; left time: 753.9768s\n",
      "\titers: 200, epoch: 9 | loss: 0.0720558\n",
      "\tspeed: 0.0152s/iter; left time: 309.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0740447 Vali Loss: 0.0870932 Test Loss: 0.0891499\n",
      "Validation loss decreased (0.087632 --> 0.087093).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726922\n",
      "\tspeed: 0.0380s/iter; left time: 771.5329s\n",
      "\titers: 200, epoch: 10 | loss: 0.0745696\n",
      "\tspeed: 0.0159s/iter; left time: 320.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0736376 Vali Loss: 0.0868243 Test Loss: 0.0889371\n",
      "Validation loss decreased (0.087093 --> 0.086824).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685705\n",
      "\tspeed: 0.0357s/iter; left time: 716.4272s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697067\n",
      "\tspeed: 0.0150s/iter; left time: 300.0700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0733032 Vali Loss: 0.0868257 Test Loss: 0.0887700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0702654\n",
      "\tspeed: 0.0334s/iter; left time: 662.6455s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722485\n",
      "\tspeed: 0.0150s/iter; left time: 296.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0729990 Vali Loss: 0.0867122 Test Loss: 0.0885437\n",
      "Validation loss decreased (0.086824 --> 0.086712).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722399\n",
      "\tspeed: 0.0349s/iter; left time: 684.9321s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783269\n",
      "\tspeed: 0.0159s/iter; left time: 309.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0727403 Vali Loss: 0.0864957 Test Loss: 0.0886285\n",
      "Validation loss decreased (0.086712 --> 0.086496).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0701331\n",
      "\tspeed: 0.0340s/iter; left time: 658.2688s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752917\n",
      "\tspeed: 0.0150s/iter; left time: 290.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0725547 Vali Loss: 0.0861861 Test Loss: 0.0884400\n",
      "Validation loss decreased (0.086496 --> 0.086186).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738760\n",
      "\tspeed: 0.0336s/iter; left time: 644.6244s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728909\n",
      "\tspeed: 0.0166s/iter; left time: 316.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0723449 Vali Loss: 0.0862782 Test Loss: 0.0885036\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734793\n",
      "\tspeed: 0.0388s/iter; left time: 735.4882s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676081\n",
      "\tspeed: 0.0182s/iter; left time: 343.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0721527 Vali Loss: 0.0864140 Test Loss: 0.0884588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0718961\n",
      "\tspeed: 0.0385s/iter; left time: 720.2076s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705533\n",
      "\tspeed: 0.0169s/iter; left time: 315.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0720608 Vali Loss: 0.0860744 Test Loss: 0.0882078\n",
      "Validation loss decreased (0.086186 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0697139\n",
      "\tspeed: 0.0342s/iter; left time: 633.3511s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702659\n",
      "\tspeed: 0.0150s/iter; left time: 275.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0719050 Vali Loss: 0.0860787 Test Loss: 0.0882772\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0671234\n",
      "\tspeed: 0.0362s/iter; left time: 661.4288s\n",
      "\titers: 200, epoch: 19 | loss: 0.0692945\n",
      "\tspeed: 0.0182s/iter; left time: 329.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0717753 Vali Loss: 0.0862968 Test Loss: 0.0883190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733683\n",
      "\tspeed: 0.0348s/iter; left time: 627.5437s\n",
      "\titers: 200, epoch: 20 | loss: 0.0683619\n",
      "\tspeed: 0.0159s/iter; left time: 284.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0716777 Vali Loss: 0.0859621 Test Loss: 0.0881678\n",
      "Validation loss decreased (0.086074 --> 0.085962).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684209\n",
      "\tspeed: 0.0343s/iter; left time: 611.2440s\n",
      "\titers: 200, epoch: 21 | loss: 0.0697097\n",
      "\tspeed: 0.0150s/iter; left time: 266.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0715680 Vali Loss: 0.0861959 Test Loss: 0.0882897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0660297\n",
      "\tspeed: 0.0407s/iter; left time: 715.9391s\n",
      "\titers: 200, epoch: 22 | loss: 0.0708514\n",
      "\tspeed: 0.0169s/iter; left time: 295.2067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0715171 Vali Loss: 0.0859312 Test Loss: 0.0880625\n",
      "Validation loss decreased (0.085962 --> 0.085931).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772004\n",
      "\tspeed: 0.0373s/iter; left time: 648.4993s\n",
      "\titers: 200, epoch: 23 | loss: 0.0758150\n",
      "\tspeed: 0.0167s/iter; left time: 289.0750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0714162 Vali Loss: 0.0858791 Test Loss: 0.0881526\n",
      "Validation loss decreased (0.085931 --> 0.085879).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0704919\n",
      "\tspeed: 0.0357s/iter; left time: 612.1264s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710698\n",
      "\tspeed: 0.0168s/iter; left time: 286.5181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0713394 Vali Loss: 0.0859242 Test Loss: 0.0880479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0734032\n",
      "\tspeed: 0.0339s/iter; left time: 574.1821s\n",
      "\titers: 200, epoch: 25 | loss: 0.0718507\n",
      "\tspeed: 0.0151s/iter; left time: 254.6573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0713331 Vali Loss: 0.0858649 Test Loss: 0.0880548\n",
      "Validation loss decreased (0.085879 --> 0.085865).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0737671\n",
      "\tspeed: 0.0355s/iter; left time: 593.5493s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793684\n",
      "\tspeed: 0.0157s/iter; left time: 260.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0712752 Vali Loss: 0.0859167 Test Loss: 0.0880084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0717697\n",
      "\tspeed: 0.0354s/iter; left time: 583.5597s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761196\n",
      "\tspeed: 0.0164s/iter; left time: 268.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0712137 Vali Loss: 0.0857490 Test Loss: 0.0879978\n",
      "Validation loss decreased (0.085865 --> 0.085749).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0689749\n",
      "\tspeed: 0.0353s/iter; left time: 573.8777s\n",
      "\titers: 200, epoch: 28 | loss: 0.0685668\n",
      "\tspeed: 0.0165s/iter; left time: 265.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0711730 Vali Loss: 0.0857674 Test Loss: 0.0879916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716897\n",
      "\tspeed: 0.0333s/iter; left time: 533.1187s\n",
      "\titers: 200, epoch: 29 | loss: 0.0727498\n",
      "\tspeed: 0.0174s/iter; left time: 277.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0711478 Vali Loss: 0.0857764 Test Loss: 0.0880277\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0729597\n",
      "\tspeed: 0.0364s/iter; left time: 575.1297s\n",
      "\titers: 200, epoch: 30 | loss: 0.0694474\n",
      "\tspeed: 0.0163s/iter; left time: 255.9871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0711195 Vali Loss: 0.0858107 Test Loss: 0.0880703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705280\n",
      "\tspeed: 0.0354s/iter; left time: 551.5650s\n",
      "\titers: 200, epoch: 31 | loss: 0.0706446\n",
      "\tspeed: 0.0162s/iter; left time: 250.7307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0710709 Vali Loss: 0.0856519 Test Loss: 0.0879048\n",
      "Validation loss decreased (0.085749 --> 0.085652).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0737029\n",
      "\tspeed: 0.0343s/iter; left time: 527.3157s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705879\n",
      "\tspeed: 0.0156s/iter; left time: 237.8526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0710011 Vali Loss: 0.0858139 Test Loss: 0.0879638\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0717120\n",
      "\tspeed: 0.0334s/iter; left time: 504.6895s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713802\n",
      "\tspeed: 0.0153s/iter; left time: 230.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0710676 Vali Loss: 0.0856694 Test Loss: 0.0879647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0718361\n",
      "\tspeed: 0.0338s/iter; left time: 503.6925s\n",
      "\titers: 200, epoch: 34 | loss: 0.0665619\n",
      "\tspeed: 0.0150s/iter; left time: 221.8731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0710157 Vali Loss: 0.0856699 Test Loss: 0.0879787\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0683812\n",
      "\tspeed: 0.0400s/iter; left time: 587.5014s\n",
      "\titers: 200, epoch: 35 | loss: 0.0770575\n",
      "\tspeed: 0.0175s/iter; left time: 254.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0710199 Vali Loss: 0.0856712 Test Loss: 0.0880343\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0658582\n",
      "\tspeed: 0.0367s/iter; left time: 530.7559s\n",
      "\titers: 200, epoch: 36 | loss: 0.0727000\n",
      "\tspeed: 0.0151s/iter; left time: 216.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0709822 Vali Loss: 0.0857249 Test Loss: 0.0879414\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0728939\n",
      "\tspeed: 0.0371s/iter; left time: 528.1510s\n",
      "\titers: 200, epoch: 37 | loss: 0.0696180\n",
      "\tspeed: 0.0157s/iter; left time: 222.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0709400 Vali Loss: 0.0855674 Test Loss: 0.0879513\n",
      "Validation loss decreased (0.085652 --> 0.085567).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0685611\n",
      "\tspeed: 0.0349s/iter; left time: 488.7168s\n",
      "\titers: 200, epoch: 38 | loss: 0.0669454\n",
      "\tspeed: 0.0150s/iter; left time: 209.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0709167 Vali Loss: 0.0856696 Test Loss: 0.0879596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0682163\n",
      "\tspeed: 0.0345s/iter; left time: 475.5114s\n",
      "\titers: 200, epoch: 39 | loss: 0.0693299\n",
      "\tspeed: 0.0187s/iter; left time: 256.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0709788 Vali Loss: 0.0856298 Test Loss: 0.0879837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0720993\n",
      "\tspeed: 0.0406s/iter; left time: 550.9434s\n",
      "\titers: 200, epoch: 40 | loss: 0.0645864\n",
      "\tspeed: 0.0196s/iter; left time: 263.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0709315 Vali Loss: 0.0857686 Test Loss: 0.0879399\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700375\n",
      "\tspeed: 0.0382s/iter; left time: 509.5840s\n",
      "\titers: 200, epoch: 41 | loss: 0.0746205\n",
      "\tspeed: 0.0161s/iter; left time: 213.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0708762 Vali Loss: 0.0856172 Test Loss: 0.0879617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0741807\n",
      "\tspeed: 0.0348s/iter; left time: 456.9177s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767551\n",
      "\tspeed: 0.0151s/iter; left time: 197.0823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0708721 Vali Loss: 0.0856957 Test Loss: 0.0879599\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0689145\n",
      "\tspeed: 0.0344s/iter; left time: 443.8696s\n",
      "\titers: 200, epoch: 43 | loss: 0.0758610\n",
      "\tspeed: 0.0154s/iter; left time: 197.4996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0709182 Vali Loss: 0.0856939 Test Loss: 0.0879526\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0721271\n",
      "\tspeed: 0.0387s/iter; left time: 490.5866s\n",
      "\titers: 200, epoch: 44 | loss: 0.0698737\n",
      "\tspeed: 0.0166s/iter; left time: 208.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0708669 Vali Loss: 0.0856575 Test Loss: 0.0879525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0766429\n",
      "\tspeed: 0.0354s/iter; left time: 440.3253s\n",
      "\titers: 200, epoch: 45 | loss: 0.0731394\n",
      "\tspeed: 0.0155s/iter; left time: 190.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0708668 Vali Loss: 0.0857093 Test Loss: 0.0879571\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0719643\n",
      "\tspeed: 0.0357s/iter; left time: 436.8546s\n",
      "\titers: 200, epoch: 46 | loss: 0.0734378\n",
      "\tspeed: 0.0150s/iter; left time: 182.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0708898 Vali Loss: 0.0855689 Test Loss: 0.0879298\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0741157\n",
      "\tspeed: 0.0350s/iter; left time: 419.3198s\n",
      "\titers: 200, epoch: 47 | loss: 0.0673396\n",
      "\tspeed: 0.0160s/iter; left time: 190.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0708373 Vali Loss: 0.0856182 Test Loss: 0.0879349\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02102525718510151, rmse:0.1450008898973465, mae:0.08795136213302612, rse:0.5117281675338745\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1620079\n",
      "\tspeed: 0.0211s/iter; left time: 470.9483s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357053\n",
      "\tspeed: 0.0176s/iter; left time: 391.1295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.1519175 Vali Loss: 0.1384056 Test Loss: 0.1470439\n",
      "Validation loss decreased (inf --> 0.138406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0925075\n",
      "\tspeed: 0.0382s/iter; left time: 843.9576s\n",
      "\titers: 200, epoch: 2 | loss: 0.0837343\n",
      "\tspeed: 0.0179s/iter; left time: 392.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0915478 Vali Loss: 0.0947697 Test Loss: 0.0955146\n",
      "Validation loss decreased (0.138406 --> 0.094770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775172\n",
      "\tspeed: 0.0361s/iter; left time: 789.7629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0783977\n",
      "\tspeed: 0.0150s/iter; left time: 326.8605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0813297 Vali Loss: 0.0916922 Test Loss: 0.0929940\n",
      "Validation loss decreased (0.094770 --> 0.091692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0831601\n",
      "\tspeed: 0.0364s/iter; left time: 787.4113s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811897\n",
      "\tspeed: 0.0175s/iter; left time: 376.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0786103 Vali Loss: 0.0896054 Test Loss: 0.0916582\n",
      "Validation loss decreased (0.091692 --> 0.089605).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0781299\n",
      "\tspeed: 0.0375s/iter; left time: 803.4343s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801012\n",
      "\tspeed: 0.0160s/iter; left time: 340.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0770884 Vali Loss: 0.0891516 Test Loss: 0.0909934\n",
      "Validation loss decreased (0.089605 --> 0.089152).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0762265\n",
      "\tspeed: 0.0423s/iter; left time: 896.9180s\n",
      "\titers: 200, epoch: 6 | loss: 0.0741063\n",
      "\tspeed: 0.0151s/iter; left time: 318.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0760599 Vali Loss: 0.0883477 Test Loss: 0.0903914\n",
      "Validation loss decreased (0.089152 --> 0.088348).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0709737\n",
      "\tspeed: 0.0347s/iter; left time: 727.7385s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733578\n",
      "\tspeed: 0.0150s/iter; left time: 313.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0752132 Vali Loss: 0.0878761 Test Loss: 0.0899173\n",
      "Validation loss decreased (0.088348 --> 0.087876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752652\n",
      "\tspeed: 0.0371s/iter; left time: 768.8032s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752018\n",
      "\tspeed: 0.0164s/iter; left time: 338.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0746590 Vali Loss: 0.0877004 Test Loss: 0.0893606\n",
      "Validation loss decreased (0.087876 --> 0.087700).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722681\n",
      "\tspeed: 0.0370s/iter; left time: 758.0550s\n",
      "\titers: 200, epoch: 9 | loss: 0.0737365\n",
      "\tspeed: 0.0164s/iter; left time: 334.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0741428 Vali Loss: 0.0871071 Test Loss: 0.0893279\n",
      "Validation loss decreased (0.087700 --> 0.087107).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0672431\n",
      "\tspeed: 0.0406s/iter; left time: 824.5834s\n",
      "\titers: 200, epoch: 10 | loss: 0.0725504\n",
      "\tspeed: 0.0207s/iter; left time: 417.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0737040 Vali Loss: 0.0868370 Test Loss: 0.0890208\n",
      "Validation loss decreased (0.087107 --> 0.086837).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0729174\n",
      "\tspeed: 0.0358s/iter; left time: 718.2947s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749508\n",
      "\tspeed: 0.0177s/iter; left time: 354.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0734557 Vali Loss: 0.0868050 Test Loss: 0.0888223\n",
      "Validation loss decreased (0.086837 --> 0.086805).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0724564\n",
      "\tspeed: 0.0372s/iter; left time: 738.5988s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730564\n",
      "\tspeed: 0.0160s/iter; left time: 315.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0730905 Vali Loss: 0.0864978 Test Loss: 0.0886044\n",
      "Validation loss decreased (0.086805 --> 0.086498).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0681100\n",
      "\tspeed: 0.0354s/iter; left time: 694.9149s\n",
      "\titers: 200, epoch: 13 | loss: 0.0772323\n",
      "\tspeed: 0.0152s/iter; left time: 297.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0728838 Vali Loss: 0.0863788 Test Loss: 0.0886928\n",
      "Validation loss decreased (0.086498 --> 0.086379).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695235\n",
      "\tspeed: 0.0379s/iter; left time: 734.9984s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697198\n",
      "\tspeed: 0.0170s/iter; left time: 327.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0726609 Vali Loss: 0.0863451 Test Loss: 0.0884922\n",
      "Validation loss decreased (0.086379 --> 0.086345).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0687942\n",
      "\tspeed: 0.0360s/iter; left time: 690.8908s\n",
      "\titers: 200, epoch: 15 | loss: 0.0724361\n",
      "\tspeed: 0.0151s/iter; left time: 286.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0724553 Vali Loss: 0.0863603 Test Loss: 0.0886412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0753057\n",
      "\tspeed: 0.0337s/iter; left time: 638.7363s\n",
      "\titers: 200, epoch: 16 | loss: 0.0712433\n",
      "\tspeed: 0.0151s/iter; left time: 284.3195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0722672 Vali Loss: 0.0858427 Test Loss: 0.0881298\n",
      "Validation loss decreased (0.086345 --> 0.085843).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0701859\n",
      "\tspeed: 0.0347s/iter; left time: 649.5600s\n",
      "\titers: 200, epoch: 17 | loss: 0.0739559\n",
      "\tspeed: 0.0150s/iter; left time: 278.6778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0721210 Vali Loss: 0.0860098 Test Loss: 0.0884278\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726327\n",
      "\tspeed: 0.0396s/iter; left time: 732.1841s\n",
      "\titers: 200, epoch: 18 | loss: 0.0713935\n",
      "\tspeed: 0.0200s/iter; left time: 367.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0719620 Vali Loss: 0.0857885 Test Loss: 0.0881801\n",
      "Validation loss decreased (0.085843 --> 0.085789).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0742131\n",
      "\tspeed: 0.0377s/iter; left time: 688.8838s\n",
      "\titers: 200, epoch: 19 | loss: 0.0732629\n",
      "\tspeed: 0.0179s/iter; left time: 324.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0718759 Vali Loss: 0.0859508 Test Loss: 0.0884113\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0714221\n",
      "\tspeed: 0.0345s/iter; left time: 623.4420s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717010\n",
      "\tspeed: 0.0151s/iter; left time: 271.7996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0717745 Vali Loss: 0.0855055 Test Loss: 0.0880914\n",
      "Validation loss decreased (0.085789 --> 0.085505).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0771475\n",
      "\tspeed: 0.0347s/iter; left time: 618.5704s\n",
      "\titers: 200, epoch: 21 | loss: 0.0724728\n",
      "\tspeed: 0.0151s/iter; left time: 266.7434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0717007 Vali Loss: 0.0856328 Test Loss: 0.0881867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0788103\n",
      "\tspeed: 0.0368s/iter; left time: 647.5301s\n",
      "\titers: 200, epoch: 22 | loss: 0.0694613\n",
      "\tspeed: 0.0168s/iter; left time: 293.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0715633 Vali Loss: 0.0856718 Test Loss: 0.0880542\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0743566\n",
      "\tspeed: 0.0370s/iter; left time: 642.4992s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691096\n",
      "\tspeed: 0.0159s/iter; left time: 274.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0715231 Vali Loss: 0.0856822 Test Loss: 0.0880020\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0666789\n",
      "\tspeed: 0.0351s/iter; left time: 601.3510s\n",
      "\titers: 200, epoch: 24 | loss: 0.0711413\n",
      "\tspeed: 0.0150s/iter; left time: 255.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0714732 Vali Loss: 0.0855215 Test Loss: 0.0879863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0715382\n",
      "\tspeed: 0.0350s/iter; left time: 592.7788s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703375\n",
      "\tspeed: 0.0168s/iter; left time: 282.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0714018 Vali Loss: 0.0854952 Test Loss: 0.0879767\n",
      "Validation loss decreased (0.085505 --> 0.085495).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0712197\n",
      "\tspeed: 0.0365s/iter; left time: 610.1198s\n",
      "\titers: 200, epoch: 26 | loss: 0.0679051\n",
      "\tspeed: 0.0165s/iter; left time: 273.4259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0713313 Vali Loss: 0.0855626 Test Loss: 0.0880481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0659714\n",
      "\tspeed: 0.0387s/iter; left time: 637.1007s\n",
      "\titers: 200, epoch: 27 | loss: 0.0693258\n",
      "\tspeed: 0.0162s/iter; left time: 266.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0712896 Vali Loss: 0.0853323 Test Loss: 0.0881169\n",
      "Validation loss decreased (0.085495 --> 0.085332).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0719323\n",
      "\tspeed: 0.0350s/iter; left time: 568.8569s\n",
      "\titers: 200, epoch: 28 | loss: 0.0705319\n",
      "\tspeed: 0.0160s/iter; left time: 258.1042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0712321 Vali Loss: 0.0854750 Test Loss: 0.0880130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0682046\n",
      "\tspeed: 0.0362s/iter; left time: 580.9536s\n",
      "\titers: 200, epoch: 29 | loss: 0.0715686\n",
      "\tspeed: 0.0191s/iter; left time: 304.1477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0712571 Vali Loss: 0.0855410 Test Loss: 0.0880609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701953\n",
      "\tspeed: 0.0382s/iter; left time: 602.9752s\n",
      "\titers: 200, epoch: 30 | loss: 0.0651151\n",
      "\tspeed: 0.0169s/iter; left time: 265.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0711798 Vali Loss: 0.0854954 Test Loss: 0.0880713\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0724007\n",
      "\tspeed: 0.0373s/iter; left time: 581.5572s\n",
      "\titers: 200, epoch: 31 | loss: 0.0681549\n",
      "\tspeed: 0.0155s/iter; left time: 240.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0711801 Vali Loss: 0.0854340 Test Loss: 0.0879384\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0723109\n",
      "\tspeed: 0.0380s/iter; left time: 584.0885s\n",
      "\titers: 200, epoch: 32 | loss: 0.0718525\n",
      "\tspeed: 0.0164s/iter; left time: 249.7781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0711136 Vali Loss: 0.0854606 Test Loss: 0.0879204\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0678901\n",
      "\tspeed: 0.0362s/iter; left time: 547.3003s\n",
      "\titers: 200, epoch: 33 | loss: 0.0716351\n",
      "\tspeed: 0.0159s/iter; left time: 239.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0711025 Vali Loss: 0.0853737 Test Loss: 0.0879659\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0742364\n",
      "\tspeed: 0.0362s/iter; left time: 539.0277s\n",
      "\titers: 200, epoch: 34 | loss: 0.0696593\n",
      "\tspeed: 0.0158s/iter; left time: 234.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0710668 Vali Loss: 0.0855342 Test Loss: 0.0879665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0670826\n",
      "\tspeed: 0.0384s/iter; left time: 563.6345s\n",
      "\titers: 200, epoch: 35 | loss: 0.0684078\n",
      "\tspeed: 0.0197s/iter; left time: 287.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0710488 Vali Loss: 0.0852844 Test Loss: 0.0879627\n",
      "Validation loss decreased (0.085332 --> 0.085284).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0724782\n",
      "\tspeed: 0.0361s/iter; left time: 522.5974s\n",
      "\titers: 200, epoch: 36 | loss: 0.0674055\n",
      "\tspeed: 0.0168s/iter; left time: 240.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0710851 Vali Loss: 0.0854017 Test Loss: 0.0879259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0727166\n",
      "\tspeed: 0.0364s/iter; left time: 517.5539s\n",
      "\titers: 200, epoch: 37 | loss: 0.0690973\n",
      "\tspeed: 0.0159s/iter; left time: 224.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0710921 Vali Loss: 0.0853984 Test Loss: 0.0879408\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0656462\n",
      "\tspeed: 0.0366s/iter; left time: 513.1425s\n",
      "\titers: 200, epoch: 38 | loss: 0.0702380\n",
      "\tspeed: 0.0161s/iter; left time: 224.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0710484 Vali Loss: 0.0853677 Test Loss: 0.0879387\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720998\n",
      "\tspeed: 0.0377s/iter; left time: 519.7150s\n",
      "\titers: 200, epoch: 39 | loss: 0.0671679\n",
      "\tspeed: 0.0160s/iter; left time: 219.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0710056 Vali Loss: 0.0852800 Test Loss: 0.0879372\n",
      "Validation loss decreased (0.085284 --> 0.085280).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0701672\n",
      "\tspeed: 0.0363s/iter; left time: 492.9902s\n",
      "\titers: 200, epoch: 40 | loss: 0.0716853\n",
      "\tspeed: 0.0169s/iter; left time: 227.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0709927 Vali Loss: 0.0853299 Test Loss: 0.0879583\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0716479\n",
      "\tspeed: 0.0368s/iter; left time: 490.9810s\n",
      "\titers: 200, epoch: 41 | loss: 0.0675496\n",
      "\tspeed: 0.0170s/iter; left time: 224.6470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0709191 Vali Loss: 0.0852563 Test Loss: 0.0879528\n",
      "Validation loss decreased (0.085280 --> 0.085256).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0730136\n",
      "\tspeed: 0.0345s/iter; left time: 452.1410s\n",
      "\titers: 200, epoch: 42 | loss: 0.0677877\n",
      "\tspeed: 0.0151s/iter; left time: 196.1489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0709791 Vali Loss: 0.0852981 Test Loss: 0.0879164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0697727\n",
      "\tspeed: 0.0340s/iter; left time: 438.1032s\n",
      "\titers: 200, epoch: 43 | loss: 0.0682580\n",
      "\tspeed: 0.0151s/iter; left time: 193.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0709161 Vali Loss: 0.0853420 Test Loss: 0.0879155\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0690341\n",
      "\tspeed: 0.0382s/iter; left time: 484.3897s\n",
      "\titers: 200, epoch: 44 | loss: 0.0728753\n",
      "\tspeed: 0.0182s/iter; left time: 229.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0709640 Vali Loss: 0.0852692 Test Loss: 0.0879469\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0711762\n",
      "\tspeed: 0.0405s/iter; left time: 503.9695s\n",
      "\titers: 200, epoch: 45 | loss: 0.0739983\n",
      "\tspeed: 0.0184s/iter; left time: 227.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0709666 Vali Loss: 0.0853027 Test Loss: 0.0879316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0751044\n",
      "\tspeed: 0.0369s/iter; left time: 450.7532s\n",
      "\titers: 200, epoch: 46 | loss: 0.0716240\n",
      "\tspeed: 0.0163s/iter; left time: 197.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0709252 Vali Loss: 0.0852374 Test Loss: 0.0879348\n",
      "Validation loss decreased (0.085256 --> 0.085237).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0658800\n",
      "\tspeed: 0.0392s/iter; left time: 470.8725s\n",
      "\titers: 200, epoch: 47 | loss: 0.0709079\n",
      "\tspeed: 0.0158s/iter; left time: 188.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0709356 Vali Loss: 0.0852484 Test Loss: 0.0879276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0675698\n",
      "\tspeed: 0.0360s/iter; left time: 424.1448s\n",
      "\titers: 200, epoch: 48 | loss: 0.0716024\n",
      "\tspeed: 0.0157s/iter; left time: 183.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0708872 Vali Loss: 0.0853943 Test Loss: 0.0879419\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0706257\n",
      "\tspeed: 0.0389s/iter; left time: 449.3166s\n",
      "\titers: 200, epoch: 49 | loss: 0.0669339\n",
      "\tspeed: 0.0172s/iter; left time: 196.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0709641 Vali Loss: 0.0853103 Test Loss: 0.0879224\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0755349\n",
      "\tspeed: 0.0359s/iter; left time: 406.5473s\n",
      "\titers: 200, epoch: 50 | loss: 0.0702147\n",
      "\tspeed: 0.0151s/iter; left time: 169.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0708876 Vali Loss: 0.0853348 Test Loss: 0.0879313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0721121\n",
      "\tspeed: 0.0338s/iter; left time: 375.3850s\n",
      "\titers: 200, epoch: 51 | loss: 0.0676583\n",
      "\tspeed: 0.0150s/iter; left time: 165.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0708749 Vali Loss: 0.0852411 Test Loss: 0.0879243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0716265\n",
      "\tspeed: 0.0337s/iter; left time: 366.6702s\n",
      "\titers: 200, epoch: 52 | loss: 0.0739582\n",
      "\tspeed: 0.0151s/iter; left time: 162.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0708858 Vali Loss: 0.0853590 Test Loss: 0.0879341\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0707915\n",
      "\tspeed: 0.0346s/iter; left time: 368.5474s\n",
      "\titers: 200, epoch: 53 | loss: 0.0728113\n",
      "\tspeed: 0.0151s/iter; left time: 159.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0709129 Vali Loss: 0.0852740 Test Loss: 0.0879305\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0682394\n",
      "\tspeed: 0.0352s/iter; left time: 367.4443s\n",
      "\titers: 200, epoch: 54 | loss: 0.0667391\n",
      "\tspeed: 0.0151s/iter; left time: 156.1786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0709479 Vali Loss: 0.0853292 Test Loss: 0.0879283\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0697148\n",
      "\tspeed: 0.0348s/iter; left time: 355.5199s\n",
      "\titers: 200, epoch: 55 | loss: 0.0655596\n",
      "\tspeed: 0.0170s/iter; left time: 171.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0708822 Vali Loss: 0.0853821 Test Loss: 0.0879369\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0722160\n",
      "\tspeed: 0.0389s/iter; left time: 388.6583s\n",
      "\titers: 200, epoch: 56 | loss: 0.0701749\n",
      "\tspeed: 0.0189s/iter; left time: 186.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0708431 Vali Loss: 0.0853964 Test Loss: 0.0879415\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021055331453680992, rmse:0.1451045572757721, mae:0.08793476969003677, rse:0.5120940804481506\n",
      "Intermediate time for DE and pred_len 24: 00h:09m:11.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1617293\n",
      "\tspeed: 0.0397s/iter; left time: 885.3294s\n",
      "\titers: 200, epoch: 1 | loss: 0.1502261\n",
      "\tspeed: 0.0152s/iter; left time: 337.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1589484 Vali Loss: 0.1489534 Test Loss: 0.1608385\n",
      "Validation loss decreased (inf --> 0.148953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1088347\n",
      "\tspeed: 0.0353s/iter; left time: 780.4191s\n",
      "\titers: 200, epoch: 2 | loss: 0.1147311\n",
      "\tspeed: 0.0152s/iter; left time: 334.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1169258 Vali Loss: 0.1223775 Test Loss: 0.1303410\n",
      "Validation loss decreased (0.148953 --> 0.122377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055293\n",
      "\tspeed: 0.0364s/iter; left time: 794.7829s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986288\n",
      "\tspeed: 0.0166s/iter; left time: 360.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1074978 Vali Loss: 0.1198995 Test Loss: 0.1283483\n",
      "Validation loss decreased (0.122377 --> 0.119899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1030197\n",
      "\tspeed: 0.0354s/iter; left time: 764.8154s\n",
      "\titers: 200, epoch: 4 | loss: 0.1036162\n",
      "\tspeed: 0.0152s/iter; left time: 327.6601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1053726 Vali Loss: 0.1190406 Test Loss: 0.1278044\n",
      "Validation loss decreased (0.119899 --> 0.119041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044356\n",
      "\tspeed: 0.0385s/iter; left time: 824.2357s\n",
      "\titers: 200, epoch: 5 | loss: 0.1062173\n",
      "\tspeed: 0.0152s/iter; left time: 322.8208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1040613 Vali Loss: 0.1187894 Test Loss: 0.1276770\n",
      "Validation loss decreased (0.119041 --> 0.118789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023082\n",
      "\tspeed: 0.0359s/iter; left time: 759.4906s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002097\n",
      "\tspeed: 0.0151s/iter; left time: 319.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.1030888 Vali Loss: 0.1175843 Test Loss: 0.1267586\n",
      "Validation loss decreased (0.118789 --> 0.117584).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985272\n",
      "\tspeed: 0.0362s/iter; left time: 758.0566s\n",
      "\titers: 200, epoch: 7 | loss: 0.1033290\n",
      "\tspeed: 0.0151s/iter; left time: 315.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1023778 Vali Loss: 0.1178266 Test Loss: 0.1273874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0990437\n",
      "\tspeed: 0.0368s/iter; left time: 762.1291s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037220\n",
      "\tspeed: 0.0152s/iter; left time: 313.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1017019 Vali Loss: 0.1178749 Test Loss: 0.1282059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1000827\n",
      "\tspeed: 0.0346s/iter; left time: 710.5840s\n",
      "\titers: 200, epoch: 9 | loss: 0.1004790\n",
      "\tspeed: 0.0152s/iter; left time: 310.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1011080 Vali Loss: 0.1178433 Test Loss: 0.1280416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0967632\n",
      "\tspeed: 0.0359s/iter; left time: 727.7031s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985029\n",
      "\tspeed: 0.0167s/iter; left time: 337.7379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1005722 Vali Loss: 0.1179191 Test Loss: 0.1280248\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0999602\n",
      "\tspeed: 0.0366s/iter; left time: 734.3018s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048836\n",
      "\tspeed: 0.0167s/iter; left time: 333.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.1001029 Vali Loss: 0.1170781 Test Loss: 0.1272336\n",
      "Validation loss decreased (0.117584 --> 0.117078).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0998638\n",
      "\tspeed: 0.0368s/iter; left time: 729.9865s\n",
      "\titers: 200, epoch: 12 | loss: 0.0988359\n",
      "\tspeed: 0.0157s/iter; left time: 310.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0995904 Vali Loss: 0.1173029 Test Loss: 0.1276678\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029612\n",
      "\tspeed: 0.0368s/iter; left time: 721.8141s\n",
      "\titers: 200, epoch: 13 | loss: 0.0956578\n",
      "\tspeed: 0.0176s/iter; left time: 343.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0991521 Vali Loss: 0.1173498 Test Loss: 0.1281194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1017543\n",
      "\tspeed: 0.0340s/iter; left time: 658.7187s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952376\n",
      "\tspeed: 0.0151s/iter; left time: 292.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0987826 Vali Loss: 0.1174424 Test Loss: 0.1278649\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1004049\n",
      "\tspeed: 0.0374s/iter; left time: 716.6262s\n",
      "\titers: 200, epoch: 15 | loss: 0.1025560\n",
      "\tspeed: 0.0162s/iter; left time: 309.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0983810 Vali Loss: 0.1175421 Test Loss: 0.1287416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000547\n",
      "\tspeed: 0.0370s/iter; left time: 699.9222s\n",
      "\titers: 200, epoch: 16 | loss: 0.0976227\n",
      "\tspeed: 0.0196s/iter; left time: 369.5051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0980522 Vali Loss: 0.1172046 Test Loss: 0.1286765\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0966947\n",
      "\tspeed: 0.0361s/iter; left time: 676.3541s\n",
      "\titers: 200, epoch: 17 | loss: 0.1031760\n",
      "\tspeed: 0.0152s/iter; left time: 283.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0977161 Vali Loss: 0.1172002 Test Loss: 0.1285316\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1013617\n",
      "\tspeed: 0.0358s/iter; left time: 662.1116s\n",
      "\titers: 200, epoch: 18 | loss: 0.1001893\n",
      "\tspeed: 0.0169s/iter; left time: 310.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0974929 Vali Loss: 0.1171749 Test Loss: 0.1282448\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0948397\n",
      "\tspeed: 0.0402s/iter; left time: 734.3479s\n",
      "\titers: 200, epoch: 19 | loss: 0.0959898\n",
      "\tspeed: 0.0169s/iter; left time: 306.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0972172 Vali Loss: 0.1171801 Test Loss: 0.1279889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0927467\n",
      "\tspeed: 0.0361s/iter; left time: 651.9246s\n",
      "\titers: 200, epoch: 20 | loss: 0.0937767\n",
      "\tspeed: 0.0159s/iter; left time: 286.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0969838 Vali Loss: 0.1173577 Test Loss: 0.1282616\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0975111\n",
      "\tspeed: 0.0366s/iter; left time: 651.3667s\n",
      "\titers: 200, epoch: 21 | loss: 0.0933360\n",
      "\tspeed: 0.0165s/iter; left time: 291.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0967536 Vali Loss: 0.1171621 Test Loss: 0.1285279\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037020161747932434, rmse:0.19240623712539673, mae:0.1272336095571518, rse:0.6813493967056274\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600528\n",
      "\tspeed: 0.0182s/iter; left time: 406.6441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1410382\n",
      "\tspeed: 0.0162s/iter; left time: 360.2117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1596030 Vali Loss: 0.1500779 Test Loss: 0.1617432\n",
      "Validation loss decreased (inf --> 0.150078).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1118094\n",
      "\tspeed: 0.0390s/iter; left time: 860.0622s\n",
      "\titers: 200, epoch: 2 | loss: 0.1140975\n",
      "\tspeed: 0.0196s/iter; left time: 429.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.1169051 Vali Loss: 0.1221950 Test Loss: 0.1299460\n",
      "Validation loss decreased (0.150078 --> 0.122195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1062572\n",
      "\tspeed: 0.0434s/iter; left time: 948.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.1093073\n",
      "\tspeed: 0.0218s/iter; left time: 475.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.1074045 Vali Loss: 0.1202091 Test Loss: 0.1291349\n",
      "Validation loss decreased (0.122195 --> 0.120209).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090612\n",
      "\tspeed: 0.0439s/iter; left time: 949.8817s\n",
      "\titers: 200, epoch: 4 | loss: 0.1101548\n",
      "\tspeed: 0.0152s/iter; left time: 326.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1053431 Vali Loss: 0.1189654 Test Loss: 0.1284793\n",
      "Validation loss decreased (0.120209 --> 0.118965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029042\n",
      "\tspeed: 0.0395s/iter; left time: 846.1193s\n",
      "\titers: 200, epoch: 5 | loss: 0.0994053\n",
      "\tspeed: 0.0164s/iter; left time: 350.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.1039627 Vali Loss: 0.1184063 Test Loss: 0.1274871\n",
      "Validation loss decreased (0.118965 --> 0.118406).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982993\n",
      "\tspeed: 0.0431s/iter; left time: 913.0918s\n",
      "\titers: 200, epoch: 6 | loss: 0.1053806\n",
      "\tspeed: 0.0200s/iter; left time: 422.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.1030563 Vali Loss: 0.1181395 Test Loss: 0.1281831\n",
      "Validation loss decreased (0.118406 --> 0.118140).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1086963\n",
      "\tspeed: 0.0358s/iter; left time: 750.6966s\n",
      "\titers: 200, epoch: 7 | loss: 0.0964198\n",
      "\tspeed: 0.0152s/iter; left time: 316.9981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1022796 Vali Loss: 0.1189083 Test Loss: 0.1287796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0968450\n",
      "\tspeed: 0.0448s/iter; left time: 928.3234s\n",
      "\titers: 200, epoch: 8 | loss: 0.1034105\n",
      "\tspeed: 0.0173s/iter; left time: 356.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1016460 Vali Loss: 0.1179143 Test Loss: 0.1281167\n",
      "Validation loss decreased (0.118140 --> 0.117914).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0973989\n",
      "\tspeed: 0.0379s/iter; left time: 778.0159s\n",
      "\titers: 200, epoch: 9 | loss: 0.1020499\n",
      "\tspeed: 0.0152s/iter; left time: 310.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1009939 Vali Loss: 0.1183126 Test Loss: 0.1282138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0978476\n",
      "\tspeed: 0.0369s/iter; left time: 749.3965s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003062\n",
      "\tspeed: 0.0195s/iter; left time: 392.8052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1004418 Vali Loss: 0.1181370 Test Loss: 0.1278159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0967827\n",
      "\tspeed: 0.0399s/iter; left time: 800.6391s\n",
      "\titers: 200, epoch: 11 | loss: 0.0992493\n",
      "\tspeed: 0.0188s/iter; left time: 375.1446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0999447 Vali Loss: 0.1182281 Test Loss: 0.1283551\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0979529\n",
      "\tspeed: 0.0393s/iter; left time: 779.8253s\n",
      "\titers: 200, epoch: 12 | loss: 0.0982875\n",
      "\tspeed: 0.0161s/iter; left time: 317.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0995006 Vali Loss: 0.1180363 Test Loss: 0.1286141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0960883\n",
      "\tspeed: 0.0397s/iter; left time: 778.4961s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018825\n",
      "\tspeed: 0.0156s/iter; left time: 304.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0989925 Vali Loss: 0.1181305 Test Loss: 0.1283321\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0980101\n",
      "\tspeed: 0.0356s/iter; left time: 689.9700s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960893\n",
      "\tspeed: 0.0152s/iter; left time: 292.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0985814 Vali Loss: 0.1183441 Test Loss: 0.1289180\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0970033\n",
      "\tspeed: 0.0412s/iter; left time: 789.2387s\n",
      "\titers: 200, epoch: 15 | loss: 0.1022276\n",
      "\tspeed: 0.0204s/iter; left time: 388.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0982293 Vali Loss: 0.1184064 Test Loss: 0.1294909\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0992394\n",
      "\tspeed: 0.0392s/iter; left time: 742.2513s\n",
      "\titers: 200, epoch: 16 | loss: 0.0945385\n",
      "\tspeed: 0.0188s/iter; left time: 353.4450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0978067 Vali Loss: 0.1182202 Test Loss: 0.1290659\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0961426\n",
      "\tspeed: 0.0421s/iter; left time: 788.2307s\n",
      "\titers: 200, epoch: 17 | loss: 0.0946452\n",
      "\tspeed: 0.0182s/iter; left time: 339.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0975315 Vali Loss: 0.1182176 Test Loss: 0.1290844\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1001692\n",
      "\tspeed: 0.0393s/iter; left time: 726.4549s\n",
      "\titers: 200, epoch: 18 | loss: 0.0999711\n",
      "\tspeed: 0.0196s/iter; left time: 359.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0972824 Vali Loss: 0.1182895 Test Loss: 0.1291146\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037602849304676056, rmse:0.19391454756259918, mae:0.12811671197414398, rse:0.686690628528595\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:45.24s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1630802\n",
      "\tspeed: 0.0415s/iter; left time: 921.3775s\n",
      "\titers: 200, epoch: 1 | loss: 0.1465753\n",
      "\tspeed: 0.0170s/iter; left time: 374.6686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1605783 Vali Loss: 0.1508962 Test Loss: 0.1630176\n",
      "Validation loss decreased (inf --> 0.150896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295763\n",
      "\tspeed: 0.0361s/iter; left time: 794.3364s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168139\n",
      "\tspeed: 0.0154s/iter; left time: 337.9190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1227621 Vali Loss: 0.1269557 Test Loss: 0.1364352\n",
      "Validation loss decreased (0.150896 --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145269\n",
      "\tspeed: 0.0359s/iter; left time: 781.9506s\n",
      "\titers: 200, epoch: 3 | loss: 0.1162174\n",
      "\tspeed: 0.0154s/iter; left time: 333.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1136734 Vali Loss: 0.1247916 Test Loss: 0.1347414\n",
      "Validation loss decreased (0.126956 --> 0.124792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097216\n",
      "\tspeed: 0.0367s/iter; left time: 789.6054s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118387\n",
      "\tspeed: 0.0154s/iter; left time: 330.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.1113515 Vali Loss: 0.1241977 Test Loss: 0.1348312\n",
      "Validation loss decreased (0.124792 --> 0.124198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120783\n",
      "\tspeed: 0.0362s/iter; left time: 771.1646s\n",
      "\titers: 200, epoch: 5 | loss: 0.1105169\n",
      "\tspeed: 0.0161s/iter; left time: 341.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.1099460 Vali Loss: 0.1236693 Test Loss: 0.1346285\n",
      "Validation loss decreased (0.124198 --> 0.123669).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060411\n",
      "\tspeed: 0.0366s/iter; left time: 772.6807s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044471\n",
      "\tspeed: 0.0155s/iter; left time: 324.4258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1088728 Vali Loss: 0.1233766 Test Loss: 0.1346566\n",
      "Validation loss decreased (0.123669 --> 0.123377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1017920\n",
      "\tspeed: 0.0383s/iter; left time: 799.1719s\n",
      "\titers: 200, epoch: 7 | loss: 0.1089835\n",
      "\tspeed: 0.0166s/iter; left time: 343.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.1079321 Vali Loss: 0.1237818 Test Loss: 0.1350066\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1103656\n",
      "\tspeed: 0.0407s/iter; left time: 839.3098s\n",
      "\titers: 200, epoch: 8 | loss: 0.1075654\n",
      "\tspeed: 0.0164s/iter; left time: 337.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1071216 Vali Loss: 0.1238213 Test Loss: 0.1350236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030786\n",
      "\tspeed: 0.0388s/iter; left time: 791.8497s\n",
      "\titers: 200, epoch: 9 | loss: 0.1097195\n",
      "\tspeed: 0.0172s/iter; left time: 349.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1063707 Vali Loss: 0.1244656 Test Loss: 0.1355901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035809\n",
      "\tspeed: 0.0354s/iter; left time: 715.6350s\n",
      "\titers: 200, epoch: 10 | loss: 0.1176516\n",
      "\tspeed: 0.0158s/iter; left time: 317.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.1057048 Vali Loss: 0.1241349 Test Loss: 0.1359958\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068485\n",
      "\tspeed: 0.0395s/iter; left time: 789.2654s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104806\n",
      "\tspeed: 0.0192s/iter; left time: 380.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.1050271 Vali Loss: 0.1242511 Test Loss: 0.1356018\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1048287\n",
      "\tspeed: 0.0384s/iter; left time: 757.3430s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035267\n",
      "\tspeed: 0.0176s/iter; left time: 345.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1044566 Vali Loss: 0.1242530 Test Loss: 0.1356748\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1061895\n",
      "\tspeed: 0.0353s/iter; left time: 690.0523s\n",
      "\titers: 200, epoch: 13 | loss: 0.1037243\n",
      "\tspeed: 0.0154s/iter; left time: 298.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1037393 Vali Loss: 0.1250260 Test Loss: 0.1364646\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1026239\n",
      "\tspeed: 0.0383s/iter; left time: 739.2961s\n",
      "\titers: 200, epoch: 14 | loss: 0.1011197\n",
      "\tspeed: 0.0174s/iter; left time: 334.1004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1031816 Vali Loss: 0.1250276 Test Loss: 0.1366612\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0981597\n",
      "\tspeed: 0.0409s/iter; left time: 780.3921s\n",
      "\titers: 200, epoch: 15 | loss: 0.0960923\n",
      "\tspeed: 0.0201s/iter; left time: 381.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.1027198 Vali Loss: 0.1249749 Test Loss: 0.1370500\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990345\n",
      "\tspeed: 0.0363s/iter; left time: 684.1811s\n",
      "\titers: 200, epoch: 16 | loss: 0.1006227\n",
      "\tspeed: 0.0154s/iter; left time: 288.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1023213 Vali Loss: 0.1253612 Test Loss: 0.1375442\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039681319147348404, rmse:0.19920170307159424, mae:0.1346566081047058, rse:0.7055884599685669\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1615392\n",
      "\tspeed: 0.0179s/iter; left time: 397.8424s\n",
      "\titers: 200, epoch: 1 | loss: 0.1472335\n",
      "\tspeed: 0.0221s/iter; left time: 488.3775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.1615935 Vali Loss: 0.1517360 Test Loss: 0.1639789\n",
      "Validation loss decreased (inf --> 0.151736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1188105\n",
      "\tspeed: 0.0394s/iter; left time: 865.3027s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159582\n",
      "\tspeed: 0.0164s/iter; left time: 358.9909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1226996 Vali Loss: 0.1268991 Test Loss: 0.1364999\n",
      "Validation loss decreased (0.151736 --> 0.126899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1126640\n",
      "\tspeed: 0.0415s/iter; left time: 901.9360s\n",
      "\titers: 200, epoch: 3 | loss: 0.1099748\n",
      "\tspeed: 0.0166s/iter; left time: 360.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.1135890 Vali Loss: 0.1246618 Test Loss: 0.1355758\n",
      "Validation loss decreased (0.126899 --> 0.124662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1082185\n",
      "\tspeed: 0.0377s/iter; left time: 812.3663s\n",
      "\titers: 200, epoch: 4 | loss: 0.1109522\n",
      "\tspeed: 0.0160s/iter; left time: 343.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1111873 Vali Loss: 0.1241053 Test Loss: 0.1354842\n",
      "Validation loss decreased (0.124662 --> 0.124105).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1136813\n",
      "\tspeed: 0.0369s/iter; left time: 785.3416s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072372\n",
      "\tspeed: 0.0163s/iter; left time: 346.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.1097294 Vali Loss: 0.1239886 Test Loss: 0.1355397\n",
      "Validation loss decreased (0.124105 --> 0.123989).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1017980\n",
      "\tspeed: 0.0419s/iter; left time: 884.3329s\n",
      "\titers: 200, epoch: 6 | loss: 0.1040525\n",
      "\tspeed: 0.0171s/iter; left time: 359.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1086759 Vali Loss: 0.1239656 Test Loss: 0.1352768\n",
      "Validation loss decreased (0.123989 --> 0.123966).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1035973\n",
      "\tspeed: 0.0362s/iter; left time: 754.9412s\n",
      "\titers: 200, epoch: 7 | loss: 0.1087498\n",
      "\tspeed: 0.0154s/iter; left time: 320.2582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.1078367 Vali Loss: 0.1238061 Test Loss: 0.1350280\n",
      "Validation loss decreased (0.123966 --> 0.123806).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1073678\n",
      "\tspeed: 0.0378s/iter; left time: 779.6828s\n",
      "\titers: 200, epoch: 8 | loss: 0.1042683\n",
      "\tspeed: 0.0174s/iter; left time: 356.7737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1068856 Vali Loss: 0.1239254 Test Loss: 0.1354550\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043975\n",
      "\tspeed: 0.0365s/iter; left time: 744.3069s\n",
      "\titers: 200, epoch: 9 | loss: 0.1055149\n",
      "\tspeed: 0.0164s/iter; left time: 333.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.1062039 Vali Loss: 0.1239515 Test Loss: 0.1359528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1078688\n",
      "\tspeed: 0.0396s/iter; left time: 799.1089s\n",
      "\titers: 200, epoch: 10 | loss: 0.0995901\n",
      "\tspeed: 0.0169s/iter; left time: 340.2540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1054967 Vali Loss: 0.1237788 Test Loss: 0.1358146\n",
      "Validation loss decreased (0.123806 --> 0.123779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1077963\n",
      "\tspeed: 0.0378s/iter; left time: 755.2782s\n",
      "\titers: 200, epoch: 11 | loss: 0.1025452\n",
      "\tspeed: 0.0165s/iter; left time: 327.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1047987 Vali Loss: 0.1244325 Test Loss: 0.1359357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1038067\n",
      "\tspeed: 0.0376s/iter; left time: 741.5940s\n",
      "\titers: 200, epoch: 12 | loss: 0.1016396\n",
      "\tspeed: 0.0160s/iter; left time: 313.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1042451 Vali Loss: 0.1244212 Test Loss: 0.1363232\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1007343\n",
      "\tspeed: 0.0356s/iter; left time: 694.5000s\n",
      "\titers: 200, epoch: 13 | loss: 0.1011594\n",
      "\tspeed: 0.0154s/iter; left time: 299.5344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.1035933 Vali Loss: 0.1246336 Test Loss: 0.1362268\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0997022\n",
      "\tspeed: 0.0421s/iter; left time: 813.1161s\n",
      "\titers: 200, epoch: 14 | loss: 0.1003755\n",
      "\tspeed: 0.0211s/iter; left time: 404.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.1031011 Vali Loss: 0.1248773 Test Loss: 0.1366268\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0999414\n",
      "\tspeed: 0.0372s/iter; left time: 709.8266s\n",
      "\titers: 200, epoch: 15 | loss: 0.0990071\n",
      "\tspeed: 0.0165s/iter; left time: 312.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1026213 Vali Loss: 0.1247777 Test Loss: 0.1364632\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1054942\n",
      "\tspeed: 0.0387s/iter; left time: 729.7293s\n",
      "\titers: 200, epoch: 16 | loss: 0.1023357\n",
      "\tspeed: 0.0191s/iter; left time: 357.8694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1021945 Vali Loss: 0.1252224 Test Loss: 0.1366782\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1022452\n",
      "\tspeed: 0.0379s/iter; left time: 705.3854s\n",
      "\titers: 200, epoch: 17 | loss: 0.0991455\n",
      "\tspeed: 0.0154s/iter; left time: 285.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1018964 Vali Loss: 0.1252745 Test Loss: 0.1368515\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1001951\n",
      "\tspeed: 0.0400s/iter; left time: 736.0715s\n",
      "\titers: 200, epoch: 18 | loss: 0.0983172\n",
      "\tspeed: 0.0169s/iter; left time: 310.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1015917 Vali Loss: 0.1256364 Test Loss: 0.1368796\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1051526\n",
      "\tspeed: 0.0371s/iter; left time: 674.0911s\n",
      "\titers: 200, epoch: 19 | loss: 0.0987805\n",
      "\tspeed: 0.0153s/iter; left time: 277.4451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.1013475 Vali Loss: 0.1255676 Test Loss: 0.1368964\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1039340\n",
      "\tspeed: 0.0375s/iter; left time: 674.4898s\n",
      "\titers: 200, epoch: 20 | loss: 0.0976061\n",
      "\tspeed: 0.0154s/iter; left time: 275.3022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.1010671 Vali Loss: 0.1256928 Test Loss: 0.1371456\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04075612500309944, rmse:0.20188146829605103, mae:0.1358145773410797, rse:0.7150803804397583\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:29.73s\n",
      "Intermediate time for DE: 00h:16m:26.38s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1408029\n",
      "\tspeed: 0.0384s/iter; left time: 856.0958s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220715\n",
      "\tspeed: 0.0150s/iter; left time: 332.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.1394795 Vali Loss: 0.1303381 Test Loss: 0.1521771\n",
      "Validation loss decreased (inf --> 0.130338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0838467\n",
      "\tspeed: 0.0343s/iter; left time: 757.1111s\n",
      "\titers: 200, epoch: 2 | loss: 0.0810687\n",
      "\tspeed: 0.0154s/iter; left time: 339.1778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0883854 Vali Loss: 0.0922935 Test Loss: 0.1038328\n",
      "Validation loss decreased (0.130338 --> 0.092294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813066\n",
      "\tspeed: 0.0338s/iter; left time: 739.2029s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811429\n",
      "\tspeed: 0.0152s/iter; left time: 329.6298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0800376 Vali Loss: 0.0906270 Test Loss: 0.1026502\n",
      "Validation loss decreased (0.092294 --> 0.090627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798900\n",
      "\tspeed: 0.0353s/iter; left time: 764.1054s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782969\n",
      "\tspeed: 0.0158s/iter; left time: 339.2909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0784506 Vali Loss: 0.0899711 Test Loss: 0.1023145\n",
      "Validation loss decreased (0.090627 --> 0.089971).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0802007\n",
      "\tspeed: 0.0342s/iter; left time: 732.0227s\n",
      "\titers: 200, epoch: 5 | loss: 0.0761889\n",
      "\tspeed: 0.0155s/iter; left time: 330.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0775106 Vali Loss: 0.0896766 Test Loss: 0.1023679\n",
      "Validation loss decreased (0.089971 --> 0.089677).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737546\n",
      "\tspeed: 0.0340s/iter; left time: 720.8107s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722272\n",
      "\tspeed: 0.0158s/iter; left time: 333.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0767953 Vali Loss: 0.0892543 Test Loss: 0.1016112\n",
      "Validation loss decreased (0.089677 --> 0.089254).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772201\n",
      "\tspeed: 0.0343s/iter; left time: 717.9556s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759338\n",
      "\tspeed: 0.0151s/iter; left time: 314.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0762198 Vali Loss: 0.0889135 Test Loss: 0.1021290\n",
      "Validation loss decreased (0.089254 --> 0.088914).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0737974\n",
      "\tspeed: 0.0337s/iter; left time: 698.3065s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742771\n",
      "\tspeed: 0.0157s/iter; left time: 323.8577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0758061 Vali Loss: 0.0888634 Test Loss: 0.1011181\n",
      "Validation loss decreased (0.088914 --> 0.088863).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776098\n",
      "\tspeed: 0.0365s/iter; left time: 749.1197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778834\n",
      "\tspeed: 0.0172s/iter; left time: 350.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0754323 Vali Loss: 0.0887642 Test Loss: 0.1017987\n",
      "Validation loss decreased (0.088863 --> 0.088764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783418\n",
      "\tspeed: 0.0342s/iter; left time: 693.6374s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797399\n",
      "\tspeed: 0.0158s/iter; left time: 319.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0750985 Vali Loss: 0.0884259 Test Loss: 0.1014588\n",
      "Validation loss decreased (0.088764 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765481\n",
      "\tspeed: 0.0382s/iter; left time: 766.6728s\n",
      "\titers: 200, epoch: 11 | loss: 0.0767598\n",
      "\tspeed: 0.0191s/iter; left time: 380.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0748397 Vali Loss: 0.0884989 Test Loss: 0.1009134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725433\n",
      "\tspeed: 0.0344s/iter; left time: 683.2909s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751468\n",
      "\tspeed: 0.0150s/iter; left time: 296.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0746248 Vali Loss: 0.0884313 Test Loss: 0.1013561\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761357\n",
      "\tspeed: 0.0344s/iter; left time: 674.6641s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725394\n",
      "\tspeed: 0.0163s/iter; left time: 317.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0744325 Vali Loss: 0.0881754 Test Loss: 0.1007002\n",
      "Validation loss decreased (0.088426 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779839\n",
      "\tspeed: 0.0362s/iter; left time: 702.5109s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749262\n",
      "\tspeed: 0.0217s/iter; left time: 419.1634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0742962 Vali Loss: 0.0882207 Test Loss: 0.1010617\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0688910\n",
      "\tspeed: 0.0391s/iter; left time: 749.4955s\n",
      "\titers: 200, epoch: 15 | loss: 0.0793659\n",
      "\tspeed: 0.0181s/iter; left time: 345.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0741033 Vali Loss: 0.0882980 Test Loss: 0.1009011\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0731619\n",
      "\tspeed: 0.0392s/iter; left time: 741.7162s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750202\n",
      "\tspeed: 0.0174s/iter; left time: 328.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0739156 Vali Loss: 0.0880635 Test Loss: 0.1010218\n",
      "Validation loss decreased (0.088175 --> 0.088063).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808460\n",
      "\tspeed: 0.0328s/iter; left time: 613.9804s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702096\n",
      "\tspeed: 0.0150s/iter; left time: 279.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0738391 Vali Loss: 0.0881552 Test Loss: 0.1009193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780886\n",
      "\tspeed: 0.0372s/iter; left time: 688.4836s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703475\n",
      "\tspeed: 0.0165s/iter; left time: 304.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0736550 Vali Loss: 0.0880305 Test Loss: 0.1005262\n",
      "Validation loss decreased (0.088063 --> 0.088030).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725428\n",
      "\tspeed: 0.0412s/iter; left time: 753.3311s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751350\n",
      "\tspeed: 0.0247s/iter; left time: 448.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0735561 Vali Loss: 0.0878773 Test Loss: 0.1006675\n",
      "Validation loss decreased (0.088030 --> 0.087877).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739074\n",
      "\tspeed: 0.0399s/iter; left time: 720.2743s\n",
      "\titers: 200, epoch: 20 | loss: 0.0685736\n",
      "\tspeed: 0.0150s/iter; left time: 269.3668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734560 Vali Loss: 0.0880576 Test Loss: 0.1006947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0714074\n",
      "\tspeed: 0.0343s/iter; left time: 610.6683s\n",
      "\titers: 200, epoch: 21 | loss: 0.0703999\n",
      "\tspeed: 0.0175s/iter; left time: 310.7305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0733898 Vali Loss: 0.0879714 Test Loss: 0.1007017\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0700551\n",
      "\tspeed: 0.0407s/iter; left time: 716.2715s\n",
      "\titers: 200, epoch: 22 | loss: 0.0725067\n",
      "\tspeed: 0.0178s/iter; left time: 311.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0733134 Vali Loss: 0.0880279 Test Loss: 0.1006018\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729847\n",
      "\tspeed: 0.0365s/iter; left time: 633.8070s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714305\n",
      "\tspeed: 0.0205s/iter; left time: 354.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0732090 Vali Loss: 0.0879985 Test Loss: 0.1007273\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0773718\n",
      "\tspeed: 0.0395s/iter; left time: 678.1698s\n",
      "\titers: 200, epoch: 24 | loss: 0.0762628\n",
      "\tspeed: 0.0209s/iter; left time: 356.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0732091 Vali Loss: 0.0879521 Test Loss: 0.1005794\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0739303\n",
      "\tspeed: 0.0361s/iter; left time: 610.2401s\n",
      "\titers: 200, epoch: 25 | loss: 0.0729150\n",
      "\tspeed: 0.0171s/iter; left time: 288.0530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0731054 Vali Loss: 0.0879082 Test Loss: 0.1006329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0745555\n",
      "\tspeed: 0.0346s/iter; left time: 578.4111s\n",
      "\titers: 200, epoch: 26 | loss: 0.0727787\n",
      "\tspeed: 0.0162s/iter; left time: 268.6249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0730196 Vali Loss: 0.0878684 Test Loss: 0.1007248\n",
      "Validation loss decreased (0.087877 --> 0.087868).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0761072\n",
      "\tspeed: 0.0395s/iter; left time: 651.3951s\n",
      "\titers: 200, epoch: 27 | loss: 0.0773405\n",
      "\tspeed: 0.0157s/iter; left time: 256.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0730278 Vali Loss: 0.0880038 Test Loss: 0.1007899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0735641\n",
      "\tspeed: 0.0390s/iter; left time: 633.8670s\n",
      "\titers: 200, epoch: 28 | loss: 0.0740679\n",
      "\tspeed: 0.0150s/iter; left time: 241.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0729844 Vali Loss: 0.0878147 Test Loss: 0.1007143\n",
      "Validation loss decreased (0.087868 --> 0.087815).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0745814\n",
      "\tspeed: 0.0341s/iter; left time: 547.1656s\n",
      "\titers: 200, epoch: 29 | loss: 0.0710949\n",
      "\tspeed: 0.0162s/iter; left time: 257.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0729766 Vali Loss: 0.0879899 Test Loss: 0.1007285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0715314\n",
      "\tspeed: 0.0337s/iter; left time: 532.3452s\n",
      "\titers: 200, epoch: 30 | loss: 0.0730101\n",
      "\tspeed: 0.0190s/iter; left time: 298.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0728889 Vali Loss: 0.0878834 Test Loss: 0.1006814\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0756869\n",
      "\tspeed: 0.0332s/iter; left time: 516.6626s\n",
      "\titers: 200, epoch: 31 | loss: 0.0730945\n",
      "\tspeed: 0.0176s/iter; left time: 272.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0728774 Vali Loss: 0.0878909 Test Loss: 0.1007599\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0711659\n",
      "\tspeed: 0.0335s/iter; left time: 514.6951s\n",
      "\titers: 200, epoch: 32 | loss: 0.0702189\n",
      "\tspeed: 0.0180s/iter; left time: 274.1315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0728344 Vali Loss: 0.0878091 Test Loss: 0.1006202\n",
      "Validation loss decreased (0.087815 --> 0.087809).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0729318\n",
      "\tspeed: 0.0347s/iter; left time: 525.5789s\n",
      "\titers: 200, epoch: 33 | loss: 0.0723447\n",
      "\tspeed: 0.0180s/iter; left time: 270.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0728347 Vali Loss: 0.0878830 Test Loss: 0.1007240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0718725\n",
      "\tspeed: 0.0384s/iter; left time: 572.9049s\n",
      "\titers: 200, epoch: 34 | loss: 0.0697967\n",
      "\tspeed: 0.0152s/iter; left time: 224.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0728157 Vali Loss: 0.0879759 Test Loss: 0.1006575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0755779\n",
      "\tspeed: 0.0356s/iter; left time: 522.4108s\n",
      "\titers: 200, epoch: 35 | loss: 0.0749521\n",
      "\tspeed: 0.0189s/iter; left time: 276.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0727617 Vali Loss: 0.0878920 Test Loss: 0.1006611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686863\n",
      "\tspeed: 0.0338s/iter; left time: 488.4751s\n",
      "\titers: 200, epoch: 36 | loss: 0.0681522\n",
      "\tspeed: 0.0160s/iter; left time: 229.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0727965 Vali Loss: 0.0878360 Test Loss: 0.1006562\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0730847\n",
      "\tspeed: 0.0342s/iter; left time: 487.5345s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692500\n",
      "\tspeed: 0.0150s/iter; left time: 211.8312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0727670 Vali Loss: 0.0878591 Test Loss: 0.1005846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0715135\n",
      "\tspeed: 0.0338s/iter; left time: 473.9603s\n",
      "\titers: 200, epoch: 38 | loss: 0.0731504\n",
      "\tspeed: 0.0167s/iter; left time: 232.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0727103 Vali Loss: 0.0878406 Test Loss: 0.1006778\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0693577\n",
      "\tspeed: 0.0368s/iter; left time: 507.2610s\n",
      "\titers: 200, epoch: 39 | loss: 0.0713527\n",
      "\tspeed: 0.0186s/iter; left time: 255.1837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0727609 Vali Loss: 0.0877320 Test Loss: 0.1006733\n",
      "Validation loss decreased (0.087809 --> 0.087732).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0684860\n",
      "\tspeed: 0.0413s/iter; left time: 559.6970s\n",
      "\titers: 200, epoch: 40 | loss: 0.0680570\n",
      "\tspeed: 0.0159s/iter; left time: 214.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0726749 Vali Loss: 0.0878199 Test Loss: 0.1006442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0710978\n",
      "\tspeed: 0.0368s/iter; left time: 491.0566s\n",
      "\titers: 200, epoch: 41 | loss: 0.0750010\n",
      "\tspeed: 0.0158s/iter; left time: 208.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0727057 Vali Loss: 0.0877864 Test Loss: 0.1006729\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0762781\n",
      "\tspeed: 0.0334s/iter; left time: 438.6128s\n",
      "\titers: 200, epoch: 42 | loss: 0.0710198\n",
      "\tspeed: 0.0150s/iter; left time: 195.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0727418 Vali Loss: 0.0878837 Test Loss: 0.1006545\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0734228\n",
      "\tspeed: 0.0399s/iter; left time: 514.1314s\n",
      "\titers: 200, epoch: 43 | loss: 0.0763203\n",
      "\tspeed: 0.0195s/iter; left time: 249.6712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0726992 Vali Loss: 0.0878944 Test Loss: 0.1006799\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0732810\n",
      "\tspeed: 0.0351s/iter; left time: 445.0388s\n",
      "\titers: 200, epoch: 44 | loss: 0.0686441\n",
      "\tspeed: 0.0171s/iter; left time: 214.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0726955 Vali Loss: 0.0878785 Test Loss: 0.1006678\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0723467\n",
      "\tspeed: 0.0375s/iter; left time: 466.9077s\n",
      "\titers: 200, epoch: 45 | loss: 0.0720298\n",
      "\tspeed: 0.0185s/iter; left time: 228.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0726699 Vali Loss: 0.0878067 Test Loss: 0.1006703\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0771320\n",
      "\tspeed: 0.0361s/iter; left time: 441.6862s\n",
      "\titers: 200, epoch: 46 | loss: 0.0774246\n",
      "\tspeed: 0.0177s/iter; left time: 214.7685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0726697 Vali Loss: 0.0878640 Test Loss: 0.1006538\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0711296\n",
      "\tspeed: 0.0342s/iter; left time: 410.4987s\n",
      "\titers: 200, epoch: 47 | loss: 0.0677945\n",
      "\tspeed: 0.0156s/iter; left time: 185.5450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0726275 Vali Loss: 0.0878923 Test Loss: 0.1006669\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0696700\n",
      "\tspeed: 0.0334s/iter; left time: 393.3209s\n",
      "\titers: 200, epoch: 48 | loss: 0.0726412\n",
      "\tspeed: 0.0160s/iter; left time: 186.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0726417 Vali Loss: 0.0877637 Test Loss: 0.1006608\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0740207\n",
      "\tspeed: 0.0396s/iter; left time: 456.8185s\n",
      "\titers: 200, epoch: 49 | loss: 0.0715442\n",
      "\tspeed: 0.0164s/iter; left time: 188.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0726434 Vali Loss: 0.0877807 Test Loss: 0.1006912\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025688007473945618, rmse:0.16027478873729706, mae:0.10067335516214371, rse:0.5529025793075562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1359176\n",
      "\tspeed: 0.0177s/iter; left time: 393.6172s\n",
      "\titers: 200, epoch: 1 | loss: 0.1237862\n",
      "\tspeed: 0.0150s/iter; left time: 331.9743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1350644 Vali Loss: 0.1265337 Test Loss: 0.1471120\n",
      "Validation loss decreased (inf --> 0.126534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0822858\n",
      "\tspeed: 0.0383s/iter; left time: 846.0839s\n",
      "\titers: 200, epoch: 2 | loss: 0.0843877\n",
      "\tspeed: 0.0159s/iter; left time: 349.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0877622 Vali Loss: 0.0920928 Test Loss: 0.1035819\n",
      "Validation loss decreased (0.126534 --> 0.092093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795637\n",
      "\tspeed: 0.0341s/iter; left time: 746.2171s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806163\n",
      "\tspeed: 0.0156s/iter; left time: 339.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0800861 Vali Loss: 0.0909713 Test Loss: 0.1028185\n",
      "Validation loss decreased (0.092093 --> 0.090971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0742611\n",
      "\tspeed: 0.0348s/iter; left time: 752.0801s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792782\n",
      "\tspeed: 0.0156s/iter; left time: 335.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0784736 Vali Loss: 0.0905463 Test Loss: 0.1019813\n",
      "Validation loss decreased (0.090971 --> 0.090546).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0745784\n",
      "\tspeed: 0.0342s/iter; left time: 731.4407s\n",
      "\titers: 200, epoch: 5 | loss: 0.0746641\n",
      "\tspeed: 0.0150s/iter; left time: 320.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0774669 Vali Loss: 0.0897166 Test Loss: 0.1022086\n",
      "Validation loss decreased (0.090546 --> 0.089717).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0746588\n",
      "\tspeed: 0.0338s/iter; left time: 716.7045s\n",
      "\titers: 200, epoch: 6 | loss: 0.0755551\n",
      "\tspeed: 0.0149s/iter; left time: 314.4027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0768000 Vali Loss: 0.0893867 Test Loss: 0.1016450\n",
      "Validation loss decreased (0.089717 --> 0.089387).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844807\n",
      "\tspeed: 0.0363s/iter; left time: 761.5214s\n",
      "\titers: 200, epoch: 7 | loss: 0.0720557\n",
      "\tspeed: 0.0156s/iter; left time: 324.3411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0762560 Vali Loss: 0.0890488 Test Loss: 0.1016352\n",
      "Validation loss decreased (0.089387 --> 0.089049).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0762478\n",
      "\tspeed: 0.0352s/iter; left time: 729.5889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758487\n",
      "\tspeed: 0.0176s/iter; left time: 364.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0757723 Vali Loss: 0.0889693 Test Loss: 0.1014884\n",
      "Validation loss decreased (0.089049 --> 0.088969).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0710059\n",
      "\tspeed: 0.0374s/iter; left time: 766.7086s\n",
      "\titers: 200, epoch: 9 | loss: 0.0739908\n",
      "\tspeed: 0.0150s/iter; left time: 305.9504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0754611 Vali Loss: 0.0888337 Test Loss: 0.1011940\n",
      "Validation loss decreased (0.088969 --> 0.088834).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787651\n",
      "\tspeed: 0.0383s/iter; left time: 776.8344s\n",
      "\titers: 200, epoch: 10 | loss: 0.0709229\n",
      "\tspeed: 0.0173s/iter; left time: 348.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0751017 Vali Loss: 0.0887285 Test Loss: 0.1012351\n",
      "Validation loss decreased (0.088834 --> 0.088729).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762169\n",
      "\tspeed: 0.0367s/iter; left time: 735.9555s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676789\n",
      "\tspeed: 0.0168s/iter; left time: 335.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0748797 Vali Loss: 0.0885299 Test Loss: 0.1010573\n",
      "Validation loss decreased (0.088729 --> 0.088530).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0656144\n",
      "\tspeed: 0.0339s/iter; left time: 672.8140s\n",
      "\titers: 200, epoch: 12 | loss: 0.0753150\n",
      "\tspeed: 0.0155s/iter; left time: 306.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0746369 Vali Loss: 0.0884178 Test Loss: 0.1011004\n",
      "Validation loss decreased (0.088530 --> 0.088418).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0683142\n",
      "\tspeed: 0.0345s/iter; left time: 676.1332s\n",
      "\titers: 200, epoch: 13 | loss: 0.0735927\n",
      "\tspeed: 0.0150s/iter; left time: 292.5672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0744430 Vali Loss: 0.0884843 Test Loss: 0.1010363\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758734\n",
      "\tspeed: 0.0379s/iter; left time: 735.7170s\n",
      "\titers: 200, epoch: 14 | loss: 0.0773935\n",
      "\tspeed: 0.0150s/iter; left time: 289.1854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0742171 Vali Loss: 0.0882327 Test Loss: 0.1009824\n",
      "Validation loss decreased (0.088418 --> 0.088233).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0726093\n",
      "\tspeed: 0.0334s/iter; left time: 639.9060s\n",
      "\titers: 200, epoch: 15 | loss: 0.0751845\n",
      "\tspeed: 0.0150s/iter; left time: 285.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 224 | Train Loss: 0.0740030 Vali Loss: 0.0883959 Test Loss: 0.1009312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0698116\n",
      "\tspeed: 0.0392s/iter; left time: 742.6279s\n",
      "\titers: 200, epoch: 16 | loss: 0.0771637\n",
      "\tspeed: 0.0182s/iter; left time: 342.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0739061 Vali Loss: 0.0883415 Test Loss: 0.1008478\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0752955\n",
      "\tspeed: 0.0334s/iter; left time: 624.2744s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744211\n",
      "\tspeed: 0.0149s/iter; left time: 278.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0737940 Vali Loss: 0.0881952 Test Loss: 0.1008427\n",
      "Validation loss decreased (0.088233 --> 0.088195).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0703673\n",
      "\tspeed: 0.0364s/iter; left time: 673.0150s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669557\n",
      "\tspeed: 0.0164s/iter; left time: 302.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0737238 Vali Loss: 0.0881428 Test Loss: 0.1009992\n",
      "Validation loss decreased (0.088195 --> 0.088143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0703847\n",
      "\tspeed: 0.0361s/iter; left time: 659.2790s\n",
      "\titers: 200, epoch: 19 | loss: 0.0756136\n",
      "\tspeed: 0.0150s/iter; left time: 271.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0735361 Vali Loss: 0.0881161 Test Loss: 0.1009621\n",
      "Validation loss decreased (0.088143 --> 0.088116).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0785401\n",
      "\tspeed: 0.0415s/iter; left time: 749.7543s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720342\n",
      "\tspeed: 0.0182s/iter; left time: 326.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0734682 Vali Loss: 0.0881935 Test Loss: 0.1009694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766241\n",
      "\tspeed: 0.0368s/iter; left time: 655.0196s\n",
      "\titers: 200, epoch: 21 | loss: 0.0695508\n",
      "\tspeed: 0.0150s/iter; left time: 265.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0733689 Vali Loss: 0.0880806 Test Loss: 0.1008465\n",
      "Validation loss decreased (0.088116 --> 0.088081).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706942\n",
      "\tspeed: 0.0335s/iter; left time: 589.1892s\n",
      "\titers: 200, epoch: 22 | loss: 0.0706000\n",
      "\tspeed: 0.0150s/iter; left time: 262.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0732897 Vali Loss: 0.0880706 Test Loss: 0.1010620\n",
      "Validation loss decreased (0.088081 --> 0.088071).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0741193\n",
      "\tspeed: 0.0342s/iter; left time: 594.0316s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724776\n",
      "\tspeed: 0.0150s/iter; left time: 259.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0732011 Vali Loss: 0.0879416 Test Loss: 0.1008240\n",
      "Validation loss decreased (0.088071 --> 0.087942).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0806744\n",
      "\tspeed: 0.0341s/iter; left time: 584.0962s\n",
      "\titers: 200, epoch: 24 | loss: 0.0713785\n",
      "\tspeed: 0.0150s/iter; left time: 255.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0880748 Test Loss: 0.1009895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0689403\n",
      "\tspeed: 0.0339s/iter; left time: 574.2572s\n",
      "\titers: 200, epoch: 25 | loss: 0.0729046\n",
      "\tspeed: 0.0165s/iter; left time: 276.8651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0730849 Vali Loss: 0.0879434 Test Loss: 0.1009023\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0746335\n",
      "\tspeed: 0.0362s/iter; left time: 605.3144s\n",
      "\titers: 200, epoch: 26 | loss: 0.0745048\n",
      "\tspeed: 0.0155s/iter; left time: 257.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0730684 Vali Loss: 0.0879964 Test Loss: 0.1008192\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0701253\n",
      "\tspeed: 0.0338s/iter; left time: 557.4870s\n",
      "\titers: 200, epoch: 27 | loss: 0.0730696\n",
      "\tspeed: 0.0158s/iter; left time: 258.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0729835 Vali Loss: 0.0880767 Test Loss: 0.1008227\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0695767\n",
      "\tspeed: 0.0358s/iter; left time: 582.0563s\n",
      "\titers: 200, epoch: 28 | loss: 0.0710038\n",
      "\tspeed: 0.0172s/iter; left time: 278.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0729653 Vali Loss: 0.0880181 Test Loss: 0.1009478\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0770177\n",
      "\tspeed: 0.0384s/iter; left time: 614.9844s\n",
      "\titers: 200, epoch: 29 | loss: 0.0710353\n",
      "\tspeed: 0.0166s/iter; left time: 264.9616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0729023 Vali Loss: 0.0879682 Test Loss: 0.1009113\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0697161\n",
      "\tspeed: 0.0331s/iter; left time: 522.4713s\n",
      "\titers: 200, epoch: 30 | loss: 0.0785530\n",
      "\tspeed: 0.0157s/iter; left time: 247.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0728675 Vali Loss: 0.0880093 Test Loss: 0.1007866\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705319\n",
      "\tspeed: 0.0355s/iter; left time: 552.7758s\n",
      "\titers: 200, epoch: 31 | loss: 0.0707693\n",
      "\tspeed: 0.0160s/iter; left time: 248.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0728785 Vali Loss: 0.0878595 Test Loss: 0.1010267\n",
      "Validation loss decreased (0.087942 --> 0.087859).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0783504\n",
      "\tspeed: 0.0390s/iter; left time: 599.3178s\n",
      "\titers: 200, epoch: 32 | loss: 0.0731988\n",
      "\tspeed: 0.0152s/iter; left time: 232.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0728380 Vali Loss: 0.0879082 Test Loss: 0.1008059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0729752\n",
      "\tspeed: 0.0337s/iter; left time: 510.5099s\n",
      "\titers: 200, epoch: 33 | loss: 0.0714536\n",
      "\tspeed: 0.0158s/iter; left time: 237.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0727974 Vali Loss: 0.0878810 Test Loss: 0.1009182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0730538\n",
      "\tspeed: 0.0341s/iter; left time: 508.7862s\n",
      "\titers: 200, epoch: 34 | loss: 0.0767054\n",
      "\tspeed: 0.0150s/iter; left time: 221.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0728525 Vali Loss: 0.0878566 Test Loss: 0.1009485\n",
      "Validation loss decreased (0.087859 --> 0.087857).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735576\n",
      "\tspeed: 0.0334s/iter; left time: 491.1460s\n",
      "\titers: 200, epoch: 35 | loss: 0.0814113\n",
      "\tspeed: 0.0150s/iter; left time: 218.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0727715 Vali Loss: 0.0879617 Test Loss: 0.1009069\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0656638\n",
      "\tspeed: 0.0353s/iter; left time: 511.1125s\n",
      "\titers: 200, epoch: 36 | loss: 0.0672448\n",
      "\tspeed: 0.0154s/iter; left time: 221.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0727151 Vali Loss: 0.0880251 Test Loss: 0.1009503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0732373\n",
      "\tspeed: 0.0406s/iter; left time: 577.5287s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692985\n",
      "\tspeed: 0.0192s/iter; left time: 271.9459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0727092 Vali Loss: 0.0878786 Test Loss: 0.1008640\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0743170\n",
      "\tspeed: 0.0352s/iter; left time: 493.2825s\n",
      "\titers: 200, epoch: 38 | loss: 0.0786708\n",
      "\tspeed: 0.0167s/iter; left time: 232.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0727368 Vali Loss: 0.0878699 Test Loss: 0.1008996\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0729692\n",
      "\tspeed: 0.0349s/iter; left time: 481.8892s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711635\n",
      "\tspeed: 0.0152s/iter; left time: 208.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0726836 Vali Loss: 0.0878715 Test Loss: 0.1009543\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0789950\n",
      "\tspeed: 0.0378s/iter; left time: 513.3200s\n",
      "\titers: 200, epoch: 40 | loss: 0.0732279\n",
      "\tspeed: 0.0164s/iter; left time: 220.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0727063 Vali Loss: 0.0880014 Test Loss: 0.1009281\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0720723\n",
      "\tspeed: 0.0330s/iter; left time: 440.0151s\n",
      "\titers: 200, epoch: 41 | loss: 0.0724575\n",
      "\tspeed: 0.0150s/iter; left time: 198.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0727321 Vali Loss: 0.0879272 Test Loss: 0.1009536\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0718250\n",
      "\tspeed: 0.0345s/iter; left time: 452.4212s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704483\n",
      "\tspeed: 0.0161s/iter; left time: 209.6091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0726884 Vali Loss: 0.0879183 Test Loss: 0.1008967\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0741829\n",
      "\tspeed: 0.0339s/iter; left time: 437.2305s\n",
      "\titers: 200, epoch: 43 | loss: 0.0716968\n",
      "\tspeed: 0.0157s/iter; left time: 201.0796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0726866 Vali Loss: 0.0878945 Test Loss: 0.1009186\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0755216\n",
      "\tspeed: 0.0341s/iter; left time: 431.6669s\n",
      "\titers: 200, epoch: 44 | loss: 0.0732390\n",
      "\tspeed: 0.0150s/iter; left time: 188.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0726649 Vali Loss: 0.0878734 Test Loss: 0.1009061\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025892343372106552, rmse:0.1609109789133072, mae:0.1009485051035881, rse:0.5550972819328308\n",
      "Intermediate time for GB and pred_len 24: 00h:08m:16.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1464807\n",
      "\tspeed: 0.0382s/iter; left time: 852.3032s\n",
      "\titers: 200, epoch: 1 | loss: 0.1339110\n",
      "\tspeed: 0.0153s/iter; left time: 339.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1435963 Vali Loss: 0.1385392 Test Loss: 0.1633495\n",
      "Validation loss decreased (inf --> 0.138539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108301\n",
      "\tspeed: 0.0362s/iter; left time: 800.0999s\n",
      "\titers: 200, epoch: 2 | loss: 0.1111001\n",
      "\tspeed: 0.0168s/iter; left time: 369.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1108053 Vali Loss: 0.1185568 Test Loss: 0.1400027\n",
      "Validation loss decreased (0.138539 --> 0.118557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053875\n",
      "\tspeed: 0.0393s/iter; left time: 858.7809s\n",
      "\titers: 200, epoch: 3 | loss: 0.1026320\n",
      "\tspeed: 0.0193s/iter; left time: 419.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1047060 Vali Loss: 0.1174756 Test Loss: 0.1414031\n",
      "Validation loss decreased (0.118557 --> 0.117476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1013440\n",
      "\tspeed: 0.0389s/iter; left time: 841.4392s\n",
      "\titers: 200, epoch: 4 | loss: 0.1018285\n",
      "\tspeed: 0.0217s/iter; left time: 466.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1030777 Vali Loss: 0.1173579 Test Loss: 0.1412462\n",
      "Validation loss decreased (0.117476 --> 0.117358).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023715\n",
      "\tspeed: 0.0381s/iter; left time: 816.4138s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012354\n",
      "\tspeed: 0.0210s/iter; left time: 447.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1020954 Vali Loss: 0.1173018 Test Loss: 0.1421996\n",
      "Validation loss decreased (0.117358 --> 0.117302).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1005838\n",
      "\tspeed: 0.0416s/iter; left time: 881.3740s\n",
      "\titers: 200, epoch: 6 | loss: 0.0990829\n",
      "\tspeed: 0.0168s/iter; left time: 354.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1010528 Vali Loss: 0.1163672 Test Loss: 0.1405692\n",
      "Validation loss decreased (0.117302 --> 0.116367).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036074\n",
      "\tspeed: 0.0391s/iter; left time: 819.9267s\n",
      "\titers: 200, epoch: 7 | loss: 0.0971777\n",
      "\tspeed: 0.0188s/iter; left time: 392.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1001650 Vali Loss: 0.1160881 Test Loss: 0.1422270\n",
      "Validation loss decreased (0.116367 --> 0.116088).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0971712\n",
      "\tspeed: 0.0362s/iter; left time: 751.0728s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009590\n",
      "\tspeed: 0.0183s/iter; left time: 377.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0993132 Vali Loss: 0.1162736 Test Loss: 0.1431388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0981892\n",
      "\tspeed: 0.0366s/iter; left time: 751.3918s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977690\n",
      "\tspeed: 0.0163s/iter; left time: 331.7823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0985008 Vali Loss: 0.1168711 Test Loss: 0.1422294\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0964508\n",
      "\tspeed: 0.0411s/iter; left time: 833.9758s\n",
      "\titers: 200, epoch: 10 | loss: 0.1008207\n",
      "\tspeed: 0.0159s/iter; left time: 321.1476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0979480 Vali Loss: 0.1169810 Test Loss: 0.1432338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0970866\n",
      "\tspeed: 0.0375s/iter; left time: 751.9210s\n",
      "\titers: 200, epoch: 11 | loss: 0.1026615\n",
      "\tspeed: 0.0175s/iter; left time: 349.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0973957 Vali Loss: 0.1166952 Test Loss: 0.1422242\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0952063\n",
      "\tspeed: 0.0360s/iter; left time: 713.5672s\n",
      "\titers: 200, epoch: 12 | loss: 0.0954418\n",
      "\tspeed: 0.0157s/iter; left time: 309.9514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0969392 Vali Loss: 0.1171512 Test Loss: 0.1435936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988464\n",
      "\tspeed: 0.0346s/iter; left time: 677.8956s\n",
      "\titers: 200, epoch: 13 | loss: 0.0955502\n",
      "\tspeed: 0.0151s/iter; left time: 293.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0965157 Vali Loss: 0.1174552 Test Loss: 0.1434177\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0952114\n",
      "\tspeed: 0.0381s/iter; left time: 739.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0927126\n",
      "\tspeed: 0.0174s/iter; left time: 335.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0961502 Vali Loss: 0.1172033 Test Loss: 0.1439700\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0956844\n",
      "\tspeed: 0.0384s/iter; left time: 736.5514s\n",
      "\titers: 200, epoch: 15 | loss: 0.0979720\n",
      "\tspeed: 0.0178s/iter; left time: 339.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0958619 Vali Loss: 0.1173282 Test Loss: 0.1442591\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0946395\n",
      "\tspeed: 0.0355s/iter; left time: 672.7536s\n",
      "\titers: 200, epoch: 16 | loss: 0.0946783\n",
      "\tspeed: 0.0151s/iter; left time: 284.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0955484 Vali Loss: 0.1174267 Test Loss: 0.1442727\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0975685\n",
      "\tspeed: 0.0375s/iter; left time: 701.9112s\n",
      "\titers: 200, epoch: 17 | loss: 0.0967622\n",
      "\tspeed: 0.0171s/iter; left time: 317.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0952776 Vali Loss: 0.1176038 Test Loss: 0.1435814\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0437089167535305, rmse:0.20906677842140198, mae:0.1422269642353058, rse:0.7229820489883423\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1483573\n",
      "\tspeed: 0.0208s/iter; left time: 462.9153s\n",
      "\titers: 200, epoch: 1 | loss: 0.1335595\n",
      "\tspeed: 0.0151s/iter; left time: 334.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1448874 Vali Loss: 0.1387068 Test Loss: 0.1635647\n",
      "Validation loss decreased (inf --> 0.138707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1135517\n",
      "\tspeed: 0.0373s/iter; left time: 824.3465s\n",
      "\titers: 200, epoch: 2 | loss: 0.1045652\n",
      "\tspeed: 0.0177s/iter; left time: 390.0209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1110517 Vali Loss: 0.1184260 Test Loss: 0.1397510\n",
      "Validation loss decreased (0.138707 --> 0.118426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069388\n",
      "\tspeed: 0.0389s/iter; left time: 850.4916s\n",
      "\titers: 200, epoch: 3 | loss: 0.1100883\n",
      "\tspeed: 0.0199s/iter; left time: 431.9628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1047683 Vali Loss: 0.1176687 Test Loss: 0.1415901\n",
      "Validation loss decreased (0.118426 --> 0.117669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1063060\n",
      "\tspeed: 0.0442s/iter; left time: 955.4800s\n",
      "\titers: 200, epoch: 4 | loss: 0.1074148\n",
      "\tspeed: 0.0173s/iter; left time: 372.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1030274 Vali Loss: 0.1168680 Test Loss: 0.1414879\n",
      "Validation loss decreased (0.117669 --> 0.116868).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1031246\n",
      "\tspeed: 0.0388s/iter; left time: 831.3835s\n",
      "\titers: 200, epoch: 5 | loss: 0.0976341\n",
      "\tspeed: 0.0168s/iter; left time: 358.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1018444 Vali Loss: 0.1165166 Test Loss: 0.1416522\n",
      "Validation loss decreased (0.116868 --> 0.116517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1009072\n",
      "\tspeed: 0.0374s/iter; left time: 792.9242s\n",
      "\titers: 200, epoch: 6 | loss: 0.1085383\n",
      "\tspeed: 0.0165s/iter; left time: 347.3765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1008019 Vali Loss: 0.1166348 Test Loss: 0.1433140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0994561\n",
      "\tspeed: 0.0367s/iter; left time: 768.4087s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075225\n",
      "\tspeed: 0.0151s/iter; left time: 314.0253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0998229 Vali Loss: 0.1162102 Test Loss: 0.1425487\n",
      "Validation loss decreased (0.116517 --> 0.116210).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994152\n",
      "\tspeed: 0.0384s/iter; left time: 796.1502s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013313\n",
      "\tspeed: 0.0184s/iter; left time: 379.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0990098 Vali Loss: 0.1166358 Test Loss: 0.1419476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0992478\n",
      "\tspeed: 0.0392s/iter; left time: 803.5034s\n",
      "\titers: 200, epoch: 9 | loss: 0.0964094\n",
      "\tspeed: 0.0184s/iter; left time: 375.4065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0982201 Vali Loss: 0.1166657 Test Loss: 0.1426085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954708\n",
      "\tspeed: 0.0379s/iter; left time: 769.5753s\n",
      "\titers: 200, epoch: 10 | loss: 0.0983775\n",
      "\tspeed: 0.0172s/iter; left time: 347.0179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0976414 Vali Loss: 0.1169606 Test Loss: 0.1438858\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003094\n",
      "\tspeed: 0.0395s/iter; left time: 792.1925s\n",
      "\titers: 200, epoch: 11 | loss: 0.0950748\n",
      "\tspeed: 0.0174s/iter; left time: 347.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0970598 Vali Loss: 0.1178075 Test Loss: 0.1449654\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0950094\n",
      "\tspeed: 0.0381s/iter; left time: 755.7995s\n",
      "\titers: 200, epoch: 12 | loss: 0.0963108\n",
      "\tspeed: 0.0167s/iter; left time: 328.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0966226 Vali Loss: 0.1169189 Test Loss: 0.1428664\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961957\n",
      "\tspeed: 0.0359s/iter; left time: 704.7669s\n",
      "\titers: 200, epoch: 13 | loss: 0.0952444\n",
      "\tspeed: 0.0151s/iter; left time: 294.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0961550 Vali Loss: 0.1175623 Test Loss: 0.1449113\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0946733\n",
      "\tspeed: 0.0400s/iter; left time: 774.8569s\n",
      "\titers: 200, epoch: 14 | loss: 0.0962060\n",
      "\tspeed: 0.0160s/iter; left time: 308.5850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0957776 Vali Loss: 0.1177664 Test Loss: 0.1448065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0880322\n",
      "\tspeed: 0.0390s/iter; left time: 748.1948s\n",
      "\titers: 200, epoch: 15 | loss: 0.0904843\n",
      "\tspeed: 0.0177s/iter; left time: 336.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0953828 Vali Loss: 0.1182412 Test Loss: 0.1448159\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0913855\n",
      "\tspeed: 0.0379s/iter; left time: 717.0760s\n",
      "\titers: 200, epoch: 16 | loss: 0.0911133\n",
      "\tspeed: 0.0155s/iter; left time: 291.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0950397 Vali Loss: 0.1180615 Test Loss: 0.1445071\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0947852\n",
      "\tspeed: 0.0390s/iter; left time: 730.6880s\n",
      "\titers: 200, epoch: 17 | loss: 0.0975491\n",
      "\tspeed: 0.0188s/iter; left time: 349.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0947904 Vali Loss: 0.1183730 Test Loss: 0.1455977\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04340295493602753, rmse:0.20833376049995422, mae:0.14254872500896454, rse:0.7204471826553345\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:20.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1477975\n",
      "\tspeed: 0.0394s/iter; left time: 874.3631s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0191s/iter; left time: 421.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.1446544 Vali Loss: 0.1404012 Test Loss: 0.1657628\n",
      "Validation loss decreased (inf --> 0.140401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182125\n",
      "\tspeed: 0.0385s/iter; left time: 847.1261s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102384\n",
      "\tspeed: 0.0173s/iter; left time: 377.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1153861 Vali Loss: 0.1230363 Test Loss: 0.1469368\n",
      "Validation loss decreased (0.140401 --> 0.123036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1079936\n",
      "\tspeed: 0.0381s/iter; left time: 829.5669s\n",
      "\titers: 200, epoch: 3 | loss: 0.1093975\n",
      "\tspeed: 0.0177s/iter; left time: 383.0345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1094925 Vali Loss: 0.1216000 Test Loss: 0.1470946\n",
      "Validation loss decreased (0.123036 --> 0.121600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1063738\n",
      "\tspeed: 0.0413s/iter; left time: 888.5787s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092678\n",
      "\tspeed: 0.0169s/iter; left time: 361.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1076454 Vali Loss: 0.1222603 Test Loss: 0.1490110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1073611\n",
      "\tspeed: 0.0392s/iter; left time: 835.5205s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071665\n",
      "\tspeed: 0.0192s/iter; left time: 406.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1062244 Vali Loss: 0.1216785 Test Loss: 0.1476179\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1029608\n",
      "\tspeed: 0.0363s/iter; left time: 765.3223s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022937\n",
      "\tspeed: 0.0164s/iter; left time: 345.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.1047133 Vali Loss: 0.1216168 Test Loss: 0.1480931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014383\n",
      "\tspeed: 0.0369s/iter; left time: 770.3467s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044426\n",
      "\tspeed: 0.0157s/iter; left time: 325.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1036095 Vali Loss: 0.1215207 Test Loss: 0.1481168\n",
      "Validation loss decreased (0.121600 --> 0.121521).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1046117\n",
      "\tspeed: 0.0356s/iter; left time: 735.1087s\n",
      "\titers: 200, epoch: 8 | loss: 0.1001345\n",
      "\tspeed: 0.0153s/iter; left time: 315.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1027809 Vali Loss: 0.1216274 Test Loss: 0.1474974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1017520\n",
      "\tspeed: 0.0386s/iter; left time: 788.7291s\n",
      "\titers: 200, epoch: 9 | loss: 0.1024707\n",
      "\tspeed: 0.0164s/iter; left time: 332.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.1020090 Vali Loss: 0.1216672 Test Loss: 0.1507545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1014575\n",
      "\tspeed: 0.0415s/iter; left time: 838.8525s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068425\n",
      "\tspeed: 0.0190s/iter; left time: 382.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1013790 Vali Loss: 0.1224590 Test Loss: 0.1511485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1007545\n",
      "\tspeed: 0.0358s/iter; left time: 714.1558s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064068\n",
      "\tspeed: 0.0154s/iter; left time: 305.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1008511 Vali Loss: 0.1220196 Test Loss: 0.1480358\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996748\n",
      "\tspeed: 0.0389s/iter; left time: 768.4779s\n",
      "\titers: 200, epoch: 12 | loss: 0.1018326\n",
      "\tspeed: 0.0228s/iter; left time: 448.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.1003750 Vali Loss: 0.1224540 Test Loss: 0.1507005\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0989276\n",
      "\tspeed: 0.0365s/iter; left time: 713.0247s\n",
      "\titers: 200, epoch: 13 | loss: 0.0984275\n",
      "\tspeed: 0.0154s/iter; left time: 298.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0998748 Vali Loss: 0.1222923 Test Loss: 0.1502105\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007655\n",
      "\tspeed: 0.0383s/iter; left time: 738.3637s\n",
      "\titers: 200, epoch: 14 | loss: 0.0957097\n",
      "\tspeed: 0.0168s/iter; left time: 322.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0995233 Vali Loss: 0.1230057 Test Loss: 0.1523806\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0975383\n",
      "\tspeed: 0.0356s/iter; left time: 679.4668s\n",
      "\titers: 200, epoch: 15 | loss: 0.0983925\n",
      "\tspeed: 0.0154s/iter; left time: 291.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0991967 Vali Loss: 0.1225890 Test Loss: 0.1503948\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0996271\n",
      "\tspeed: 0.0389s/iter; left time: 733.0675s\n",
      "\titers: 200, epoch: 16 | loss: 0.0969388\n",
      "\tspeed: 0.0174s/iter; left time: 325.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0987937 Vali Loss: 0.1224905 Test Loss: 0.1509960\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0964561\n",
      "\tspeed: 0.0367s/iter; left time: 682.9516s\n",
      "\titers: 200, epoch: 17 | loss: 0.0985527\n",
      "\tspeed: 0.0153s/iter; left time: 283.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0985206 Vali Loss: 0.1225557 Test Loss: 0.1503801\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045974038541316986, rmse:0.21441558003425598, mae:0.14811687171459198, rse:0.7434096336364746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1485232\n",
      "\tspeed: 0.0220s/iter; left time: 489.0875s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326798\n",
      "\tspeed: 0.0195s/iter; left time: 430.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.1462089 Vali Loss: 0.1411625 Test Loss: 0.1666872\n",
      "Validation loss decreased (inf --> 0.141162).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1128631\n",
      "\tspeed: 0.0375s/iter; left time: 823.0771s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095340\n",
      "\tspeed: 0.0153s/iter; left time: 335.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1152889 Vali Loss: 0.1229838 Test Loss: 0.1473348\n",
      "Validation loss decreased (0.141162 --> 0.122984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1077277\n",
      "\tspeed: 0.0362s/iter; left time: 786.6052s\n",
      "\titers: 200, epoch: 3 | loss: 0.1124109\n",
      "\tspeed: 0.0154s/iter; left time: 332.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.1093560 Vali Loss: 0.1221005 Test Loss: 0.1468865\n",
      "Validation loss decreased (0.122984 --> 0.122100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1085389\n",
      "\tspeed: 0.0407s/iter; left time: 875.7140s\n",
      "\titers: 200, epoch: 4 | loss: 0.1043095\n",
      "\tspeed: 0.0154s/iter; left time: 329.4499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.1076055 Vali Loss: 0.1215019 Test Loss: 0.1473855\n",
      "Validation loss decreased (0.122100 --> 0.121502).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1025974\n",
      "\tspeed: 0.0378s/iter; left time: 805.5952s\n",
      "\titers: 200, epoch: 5 | loss: 0.1006435\n",
      "\tspeed: 0.0153s/iter; left time: 324.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.1061568 Vali Loss: 0.1214991 Test Loss: 0.1484127\n",
      "Validation loss decreased (0.121502 --> 0.121499).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1014197\n",
      "\tspeed: 0.0358s/iter; left time: 755.3156s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056328\n",
      "\tspeed: 0.0153s/iter; left time: 321.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.1048112 Vali Loss: 0.1219019 Test Loss: 0.1487847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1069436\n",
      "\tspeed: 0.0378s/iter; left time: 787.6861s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031824\n",
      "\tspeed: 0.0173s/iter; left time: 358.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1037841 Vali Loss: 0.1216576 Test Loss: 0.1495134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024936\n",
      "\tspeed: 0.0433s/iter; left time: 893.1138s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013833\n",
      "\tspeed: 0.0222s/iter; left time: 455.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.1027837 Vali Loss: 0.1214212 Test Loss: 0.1503495\n",
      "Validation loss decreased (0.121499 --> 0.121421).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1029446\n",
      "\tspeed: 0.0451s/iter; left time: 920.6645s\n",
      "\titers: 200, epoch: 9 | loss: 0.0999009\n",
      "\tspeed: 0.0196s/iter; left time: 399.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1020559 Vali Loss: 0.1214604 Test Loss: 0.1512178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037995\n",
      "\tspeed: 0.0435s/iter; left time: 877.4338s\n",
      "\titers: 200, epoch: 10 | loss: 0.1004231\n",
      "\tspeed: 0.0160s/iter; left time: 322.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1013065 Vali Loss: 0.1217448 Test Loss: 0.1508195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1018958\n",
      "\tspeed: 0.0403s/iter; left time: 804.8046s\n",
      "\titers: 200, epoch: 11 | loss: 0.0977842\n",
      "\tspeed: 0.0180s/iter; left time: 357.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1007819 Vali Loss: 0.1215730 Test Loss: 0.1511723\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0988090\n",
      "\tspeed: 0.0374s/iter; left time: 739.1024s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971303\n",
      "\tspeed: 0.0178s/iter; left time: 350.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1002772 Vali Loss: 0.1216078 Test Loss: 0.1502636\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0991449\n",
      "\tspeed: 0.0372s/iter; left time: 726.6279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0983632\n",
      "\tspeed: 0.0153s/iter; left time: 298.1071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.0997312 Vali Loss: 0.1216895 Test Loss: 0.1517303\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0970275\n",
      "\tspeed: 0.0401s/iter; left time: 774.4089s\n",
      "\titers: 200, epoch: 14 | loss: 0.0997231\n",
      "\tspeed: 0.0186s/iter; left time: 356.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0992422 Vali Loss: 0.1217686 Test Loss: 0.1520171\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0999122\n",
      "\tspeed: 0.0368s/iter; left time: 702.4541s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981217\n",
      "\tspeed: 0.0159s/iter; left time: 301.9961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0988474 Vali Loss: 0.1223386 Test Loss: 0.1520432\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1005419\n",
      "\tspeed: 0.0378s/iter; left time: 712.6622s\n",
      "\titers: 200, epoch: 16 | loss: 0.0979159\n",
      "\tspeed: 0.0166s/iter; left time: 311.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0984472 Vali Loss: 0.1221021 Test Loss: 0.1520024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0976054\n",
      "\tspeed: 0.0376s/iter; left time: 700.3440s\n",
      "\titers: 200, epoch: 17 | loss: 0.0958428\n",
      "\tspeed: 0.0175s/iter; left time: 323.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0981649 Vali Loss: 0.1223424 Test Loss: 0.1528471\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0990245\n",
      "\tspeed: 0.0384s/iter; left time: 707.1603s\n",
      "\titers: 200, epoch: 18 | loss: 0.0965989\n",
      "\tspeed: 0.0182s/iter; left time: 333.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0978567 Vali Loss: 0.1221172 Test Loss: 0.1524515\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047312140464782715, rmse:0.2175135463476181, mae:0.15034949779510498, rse:0.7541506886482239\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:27.96s\n",
      "Intermediate time for GB: 00h:15m:05.23s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1472617\n",
      "\tspeed: 0.0395s/iter; left time: 880.2897s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270657\n",
      "\tspeed: 0.0176s/iter; left time: 390.5415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1529596 Vali Loss: 0.1144776 Test Loss: 0.1285696\n",
      "Validation loss decreased (inf --> 0.114478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0764008\n",
      "\tspeed: 0.0320s/iter; left time: 707.3402s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672378\n",
      "\tspeed: 0.0152s/iter; left time: 334.2194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0811919 Vali Loss: 0.0650535 Test Loss: 0.0721725\n",
      "Validation loss decreased (0.114478 --> 0.065053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697924\n",
      "\tspeed: 0.0326s/iter; left time: 713.4735s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655599\n",
      "\tspeed: 0.0167s/iter; left time: 363.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0678223 Vali Loss: 0.0616374 Test Loss: 0.0684299\n",
      "Validation loss decreased (0.065053 --> 0.061637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0617359\n",
      "\tspeed: 0.0324s/iter; left time: 700.6466s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651039\n",
      "\tspeed: 0.0152s/iter; left time: 327.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0643864 Vali Loss: 0.0593651 Test Loss: 0.0659961\n",
      "Validation loss decreased (0.061637 --> 0.059365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612776\n",
      "\tspeed: 0.0329s/iter; left time: 705.2785s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621016\n",
      "\tspeed: 0.0169s/iter; left time: 360.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0622860 Vali Loss: 0.0583341 Test Loss: 0.0648153\n",
      "Validation loss decreased (0.059365 --> 0.058334).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601563\n",
      "\tspeed: 0.0316s/iter; left time: 670.3410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582275\n",
      "\tspeed: 0.0160s/iter; left time: 338.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0573691 Test Loss: 0.0637348\n",
      "Validation loss decreased (0.058334 --> 0.057369).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599583\n",
      "\tspeed: 0.0307s/iter; left time: 643.0972s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620039\n",
      "\tspeed: 0.0169s/iter; left time: 352.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0597635 Vali Loss: 0.0567544 Test Loss: 0.0630717\n",
      "Validation loss decreased (0.057369 --> 0.056754).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591449\n",
      "\tspeed: 0.0318s/iter; left time: 659.9652s\n",
      "\titers: 200, epoch: 8 | loss: 0.0592528\n",
      "\tspeed: 0.0159s/iter; left time: 327.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0589754 Vali Loss: 0.0563358 Test Loss: 0.0625656\n",
      "Validation loss decreased (0.056754 --> 0.056336).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0572533\n",
      "\tspeed: 0.0342s/iter; left time: 700.5446s\n",
      "\titers: 200, epoch: 9 | loss: 0.0543959\n",
      "\tspeed: 0.0168s/iter; left time: 342.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0582308 Vali Loss: 0.0558458 Test Loss: 0.0622937\n",
      "Validation loss decreased (0.056336 --> 0.055846).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586669\n",
      "\tspeed: 0.0322s/iter; left time: 653.7829s\n",
      "\titers: 200, epoch: 10 | loss: 0.0573274\n",
      "\tspeed: 0.0158s/iter; left time: 318.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0577035 Vali Loss: 0.0553874 Test Loss: 0.0618086\n",
      "Validation loss decreased (0.055846 --> 0.055387).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0590035\n",
      "\tspeed: 0.0324s/iter; left time: 649.5312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585526\n",
      "\tspeed: 0.0161s/iter; left time: 320.6576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0572359 Vali Loss: 0.0551490 Test Loss: 0.0616998\n",
      "Validation loss decreased (0.055387 --> 0.055149).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0607780\n",
      "\tspeed: 0.0357s/iter; left time: 708.2459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0548319\n",
      "\tspeed: 0.0182s/iter; left time: 359.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0568701 Vali Loss: 0.0549978 Test Loss: 0.0614600\n",
      "Validation loss decreased (0.055149 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575080\n",
      "\tspeed: 0.0342s/iter; left time: 671.3134s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571135\n",
      "\tspeed: 0.0177s/iter; left time: 345.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0565177 Vali Loss: 0.0547642 Test Loss: 0.0613089\n",
      "Validation loss decreased (0.054998 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0551755\n",
      "\tspeed: 0.0320s/iter; left time: 620.1193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569541\n",
      "\tspeed: 0.0154s/iter; left time: 296.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0561891 Vali Loss: 0.0546994 Test Loss: 0.0611044\n",
      "Validation loss decreased (0.054764 --> 0.054699).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0515674\n",
      "\tspeed: 0.0308s/iter; left time: 589.7752s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551809\n",
      "\tspeed: 0.0173s/iter; left time: 329.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0559423 Vali Loss: 0.0544962 Test Loss: 0.0609704\n",
      "Validation loss decreased (0.054699 --> 0.054496).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0602068\n",
      "\tspeed: 0.0340s/iter; left time: 643.3606s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552587\n",
      "\tspeed: 0.0119s/iter; left time: 223.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 224 | Train Loss: 0.0557383 Vali Loss: 0.0544265 Test Loss: 0.0608705\n",
      "Validation loss decreased (0.054496 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0534508\n",
      "\tspeed: 0.0322s/iter; left time: 601.8865s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564713\n",
      "\tspeed: 0.0158s/iter; left time: 293.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0555938 Vali Loss: 0.0543226 Test Loss: 0.0608117\n",
      "Validation loss decreased (0.054427 --> 0.054323).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573428\n",
      "\tspeed: 0.0349s/iter; left time: 644.8167s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537848\n",
      "\tspeed: 0.0184s/iter; left time: 338.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0554106 Vali Loss: 0.0542706 Test Loss: 0.0606971\n",
      "Validation loss decreased (0.054323 --> 0.054271).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550534\n",
      "\tspeed: 0.0354s/iter; left time: 647.3054s\n",
      "\titers: 200, epoch: 19 | loss: 0.0558107\n",
      "\tspeed: 0.0179s/iter; left time: 325.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0552027 Vali Loss: 0.0540916 Test Loss: 0.0605637\n",
      "Validation loss decreased (0.054271 --> 0.054092).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0584598\n",
      "\tspeed: 0.0348s/iter; left time: 627.3724s\n",
      "\titers: 200, epoch: 20 | loss: 0.0512681\n",
      "\tspeed: 0.0177s/iter; left time: 317.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0551428 Vali Loss: 0.0540117 Test Loss: 0.0604790\n",
      "Validation loss decreased (0.054092 --> 0.054012).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0581162\n",
      "\tspeed: 0.0421s/iter; left time: 750.2755s\n",
      "\titers: 200, epoch: 21 | loss: 0.0554886\n",
      "\tspeed: 0.0180s/iter; left time: 319.6084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0549709 Vali Loss: 0.0540308 Test Loss: 0.0603956\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0541422\n",
      "\tspeed: 0.0384s/iter; left time: 675.8690s\n",
      "\titers: 200, epoch: 22 | loss: 0.0569617\n",
      "\tspeed: 0.0178s/iter; left time: 311.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0548899 Vali Loss: 0.0539734 Test Loss: 0.0603466\n",
      "Validation loss decreased (0.054012 --> 0.053973).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0563077\n",
      "\tspeed: 0.0360s/iter; left time: 625.6073s\n",
      "\titers: 200, epoch: 23 | loss: 0.0563497\n",
      "\tspeed: 0.0184s/iter; left time: 317.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0547798 Vali Loss: 0.0538734 Test Loss: 0.0603402\n",
      "Validation loss decreased (0.053973 --> 0.053873).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0527598\n",
      "\tspeed: 0.0329s/iter; left time: 564.0293s\n",
      "\titers: 200, epoch: 24 | loss: 0.0568597\n",
      "\tspeed: 0.0157s/iter; left time: 267.9039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0547481 Vali Loss: 0.0538175 Test Loss: 0.0602857\n",
      "Validation loss decreased (0.053873 --> 0.053817).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0493842\n",
      "\tspeed: 0.0336s/iter; left time: 568.6144s\n",
      "\titers: 200, epoch: 25 | loss: 0.0544027\n",
      "\tspeed: 0.0163s/iter; left time: 275.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0546226 Vali Loss: 0.0538801 Test Loss: 0.0603243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0580615\n",
      "\tspeed: 0.0317s/iter; left time: 529.3050s\n",
      "\titers: 200, epoch: 26 | loss: 0.0540778\n",
      "\tspeed: 0.0157s/iter; left time: 260.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0545455 Vali Loss: 0.0538199 Test Loss: 0.0602136\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572265\n",
      "\tspeed: 0.0325s/iter; left time: 535.0794s\n",
      "\titers: 200, epoch: 27 | loss: 0.0544031\n",
      "\tspeed: 0.0171s/iter; left time: 280.6028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0544826 Vali Loss: 0.0537360 Test Loss: 0.0601902\n",
      "Validation loss decreased (0.053817 --> 0.053736).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0538303\n",
      "\tspeed: 0.0311s/iter; left time: 505.0264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0551589\n",
      "\tspeed: 0.0155s/iter; left time: 250.0939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0544424 Vali Loss: 0.0537059 Test Loss: 0.0601137\n",
      "Validation loss decreased (0.053736 --> 0.053706).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0553337\n",
      "\tspeed: 0.0359s/iter; left time: 575.5613s\n",
      "\titers: 200, epoch: 29 | loss: 0.0533355\n",
      "\tspeed: 0.0155s/iter; left time: 246.5926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0544348 Vali Loss: 0.0537533 Test Loss: 0.0600940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0526477\n",
      "\tspeed: 0.0286s/iter; left time: 452.0002s\n",
      "\titers: 200, epoch: 30 | loss: 0.0525212\n",
      "\tspeed: 0.0140s/iter; left time: 219.4672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.0543426 Vali Loss: 0.0536811 Test Loss: 0.0601132\n",
      "Validation loss decreased (0.053706 --> 0.053681).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0535888\n",
      "\tspeed: 0.0349s/iter; left time: 543.0759s\n",
      "\titers: 200, epoch: 31 | loss: 0.0550774\n",
      "\tspeed: 0.0172s/iter; left time: 266.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0543355 Vali Loss: 0.0536017 Test Loss: 0.0600619\n",
      "Validation loss decreased (0.053681 --> 0.053602).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0529668\n",
      "\tspeed: 0.0327s/iter; left time: 502.7831s\n",
      "\titers: 200, epoch: 32 | loss: 0.0537781\n",
      "\tspeed: 0.0218s/iter; left time: 332.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0542805 Vali Loss: 0.0536844 Test Loss: 0.0600690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0530790\n",
      "\tspeed: 0.0350s/iter; left time: 529.9763s\n",
      "\titers: 200, epoch: 33 | loss: 0.0561320\n",
      "\tspeed: 0.0181s/iter; left time: 272.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0542772 Vali Loss: 0.0536642 Test Loss: 0.0600291\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547816\n",
      "\tspeed: 0.0355s/iter; left time: 529.2788s\n",
      "\titers: 200, epoch: 34 | loss: 0.0579684\n",
      "\tspeed: 0.0214s/iter; left time: 316.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0542418 Vali Loss: 0.0535975 Test Loss: 0.0600431\n",
      "Validation loss decreased (0.053602 --> 0.053597).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0537645\n",
      "\tspeed: 0.0363s/iter; left time: 533.1512s\n",
      "\titers: 200, epoch: 35 | loss: 0.0523877\n",
      "\tspeed: 0.0171s/iter; left time: 249.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0542327 Vali Loss: 0.0535786 Test Loss: 0.0600224\n",
      "Validation loss decreased (0.053597 --> 0.053579).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0553950\n",
      "\tspeed: 0.0341s/iter; left time: 492.7297s\n",
      "\titers: 200, epoch: 36 | loss: 0.0522558\n",
      "\tspeed: 0.0174s/iter; left time: 249.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0541670 Vali Loss: 0.0535862 Test Loss: 0.0599753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532314\n",
      "\tspeed: 0.0340s/iter; left time: 483.9508s\n",
      "\titers: 200, epoch: 37 | loss: 0.0542313\n",
      "\tspeed: 0.0181s/iter; left time: 256.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0541198 Vali Loss: 0.0535830 Test Loss: 0.0599396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0537845\n",
      "\tspeed: 0.0326s/iter; left time: 457.3298s\n",
      "\titers: 200, epoch: 38 | loss: 0.0532996\n",
      "\tspeed: 0.0179s/iter; left time: 249.3984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0541641 Vali Loss: 0.0535736 Test Loss: 0.0600272\n",
      "Validation loss decreased (0.053579 --> 0.053574).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526192\n",
      "\tspeed: 0.0323s/iter; left time: 446.0711s\n",
      "\titers: 200, epoch: 39 | loss: 0.0519480\n",
      "\tspeed: 0.0160s/iter; left time: 219.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0542182 Vali Loss: 0.0535153 Test Loss: 0.0599198\n",
      "Validation loss decreased (0.053574 --> 0.053515).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0526440\n",
      "\tspeed: 0.0336s/iter; left time: 456.0600s\n",
      "\titers: 200, epoch: 40 | loss: 0.0508640\n",
      "\tspeed: 0.0133s/iter; left time: 178.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0541809 Vali Loss: 0.0535721 Test Loss: 0.0599469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0548571\n",
      "\tspeed: 0.0333s/iter; left time: 444.3048s\n",
      "\titers: 200, epoch: 41 | loss: 0.0546414\n",
      "\tspeed: 0.0164s/iter; left time: 217.6670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0540777 Vali Loss: 0.0535765 Test Loss: 0.0599597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0539330\n",
      "\tspeed: 0.0312s/iter; left time: 409.5643s\n",
      "\titers: 200, epoch: 42 | loss: 0.0544378\n",
      "\tspeed: 0.0152s/iter; left time: 198.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0540990 Vali Loss: 0.0535763 Test Loss: 0.0599804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0515231\n",
      "\tspeed: 0.0314s/iter; left time: 405.1581s\n",
      "\titers: 200, epoch: 43 | loss: 0.0570885\n",
      "\tspeed: 0.0155s/iter; left time: 198.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0540799 Vali Loss: 0.0535924 Test Loss: 0.0599953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0566669\n",
      "\tspeed: 0.0323s/iter; left time: 409.3479s\n",
      "\titers: 200, epoch: 44 | loss: 0.0548820\n",
      "\tspeed: 0.0181s/iter; left time: 227.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0540833 Vali Loss: 0.0534712 Test Loss: 0.0599837\n",
      "Validation loss decreased (0.053515 --> 0.053471).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0570246\n",
      "\tspeed: 0.0345s/iter; left time: 429.3212s\n",
      "\titers: 200, epoch: 45 | loss: 0.0552215\n",
      "\tspeed: 0.0201s/iter; left time: 248.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0540127 Vali Loss: 0.0535750 Test Loss: 0.0599501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0536156\n",
      "\tspeed: 0.0350s/iter; left time: 427.8134s\n",
      "\titers: 200, epoch: 46 | loss: 0.0573239\n",
      "\tspeed: 0.0191s/iter; left time: 230.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0540944 Vali Loss: 0.0535047 Test Loss: 0.0599188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0520755\n",
      "\tspeed: 0.0322s/iter; left time: 386.8412s\n",
      "\titers: 200, epoch: 47 | loss: 0.0534585\n",
      "\tspeed: 0.0161s/iter; left time: 191.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0540301 Vali Loss: 0.0535193 Test Loss: 0.0599500\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0557514\n",
      "\tspeed: 0.0307s/iter; left time: 361.4213s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528659\n",
      "\tspeed: 0.0148s/iter; left time: 173.2371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0540583 Vali Loss: 0.0535084 Test Loss: 0.0599511\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0556433\n",
      "\tspeed: 0.0307s/iter; left time: 354.0400s\n",
      "\titers: 200, epoch: 49 | loss: 0.0555437\n",
      "\tspeed: 0.0173s/iter; left time: 197.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0540406 Vali Loss: 0.0534852 Test Loss: 0.0599190\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0529957\n",
      "\tspeed: 0.0310s/iter; left time: 351.1079s\n",
      "\titers: 200, epoch: 50 | loss: 0.0531824\n",
      "\tspeed: 0.0156s/iter; left time: 174.6293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0541148 Vali Loss: 0.0535448 Test Loss: 0.0599645\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0547251\n",
      "\tspeed: 0.0357s/iter; left time: 396.1375s\n",
      "\titers: 200, epoch: 51 | loss: 0.0559765\n",
      "\tspeed: 0.0187s/iter; left time: 205.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0540441 Vali Loss: 0.0534796 Test Loss: 0.0599179\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0526320\n",
      "\tspeed: 0.0323s/iter; left time: 351.5520s\n",
      "\titers: 200, epoch: 52 | loss: 0.0545090\n",
      "\tspeed: 0.0178s/iter; left time: 192.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0540496 Vali Loss: 0.0535315 Test Loss: 0.0598623\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0547153\n",
      "\tspeed: 0.0336s/iter; left time: 357.7257s\n",
      "\titers: 200, epoch: 53 | loss: 0.0532390\n",
      "\tspeed: 0.0183s/iter; left time: 192.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0539921 Vali Loss: 0.0535231 Test Loss: 0.0599793\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0517391\n",
      "\tspeed: 0.0358s/iter; left time: 373.6728s\n",
      "\titers: 200, epoch: 54 | loss: 0.0540907\n",
      "\tspeed: 0.0171s/iter; left time: 176.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0540350 Vali Loss: 0.0535709 Test Loss: 0.0599222\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009865866042673588, rmse:0.09932706505060196, mae:0.05998367443680763, rse:0.2923075556755066\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1611415\n",
      "\tspeed: 0.0192s/iter; left time: 429.0398s\n",
      "\titers: 200, epoch: 1 | loss: 0.1268540\n",
      "\tspeed: 0.0155s/iter; left time: 344.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.1588122 Vali Loss: 0.1167430 Test Loss: 0.1333303\n",
      "Validation loss decreased (inf --> 0.116743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0782896\n",
      "\tspeed: 0.0362s/iter; left time: 799.3861s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722682\n",
      "\tspeed: 0.0203s/iter; left time: 445.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0807641 Vali Loss: 0.0650539 Test Loss: 0.0717954\n",
      "Validation loss decreased (0.116743 --> 0.065054).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0663323\n",
      "\tspeed: 0.0317s/iter; left time: 692.3537s\n",
      "\titers: 200, epoch: 3 | loss: 0.0648648\n",
      "\tspeed: 0.0157s/iter; left time: 342.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0674660 Vali Loss: 0.0611912 Test Loss: 0.0678108\n",
      "Validation loss decreased (0.065054 --> 0.061191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0634658\n",
      "\tspeed: 0.0340s/iter; left time: 735.9465s\n",
      "\titers: 200, epoch: 4 | loss: 0.0640965\n",
      "\tspeed: 0.0179s/iter; left time: 384.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0641639 Vali Loss: 0.0593155 Test Loss: 0.0658204\n",
      "Validation loss decreased (0.061191 --> 0.059316).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630496\n",
      "\tspeed: 0.0323s/iter; left time: 692.2257s\n",
      "\titers: 200, epoch: 5 | loss: 0.0598906\n",
      "\tspeed: 0.0165s/iter; left time: 352.3269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0621149 Vali Loss: 0.0581182 Test Loss: 0.0645412\n",
      "Validation loss decreased (0.059316 --> 0.058118).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616817\n",
      "\tspeed: 0.0344s/iter; left time: 729.2624s\n",
      "\titers: 200, epoch: 6 | loss: 0.0606987\n",
      "\tspeed: 0.0170s/iter; left time: 359.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0606917 Vali Loss: 0.0575407 Test Loss: 0.0640190\n",
      "Validation loss decreased (0.058118 --> 0.057541).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0587055\n",
      "\tspeed: 0.0347s/iter; left time: 726.8533s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607607\n",
      "\tspeed: 0.0182s/iter; left time: 379.3942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0597081 Vali Loss: 0.0565296 Test Loss: 0.0628788\n",
      "Validation loss decreased (0.057541 --> 0.056530).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0577919\n",
      "\tspeed: 0.0333s/iter; left time: 690.3216s\n",
      "\titers: 200, epoch: 8 | loss: 0.0544849\n",
      "\tspeed: 0.0171s/iter; left time: 353.8544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0589525 Vali Loss: 0.0559611 Test Loss: 0.0624849\n",
      "Validation loss decreased (0.056530 --> 0.055961).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0591754\n",
      "\tspeed: 0.0314s/iter; left time: 643.7677s\n",
      "\titers: 200, epoch: 9 | loss: 0.0586939\n",
      "\tspeed: 0.0177s/iter; left time: 360.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0582325 Vali Loss: 0.0556815 Test Loss: 0.0623249\n",
      "Validation loss decreased (0.055961 --> 0.055681).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0550052\n",
      "\tspeed: 0.0321s/iter; left time: 650.7156s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594780\n",
      "\tspeed: 0.0158s/iter; left time: 319.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0576239 Vali Loss: 0.0552863 Test Loss: 0.0616748\n",
      "Validation loss decreased (0.055681 --> 0.055286).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0554350\n",
      "\tspeed: 0.0327s/iter; left time: 655.3765s\n",
      "\titers: 200, epoch: 11 | loss: 0.0557510\n",
      "\tspeed: 0.0168s/iter; left time: 334.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0572855 Vali Loss: 0.0552042 Test Loss: 0.0615346\n",
      "Validation loss decreased (0.055286 --> 0.055204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560821\n",
      "\tspeed: 0.0309s/iter; left time: 613.6833s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535479\n",
      "\tspeed: 0.0172s/iter; left time: 339.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0569391 Vali Loss: 0.0548631 Test Loss: 0.0613890\n",
      "Validation loss decreased (0.055204 --> 0.054863).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0585859\n",
      "\tspeed: 0.0349s/iter; left time: 684.1722s\n",
      "\titers: 200, epoch: 13 | loss: 0.0594604\n",
      "\tspeed: 0.0177s/iter; left time: 346.2892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0565858 Vali Loss: 0.0546589 Test Loss: 0.0611994\n",
      "Validation loss decreased (0.054863 --> 0.054659).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0574423\n",
      "\tspeed: 0.0330s/iter; left time: 640.4858s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555846\n",
      "\tspeed: 0.0163s/iter; left time: 313.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0562533 Vali Loss: 0.0544752 Test Loss: 0.0610455\n",
      "Validation loss decreased (0.054659 --> 0.054475).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574170\n",
      "\tspeed: 0.0315s/iter; left time: 603.5826s\n",
      "\titers: 200, epoch: 15 | loss: 0.0556960\n",
      "\tspeed: 0.0161s/iter; left time: 306.5414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0559833 Vali Loss: 0.0545037 Test Loss: 0.0610347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575818\n",
      "\tspeed: 0.0328s/iter; left time: 621.9040s\n",
      "\titers: 200, epoch: 16 | loss: 0.0563972\n",
      "\tspeed: 0.0177s/iter; left time: 334.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0557937 Vali Loss: 0.0544090 Test Loss: 0.0609273\n",
      "Validation loss decreased (0.054475 --> 0.054409).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0522419\n",
      "\tspeed: 0.0337s/iter; left time: 631.2015s\n",
      "\titers: 200, epoch: 17 | loss: 0.0578425\n",
      "\tspeed: 0.0181s/iter; left time: 337.4697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0555579 Vali Loss: 0.0541782 Test Loss: 0.0607166\n",
      "Validation loss decreased (0.054409 --> 0.054178).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0555325\n",
      "\tspeed: 0.0329s/iter; left time: 609.1570s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574589\n",
      "\tspeed: 0.0153s/iter; left time: 281.8704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0554005 Vali Loss: 0.0543410 Test Loss: 0.0607921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0557113\n",
      "\tspeed: 0.0354s/iter; left time: 647.5937s\n",
      "\titers: 200, epoch: 19 | loss: 0.0563946\n",
      "\tspeed: 0.0154s/iter; left time: 280.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0552850 Vali Loss: 0.0542294 Test Loss: 0.0607280\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0524264\n",
      "\tspeed: 0.0323s/iter; left time: 583.4069s\n",
      "\titers: 200, epoch: 20 | loss: 0.0566870\n",
      "\tspeed: 0.0183s/iter; left time: 329.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0551585 Vali Loss: 0.0539962 Test Loss: 0.0605864\n",
      "Validation loss decreased (0.054178 --> 0.053996).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0529983\n",
      "\tspeed: 0.0332s/iter; left time: 592.0558s\n",
      "\titers: 200, epoch: 21 | loss: 0.0570656\n",
      "\tspeed: 0.0149s/iter; left time: 264.6015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0550185 Vali Loss: 0.0540909 Test Loss: 0.0605701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0550057\n",
      "\tspeed: 0.0339s/iter; left time: 597.0561s\n",
      "\titers: 200, epoch: 22 | loss: 0.0588716\n",
      "\tspeed: 0.0203s/iter; left time: 354.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0549803 Vali Loss: 0.0538862 Test Loss: 0.0604518\n",
      "Validation loss decreased (0.053996 --> 0.053886).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0527419\n",
      "\tspeed: 0.0373s/iter; left time: 647.1554s\n",
      "\titers: 200, epoch: 23 | loss: 0.0534608\n",
      "\tspeed: 0.0194s/iter; left time: 334.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0548538 Vali Loss: 0.0538469 Test Loss: 0.0603574\n",
      "Validation loss decreased (0.053886 --> 0.053847).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0559095\n",
      "\tspeed: 0.0315s/iter; left time: 539.4043s\n",
      "\titers: 200, epoch: 24 | loss: 0.0546478\n",
      "\tspeed: 0.0156s/iter; left time: 265.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0547567 Vali Loss: 0.0538010 Test Loss: 0.0603754\n",
      "Validation loss decreased (0.053847 --> 0.053801).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0554652\n",
      "\tspeed: 0.0345s/iter; left time: 583.7768s\n",
      "\titers: 200, epoch: 25 | loss: 0.0572795\n",
      "\tspeed: 0.0125s/iter; left time: 210.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0546980 Vali Loss: 0.0538305 Test Loss: 0.0602854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0536041\n",
      "\tspeed: 0.0313s/iter; left time: 523.5566s\n",
      "\titers: 200, epoch: 26 | loss: 0.0501037\n",
      "\tspeed: 0.0168s/iter; left time: 278.6696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0546510 Vali Loss: 0.0537666 Test Loss: 0.0603857\n",
      "Validation loss decreased (0.053801 --> 0.053767).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0563762\n",
      "\tspeed: 0.0343s/iter; left time: 565.4407s\n",
      "\titers: 200, epoch: 27 | loss: 0.0538946\n",
      "\tspeed: 0.0161s/iter; left time: 262.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0545979 Vali Loss: 0.0537702 Test Loss: 0.0602635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0521253\n",
      "\tspeed: 0.0347s/iter; left time: 564.1491s\n",
      "\titers: 200, epoch: 28 | loss: 0.0537604\n",
      "\tspeed: 0.0172s/iter; left time: 277.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0545550 Vali Loss: 0.0536571 Test Loss: 0.0603112\n",
      "Validation loss decreased (0.053767 --> 0.053657).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0573157\n",
      "\tspeed: 0.0363s/iter; left time: 582.0923s\n",
      "\titers: 200, epoch: 29 | loss: 0.0560602\n",
      "\tspeed: 0.0162s/iter; left time: 258.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0544993 Vali Loss: 0.0538394 Test Loss: 0.0602524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0549836\n",
      "\tspeed: 0.0325s/iter; left time: 513.8470s\n",
      "\titers: 200, epoch: 30 | loss: 0.0534236\n",
      "\tspeed: 0.0163s/iter; left time: 256.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0544783 Vali Loss: 0.0536632 Test Loss: 0.0601725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0566648\n",
      "\tspeed: 0.0321s/iter; left time: 499.7045s\n",
      "\titers: 200, epoch: 31 | loss: 0.0543595\n",
      "\tspeed: 0.0179s/iter; left time: 277.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0544464 Vali Loss: 0.0537048 Test Loss: 0.0602124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0527624\n",
      "\tspeed: 0.0332s/iter; left time: 509.6487s\n",
      "\titers: 200, epoch: 32 | loss: 0.0539591\n",
      "\tspeed: 0.0155s/iter; left time: 236.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0543798 Vali Loss: 0.0536996 Test Loss: 0.0602297\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0523872\n",
      "\tspeed: 0.0326s/iter; left time: 493.3771s\n",
      "\titers: 200, epoch: 33 | loss: 0.0554522\n",
      "\tspeed: 0.0162s/iter; left time: 242.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0543936 Vali Loss: 0.0536801 Test Loss: 0.0601416\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0556251\n",
      "\tspeed: 0.0319s/iter; left time: 476.1093s\n",
      "\titers: 200, epoch: 34 | loss: 0.0582312\n",
      "\tspeed: 0.0157s/iter; left time: 232.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0543392 Vali Loss: 0.0536149 Test Loss: 0.0601553\n",
      "Validation loss decreased (0.053657 --> 0.053615).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0560500\n",
      "\tspeed: 0.0325s/iter; left time: 476.5456s\n",
      "\titers: 200, epoch: 35 | loss: 0.0506838\n",
      "\tspeed: 0.0167s/iter; left time: 244.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0542865 Vali Loss: 0.0536054 Test Loss: 0.0601218\n",
      "Validation loss decreased (0.053615 --> 0.053605).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0565769\n",
      "\tspeed: 0.0312s/iter; left time: 451.8656s\n",
      "\titers: 200, epoch: 36 | loss: 0.0560829\n",
      "\tspeed: 0.0155s/iter; left time: 222.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0543217 Vali Loss: 0.0536388 Test Loss: 0.0600952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0560940\n",
      "\tspeed: 0.0336s/iter; left time: 478.7305s\n",
      "\titers: 200, epoch: 37 | loss: 0.0536326\n",
      "\tspeed: 0.0160s/iter; left time: 225.9336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0542406 Vali Loss: 0.0536139 Test Loss: 0.0601257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0542543\n",
      "\tspeed: 0.0316s/iter; left time: 443.0960s\n",
      "\titers: 200, epoch: 38 | loss: 0.0539875\n",
      "\tspeed: 0.0130s/iter; left time: 181.2653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 224 | Train Loss: 0.0542799 Vali Loss: 0.0536442 Test Loss: 0.0600759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0531456\n",
      "\tspeed: 0.0298s/iter; left time: 410.4440s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543458\n",
      "\tspeed: 0.0151s/iter; left time: 207.3707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0541778 Vali Loss: 0.0536396 Test Loss: 0.0600868\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0551576\n",
      "\tspeed: 0.0306s/iter; left time: 415.3457s\n",
      "\titers: 200, epoch: 40 | loss: 0.0522833\n",
      "\tspeed: 0.0162s/iter; left time: 217.8727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0542236 Vali Loss: 0.0534882 Test Loss: 0.0600815\n",
      "Validation loss decreased (0.053605 --> 0.053488).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0595516\n",
      "\tspeed: 0.0320s/iter; left time: 426.4425s\n",
      "\titers: 200, epoch: 41 | loss: 0.0541378\n",
      "\tspeed: 0.0158s/iter; left time: 208.7324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0541811 Vali Loss: 0.0535883 Test Loss: 0.0600819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0557711\n",
      "\tspeed: 0.0323s/iter; left time: 423.8678s\n",
      "\titers: 200, epoch: 42 | loss: 0.0541469\n",
      "\tspeed: 0.0169s/iter; left time: 219.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0541743 Vali Loss: 0.0536318 Test Loss: 0.0601345\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0540865\n",
      "\tspeed: 0.0336s/iter; left time: 433.1275s\n",
      "\titers: 200, epoch: 43 | loss: 0.0551264\n",
      "\tspeed: 0.0156s/iter; left time: 199.1560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0541916 Vali Loss: 0.0536020 Test Loss: 0.0600599\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537366\n",
      "\tspeed: 0.0345s/iter; left time: 437.1498s\n",
      "\titers: 200, epoch: 44 | loss: 0.0514312\n",
      "\tspeed: 0.0160s/iter; left time: 201.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0542095 Vali Loss: 0.0536018 Test Loss: 0.0600907\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551771\n",
      "\tspeed: 0.0343s/iter; left time: 426.3972s\n",
      "\titers: 200, epoch: 45 | loss: 0.0536026\n",
      "\tspeed: 0.0167s/iter; left time: 206.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0541252 Vali Loss: 0.0536186 Test Loss: 0.0600570\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0535056\n",
      "\tspeed: 0.0323s/iter; left time: 394.3199s\n",
      "\titers: 200, epoch: 46 | loss: 0.0522256\n",
      "\tspeed: 0.0154s/iter; left time: 187.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0541536 Vali Loss: 0.0535456 Test Loss: 0.0600534\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0529868\n",
      "\tspeed: 0.0311s/iter; left time: 373.3468s\n",
      "\titers: 200, epoch: 47 | loss: 0.0523526\n",
      "\tspeed: 0.0155s/iter; left time: 184.7168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0541327 Vali Loss: 0.0535554 Test Loss: 0.0600694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522863\n",
      "\tspeed: 0.0352s/iter; left time: 414.8469s\n",
      "\titers: 200, epoch: 48 | loss: 0.0539552\n",
      "\tspeed: 0.0180s/iter; left time: 210.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0541890 Vali Loss: 0.0535787 Test Loss: 0.0600495\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0555330\n",
      "\tspeed: 0.0323s/iter; left time: 373.2566s\n",
      "\titers: 200, epoch: 49 | loss: 0.0567820\n",
      "\tspeed: 0.0158s/iter; left time: 181.3914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0541240 Vali Loss: 0.0536024 Test Loss: 0.0600337\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0527807\n",
      "\tspeed: 0.0349s/iter; left time: 394.9763s\n",
      "\titers: 200, epoch: 50 | loss: 0.0553038\n",
      "\tspeed: 0.0161s/iter; left time: 181.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0540975 Vali Loss: 0.0535645 Test Loss: 0.0600576\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009895199909806252, rmse:0.09947461634874344, mae:0.06008148938417435, rse:0.2927417755126953\n",
      "Intermediate time for ES and pred_len 24: 00h:08m:49.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1598105\n",
      "\tspeed: 0.0396s/iter; left time: 882.7335s\n",
      "\titers: 200, epoch: 1 | loss: 0.1323677\n",
      "\tspeed: 0.0154s/iter; left time: 340.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1563091 Vali Loss: 0.1220054 Test Loss: 0.1378020\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989023\n",
      "\tspeed: 0.0346s/iter; left time: 763.7621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922406\n",
      "\tspeed: 0.0130s/iter; left time: 285.3665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0986842 Vali Loss: 0.0867798 Test Loss: 0.0978109\n",
      "Validation loss decreased (0.122005 --> 0.086780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870436\n",
      "\tspeed: 0.0326s/iter; left time: 712.7257s\n",
      "\titers: 200, epoch: 3 | loss: 0.0854841\n",
      "\tspeed: 0.0166s/iter; left time: 361.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0874289 Vali Loss: 0.0815691 Test Loss: 0.0928535\n",
      "Validation loss decreased (0.086780 --> 0.081569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0864892\n",
      "\tspeed: 0.0324s/iter; left time: 701.0906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789671\n",
      "\tspeed: 0.0159s/iter; left time: 342.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0836981 Vali Loss: 0.0796518 Test Loss: 0.0907823\n",
      "Validation loss decreased (0.081569 --> 0.079652).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813103\n",
      "\tspeed: 0.0371s/iter; left time: 794.0558s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827484\n",
      "\tspeed: 0.0160s/iter; left time: 341.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0816990 Vali Loss: 0.0787125 Test Loss: 0.0895975\n",
      "Validation loss decreased (0.079652 --> 0.078713).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800737\n",
      "\tspeed: 0.0338s/iter; left time: 716.4005s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752990\n",
      "\tspeed: 0.0154s/iter; left time: 324.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0803113 Vali Loss: 0.0778247 Test Loss: 0.0889565\n",
      "Validation loss decreased (0.078713 --> 0.077825).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789210\n",
      "\tspeed: 0.0333s/iter; left time: 697.7869s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756818\n",
      "\tspeed: 0.0173s/iter; left time: 360.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0792497 Vali Loss: 0.0773080 Test Loss: 0.0883113\n",
      "Validation loss decreased (0.077825 --> 0.077308).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0813592\n",
      "\tspeed: 0.0371s/iter; left time: 769.5379s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797191\n",
      "\tspeed: 0.0120s/iter; left time: 246.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0784300 Vali Loss: 0.0769897 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.077308 --> 0.076990).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778591\n",
      "\tspeed: 0.0322s/iter; left time: 660.5282s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800109\n",
      "\tspeed: 0.0160s/iter; left time: 326.2531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0777183 Vali Loss: 0.0771957 Test Loss: 0.0878055\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0771751\n",
      "\tspeed: 0.0340s/iter; left time: 690.6601s\n",
      "\titers: 200, epoch: 10 | loss: 0.0770075\n",
      "\tspeed: 0.0177s/iter; left time: 357.5867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0771960 Vali Loss: 0.0773262 Test Loss: 0.0880145\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753757\n",
      "\tspeed: 0.0330s/iter; left time: 662.4890s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774721\n",
      "\tspeed: 0.0155s/iter; left time: 309.6655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0767264 Vali Loss: 0.0769818 Test Loss: 0.0878005\n",
      "Validation loss decreased (0.076990 --> 0.076982).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767876\n",
      "\tspeed: 0.0334s/iter; left time: 663.3318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779550\n",
      "\tspeed: 0.0155s/iter; left time: 306.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0763607 Vali Loss: 0.0771153 Test Loss: 0.0876895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749844\n",
      "\tspeed: 0.0358s/iter; left time: 702.1293s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752065\n",
      "\tspeed: 0.0204s/iter; left time: 397.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0760326 Vali Loss: 0.0774750 Test Loss: 0.0875740\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715508\n",
      "\tspeed: 0.0367s/iter; left time: 711.2940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734959\n",
      "\tspeed: 0.0177s/iter; left time: 341.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0756991 Vali Loss: 0.0771718 Test Loss: 0.0875562\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778454\n",
      "\tspeed: 0.0321s/iter; left time: 616.1117s\n",
      "\titers: 200, epoch: 15 | loss: 0.0767315\n",
      "\tspeed: 0.0144s/iter; left time: 274.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 224 | Train Loss: 0.0753907 Vali Loss: 0.0773028 Test Loss: 0.0875162\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736728\n",
      "\tspeed: 0.0331s/iter; left time: 626.8594s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731484\n",
      "\tspeed: 0.0164s/iter; left time: 309.7911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0752085 Vali Loss: 0.0774523 Test Loss: 0.0875667\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0803624\n",
      "\tspeed: 0.0351s/iter; left time: 657.5070s\n",
      "\titers: 200, epoch: 17 | loss: 0.0747879\n",
      "\tspeed: 0.0155s/iter; left time: 288.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0749522 Vali Loss: 0.0777390 Test Loss: 0.0877483\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756685\n",
      "\tspeed: 0.0336s/iter; left time: 621.8951s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760199\n",
      "\tspeed: 0.0161s/iter; left time: 296.2482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0747363 Vali Loss: 0.0774303 Test Loss: 0.0876735\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725631\n",
      "\tspeed: 0.0351s/iter; left time: 641.5516s\n",
      "\titers: 200, epoch: 19 | loss: 0.0743213\n",
      "\tspeed: 0.0152s/iter; left time: 276.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0745701 Vali Loss: 0.0775832 Test Loss: 0.0877615\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0721331\n",
      "\tspeed: 0.0349s/iter; left time: 629.5114s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723300\n",
      "\tspeed: 0.0175s/iter; left time: 313.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0744506 Vali Loss: 0.0776916 Test Loss: 0.0877296\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0722935\n",
      "\tspeed: 0.0338s/iter; left time: 601.5176s\n",
      "\titers: 200, epoch: 21 | loss: 0.0746893\n",
      "\tspeed: 0.0124s/iter; left time: 219.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 224 | Train Loss: 0.0742738 Vali Loss: 0.0776583 Test Loss: 0.0876513\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01882317289710045, rmse:0.1371975690126419, mae:0.08780049532651901, rse:0.4030451774597168\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600386\n",
      "\tspeed: 0.0166s/iter; left time: 369.6377s\n",
      "\titers: 200, epoch: 1 | loss: 0.1320430\n",
      "\tspeed: 0.0166s/iter; left time: 367.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1580584 Vali Loss: 0.1241672 Test Loss: 0.1401724\n",
      "Validation loss decreased (inf --> 0.124167).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936015\n",
      "\tspeed: 0.0368s/iter; left time: 811.7360s\n",
      "\titers: 200, epoch: 2 | loss: 0.0943571\n",
      "\tspeed: 0.0178s/iter; left time: 390.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0985815 Vali Loss: 0.0865478 Test Loss: 0.0973808\n",
      "Validation loss decreased (0.124167 --> 0.086548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0932199\n",
      "\tspeed: 0.0366s/iter; left time: 799.5932s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883732\n",
      "\tspeed: 0.0168s/iter; left time: 365.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0873929 Vali Loss: 0.0811901 Test Loss: 0.0925268\n",
      "Validation loss decreased (0.086548 --> 0.081190).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0831787\n",
      "\tspeed: 0.0359s/iter; left time: 777.1139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828029\n",
      "\tspeed: 0.0174s/iter; left time: 374.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0837343 Vali Loss: 0.0793707 Test Loss: 0.0903468\n",
      "Validation loss decreased (0.081190 --> 0.079371).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0794180\n",
      "\tspeed: 0.0387s/iter; left time: 827.7027s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803512\n",
      "\tspeed: 0.0157s/iter; left time: 333.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0817670 Vali Loss: 0.0785024 Test Loss: 0.0893094\n",
      "Validation loss decreased (0.079371 --> 0.078502).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814589\n",
      "\tspeed: 0.0348s/iter; left time: 737.9587s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822347\n",
      "\tspeed: 0.0179s/iter; left time: 377.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0804843 Vali Loss: 0.0779199 Test Loss: 0.0885575\n",
      "Validation loss decreased (0.078502 --> 0.077920).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0796365\n",
      "\tspeed: 0.0372s/iter; left time: 778.7766s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786652\n",
      "\tspeed: 0.0203s/iter; left time: 424.0511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0793796 Vali Loss: 0.0772564 Test Loss: 0.0880500\n",
      "Validation loss decreased (0.077920 --> 0.077256).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0783444\n",
      "\tspeed: 0.0339s/iter; left time: 703.6924s\n",
      "\titers: 200, epoch: 8 | loss: 0.0782565\n",
      "\tspeed: 0.0174s/iter; left time: 360.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0785196 Vali Loss: 0.0771355 Test Loss: 0.0878103\n",
      "Validation loss decreased (0.077256 --> 0.077135).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776129\n",
      "\tspeed: 0.0373s/iter; left time: 765.2246s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779193\n",
      "\tspeed: 0.0197s/iter; left time: 402.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0779028 Vali Loss: 0.0767899 Test Loss: 0.0876816\n",
      "Validation loss decreased (0.077135 --> 0.076790).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769310\n",
      "\tspeed: 0.0405s/iter; left time: 822.4023s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751809\n",
      "\tspeed: 0.0137s/iter; left time: 276.4467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0773194 Vali Loss: 0.0769143 Test Loss: 0.0876897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739529\n",
      "\tspeed: 0.0342s/iter; left time: 685.8315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0743415\n",
      "\tspeed: 0.0207s/iter; left time: 412.5022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0768274 Vali Loss: 0.0773009 Test Loss: 0.0876690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0762403\n",
      "\tspeed: 0.0354s/iter; left time: 702.9905s\n",
      "\titers: 200, epoch: 12 | loss: 0.0772672\n",
      "\tspeed: 0.0160s/iter; left time: 315.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0764189 Vali Loss: 0.0769980 Test Loss: 0.0874500\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0733816\n",
      "\tspeed: 0.0387s/iter; left time: 759.5937s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751068\n",
      "\tspeed: 0.0190s/iter; left time: 371.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0760827 Vali Loss: 0.0769310 Test Loss: 0.0872965\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792009\n",
      "\tspeed: 0.0330s/iter; left time: 640.5848s\n",
      "\titers: 200, epoch: 14 | loss: 0.0764572\n",
      "\tspeed: 0.0157s/iter; left time: 301.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0758480 Vali Loss: 0.0770768 Test Loss: 0.0874091\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0752731\n",
      "\tspeed: 0.0342s/iter; left time: 655.2293s\n",
      "\titers: 200, epoch: 15 | loss: 0.0777069\n",
      "\tspeed: 0.0167s/iter; left time: 318.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0755716 Vali Loss: 0.0769196 Test Loss: 0.0873800\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0754312\n",
      "\tspeed: 0.0333s/iter; left time: 631.3895s\n",
      "\titers: 200, epoch: 16 | loss: 0.0742673\n",
      "\tspeed: 0.0166s/iter; left time: 312.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0752459 Vali Loss: 0.0773431 Test Loss: 0.0876035\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705559\n",
      "\tspeed: 0.0340s/iter; left time: 635.5527s\n",
      "\titers: 200, epoch: 17 | loss: 0.0749878\n",
      "\tspeed: 0.0180s/iter; left time: 334.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0750879 Vali Loss: 0.0770929 Test Loss: 0.0874643\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0722637\n",
      "\tspeed: 0.0334s/iter; left time: 618.3557s\n",
      "\titers: 200, epoch: 18 | loss: 0.0736707\n",
      "\tspeed: 0.0169s/iter; left time: 310.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0748356 Vali Loss: 0.0768244 Test Loss: 0.0872946\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0717781\n",
      "\tspeed: 0.0323s/iter; left time: 590.2885s\n",
      "\titers: 200, epoch: 19 | loss: 0.0719507\n",
      "\tspeed: 0.0158s/iter; left time: 286.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0746740 Vali Loss: 0.0769784 Test Loss: 0.0872839\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01879911683499813, rmse:0.1371098756790161, mae:0.0876816138625145, rse:0.40278756618499756\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:35.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588590\n",
      "\tspeed: 0.0457s/iter; left time: 1014.3167s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345927\n",
      "\tspeed: 0.0245s/iter; left time: 541.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.1578327 Vali Loss: 0.1251587 Test Loss: 0.1401146\n",
      "Validation loss decreased (inf --> 0.125159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031658\n",
      "\tspeed: 0.0425s/iter; left time: 934.7593s\n",
      "\titers: 200, epoch: 2 | loss: 0.0960442\n",
      "\tspeed: 0.0220s/iter; left time: 480.2656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.1027083 Vali Loss: 0.0920010 Test Loss: 0.1034549\n",
      "Validation loss decreased (0.125159 --> 0.092001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925628\n",
      "\tspeed: 0.0389s/iter; left time: 846.6512s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885058\n",
      "\tspeed: 0.0203s/iter; left time: 438.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0920447 Vali Loss: 0.0870601 Test Loss: 0.0977339\n",
      "Validation loss decreased (0.092001 --> 0.087060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0894964\n",
      "\tspeed: 0.0366s/iter; left time: 788.9461s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878705\n",
      "\tspeed: 0.0175s/iter; left time: 375.6643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0885116 Vali Loss: 0.0853489 Test Loss: 0.0955454\n",
      "Validation loss decreased (0.087060 --> 0.085349).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861767\n",
      "\tspeed: 0.0365s/iter; left time: 776.9391s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893044\n",
      "\tspeed: 0.0189s/iter; left time: 399.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0865645 Vali Loss: 0.0847000 Test Loss: 0.0949086\n",
      "Validation loss decreased (0.085349 --> 0.084700).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860761\n",
      "\tspeed: 0.0351s/iter; left time: 740.5277s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822750\n",
      "\tspeed: 0.0163s/iter; left time: 341.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0852246 Vali Loss: 0.0838490 Test Loss: 0.0941687\n",
      "Validation loss decreased (0.084700 --> 0.083849).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844567\n",
      "\tspeed: 0.0366s/iter; left time: 763.9880s\n",
      "\titers: 200, epoch: 7 | loss: 0.0868250\n",
      "\tspeed: 0.0184s/iter; left time: 382.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0841996 Vali Loss: 0.0832387 Test Loss: 0.0941152\n",
      "Validation loss decreased (0.083849 --> 0.083239).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873774\n",
      "\tspeed: 0.0371s/iter; left time: 765.0394s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820005\n",
      "\tspeed: 0.0189s/iter; left time: 387.8712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0833750 Vali Loss: 0.0830650 Test Loss: 0.0936024\n",
      "Validation loss decreased (0.083239 --> 0.083065).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829483\n",
      "\tspeed: 0.0395s/iter; left time: 805.6357s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805004\n",
      "\tspeed: 0.0179s/iter; left time: 363.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0827375 Vali Loss: 0.0830914 Test Loss: 0.0932296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832330\n",
      "\tspeed: 0.0342s/iter; left time: 690.7906s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844381\n",
      "\tspeed: 0.0169s/iter; left time: 339.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0821893 Vali Loss: 0.0831509 Test Loss: 0.0935011\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838833\n",
      "\tspeed: 0.0394s/iter; left time: 787.3691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0842650\n",
      "\tspeed: 0.0175s/iter; left time: 347.6686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0816421 Vali Loss: 0.0830360 Test Loss: 0.0937280\n",
      "Validation loss decreased (0.083065 --> 0.083036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819793\n",
      "\tspeed: 0.0369s/iter; left time: 728.6392s\n",
      "\titers: 200, epoch: 12 | loss: 0.0781054\n",
      "\tspeed: 0.0198s/iter; left time: 388.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0812782 Vali Loss: 0.0829809 Test Loss: 0.0936222\n",
      "Validation loss decreased (0.083036 --> 0.082981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817220\n",
      "\tspeed: 0.0358s/iter; left time: 699.6295s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826705\n",
      "\tspeed: 0.0198s/iter; left time: 384.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0808690 Vali Loss: 0.0833226 Test Loss: 0.0937399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822457\n",
      "\tspeed: 0.0381s/iter; left time: 735.4080s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779094\n",
      "\tspeed: 0.0199s/iter; left time: 382.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0806014 Vali Loss: 0.0836196 Test Loss: 0.0937464\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0783274\n",
      "\tspeed: 0.0343s/iter; left time: 653.6021s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781628\n",
      "\tspeed: 0.0162s/iter; left time: 307.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0802118 Vali Loss: 0.0835069 Test Loss: 0.0935566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785731\n",
      "\tspeed: 0.0382s/iter; left time: 720.1741s\n",
      "\titers: 200, epoch: 16 | loss: 0.0764296\n",
      "\tspeed: 0.0186s/iter; left time: 349.3617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0798898 Vali Loss: 0.0836725 Test Loss: 0.0937837\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801015\n",
      "\tspeed: 0.0338s/iter; left time: 630.3868s\n",
      "\titers: 200, epoch: 17 | loss: 0.0836306\n",
      "\tspeed: 0.0167s/iter; left time: 310.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0796882 Vali Loss: 0.0840067 Test Loss: 0.0938545\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0792593\n",
      "\tspeed: 0.0392s/iter; left time: 722.2639s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796021\n",
      "\tspeed: 0.0180s/iter; left time: 330.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0795331 Vali Loss: 0.0838868 Test Loss: 0.0939058\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0789474\n",
      "\tspeed: 0.0348s/iter; left time: 633.2982s\n",
      "\titers: 200, epoch: 19 | loss: 0.0795470\n",
      "\tspeed: 0.0184s/iter; left time: 333.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0792791 Vali Loss: 0.0844970 Test Loss: 0.0941869\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0775987\n",
      "\tspeed: 0.0346s/iter; left time: 621.6577s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812784\n",
      "\tspeed: 0.0170s/iter; left time: 303.6301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0791397 Vali Loss: 0.0838872 Test Loss: 0.0938403\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0800104\n",
      "\tspeed: 0.0332s/iter; left time: 588.8262s\n",
      "\titers: 200, epoch: 21 | loss: 0.0797400\n",
      "\tspeed: 0.0203s/iter; left time: 357.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0789559 Vali Loss: 0.0840701 Test Loss: 0.0938450\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0792030\n",
      "\tspeed: 0.0344s/iter; left time: 603.0334s\n",
      "\titers: 200, epoch: 22 | loss: 0.0806545\n",
      "\tspeed: 0.0193s/iter; left time: 336.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0788491 Vali Loss: 0.0840587 Test Loss: 0.0939712\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0211891271173954, rmse:0.14556485414505005, mae:0.093622125685215, rse:0.4276564419269562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1614740\n",
      "\tspeed: 0.0212s/iter; left time: 470.9183s\n",
      "\titers: 200, epoch: 1 | loss: 0.1368691\n",
      "\tspeed: 0.0178s/iter; left time: 394.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1596596 Vali Loss: 0.1268055 Test Loss: 0.1421394\n",
      "Validation loss decreased (inf --> 0.126805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1006072\n",
      "\tspeed: 0.0367s/iter; left time: 805.5925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0953421\n",
      "\tspeed: 0.0166s/iter; left time: 364.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1026021 Vali Loss: 0.0916592 Test Loss: 0.1032356\n",
      "Validation loss decreased (0.126805 --> 0.091659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0914265\n",
      "\tspeed: 0.0407s/iter; left time: 886.2756s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917145\n",
      "\tspeed: 0.0172s/iter; left time: 372.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0921198 Vali Loss: 0.0869974 Test Loss: 0.0982788\n",
      "Validation loss decreased (0.091659 --> 0.086997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0851727\n",
      "\tspeed: 0.0368s/iter; left time: 793.1004s\n",
      "\titers: 200, epoch: 4 | loss: 0.0862871\n",
      "\tspeed: 0.0134s/iter; left time: 287.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0885619 Vali Loss: 0.0851515 Test Loss: 0.0956960\n",
      "Validation loss decreased (0.086997 --> 0.085152).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870870\n",
      "\tspeed: 0.0375s/iter; left time: 800.0976s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848352\n",
      "\tspeed: 0.0202s/iter; left time: 429.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0865376 Vali Loss: 0.0844742 Test Loss: 0.0949248\n",
      "Validation loss decreased (0.085152 --> 0.084474).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0866458\n",
      "\tspeed: 0.0382s/iter; left time: 805.6773s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826480\n",
      "\tspeed: 0.0156s/iter; left time: 327.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0851096 Vali Loss: 0.0836311 Test Loss: 0.0940858\n",
      "Validation loss decreased (0.084474 --> 0.083631).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0868849\n",
      "\tspeed: 0.0412s/iter; left time: 859.4933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837381\n",
      "\tspeed: 0.0200s/iter; left time: 414.4465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0840204 Vali Loss: 0.0839297 Test Loss: 0.0941062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826421\n",
      "\tspeed: 0.0405s/iter; left time: 835.5970s\n",
      "\titers: 200, epoch: 8 | loss: 0.0852803\n",
      "\tspeed: 0.0212s/iter; left time: 435.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0831774 Vali Loss: 0.0837196 Test Loss: 0.0935950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0811963\n",
      "\tspeed: 0.0380s/iter; left time: 775.0128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0823783\n",
      "\tspeed: 0.0181s/iter; left time: 366.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0825027 Vali Loss: 0.0834863 Test Loss: 0.0937589\n",
      "Validation loss decreased (0.083631 --> 0.083486).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0822163\n",
      "\tspeed: 0.0400s/iter; left time: 807.8919s\n",
      "\titers: 200, epoch: 10 | loss: 0.0815594\n",
      "\tspeed: 0.0182s/iter; left time: 365.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0819062 Vali Loss: 0.0835692 Test Loss: 0.0937383\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0847772\n",
      "\tspeed: 0.0365s/iter; left time: 728.0652s\n",
      "\titers: 200, epoch: 11 | loss: 0.0841018\n",
      "\tspeed: 0.0160s/iter; left time: 318.5932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0814248 Vali Loss: 0.0837116 Test Loss: 0.0936045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0766310\n",
      "\tspeed: 0.0354s/iter; left time: 699.1173s\n",
      "\titers: 200, epoch: 12 | loss: 0.0835811\n",
      "\tspeed: 0.0172s/iter; left time: 337.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0809366 Vali Loss: 0.0839662 Test Loss: 0.0939135\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0844224\n",
      "\tspeed: 0.0348s/iter; left time: 679.2073s\n",
      "\titers: 200, epoch: 13 | loss: 0.0777171\n",
      "\tspeed: 0.0168s/iter; left time: 326.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0805999 Vali Loss: 0.0836229 Test Loss: 0.0935848\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0813105\n",
      "\tspeed: 0.0365s/iter; left time: 705.2259s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795342\n",
      "\tspeed: 0.0165s/iter; left time: 317.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0802298 Vali Loss: 0.0838854 Test Loss: 0.0937119\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0773489\n",
      "\tspeed: 0.0370s/iter; left time: 705.2222s\n",
      "\titers: 200, epoch: 15 | loss: 0.0826144\n",
      "\tspeed: 0.0224s/iter; left time: 425.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0800226 Vali Loss: 0.0840788 Test Loss: 0.0937466\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815831\n",
      "\tspeed: 0.0406s/iter; left time: 765.6715s\n",
      "\titers: 200, epoch: 16 | loss: 0.0842106\n",
      "\tspeed: 0.0206s/iter; left time: 387.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0796761 Vali Loss: 0.0838765 Test Loss: 0.0938185\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0795426\n",
      "\tspeed: 0.0364s/iter; left time: 678.0183s\n",
      "\titers: 200, epoch: 17 | loss: 0.0803277\n",
      "\tspeed: 0.0172s/iter; left time: 318.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0794209 Vali Loss: 0.0847361 Test Loss: 0.0943312\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0816964\n",
      "\tspeed: 0.0361s/iter; left time: 664.8851s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769105\n",
      "\tspeed: 0.0166s/iter; left time: 304.8480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0792374 Vali Loss: 0.0842879 Test Loss: 0.0940923\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784574\n",
      "\tspeed: 0.0342s/iter; left time: 621.7265s\n",
      "\titers: 200, epoch: 19 | loss: 0.0803968\n",
      "\tspeed: 0.0183s/iter; left time: 330.5564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0790553 Vali Loss: 0.0839203 Test Loss: 0.0937492\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020983636379241943, rmse:0.14485730230808258, mae:0.09375885128974915, rse:0.42557770013809204\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:59.19s\n",
      "Intermediate time for ES: 00h:16m:24.26s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1097015\n",
      "\tspeed: 0.0406s/iter; left time: 906.3268s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887853\n",
      "\tspeed: 0.0140s/iter; left time: 311.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1121289 Vali Loss: 0.0946256 Test Loss: 0.1039862\n",
      "Validation loss decreased (inf --> 0.094626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534826\n",
      "\tspeed: 0.0303s/iter; left time: 668.0591s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533698\n",
      "\tspeed: 0.0155s/iter; left time: 340.5770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0595254 Vali Loss: 0.0593359 Test Loss: 0.0626762\n",
      "Validation loss decreased (0.094626 --> 0.059336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0492144\n",
      "\tspeed: 0.0310s/iter; left time: 677.8987s\n",
      "\titers: 200, epoch: 3 | loss: 0.0486399\n",
      "\tspeed: 0.0155s/iter; left time: 336.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0507849 Vali Loss: 0.0569176 Test Loss: 0.0601328\n",
      "Validation loss decreased (0.059336 --> 0.056918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0484496\n",
      "\tspeed: 0.0316s/iter; left time: 683.4216s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481661\n",
      "\tspeed: 0.0183s/iter; left time: 394.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0485986 Vali Loss: 0.0556101 Test Loss: 0.0590208\n",
      "Validation loss decreased (0.056918 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467192\n",
      "\tspeed: 0.0341s/iter; left time: 729.7856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0484249\n",
      "\tspeed: 0.0151s/iter; left time: 320.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0472493 Vali Loss: 0.0546849 Test Loss: 0.0583969\n",
      "Validation loss decreased (0.055610 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0475310\n",
      "\tspeed: 0.0352s/iter; left time: 745.8896s\n",
      "\titers: 200, epoch: 6 | loss: 0.0457387\n",
      "\tspeed: 0.0169s/iter; left time: 356.3752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0462754 Vali Loss: 0.0535959 Test Loss: 0.0575769\n",
      "Validation loss decreased (0.054685 --> 0.053596).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0468816\n",
      "\tspeed: 0.0327s/iter; left time: 686.2314s\n",
      "\titers: 200, epoch: 7 | loss: 0.0452926\n",
      "\tspeed: 0.0130s/iter; left time: 271.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0455841 Vali Loss: 0.0534057 Test Loss: 0.0573068\n",
      "Validation loss decreased (0.053596 --> 0.053406).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0474218\n",
      "\tspeed: 0.0324s/iter; left time: 671.6504s\n",
      "\titers: 200, epoch: 8 | loss: 0.0434757\n",
      "\tspeed: 0.0181s/iter; left time: 374.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0450097 Vali Loss: 0.0531013 Test Loss: 0.0570163\n",
      "Validation loss decreased (0.053406 --> 0.053101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0466082\n",
      "\tspeed: 0.0342s/iter; left time: 701.9817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0406892\n",
      "\tspeed: 0.0155s/iter; left time: 316.3156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0445724 Vali Loss: 0.0529589 Test Loss: 0.0571137\n",
      "Validation loss decreased (0.053101 --> 0.052959).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0472855\n",
      "\tspeed: 0.0358s/iter; left time: 726.0558s\n",
      "\titers: 200, epoch: 10 | loss: 0.0445645\n",
      "\tspeed: 0.0162s/iter; left time: 327.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0441734 Vali Loss: 0.0526272 Test Loss: 0.0568700\n",
      "Validation loss decreased (0.052959 --> 0.052627).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434398\n",
      "\tspeed: 0.0327s/iter; left time: 656.7324s\n",
      "\titers: 200, epoch: 11 | loss: 0.0426368\n",
      "\tspeed: 0.0162s/iter; left time: 323.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0438455 Vali Loss: 0.0523278 Test Loss: 0.0564668\n",
      "Validation loss decreased (0.052627 --> 0.052328).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0431309\n",
      "\tspeed: 0.0307s/iter; left time: 608.5433s\n",
      "\titers: 200, epoch: 12 | loss: 0.0433577\n",
      "\tspeed: 0.0157s/iter; left time: 310.7402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0436222 Vali Loss: 0.0522362 Test Loss: 0.0562486\n",
      "Validation loss decreased (0.052328 --> 0.052236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0426902\n",
      "\tspeed: 0.0309s/iter; left time: 606.6136s\n",
      "\titers: 200, epoch: 13 | loss: 0.0428892\n",
      "\tspeed: 0.0164s/iter; left time: 319.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0433593 Vali Loss: 0.0520524 Test Loss: 0.0562706\n",
      "Validation loss decreased (0.052236 --> 0.052052).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0434505\n",
      "\tspeed: 0.0318s/iter; left time: 617.1552s\n",
      "\titers: 200, epoch: 14 | loss: 0.0460396\n",
      "\tspeed: 0.0158s/iter; left time: 303.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0431982 Vali Loss: 0.0523667 Test Loss: 0.0561814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0428227\n",
      "\tspeed: 0.0343s/iter; left time: 656.4160s\n",
      "\titers: 200, epoch: 15 | loss: 0.0418219\n",
      "\tspeed: 0.0158s/iter; left time: 301.1862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0429733 Vali Loss: 0.0519710 Test Loss: 0.0561296\n",
      "Validation loss decreased (0.052052 --> 0.051971).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0426776\n",
      "\tspeed: 0.0338s/iter; left time: 639.9347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441703\n",
      "\tspeed: 0.0154s/iter; left time: 289.4156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0428724 Vali Loss: 0.0518400 Test Loss: 0.0559802\n",
      "Validation loss decreased (0.051971 --> 0.051840).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0421949\n",
      "\tspeed: 0.0332s/iter; left time: 621.3694s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410631\n",
      "\tspeed: 0.0192s/iter; left time: 357.2043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0427084 Vali Loss: 0.0517573 Test Loss: 0.0560051\n",
      "Validation loss decreased (0.051840 --> 0.051757).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443506\n",
      "\tspeed: 0.0316s/iter; left time: 584.9092s\n",
      "\titers: 200, epoch: 18 | loss: 0.0417061\n",
      "\tspeed: 0.0156s/iter; left time: 286.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0425945 Vali Loss: 0.0517659 Test Loss: 0.0559824\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0399689\n",
      "\tspeed: 0.0275s/iter; left time: 503.1896s\n",
      "\titers: 200, epoch: 19 | loss: 0.0442903\n",
      "\tspeed: 0.0099s/iter; left time: 179.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.59s\n",
      "Steps: 224 | Train Loss: 0.0424989 Vali Loss: 0.0516519 Test Loss: 0.0558209\n",
      "Validation loss decreased (0.051757 --> 0.051652).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0412286\n",
      "\tspeed: 0.0360s/iter; left time: 649.4498s\n",
      "\titers: 200, epoch: 20 | loss: 0.0390507\n",
      "\tspeed: 0.0162s/iter; left time: 291.2772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0423428 Vali Loss: 0.0516512 Test Loss: 0.0557739\n",
      "Validation loss decreased (0.051652 --> 0.051651).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0409525\n",
      "\tspeed: 0.0365s/iter; left time: 650.8688s\n",
      "\titers: 200, epoch: 21 | loss: 0.0423990\n",
      "\tspeed: 0.0196s/iter; left time: 347.6174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0423433 Vali Loss: 0.0517129 Test Loss: 0.0558281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0415610\n",
      "\tspeed: 0.0342s/iter; left time: 601.9177s\n",
      "\titers: 200, epoch: 22 | loss: 0.0422034\n",
      "\tspeed: 0.0179s/iter; left time: 313.6171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0422027 Vali Loss: 0.0516596 Test Loss: 0.0556948\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0430506\n",
      "\tspeed: 0.0372s/iter; left time: 645.9111s\n",
      "\titers: 200, epoch: 23 | loss: 0.0418019\n",
      "\tspeed: 0.0186s/iter; left time: 321.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0421560 Vali Loss: 0.0514954 Test Loss: 0.0557444\n",
      "Validation loss decreased (0.051651 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0415646\n",
      "\tspeed: 0.0332s/iter; left time: 569.8740s\n",
      "\titers: 200, epoch: 24 | loss: 0.0397885\n",
      "\tspeed: 0.0160s/iter; left time: 271.9915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0421029 Vali Loss: 0.0514459 Test Loss: 0.0556594\n",
      "Validation loss decreased (0.051495 --> 0.051446).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0417303\n",
      "\tspeed: 0.0346s/iter; left time: 586.1300s\n",
      "\titers: 200, epoch: 25 | loss: 0.0445542\n",
      "\tspeed: 0.0159s/iter; left time: 267.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0420585 Vali Loss: 0.0515431 Test Loss: 0.0555989\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0418962\n",
      "\tspeed: 0.0340s/iter; left time: 567.2828s\n",
      "\titers: 200, epoch: 26 | loss: 0.0463416\n",
      "\tspeed: 0.0161s/iter; left time: 267.6914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0420164 Vali Loss: 0.0514875 Test Loss: 0.0556201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0443795\n",
      "\tspeed: 0.0337s/iter; left time: 555.9818s\n",
      "\titers: 200, epoch: 27 | loss: 0.0387430\n",
      "\tspeed: 0.0202s/iter; left time: 330.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0419670 Vali Loss: 0.0514544 Test Loss: 0.0555616\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0420398\n",
      "\tspeed: 0.0305s/iter; left time: 495.2399s\n",
      "\titers: 200, epoch: 28 | loss: 0.0404838\n",
      "\tspeed: 0.0156s/iter; left time: 251.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0418996 Vali Loss: 0.0513931 Test Loss: 0.0555418\n",
      "Validation loss decreased (0.051446 --> 0.051393).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0422525\n",
      "\tspeed: 0.0363s/iter; left time: 582.0569s\n",
      "\titers: 200, epoch: 29 | loss: 0.0420631\n",
      "\tspeed: 0.0197s/iter; left time: 313.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0418604 Vali Loss: 0.0514061 Test Loss: 0.0555391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0412472\n",
      "\tspeed: 0.0317s/iter; left time: 500.2506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0401083\n",
      "\tspeed: 0.0121s/iter; left time: 190.6509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0418587 Vali Loss: 0.0513626 Test Loss: 0.0555390\n",
      "Validation loss decreased (0.051393 --> 0.051363).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0408360\n",
      "\tspeed: 0.0306s/iter; left time: 477.5095s\n",
      "\titers: 200, epoch: 31 | loss: 0.0447715\n",
      "\tspeed: 0.0161s/iter; left time: 249.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0417779 Vali Loss: 0.0513673 Test Loss: 0.0555260\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0407078\n",
      "\tspeed: 0.0339s/iter; left time: 520.6888s\n",
      "\titers: 200, epoch: 32 | loss: 0.0418107\n",
      "\tspeed: 0.0172s/iter; left time: 261.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0418036 Vali Loss: 0.0513723 Test Loss: 0.0555180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0403561\n",
      "\tspeed: 0.0330s/iter; left time: 498.7969s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424583\n",
      "\tspeed: 0.0161s/iter; left time: 242.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0417103 Vali Loss: 0.0513903 Test Loss: 0.0554956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0404760\n",
      "\tspeed: 0.0334s/iter; left time: 497.9434s\n",
      "\titers: 200, epoch: 34 | loss: 0.0403951\n",
      "\tspeed: 0.0174s/iter; left time: 258.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0417552 Vali Loss: 0.0513530 Test Loss: 0.0554836\n",
      "Validation loss decreased (0.051363 --> 0.051353).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0427985\n",
      "\tspeed: 0.0344s/iter; left time: 505.7937s\n",
      "\titers: 200, epoch: 35 | loss: 0.0402471\n",
      "\tspeed: 0.0213s/iter; left time: 310.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0417380 Vali Loss: 0.0513526 Test Loss: 0.0555068\n",
      "Validation loss decreased (0.051353 --> 0.051353).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0386213\n",
      "\tspeed: 0.0371s/iter; left time: 536.1628s\n",
      "\titers: 200, epoch: 36 | loss: 0.0393753\n",
      "\tspeed: 0.0178s/iter; left time: 255.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0416732 Vali Loss: 0.0513832 Test Loss: 0.0554862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0408963\n",
      "\tspeed: 0.0337s/iter; left time: 479.9361s\n",
      "\titers: 200, epoch: 37 | loss: 0.0432493\n",
      "\tspeed: 0.0160s/iter; left time: 225.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0417258 Vali Loss: 0.0513284 Test Loss: 0.0554904\n",
      "Validation loss decreased (0.051353 --> 0.051328).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0417266\n",
      "\tspeed: 0.0366s/iter; left time: 512.4411s\n",
      "\titers: 200, epoch: 38 | loss: 0.0394331\n",
      "\tspeed: 0.0160s/iter; left time: 222.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0416906 Vali Loss: 0.0513835 Test Loss: 0.0554471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0406633\n",
      "\tspeed: 0.0321s/iter; left time: 442.7910s\n",
      "\titers: 200, epoch: 39 | loss: 0.0404283\n",
      "\tspeed: 0.0170s/iter; left time: 232.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0417076 Vali Loss: 0.0513519 Test Loss: 0.0554570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0411297\n",
      "\tspeed: 0.0357s/iter; left time: 484.1638s\n",
      "\titers: 200, epoch: 40 | loss: 0.0387189\n",
      "\tspeed: 0.0171s/iter; left time: 229.6346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0416953 Vali Loss: 0.0513288 Test Loss: 0.0554681\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0402259\n",
      "\tspeed: 0.0322s/iter; left time: 429.9865s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402706\n",
      "\tspeed: 0.0179s/iter; left time: 237.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0416524 Vali Loss: 0.0513917 Test Loss: 0.0554390\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0424217\n",
      "\tspeed: 0.0329s/iter; left time: 431.5525s\n",
      "\titers: 200, epoch: 42 | loss: 0.0432451\n",
      "\tspeed: 0.0188s/iter; left time: 245.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0416016 Vali Loss: 0.0513356 Test Loss: 0.0554367\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0396264\n",
      "\tspeed: 0.0355s/iter; left time: 458.1155s\n",
      "\titers: 200, epoch: 43 | loss: 0.0448006\n",
      "\tspeed: 0.0172s/iter; left time: 220.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0416167 Vali Loss: 0.0513517 Test Loss: 0.0554314\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0451020\n",
      "\tspeed: 0.0353s/iter; left time: 447.1240s\n",
      "\titers: 200, epoch: 44 | loss: 0.0401483\n",
      "\tspeed: 0.0189s/iter; left time: 237.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0416575 Vali Loss: 0.0513275 Test Loss: 0.0554304\n",
      "Validation loss decreased (0.051328 --> 0.051327).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0421727\n",
      "\tspeed: 0.0333s/iter; left time: 413.8943s\n",
      "\titers: 200, epoch: 45 | loss: 0.0439378\n",
      "\tspeed: 0.0119s/iter; left time: 147.4548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0416004 Vali Loss: 0.0513106 Test Loss: 0.0554274\n",
      "Validation loss decreased (0.051327 --> 0.051311).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0405932\n",
      "\tspeed: 0.0321s/iter; left time: 392.5109s\n",
      "\titers: 200, epoch: 46 | loss: 0.0446997\n",
      "\tspeed: 0.0174s/iter; left time: 211.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0415836 Vali Loss: 0.0513469 Test Loss: 0.0554078\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0402025\n",
      "\tspeed: 0.0317s/iter; left time: 379.7401s\n",
      "\titers: 200, epoch: 47 | loss: 0.0396418\n",
      "\tspeed: 0.0156s/iter; left time: 185.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0415811 Vali Loss: 0.0513474 Test Loss: 0.0554269\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0425316\n",
      "\tspeed: 0.0322s/iter; left time: 378.5675s\n",
      "\titers: 200, epoch: 48 | loss: 0.0427716\n",
      "\tspeed: 0.0099s/iter; left time: 115.6280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0415999 Vali Loss: 0.0513182 Test Loss: 0.0554259\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0429427\n",
      "\tspeed: 0.0303s/iter; left time: 350.2498s\n",
      "\titers: 200, epoch: 49 | loss: 0.0389868\n",
      "\tspeed: 0.0152s/iter; left time: 173.9497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0416206 Vali Loss: 0.0512744 Test Loss: 0.0554173\n",
      "Validation loss decreased (0.051311 --> 0.051274).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0433284\n",
      "\tspeed: 0.0333s/iter; left time: 377.3006s\n",
      "\titers: 200, epoch: 50 | loss: 0.0415467\n",
      "\tspeed: 0.0160s/iter; left time: 180.0323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0416315 Vali Loss: 0.0513450 Test Loss: 0.0554281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0462583\n",
      "\tspeed: 0.0320s/iter; left time: 355.1939s\n",
      "\titers: 200, epoch: 51 | loss: 0.0416190\n",
      "\tspeed: 0.0190s/iter; left time: 209.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0416029 Vali Loss: 0.0513489 Test Loss: 0.0554212\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0422685\n",
      "\tspeed: 0.0314s/iter; left time: 341.0576s\n",
      "\titers: 200, epoch: 52 | loss: 0.0437222\n",
      "\tspeed: 0.0158s/iter; left time: 170.1313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0416151 Vali Loss: 0.0513167 Test Loss: 0.0554113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0431240\n",
      "\tspeed: 0.0389s/iter; left time: 414.1950s\n",
      "\titers: 200, epoch: 53 | loss: 0.0416722\n",
      "\tspeed: 0.0204s/iter; left time: 215.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0416176 Vali Loss: 0.0513061 Test Loss: 0.0554057\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0439605\n",
      "\tspeed: 0.0355s/iter; left time: 370.2824s\n",
      "\titers: 200, epoch: 54 | loss: 0.0439989\n",
      "\tspeed: 0.0188s/iter; left time: 193.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0415792 Vali Loss: 0.0513847 Test Loss: 0.0554150\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0422027\n",
      "\tspeed: 0.0335s/iter; left time: 341.6693s\n",
      "\titers: 200, epoch: 55 | loss: 0.0403531\n",
      "\tspeed: 0.0175s/iter; left time: 176.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0415882 Vali Loss: 0.0513136 Test Loss: 0.0554142\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0416451\n",
      "\tspeed: 0.0375s/iter; left time: 373.8406s\n",
      "\titers: 200, epoch: 56 | loss: 0.0380465\n",
      "\tspeed: 0.0209s/iter; left time: 206.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0416262 Vali Loss: 0.0513836 Test Loss: 0.0554235\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0440627\n",
      "\tspeed: 0.0332s/iter; left time: 324.3176s\n",
      "\titers: 200, epoch: 57 | loss: 0.0437547\n",
      "\tspeed: 0.0172s/iter; left time: 166.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0416621 Vali Loss: 0.0513555 Test Loss: 0.0554003\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0418365\n",
      "\tspeed: 0.0341s/iter; left time: 324.9148s\n",
      "\titers: 200, epoch: 58 | loss: 0.0405680\n",
      "\tspeed: 0.0189s/iter; left time: 177.9576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0416161 Vali Loss: 0.0513102 Test Loss: 0.0554134\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0441648\n",
      "\tspeed: 0.0340s/iter; left time: 316.4858s\n",
      "\titers: 200, epoch: 59 | loss: 0.0452958\n",
      "\tspeed: 0.0163s/iter; left time: 150.2447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0416127 Vali Loss: 0.0512991 Test Loss: 0.0554122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010099428705871105, rmse:0.10049591213464737, mae:0.05541735514998436, rse:0.38771042227745056\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1069858\n",
      "\tspeed: 0.0210s/iter; left time: 467.8363s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905572\n",
      "\tspeed: 0.0188s/iter; left time: 417.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1072742 Vali Loss: 0.0922806 Test Loss: 0.1009484\n",
      "Validation loss decreased (inf --> 0.092281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0541535\n",
      "\tspeed: 0.0357s/iter; left time: 788.6453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0516308\n",
      "\tspeed: 0.0189s/iter; left time: 415.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0590231 Vali Loss: 0.0593697 Test Loss: 0.0627067\n",
      "Validation loss decreased (0.092281 --> 0.059370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0512797\n",
      "\tspeed: 0.0354s/iter; left time: 772.7446s\n",
      "\titers: 200, epoch: 3 | loss: 0.0498737\n",
      "\tspeed: 0.0159s/iter; left time: 344.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0506631 Vali Loss: 0.0566041 Test Loss: 0.0601631\n",
      "Validation loss decreased (0.059370 --> 0.056604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0469981\n",
      "\tspeed: 0.0351s/iter; left time: 759.8585s\n",
      "\titers: 200, epoch: 4 | loss: 0.0446057\n",
      "\tspeed: 0.0168s/iter; left time: 361.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0484095 Vali Loss: 0.0552692 Test Loss: 0.0590177\n",
      "Validation loss decreased (0.056604 --> 0.055269).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478297\n",
      "\tspeed: 0.0375s/iter; left time: 801.7233s\n",
      "\titers: 200, epoch: 5 | loss: 0.0472397\n",
      "\tspeed: 0.0166s/iter; left time: 354.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0471005 Vali Loss: 0.0545985 Test Loss: 0.0586126\n",
      "Validation loss decreased (0.055269 --> 0.054598).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0441277\n",
      "\tspeed: 0.0357s/iter; left time: 755.6270s\n",
      "\titers: 200, epoch: 6 | loss: 0.0451250\n",
      "\tspeed: 0.0169s/iter; left time: 356.1179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0462100 Vali Loss: 0.0538589 Test Loss: 0.0579011\n",
      "Validation loss decreased (0.054598 --> 0.053859).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0432887\n",
      "\tspeed: 0.0359s/iter; left time: 752.6445s\n",
      "\titers: 200, epoch: 7 | loss: 0.0423730\n",
      "\tspeed: 0.0197s/iter; left time: 411.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0454374 Vali Loss: 0.0534419 Test Loss: 0.0576101\n",
      "Validation loss decreased (0.053859 --> 0.053442).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0468881\n",
      "\tspeed: 0.0360s/iter; left time: 747.2667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449685\n",
      "\tspeed: 0.0187s/iter; left time: 385.9318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0449213 Vali Loss: 0.0532706 Test Loss: 0.0572513\n",
      "Validation loss decreased (0.053442 --> 0.053271).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0447122\n",
      "\tspeed: 0.0341s/iter; left time: 699.3897s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443079\n",
      "\tspeed: 0.0194s/iter; left time: 395.3572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0444387 Vali Loss: 0.0526615 Test Loss: 0.0572140\n",
      "Validation loss decreased (0.053271 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0416612\n",
      "\tspeed: 0.0339s/iter; left time: 687.4346s\n",
      "\titers: 200, epoch: 10 | loss: 0.0422850\n",
      "\tspeed: 0.0179s/iter; left time: 360.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0440636 Vali Loss: 0.0525660 Test Loss: 0.0569638\n",
      "Validation loss decreased (0.052662 --> 0.052566).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0422997\n",
      "\tspeed: 0.0343s/iter; left time: 688.5123s\n",
      "\titers: 200, epoch: 11 | loss: 0.0420976\n",
      "\tspeed: 0.0173s/iter; left time: 344.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0437480 Vali Loss: 0.0524512 Test Loss: 0.0565797\n",
      "Validation loss decreased (0.052566 --> 0.052451).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414005\n",
      "\tspeed: 0.0338s/iter; left time: 671.1621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0415740\n",
      "\tspeed: 0.0158s/iter; left time: 312.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0434542 Vali Loss: 0.0522068 Test Loss: 0.0565036\n",
      "Validation loss decreased (0.052451 --> 0.052207).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0428762\n",
      "\tspeed: 0.0333s/iter; left time: 652.7750s\n",
      "\titers: 200, epoch: 13 | loss: 0.0444564\n",
      "\tspeed: 0.0186s/iter; left time: 362.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0431964 Vali Loss: 0.0519800 Test Loss: 0.0562444\n",
      "Validation loss decreased (0.052207 --> 0.051980).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0469605\n",
      "\tspeed: 0.0318s/iter; left time: 616.1440s\n",
      "\titers: 200, epoch: 14 | loss: 0.0413370\n",
      "\tspeed: 0.0156s/iter; left time: 301.5916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0430408 Vali Loss: 0.0519134 Test Loss: 0.0561929\n",
      "Validation loss decreased (0.051980 --> 0.051913).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0399953\n",
      "\tspeed: 0.0356s/iter; left time: 683.1198s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422832\n",
      "\tspeed: 0.0162s/iter; left time: 308.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0428868 Vali Loss: 0.0519125 Test Loss: 0.0560905\n",
      "Validation loss decreased (0.051913 --> 0.051912).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0437544\n",
      "\tspeed: 0.0327s/iter; left time: 619.5839s\n",
      "\titers: 200, epoch: 16 | loss: 0.0410466\n",
      "\tspeed: 0.0172s/iter; left time: 324.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0427167 Vali Loss: 0.0517752 Test Loss: 0.0560598\n",
      "Validation loss decreased (0.051912 --> 0.051775).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0424067\n",
      "\tspeed: 0.0371s/iter; left time: 695.1356s\n",
      "\titers: 200, epoch: 17 | loss: 0.0435748\n",
      "\tspeed: 0.0207s/iter; left time: 385.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0425871 Vali Loss: 0.0517997 Test Loss: 0.0559582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0399558\n",
      "\tspeed: 0.0388s/iter; left time: 717.1779s\n",
      "\titers: 200, epoch: 18 | loss: 0.0402812\n",
      "\tspeed: 0.0164s/iter; left time: 300.7309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0424283 Vali Loss: 0.0517233 Test Loss: 0.0559206\n",
      "Validation loss decreased (0.051775 --> 0.051723).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0411396\n",
      "\tspeed: 0.0318s/iter; left time: 581.7656s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441001\n",
      "\tspeed: 0.0154s/iter; left time: 279.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0423925 Vali Loss: 0.0515982 Test Loss: 0.0558247\n",
      "Validation loss decreased (0.051723 --> 0.051598).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0425835\n",
      "\tspeed: 0.0348s/iter; left time: 628.5216s\n",
      "\titers: 200, epoch: 20 | loss: 0.0487299\n",
      "\tspeed: 0.0166s/iter; left time: 297.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0422478 Vali Loss: 0.0515914 Test Loss: 0.0558050\n",
      "Validation loss decreased (0.051598 --> 0.051591).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0407321\n",
      "\tspeed: 0.0324s/iter; left time: 577.8724s\n",
      "\titers: 200, epoch: 21 | loss: 0.0401658\n",
      "\tspeed: 0.0182s/iter; left time: 321.7754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0422160 Vali Loss: 0.0514660 Test Loss: 0.0557320\n",
      "Validation loss decreased (0.051591 --> 0.051466).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414102\n",
      "\tspeed: 0.0347s/iter; left time: 610.3975s\n",
      "\titers: 200, epoch: 22 | loss: 0.0409535\n",
      "\tspeed: 0.0164s/iter; left time: 286.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0421026 Vali Loss: 0.0515408 Test Loss: 0.0556832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0396718\n",
      "\tspeed: 0.0339s/iter; left time: 588.9066s\n",
      "\titers: 200, epoch: 23 | loss: 0.0391857\n",
      "\tspeed: 0.0170s/iter; left time: 293.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0420444 Vali Loss: 0.0514479 Test Loss: 0.0557304\n",
      "Validation loss decreased (0.051466 --> 0.051448).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0434424\n",
      "\tspeed: 0.0405s/iter; left time: 693.7866s\n",
      "\titers: 200, epoch: 24 | loss: 0.0414429\n",
      "\tspeed: 0.0190s/iter; left time: 323.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0420187 Vali Loss: 0.0514366 Test Loss: 0.0556423\n",
      "Validation loss decreased (0.051448 --> 0.051437).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0431887\n",
      "\tspeed: 0.0368s/iter; left time: 622.7349s\n",
      "\titers: 200, epoch: 25 | loss: 0.0424265\n",
      "\tspeed: 0.0202s/iter; left time: 340.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0419006 Vali Loss: 0.0512903 Test Loss: 0.0556046\n",
      "Validation loss decreased (0.051437 --> 0.051290).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0431911\n",
      "\tspeed: 0.0338s/iter; left time: 565.3255s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404304\n",
      "\tspeed: 0.0158s/iter; left time: 261.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0418660 Vali Loss: 0.0513278 Test Loss: 0.0555743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0421428\n",
      "\tspeed: 0.0364s/iter; left time: 598.9414s\n",
      "\titers: 200, epoch: 27 | loss: 0.0379287\n",
      "\tspeed: 0.0196s/iter; left time: 321.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0417966 Vali Loss: 0.0513411 Test Loss: 0.0555147\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0425174\n",
      "\tspeed: 0.0332s/iter; left time: 539.7846s\n",
      "\titers: 200, epoch: 28 | loss: 0.0440610\n",
      "\tspeed: 0.0159s/iter; left time: 256.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0418418 Vali Loss: 0.0513262 Test Loss: 0.0555246\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0450456\n",
      "\tspeed: 0.0327s/iter; left time: 524.2018s\n",
      "\titers: 200, epoch: 29 | loss: 0.0425672\n",
      "\tspeed: 0.0187s/iter; left time: 298.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0417624 Vali Loss: 0.0513244 Test Loss: 0.0555250\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0428731\n",
      "\tspeed: 0.0344s/iter; left time: 544.0296s\n",
      "\titers: 200, epoch: 30 | loss: 0.0389375\n",
      "\tspeed: 0.0176s/iter; left time: 276.2495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0417171 Vali Loss: 0.0513459 Test Loss: 0.0555162\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0402728\n",
      "\tspeed: 0.0371s/iter; left time: 577.8059s\n",
      "\titers: 200, epoch: 31 | loss: 0.0404726\n",
      "\tspeed: 0.0176s/iter; left time: 272.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0417310 Vali Loss: 0.0513120 Test Loss: 0.0554989\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403957\n",
      "\tspeed: 0.0348s/iter; left time: 534.9508s\n",
      "\titers: 200, epoch: 32 | loss: 0.0408003\n",
      "\tspeed: 0.0157s/iter; left time: 240.0695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0416980 Vali Loss: 0.0513008 Test Loss: 0.0554766\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0440529\n",
      "\tspeed: 0.0319s/iter; left time: 482.6293s\n",
      "\titers: 200, epoch: 33 | loss: 0.0418589\n",
      "\tspeed: 0.0158s/iter; left time: 237.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0416855 Vali Loss: 0.0512874 Test Loss: 0.0554821\n",
      "Validation loss decreased (0.051290 --> 0.051287).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0421416\n",
      "\tspeed: 0.0318s/iter; left time: 474.1906s\n",
      "\titers: 200, epoch: 34 | loss: 0.0434756\n",
      "\tspeed: 0.0154s/iter; left time: 228.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0416528 Vali Loss: 0.0513258 Test Loss: 0.0554486\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0405060\n",
      "\tspeed: 0.0321s/iter; left time: 470.9267s\n",
      "\titers: 200, epoch: 35 | loss: 0.0389048\n",
      "\tspeed: 0.0159s/iter; left time: 231.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0416362 Vali Loss: 0.0512096 Test Loss: 0.0555009\n",
      "Validation loss decreased (0.051287 --> 0.051210).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0422319\n",
      "\tspeed: 0.0343s/iter; left time: 495.6617s\n",
      "\titers: 200, epoch: 36 | loss: 0.0401925\n",
      "\tspeed: 0.0191s/iter; left time: 273.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0416285 Vali Loss: 0.0512667 Test Loss: 0.0554312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0403521\n",
      "\tspeed: 0.0361s/iter; left time: 514.0080s\n",
      "\titers: 200, epoch: 37 | loss: 0.0400745\n",
      "\tspeed: 0.0156s/iter; left time: 220.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0415903 Vali Loss: 0.0512633 Test Loss: 0.0554522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0423123\n",
      "\tspeed: 0.0270s/iter; left time: 378.1472s\n",
      "\titers: 200, epoch: 38 | loss: 0.0414664\n",
      "\tspeed: 0.0174s/iter; left time: 242.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 224 | Train Loss: 0.0415699 Vali Loss: 0.0513026 Test Loss: 0.0554473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0423455\n",
      "\tspeed: 0.0328s/iter; left time: 451.6660s\n",
      "\titers: 200, epoch: 39 | loss: 0.0396733\n",
      "\tspeed: 0.0169s/iter; left time: 230.7367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0415576 Vali Loss: 0.0512397 Test Loss: 0.0554350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0404658\n",
      "\tspeed: 0.0325s/iter; left time: 440.5104s\n",
      "\titers: 200, epoch: 40 | loss: 0.0419236\n",
      "\tspeed: 0.0156s/iter; left time: 210.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0415481 Vali Loss: 0.0512365 Test Loss: 0.0554207\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0403849\n",
      "\tspeed: 0.0347s/iter; left time: 463.1185s\n",
      "\titers: 200, epoch: 41 | loss: 0.0390456\n",
      "\tspeed: 0.0163s/iter; left time: 216.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0414813 Vali Loss: 0.0511526 Test Loss: 0.0554164\n",
      "Validation loss decreased (0.051210 --> 0.051153).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0421273\n",
      "\tspeed: 0.0348s/iter; left time: 456.8204s\n",
      "\titers: 200, epoch: 42 | loss: 0.0394830\n",
      "\tspeed: 0.0161s/iter; left time: 209.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0415325 Vali Loss: 0.0511710 Test Loss: 0.0554213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0408628\n",
      "\tspeed: 0.0357s/iter; left time: 460.4832s\n",
      "\titers: 200, epoch: 43 | loss: 0.0419542\n",
      "\tspeed: 0.0185s/iter; left time: 236.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0415408 Vali Loss: 0.0512386 Test Loss: 0.0554338\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0423564\n",
      "\tspeed: 0.0317s/iter; left time: 402.1836s\n",
      "\titers: 200, epoch: 44 | loss: 0.0423347\n",
      "\tspeed: 0.0159s/iter; left time: 199.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0415343 Vali Loss: 0.0512940 Test Loss: 0.0554214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0418017\n",
      "\tspeed: 0.0305s/iter; left time: 379.3849s\n",
      "\titers: 200, epoch: 45 | loss: 0.0446287\n",
      "\tspeed: 0.0154s/iter; left time: 189.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0415096 Vali Loss: 0.0511924 Test Loss: 0.0554004\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0386765\n",
      "\tspeed: 0.0331s/iter; left time: 404.7705s\n",
      "\titers: 200, epoch: 46 | loss: 0.0422158\n",
      "\tspeed: 0.0165s/iter; left time: 199.9333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0415454 Vali Loss: 0.0512207 Test Loss: 0.0553997\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0397347\n",
      "\tspeed: 0.0330s/iter; left time: 395.4360s\n",
      "\titers: 200, epoch: 47 | loss: 0.0410640\n",
      "\tspeed: 0.0169s/iter; left time: 201.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0415524 Vali Loss: 0.0512448 Test Loss: 0.0553860\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0416812\n",
      "\tspeed: 0.0311s/iter; left time: 366.6456s\n",
      "\titers: 200, epoch: 48 | loss: 0.0440729\n",
      "\tspeed: 0.0161s/iter; left time: 187.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0415353 Vali Loss: 0.0512030 Test Loss: 0.0554056\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0423379\n",
      "\tspeed: 0.0336s/iter; left time: 388.4857s\n",
      "\titers: 200, epoch: 49 | loss: 0.0419827\n",
      "\tspeed: 0.0157s/iter; left time: 179.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0414885 Vali Loss: 0.0511615 Test Loss: 0.0553941\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0429531\n",
      "\tspeed: 0.0316s/iter; left time: 357.8614s\n",
      "\titers: 200, epoch: 50 | loss: 0.0367783\n",
      "\tspeed: 0.0155s/iter; left time: 174.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0414849 Vali Loss: 0.0511634 Test Loss: 0.0553862\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0427272\n",
      "\tspeed: 0.0323s/iter; left time: 358.8486s\n",
      "\titers: 200, epoch: 51 | loss: 0.0440606\n",
      "\tspeed: 0.0163s/iter; left time: 179.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0414986 Vali Loss: 0.0512087 Test Loss: 0.0553996\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01014432217925787, rmse:0.10071902722120285, mae:0.055416375398635864, rse:0.38857123255729675\n",
      "Intermediate time for FR and pred_len 24: 00h:09m:27.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1150345\n",
      "\tspeed: 0.0403s/iter; left time: 897.7116s\n",
      "\titers: 200, epoch: 1 | loss: 0.0994970\n",
      "\tspeed: 0.0156s/iter; left time: 345.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1151521 Vali Loss: 0.1004603 Test Loss: 0.1112473\n",
      "Validation loss decreased (inf --> 0.100460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693080\n",
      "\tspeed: 0.0330s/iter; left time: 728.8859s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724322\n",
      "\tspeed: 0.0152s/iter; left time: 334.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0735030 Vali Loss: 0.0765681 Test Loss: 0.0844831\n",
      "Validation loss decreased (0.100460 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0613564\n",
      "\tspeed: 0.0338s/iter; left time: 738.6879s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634928\n",
      "\tspeed: 0.0169s/iter; left time: 368.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0658099 Vali Loss: 0.0732510 Test Loss: 0.0826563\n",
      "Validation loss decreased (0.076568 --> 0.073251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623701\n",
      "\tspeed: 0.0345s/iter; left time: 746.3441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0633448\n",
      "\tspeed: 0.0175s/iter; left time: 377.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0633823 Vali Loss: 0.0719194 Test Loss: 0.0820371\n",
      "Validation loss decreased (0.073251 --> 0.071919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614888\n",
      "\tspeed: 0.0360s/iter; left time: 770.7342s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610972\n",
      "\tspeed: 0.0186s/iter; left time: 395.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0621701 Vali Loss: 0.0716075 Test Loss: 0.0817624\n",
      "Validation loss decreased (0.071919 --> 0.071608).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612228\n",
      "\tspeed: 0.0390s/iter; left time: 825.8276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592582\n",
      "\tspeed: 0.0177s/iter; left time: 372.9398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0613832 Vali Loss: 0.0709181 Test Loss: 0.0815005\n",
      "Validation loss decreased (0.071608 --> 0.070918).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582864\n",
      "\tspeed: 0.0383s/iter; left time: 802.5415s\n",
      "\titers: 200, epoch: 7 | loss: 0.0598563\n",
      "\tspeed: 0.0208s/iter; left time: 434.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0607176 Vali Loss: 0.0706939 Test Loss: 0.0812478\n",
      "Validation loss decreased (0.070918 --> 0.070694).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0593617\n",
      "\tspeed: 0.0355s/iter; left time: 735.3966s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628847\n",
      "\tspeed: 0.0172s/iter; left time: 354.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0602211 Vali Loss: 0.0707668 Test Loss: 0.0811632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580503\n",
      "\tspeed: 0.0368s/iter; left time: 753.9842s\n",
      "\titers: 200, epoch: 9 | loss: 0.0611335\n",
      "\tspeed: 0.0168s/iter; left time: 343.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0597630 Vali Loss: 0.0707890 Test Loss: 0.0808218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602699\n",
      "\tspeed: 0.0331s/iter; left time: 670.9764s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593928\n",
      "\tspeed: 0.0167s/iter; left time: 337.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0593691 Vali Loss: 0.0710047 Test Loss: 0.0808480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0556815\n",
      "\tspeed: 0.0330s/iter; left time: 661.7002s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595476\n",
      "\tspeed: 0.0164s/iter; left time: 326.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0590156 Vali Loss: 0.0708511 Test Loss: 0.0812676\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595886\n",
      "\tspeed: 0.0344s/iter; left time: 683.3489s\n",
      "\titers: 200, epoch: 12 | loss: 0.0590767\n",
      "\tspeed: 0.0159s/iter; left time: 313.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0587250 Vali Loss: 0.0708682 Test Loss: 0.0809419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582252\n",
      "\tspeed: 0.0371s/iter; left time: 728.5974s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554791\n",
      "\tspeed: 0.0182s/iter; left time: 354.9962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0584485 Vali Loss: 0.0707450 Test Loss: 0.0809526\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605339\n",
      "\tspeed: 0.0356s/iter; left time: 689.5043s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563258\n",
      "\tspeed: 0.0164s/iter; left time: 316.9236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0582030 Vali Loss: 0.0710068 Test Loss: 0.0812410\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0585901\n",
      "\tspeed: 0.0326s/iter; left time: 624.9323s\n",
      "\titers: 200, epoch: 15 | loss: 0.0581249\n",
      "\tspeed: 0.0114s/iter; left time: 216.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.0579818 Vali Loss: 0.0709966 Test Loss: 0.0811102\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0608349\n",
      "\tspeed: 0.0310s/iter; left time: 586.9986s\n",
      "\titers: 200, epoch: 16 | loss: 0.0559778\n",
      "\tspeed: 0.0162s/iter; left time: 304.3297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0577491 Vali Loss: 0.0710170 Test Loss: 0.0809873\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0600169\n",
      "\tspeed: 0.0331s/iter; left time: 619.8494s\n",
      "\titers: 200, epoch: 17 | loss: 0.0599653\n",
      "\tspeed: 0.0160s/iter; left time: 298.7319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0576293 Vali Loss: 0.0709068 Test Loss: 0.0809604\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019239535555243492, rmse:0.13870665431022644, mae:0.08124779164791107, rse:0.536554217338562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1205367\n",
      "\tspeed: 0.0223s/iter; left time: 498.2872s\n",
      "\titers: 200, epoch: 1 | loss: 0.0998166\n",
      "\tspeed: 0.0195s/iter; left time: 433.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1172998 Vali Loss: 0.1021035 Test Loss: 0.1127409\n",
      "Validation loss decreased (inf --> 0.102103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0729760\n",
      "\tspeed: 0.0345s/iter; left time: 761.1189s\n",
      "\titers: 200, epoch: 2 | loss: 0.0699756\n",
      "\tspeed: 0.0168s/iter; left time: 368.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0736096 Vali Loss: 0.0765786 Test Loss: 0.0843095\n",
      "Validation loss decreased (0.102103 --> 0.076579).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0664954\n",
      "\tspeed: 0.0403s/iter; left time: 880.4525s\n",
      "\titers: 200, epoch: 3 | loss: 0.0646975\n",
      "\tspeed: 0.0200s/iter; left time: 434.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0657960 Vali Loss: 0.0734283 Test Loss: 0.0830839\n",
      "Validation loss decreased (0.076579 --> 0.073428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0618110\n",
      "\tspeed: 0.0378s/iter; left time: 818.3536s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655941\n",
      "\tspeed: 0.0175s/iter; left time: 377.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0634535 Vali Loss: 0.0722552 Test Loss: 0.0823200\n",
      "Validation loss decreased (0.073428 --> 0.072255).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0657298\n",
      "\tspeed: 0.0384s/iter; left time: 822.9576s\n",
      "\titers: 200, epoch: 5 | loss: 0.0572107\n",
      "\tspeed: 0.0172s/iter; left time: 365.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0622187 Vali Loss: 0.0716738 Test Loss: 0.0818440\n",
      "Validation loss decreased (0.072255 --> 0.071674).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0609847\n",
      "\tspeed: 0.0374s/iter; left time: 793.0605s\n",
      "\titers: 200, epoch: 6 | loss: 0.0643214\n",
      "\tspeed: 0.0184s/iter; left time: 388.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0613471 Vali Loss: 0.0713921 Test Loss: 0.0818061\n",
      "Validation loss decreased (0.071674 --> 0.071392).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584245\n",
      "\tspeed: 0.0342s/iter; left time: 716.4775s\n",
      "\titers: 200, epoch: 7 | loss: 0.0652889\n",
      "\tspeed: 0.0180s/iter; left time: 374.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0606645 Vali Loss: 0.0711932 Test Loss: 0.0815652\n",
      "Validation loss decreased (0.071392 --> 0.071193).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637661\n",
      "\tspeed: 0.0358s/iter; left time: 741.8518s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629927\n",
      "\tspeed: 0.0189s/iter; left time: 389.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0601458 Vali Loss: 0.0710462 Test Loss: 0.0809855\n",
      "Validation loss decreased (0.071193 --> 0.071046).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606390\n",
      "\tspeed: 0.0382s/iter; left time: 782.8211s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573377\n",
      "\tspeed: 0.0199s/iter; left time: 406.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0595969 Vali Loss: 0.0710664 Test Loss: 0.0812815\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0555640\n",
      "\tspeed: 0.0339s/iter; left time: 687.7493s\n",
      "\titers: 200, epoch: 10 | loss: 0.0637766\n",
      "\tspeed: 0.0156s/iter; left time: 314.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0592606 Vali Loss: 0.0708035 Test Loss: 0.0812008\n",
      "Validation loss decreased (0.071046 --> 0.070804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0608816\n",
      "\tspeed: 0.0359s/iter; left time: 721.1529s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565914\n",
      "\tspeed: 0.0182s/iter; left time: 363.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0589207 Vali Loss: 0.0708215 Test Loss: 0.0806667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567831\n",
      "\tspeed: 0.0340s/iter; left time: 673.7956s\n",
      "\titers: 200, epoch: 12 | loss: 0.0597422\n",
      "\tspeed: 0.0168s/iter; left time: 332.5617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0585763 Vali Loss: 0.0707649 Test Loss: 0.0809839\n",
      "Validation loss decreased (0.070804 --> 0.070765).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0583152\n",
      "\tspeed: 0.0359s/iter; left time: 703.7509s\n",
      "\titers: 200, epoch: 13 | loss: 0.0574382\n",
      "\tspeed: 0.0174s/iter; left time: 340.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0582973 Vali Loss: 0.0708154 Test Loss: 0.0806221\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0587881\n",
      "\tspeed: 0.0329s/iter; left time: 638.2203s\n",
      "\titers: 200, epoch: 14 | loss: 0.0599961\n",
      "\tspeed: 0.0157s/iter; left time: 303.4361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0580145 Vali Loss: 0.0709126 Test Loss: 0.0810556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0572370\n",
      "\tspeed: 0.0334s/iter; left time: 640.4189s\n",
      "\titers: 200, epoch: 15 | loss: 0.0546580\n",
      "\tspeed: 0.0176s/iter; left time: 334.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0577856 Vali Loss: 0.0710658 Test Loss: 0.0806780\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0562614\n",
      "\tspeed: 0.0357s/iter; left time: 676.6003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0550613\n",
      "\tspeed: 0.0155s/iter; left time: 291.5741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0575882 Vali Loss: 0.0708767 Test Loss: 0.0809355\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567380\n",
      "\tspeed: 0.0303s/iter; left time: 567.5180s\n",
      "\titers: 200, epoch: 17 | loss: 0.0561708\n",
      "\tspeed: 0.0114s/iter; left time: 212.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.0573832 Vali Loss: 0.0709557 Test Loss: 0.0809626\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0607312\n",
      "\tspeed: 0.0350s/iter; left time: 646.8254s\n",
      "\titers: 200, epoch: 18 | loss: 0.0602129\n",
      "\tspeed: 0.0212s/iter; left time: 389.7999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0571883 Vali Loss: 0.0709579 Test Loss: 0.0806802\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572911\n",
      "\tspeed: 0.0361s/iter; left time: 659.2290s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603478\n",
      "\tspeed: 0.0161s/iter; left time: 292.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0570933 Vali Loss: 0.0709495 Test Loss: 0.0805782\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0579661\n",
      "\tspeed: 0.0257s/iter; left time: 464.1776s\n",
      "\titers: 200, epoch: 20 | loss: 0.0555187\n",
      "\tspeed: 0.0102s/iter; left time: 183.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.52s\n",
      "Steps: 224 | Train Loss: 0.0569463 Vali Loss: 0.0710830 Test Loss: 0.0806199\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0521434\n",
      "\tspeed: 0.0335s/iter; left time: 596.5032s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538426\n",
      "\tspeed: 0.0190s/iter; left time: 336.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0568332 Vali Loss: 0.0709159 Test Loss: 0.0807794\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0584142\n",
      "\tspeed: 0.0402s/iter; left time: 707.3272s\n",
      "\titers: 200, epoch: 22 | loss: 0.0541840\n",
      "\tspeed: 0.0202s/iter; left time: 353.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0566690 Vali Loss: 0.0708906 Test Loss: 0.0806457\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01897253282368183, rmse:0.137740820646286, mae:0.08098392933607101, rse:0.5328181385993958\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:34.28s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1184496\n",
      "\tspeed: 0.0382s/iter; left time: 848.4294s\n",
      "\titers: 200, epoch: 1 | loss: 0.0971473\n",
      "\tspeed: 0.0170s/iter; left time: 375.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.1167316 Vali Loss: 0.1032083 Test Loss: 0.1129677\n",
      "Validation loss decreased (inf --> 0.103208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0822949\n",
      "\tspeed: 0.0335s/iter; left time: 737.2599s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746721\n",
      "\tspeed: 0.0168s/iter; left time: 367.4588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0773156 Vali Loss: 0.0803216 Test Loss: 0.0886327\n",
      "Validation loss decreased (0.103208 --> 0.080322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0713718\n",
      "\tspeed: 0.0356s/iter; left time: 773.5673s\n",
      "\titers: 200, epoch: 3 | loss: 0.0684350\n",
      "\tspeed: 0.0162s/iter; left time: 350.6414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0697741 Vali Loss: 0.0767432 Test Loss: 0.0876774\n",
      "Validation loss decreased (0.080322 --> 0.076743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674153\n",
      "\tspeed: 0.0345s/iter; left time: 743.1741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699043\n",
      "\tspeed: 0.0163s/iter; left time: 349.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0672569 Vali Loss: 0.0758318 Test Loss: 0.0873202\n",
      "Validation loss decreased (0.076743 --> 0.075832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679794\n",
      "\tspeed: 0.0351s/iter; left time: 747.4898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0696597\n",
      "\tspeed: 0.0167s/iter; left time: 353.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0661320 Vali Loss: 0.0753898 Test Loss: 0.0871050\n",
      "Validation loss decreased (0.075832 --> 0.075390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637402\n",
      "\tspeed: 0.0362s/iter; left time: 762.6548s\n",
      "\titers: 200, epoch: 6 | loss: 0.0633766\n",
      "\tspeed: 0.0164s/iter; left time: 344.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0652604 Vali Loss: 0.0750106 Test Loss: 0.0866593\n",
      "Validation loss decreased (0.075390 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0654606\n",
      "\tspeed: 0.0334s/iter; left time: 695.8694s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664279\n",
      "\tspeed: 0.0158s/iter; left time: 328.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0647009 Vali Loss: 0.0749119 Test Loss: 0.0863478\n",
      "Validation loss decreased (0.075011 --> 0.074912).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0680805\n",
      "\tspeed: 0.0342s/iter; left time: 705.1026s\n",
      "\titers: 200, epoch: 8 | loss: 0.0621320\n",
      "\tspeed: 0.0180s/iter; left time: 370.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0641877 Vali Loss: 0.0751029 Test Loss: 0.0873028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651313\n",
      "\tspeed: 0.0378s/iter; left time: 772.5816s\n",
      "\titers: 200, epoch: 9 | loss: 0.0634317\n",
      "\tspeed: 0.0188s/iter; left time: 382.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0637819 Vali Loss: 0.0752244 Test Loss: 0.0870896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0616768\n",
      "\tspeed: 0.0374s/iter; left time: 755.4338s\n",
      "\titers: 200, epoch: 10 | loss: 0.0662288\n",
      "\tspeed: 0.0173s/iter; left time: 346.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0634420 Vali Loss: 0.0752584 Test Loss: 0.0871234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0668921\n",
      "\tspeed: 0.0366s/iter; left time: 730.2148s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658013\n",
      "\tspeed: 0.0180s/iter; left time: 357.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0630799 Vali Loss: 0.0751184 Test Loss: 0.0872565\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644008\n",
      "\tspeed: 0.0369s/iter; left time: 727.9760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0626267\n",
      "\tspeed: 0.0178s/iter; left time: 349.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0627786 Vali Loss: 0.0755117 Test Loss: 0.0872327\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0656211\n",
      "\tspeed: 0.0348s/iter; left time: 678.5966s\n",
      "\titers: 200, epoch: 13 | loss: 0.0651881\n",
      "\tspeed: 0.0167s/iter; left time: 325.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0625154 Vali Loss: 0.0754505 Test Loss: 0.0871814\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0627563\n",
      "\tspeed: 0.0348s/iter; left time: 672.2194s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605988\n",
      "\tspeed: 0.0174s/iter; left time: 333.8653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0622779 Vali Loss: 0.0753620 Test Loss: 0.0871366\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0575872\n",
      "\tspeed: 0.0347s/iter; left time: 661.9087s\n",
      "\titers: 200, epoch: 15 | loss: 0.0590335\n",
      "\tspeed: 0.0179s/iter; left time: 340.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0620248 Vali Loss: 0.0754092 Test Loss: 0.0868788\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0634177\n",
      "\tspeed: 0.0340s/iter; left time: 642.0154s\n",
      "\titers: 200, epoch: 16 | loss: 0.0600698\n",
      "\tspeed: 0.0172s/iter; left time: 323.2388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0618397 Vali Loss: 0.0753441 Test Loss: 0.0870627\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604233\n",
      "\tspeed: 0.0331s/iter; left time: 617.6786s\n",
      "\titers: 200, epoch: 17 | loss: 0.0613871\n",
      "\tspeed: 0.0166s/iter; left time: 306.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0616135 Vali Loss: 0.0754214 Test Loss: 0.0868189\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020680325105786324, rmse:0.1438065618276596, mae:0.08634777367115021, rse:0.5569763779640198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1199273\n",
      "\tspeed: 0.0199s/iter; left time: 442.6888s\n",
      "\titers: 200, epoch: 1 | loss: 0.0989189\n",
      "\tspeed: 0.0177s/iter; left time: 391.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1187141 Vali Loss: 0.1047034 Test Loss: 0.1147500\n",
      "Validation loss decreased (inf --> 0.104703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0757048\n",
      "\tspeed: 0.0365s/iter; left time: 801.5526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0738494\n",
      "\tspeed: 0.0171s/iter; left time: 374.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0777085 Vali Loss: 0.0807960 Test Loss: 0.0889714\n",
      "Validation loss decreased (0.104703 --> 0.080796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714377\n",
      "\tspeed: 0.0384s/iter; left time: 834.3769s\n",
      "\titers: 200, epoch: 3 | loss: 0.0712184\n",
      "\tspeed: 0.0199s/iter; left time: 431.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0699912 Vali Loss: 0.0772108 Test Loss: 0.0877922\n",
      "Validation loss decreased (0.080796 --> 0.077211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0695626\n",
      "\tspeed: 0.0410s/iter; left time: 882.0667s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655936\n",
      "\tspeed: 0.0184s/iter; left time: 393.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0672771 Vali Loss: 0.0760775 Test Loss: 0.0875164\n",
      "Validation loss decreased (0.077211 --> 0.076078).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0644204\n",
      "\tspeed: 0.0368s/iter; left time: 783.1993s\n",
      "\titers: 200, epoch: 5 | loss: 0.0656032\n",
      "\tspeed: 0.0136s/iter; left time: 287.8964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0660556 Vali Loss: 0.0758454 Test Loss: 0.0869548\n",
      "Validation loss decreased (0.076078 --> 0.075845).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0623212\n",
      "\tspeed: 0.0368s/iter; left time: 775.1321s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686863\n",
      "\tspeed: 0.0187s/iter; left time: 391.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0652493 Vali Loss: 0.0755209 Test Loss: 0.0870234\n",
      "Validation loss decreased (0.075845 --> 0.075521).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662842\n",
      "\tspeed: 0.0356s/iter; left time: 742.3226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0639251\n",
      "\tspeed: 0.0103s/iter; left time: 214.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.0646592 Vali Loss: 0.0752190 Test Loss: 0.0869825\n",
      "Validation loss decreased (0.075521 --> 0.075219).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0654634\n",
      "\tspeed: 0.0302s/iter; left time: 623.6208s\n",
      "\titers: 200, epoch: 8 | loss: 0.0651252\n",
      "\tspeed: 0.0112s/iter; left time: 230.5651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0641802 Vali Loss: 0.0752478 Test Loss: 0.0872835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623540\n",
      "\tspeed: 0.0334s/iter; left time: 682.7451s\n",
      "\titers: 200, epoch: 9 | loss: 0.0637192\n",
      "\tspeed: 0.0203s/iter; left time: 412.4365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0637615 Vali Loss: 0.0753023 Test Loss: 0.0868635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667625\n",
      "\tspeed: 0.0352s/iter; left time: 711.2027s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623384\n",
      "\tspeed: 0.0166s/iter; left time: 332.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0633828 Vali Loss: 0.0753395 Test Loss: 0.0872248\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0618423\n",
      "\tspeed: 0.0349s/iter; left time: 696.5366s\n",
      "\titers: 200, epoch: 11 | loss: 0.0635836\n",
      "\tspeed: 0.0166s/iter; left time: 330.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0630827 Vali Loss: 0.0754981 Test Loss: 0.0873296\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0592245\n",
      "\tspeed: 0.0333s/iter; left time: 657.1804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0593541\n",
      "\tspeed: 0.0112s/iter; left time: 220.4952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.0627813 Vali Loss: 0.0754852 Test Loss: 0.0872886\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0609198\n",
      "\tspeed: 0.0379s/iter; left time: 740.6281s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618616\n",
      "\tspeed: 0.0208s/iter; left time: 403.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0625009 Vali Loss: 0.0756986 Test Loss: 0.0873795\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0633694\n",
      "\tspeed: 0.0381s/iter; left time: 736.0156s\n",
      "\titers: 200, epoch: 14 | loss: 0.0584620\n",
      "\tspeed: 0.0199s/iter; left time: 382.6407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0622817 Vali Loss: 0.0755458 Test Loss: 0.0874008\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0634874\n",
      "\tspeed: 0.0360s/iter; left time: 686.8034s\n",
      "\titers: 200, epoch: 15 | loss: 0.0633634\n",
      "\tspeed: 0.0170s/iter; left time: 323.2656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0620784 Vali Loss: 0.0755770 Test Loss: 0.0873563\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0619751\n",
      "\tspeed: 0.0339s/iter; left time: 638.9103s\n",
      "\titers: 200, epoch: 16 | loss: 0.0627747\n",
      "\tspeed: 0.0162s/iter; left time: 302.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0618906 Vali Loss: 0.0755610 Test Loss: 0.0875779\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0608088\n",
      "\tspeed: 0.0339s/iter; left time: 632.4883s\n",
      "\titers: 200, epoch: 17 | loss: 0.0618009\n",
      "\tspeed: 0.0154s/iter; left time: 286.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0617321 Vali Loss: 0.0756512 Test Loss: 0.0872132\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020824121311306953, rmse:0.14430564641952515, mae:0.08698248863220215, rse:0.5589094161987305\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:08.51s\n",
      "Intermediate time for FR: 00h:16m:10.19s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616937\n",
      "\tspeed: 0.0419s/iter; left time: 933.3896s\n",
      "\titers: 200, epoch: 1 | loss: 0.1293149\n",
      "\tspeed: 0.0162s/iter; left time: 360.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1621773 Vali Loss: 0.1138775 Test Loss: 0.1172790\n",
      "Validation loss decreased (inf --> 0.113878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786218\n",
      "\tspeed: 0.0397s/iter; left time: 875.9591s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0159s/iter; left time: 349.1550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0831071 Vali Loss: 0.0641884 Test Loss: 0.0671537\n",
      "Validation loss decreased (0.113878 --> 0.064188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700320\n",
      "\tspeed: 0.0335s/iter; left time: 731.5165s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662021\n",
      "\tspeed: 0.0214s/iter; left time: 465.3328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0678796 Vali Loss: 0.0606680 Test Loss: 0.0635218\n",
      "Validation loss decreased (0.064188 --> 0.060668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612472\n",
      "\tspeed: 0.0380s/iter; left time: 821.8338s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621978\n",
      "\tspeed: 0.0216s/iter; left time: 464.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0645124 Vali Loss: 0.0592873 Test Loss: 0.0619248\n",
      "Validation loss decreased (0.060668 --> 0.059287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0623944\n",
      "\tspeed: 0.0400s/iter; left time: 855.2095s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643269\n",
      "\tspeed: 0.0217s/iter; left time: 462.4347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0625303 Vali Loss: 0.0582227 Test Loss: 0.0607137\n",
      "Validation loss decreased (0.059287 --> 0.058223).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0643557\n",
      "\tspeed: 0.0418s/iter; left time: 886.1937s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613264\n",
      "\tspeed: 0.0238s/iter; left time: 501.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0612088 Vali Loss: 0.0574816 Test Loss: 0.0600706\n",
      "Validation loss decreased (0.058223 --> 0.057482).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583737\n",
      "\tspeed: 0.0406s/iter; left time: 850.7318s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589131\n",
      "\tspeed: 0.0215s/iter; left time: 448.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0603114 Vali Loss: 0.0568728 Test Loss: 0.0594318\n",
      "Validation loss decreased (0.057482 --> 0.056873).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0602870\n",
      "\tspeed: 0.0386s/iter; left time: 800.1336s\n",
      "\titers: 200, epoch: 8 | loss: 0.0557014\n",
      "\tspeed: 0.0207s/iter; left time: 427.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0596433 Vali Loss: 0.0565994 Test Loss: 0.0593777\n",
      "Validation loss decreased (0.056873 --> 0.056599).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0564329\n",
      "\tspeed: 0.0403s/iter; left time: 827.1636s\n",
      "\titers: 200, epoch: 9 | loss: 0.0571721\n",
      "\tspeed: 0.0208s/iter; left time: 425.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0589292 Vali Loss: 0.0562056 Test Loss: 0.0591851\n",
      "Validation loss decreased (0.056599 --> 0.056206).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0580420\n",
      "\tspeed: 0.0401s/iter; left time: 813.4893s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585416\n",
      "\tspeed: 0.0216s/iter; left time: 436.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0584382 Vali Loss: 0.0559097 Test Loss: 0.0587973\n",
      "Validation loss decreased (0.056206 --> 0.055910).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601182\n",
      "\tspeed: 0.0332s/iter; left time: 665.2795s\n",
      "\titers: 200, epoch: 11 | loss: 0.0593806\n",
      "\tspeed: 0.0160s/iter; left time: 318.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0579796 Vali Loss: 0.0556803 Test Loss: 0.0584713\n",
      "Validation loss decreased (0.055910 --> 0.055680).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591369\n",
      "\tspeed: 0.0357s/iter; left time: 708.2638s\n",
      "\titers: 200, epoch: 12 | loss: 0.0568577\n",
      "\tspeed: 0.0202s/iter; left time: 398.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0576995 Vali Loss: 0.0555104 Test Loss: 0.0582978\n",
      "Validation loss decreased (0.055680 --> 0.055510).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595251\n",
      "\tspeed: 0.0380s/iter; left time: 745.7967s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602591\n",
      "\tspeed: 0.0185s/iter; left time: 360.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0573981 Vali Loss: 0.0553351 Test Loss: 0.0582722\n",
      "Validation loss decreased (0.055510 --> 0.055335).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0583053\n",
      "\tspeed: 0.0404s/iter; left time: 782.9728s\n",
      "\titers: 200, epoch: 14 | loss: 0.0602665\n",
      "\tspeed: 0.0211s/iter; left time: 406.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0570490 Vali Loss: 0.0551690 Test Loss: 0.0581385\n",
      "Validation loss decreased (0.055335 --> 0.055169).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0560705\n",
      "\tspeed: 0.0387s/iter; left time: 741.8995s\n",
      "\titers: 200, epoch: 15 | loss: 0.0556168\n",
      "\tspeed: 0.0209s/iter; left time: 397.5476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0568528 Vali Loss: 0.0549350 Test Loss: 0.0578218\n",
      "Validation loss decreased (0.055169 --> 0.054935).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580549\n",
      "\tspeed: 0.0404s/iter; left time: 766.0363s\n",
      "\titers: 200, epoch: 16 | loss: 0.0600087\n",
      "\tspeed: 0.0218s/iter; left time: 410.9668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0566595 Vali Loss: 0.0549669 Test Loss: 0.0577802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645831\n",
      "\tspeed: 0.0414s/iter; left time: 775.0621s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576199\n",
      "\tspeed: 0.0269s/iter; left time: 500.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0564659 Vali Loss: 0.0549089 Test Loss: 0.0576262\n",
      "Validation loss decreased (0.054935 --> 0.054909).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542376\n",
      "\tspeed: 0.0389s/iter; left time: 718.5548s\n",
      "\titers: 200, epoch: 18 | loss: 0.0603156\n",
      "\tspeed: 0.0220s/iter; left time: 403.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0562640 Vali Loss: 0.0548581 Test Loss: 0.0575692\n",
      "Validation loss decreased (0.054909 --> 0.054858).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0547322\n",
      "\tspeed: 0.0392s/iter; left time: 716.5497s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540715\n",
      "\tspeed: 0.0196s/iter; left time: 356.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0561902 Vali Loss: 0.0546502 Test Loss: 0.0575371\n",
      "Validation loss decreased (0.054858 --> 0.054650).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0570445\n",
      "\tspeed: 0.0427s/iter; left time: 771.0590s\n",
      "\titers: 200, epoch: 20 | loss: 0.0555143\n",
      "\tspeed: 0.0265s/iter; left time: 474.8313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0560226 Vali Loss: 0.0546247 Test Loss: 0.0574184\n",
      "Validation loss decreased (0.054650 --> 0.054625).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0558135\n",
      "\tspeed: 0.0379s/iter; left time: 675.5405s\n",
      "\titers: 200, epoch: 21 | loss: 0.0566086\n",
      "\tspeed: 0.0207s/iter; left time: 367.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0559200 Vali Loss: 0.0546582 Test Loss: 0.0573801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0552839\n",
      "\tspeed: 0.0375s/iter; left time: 659.2791s\n",
      "\titers: 200, epoch: 22 | loss: 0.0544736\n",
      "\tspeed: 0.0224s/iter; left time: 392.2094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0558326 Vali Loss: 0.0545838 Test Loss: 0.0573570\n",
      "Validation loss decreased (0.054625 --> 0.054584).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0524441\n",
      "\tspeed: 0.0379s/iter; left time: 658.5418s\n",
      "\titers: 200, epoch: 23 | loss: 0.0555646\n",
      "\tspeed: 0.0226s/iter; left time: 390.7118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0556918 Vali Loss: 0.0544404 Test Loss: 0.0574504\n",
      "Validation loss decreased (0.054584 --> 0.054440).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0550653\n",
      "\tspeed: 0.0383s/iter; left time: 656.6299s\n",
      "\titers: 200, epoch: 24 | loss: 0.0564538\n",
      "\tspeed: 0.0153s/iter; left time: 261.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0556784 Vali Loss: 0.0544493 Test Loss: 0.0573502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0545851\n",
      "\tspeed: 0.0384s/iter; left time: 650.0851s\n",
      "\titers: 200, epoch: 25 | loss: 0.0584961\n",
      "\tspeed: 0.0206s/iter; left time: 346.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0555970 Vali Loss: 0.0544318 Test Loss: 0.0573393\n",
      "Validation loss decreased (0.054440 --> 0.054432).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0540913\n",
      "\tspeed: 0.0402s/iter; left time: 672.2056s\n",
      "\titers: 200, epoch: 26 | loss: 0.0536483\n",
      "\tspeed: 0.0238s/iter; left time: 394.4233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0554906 Vali Loss: 0.0545393 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0575815\n",
      "\tspeed: 0.0381s/iter; left time: 628.0815s\n",
      "\titers: 200, epoch: 27 | loss: 0.0563095\n",
      "\tspeed: 0.0202s/iter; left time: 330.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0554416 Vali Loss: 0.0544036 Test Loss: 0.0572838\n",
      "Validation loss decreased (0.054432 --> 0.054404).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553780\n",
      "\tspeed: 0.0349s/iter; left time: 567.8167s\n",
      "\titers: 200, epoch: 28 | loss: 0.0565708\n",
      "\tspeed: 0.0207s/iter; left time: 333.8519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0553560 Vali Loss: 0.0543272 Test Loss: 0.0572298\n",
      "Validation loss decreased (0.054404 --> 0.054327).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0568186\n",
      "\tspeed: 0.0389s/iter; left time: 624.1131s\n",
      "\titers: 200, epoch: 29 | loss: 0.0543701\n",
      "\tspeed: 0.0214s/iter; left time: 340.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0553623 Vali Loss: 0.0543758 Test Loss: 0.0572267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0567131\n",
      "\tspeed: 0.0413s/iter; left time: 653.4989s\n",
      "\titers: 200, epoch: 30 | loss: 0.0531917\n",
      "\tspeed: 0.0197s/iter; left time: 310.1616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0553197 Vali Loss: 0.0542728 Test Loss: 0.0572275\n",
      "Validation loss decreased (0.054327 --> 0.054273).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0558449\n",
      "\tspeed: 0.0344s/iter; left time: 535.9838s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548754\n",
      "\tspeed: 0.0211s/iter; left time: 326.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0552432 Vali Loss: 0.0543370 Test Loss: 0.0572568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0554102\n",
      "\tspeed: 0.0388s/iter; left time: 595.4150s\n",
      "\titers: 200, epoch: 32 | loss: 0.0523020\n",
      "\tspeed: 0.0211s/iter; left time: 321.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0551945 Vali Loss: 0.0543816 Test Loss: 0.0572216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0551455\n",
      "\tspeed: 0.0380s/iter; left time: 575.0281s\n",
      "\titers: 200, epoch: 33 | loss: 0.0554751\n",
      "\tspeed: 0.0215s/iter; left time: 322.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0551863 Vali Loss: 0.0542584 Test Loss: 0.0572228\n",
      "Validation loss decreased (0.054273 --> 0.054258).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0576348\n",
      "\tspeed: 0.0359s/iter; left time: 535.0968s\n",
      "\titers: 200, epoch: 34 | loss: 0.0498386\n",
      "\tspeed: 0.0173s/iter; left time: 256.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0552659 Vali Loss: 0.0542453 Test Loss: 0.0571133\n",
      "Validation loss decreased (0.054258 --> 0.054245).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0543972\n",
      "\tspeed: 0.0322s/iter; left time: 472.1983s\n",
      "\titers: 200, epoch: 35 | loss: 0.0587596\n",
      "\tspeed: 0.0162s/iter; left time: 235.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0551590 Vali Loss: 0.0541801 Test Loss: 0.0570815\n",
      "Validation loss decreased (0.054245 --> 0.054180).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545957\n",
      "\tspeed: 0.0373s/iter; left time: 538.9974s\n",
      "\titers: 200, epoch: 36 | loss: 0.0558465\n",
      "\tspeed: 0.0178s/iter; left time: 255.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0551445 Vali Loss: 0.0542503 Test Loss: 0.0571125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0563166\n",
      "\tspeed: 0.0427s/iter; left time: 608.2393s\n",
      "\titers: 200, epoch: 37 | loss: 0.0556657\n",
      "\tspeed: 0.0188s/iter; left time: 266.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0550431 Vali Loss: 0.0542911 Test Loss: 0.0571352\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0558167\n",
      "\tspeed: 0.0328s/iter; left time: 459.0170s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548673\n",
      "\tspeed: 0.0182s/iter; left time: 252.5437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0551248 Vali Loss: 0.0542361 Test Loss: 0.0571126\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0531604\n",
      "\tspeed: 0.0348s/iter; left time: 479.6322s\n",
      "\titers: 200, epoch: 39 | loss: 0.0541852\n",
      "\tspeed: 0.0181s/iter; left time: 248.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0551302 Vali Loss: 0.0542396 Test Loss: 0.0571269\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0536777\n",
      "\tspeed: 0.0334s/iter; left time: 453.5990s\n",
      "\titers: 200, epoch: 40 | loss: 0.0491179\n",
      "\tspeed: 0.0166s/iter; left time: 223.1372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0550740 Vali Loss: 0.0542012 Test Loss: 0.0571210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0555353\n",
      "\tspeed: 0.0316s/iter; left time: 420.9979s\n",
      "\titers: 200, epoch: 41 | loss: 0.0553311\n",
      "\tspeed: 0.0168s/iter; left time: 221.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0550478 Vali Loss: 0.0542384 Test Loss: 0.0570900\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0529031\n",
      "\tspeed: 0.0323s/iter; left time: 423.8254s\n",
      "\titers: 200, epoch: 42 | loss: 0.0545491\n",
      "\tspeed: 0.0160s/iter; left time: 207.8017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0550387 Vali Loss: 0.0542013 Test Loss: 0.0570917\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0543719\n",
      "\tspeed: 0.0323s/iter; left time: 416.8325s\n",
      "\titers: 200, epoch: 43 | loss: 0.0559602\n",
      "\tspeed: 0.0162s/iter; left time: 207.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0550606 Vali Loss: 0.0541766 Test Loss: 0.0570903\n",
      "Validation loss decreased (0.054180 --> 0.054177).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0572202\n",
      "\tspeed: 0.0349s/iter; left time: 442.6877s\n",
      "\titers: 200, epoch: 44 | loss: 0.0519166\n",
      "\tspeed: 0.0165s/iter; left time: 207.5768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0550394 Vali Loss: 0.0542363 Test Loss: 0.0571050\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0566712\n",
      "\tspeed: 0.0352s/iter; left time: 437.6729s\n",
      "\titers: 200, epoch: 45 | loss: 0.0531058\n",
      "\tspeed: 0.0218s/iter; left time: 269.2909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0550391 Vali Loss: 0.0542344 Test Loss: 0.0570580\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0527859\n",
      "\tspeed: 0.0395s/iter; left time: 482.2283s\n",
      "\titers: 200, epoch: 46 | loss: 0.0594338\n",
      "\tspeed: 0.0226s/iter; left time: 273.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0550554 Vali Loss: 0.0542034 Test Loss: 0.0570808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0532356\n",
      "\tspeed: 0.0408s/iter; left time: 489.5568s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507534\n",
      "\tspeed: 0.0229s/iter; left time: 272.9261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0550222 Vali Loss: 0.0542041 Test Loss: 0.0570767\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0573041\n",
      "\tspeed: 0.0370s/iter; left time: 435.3961s\n",
      "\titers: 200, epoch: 48 | loss: 0.0557307\n",
      "\tspeed: 0.0184s/iter; left time: 214.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0550038 Vali Loss: 0.0542078 Test Loss: 0.0570859\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0526317\n",
      "\tspeed: 0.0380s/iter; left time: 439.3102s\n",
      "\titers: 200, epoch: 49 | loss: 0.0579636\n",
      "\tspeed: 0.0170s/iter; left time: 195.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0549856 Vali Loss: 0.0541985 Test Loss: 0.0570581\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0523591\n",
      "\tspeed: 0.0387s/iter; left time: 438.1626s\n",
      "\titers: 200, epoch: 50 | loss: 0.0563584\n",
      "\tspeed: 0.0198s/iter; left time: 222.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0550367 Vali Loss: 0.0541956 Test Loss: 0.0570556\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0564525\n",
      "\tspeed: 0.0366s/iter; left time: 406.3829s\n",
      "\titers: 200, epoch: 51 | loss: 0.0565447\n",
      "\tspeed: 0.0222s/iter; left time: 244.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0550026 Vali Loss: 0.0542391 Test Loss: 0.0570694\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0506994\n",
      "\tspeed: 0.0377s/iter; left time: 410.0745s\n",
      "\titers: 200, epoch: 52 | loss: 0.0568837\n",
      "\tspeed: 0.0163s/iter; left time: 176.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0549957 Vali Loss: 0.0541974 Test Loss: 0.0570478\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0580142\n",
      "\tspeed: 0.0324s/iter; left time: 345.4775s\n",
      "\titers: 200, epoch: 53 | loss: 0.0541511\n",
      "\tspeed: 0.0166s/iter; left time: 174.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0550675 Vali Loss: 0.0542083 Test Loss: 0.0570548\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010154716670513153, rmse:0.10077061504125595, mae:0.05709032714366913, rse:0.3807625472545624\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1610506\n",
      "\tspeed: 0.0188s/iter; left time: 419.7050s\n",
      "\titers: 200, epoch: 1 | loss: 0.1285035\n",
      "\tspeed: 0.0181s/iter; left time: 402.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1584078 Vali Loss: 0.1112813 Test Loss: 0.1148751\n",
      "Validation loss decreased (inf --> 0.111281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0787778\n",
      "\tspeed: 0.0362s/iter; left time: 799.3922s\n",
      "\titers: 200, epoch: 2 | loss: 0.0683310\n",
      "\tspeed: 0.0207s/iter; left time: 454.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0820684 Vali Loss: 0.0645437 Test Loss: 0.0670378\n",
      "Validation loss decreased (0.111281 --> 0.064544).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0723705\n",
      "\tspeed: 0.0330s/iter; left time: 722.1809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655988\n",
      "\tspeed: 0.0166s/iter; left time: 360.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0676317 Vali Loss: 0.0607514 Test Loss: 0.0636831\n",
      "Validation loss decreased (0.064544 --> 0.060751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0685277\n",
      "\tspeed: 0.0347s/iter; left time: 751.0939s\n",
      "\titers: 200, epoch: 4 | loss: 0.0653297\n",
      "\tspeed: 0.0160s/iter; left time: 343.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0643501 Vali Loss: 0.0591042 Test Loss: 0.0618261\n",
      "Validation loss decreased (0.060751 --> 0.059104).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0672670\n",
      "\tspeed: 0.0347s/iter; left time: 742.0660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0667990\n",
      "\tspeed: 0.0181s/iter; left time: 385.5306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0623819 Vali Loss: 0.0582878 Test Loss: 0.0607396\n",
      "Validation loss decreased (0.059104 --> 0.058288).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608419\n",
      "\tspeed: 0.0351s/iter; left time: 742.9724s\n",
      "\titers: 200, epoch: 6 | loss: 0.0622714\n",
      "\tspeed: 0.0177s/iter; left time: 372.3297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0611188 Vali Loss: 0.0573623 Test Loss: 0.0598728\n",
      "Validation loss decreased (0.058288 --> 0.057362).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605497\n",
      "\tspeed: 0.0377s/iter; left time: 790.6057s\n",
      "\titers: 200, epoch: 7 | loss: 0.0576070\n",
      "\tspeed: 0.0173s/iter; left time: 360.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0601095 Vali Loss: 0.0568216 Test Loss: 0.0594647\n",
      "Validation loss decreased (0.057362 --> 0.056822).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0584388\n",
      "\tspeed: 0.0400s/iter; left time: 828.8036s\n",
      "\titers: 200, epoch: 8 | loss: 0.0627291\n",
      "\tspeed: 0.0164s/iter; left time: 339.3710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0594910 Vali Loss: 0.0564318 Test Loss: 0.0589640\n",
      "Validation loss decreased (0.056822 --> 0.056432).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600662\n",
      "\tspeed: 0.0325s/iter; left time: 667.1825s\n",
      "\titers: 200, epoch: 9 | loss: 0.0586554\n",
      "\tspeed: 0.0154s/iter; left time: 314.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0588444 Vali Loss: 0.0561253 Test Loss: 0.0588837\n",
      "Validation loss decreased (0.056432 --> 0.056125).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0557066\n",
      "\tspeed: 0.0318s/iter; left time: 645.6211s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584247\n",
      "\tspeed: 0.0167s/iter; left time: 336.1058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0583450 Vali Loss: 0.0557308 Test Loss: 0.0584586\n",
      "Validation loss decreased (0.056125 --> 0.055731).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559020\n",
      "\tspeed: 0.0428s/iter; left time: 858.3108s\n",
      "\titers: 200, epoch: 11 | loss: 0.0576367\n",
      "\tspeed: 0.0279s/iter; left time: 557.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0579040 Vali Loss: 0.0555348 Test Loss: 0.0581103\n",
      "Validation loss decreased (0.055731 --> 0.055535).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567538\n",
      "\tspeed: 0.0421s/iter; left time: 835.7765s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560350\n",
      "\tspeed: 0.0215s/iter; left time: 424.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0575043 Vali Loss: 0.0554236 Test Loss: 0.0582516\n",
      "Validation loss decreased (0.055535 --> 0.055424).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564369\n",
      "\tspeed: 0.0357s/iter; left time: 699.3805s\n",
      "\titers: 200, epoch: 13 | loss: 0.0550606\n",
      "\tspeed: 0.0172s/iter; left time: 334.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0572653 Vali Loss: 0.0552685 Test Loss: 0.0578046\n",
      "Validation loss decreased (0.055424 --> 0.055268).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552796\n",
      "\tspeed: 0.0340s/iter; left time: 658.8784s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563061\n",
      "\tspeed: 0.0168s/iter; left time: 323.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0569976 Vali Loss: 0.0549985 Test Loss: 0.0578449\n",
      "Validation loss decreased (0.055268 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0553267\n",
      "\tspeed: 0.0346s/iter; left time: 663.8554s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552410\n",
      "\tspeed: 0.0235s/iter; left time: 448.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0566966 Vali Loss: 0.0550084 Test Loss: 0.0578465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0579220\n",
      "\tspeed: 0.0395s/iter; left time: 749.0941s\n",
      "\titers: 200, epoch: 16 | loss: 0.0572330\n",
      "\tspeed: 0.0218s/iter; left time: 409.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0564825 Vali Loss: 0.0547918 Test Loss: 0.0575776\n",
      "Validation loss decreased (0.054998 --> 0.054792).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589450\n",
      "\tspeed: 0.0383s/iter; left time: 717.0681s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576640\n",
      "\tspeed: 0.0187s/iter; left time: 348.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0562846 Vali Loss: 0.0547845 Test Loss: 0.0577217\n",
      "Validation loss decreased (0.054792 --> 0.054784).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0530010\n",
      "\tspeed: 0.0357s/iter; left time: 660.6890s\n",
      "\titers: 200, epoch: 18 | loss: 0.0555538\n",
      "\tspeed: 0.0177s/iter; left time: 326.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0562040 Vali Loss: 0.0546647 Test Loss: 0.0575470\n",
      "Validation loss decreased (0.054784 --> 0.054665).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0600372\n",
      "\tspeed: 0.0344s/iter; left time: 628.8980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588763\n",
      "\tspeed: 0.0221s/iter; left time: 402.1395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0560034 Vali Loss: 0.0546750 Test Loss: 0.0575076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549666\n",
      "\tspeed: 0.0353s/iter; left time: 636.6114s\n",
      "\titers: 200, epoch: 20 | loss: 0.0557349\n",
      "\tspeed: 0.0169s/iter; left time: 302.3769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0558920 Vali Loss: 0.0546148 Test Loss: 0.0572925\n",
      "Validation loss decreased (0.054665 --> 0.054615).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0611273\n",
      "\tspeed: 0.0334s/iter; left time: 595.8716s\n",
      "\titers: 200, epoch: 21 | loss: 0.0555432\n",
      "\tspeed: 0.0180s/iter; left time: 319.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0558074 Vali Loss: 0.0544638 Test Loss: 0.0573065\n",
      "Validation loss decreased (0.054615 --> 0.054464).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0553261\n",
      "\tspeed: 0.0349s/iter; left time: 613.9448s\n",
      "\titers: 200, epoch: 22 | loss: 0.0545610\n",
      "\tspeed: 0.0243s/iter; left time: 426.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0556516 Vali Loss: 0.0545388 Test Loss: 0.0573563\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0519268\n",
      "\tspeed: 0.0405s/iter; left time: 703.6119s\n",
      "\titers: 200, epoch: 23 | loss: 0.0549375\n",
      "\tspeed: 0.0173s/iter; left time: 298.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0554982 Vali Loss: 0.0544698 Test Loss: 0.0573073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0538077\n",
      "\tspeed: 0.0383s/iter; left time: 656.1082s\n",
      "\titers: 200, epoch: 24 | loss: 0.0499192\n",
      "\tspeed: 0.0185s/iter; left time: 314.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0555171 Vali Loss: 0.0543724 Test Loss: 0.0572519\n",
      "Validation loss decreased (0.054464 --> 0.054372).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521827\n",
      "\tspeed: 0.0360s/iter; left time: 609.6250s\n",
      "\titers: 200, epoch: 25 | loss: 0.0556912\n",
      "\tspeed: 0.0184s/iter; left time: 310.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0554058 Vali Loss: 0.0543955 Test Loss: 0.0572159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0546092\n",
      "\tspeed: 0.0398s/iter; left time: 664.5969s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594402\n",
      "\tspeed: 0.0188s/iter; left time: 312.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0554423 Vali Loss: 0.0543845 Test Loss: 0.0572353\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0523095\n",
      "\tspeed: 0.0327s/iter; left time: 539.2249s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493897\n",
      "\tspeed: 0.0165s/iter; left time: 270.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0553154 Vali Loss: 0.0543739 Test Loss: 0.0571078\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0535763\n",
      "\tspeed: 0.0360s/iter; left time: 584.5392s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525553\n",
      "\tspeed: 0.0191s/iter; left time: 308.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0552507 Vali Loss: 0.0543096 Test Loss: 0.0571405\n",
      "Validation loss decreased (0.054372 --> 0.054310).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0524478\n",
      "\tspeed: 0.0388s/iter; left time: 622.1581s\n",
      "\titers: 200, epoch: 29 | loss: 0.0570504\n",
      "\tspeed: 0.0188s/iter; left time: 299.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0551900 Vali Loss: 0.0542487 Test Loss: 0.0571053\n",
      "Validation loss decreased (0.054310 --> 0.054249).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0561734\n",
      "\tspeed: 0.0321s/iter; left time: 507.7820s\n",
      "\titers: 200, epoch: 30 | loss: 0.0546668\n",
      "\tspeed: 0.0208s/iter; left time: 326.9252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0551544 Vali Loss: 0.0542268 Test Loss: 0.0570755\n",
      "Validation loss decreased (0.054249 --> 0.054227).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0529816\n",
      "\tspeed: 0.0411s/iter; left time: 640.4285s\n",
      "\titers: 200, epoch: 31 | loss: 0.0546759\n",
      "\tspeed: 0.0219s/iter; left time: 338.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0551590 Vali Loss: 0.0542538 Test Loss: 0.0570476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555592\n",
      "\tspeed: 0.0387s/iter; left time: 593.7071s\n",
      "\titers: 200, epoch: 32 | loss: 0.0514617\n",
      "\tspeed: 0.0168s/iter; left time: 256.3955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0551488 Vali Loss: 0.0542344 Test Loss: 0.0570845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0525008\n",
      "\tspeed: 0.0337s/iter; left time: 510.3743s\n",
      "\titers: 200, epoch: 33 | loss: 0.0569440\n",
      "\tspeed: 0.0160s/iter; left time: 240.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0550831 Vali Loss: 0.0542495 Test Loss: 0.0570644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525543\n",
      "\tspeed: 0.0352s/iter; left time: 525.4690s\n",
      "\titers: 200, epoch: 34 | loss: 0.0591688\n",
      "\tspeed: 0.0218s/iter; left time: 322.7212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0550690 Vali Loss: 0.0542471 Test Loss: 0.0570282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535423\n",
      "\tspeed: 0.0408s/iter; left time: 598.7067s\n",
      "\titers: 200, epoch: 35 | loss: 0.0579209\n",
      "\tspeed: 0.0181s/iter; left time: 263.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0550663 Vali Loss: 0.0541829 Test Loss: 0.0570068\n",
      "Validation loss decreased (0.054227 --> 0.054183).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0559429\n",
      "\tspeed: 0.0337s/iter; left time: 486.8526s\n",
      "\titers: 200, epoch: 36 | loss: 0.0543486\n",
      "\tspeed: 0.0215s/iter; left time: 309.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0549738 Vali Loss: 0.0542202 Test Loss: 0.0570162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0546824\n",
      "\tspeed: 0.0388s/iter; left time: 552.9148s\n",
      "\titers: 200, epoch: 37 | loss: 0.0575518\n",
      "\tspeed: 0.0208s/iter; left time: 293.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0549713 Vali Loss: 0.0542553 Test Loss: 0.0570356\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0555415\n",
      "\tspeed: 0.0395s/iter; left time: 553.1188s\n",
      "\titers: 200, epoch: 38 | loss: 0.0582025\n",
      "\tspeed: 0.0230s/iter; left time: 320.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0549408 Vali Loss: 0.0542287 Test Loss: 0.0569837\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0545080\n",
      "\tspeed: 0.0416s/iter; left time: 573.1975s\n",
      "\titers: 200, epoch: 39 | loss: 0.0574678\n",
      "\tspeed: 0.0259s/iter; left time: 354.7270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0548682 Vali Loss: 0.0542823 Test Loss: 0.0570213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552859\n",
      "\tspeed: 0.0419s/iter; left time: 567.7448s\n",
      "\titers: 200, epoch: 40 | loss: 0.0583868\n",
      "\tspeed: 0.0171s/iter; left time: 230.3021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0549664 Vali Loss: 0.0542373 Test Loss: 0.0570116\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0586167\n",
      "\tspeed: 0.0440s/iter; left time: 587.5427s\n",
      "\titers: 200, epoch: 41 | loss: 0.0589474\n",
      "\tspeed: 0.0235s/iter; left time: 310.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0549188 Vali Loss: 0.0541179 Test Loss: 0.0569886\n",
      "Validation loss decreased (0.054183 --> 0.054118).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0568754\n",
      "\tspeed: 0.0351s/iter; left time: 460.4627s\n",
      "\titers: 200, epoch: 42 | loss: 0.0575526\n",
      "\tspeed: 0.0163s/iter; left time: 211.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0549190 Vali Loss: 0.0541962 Test Loss: 0.0569879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0539311\n",
      "\tspeed: 0.0335s/iter; left time: 431.6980s\n",
      "\titers: 200, epoch: 43 | loss: 0.0541260\n",
      "\tspeed: 0.0170s/iter; left time: 217.8075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0548723 Vali Loss: 0.0542162 Test Loss: 0.0569841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0590743\n",
      "\tspeed: 0.0350s/iter; left time: 443.8204s\n",
      "\titers: 200, epoch: 44 | loss: 0.0580704\n",
      "\tspeed: 0.0218s/iter; left time: 274.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0548795 Vali Loss: 0.0542419 Test Loss: 0.0569613\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0549333\n",
      "\tspeed: 0.0415s/iter; left time: 516.9520s\n",
      "\titers: 200, epoch: 45 | loss: 0.0572556\n",
      "\tspeed: 0.0212s/iter; left time: 262.1793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0548682 Vali Loss: 0.0541162 Test Loss: 0.0569563\n",
      "Validation loss decreased (0.054118 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609165\n",
      "\tspeed: 0.0416s/iter; left time: 507.8956s\n",
      "\titers: 200, epoch: 46 | loss: 0.0561033\n",
      "\tspeed: 0.0238s/iter; left time: 288.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0547962 Vali Loss: 0.0542484 Test Loss: 0.0569912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0509932\n",
      "\tspeed: 0.0363s/iter; left time: 435.6607s\n",
      "\titers: 200, epoch: 47 | loss: 0.0555913\n",
      "\tspeed: 0.0185s/iter; left time: 220.0668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0547953 Vali Loss: 0.0541397 Test Loss: 0.0569934\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0519225\n",
      "\tspeed: 0.0338s/iter; left time: 397.8171s\n",
      "\titers: 200, epoch: 48 | loss: 0.0512742\n",
      "\tspeed: 0.0170s/iter; left time: 198.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0549362 Vali Loss: 0.0541236 Test Loss: 0.0569956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0553043\n",
      "\tspeed: 0.0388s/iter; left time: 448.0505s\n",
      "\titers: 200, epoch: 49 | loss: 0.0537112\n",
      "\tspeed: 0.0185s/iter; left time: 212.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0548709 Vali Loss: 0.0541980 Test Loss: 0.0569574\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0526863\n",
      "\tspeed: 0.0374s/iter; left time: 424.0368s\n",
      "\titers: 200, epoch: 50 | loss: 0.0535873\n",
      "\tspeed: 0.0127s/iter; left time: 142.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0548540 Vali Loss: 0.0541940 Test Loss: 0.0569610\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0517663\n",
      "\tspeed: 0.0391s/iter; left time: 434.3092s\n",
      "\titers: 200, epoch: 51 | loss: 0.0557087\n",
      "\tspeed: 0.0171s/iter; left time: 188.3720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0547719 Vali Loss: 0.0541577 Test Loss: 0.0569437\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0523879\n",
      "\tspeed: 0.0390s/iter; left time: 424.1019s\n",
      "\titers: 200, epoch: 52 | loss: 0.0544043\n",
      "\tspeed: 0.0174s/iter; left time: 187.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0548296 Vali Loss: 0.0541183 Test Loss: 0.0569324\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0534062\n",
      "\tspeed: 0.0387s/iter; left time: 411.7966s\n",
      "\titers: 200, epoch: 53 | loss: 0.0576608\n",
      "\tspeed: 0.0219s/iter; left time: 231.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0548698 Vali Loss: 0.0541877 Test Loss: 0.0569458\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0591096\n",
      "\tspeed: 0.0408s/iter; left time: 425.7588s\n",
      "\titers: 200, epoch: 54 | loss: 0.0546674\n",
      "\tspeed: 0.0170s/iter; left time: 175.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0548560 Vali Loss: 0.0541285 Test Loss: 0.0569474\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0541307\n",
      "\tspeed: 0.0437s/iter; left time: 446.3391s\n",
      "\titers: 200, epoch: 55 | loss: 0.0533886\n",
      "\tspeed: 0.0229s/iter; left time: 231.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0549147 Vali Loss: 0.0541105 Test Loss: 0.0569596\n",
      "Validation loss decreased (0.054116 --> 0.054110).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0534275\n",
      "\tspeed: 0.0414s/iter; left time: 413.4563s\n",
      "\titers: 200, epoch: 56 | loss: 0.0536850\n",
      "\tspeed: 0.0269s/iter; left time: 265.3281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0547930 Vali Loss: 0.0541781 Test Loss: 0.0569503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0550939\n",
      "\tspeed: 0.0408s/iter; left time: 398.4272s\n",
      "\titers: 200, epoch: 57 | loss: 0.0559920\n",
      "\tspeed: 0.0180s/iter; left time: 173.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0548085 Vali Loss: 0.0541837 Test Loss: 0.0569546\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538930\n",
      "\tspeed: 0.0378s/iter; left time: 360.5746s\n",
      "\titers: 200, epoch: 58 | loss: 0.0550613\n",
      "\tspeed: 0.0171s/iter; left time: 161.3936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0548473 Vali Loss: 0.0542200 Test Loss: 0.0569798\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0557063\n",
      "\tspeed: 0.0361s/iter; left time: 335.7895s\n",
      "\titers: 200, epoch: 59 | loss: 0.0589967\n",
      "\tspeed: 0.0178s/iter; left time: 164.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0547753 Vali Loss: 0.0541430 Test Loss: 0.0569533\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0537207\n",
      "\tspeed: 0.0394s/iter; left time: 358.2576s\n",
      "\titers: 200, epoch: 60 | loss: 0.0574303\n",
      "\tspeed: 0.0212s/iter; left time: 190.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0548411 Vali Loss: 0.0541856 Test Loss: 0.0569484\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0524038\n",
      "\tspeed: 0.0355s/iter; left time: 314.9880s\n",
      "\titers: 200, epoch: 61 | loss: 0.0546406\n",
      "\tspeed: 0.0187s/iter; left time: 163.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0548166 Vali Loss: 0.0541738 Test Loss: 0.0569333\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0557023\n",
      "\tspeed: 0.0336s/iter; left time: 289.8538s\n",
      "\titers: 200, epoch: 62 | loss: 0.0560640\n",
      "\tspeed: 0.0159s/iter; left time: 135.7065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0547961 Vali Loss: 0.0540890 Test Loss: 0.0569430\n",
      "Validation loss decreased (0.054110 --> 0.054089).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0616305\n",
      "\tspeed: 0.0348s/iter; left time: 292.7688s\n",
      "\titers: 200, epoch: 63 | loss: 0.0507061\n",
      "\tspeed: 0.0168s/iter; left time: 139.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0548283 Vali Loss: 0.0542220 Test Loss: 0.0569397\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0551994\n",
      "\tspeed: 0.0378s/iter; left time: 309.3181s\n",
      "\titers: 200, epoch: 64 | loss: 0.0580233\n",
      "\tspeed: 0.0199s/iter; left time: 160.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0548663 Vali Loss: 0.0541582 Test Loss: 0.0569373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0558159\n",
      "\tspeed: 0.0394s/iter; left time: 313.4469s\n",
      "\titers: 200, epoch: 65 | loss: 0.0510268\n",
      "\tspeed: 0.0162s/iter; left time: 127.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0548699 Vali Loss: 0.0541637 Test Loss: 0.0569647\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0602888\n",
      "\tspeed: 0.0322s/iter; left time: 249.3107s\n",
      "\titers: 200, epoch: 66 | loss: 0.0574390\n",
      "\tspeed: 0.0151s/iter; left time: 115.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0548316 Vali Loss: 0.0541826 Test Loss: 0.0569478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0549449\n",
      "\tspeed: 0.0378s/iter; left time: 284.4538s\n",
      "\titers: 200, epoch: 67 | loss: 0.0568513\n",
      "\tspeed: 0.0210s/iter; left time: 156.0257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0549008 Vali Loss: 0.0541090 Test Loss: 0.0569556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0559882\n",
      "\tspeed: 0.0361s/iter; left time: 263.6359s\n",
      "\titers: 200, epoch: 68 | loss: 0.0570946\n",
      "\tspeed: 0.0219s/iter; left time: 157.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0548129 Vali Loss: 0.0541378 Test Loss: 0.0569541\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0568874\n",
      "\tspeed: 0.0406s/iter; left time: 286.6848s\n",
      "\titers: 200, epoch: 69 | loss: 0.0531420\n",
      "\tspeed: 0.0202s/iter; left time: 140.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0548210 Vali Loss: 0.0542030 Test Loss: 0.0569456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0551165\n",
      "\tspeed: 0.0430s/iter; left time: 294.2183s\n",
      "\titers: 200, epoch: 70 | loss: 0.0531022\n",
      "\tspeed: 0.0202s/iter; left time: 136.3124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0547467 Vali Loss: 0.0541319 Test Loss: 0.0569604\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0548610\n",
      "\tspeed: 0.0410s/iter; left time: 271.6738s\n",
      "\titers: 200, epoch: 71 | loss: 0.0548555\n",
      "\tspeed: 0.0198s/iter; left time: 128.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0547453 Vali Loss: 0.0541806 Test Loss: 0.0569549\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0514987\n",
      "\tspeed: 0.0359s/iter; left time: 229.5886s\n",
      "\titers: 200, epoch: 72 | loss: 0.0534531\n",
      "\tspeed: 0.0163s/iter; left time: 102.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0548215 Vali Loss: 0.0542229 Test Loss: 0.0569531\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010122844018042088, rmse:0.1006123423576355, mae:0.05694303661584854, rse:0.3801645338535309\n",
      "Intermediate time for IT and pred_len 24: 00h:12m:01.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1697901\n",
      "\tspeed: 0.0419s/iter; left time: 934.6367s\n",
      "\titers: 200, epoch: 1 | loss: 0.1417536\n",
      "\tspeed: 0.0156s/iter; left time: 345.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1661587 Vali Loss: 0.1205689 Test Loss: 0.1254019\n",
      "Validation loss decreased (inf --> 0.120569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0981152\n",
      "\tspeed: 0.0364s/iter; left time: 804.2187s\n",
      "\titers: 200, epoch: 2 | loss: 0.0931919\n",
      "\tspeed: 0.0180s/iter; left time: 395.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.1010543 Vali Loss: 0.0828838 Test Loss: 0.0878194\n",
      "Validation loss decreased (0.120569 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0871705\n",
      "\tspeed: 0.0362s/iter; left time: 790.8101s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823159\n",
      "\tspeed: 0.0196s/iter; left time: 426.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0867661 Vali Loss: 0.0794811 Test Loss: 0.0843781\n",
      "Validation loss decreased (0.082884 --> 0.079481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838890\n",
      "\tspeed: 0.0354s/iter; left time: 765.9674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801001\n",
      "\tspeed: 0.0157s/iter; left time: 338.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0835624 Vali Loss: 0.0781997 Test Loss: 0.0834986\n",
      "Validation loss decreased (0.079481 --> 0.078200).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819419\n",
      "\tspeed: 0.0334s/iter; left time: 714.5210s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834576\n",
      "\tspeed: 0.0172s/iter; left time: 365.8370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0817635 Vali Loss: 0.0775758 Test Loss: 0.0826953\n",
      "Validation loss decreased (0.078200 --> 0.077576).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838633\n",
      "\tspeed: 0.0350s/iter; left time: 742.2699s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800622\n",
      "\tspeed: 0.0203s/iter; left time: 428.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0805275 Vali Loss: 0.0772487 Test Loss: 0.0826419\n",
      "Validation loss decreased (0.077576 --> 0.077249).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770448\n",
      "\tspeed: 0.0336s/iter; left time: 703.9137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791029\n",
      "\tspeed: 0.0167s/iter; left time: 347.5852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0796021 Vali Loss: 0.0769699 Test Loss: 0.0821760\n",
      "Validation loss decreased (0.077249 --> 0.076970).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800148\n",
      "\tspeed: 0.0343s/iter; left time: 711.8245s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800654\n",
      "\tspeed: 0.0162s/iter; left time: 333.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0788863 Vali Loss: 0.0766922 Test Loss: 0.0817522\n",
      "Validation loss decreased (0.076970 --> 0.076692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763567\n",
      "\tspeed: 0.0356s/iter; left time: 731.0620s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756575\n",
      "\tspeed: 0.0175s/iter; left time: 357.9637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0782481 Vali Loss: 0.0764618 Test Loss: 0.0816592\n",
      "Validation loss decreased (0.076692 --> 0.076462).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781845\n",
      "\tspeed: 0.0362s/iter; left time: 734.7566s\n",
      "\titers: 200, epoch: 10 | loss: 0.0800031\n",
      "\tspeed: 0.0198s/iter; left time: 400.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0776947 Vali Loss: 0.0764062 Test Loss: 0.0814688\n",
      "Validation loss decreased (0.076462 --> 0.076406).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0756868\n",
      "\tspeed: 0.0385s/iter; left time: 772.2800s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766438\n",
      "\tspeed: 0.0135s/iter; left time: 268.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0772751 Vali Loss: 0.0763349 Test Loss: 0.0814497\n",
      "Validation loss decreased (0.076406 --> 0.076335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758763\n",
      "\tspeed: 0.0343s/iter; left time: 681.2724s\n",
      "\titers: 200, epoch: 12 | loss: 0.0747020\n",
      "\tspeed: 0.0162s/iter; left time: 319.6337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0767900 Vali Loss: 0.0761060 Test Loss: 0.0813051\n",
      "Validation loss decreased (0.076335 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789600\n",
      "\tspeed: 0.0358s/iter; left time: 703.0655s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759603\n",
      "\tspeed: 0.0184s/iter; left time: 358.2770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0764186 Vali Loss: 0.0763179 Test Loss: 0.0813079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0704881\n",
      "\tspeed: 0.0354s/iter; left time: 687.3356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0755752\n",
      "\tspeed: 0.0192s/iter; left time: 369.8767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0761283 Vali Loss: 0.0763324 Test Loss: 0.0812085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780939\n",
      "\tspeed: 0.0376s/iter; left time: 720.0422s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711667\n",
      "\tspeed: 0.0153s/iter; left time: 291.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0758143 Vali Loss: 0.0761845 Test Loss: 0.0810637\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718904\n",
      "\tspeed: 0.0328s/iter; left time: 620.8424s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772383\n",
      "\tspeed: 0.0174s/iter; left time: 328.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0754854 Vali Loss: 0.0761187 Test Loss: 0.0811562\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0739559\n",
      "\tspeed: 0.0373s/iter; left time: 698.9420s\n",
      "\titers: 200, epoch: 17 | loss: 0.0751932\n",
      "\tspeed: 0.0165s/iter; left time: 307.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0752675 Vali Loss: 0.0761033 Test Loss: 0.0810552\n",
      "Validation loss decreased (0.076106 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773290\n",
      "\tspeed: 0.0329s/iter; left time: 608.8784s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747019\n",
      "\tspeed: 0.0180s/iter; left time: 330.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0750758 Vali Loss: 0.0761617 Test Loss: 0.0808548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718658\n",
      "\tspeed: 0.0365s/iter; left time: 666.7726s\n",
      "\titers: 200, epoch: 19 | loss: 0.0726776\n",
      "\tspeed: 0.0173s/iter; left time: 314.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0749217 Vali Loss: 0.0761442 Test Loss: 0.0809737\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0708190\n",
      "\tspeed: 0.0359s/iter; left time: 648.3600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0749490\n",
      "\tspeed: 0.0176s/iter; left time: 316.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0747592 Vali Loss: 0.0761574 Test Loss: 0.0809266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0695070\n",
      "\tspeed: 0.0328s/iter; left time: 584.4137s\n",
      "\titers: 200, epoch: 21 | loss: 0.0726070\n",
      "\tspeed: 0.0164s/iter; left time: 289.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0745507 Vali Loss: 0.0760370 Test Loss: 0.0808984\n",
      "Validation loss decreased (0.076103 --> 0.076037).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802664\n",
      "\tspeed: 0.0344s/iter; left time: 604.7948s\n",
      "\titers: 200, epoch: 22 | loss: 0.0732480\n",
      "\tspeed: 0.0178s/iter; left time: 310.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0744607 Vali Loss: 0.0760612 Test Loss: 0.0809186\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725599\n",
      "\tspeed: 0.0367s/iter; left time: 636.9280s\n",
      "\titers: 200, epoch: 23 | loss: 0.0737257\n",
      "\tspeed: 0.0209s/iter; left time: 360.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0742709 Vali Loss: 0.0759931 Test Loss: 0.0808898\n",
      "Validation loss decreased (0.076037 --> 0.075993).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0728129\n",
      "\tspeed: 0.0330s/iter; left time: 566.1132s\n",
      "\titers: 200, epoch: 24 | loss: 0.0713110\n",
      "\tspeed: 0.0183s/iter; left time: 312.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0741879 Vali Loss: 0.0760532 Test Loss: 0.0809372\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0735495\n",
      "\tspeed: 0.0356s/iter; left time: 602.9066s\n",
      "\titers: 200, epoch: 25 | loss: 0.0745302\n",
      "\tspeed: 0.0101s/iter; left time: 170.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0740657 Vali Loss: 0.0761088 Test Loss: 0.0808977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0735979\n",
      "\tspeed: 0.0335s/iter; left time: 559.4962s\n",
      "\titers: 200, epoch: 26 | loss: 0.0791627\n",
      "\tspeed: 0.0166s/iter; left time: 276.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0740008 Vali Loss: 0.0760739 Test Loss: 0.0809238\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0749572\n",
      "\tspeed: 0.0357s/iter; left time: 588.1393s\n",
      "\titers: 200, epoch: 27 | loss: 0.0739172\n",
      "\tspeed: 0.0154s/iter; left time: 251.8744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0738577 Vali Loss: 0.0760024 Test Loss: 0.0808745\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0706536\n",
      "\tspeed: 0.0361s/iter; left time: 586.9199s\n",
      "\titers: 200, epoch: 28 | loss: 0.0727409\n",
      "\tspeed: 0.0169s/iter; left time: 272.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0738605 Vali Loss: 0.0760545 Test Loss: 0.0808532\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0768558\n",
      "\tspeed: 0.0327s/iter; left time: 524.5591s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731326\n",
      "\tspeed: 0.0175s/iter; left time: 278.1858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0738293 Vali Loss: 0.0760232 Test Loss: 0.0808351\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0717391\n",
      "\tspeed: 0.0337s/iter; left time: 532.0636s\n",
      "\titers: 200, epoch: 30 | loss: 0.0732696\n",
      "\tspeed: 0.0159s/iter; left time: 249.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0737197 Vali Loss: 0.0759862 Test Loss: 0.0807733\n",
      "Validation loss decreased (0.075993 --> 0.075986).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0773381\n",
      "\tspeed: 0.0361s/iter; left time: 562.6473s\n",
      "\titers: 200, epoch: 31 | loss: 0.0718320\n",
      "\tspeed: 0.0188s/iter; left time: 291.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0737303 Vali Loss: 0.0759651 Test Loss: 0.0808446\n",
      "Validation loss decreased (0.075986 --> 0.075965).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0737139\n",
      "\tspeed: 0.0411s/iter; left time: 631.4901s\n",
      "\titers: 200, epoch: 32 | loss: 0.0782378\n",
      "\tspeed: 0.0217s/iter; left time: 330.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0736226 Vali Loss: 0.0760542 Test Loss: 0.0808185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0770072\n",
      "\tspeed: 0.0318s/iter; left time: 480.6946s\n",
      "\titers: 200, epoch: 33 | loss: 0.0730668\n",
      "\tspeed: 0.0159s/iter; left time: 239.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0736442 Vali Loss: 0.0759856 Test Loss: 0.0808112\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0744206\n",
      "\tspeed: 0.0303s/iter; left time: 451.1581s\n",
      "\titers: 200, epoch: 34 | loss: 0.0731017\n",
      "\tspeed: 0.0151s/iter; left time: 223.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0735554 Vali Loss: 0.0759941 Test Loss: 0.0807947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0736821\n",
      "\tspeed: 0.0339s/iter; left time: 497.5747s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741280\n",
      "\tspeed: 0.0153s/iter; left time: 222.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0735540 Vali Loss: 0.0759959 Test Loss: 0.0808094\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0738688\n",
      "\tspeed: 0.0334s/iter; left time: 482.3774s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716741\n",
      "\tspeed: 0.0197s/iter; left time: 282.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0735618 Vali Loss: 0.0759778 Test Loss: 0.0808178\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0719657\n",
      "\tspeed: 0.0350s/iter; left time: 498.8367s\n",
      "\titers: 200, epoch: 37 | loss: 0.0730015\n",
      "\tspeed: 0.0185s/iter; left time: 261.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0734915 Vali Loss: 0.0759785 Test Loss: 0.0808076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0714616\n",
      "\tspeed: 0.0357s/iter; left time: 500.2303s\n",
      "\titers: 200, epoch: 38 | loss: 0.0743507\n",
      "\tspeed: 0.0168s/iter; left time: 233.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0734432 Vali Loss: 0.0759597 Test Loss: 0.0807968\n",
      "Validation loss decreased (0.075965 --> 0.075960).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0752579\n",
      "\tspeed: 0.0334s/iter; left time: 460.6141s\n",
      "\titers: 200, epoch: 39 | loss: 0.0728328\n",
      "\tspeed: 0.0159s/iter; left time: 217.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0734851 Vali Loss: 0.0759584 Test Loss: 0.0808056\n",
      "Validation loss decreased (0.075960 --> 0.075958).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0745227\n",
      "\tspeed: 0.0368s/iter; left time: 499.1602s\n",
      "\titers: 200, epoch: 40 | loss: 0.0717845\n",
      "\tspeed: 0.0197s/iter; left time: 265.8631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0735000 Vali Loss: 0.0759864 Test Loss: 0.0807841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0732947\n",
      "\tspeed: 0.0406s/iter; left time: 541.4787s\n",
      "\titers: 200, epoch: 41 | loss: 0.0714626\n",
      "\tspeed: 0.0156s/iter; left time: 206.0080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0733969 Vali Loss: 0.0759929 Test Loss: 0.0808170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0734959\n",
      "\tspeed: 0.0330s/iter; left time: 432.6910s\n",
      "\titers: 200, epoch: 42 | loss: 0.0773230\n",
      "\tspeed: 0.0162s/iter; left time: 210.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0734584 Vali Loss: 0.0760043 Test Loss: 0.0808014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0744315\n",
      "\tspeed: 0.0339s/iter; left time: 436.4601s\n",
      "\titers: 200, epoch: 43 | loss: 0.0728686\n",
      "\tspeed: 0.0171s/iter; left time: 219.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0733872 Vali Loss: 0.0759762 Test Loss: 0.0807917\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0713220\n",
      "\tspeed: 0.0337s/iter; left time: 427.2511s\n",
      "\titers: 200, epoch: 44 | loss: 0.0746999\n",
      "\tspeed: 0.0161s/iter; left time: 201.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0733522 Vali Loss: 0.0759986 Test Loss: 0.0807751\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0731387\n",
      "\tspeed: 0.0346s/iter; left time: 430.5467s\n",
      "\titers: 200, epoch: 45 | loss: 0.0709675\n",
      "\tspeed: 0.0164s/iter; left time: 202.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0733930 Vali Loss: 0.0759774 Test Loss: 0.0807685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0724939\n",
      "\tspeed: 0.0352s/iter; left time: 430.4732s\n",
      "\titers: 200, epoch: 46 | loss: 0.0697997\n",
      "\tspeed: 0.0176s/iter; left time: 213.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0733245 Vali Loss: 0.0759801 Test Loss: 0.0807872\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0704474\n",
      "\tspeed: 0.0319s/iter; left time: 382.1654s\n",
      "\titers: 200, epoch: 47 | loss: 0.0761166\n",
      "\tspeed: 0.0167s/iter; left time: 198.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0733120 Vali Loss: 0.0759149 Test Loss: 0.0807728\n",
      "Validation loss decreased (0.075958 --> 0.075915).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0736583\n",
      "\tspeed: 0.0362s/iter; left time: 426.3896s\n",
      "\titers: 200, epoch: 48 | loss: 0.0728498\n",
      "\tspeed: 0.0180s/iter; left time: 209.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0733864 Vali Loss: 0.0759525 Test Loss: 0.0807799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0738396\n",
      "\tspeed: 0.0366s/iter; left time: 422.7975s\n",
      "\titers: 200, epoch: 49 | loss: 0.0701421\n",
      "\tspeed: 0.0172s/iter; left time: 197.0605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0733397 Vali Loss: 0.0759614 Test Loss: 0.0808031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0723387\n",
      "\tspeed: 0.0336s/iter; left time: 380.2585s\n",
      "\titers: 200, epoch: 50 | loss: 0.0725155\n",
      "\tspeed: 0.0160s/iter; left time: 179.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0733075 Vali Loss: 0.0759624 Test Loss: 0.0808017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0712942\n",
      "\tspeed: 0.0315s/iter; left time: 349.7763s\n",
      "\titers: 200, epoch: 51 | loss: 0.0757016\n",
      "\tspeed: 0.0162s/iter; left time: 178.3869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0733243 Vali Loss: 0.0759654 Test Loss: 0.0807762\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0705229\n",
      "\tspeed: 0.0324s/iter; left time: 352.9463s\n",
      "\titers: 200, epoch: 52 | loss: 0.0745450\n",
      "\tspeed: 0.0166s/iter; left time: 179.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0733400 Vali Loss: 0.0759794 Test Loss: 0.0807876\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0731285\n",
      "\tspeed: 0.0357s/iter; left time: 379.9100s\n",
      "\titers: 200, epoch: 53 | loss: 0.0765970\n",
      "\tspeed: 0.0173s/iter; left time: 183.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0732939 Vali Loss: 0.0759942 Test Loss: 0.0807743\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0708536\n",
      "\tspeed: 0.0330s/iter; left time: 343.8093s\n",
      "\titers: 200, epoch: 54 | loss: 0.0731883\n",
      "\tspeed: 0.0186s/iter; left time: 192.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0732995 Vali Loss: 0.0759793 Test Loss: 0.0807580\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0714670\n",
      "\tspeed: 0.0328s/iter; left time: 334.8288s\n",
      "\titers: 200, epoch: 55 | loss: 0.0740134\n",
      "\tspeed: 0.0183s/iter; left time: 185.4065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0732878 Vali Loss: 0.0759715 Test Loss: 0.0807782\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0752604\n",
      "\tspeed: 0.0315s/iter; left time: 314.4306s\n",
      "\titers: 200, epoch: 56 | loss: 0.0767601\n",
      "\tspeed: 0.0102s/iter; left time: 100.5934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0733636 Vali Loss: 0.0759700 Test Loss: 0.0807596\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0736819\n",
      "\tspeed: 0.0347s/iter; left time: 338.5717s\n",
      "\titers: 200, epoch: 57 | loss: 0.0712866\n",
      "\tspeed: 0.0178s/iter; left time: 171.8698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0732659 Vali Loss: 0.0759884 Test Loss: 0.0807610\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0183547530323267, rmse:0.13547971844673157, mae:0.08077280968427658, rse:0.5122634172439575\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1665507\n",
      "\tspeed: 0.0132s/iter; left time: 294.4499s\n",
      "\titers: 200, epoch: 1 | loss: 0.1391663\n",
      "\tspeed: 0.0162s/iter; left time: 359.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 224 | Train Loss: 0.1662964 Vali Loss: 0.1215477 Test Loss: 0.1261288\n",
      "Validation loss decreased (inf --> 0.121548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0998002\n",
      "\tspeed: 0.0393s/iter; left time: 868.0726s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915092\n",
      "\tspeed: 0.0228s/iter; left time: 501.3282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.1009761 Vali Loss: 0.0827417 Test Loss: 0.0878231\n",
      "Validation loss decreased (0.121548 --> 0.082742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0826541\n",
      "\tspeed: 0.0367s/iter; left time: 801.0872s\n",
      "\titers: 200, epoch: 3 | loss: 0.0808720\n",
      "\tspeed: 0.0189s/iter; left time: 411.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0866059 Vali Loss: 0.0795398 Test Loss: 0.0842613\n",
      "Validation loss decreased (0.082742 --> 0.079540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845862\n",
      "\tspeed: 0.0365s/iter; left time: 790.3737s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785832\n",
      "\tspeed: 0.0161s/iter; left time: 345.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0833765 Vali Loss: 0.0784097 Test Loss: 0.0833860\n",
      "Validation loss decreased (0.079540 --> 0.078410).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0896866\n",
      "\tspeed: 0.0390s/iter; left time: 834.3396s\n",
      "\titers: 200, epoch: 5 | loss: 0.0804341\n",
      "\tspeed: 0.0158s/iter; left time: 337.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0816916 Vali Loss: 0.0776654 Test Loss: 0.0826235\n",
      "Validation loss decreased (0.078410 --> 0.077665).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0784190\n",
      "\tspeed: 0.0367s/iter; left time: 778.2262s\n",
      "\titers: 200, epoch: 6 | loss: 0.0796472\n",
      "\tspeed: 0.0176s/iter; left time: 370.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0803280 Vali Loss: 0.0773824 Test Loss: 0.0822208\n",
      "Validation loss decreased (0.077665 --> 0.077382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0786439\n",
      "\tspeed: 0.0355s/iter; left time: 743.4538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746353\n",
      "\tspeed: 0.0191s/iter; left time: 399.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0792983 Vali Loss: 0.0769876 Test Loss: 0.0817449\n",
      "Validation loss decreased (0.077382 --> 0.076988).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775864\n",
      "\tspeed: 0.0374s/iter; left time: 774.4947s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763349\n",
      "\tspeed: 0.0178s/iter; left time: 367.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0785563 Vali Loss: 0.0767523 Test Loss: 0.0821021\n",
      "Validation loss decreased (0.076988 --> 0.076752).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766603\n",
      "\tspeed: 0.0350s/iter; left time: 717.4048s\n",
      "\titers: 200, epoch: 9 | loss: 0.0775894\n",
      "\tspeed: 0.0185s/iter; left time: 377.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0779603 Vali Loss: 0.0763774 Test Loss: 0.0817005\n",
      "Validation loss decreased (0.076752 --> 0.076377).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778862\n",
      "\tspeed: 0.0341s/iter; left time: 692.2921s\n",
      "\titers: 200, epoch: 10 | loss: 0.0766565\n",
      "\tspeed: 0.0164s/iter; left time: 331.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0773785 Vali Loss: 0.0764705 Test Loss: 0.0814242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775365\n",
      "\tspeed: 0.0334s/iter; left time: 670.6094s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782466\n",
      "\tspeed: 0.0164s/iter; left time: 328.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0768843 Vali Loss: 0.0765414 Test Loss: 0.0813353\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0771421\n",
      "\tspeed: 0.0353s/iter; left time: 701.1447s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787457\n",
      "\tspeed: 0.0176s/iter; left time: 348.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0765235 Vali Loss: 0.0763518 Test Loss: 0.0811210\n",
      "Validation loss decreased (0.076377 --> 0.076352).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751633\n",
      "\tspeed: 0.0380s/iter; left time: 745.7905s\n",
      "\titers: 200, epoch: 13 | loss: 0.0773725\n",
      "\tspeed: 0.0191s/iter; left time: 372.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0760972 Vali Loss: 0.0764464 Test Loss: 0.0809084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771176\n",
      "\tspeed: 0.0392s/iter; left time: 760.6272s\n",
      "\titers: 200, epoch: 14 | loss: 0.0714299\n",
      "\tspeed: 0.0188s/iter; left time: 362.6296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0758128 Vali Loss: 0.0762600 Test Loss: 0.0808917\n",
      "Validation loss decreased (0.076352 --> 0.076260).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0754964\n",
      "\tspeed: 0.0359s/iter; left time: 688.2839s\n",
      "\titers: 200, epoch: 15 | loss: 0.0749718\n",
      "\tspeed: 0.0179s/iter; left time: 340.7178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0754917 Vali Loss: 0.0762124 Test Loss: 0.0809820\n",
      "Validation loss decreased (0.076260 --> 0.076212).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0727005\n",
      "\tspeed: 0.0372s/iter; left time: 705.1876s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801467\n",
      "\tspeed: 0.0177s/iter; left time: 333.3389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0751626 Vali Loss: 0.0762162 Test Loss: 0.0808641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807021\n",
      "\tspeed: 0.0364s/iter; left time: 682.1598s\n",
      "\titers: 200, epoch: 17 | loss: 0.0749142\n",
      "\tspeed: 0.0177s/iter; left time: 330.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0749212 Vali Loss: 0.0763594 Test Loss: 0.0808320\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0722500\n",
      "\tspeed: 0.0347s/iter; left time: 642.5929s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748101\n",
      "\tspeed: 0.0158s/iter; left time: 290.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0748233 Vali Loss: 0.0762598 Test Loss: 0.0807782\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725585\n",
      "\tspeed: 0.0341s/iter; left time: 623.1407s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709015\n",
      "\tspeed: 0.0157s/iter; left time: 285.8651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0745740 Vali Loss: 0.0762685 Test Loss: 0.0807900\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724404\n",
      "\tspeed: 0.0336s/iter; left time: 606.2497s\n",
      "\titers: 200, epoch: 20 | loss: 0.0748593\n",
      "\tspeed: 0.0159s/iter; left time: 285.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0743484 Vali Loss: 0.0762499 Test Loss: 0.0807893\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0716822\n",
      "\tspeed: 0.0336s/iter; left time: 598.2487s\n",
      "\titers: 200, epoch: 21 | loss: 0.0740288\n",
      "\tspeed: 0.0167s/iter; left time: 295.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0741966 Vali Loss: 0.0763500 Test Loss: 0.0808541\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0763151\n",
      "\tspeed: 0.0382s/iter; left time: 672.9146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733430\n",
      "\tspeed: 0.0187s/iter; left time: 326.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0741487 Vali Loss: 0.0764399 Test Loss: 0.0807410\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765173\n",
      "\tspeed: 0.0360s/iter; left time: 625.6788s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725549\n",
      "\tspeed: 0.0182s/iter; left time: 314.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0739900 Vali Loss: 0.0764249 Test Loss: 0.0808813\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0735563\n",
      "\tspeed: 0.0344s/iter; left time: 589.9629s\n",
      "\titers: 200, epoch: 24 | loss: 0.0717174\n",
      "\tspeed: 0.0180s/iter; left time: 306.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0739177 Vali Loss: 0.0763844 Test Loss: 0.0807636\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0749144\n",
      "\tspeed: 0.0329s/iter; left time: 556.8010s\n",
      "\titers: 200, epoch: 25 | loss: 0.0682475\n",
      "\tspeed: 0.0191s/iter; left time: 321.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0737392 Vali Loss: 0.0764543 Test Loss: 0.0808056\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018447913229465485, rmse:0.1358231008052826, mae:0.08098198473453522, rse:0.5135617852210999\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:19.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1688796\n",
      "\tspeed: 0.0371s/iter; left time: 824.0909s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379916\n",
      "\tspeed: 0.0144s/iter; left time: 317.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1675218 Vali Loss: 0.1228508 Test Loss: 0.1272653\n",
      "Validation loss decreased (inf --> 0.122851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052821\n",
      "\tspeed: 0.0314s/iter; left time: 691.1290s\n",
      "\titers: 200, epoch: 2 | loss: 0.0951657\n",
      "\tspeed: 0.0150s/iter; left time: 328.0999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.1046993 Vali Loss: 0.0870518 Test Loss: 0.0914203\n",
      "Validation loss decreased (0.122851 --> 0.087052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0941121\n",
      "\tspeed: 0.0347s/iter; left time: 755.3490s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910775\n",
      "\tspeed: 0.0163s/iter; left time: 353.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0910649 Vali Loss: 0.0845050 Test Loss: 0.0885898\n",
      "Validation loss decreased (0.087052 --> 0.084505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0896367\n",
      "\tspeed: 0.0339s/iter; left time: 729.5131s\n",
      "\titers: 200, epoch: 4 | loss: 0.0880488\n",
      "\tspeed: 0.0156s/iter; left time: 333.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0877382 Vali Loss: 0.0837493 Test Loss: 0.0879036\n",
      "Validation loss decreased (0.084505 --> 0.083749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0890387\n",
      "\tspeed: 0.0330s/iter; left time: 703.4094s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900611\n",
      "\tspeed: 0.0166s/iter; left time: 351.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0859197 Vali Loss: 0.0826701 Test Loss: 0.0875381\n",
      "Validation loss decreased (0.083749 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836859\n",
      "\tspeed: 0.0344s/iter; left time: 724.6383s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846288\n",
      "\tspeed: 0.0165s/iter; left time: 345.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0846551 Vali Loss: 0.0824386 Test Loss: 0.0872829\n",
      "Validation loss decreased (0.082670 --> 0.082439).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834522\n",
      "\tspeed: 0.0291s/iter; left time: 607.3513s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817988\n",
      "\tspeed: 0.0145s/iter; left time: 300.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 223 | Train Loss: 0.0837010 Vali Loss: 0.0825027 Test Loss: 0.0870421\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834716\n",
      "\tspeed: 0.0335s/iter; left time: 691.9634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836445\n",
      "\tspeed: 0.0188s/iter; left time: 386.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0828991 Vali Loss: 0.0822424 Test Loss: 0.0870820\n",
      "Validation loss decreased (0.082439 --> 0.082242).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822689\n",
      "\tspeed: 0.0365s/iter; left time: 745.8786s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835607\n",
      "\tspeed: 0.0168s/iter; left time: 340.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0822176 Vali Loss: 0.0821146 Test Loss: 0.0869594\n",
      "Validation loss decreased (0.082242 --> 0.082115).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775967\n",
      "\tspeed: 0.0331s/iter; left time: 668.4380s\n",
      "\titers: 200, epoch: 10 | loss: 0.0858709\n",
      "\tspeed: 0.0102s/iter; left time: 205.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0816483 Vali Loss: 0.0820896 Test Loss: 0.0869541\n",
      "Validation loss decreased (0.082115 --> 0.082090).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0805347\n",
      "\tspeed: 0.0321s/iter; left time: 641.8258s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823051\n",
      "\tspeed: 0.0133s/iter; left time: 263.3586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.0812410 Vali Loss: 0.0822447 Test Loss: 0.0866475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830619\n",
      "\tspeed: 0.0337s/iter; left time: 664.5578s\n",
      "\titers: 200, epoch: 12 | loss: 0.0789892\n",
      "\tspeed: 0.0164s/iter; left time: 322.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0807341 Vali Loss: 0.0823029 Test Loss: 0.0866804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0821077\n",
      "\tspeed: 0.0333s/iter; left time: 649.7176s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781240\n",
      "\tspeed: 0.0164s/iter; left time: 318.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0803641 Vali Loss: 0.0823105 Test Loss: 0.0865855\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0829568\n",
      "\tspeed: 0.0369s/iter; left time: 711.9196s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800612\n",
      "\tspeed: 0.0182s/iter; left time: 349.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0800562 Vali Loss: 0.0821699 Test Loss: 0.0866186\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798516\n",
      "\tspeed: 0.0346s/iter; left time: 659.9531s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776321\n",
      "\tspeed: 0.0179s/iter; left time: 339.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0797893 Vali Loss: 0.0821470 Test Loss: 0.0864509\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785727\n",
      "\tspeed: 0.0345s/iter; left time: 649.6559s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760908\n",
      "\tspeed: 0.0175s/iter; left time: 327.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0794582 Vali Loss: 0.0821686 Test Loss: 0.0865523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0791310\n",
      "\tspeed: 0.0376s/iter; left time: 701.4420s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806438\n",
      "\tspeed: 0.0203s/iter; left time: 375.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0792231 Vali Loss: 0.0823976 Test Loss: 0.0863348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787737\n",
      "\tspeed: 0.0340s/iter; left time: 625.8408s\n",
      "\titers: 200, epoch: 18 | loss: 0.0793758\n",
      "\tspeed: 0.0121s/iter; left time: 220.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.0790555 Vali Loss: 0.0823225 Test Loss: 0.0863165\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0827489\n",
      "\tspeed: 0.0376s/iter; left time: 683.6915s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779505\n",
      "\tspeed: 0.0193s/iter; left time: 349.7543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0788790 Vali Loss: 0.0821886 Test Loss: 0.0864874\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787672\n",
      "\tspeed: 0.0364s/iter; left time: 653.2971s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791606\n",
      "\tspeed: 0.0163s/iter; left time: 291.2291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0786808 Vali Loss: 0.0822212 Test Loss: 0.0863241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020483501255512238, rmse:0.14312058687210083, mae:0.08695410192012787, rse:0.5416572093963623\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1696180\n",
      "\tspeed: 0.0184s/iter; left time: 408.8852s\n",
      "\titers: 200, epoch: 1 | loss: 0.1395149\n",
      "\tspeed: 0.0164s/iter; left time: 363.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1684346 Vali Loss: 0.1243715 Test Loss: 0.1288740\n",
      "Validation loss decreased (inf --> 0.124372).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1013771\n",
      "\tspeed: 0.0357s/iter; left time: 785.2728s\n",
      "\titers: 200, epoch: 2 | loss: 0.0979297\n",
      "\tspeed: 0.0168s/iter; left time: 367.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1041851 Vali Loss: 0.0873446 Test Loss: 0.0915076\n",
      "Validation loss decreased (0.124372 --> 0.087345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933065\n",
      "\tspeed: 0.0370s/iter; left time: 804.6208s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946031\n",
      "\tspeed: 0.0168s/iter; left time: 363.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0909246 Vali Loss: 0.0848126 Test Loss: 0.0887092\n",
      "Validation loss decreased (0.087345 --> 0.084813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0869203\n",
      "\tspeed: 0.0358s/iter; left time: 770.5557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0843926\n",
      "\tspeed: 0.0183s/iter; left time: 393.2482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0877403 Vali Loss: 0.0833227 Test Loss: 0.0877769\n",
      "Validation loss decreased (0.084813 --> 0.083323).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833487\n",
      "\tspeed: 0.0388s/iter; left time: 827.0418s\n",
      "\titers: 200, epoch: 5 | loss: 0.0863448\n",
      "\tspeed: 0.0169s/iter; left time: 358.5928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0859352 Vali Loss: 0.0829588 Test Loss: 0.0875156\n",
      "Validation loss decreased (0.083323 --> 0.082959).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0801839\n",
      "\tspeed: 0.0372s/iter; left time: 785.1964s\n",
      "\titers: 200, epoch: 6 | loss: 0.0824517\n",
      "\tspeed: 0.0191s/iter; left time: 401.6001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0846603 Vali Loss: 0.0825818 Test Loss: 0.0872864\n",
      "Validation loss decreased (0.082959 --> 0.082582).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0875021\n",
      "\tspeed: 0.0361s/iter; left time: 752.2630s\n",
      "\titers: 200, epoch: 7 | loss: 0.0818823\n",
      "\tspeed: 0.0177s/iter; left time: 366.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0837073 Vali Loss: 0.0821714 Test Loss: 0.0869476\n",
      "Validation loss decreased (0.082582 --> 0.082171).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0850542\n",
      "\tspeed: 0.0380s/iter; left time: 784.0773s\n",
      "\titers: 200, epoch: 8 | loss: 0.0834179\n",
      "\tspeed: 0.0173s/iter; left time: 355.8922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0829105 Vali Loss: 0.0821604 Test Loss: 0.0871390\n",
      "Validation loss decreased (0.082171 --> 0.082160).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821566\n",
      "\tspeed: 0.0364s/iter; left time: 743.0662s\n",
      "\titers: 200, epoch: 9 | loss: 0.0812122\n",
      "\tspeed: 0.0162s/iter; left time: 328.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0822873 Vali Loss: 0.0820569 Test Loss: 0.0870056\n",
      "Validation loss decreased (0.082160 --> 0.082057).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0805033\n",
      "\tspeed: 0.0345s/iter; left time: 695.8033s\n",
      "\titers: 200, epoch: 10 | loss: 0.0808220\n",
      "\tspeed: 0.0167s/iter; left time: 336.3575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0817796 Vali Loss: 0.0822152 Test Loss: 0.0870447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0818749\n",
      "\tspeed: 0.0348s/iter; left time: 694.3280s\n",
      "\titers: 200, epoch: 11 | loss: 0.0800469\n",
      "\tspeed: 0.0177s/iter; left time: 352.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0813343 Vali Loss: 0.0819895 Test Loss: 0.0870972\n",
      "Validation loss decreased (0.082057 --> 0.081990).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813829\n",
      "\tspeed: 0.0382s/iter; left time: 754.7496s\n",
      "\titers: 200, epoch: 12 | loss: 0.0853255\n",
      "\tspeed: 0.0204s/iter; left time: 400.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0808560 Vali Loss: 0.0820851 Test Loss: 0.0869680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843726\n",
      "\tspeed: 0.0382s/iter; left time: 745.9204s\n",
      "\titers: 200, epoch: 13 | loss: 0.0811540\n",
      "\tspeed: 0.0178s/iter; left time: 345.0360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0804438 Vali Loss: 0.0819604 Test Loss: 0.0869097\n",
      "Validation loss decreased (0.081990 --> 0.081960).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787144\n",
      "\tspeed: 0.0359s/iter; left time: 692.2298s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786381\n",
      "\tspeed: 0.0210s/iter; left time: 404.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0801603 Vali Loss: 0.0819257 Test Loss: 0.0869135\n",
      "Validation loss decreased (0.081960 --> 0.081926).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0828755\n",
      "\tspeed: 0.0371s/iter; left time: 707.3938s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804908\n",
      "\tspeed: 0.0188s/iter; left time: 356.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0798426 Vali Loss: 0.0821048 Test Loss: 0.0870731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815447\n",
      "\tspeed: 0.0405s/iter; left time: 763.3696s\n",
      "\titers: 200, epoch: 16 | loss: 0.0780104\n",
      "\tspeed: 0.0203s/iter; left time: 379.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0795772 Vali Loss: 0.0818957 Test Loss: 0.0870080\n",
      "Validation loss decreased (0.081926 --> 0.081896).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0811224\n",
      "\tspeed: 0.0420s/iter; left time: 782.6522s\n",
      "\titers: 200, epoch: 17 | loss: 0.0815070\n",
      "\tspeed: 0.0174s/iter; left time: 321.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0793306 Vali Loss: 0.0821743 Test Loss: 0.0870327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0764862\n",
      "\tspeed: 0.0394s/iter; left time: 724.8722s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771449\n",
      "\tspeed: 0.0206s/iter; left time: 376.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0790747 Vali Loss: 0.0819055 Test Loss: 0.0868248\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806189\n",
      "\tspeed: 0.0352s/iter; left time: 640.1110s\n",
      "\titers: 200, epoch: 19 | loss: 0.0805428\n",
      "\tspeed: 0.0169s/iter; left time: 305.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0789692 Vali Loss: 0.0819213 Test Loss: 0.0869922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0800329\n",
      "\tspeed: 0.0387s/iter; left time: 695.2497s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795526\n",
      "\tspeed: 0.0167s/iter; left time: 298.7761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0786699 Vali Loss: 0.0820429 Test Loss: 0.0868660\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0803638\n",
      "\tspeed: 0.0355s/iter; left time: 629.4719s\n",
      "\titers: 200, epoch: 21 | loss: 0.0797248\n",
      "\tspeed: 0.0102s/iter; left time: 179.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 223 | Train Loss: 0.0785386 Vali Loss: 0.0819414 Test Loss: 0.0869998\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0774380\n",
      "\tspeed: 0.0349s/iter; left time: 611.6773s\n",
      "\titers: 200, epoch: 22 | loss: 0.0773861\n",
      "\tspeed: 0.0164s/iter; left time: 285.2995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0783755 Vali Loss: 0.0821869 Test Loss: 0.0870399\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0747020\n",
      "\tspeed: 0.0369s/iter; left time: 638.9979s\n",
      "\titers: 200, epoch: 23 | loss: 0.0795917\n",
      "\tspeed: 0.0225s/iter; left time: 386.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0782407 Vali Loss: 0.0820802 Test Loss: 0.0869701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0767323\n",
      "\tspeed: 0.0399s/iter; left time: 681.3772s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754954\n",
      "\tspeed: 0.0223s/iter; left time: 378.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0781603 Vali Loss: 0.0819480 Test Loss: 0.0870242\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0827827\n",
      "\tspeed: 0.0373s/iter; left time: 628.5809s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822115\n",
      "\tspeed: 0.0169s/iter; left time: 282.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0780510 Vali Loss: 0.0820884 Test Loss: 0.0870255\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0772600\n",
      "\tspeed: 0.0360s/iter; left time: 598.0272s\n",
      "\titers: 200, epoch: 26 | loss: 0.0785076\n",
      "\tspeed: 0.0158s/iter; left time: 261.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0779458 Vali Loss: 0.0821003 Test Loss: 0.0870721\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020353496074676514, rmse:0.14266568422317505, mae:0.08700801432132721, rse:0.5399355888366699\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:15.40s\n",
      "Intermediate time for IT: 00h:23m:36.44s\n",
      "Total time: 01h:27m:42.53s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0214  0.1464  0.0900\n",
       "        96        0.0399  0.1997  0.1311\n",
       "        168       0.0418  0.2045  0.1374\n",
       "ES      24        0.0122  0.1100  0.0680\n",
       "        96        0.0242  0.1543  0.0994\n",
       "        168       0.0266  0.1622  0.1060\n",
       "FR      24        0.0106  0.1028  0.0581\n",
       "        96        0.0201  0.1416  0.0829\n",
       "        168       0.0220  0.1484  0.0885\n",
       "GB      24        0.0263  0.1620  0.1032\n",
       "        96        0.0475  0.2177  0.1469\n",
       "        168       0.0505  0.2245  0.1534\n",
       "IT      24        0.0105  0.1024  0.0594\n",
       "        96        0.0185  0.1359  0.0823\n",
       "        168       0.0203  0.1425  0.0878"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0414s/iter; left time: 922.8693s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0148s/iter; left time: 329.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0327s/iter; left time: 721.5018s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0149s/iter; left time: 327.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0355s/iter; left time: 775.2454s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0165s/iter; left time: 358.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0363s/iter; left time: 784.5807s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0154s/iter; left time: 331.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0351s/iter; left time: 750.5363s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0164s/iter; left time: 350.0788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0339s/iter; left time: 717.9479s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0166s/iter; left time: 350.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0349s/iter; left time: 731.3280s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0153s/iter; left time: 319.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0334s/iter; left time: 692.8863s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0153s/iter; left time: 315.9255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0352s/iter; left time: 721.2601s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0159s/iter; left time: 323.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0347s/iter; left time: 703.2361s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0172s/iter; left time: 346.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0340s/iter; left time: 681.8476s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0157s/iter; left time: 312.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0363s/iter; left time: 719.3049s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0163s/iter; left time: 321.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0367s/iter; left time: 720.0186s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0165s/iter; left time: 322.4143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0347s/iter; left time: 672.9456s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0162s/iter; left time: 311.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0385s/iter; left time: 737.4438s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0232s/iter; left time: 441.7032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0366s/iter; left time: 693.8971s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0155s/iter; left time: 291.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0336s/iter; left time: 629.0564s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0149s/iter; left time: 276.5916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0381s/iter; left time: 704.6770s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0161s/iter; left time: 295.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0405s/iter; left time: 739.3619s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0167s/iter; left time: 304.0126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0333s/iter; left time: 601.5741s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0149s/iter; left time: 267.4181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0754218\n",
      "\tspeed: 0.0337s/iter; left time: 601.3609s\n",
      "\titers: 200, epoch: 21 | loss: 0.0769159\n",
      "\tspeed: 0.0156s/iter; left time: 276.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0778717 Vali Loss: 0.0905973 Test Loss: 0.0927691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0722155\n",
      "\tspeed: 0.0340s/iter; left time: 597.7929s\n",
      "\titers: 200, epoch: 22 | loss: 0.0763010\n",
      "\tspeed: 0.0169s/iter; left time: 296.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0778838 Vali Loss: 0.0902790 Test Loss: 0.0928775\n",
      "Validation loss decreased (0.090461 --> 0.090279).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0840008\n",
      "\tspeed: 0.0349s/iter; left time: 606.9452s\n",
      "\titers: 200, epoch: 23 | loss: 0.0815538\n",
      "\tspeed: 0.0167s/iter; left time: 289.2008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0776099 Vali Loss: 0.0901982 Test Loss: 0.0925049\n",
      "Validation loss decreased (0.090279 --> 0.090198).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761470\n",
      "\tspeed: 0.0332s/iter; left time: 568.9277s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754500\n",
      "\tspeed: 0.0149s/iter; left time: 253.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0774545 Vali Loss: 0.0899673 Test Loss: 0.0924277\n",
      "Validation loss decreased (0.090198 --> 0.089967).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0775773\n",
      "\tspeed: 0.0342s/iter; left time: 578.7170s\n",
      "\titers: 200, epoch: 25 | loss: 0.0774031\n",
      "\tspeed: 0.0161s/iter; left time: 271.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0773735 Vali Loss: 0.0899634 Test Loss: 0.0922804\n",
      "Validation loss decreased (0.089967 --> 0.089963).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0793764\n",
      "\tspeed: 0.0345s/iter; left time: 575.8033s\n",
      "\titers: 200, epoch: 26 | loss: 0.0849619\n",
      "\tspeed: 0.0151s/iter; left time: 250.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0774353 Vali Loss: 0.0902629 Test Loss: 0.0924093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0784349\n",
      "\tspeed: 0.0321s/iter; left time: 528.7227s\n",
      "\titers: 200, epoch: 27 | loss: 0.0804014\n",
      "\tspeed: 0.0149s/iter; left time: 244.2088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 224 | Train Loss: 0.0771873 Vali Loss: 0.0902476 Test Loss: 0.0924189\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0754124\n",
      "\tspeed: 0.0337s/iter; left time: 547.5741s\n",
      "\titers: 200, epoch: 28 | loss: 0.0748610\n",
      "\tspeed: 0.0184s/iter; left time: 298.0120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0771039 Vali Loss: 0.0900546 Test Loss: 0.0922958\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0792774\n",
      "\tspeed: 0.0404s/iter; left time: 648.0339s\n",
      "\titers: 200, epoch: 29 | loss: 0.0796077\n",
      "\tspeed: 0.0203s/iter; left time: 323.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0770707 Vali Loss: 0.0897811 Test Loss: 0.0920447\n",
      "Validation loss decreased (0.089963 --> 0.089781).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0762779\n",
      "\tspeed: 0.0359s/iter; left time: 566.8440s\n",
      "\titers: 200, epoch: 30 | loss: 0.0747327\n",
      "\tspeed: 0.0173s/iter; left time: 271.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0769739 Vali Loss: 0.0902239 Test Loss: 0.0923670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0780120\n",
      "\tspeed: 0.0371s/iter; left time: 578.8179s\n",
      "\titers: 200, epoch: 31 | loss: 0.0750840\n",
      "\tspeed: 0.0193s/iter; left time: 298.6650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0769016 Vali Loss: 0.0895654 Test Loss: 0.0921225\n",
      "Validation loss decreased (0.089781 --> 0.089565).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0800933\n",
      "\tspeed: 0.0386s/iter; left time: 593.4343s\n",
      "\titers: 200, epoch: 32 | loss: 0.0767201\n",
      "\tspeed: 0.0212s/iter; left time: 323.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0769158 Vali Loss: 0.0899132 Test Loss: 0.0921777\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0769815\n",
      "\tspeed: 0.0380s/iter; left time: 574.5210s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741093\n",
      "\tspeed: 0.0170s/iter; left time: 255.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0767384 Vali Loss: 0.0897739 Test Loss: 0.0922752\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0793075\n",
      "\tspeed: 0.0346s/iter; left time: 516.3900s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709558\n",
      "\tspeed: 0.0182s/iter; left time: 269.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0767915 Vali Loss: 0.0895388 Test Loss: 0.0919821\n",
      "Validation loss decreased (0.089565 --> 0.089539).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0770702\n",
      "\tspeed: 0.0396s/iter; left time: 581.9589s\n",
      "\titers: 200, epoch: 35 | loss: 0.0845928\n",
      "\tspeed: 0.0175s/iter; left time: 254.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0768886 Vali Loss: 0.0895880 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0722219\n",
      "\tspeed: 0.0374s/iter; left time: 540.5044s\n",
      "\titers: 200, epoch: 36 | loss: 0.0776174\n",
      "\tspeed: 0.0168s/iter; left time: 241.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0768114 Vali Loss: 0.0900146 Test Loss: 0.0922739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0778614\n",
      "\tspeed: 0.0341s/iter; left time: 485.1966s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751549\n",
      "\tspeed: 0.0192s/iter; left time: 270.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0767441 Vali Loss: 0.0894062 Test Loss: 0.0918953\n",
      "Validation loss decreased (0.089539 --> 0.089406).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0742013\n",
      "\tspeed: 0.0395s/iter; left time: 553.1187s\n",
      "\titers: 200, epoch: 38 | loss: 0.0728804\n",
      "\tspeed: 0.0150s/iter; left time: 208.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0766412 Vali Loss: 0.0896684 Test Loss: 0.0921262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720863\n",
      "\tspeed: 0.0366s/iter; left time: 504.8693s\n",
      "\titers: 200, epoch: 39 | loss: 0.0745677\n",
      "\tspeed: 0.0189s/iter; left time: 259.3547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0766759 Vali Loss: 0.0898184 Test Loss: 0.0921254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0768512\n",
      "\tspeed: 0.0377s/iter; left time: 510.8438s\n",
      "\titers: 200, epoch: 40 | loss: 0.0695771\n",
      "\tspeed: 0.0201s/iter; left time: 271.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0766491 Vali Loss: 0.0900104 Test Loss: 0.0922310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0744775\n",
      "\tspeed: 0.0357s/iter; left time: 476.2983s\n",
      "\titers: 200, epoch: 41 | loss: 0.0816218\n",
      "\tspeed: 0.0168s/iter; left time: 222.6721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0766678 Vali Loss: 0.0896019 Test Loss: 0.0919775\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0793130\n",
      "\tspeed: 0.0401s/iter; left time: 525.8058s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831729\n",
      "\tspeed: 0.0199s/iter; left time: 259.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0765614 Vali Loss: 0.0896606 Test Loss: 0.0919400\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755343\n",
      "\tspeed: 0.0374s/iter; left time: 482.0484s\n",
      "\titers: 200, epoch: 43 | loss: 0.0812308\n",
      "\tspeed: 0.0191s/iter; left time: 244.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0766105 Vali Loss: 0.0897262 Test Loss: 0.0920330\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0762576\n",
      "\tspeed: 0.0328s/iter; left time: 415.8087s\n",
      "\titers: 200, epoch: 44 | loss: 0.0749513\n",
      "\tspeed: 0.0149s/iter; left time: 186.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0765386 Vali Loss: 0.0894904 Test Loss: 0.0918714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0822986\n",
      "\tspeed: 0.0381s/iter; left time: 474.7665s\n",
      "\titers: 200, epoch: 45 | loss: 0.0793362\n",
      "\tspeed: 0.0191s/iter; left time: 235.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0765737 Vali Loss: 0.0899103 Test Loss: 0.0921595\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0774861\n",
      "\tspeed: 0.0334s/iter; left time: 407.6814s\n",
      "\titers: 200, epoch: 46 | loss: 0.0801331\n",
      "\tspeed: 0.0215s/iter; left time: 260.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0765671 Vali Loss: 0.0894596 Test Loss: 0.0918659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0829733\n",
      "\tspeed: 0.0361s/iter; left time: 433.4315s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730344\n",
      "\tspeed: 0.0155s/iter; left time: 184.8080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0765457 Vali Loss: 0.0899148 Test Loss: 0.0922697\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021877428516745567, rmse:0.1479102075099945, mae:0.09189533442258835, rse:0.5219956040382385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2795793\n",
      "\tspeed: 0.0181s/iter; left time: 404.0919s\n",
      "\titers: 200, epoch: 1 | loss: 0.2581289\n",
      "\tspeed: 0.0165s/iter; left time: 366.6235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.2717099 Vali Loss: 0.2311239 Test Loss: 0.2326769\n",
      "Validation loss decreased (inf --> 0.231124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1460241\n",
      "\tspeed: 0.0380s/iter; left time: 839.4914s\n",
      "\titers: 200, epoch: 2 | loss: 0.1226775\n",
      "\tspeed: 0.0163s/iter; left time: 357.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1535573 Vali Loss: 0.1255880 Test Loss: 0.1287646\n",
      "Validation loss decreased (0.231124 --> 0.125588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1006170\n",
      "\tspeed: 0.0338s/iter; left time: 738.3729s\n",
      "\titers: 200, epoch: 3 | loss: 0.1042795\n",
      "\tspeed: 0.0149s/iter; left time: 323.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1066906 Vali Loss: 0.1052246 Test Loss: 0.1056530\n",
      "Validation loss decreased (0.125588 --> 0.105225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985685\n",
      "\tspeed: 0.0334s/iter; left time: 723.0792s\n",
      "\titers: 200, epoch: 4 | loss: 0.0950993\n",
      "\tspeed: 0.0149s/iter; left time: 320.3030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0947283 Vali Loss: 0.1006377 Test Loss: 0.1017516\n",
      "Validation loss decreased (0.105225 --> 0.100638).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0910783\n",
      "\tspeed: 0.0337s/iter; left time: 720.3075s\n",
      "\titers: 200, epoch: 5 | loss: 0.0909245\n",
      "\tspeed: 0.0149s/iter; left time: 316.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 224 | Train Loss: 0.0898671 Vali Loss: 0.0980647 Test Loss: 0.0996634\n",
      "Validation loss decreased (0.100638 --> 0.098065).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0873396\n",
      "\tspeed: 0.0369s/iter; left time: 781.7604s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838316\n",
      "\tspeed: 0.0172s/iter; left time: 362.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0869142 Vali Loss: 0.0961922 Test Loss: 0.0982261\n",
      "Validation loss decreased (0.098065 --> 0.096192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815935\n",
      "\tspeed: 0.0385s/iter; left time: 807.4367s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819990\n",
      "\tspeed: 0.0173s/iter; left time: 360.5011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0850223 Vali Loss: 0.0963149 Test Loss: 0.0987874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0845545\n",
      "\tspeed: 0.0394s/iter; left time: 816.4813s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827005\n",
      "\tspeed: 0.0205s/iter; left time: 422.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0835324 Vali Loss: 0.0940600 Test Loss: 0.0957685\n",
      "Validation loss decreased (0.096192 --> 0.094060).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804912\n",
      "\tspeed: 0.0370s/iter; left time: 758.9189s\n",
      "\titers: 200, epoch: 9 | loss: 0.0806583\n",
      "\tspeed: 0.0203s/iter; left time: 414.5486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0823066 Vali Loss: 0.0936993 Test Loss: 0.0953462\n",
      "Validation loss decreased (0.094060 --> 0.093699).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0770288\n",
      "\tspeed: 0.0350s/iter; left time: 710.2089s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785382\n",
      "\tspeed: 0.0173s/iter; left time: 348.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0816374 Vali Loss: 0.0943467 Test Loss: 0.0953491\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0793969\n",
      "\tspeed: 0.0366s/iter; left time: 733.7413s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852954\n",
      "\tspeed: 0.0189s/iter; left time: 376.7917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0807893 Vali Loss: 0.0924223 Test Loss: 0.0939639\n",
      "Validation loss decreased (0.093699 --> 0.092422).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0816043\n",
      "\tspeed: 0.0356s/iter; left time: 706.0133s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799592\n",
      "\tspeed: 0.0177s/iter; left time: 349.1356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0803146 Vali Loss: 0.0924737 Test Loss: 0.0938121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751553\n",
      "\tspeed: 0.0372s/iter; left time: 729.9210s\n",
      "\titers: 200, epoch: 13 | loss: 0.0823086\n",
      "\tspeed: 0.0172s/iter; left time: 335.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0796810 Vali Loss: 0.0924237 Test Loss: 0.0939455\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0760754\n",
      "\tspeed: 0.0333s/iter; left time: 644.7801s\n",
      "\titers: 200, epoch: 14 | loss: 0.0758581\n",
      "\tspeed: 0.0156s/iter; left time: 301.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0793448 Vali Loss: 0.0924458 Test Loss: 0.0940503\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0748765\n",
      "\tspeed: 0.0385s/iter; left time: 737.5945s\n",
      "\titers: 200, epoch: 15 | loss: 0.0785758\n",
      "\tspeed: 0.0199s/iter; left time: 379.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0790329 Vali Loss: 0.0913572 Test Loss: 0.0932310\n",
      "Validation loss decreased (0.092422 --> 0.091357).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0833294\n",
      "\tspeed: 0.0366s/iter; left time: 693.7514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0770179\n",
      "\tspeed: 0.0194s/iter; left time: 366.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0787568 Vali Loss: 0.0910991 Test Loss: 0.0928352\n",
      "Validation loss decreased (0.091357 --> 0.091099).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777185\n",
      "\tspeed: 0.0408s/iter; left time: 764.4523s\n",
      "\titers: 200, epoch: 17 | loss: 0.0779669\n",
      "\tspeed: 0.0194s/iter; left time: 360.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0785381 Vali Loss: 0.0908517 Test Loss: 0.0928423\n",
      "Validation loss decreased (0.091099 --> 0.090852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787854\n",
      "\tspeed: 0.0357s/iter; left time: 660.1017s\n",
      "\titers: 200, epoch: 18 | loss: 0.0840955\n",
      "\tspeed: 0.0158s/iter; left time: 289.8913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0784308 Vali Loss: 0.0921700 Test Loss: 0.0934294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0801536\n",
      "\tspeed: 0.0364s/iter; left time: 665.6668s\n",
      "\titers: 200, epoch: 19 | loss: 0.0787770\n",
      "\tspeed: 0.0169s/iter; left time: 307.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0780323 Vali Loss: 0.0908994 Test Loss: 0.0926545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0759411\n",
      "\tspeed: 0.0358s/iter; left time: 645.6395s\n",
      "\titers: 200, epoch: 20 | loss: 0.0778539\n",
      "\tspeed: 0.0157s/iter; left time: 281.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0778663 Vali Loss: 0.0916306 Test Loss: 0.0933820\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0819615\n",
      "\tspeed: 0.0377s/iter; left time: 671.9201s\n",
      "\titers: 200, epoch: 21 | loss: 0.0806742\n",
      "\tspeed: 0.0187s/iter; left time: 331.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0777724 Vali Loss: 0.0910355 Test Loss: 0.0926646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0842379\n",
      "\tspeed: 0.0383s/iter; left time: 673.4347s\n",
      "\titers: 200, epoch: 22 | loss: 0.0749566\n",
      "\tspeed: 0.0152s/iter; left time: 266.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0775101 Vali Loss: 0.0903652 Test Loss: 0.0923590\n",
      "Validation loss decreased (0.090852 --> 0.090365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0770355\n",
      "\tspeed: 0.0353s/iter; left time: 613.7521s\n",
      "\titers: 200, epoch: 23 | loss: 0.0765068\n",
      "\tspeed: 0.0150s/iter; left time: 258.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0774336 Vali Loss: 0.0915347 Test Loss: 0.0931197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0748078\n",
      "\tspeed: 0.0343s/iter; left time: 588.4923s\n",
      "\titers: 200, epoch: 24 | loss: 0.0763243\n",
      "\tspeed: 0.0160s/iter; left time: 272.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0774180 Vali Loss: 0.0904829 Test Loss: 0.0922597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0794534\n",
      "\tspeed: 0.0347s/iter; left time: 587.2036s\n",
      "\titers: 200, epoch: 25 | loss: 0.0773389\n",
      "\tspeed: 0.0149s/iter; left time: 250.4777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0772832 Vali Loss: 0.0909832 Test Loss: 0.0926450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0775157\n",
      "\tspeed: 0.0379s/iter; left time: 633.7347s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738235\n",
      "\tspeed: 0.0205s/iter; left time: 340.8305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0771211 Vali Loss: 0.0908386 Test Loss: 0.0925390\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0717765\n",
      "\tspeed: 0.0358s/iter; left time: 589.3197s\n",
      "\titers: 200, epoch: 27 | loss: 0.0745081\n",
      "\tspeed: 0.0197s/iter; left time: 322.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0772324 Vali Loss: 0.0899216 Test Loss: 0.0921636\n",
      "Validation loss decreased (0.090365 --> 0.089922).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0791755\n",
      "\tspeed: 0.0405s/iter; left time: 658.4145s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777192\n",
      "\tspeed: 0.0190s/iter; left time: 306.8324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0771157 Vali Loss: 0.0900271 Test Loss: 0.0919820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744445\n",
      "\tspeed: 0.0411s/iter; left time: 658.0067s\n",
      "\titers: 200, epoch: 29 | loss: 0.0746980\n",
      "\tspeed: 0.0219s/iter; left time: 349.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0771550 Vali Loss: 0.0908405 Test Loss: 0.0926438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0756679\n",
      "\tspeed: 0.0360s/iter; left time: 568.2846s\n",
      "\titers: 200, epoch: 30 | loss: 0.0718184\n",
      "\tspeed: 0.0169s/iter; left time: 265.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0770201 Vali Loss: 0.0900961 Test Loss: 0.0920187\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778587\n",
      "\tspeed: 0.0403s/iter; left time: 628.6891s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729986\n",
      "\tspeed: 0.0182s/iter; left time: 282.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0770441 Vali Loss: 0.0899777 Test Loss: 0.0918684\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0768104\n",
      "\tspeed: 0.0354s/iter; left time: 543.6505s\n",
      "\titers: 200, epoch: 32 | loss: 0.0763993\n",
      "\tspeed: 0.0165s/iter; left time: 251.7716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0768499 Vali Loss: 0.0910889 Test Loss: 0.0927245\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0730918\n",
      "\tspeed: 0.0371s/iter; left time: 561.0187s\n",
      "\titers: 200, epoch: 33 | loss: 0.0787223\n",
      "\tspeed: 0.0176s/iter; left time: 264.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0768298 Vali Loss: 0.0903262 Test Loss: 0.0922530\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0800109\n",
      "\tspeed: 0.0361s/iter; left time: 538.6389s\n",
      "\titers: 200, epoch: 34 | loss: 0.0745068\n",
      "\tspeed: 0.0205s/iter; left time: 303.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0769069 Vali Loss: 0.0905272 Test Loss: 0.0923126\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0742564\n",
      "\tspeed: 0.0392s/iter; left time: 575.8493s\n",
      "\titers: 200, epoch: 35 | loss: 0.0726635\n",
      "\tspeed: 0.0162s/iter; left time: 235.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0768160 Vali Loss: 0.0902332 Test Loss: 0.0921869\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0787445\n",
      "\tspeed: 0.0353s/iter; left time: 510.8969s\n",
      "\titers: 200, epoch: 36 | loss: 0.0738677\n",
      "\tspeed: 0.0175s/iter; left time: 250.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0767147 Vali Loss: 0.0902117 Test Loss: 0.0920638\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0791762\n",
      "\tspeed: 0.0342s/iter; left time: 486.8774s\n",
      "\titers: 200, epoch: 37 | loss: 0.0752761\n",
      "\tspeed: 0.0150s/iter; left time: 211.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0768540 Vali Loss: 0.0899249 Test Loss: 0.0918227\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021809319034218788, rmse:0.14767979085445404, mae:0.0921635851264, rse:0.5211824178695679\n",
      "Intermediate time for DE and pred_len 24: 00h:07m:39.24s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0409s/iter; left time: 911.4336s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0157s/iter; left time: 347.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0353s/iter; left time: 779.3950s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0162s/iter; left time: 356.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0365s/iter; left time: 798.4989s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0151s/iter; left time: 328.5208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0349s/iter; left time: 754.5992s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0168s/iter; left time: 360.8927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0391s/iter; left time: 836.3002s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0169s/iter; left time: 359.0662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0362s/iter; left time: 766.8005s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0175s/iter; left time: 369.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0350s/iter; left time: 734.4241s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0153s/iter; left time: 319.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0379s/iter; left time: 785.3709s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0172s/iter; left time: 355.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0367s/iter; left time: 752.0454s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0161s/iter; left time: 329.1646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0342s/iter; left time: 693.9619s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0150s/iter; left time: 303.6963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0359s/iter; left time: 720.9153s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0180s/iter; left time: 358.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0342s/iter; left time: 678.7142s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0153s/iter; left time: 302.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0349s/iter; left time: 683.6249s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0159s/iter; left time: 310.1764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0358s/iter; left time: 693.5543s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0151s/iter; left time: 290.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0364s/iter; left time: 698.4877s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0167s/iter; left time: 317.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0415s/iter; left time: 785.8616s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0215s/iter; left time: 405.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0365s/iter; left time: 682.5987s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0168s/iter; left time: 312.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0357s/iter; left time: 659.7122s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0150s/iter; left time: 275.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0349s/iter; left time: 637.7172s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0162s/iter; left time: 294.1121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0353s/iter; left time: 637.3462s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0150s/iter; left time: 269.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1045079\n",
      "\tspeed: 0.0373s/iter; left time: 664.2449s\n",
      "\titers: 200, epoch: 21 | loss: 0.1000956\n",
      "\tspeed: 0.0187s/iter; left time: 331.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1033260 Vali Loss: 0.1208959 Test Loss: 0.1334440\n",
      "Validation loss decreased (0.121249 --> 0.120896).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1021652\n",
      "\tspeed: 0.0344s/iter; left time: 606.1613s\n",
      "\titers: 200, epoch: 22 | loss: 0.1037833\n",
      "\tspeed: 0.0149s/iter; left time: 261.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1031657 Vali Loss: 0.1230096 Test Loss: 0.1364084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1002888\n",
      "\tspeed: 0.0356s/iter; left time: 618.1712s\n",
      "\titers: 200, epoch: 23 | loss: 0.1008182\n",
      "\tspeed: 0.0158s/iter; left time: 272.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1030714 Vali Loss: 0.1216729 Test Loss: 0.1350957\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1028795\n",
      "\tspeed: 0.0369s/iter; left time: 633.1076s\n",
      "\titers: 200, epoch: 24 | loss: 0.1033020\n",
      "\tspeed: 0.0169s/iter; left time: 288.4348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1029641 Vali Loss: 0.1219696 Test Loss: 0.1347010\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1043725\n",
      "\tspeed: 0.0356s/iter; left time: 601.8212s\n",
      "\titers: 200, epoch: 25 | loss: 0.1000242\n",
      "\tspeed: 0.0150s/iter; left time: 251.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1028489 Vali Loss: 0.1215873 Test Loss: 0.1350457\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1063728\n",
      "\tspeed: 0.0399s/iter; left time: 666.7966s\n",
      "\titers: 200, epoch: 26 | loss: 0.1050431\n",
      "\tspeed: 0.0171s/iter; left time: 284.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1026818 Vali Loss: 0.1212678 Test Loss: 0.1344839\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1011360\n",
      "\tspeed: 0.0343s/iter; left time: 564.3640s\n",
      "\titers: 200, epoch: 27 | loss: 0.1029830\n",
      "\tspeed: 0.0172s/iter; left time: 282.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1026702 Vali Loss: 0.1209463 Test Loss: 0.1342177\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1002764\n",
      "\tspeed: 0.0392s/iter; left time: 636.7557s\n",
      "\titers: 200, epoch: 28 | loss: 0.1004969\n",
      "\tspeed: 0.0200s/iter; left time: 323.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1026155 Vali Loss: 0.1208756 Test Loss: 0.1341508\n",
      "Validation loss decreased (0.120896 --> 0.120876).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0999793\n",
      "\tspeed: 0.0374s/iter; left time: 599.5013s\n",
      "\titers: 200, epoch: 29 | loss: 0.1064663\n",
      "\tspeed: 0.0150s/iter; left time: 238.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1025044 Vali Loss: 0.1214741 Test Loss: 0.1346115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1090808\n",
      "\tspeed: 0.0338s/iter; left time: 533.6721s\n",
      "\titers: 200, epoch: 30 | loss: 0.1034467\n",
      "\tspeed: 0.0165s/iter; left time: 259.4675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1024307 Vali Loss: 0.1210201 Test Loss: 0.1342574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1024209\n",
      "\tspeed: 0.0352s/iter; left time: 548.1812s\n",
      "\titers: 200, epoch: 31 | loss: 0.0992074\n",
      "\tspeed: 0.0162s/iter; left time: 251.3612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1023812 Vali Loss: 0.1208797 Test Loss: 0.1342156\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1037238\n",
      "\tspeed: 0.0360s/iter; left time: 553.5818s\n",
      "\titers: 200, epoch: 32 | loss: 0.1089858\n",
      "\tspeed: 0.0202s/iter; left time: 307.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.1023219 Vali Loss: 0.1209639 Test Loss: 0.1341527\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1005650\n",
      "\tspeed: 0.0363s/iter; left time: 549.7622s\n",
      "\titers: 200, epoch: 33 | loss: 0.1019282\n",
      "\tspeed: 0.0197s/iter; left time: 296.0251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.1023162 Vali Loss: 0.1213068 Test Loss: 0.1349990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1046999\n",
      "\tspeed: 0.0356s/iter; left time: 530.7118s\n",
      "\titers: 200, epoch: 34 | loss: 0.1053817\n",
      "\tspeed: 0.0159s/iter; left time: 236.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1022506 Vali Loss: 0.1213841 Test Loss: 0.1349961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1020544\n",
      "\tspeed: 0.0364s/iter; left time: 533.9748s\n",
      "\titers: 200, epoch: 35 | loss: 0.1053065\n",
      "\tspeed: 0.0162s/iter; left time: 236.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.1022157 Vali Loss: 0.1207118 Test Loss: 0.1340811\n",
      "Validation loss decreased (0.120876 --> 0.120712).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0981926\n",
      "\tspeed: 0.0383s/iter; left time: 554.5690s\n",
      "\titers: 200, epoch: 36 | loss: 0.0985543\n",
      "\tspeed: 0.0150s/iter; left time: 215.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1021788 Vali Loss: 0.1213771 Test Loss: 0.1348851\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1025196\n",
      "\tspeed: 0.0358s/iter; left time: 509.4218s\n",
      "\titers: 200, epoch: 37 | loss: 0.1011424\n",
      "\tspeed: 0.0150s/iter; left time: 212.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.1022137 Vali Loss: 0.1207183 Test Loss: 0.1340209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1000994\n",
      "\tspeed: 0.0379s/iter; left time: 531.2871s\n",
      "\titers: 200, epoch: 38 | loss: 0.1024460\n",
      "\tspeed: 0.0161s/iter; left time: 223.9064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1021722 Vali Loss: 0.1208874 Test Loss: 0.1342676\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0992368\n",
      "\tspeed: 0.0377s/iter; left time: 519.7017s\n",
      "\titers: 200, epoch: 39 | loss: 0.1020988\n",
      "\tspeed: 0.0160s/iter; left time: 219.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1022097 Vali Loss: 0.1210484 Test Loss: 0.1343632\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1060569\n",
      "\tspeed: 0.0389s/iter; left time: 527.6277s\n",
      "\titers: 200, epoch: 40 | loss: 0.0973268\n",
      "\tspeed: 0.0174s/iter; left time: 234.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1021335 Vali Loss: 0.1211180 Test Loss: 0.1345849\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0997518\n",
      "\tspeed: 0.0364s/iter; left time: 486.2108s\n",
      "\titers: 200, epoch: 41 | loss: 0.0987781\n",
      "\tspeed: 0.0179s/iter; left time: 237.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1020881 Vali Loss: 0.1210136 Test Loss: 0.1346023\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1037596\n",
      "\tspeed: 0.0359s/iter; left time: 470.7615s\n",
      "\titers: 200, epoch: 42 | loss: 0.0988206\n",
      "\tspeed: 0.0150s/iter; left time: 195.6786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1019838 Vali Loss: 0.1208392 Test Loss: 0.1343173\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1050432\n",
      "\tspeed: 0.0373s/iter; left time: 481.4121s\n",
      "\titers: 200, epoch: 43 | loss: 0.0999807\n",
      "\tspeed: 0.0189s/iter; left time: 242.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1020803 Vali Loss: 0.1214528 Test Loss: 0.1353297\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1015238\n",
      "\tspeed: 0.0331s/iter; left time: 419.3781s\n",
      "\titers: 200, epoch: 44 | loss: 0.1047472\n",
      "\tspeed: 0.0162s/iter; left time: 203.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1021086 Vali Loss: 0.1205994 Test Loss: 0.1340761\n",
      "Validation loss decreased (0.120712 --> 0.120599).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1003289\n",
      "\tspeed: 0.0377s/iter; left time: 468.9845s\n",
      "\titers: 200, epoch: 45 | loss: 0.1018850\n",
      "\tspeed: 0.0174s/iter; left time: 214.6208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1019150 Vali Loss: 0.1211080 Test Loss: 0.1347190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1009540\n",
      "\tspeed: 0.0342s/iter; left time: 417.6070s\n",
      "\titers: 200, epoch: 46 | loss: 0.1023479\n",
      "\tspeed: 0.0150s/iter; left time: 182.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1020184 Vali Loss: 0.1209162 Test Loss: 0.1344623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1061343\n",
      "\tspeed: 0.0350s/iter; left time: 420.0838s\n",
      "\titers: 200, epoch: 47 | loss: 0.0957267\n",
      "\tspeed: 0.0150s/iter; left time: 178.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1020653 Vali Loss: 0.1209101 Test Loss: 0.1344125\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0963322\n",
      "\tspeed: 0.0344s/iter; left time: 405.4104s\n",
      "\titers: 200, epoch: 48 | loss: 0.1003411\n",
      "\tspeed: 0.0150s/iter; left time: 175.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1020388 Vali Loss: 0.1212396 Test Loss: 0.1348047\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1040895\n",
      "\tspeed: 0.0356s/iter; left time: 410.6613s\n",
      "\titers: 200, epoch: 49 | loss: 0.0982405\n",
      "\tspeed: 0.0155s/iter; left time: 177.0662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1019909 Vali Loss: 0.1211116 Test Loss: 0.1349357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1047723\n",
      "\tspeed: 0.0347s/iter; left time: 393.4214s\n",
      "\titers: 200, epoch: 50 | loss: 0.1010813\n",
      "\tspeed: 0.0172s/iter; left time: 193.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1018974 Vali Loss: 0.1210461 Test Loss: 0.1346528\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0971058\n",
      "\tspeed: 0.0363s/iter; left time: 403.2996s\n",
      "\titers: 200, epoch: 51 | loss: 0.0997062\n",
      "\tspeed: 0.0176s/iter; left time: 193.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1019620 Vali Loss: 0.1212331 Test Loss: 0.1348697\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1007300\n",
      "\tspeed: 0.0363s/iter; left time: 394.6236s\n",
      "\titers: 200, epoch: 52 | loss: 0.1036818\n",
      "\tspeed: 0.0163s/iter; left time: 175.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1019240 Vali Loss: 0.1208338 Test Loss: 0.1343024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1008643\n",
      "\tspeed: 0.0345s/iter; left time: 367.5667s\n",
      "\titers: 200, epoch: 53 | loss: 0.1102143\n",
      "\tspeed: 0.0155s/iter; left time: 163.6557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1019292 Vali Loss: 0.1215294 Test Loss: 0.1354873\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1017581\n",
      "\tspeed: 0.0374s/iter; left time: 389.8196s\n",
      "\titers: 200, epoch: 54 | loss: 0.1050068\n",
      "\tspeed: 0.0159s/iter; left time: 163.8798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1019801 Vali Loss: 0.1208065 Test Loss: 0.1343537\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04197017848491669, rmse:0.20486624538898468, mae:0.13407617807388306, rse:0.7254727482795715\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2828640\n",
      "\tspeed: 0.0213s/iter; left time: 474.9778s\n",
      "\titers: 200, epoch: 1 | loss: 0.2573094\n",
      "\tspeed: 0.0184s/iter; left time: 408.4582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.2776463 Vali Loss: 0.2348661 Test Loss: 0.2387750\n",
      "Validation loss decreased (inf --> 0.234866).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1563323\n",
      "\tspeed: 0.0392s/iter; left time: 865.4189s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390097\n",
      "\tspeed: 0.0156s/iter; left time: 343.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1660178 Vali Loss: 0.1412951 Test Loss: 0.1474896\n",
      "Validation loss decreased (0.234866 --> 0.141295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1279419\n",
      "\tspeed: 0.0366s/iter; left time: 799.4770s\n",
      "\titers: 200, epoch: 3 | loss: 0.1227518\n",
      "\tspeed: 0.0158s/iter; left time: 343.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1267834 Vali Loss: 0.1325603 Test Loss: 0.1417641\n",
      "Validation loss decreased (0.141295 --> 0.132560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1186758\n",
      "\tspeed: 0.0350s/iter; left time: 757.2952s\n",
      "\titers: 200, epoch: 4 | loss: 0.1187081\n",
      "\tspeed: 0.0150s/iter; left time: 323.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1176218 Vali Loss: 0.1300932 Test Loss: 0.1413481\n",
      "Validation loss decreased (0.132560 --> 0.130093).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1111984\n",
      "\tspeed: 0.0347s/iter; left time: 742.4612s\n",
      "\titers: 200, epoch: 5 | loss: 0.1145495\n",
      "\tspeed: 0.0150s/iter; left time: 318.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1137421 Vali Loss: 0.1287800 Test Loss: 0.1390819\n",
      "Validation loss decreased (0.130093 --> 0.128780).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116873\n",
      "\tspeed: 0.0391s/iter; left time: 828.9952s\n",
      "\titers: 200, epoch: 6 | loss: 0.1175381\n",
      "\tspeed: 0.0180s/iter; left time: 378.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.1111889 Vali Loss: 0.1264265 Test Loss: 0.1354961\n",
      "Validation loss decreased (0.128780 --> 0.126427).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1079407\n",
      "\tspeed: 0.0388s/iter; left time: 812.5546s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075527\n",
      "\tspeed: 0.0168s/iter; left time: 349.4742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.1093955 Vali Loss: 0.1237439 Test Loss: 0.1325990\n",
      "Validation loss decreased (0.126427 --> 0.123744).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1147573\n",
      "\tspeed: 0.0386s/iter; left time: 801.2268s\n",
      "\titers: 200, epoch: 8 | loss: 0.1143442\n",
      "\tspeed: 0.0178s/iter; left time: 368.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1084551 Vali Loss: 0.1263838 Test Loss: 0.1361008\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1061101\n",
      "\tspeed: 0.0350s/iter; left time: 717.8125s\n",
      "\titers: 200, epoch: 9 | loss: 0.1074078\n",
      "\tspeed: 0.0150s/iter; left time: 306.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1071809 Vali Loss: 0.1259529 Test Loss: 0.1362873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1103988\n",
      "\tspeed: 0.0360s/iter; left time: 729.7137s\n",
      "\titers: 200, epoch: 10 | loss: 0.1080133\n",
      "\tspeed: 0.0166s/iter; left time: 335.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1067869 Vali Loss: 0.1244481 Test Loss: 0.1345298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1045449\n",
      "\tspeed: 0.0405s/iter; left time: 812.9419s\n",
      "\titers: 200, epoch: 11 | loss: 0.1056255\n",
      "\tspeed: 0.0197s/iter; left time: 393.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.1059381 Vali Loss: 0.1233591 Test Loss: 0.1340503\n",
      "Validation loss decreased (0.123744 --> 0.123359).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1026241\n",
      "\tspeed: 0.0390s/iter; left time: 773.9930s\n",
      "\titers: 200, epoch: 12 | loss: 0.1058688\n",
      "\tspeed: 0.0195s/iter; left time: 384.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1052782 Vali Loss: 0.1242864 Test Loss: 0.1365494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0983861\n",
      "\tspeed: 0.0403s/iter; left time: 790.4485s\n",
      "\titers: 200, epoch: 13 | loss: 0.1053534\n",
      "\tspeed: 0.0169s/iter; left time: 329.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1049482 Vali Loss: 0.1240996 Test Loss: 0.1361582\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023027\n",
      "\tspeed: 0.0392s/iter; left time: 760.6541s\n",
      "\titers: 200, epoch: 14 | loss: 0.1065905\n",
      "\tspeed: 0.0188s/iter; left time: 362.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1046526 Vali Loss: 0.1252274 Test Loss: 0.1388291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1057217\n",
      "\tspeed: 0.0407s/iter; left time: 779.3672s\n",
      "\titers: 200, epoch: 15 | loss: 0.1015313\n",
      "\tspeed: 0.0179s/iter; left time: 342.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1043697 Vali Loss: 0.1244436 Test Loss: 0.1367521\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1101613\n",
      "\tspeed: 0.0381s/iter; left time: 722.3591s\n",
      "\titers: 200, epoch: 16 | loss: 0.1031625\n",
      "\tspeed: 0.0171s/iter; left time: 322.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1040357 Vali Loss: 0.1240630 Test Loss: 0.1371671\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068942\n",
      "\tspeed: 0.0378s/iter; left time: 707.3609s\n",
      "\titers: 200, epoch: 17 | loss: 0.1008125\n",
      "\tspeed: 0.0215s/iter; left time: 400.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1039329 Vali Loss: 0.1243129 Test Loss: 0.1372844\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1050479\n",
      "\tspeed: 0.0411s/iter; left time: 759.2109s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003110\n",
      "\tspeed: 0.0184s/iter; left time: 337.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1036200 Vali Loss: 0.1230102 Test Loss: 0.1364042\n",
      "Validation loss decreased (0.123359 --> 0.123010).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1040429\n",
      "\tspeed: 0.0380s/iter; left time: 694.4650s\n",
      "\titers: 200, epoch: 19 | loss: 0.0986811\n",
      "\tspeed: 0.0173s/iter; left time: 314.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.1034381 Vali Loss: 0.1230585 Test Loss: 0.1366643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1045177\n",
      "\tspeed: 0.0363s/iter; left time: 655.6206s\n",
      "\titers: 200, epoch: 20 | loss: 0.1002315\n",
      "\tspeed: 0.0150s/iter; left time: 269.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.1032201 Vali Loss: 0.1232348 Test Loss: 0.1364671\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1003440\n",
      "\tspeed: 0.0371s/iter; left time: 661.4857s\n",
      "\titers: 200, epoch: 21 | loss: 0.1079771\n",
      "\tspeed: 0.0162s/iter; left time: 286.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1032409 Vali Loss: 0.1229962 Test Loss: 0.1363579\n",
      "Validation loss decreased (0.123010 --> 0.122996).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0974193\n",
      "\tspeed: 0.0375s/iter; left time: 659.0262s\n",
      "\titers: 200, epoch: 22 | loss: 0.1055632\n",
      "\tspeed: 0.0150s/iter; left time: 262.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1030024 Vali Loss: 0.1236867 Test Loss: 0.1368668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1045842\n",
      "\tspeed: 0.0407s/iter; left time: 706.7542s\n",
      "\titers: 200, epoch: 23 | loss: 0.1001791\n",
      "\tspeed: 0.0175s/iter; left time: 302.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1028071 Vali Loss: 0.1229351 Test Loss: 0.1367407\n",
      "Validation loss decreased (0.122996 --> 0.122935).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1028660\n",
      "\tspeed: 0.0386s/iter; left time: 661.5522s\n",
      "\titers: 200, epoch: 24 | loss: 0.1030678\n",
      "\tspeed: 0.0185s/iter; left time: 316.1862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.1027307 Vali Loss: 0.1231981 Test Loss: 0.1369780\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1079043\n",
      "\tspeed: 0.0417s/iter; left time: 705.4581s\n",
      "\titers: 200, epoch: 25 | loss: 0.0997485\n",
      "\tspeed: 0.0165s/iter; left time: 277.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1025618 Vali Loss: 0.1228432 Test Loss: 0.1368074\n",
      "Validation loss decreased (0.122935 --> 0.122843).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1013136\n",
      "\tspeed: 0.0400s/iter; left time: 668.4007s\n",
      "\titers: 200, epoch: 26 | loss: 0.1003264\n",
      "\tspeed: 0.0188s/iter; left time: 312.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.1024874 Vali Loss: 0.1222836 Test Loss: 0.1360325\n",
      "Validation loss decreased (0.122843 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1001908\n",
      "\tspeed: 0.0377s/iter; left time: 620.9193s\n",
      "\titers: 200, epoch: 27 | loss: 0.1024758\n",
      "\tspeed: 0.0201s/iter; left time: 328.4617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1024857 Vali Loss: 0.1232072 Test Loss: 0.1375727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1050656\n",
      "\tspeed: 0.0357s/iter; left time: 580.6282s\n",
      "\titers: 200, epoch: 28 | loss: 0.0989919\n",
      "\tspeed: 0.0165s/iter; left time: 266.5051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1023387 Vali Loss: 0.1223971 Test Loss: 0.1358186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0992189\n",
      "\tspeed: 0.0393s/iter; left time: 629.4105s\n",
      "\titers: 200, epoch: 29 | loss: 0.0997473\n",
      "\tspeed: 0.0207s/iter; left time: 329.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.1023556 Vali Loss: 0.1223976 Test Loss: 0.1356400\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1027533\n",
      "\tspeed: 0.0396s/iter; left time: 625.3713s\n",
      "\titers: 200, epoch: 30 | loss: 0.1043150\n",
      "\tspeed: 0.0154s/iter; left time: 241.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1023500 Vali Loss: 0.1224043 Test Loss: 0.1359883\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0997440\n",
      "\tspeed: 0.0407s/iter; left time: 634.4716s\n",
      "\titers: 200, epoch: 31 | loss: 0.1029905\n",
      "\tspeed: 0.0184s/iter; left time: 284.3750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.1021641 Vali Loss: 0.1223458 Test Loss: 0.1359386\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1053476\n",
      "\tspeed: 0.0399s/iter; left time: 613.0437s\n",
      "\titers: 200, epoch: 32 | loss: 0.0999263\n",
      "\tspeed: 0.0202s/iter; left time: 308.4802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1022238 Vali Loss: 0.1222648 Test Loss: 0.1357422\n",
      "Validation loss decreased (0.122284 --> 0.122265).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1003921\n",
      "\tspeed: 0.0376s/iter; left time: 569.1564s\n",
      "\titers: 200, epoch: 33 | loss: 0.1012147\n",
      "\tspeed: 0.0175s/iter; left time: 262.8479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1020617 Vali Loss: 0.1225676 Test Loss: 0.1362886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1035976\n",
      "\tspeed: 0.0394s/iter; left time: 587.6062s\n",
      "\titers: 200, epoch: 34 | loss: 0.0986196\n",
      "\tspeed: 0.0221s/iter; left time: 326.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.1020378 Vali Loss: 0.1226296 Test Loss: 0.1365600\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1064013\n",
      "\tspeed: 0.0415s/iter; left time: 609.4926s\n",
      "\titers: 200, epoch: 35 | loss: 0.1000919\n",
      "\tspeed: 0.0167s/iter; left time: 243.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.1020877 Vali Loss: 0.1224432 Test Loss: 0.1362459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1011138\n",
      "\tspeed: 0.0387s/iter; left time: 559.2014s\n",
      "\titers: 200, epoch: 36 | loss: 0.1072276\n",
      "\tspeed: 0.0181s/iter; left time: 259.8949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1020631 Vali Loss: 0.1221538 Test Loss: 0.1357708\n",
      "Validation loss decreased (0.122265 --> 0.122154).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1004174\n",
      "\tspeed: 0.0362s/iter; left time: 515.2943s\n",
      "\titers: 200, epoch: 37 | loss: 0.0974741\n",
      "\tspeed: 0.0153s/iter; left time: 215.8305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.1019782 Vali Loss: 0.1221450 Test Loss: 0.1356951\n",
      "Validation loss decreased (0.122154 --> 0.122145).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1009666\n",
      "\tspeed: 0.0382s/iter; left time: 535.9680s\n",
      "\titers: 200, epoch: 38 | loss: 0.0958814\n",
      "\tspeed: 0.0165s/iter; left time: 229.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1020305 Vali Loss: 0.1218969 Test Loss: 0.1350510\n",
      "Validation loss decreased (0.122145 --> 0.121897).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1072502\n",
      "\tspeed: 0.0411s/iter; left time: 567.1347s\n",
      "\titers: 200, epoch: 39 | loss: 0.1015734\n",
      "\tspeed: 0.0182s/iter; left time: 249.7761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1019427 Vali Loss: 0.1223282 Test Loss: 0.1358555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1020058\n",
      "\tspeed: 0.0366s/iter; left time: 495.8077s\n",
      "\titers: 200, epoch: 40 | loss: 0.0996480\n",
      "\tspeed: 0.0205s/iter; left time: 276.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1019052 Vali Loss: 0.1224128 Test Loss: 0.1357289\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1092607\n",
      "\tspeed: 0.0353s/iter; left time: 470.3896s\n",
      "\titers: 200, epoch: 41 | loss: 0.1032982\n",
      "\tspeed: 0.0150s/iter; left time: 198.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.1018248 Vali Loss: 0.1219604 Test Loss: 0.1354129\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1021474\n",
      "\tspeed: 0.0410s/iter; left time: 537.9664s\n",
      "\titers: 200, epoch: 42 | loss: 0.1040739\n",
      "\tspeed: 0.0165s/iter; left time: 214.4978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1018259 Vali Loss: 0.1223762 Test Loss: 0.1359084\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1060762\n",
      "\tspeed: 0.0374s/iter; left time: 481.6339s\n",
      "\titers: 200, epoch: 43 | loss: 0.1048280\n",
      "\tspeed: 0.0172s/iter; left time: 219.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1018107 Vali Loss: 0.1225776 Test Loss: 0.1364729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1029061\n",
      "\tspeed: 0.0375s/iter; left time: 474.7903s\n",
      "\titers: 200, epoch: 44 | loss: 0.0994365\n",
      "\tspeed: 0.0164s/iter; left time: 205.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1018751 Vali Loss: 0.1224436 Test Loss: 0.1361720\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0998201\n",
      "\tspeed: 0.0381s/iter; left time: 473.6046s\n",
      "\titers: 200, epoch: 45 | loss: 0.1050539\n",
      "\tspeed: 0.0185s/iter; left time: 228.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1018009 Vali Loss: 0.1221234 Test Loss: 0.1355880\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0982425\n",
      "\tspeed: 0.0386s/iter; left time: 471.1251s\n",
      "\titers: 200, epoch: 46 | loss: 0.1004094\n",
      "\tspeed: 0.0163s/iter; left time: 198.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1018462 Vali Loss: 0.1224753 Test Loss: 0.1361422\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1004537\n",
      "\tspeed: 0.0395s/iter; left time: 474.0886s\n",
      "\titers: 200, epoch: 47 | loss: 0.0961077\n",
      "\tspeed: 0.0155s/iter; left time: 183.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.1018180 Vali Loss: 0.1223693 Test Loss: 0.1359236\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1002767\n",
      "\tspeed: 0.0361s/iter; left time: 425.5463s\n",
      "\titers: 200, epoch: 48 | loss: 0.1010218\n",
      "\tspeed: 0.0162s/iter; left time: 189.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.1018113 Vali Loss: 0.1223205 Test Loss: 0.1361200\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04309926554560661, rmse:0.20760363340377808, mae:0.13505104184150696, rse:0.7351664304733276\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:24.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0395s/iter; left time: 876.3139s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0152s/iter; left time: 335.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0376s/iter; left time: 826.6072s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0174s/iter; left time: 381.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0363s/iter; left time: 790.1651s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0163s/iter; left time: 351.9294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0380s/iter; left time: 818.1769s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0168s/iter; left time: 360.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0387s/iter; left time: 824.9281s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0190s/iter; left time: 403.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0402s/iter; left time: 848.0186s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0170s/iter; left time: 356.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0375s/iter; left time: 782.5566s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0164s/iter; left time: 339.8541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0376s/iter; left time: 777.0295s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0166s/iter; left time: 341.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0364s/iter; left time: 742.8901s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0165s/iter; left time: 334.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0356s/iter; left time: 719.0075s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0152s/iter; left time: 305.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0363s/iter; left time: 725.7218s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0162s/iter; left time: 322.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0351s/iter; left time: 692.3419s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0166s/iter; left time: 325.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0397s/iter; left time: 774.3431s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0180s/iter; left time: 349.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0400s/iter; left time: 772.5251s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0208s/iter; left time: 399.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0386s/iter; left time: 736.2254s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0161s/iter; left time: 305.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0346s/iter; left time: 653.0091s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0152s/iter; left time: 285.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0353s/iter; left time: 657.5769s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0152s/iter; left time: 280.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0379s/iter; left time: 697.3954s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0208s/iter; left time: 381.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0405s/iter; left time: 736.6843s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0173s/iter; left time: 313.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1128351\n",
      "\tspeed: 0.0371s/iter; left time: 666.5857s\n",
      "\titers: 200, epoch: 20 | loss: 0.1115036\n",
      "\tspeed: 0.0181s/iter; left time: 322.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.1088133 Vali Loss: 0.1296562 Test Loss: 0.1430260\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1089209\n",
      "\tspeed: 0.0354s/iter; left time: 627.7926s\n",
      "\titers: 200, epoch: 21 | loss: 0.1049455\n",
      "\tspeed: 0.0153s/iter; left time: 269.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1087389 Vali Loss: 0.1280911 Test Loss: 0.1400650\n",
      "Validation loss decreased (0.128590 --> 0.128091).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1089510\n",
      "\tspeed: 0.0389s/iter; left time: 682.2622s\n",
      "\titers: 200, epoch: 22 | loss: 0.1118146\n",
      "\tspeed: 0.0181s/iter; left time: 315.1838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1085359 Vali Loss: 0.1289085 Test Loss: 0.1414145\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1127648\n",
      "\tspeed: 0.0367s/iter; left time: 635.5440s\n",
      "\titers: 200, epoch: 23 | loss: 0.1073037\n",
      "\tspeed: 0.0153s/iter; left time: 262.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1083876 Vali Loss: 0.1286885 Test Loss: 0.1415340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1052145\n",
      "\tspeed: 0.0377s/iter; left time: 643.3274s\n",
      "\titers: 200, epoch: 24 | loss: 0.1095430\n",
      "\tspeed: 0.0167s/iter; left time: 283.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1081785 Vali Loss: 0.1283687 Test Loss: 0.1406554\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1106745\n",
      "\tspeed: 0.0369s/iter; left time: 621.4673s\n",
      "\titers: 200, epoch: 25 | loss: 0.1078078\n",
      "\tspeed: 0.0213s/iter; left time: 356.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1080985 Vali Loss: 0.1285096 Test Loss: 0.1409658\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1090272\n",
      "\tspeed: 0.0377s/iter; left time: 626.3036s\n",
      "\titers: 200, epoch: 26 | loss: 0.1082668\n",
      "\tspeed: 0.0158s/iter; left time: 261.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.1080526 Vali Loss: 0.1276924 Test Loss: 0.1404647\n",
      "Validation loss decreased (0.128091 --> 0.127692).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1094660\n",
      "\tspeed: 0.0362s/iter; left time: 594.2780s\n",
      "\titers: 200, epoch: 27 | loss: 0.1094127\n",
      "\tspeed: 0.0174s/iter; left time: 284.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1079262 Vali Loss: 0.1288600 Test Loss: 0.1418495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1063156\n",
      "\tspeed: 0.0366s/iter; left time: 592.3783s\n",
      "\titers: 200, epoch: 28 | loss: 0.1129479\n",
      "\tspeed: 0.0180s/iter; left time: 289.4233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.1077841 Vali Loss: 0.1282874 Test Loss: 0.1410196\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1066447\n",
      "\tspeed: 0.0390s/iter; left time: 622.8050s\n",
      "\titers: 200, epoch: 29 | loss: 0.1012538\n",
      "\tspeed: 0.0166s/iter; left time: 263.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1077484 Vali Loss: 0.1283567 Test Loss: 0.1414497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1091326\n",
      "\tspeed: 0.0403s/iter; left time: 634.1901s\n",
      "\titers: 200, epoch: 30 | loss: 0.1057610\n",
      "\tspeed: 0.0185s/iter; left time: 289.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.1076596 Vali Loss: 0.1288015 Test Loss: 0.1421737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1129125\n",
      "\tspeed: 0.0413s/iter; left time: 640.7938s\n",
      "\titers: 200, epoch: 31 | loss: 0.1121067\n",
      "\tspeed: 0.0205s/iter; left time: 315.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1076513 Vali Loss: 0.1288997 Test Loss: 0.1427089\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1074071\n",
      "\tspeed: 0.0382s/iter; left time: 584.1302s\n",
      "\titers: 200, epoch: 32 | loss: 0.1050972\n",
      "\tspeed: 0.0186s/iter; left time: 283.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1075939 Vali Loss: 0.1285509 Test Loss: 0.1420687\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1064574\n",
      "\tspeed: 0.0348s/iter; left time: 524.4059s\n",
      "\titers: 200, epoch: 33 | loss: 0.1079464\n",
      "\tspeed: 0.0152s/iter; left time: 227.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.1075518 Vali Loss: 0.1277073 Test Loss: 0.1409436\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1094171\n",
      "\tspeed: 0.0379s/iter; left time: 562.4429s\n",
      "\titers: 200, epoch: 34 | loss: 0.1012441\n",
      "\tspeed: 0.0172s/iter; left time: 253.2288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1075745 Vali Loss: 0.1284703 Test Loss: 0.1418752\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1087584\n",
      "\tspeed: 0.0376s/iter; left time: 550.1703s\n",
      "\titers: 200, epoch: 35 | loss: 0.1107625\n",
      "\tspeed: 0.0166s/iter; left time: 241.1042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1074390 Vali Loss: 0.1280550 Test Loss: 0.1412895\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1054707\n",
      "\tspeed: 0.0442s/iter; left time: 635.9884s\n",
      "\titers: 200, epoch: 36 | loss: 0.1052480\n",
      "\tspeed: 0.0180s/iter; left time: 257.3389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1074146 Vali Loss: 0.1279779 Test Loss: 0.1416783\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.044552285224199295, rmse:0.2110741287469864, mae:0.14046476781368256, rse:0.7476415038108826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2744991\n",
      "\tspeed: 0.0194s/iter; left time: 430.8308s\n",
      "\titers: 200, epoch: 1 | loss: 0.2641147\n",
      "\tspeed: 0.0166s/iter; left time: 366.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.2783999 Vali Loss: 0.2379947 Test Loss: 0.2423942\n",
      "Validation loss decreased (inf --> 0.237995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1556567\n",
      "\tspeed: 0.0362s/iter; left time: 796.5652s\n",
      "\titers: 200, epoch: 2 | loss: 0.1396492\n",
      "\tspeed: 0.0163s/iter; left time: 355.6427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.1671781 Vali Loss: 0.1447358 Test Loss: 0.1522740\n",
      "Validation loss decreased (0.237995 --> 0.144736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1281172\n",
      "\tspeed: 0.0403s/iter; left time: 877.3041s\n",
      "\titers: 200, epoch: 3 | loss: 0.1312603\n",
      "\tspeed: 0.0185s/iter; left time: 401.2348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1311306 Vali Loss: 0.1353014 Test Loss: 0.1466275\n",
      "Validation loss decreased (0.144736 --> 0.135301).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1211887\n",
      "\tspeed: 0.0369s/iter; left time: 794.6325s\n",
      "\titers: 200, epoch: 4 | loss: 0.1183547\n",
      "\tspeed: 0.0152s/iter; left time: 326.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.1229378 Vali Loss: 0.1342717 Test Loss: 0.1467632\n",
      "Validation loss decreased (0.135301 --> 0.134272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1239808\n",
      "\tspeed: 0.0410s/iter; left time: 873.3143s\n",
      "\titers: 200, epoch: 5 | loss: 0.1168796\n",
      "\tspeed: 0.0202s/iter; left time: 428.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1192592 Vali Loss: 0.1300050 Test Loss: 0.1415242\n",
      "Validation loss decreased (0.134272 --> 0.130005).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1182984\n",
      "\tspeed: 0.0393s/iter; left time: 828.5885s\n",
      "\titers: 200, epoch: 6 | loss: 0.1171903\n",
      "\tspeed: 0.0167s/iter; left time: 350.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1166339 Vali Loss: 0.1296393 Test Loss: 0.1407897\n",
      "Validation loss decreased (0.130005 --> 0.129639).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1194612\n",
      "\tspeed: 0.0364s/iter; left time: 760.0350s\n",
      "\titers: 200, epoch: 7 | loss: 0.1164228\n",
      "\tspeed: 0.0152s/iter; left time: 315.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.1154953 Vali Loss: 0.1325710 Test Loss: 0.1433164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1124757\n",
      "\tspeed: 0.0370s/iter; left time: 763.5124s\n",
      "\titers: 200, epoch: 8 | loss: 0.1162293\n",
      "\tspeed: 0.0167s/iter; left time: 342.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.1143113 Vali Loss: 0.1291094 Test Loss: 0.1404415\n",
      "Validation loss decreased (0.129639 --> 0.129109).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1146200\n",
      "\tspeed: 0.0386s/iter; left time: 788.6904s\n",
      "\titers: 200, epoch: 9 | loss: 0.1169974\n",
      "\tspeed: 0.0163s/iter; left time: 332.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1132893 Vali Loss: 0.1273294 Test Loss: 0.1382572\n",
      "Validation loss decreased (0.129109 --> 0.127329).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1129709\n",
      "\tspeed: 0.0422s/iter; left time: 851.5106s\n",
      "\titers: 200, epoch: 10 | loss: 0.1146486\n",
      "\tspeed: 0.0152s/iter; left time: 304.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1127601 Vali Loss: 0.1269920 Test Loss: 0.1385130\n",
      "Validation loss decreased (0.127329 --> 0.126992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1098697\n",
      "\tspeed: 0.0379s/iter; left time: 757.8093s\n",
      "\titers: 200, epoch: 11 | loss: 0.1127002\n",
      "\tspeed: 0.0179s/iter; left time: 355.6706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1122303 Vali Loss: 0.1296180 Test Loss: 0.1411653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1178860\n",
      "\tspeed: 0.0367s/iter; left time: 725.2088s\n",
      "\titers: 200, epoch: 12 | loss: 0.1080562\n",
      "\tspeed: 0.0175s/iter; left time: 343.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1117056 Vali Loss: 0.1294848 Test Loss: 0.1418801\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1112355\n",
      "\tspeed: 0.0411s/iter; left time: 802.4621s\n",
      "\titers: 200, epoch: 13 | loss: 0.1111286\n",
      "\tspeed: 0.0190s/iter; left time: 369.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.1112279 Vali Loss: 0.1293019 Test Loss: 0.1417095\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1033714\n",
      "\tspeed: 0.0362s/iter; left time: 698.6176s\n",
      "\titers: 200, epoch: 14 | loss: 0.1122320\n",
      "\tspeed: 0.0162s/iter; left time: 310.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1108339 Vali Loss: 0.1286721 Test Loss: 0.1407368\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1146212\n",
      "\tspeed: 0.0378s/iter; left time: 721.9754s\n",
      "\titers: 200, epoch: 15 | loss: 0.1127912\n",
      "\tspeed: 0.0166s/iter; left time: 315.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.1104134 Vali Loss: 0.1296972 Test Loss: 0.1427345\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1112949\n",
      "\tspeed: 0.0355s/iter; left time: 669.9838s\n",
      "\titers: 200, epoch: 16 | loss: 0.1096983\n",
      "\tspeed: 0.0168s/iter; left time: 315.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.1101559 Vali Loss: 0.1271977 Test Loss: 0.1399690\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1107738\n",
      "\tspeed: 0.0400s/iter; left time: 746.0634s\n",
      "\titers: 200, epoch: 17 | loss: 0.1145247\n",
      "\tspeed: 0.0194s/iter; left time: 360.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1098280 Vali Loss: 0.1279991 Test Loss: 0.1410300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1091873\n",
      "\tspeed: 0.0358s/iter; left time: 659.4336s\n",
      "\titers: 200, epoch: 18 | loss: 0.1066963\n",
      "\tspeed: 0.0152s/iter; left time: 278.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.1097318 Vali Loss: 0.1293264 Test Loss: 0.1422503\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1057076\n",
      "\tspeed: 0.0421s/iter; left time: 766.0203s\n",
      "\titers: 200, epoch: 19 | loss: 0.1163264\n",
      "\tspeed: 0.0163s/iter; left time: 295.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.1094545 Vali Loss: 0.1284010 Test Loss: 0.1421688\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1145523\n",
      "\tspeed: 0.0361s/iter; left time: 648.5449s\n",
      "\titers: 200, epoch: 20 | loss: 0.1089584\n",
      "\tspeed: 0.0153s/iter; left time: 273.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1092729 Vali Loss: 0.1282443 Test Loss: 0.1419774\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04232504218816757, rmse:0.20573051273822784, mae:0.1385130137205124, rse:0.7287139892578125\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:21.90s\n",
      "Intermediate time for DE: 00h:22m:25.23s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0390s/iter; left time: 869.0456s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0149s/iter; left time: 329.7373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0333s/iter; left time: 734.7366s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0149s/iter; left time: 328.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0337s/iter; left time: 736.7449s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0148s/iter; left time: 321.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0334s/iter; left time: 723.2656s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0148s/iter; left time: 319.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0373s/iter; left time: 798.0395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0218s/iter; left time: 465.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0343s/iter; left time: 726.6886s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0149s/iter; left time: 313.6438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0373s/iter; left time: 781.8105s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0159s/iter; left time: 330.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0390s/iter; left time: 809.4581s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0188s/iter; left time: 387.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0349s/iter; left time: 715.2935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0177s/iter; left time: 360.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0395s/iter; left time: 801.8680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0186s/iter; left time: 376.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0393s/iter; left time: 789.1576s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0189s/iter; left time: 377.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0373s/iter; left time: 739.9074s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0180s/iter; left time: 355.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0394s/iter; left time: 773.1022s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0196s/iter; left time: 381.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0437s/iter; left time: 847.8326s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0176s/iter; left time: 339.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0350s/iter; left time: 670.2888s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0184s/iter; left time: 350.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0367s/iter; left time: 694.1920s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0148s/iter; left time: 279.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0370s/iter; left time: 692.6591s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0168s/iter; left time: 313.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0374s/iter; left time: 691.0593s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0212s/iter; left time: 389.9416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0332s/iter; left time: 606.5515s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0149s/iter; left time: 271.3102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0398s/iter; left time: 718.0279s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0229s/iter; left time: 411.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0764413\n",
      "\tspeed: 0.0368s/iter; left time: 656.5722s\n",
      "\titers: 200, epoch: 21 | loss: 0.0775579\n",
      "\tspeed: 0.0179s/iter; left time: 317.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0794832 Vali Loss: 0.0922160 Test Loss: 0.1059103\n",
      "Validation loss decreased (0.092648 --> 0.092216).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0750777\n",
      "\tspeed: 0.0361s/iter; left time: 635.6163s\n",
      "\titers: 200, epoch: 22 | loss: 0.0767003\n",
      "\tspeed: 0.0196s/iter; left time: 342.2780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0793035 Vali Loss: 0.0922287 Test Loss: 0.1062462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0774668\n",
      "\tspeed: 0.0397s/iter; left time: 689.3149s\n",
      "\titers: 200, epoch: 23 | loss: 0.0764778\n",
      "\tspeed: 0.0160s/iter; left time: 276.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0791268 Vali Loss: 0.0925499 Test Loss: 0.1060301\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0832801\n",
      "\tspeed: 0.0411s/iter; left time: 704.3894s\n",
      "\titers: 200, epoch: 24 | loss: 0.0814398\n",
      "\tspeed: 0.0172s/iter; left time: 292.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0789638 Vali Loss: 0.0924772 Test Loss: 0.1064283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0800643\n",
      "\tspeed: 0.0353s/iter; left time: 596.9539s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791814\n",
      "\tspeed: 0.0161s/iter; left time: 270.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0789486 Vali Loss: 0.0930298 Test Loss: 0.1066121\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796904\n",
      "\tspeed: 0.0384s/iter; left time: 641.6697s\n",
      "\titers: 200, epoch: 26 | loss: 0.0771316\n",
      "\tspeed: 0.0208s/iter; left time: 346.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0790268 Vali Loss: 0.0925604 Test Loss: 0.1061667\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0826450\n",
      "\tspeed: 0.0378s/iter; left time: 623.4627s\n",
      "\titers: 200, epoch: 27 | loss: 0.0831101\n",
      "\tspeed: 0.0171s/iter; left time: 279.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0788740 Vali Loss: 0.0926468 Test Loss: 0.1061734\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819598\n",
      "\tspeed: 0.0406s/iter; left time: 659.0946s\n",
      "\titers: 200, epoch: 28 | loss: 0.0791325\n",
      "\tspeed: 0.0161s/iter; left time: 259.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0787329 Vali Loss: 0.0931808 Test Loss: 0.1070156\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0808779\n",
      "\tspeed: 0.0394s/iter; left time: 630.8892s\n",
      "\titers: 200, epoch: 29 | loss: 0.0794952\n",
      "\tspeed: 0.0185s/iter; left time: 294.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0787373 Vali Loss: 0.0925326 Test Loss: 0.1062035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0786930\n",
      "\tspeed: 0.0341s/iter; left time: 539.1591s\n",
      "\titers: 200, epoch: 30 | loss: 0.0793163\n",
      "\tspeed: 0.0182s/iter; left time: 285.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0786670 Vali Loss: 0.0929713 Test Loss: 0.1066934\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0800112\n",
      "\tspeed: 0.0394s/iter; left time: 614.5491s\n",
      "\titers: 200, epoch: 31 | loss: 0.0791296\n",
      "\tspeed: 0.0204s/iter; left time: 316.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0786878 Vali Loss: 0.0922258 Test Loss: 0.1064776\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02694176509976387, rmse:0.16413946449756622, mae:0.10591025650501251, rse:0.5662346482276917\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2908871\n",
      "\tspeed: 0.0188s/iter; left time: 420.2659s\n",
      "\titers: 200, epoch: 1 | loss: 0.2730023\n",
      "\tspeed: 0.0150s/iter; left time: 333.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.2871942 Vali Loss: 0.2444913 Test Loss: 0.2645374\n",
      "Validation loss decreased (inf --> 0.244491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410559\n",
      "\tspeed: 0.0407s/iter; left time: 898.2868s\n",
      "\titers: 200, epoch: 2 | loss: 0.1104743\n",
      "\tspeed: 0.0179s/iter; left time: 392.3462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1550662 Vali Loss: 0.1082898 Test Loss: 0.1234926\n",
      "Validation loss decreased (0.244491 --> 0.108290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023160\n",
      "\tspeed: 0.0360s/iter; left time: 785.9072s\n",
      "\titers: 200, epoch: 3 | loss: 0.0967745\n",
      "\tspeed: 0.0200s/iter; left time: 434.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1025424 Vali Loss: 0.0974422 Test Loss: 0.1096326\n",
      "Validation loss decreased (0.108290 --> 0.097442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971604\n",
      "\tspeed: 0.0368s/iter; left time: 796.7012s\n",
      "\titers: 200, epoch: 4 | loss: 0.0899035\n",
      "\tspeed: 0.0172s/iter; left time: 369.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0924125 Vali Loss: 0.0978540 Test Loss: 0.1130235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0846692\n",
      "\tspeed: 0.0383s/iter; left time: 819.6520s\n",
      "\titers: 200, epoch: 5 | loss: 0.0906144\n",
      "\tspeed: 0.0152s/iter; left time: 324.1516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0882784 Vali Loss: 0.0959395 Test Loss: 0.1097864\n",
      "Validation loss decreased (0.097442 --> 0.095939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0848261\n",
      "\tspeed: 0.0417s/iter; left time: 882.2002s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811776\n",
      "\tspeed: 0.0200s/iter; left time: 421.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0862749 Vali Loss: 0.0952228 Test Loss: 0.1090894\n",
      "Validation loss decreased (0.095939 --> 0.095223).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828368\n",
      "\tspeed: 0.0353s/iter; left time: 739.9922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865732\n",
      "\tspeed: 0.0164s/iter; left time: 341.4881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0847028 Vali Loss: 0.0939569 Test Loss: 0.1076050\n",
      "Validation loss decreased (0.095223 --> 0.093957).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0787013\n",
      "\tspeed: 0.0362s/iter; left time: 750.1557s\n",
      "\titers: 200, epoch: 8 | loss: 0.0853842\n",
      "\tspeed: 0.0160s/iter; left time: 329.2480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0837123 Vali Loss: 0.0937281 Test Loss: 0.1069735\n",
      "Validation loss decreased (0.093957 --> 0.093728).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0831238\n",
      "\tspeed: 0.0352s/iter; left time: 722.6708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0829130\n",
      "\tspeed: 0.0186s/iter; left time: 378.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0831108 Vali Loss: 0.0937356 Test Loss: 0.1065833\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833643\n",
      "\tspeed: 0.0388s/iter; left time: 787.3302s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843041\n",
      "\tspeed: 0.0192s/iter; left time: 388.2020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0823158 Vali Loss: 0.0933490 Test Loss: 0.1061504\n",
      "Validation loss decreased (0.093728 --> 0.093349).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775133\n",
      "\tspeed: 0.0429s/iter; left time: 860.6424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786133\n",
      "\tspeed: 0.0189s/iter; left time: 376.6985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0816524 Vali Loss: 0.0931040 Test Loss: 0.1061128\n",
      "Validation loss decreased (0.093349 --> 0.093104).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781198\n",
      "\tspeed: 0.0364s/iter; left time: 721.4170s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837125\n",
      "\tspeed: 0.0169s/iter; left time: 334.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0814042 Vali Loss: 0.0932580 Test Loss: 0.1064448\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783289\n",
      "\tspeed: 0.0365s/iter; left time: 715.5823s\n",
      "\titers: 200, epoch: 13 | loss: 0.0794865\n",
      "\tspeed: 0.0189s/iter; left time: 368.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0810518 Vali Loss: 0.0928836 Test Loss: 0.1061874\n",
      "Validation loss decreased (0.093104 --> 0.092884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0789644\n",
      "\tspeed: 0.0353s/iter; left time: 683.4837s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794672\n",
      "\tspeed: 0.0161s/iter; left time: 310.8890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0806366 Vali Loss: 0.0932994 Test Loss: 0.1063543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803705\n",
      "\tspeed: 0.0363s/iter; left time: 695.0612s\n",
      "\titers: 200, epoch: 15 | loss: 0.0816594\n",
      "\tspeed: 0.0179s/iter; left time: 341.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0804825 Vali Loss: 0.0927894 Test Loss: 0.1060549\n",
      "Validation loss decreased (0.092884 --> 0.092789).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0874846\n",
      "\tspeed: 0.0374s/iter; left time: 708.8393s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787541\n",
      "\tspeed: 0.0187s/iter; left time: 352.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0802071 Vali Loss: 0.0927323 Test Loss: 0.1055353\n",
      "Validation loss decreased (0.092789 --> 0.092732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0764223\n",
      "\tspeed: 0.0364s/iter; left time: 680.5382s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876672\n",
      "\tspeed: 0.0169s/iter; left time: 315.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0799835 Vali Loss: 0.0934802 Test Loss: 0.1060668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0816835\n",
      "\tspeed: 0.0374s/iter; left time: 690.9000s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795193\n",
      "\tspeed: 0.0182s/iter; left time: 334.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0797706 Vali Loss: 0.0924805 Test Loss: 0.1056486\n",
      "Validation loss decreased (0.092732 --> 0.092481).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758096\n",
      "\tspeed: 0.0397s/iter; left time: 725.8928s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759346\n",
      "\tspeed: 0.0210s/iter; left time: 382.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0795556 Vali Loss: 0.0926971 Test Loss: 0.1054964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764526\n",
      "\tspeed: 0.0349s/iter; left time: 629.9052s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820286\n",
      "\tspeed: 0.0149s/iter; left time: 266.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0795062 Vali Loss: 0.0923530 Test Loss: 0.1052698\n",
      "Validation loss decreased (0.092481 --> 0.092353).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799056\n",
      "\tspeed: 0.0347s/iter; left time: 618.7883s\n",
      "\titers: 200, epoch: 21 | loss: 0.0803694\n",
      "\tspeed: 0.0151s/iter; left time: 268.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0794412 Vali Loss: 0.0931432 Test Loss: 0.1060107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0748962\n",
      "\tspeed: 0.0361s/iter; left time: 635.8990s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796375\n",
      "\tspeed: 0.0182s/iter; left time: 318.4474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0792102 Vali Loss: 0.0926149 Test Loss: 0.1056100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758943\n",
      "\tspeed: 0.0408s/iter; left time: 708.6523s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753200\n",
      "\tspeed: 0.0197s/iter; left time: 340.3115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0790810 Vali Loss: 0.0926582 Test Loss: 0.1055936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778612\n",
      "\tspeed: 0.0340s/iter; left time: 582.3470s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780891\n",
      "\tspeed: 0.0176s/iter; left time: 299.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0790612 Vali Loss: 0.0927992 Test Loss: 0.1057558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0871981\n",
      "\tspeed: 0.0337s/iter; left time: 570.6942s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760559\n",
      "\tspeed: 0.0160s/iter; left time: 268.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0789873 Vali Loss: 0.0921219 Test Loss: 0.1052446\n",
      "Validation loss decreased (0.092353 --> 0.092122).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0782320\n",
      "\tspeed: 0.0395s/iter; left time: 660.2051s\n",
      "\titers: 200, epoch: 26 | loss: 0.0788959\n",
      "\tspeed: 0.0224s/iter; left time: 371.3271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0788905 Vali Loss: 0.0928220 Test Loss: 0.1057923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0744453\n",
      "\tspeed: 0.0417s/iter; left time: 686.4299s\n",
      "\titers: 200, epoch: 27 | loss: 0.0798820\n",
      "\tspeed: 0.0206s/iter; left time: 336.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0787206 Vali Loss: 0.0923934 Test Loss: 0.1054663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0831386\n",
      "\tspeed: 0.0419s/iter; left time: 681.4146s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728892\n",
      "\tspeed: 0.0229s/iter; left time: 370.2113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0786545 Vali Loss: 0.0922845 Test Loss: 0.1054097\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0778653\n",
      "\tspeed: 0.0394s/iter; left time: 631.4622s\n",
      "\titers: 200, epoch: 29 | loss: 0.0719146\n",
      "\tspeed: 0.0235s/iter; left time: 373.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0787976 Vali Loss: 0.0923579 Test Loss: 0.1054754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0685690\n",
      "\tspeed: 0.0406s/iter; left time: 642.4008s\n",
      "\titers: 200, epoch: 30 | loss: 0.0806209\n",
      "\tspeed: 0.0207s/iter; left time: 325.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0786865 Vali Loss: 0.0927233 Test Loss: 0.1057628\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0726656\n",
      "\tspeed: 0.0355s/iter; left time: 552.7233s\n",
      "\titers: 200, epoch: 31 | loss: 0.0773063\n",
      "\tspeed: 0.0169s/iter; left time: 262.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0785973 Vali Loss: 0.0921454 Test Loss: 0.1053599\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816479\n",
      "\tspeed: 0.0430s/iter; left time: 660.1654s\n",
      "\titers: 200, epoch: 32 | loss: 0.0817126\n",
      "\tspeed: 0.0220s/iter; left time: 335.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0786178 Vali Loss: 0.0923548 Test Loss: 0.1056355\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0773016\n",
      "\tspeed: 0.0414s/iter; left time: 626.6649s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803075\n",
      "\tspeed: 0.0194s/iter; left time: 291.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0786045 Vali Loss: 0.0921716 Test Loss: 0.1053509\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754239\n",
      "\tspeed: 0.0336s/iter; left time: 500.2607s\n",
      "\titers: 200, epoch: 34 | loss: 0.0827927\n",
      "\tspeed: 0.0174s/iter; left time: 257.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0784336 Vali Loss: 0.0923538 Test Loss: 0.1054920\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0799392\n",
      "\tspeed: 0.0394s/iter; left time: 578.1350s\n",
      "\titers: 200, epoch: 35 | loss: 0.0800448\n",
      "\tspeed: 0.0157s/iter; left time: 229.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0785155 Vali Loss: 0.0923782 Test Loss: 0.1055542\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026500752195715904, rmse:0.16279052197933197, mae:0.10524464398622513, rse:0.5615811347961426\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:17.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0433s/iter; left time: 965.0928s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0179s/iter; left time: 396.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0394s/iter; left time: 870.3642s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0193s/iter; left time: 423.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0368s/iter; left time: 805.0498s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0174s/iter; left time: 378.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0381s/iter; left time: 823.6695s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0156s/iter; left time: 336.5995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0373s/iter; left time: 798.3692s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0168s/iter; left time: 357.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0357s/iter; left time: 755.2786s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0166s/iter; left time: 350.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0389s/iter; left time: 816.0717s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0165s/iter; left time: 344.1824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0381s/iter; left time: 789.4407s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0180s/iter; left time: 371.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0344s/iter; left time: 705.1219s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0150s/iter; left time: 305.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0331s/iter; left time: 671.1039s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0150s/iter; left time: 303.5190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0354s/iter; left time: 711.0714s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0177s/iter; left time: 352.9554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0385s/iter; left time: 763.3195s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0158s/iter; left time: 312.3024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0349s/iter; left time: 683.9526s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0155s/iter; left time: 302.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0355s/iter; left time: 688.2724s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0166s/iter; left time: 320.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0343s/iter; left time: 657.3135s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0150s/iter; left time: 286.6823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0371s/iter; left time: 703.0155s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0151s/iter; left time: 284.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1045979\n",
      "\tspeed: 0.0373s/iter; left time: 697.6761s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060435\n",
      "\tspeed: 0.0150s/iter; left time: 278.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.1029846 Vali Loss: 0.1258308 Test Loss: 0.1572115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1049089\n",
      "\tspeed: 0.0374s/iter; left time: 691.8797s\n",
      "\titers: 200, epoch: 18 | loss: 0.1004239\n",
      "\tspeed: 0.0170s/iter; left time: 311.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1027992 Vali Loss: 0.1261423 Test Loss: 0.1578836\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1043303\n",
      "\tspeed: 0.0367s/iter; left time: 669.9256s\n",
      "\titers: 200, epoch: 19 | loss: 0.1018612\n",
      "\tspeed: 0.0172s/iter; left time: 312.1830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1026257 Vali Loss: 0.1258573 Test Loss: 0.1567056\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1031136\n",
      "\tspeed: 0.0366s/iter; left time: 660.0394s\n",
      "\titers: 200, epoch: 20 | loss: 0.1018248\n",
      "\tspeed: 0.0151s/iter; left time: 270.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1024617 Vali Loss: 0.1246465 Test Loss: 0.1569057\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1018606\n",
      "\tspeed: 0.0372s/iter; left time: 663.5961s\n",
      "\titers: 200, epoch: 21 | loss: 0.0991599\n",
      "\tspeed: 0.0166s/iter; left time: 294.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1023430 Vali Loss: 0.1247049 Test Loss: 0.1567344\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2915673\n",
      "\tspeed: 0.0241s/iter; left time: 537.8002s\n",
      "\titers: 200, epoch: 1 | loss: 0.2674311\n",
      "\tspeed: 0.0167s/iter; left time: 370.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.2916491 Vali Loss: 0.2483680 Test Loss: 0.2712487\n",
      "Validation loss decreased (inf --> 0.248368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456207\n",
      "\tspeed: 0.0392s/iter; left time: 864.6435s\n",
      "\titers: 200, epoch: 2 | loss: 0.1379834\n",
      "\tspeed: 0.0181s/iter; left time: 398.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1630503 Vali Loss: 0.1345576 Test Loss: 0.1575292\n",
      "Validation loss decreased (0.248368 --> 0.134558).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1188209\n",
      "\tspeed: 0.0393s/iter; left time: 858.1208s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203921\n",
      "\tspeed: 0.0178s/iter; left time: 388.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1200628 Vali Loss: 0.1257125 Test Loss: 0.1526250\n",
      "Validation loss decreased (0.134558 --> 0.125713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1143665\n",
      "\tspeed: 0.0410s/iter; left time: 887.8449s\n",
      "\titers: 200, epoch: 4 | loss: 0.1150253\n",
      "\tspeed: 0.0160s/iter; left time: 344.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.1123677 Vali Loss: 0.1259064 Test Loss: 0.1581046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095381\n",
      "\tspeed: 0.0413s/iter; left time: 883.4850s\n",
      "\titers: 200, epoch: 5 | loss: 0.1060184\n",
      "\tspeed: 0.0170s/iter; left time: 362.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1096526 Vali Loss: 0.1241158 Test Loss: 0.1530023\n",
      "Validation loss decreased (0.125713 --> 0.124116).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060926\n",
      "\tspeed: 0.0362s/iter; left time: 767.4871s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084698\n",
      "\tspeed: 0.0164s/iter; left time: 346.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1080182 Vali Loss: 0.1248462 Test Loss: 0.1527426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1090836\n",
      "\tspeed: 0.0350s/iter; left time: 734.4987s\n",
      "\titers: 200, epoch: 7 | loss: 0.1050917\n",
      "\tspeed: 0.0156s/iter; left time: 324.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1067462 Vali Loss: 0.1260519 Test Loss: 0.1557394\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1026927\n",
      "\tspeed: 0.0362s/iter; left time: 749.7985s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051408\n",
      "\tspeed: 0.0166s/iter; left time: 343.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.1059064 Vali Loss: 0.1233336 Test Loss: 0.1507457\n",
      "Validation loss decreased (0.124116 --> 0.123334).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1041532\n",
      "\tspeed: 0.0402s/iter; left time: 824.3610s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069562\n",
      "\tspeed: 0.0172s/iter; left time: 350.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.1053053 Vali Loss: 0.1256639 Test Loss: 0.1549997\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047203\n",
      "\tspeed: 0.0372s/iter; left time: 754.3320s\n",
      "\titers: 200, epoch: 10 | loss: 0.1056637\n",
      "\tspeed: 0.0162s/iter; left time: 327.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1047988 Vali Loss: 0.1245097 Test Loss: 0.1523917\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0963618\n",
      "\tspeed: 0.0349s/iter; left time: 701.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000071\n",
      "\tspeed: 0.0178s/iter; left time: 355.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1044075 Vali Loss: 0.1244897 Test Loss: 0.1538499\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996287\n",
      "\tspeed: 0.0413s/iter; left time: 818.6305s\n",
      "\titers: 200, epoch: 12 | loss: 0.1009973\n",
      "\tspeed: 0.0174s/iter; left time: 343.1230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1041731 Vali Loss: 0.1247110 Test Loss: 0.1516322\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1045526\n",
      "\tspeed: 0.0368s/iter; left time: 721.3940s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058753\n",
      "\tspeed: 0.0164s/iter; left time: 319.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1037614 Vali Loss: 0.1245964 Test Loss: 0.1535005\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981016\n",
      "\tspeed: 0.0365s/iter; left time: 706.9089s\n",
      "\titers: 200, epoch: 14 | loss: 0.1059557\n",
      "\tspeed: 0.0158s/iter; left time: 303.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.1035623 Vali Loss: 0.1259414 Test Loss: 0.1559952\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1032800\n",
      "\tspeed: 0.0367s/iter; left time: 703.2399s\n",
      "\titers: 200, epoch: 15 | loss: 0.1087450\n",
      "\tspeed: 0.0151s/iter; left time: 287.3388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.1034006 Vali Loss: 0.1240164 Test Loss: 0.1517604\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076163\n",
      "\tspeed: 0.0357s/iter; left time: 676.5826s\n",
      "\titers: 200, epoch: 16 | loss: 0.0996509\n",
      "\tspeed: 0.0162s/iter; left time: 305.5750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1030843 Vali Loss: 0.1236664 Test Loss: 0.1521370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0992341\n",
      "\tspeed: 0.0361s/iter; left time: 675.7657s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039612\n",
      "\tspeed: 0.0178s/iter; left time: 330.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1028798 Vali Loss: 0.1244692 Test Loss: 0.1526084\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041440\n",
      "\tspeed: 0.0371s/iter; left time: 685.3838s\n",
      "\titers: 200, epoch: 18 | loss: 0.1025722\n",
      "\tspeed: 0.0164s/iter; left time: 300.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.1027069 Vali Loss: 0.1248132 Test Loss: 0.1531992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051235370337963104, rmse:0.22635231912136078, mae:0.15074577927589417, rse:0.7827578186988831\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:41.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0400s/iter; left time: 887.8761s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0152s/iter; left time: 336.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0360s/iter; left time: 791.7716s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0152s/iter; left time: 333.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0367s/iter; left time: 798.9114s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0152s/iter; left time: 329.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0379s/iter; left time: 815.4114s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0152s/iter; left time: 326.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0397s/iter; left time: 846.3410s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0189s/iter; left time: 400.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0377s/iter; left time: 794.8380s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0152s/iter; left time: 319.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0362s/iter; left time: 756.1634s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0178s/iter; left time: 370.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0367s/iter; left time: 758.4496s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0164s/iter; left time: 336.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0378s/iter; left time: 772.6383s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0188s/iter; left time: 382.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0417s/iter; left time: 843.0074s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0199s/iter; left time: 399.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0373s/iter; left time: 743.9241s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0161s/iter; left time: 319.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0371s/iter; left time: 732.3133s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0167s/iter; left time: 328.7583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0405s/iter; left time: 790.5564s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0181s/iter; left time: 351.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1064795\n",
      "\tspeed: 0.0387s/iter; left time: 747.6094s\n",
      "\titers: 200, epoch: 14 | loss: 0.1044248\n",
      "\tspeed: 0.0169s/iter; left time: 324.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1079363 Vali Loss: 0.1284752 Test Loss: 0.1583262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1090524\n",
      "\tspeed: 0.0370s/iter; left time: 706.0965s\n",
      "\titers: 200, epoch: 15 | loss: 0.1080710\n",
      "\tspeed: 0.0152s/iter; left time: 288.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1076277 Vali Loss: 0.1299890 Test Loss: 0.1589850\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1078600\n",
      "\tspeed: 0.0360s/iter; left time: 678.2590s\n",
      "\titers: 200, epoch: 16 | loss: 0.1045698\n",
      "\tspeed: 0.0175s/iter; left time: 328.7737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1073363 Vali Loss: 0.1290679 Test Loss: 0.1590714\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1044126\n",
      "\tspeed: 0.0361s/iter; left time: 672.9709s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068518\n",
      "\tspeed: 0.0152s/iter; left time: 281.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1071260 Vali Loss: 0.1287172 Test Loss: 0.1593278\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1058048\n",
      "\tspeed: 0.0357s/iter; left time: 658.0952s\n",
      "\titers: 200, epoch: 18 | loss: 0.1047655\n",
      "\tspeed: 0.0171s/iter; left time: 313.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1071445 Vali Loss: 0.1295316 Test Loss: 0.1593569\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2923186\n",
      "\tspeed: 0.0172s/iter; left time: 381.9853s\n",
      "\titers: 200, epoch: 1 | loss: 0.2762249\n",
      "\tspeed: 0.0152s/iter; left time: 335.8445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.2933771 Vali Loss: 0.2526797 Test Loss: 0.2736033\n",
      "Validation loss decreased (inf --> 0.252680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551580\n",
      "\tspeed: 0.0370s/iter; left time: 812.5683s\n",
      "\titers: 200, epoch: 2 | loss: 0.1352695\n",
      "\tspeed: 0.0165s/iter; left time: 360.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.1652988 Vali Loss: 0.1362184 Test Loss: 0.1586260\n",
      "Validation loss decreased (0.252680 --> 0.136218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1243433\n",
      "\tspeed: 0.0426s/iter; left time: 925.7772s\n",
      "\titers: 200, epoch: 3 | loss: 0.1164440\n",
      "\tspeed: 0.0181s/iter; left time: 392.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1235833 Vali Loss: 0.1302298 Test Loss: 0.1581837\n",
      "Validation loss decreased (0.136218 --> 0.130230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153650\n",
      "\tspeed: 0.0395s/iter; left time: 850.0902s\n",
      "\titers: 200, epoch: 4 | loss: 0.1093810\n",
      "\tspeed: 0.0162s/iter; left time: 347.3294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1165450 Vali Loss: 0.1327701 Test Loss: 0.1657872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1114925\n",
      "\tspeed: 0.0389s/iter; left time: 828.8978s\n",
      "\titers: 200, epoch: 5 | loss: 0.1166446\n",
      "\tspeed: 0.0225s/iter; left time: 476.6908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1142123 Vali Loss: 0.1384112 Test Loss: 0.1725486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1159245\n",
      "\tspeed: 0.0410s/iter; left time: 863.5525s\n",
      "\titers: 200, epoch: 6 | loss: 0.1144330\n",
      "\tspeed: 0.0163s/iter; left time: 341.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1128792 Vali Loss: 0.1327941 Test Loss: 0.1649415\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1111590\n",
      "\tspeed: 0.0360s/iter; left time: 750.7403s\n",
      "\titers: 200, epoch: 7 | loss: 0.1099538\n",
      "\tspeed: 0.0152s/iter; left time: 316.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1114473 Vali Loss: 0.1319743 Test Loss: 0.1646918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1125822\n",
      "\tspeed: 0.0386s/iter; left time: 797.5030s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070650\n",
      "\tspeed: 0.0198s/iter; left time: 407.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.1105803 Vali Loss: 0.1306519 Test Loss: 0.1608720\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1134858\n",
      "\tspeed: 0.0382s/iter; left time: 780.4537s\n",
      "\titers: 200, epoch: 9 | loss: 0.1098845\n",
      "\tspeed: 0.0152s/iter; left time: 309.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.1098493 Vali Loss: 0.1315106 Test Loss: 0.1636475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1113448\n",
      "\tspeed: 0.0371s/iter; left time: 749.2556s\n",
      "\titers: 200, epoch: 10 | loss: 0.1081774\n",
      "\tspeed: 0.0153s/iter; left time: 306.5478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.1093590 Vali Loss: 0.1321909 Test Loss: 0.1632495\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1055759\n",
      "\tspeed: 0.0408s/iter; left time: 814.5050s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067710\n",
      "\tspeed: 0.0175s/iter; left time: 347.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.1088795 Vali Loss: 0.1319298 Test Loss: 0.1639058\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1088536\n",
      "\tspeed: 0.0365s/iter; left time: 720.2158s\n",
      "\titers: 200, epoch: 12 | loss: 0.1071380\n",
      "\tspeed: 0.0161s/iter; left time: 315.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1083560 Vali Loss: 0.1304587 Test Loss: 0.1632485\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1050788\n",
      "\tspeed: 0.0402s/iter; left time: 784.8587s\n",
      "\titers: 200, epoch: 13 | loss: 0.1077113\n",
      "\tspeed: 0.0180s/iter; left time: 348.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.1081560 Vali Loss: 0.1302897 Test Loss: 0.1620840\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05474921688437462, rmse:0.23398549854755402, mae:0.15818369388580322, rse:0.8112613558769226\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:02.04s\n",
      "Intermediate time for GB: 00h:13m:01.58s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0384s/iter; left time: 855.6758s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0157s/iter; left time: 348.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0318s/iter; left time: 701.7125s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0126s/iter; left time: 276.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0336s/iter; left time: 733.9452s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0192s/iter; left time: 417.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0325s/iter; left time: 702.5907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0176s/iter; left time: 379.7166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0333s/iter; left time: 711.7892s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0174s/iter; left time: 369.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0361s/iter; left time: 765.5475s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0159s/iter; left time: 335.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0363s/iter; left time: 761.7160s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0171s/iter; left time: 356.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0320s/iter; left time: 663.1165s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0110s/iter; left time: 226.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0352s/iter; left time: 722.9159s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0157s/iter; left time: 319.9617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0326s/iter; left time: 661.6535s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0160s/iter; left time: 322.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0329s/iter; left time: 659.0375s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0157s/iter; left time: 312.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0326s/iter; left time: 646.8030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0186s/iter; left time: 367.7808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0369s/iter; left time: 723.9862s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0171s/iter; left time: 334.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0283s/iter; left time: 547.8673s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0101s/iter; left time: 193.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0323s/iter; left time: 619.6414s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0171s/iter; left time: 326.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0362s/iter; left time: 686.1739s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0163s/iter; left time: 307.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0361s/iter; left time: 676.5590s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0189s/iter; left time: 352.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0327s/iter; left time: 605.6019s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0192s/iter; left time: 353.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0375s/iter; left time: 685.1078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0164s/iter; left time: 298.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0317s/iter; left time: 571.9249s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0173s/iter; left time: 311.0888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0648402\n",
      "\tspeed: 0.0330s/iter; left time: 588.1987s\n",
      "\titers: 200, epoch: 21 | loss: 0.0659379\n",
      "\tspeed: 0.0153s/iter; left time: 271.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0639698 Vali Loss: 0.0608919 Test Loss: 0.0778968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0637138\n",
      "\tspeed: 0.0337s/iter; left time: 592.5647s\n",
      "\titers: 200, epoch: 22 | loss: 0.0635084\n",
      "\tspeed: 0.0165s/iter; left time: 288.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0637860 Vali Loss: 0.0606405 Test Loss: 0.0837043\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0631013\n",
      "\tspeed: 0.0375s/iter; left time: 650.8804s\n",
      "\titers: 200, epoch: 23 | loss: 0.0647522\n",
      "\tspeed: 0.0157s/iter; left time: 272.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0632991 Vali Loss: 0.0600661 Test Loss: 0.0856460\n",
      "Validation loss decreased (0.060550 --> 0.060066).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0609565\n",
      "\tspeed: 0.0329s/iter; left time: 564.6940s\n",
      "\titers: 200, epoch: 24 | loss: 0.0638104\n",
      "\tspeed: 0.0171s/iter; left time: 291.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0633592 Vali Loss: 0.0603217 Test Loss: 0.0811601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0567263\n",
      "\tspeed: 0.0335s/iter; left time: 567.2577s\n",
      "\titers: 200, epoch: 25 | loss: 0.0636959\n",
      "\tspeed: 0.0192s/iter; left time: 322.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0634488 Vali Loss: 0.0603399 Test Loss: 0.0805059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0653335\n",
      "\tspeed: 0.0318s/iter; left time: 530.5050s\n",
      "\titers: 200, epoch: 26 | loss: 0.0610906\n",
      "\tspeed: 0.0157s/iter; left time: 260.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0630774 Vali Loss: 0.0601113 Test Loss: 0.0808194\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0637621\n",
      "\tspeed: 0.0311s/iter; left time: 511.7464s\n",
      "\titers: 200, epoch: 27 | loss: 0.0624986\n",
      "\tspeed: 0.0154s/iter; left time: 251.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0631169 Vali Loss: 0.0599364 Test Loss: 0.0802414\n",
      "Validation loss decreased (0.060066 --> 0.059936).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0626996\n",
      "\tspeed: 0.0382s/iter; left time: 620.8214s\n",
      "\titers: 200, epoch: 28 | loss: 0.0650475\n",
      "\tspeed: 0.0207s/iter; left time: 333.7111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0630036 Vali Loss: 0.0599976 Test Loss: 0.0798610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0650523\n",
      "\tspeed: 0.0330s/iter; left time: 529.0379s\n",
      "\titers: 200, epoch: 29 | loss: 0.0648407\n",
      "\tspeed: 0.0165s/iter; left time: 263.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0631537 Vali Loss: 0.0601693 Test Loss: 0.0790092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0616945\n",
      "\tspeed: 0.0338s/iter; left time: 533.9914s\n",
      "\titers: 200, epoch: 30 | loss: 0.0640166\n",
      "\tspeed: 0.0172s/iter; left time: 270.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0627853 Vali Loss: 0.0597060 Test Loss: 0.0790351\n",
      "Validation loss decreased (0.059936 --> 0.059706).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0632247\n",
      "\tspeed: 0.0362s/iter; left time: 563.6902s\n",
      "\titers: 200, epoch: 31 | loss: 0.0642793\n",
      "\tspeed: 0.0199s/iter; left time: 307.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0626874 Vali Loss: 0.0596988 Test Loss: 0.0799922\n",
      "Validation loss decreased (0.059706 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0618795\n",
      "\tspeed: 0.0353s/iter; left time: 542.8332s\n",
      "\titers: 200, epoch: 32 | loss: 0.0638621\n",
      "\tspeed: 0.0206s/iter; left time: 314.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0626309 Vali Loss: 0.0600133 Test Loss: 0.0793648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0613759\n",
      "\tspeed: 0.0325s/iter; left time: 491.6919s\n",
      "\titers: 200, epoch: 33 | loss: 0.0650249\n",
      "\tspeed: 0.0189s/iter; left time: 284.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0626958 Vali Loss: 0.0597566 Test Loss: 0.0829300\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0625083\n",
      "\tspeed: 0.0325s/iter; left time: 485.1795s\n",
      "\titers: 200, epoch: 34 | loss: 0.0649817\n",
      "\tspeed: 0.0191s/iter; left time: 282.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0626086 Vali Loss: 0.0595278 Test Loss: 0.0785535\n",
      "Validation loss decreased (0.059699 --> 0.059528).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0618905\n",
      "\tspeed: 0.0339s/iter; left time: 498.2365s\n",
      "\titers: 200, epoch: 35 | loss: 0.0594872\n",
      "\tspeed: 0.0169s/iter; left time: 246.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0625302 Vali Loss: 0.0598271 Test Loss: 0.0774672\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0628262\n",
      "\tspeed: 0.0338s/iter; left time: 489.3673s\n",
      "\titers: 200, epoch: 36 | loss: 0.0613497\n",
      "\tspeed: 0.0177s/iter; left time: 254.8023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0629912 Vali Loss: 0.0594929 Test Loss: 0.0812049\n",
      "Validation loss decreased (0.059528 --> 0.059493).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0603207\n",
      "\tspeed: 0.0347s/iter; left time: 493.6192s\n",
      "\titers: 200, epoch: 37 | loss: 0.0618328\n",
      "\tspeed: 0.0165s/iter; left time: 232.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0624442 Vali Loss: 0.0599277 Test Loss: 0.0808704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0623976\n",
      "\tspeed: 0.0340s/iter; left time: 476.5979s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618199\n",
      "\tspeed: 0.0156s/iter; left time: 216.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0623962 Vali Loss: 0.0596360 Test Loss: 0.0795271\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0588883\n",
      "\tspeed: 0.0310s/iter; left time: 426.8742s\n",
      "\titers: 200, epoch: 39 | loss: 0.0610459\n",
      "\tspeed: 0.0158s/iter; left time: 216.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0623432 Vali Loss: 0.0594202 Test Loss: 0.0799924\n",
      "Validation loss decreased (0.059493 --> 0.059420).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0598964\n",
      "\tspeed: 0.0336s/iter; left time: 456.3273s\n",
      "\titers: 200, epoch: 40 | loss: 0.0590530\n",
      "\tspeed: 0.0180s/iter; left time: 241.7516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0626194 Vali Loss: 0.0593982 Test Loss: 0.0784466\n",
      "Validation loss decreased (0.059420 --> 0.059398).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0659376\n",
      "\tspeed: 0.0326s/iter; left time: 434.3538s\n",
      "\titers: 200, epoch: 41 | loss: 0.0624791\n",
      "\tspeed: 0.0159s/iter; left time: 210.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0623992 Vali Loss: 0.0596976 Test Loss: 0.0798948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0641973\n",
      "\tspeed: 0.0351s/iter; left time: 459.9691s\n",
      "\titers: 200, epoch: 42 | loss: 0.0649498\n",
      "\tspeed: 0.0189s/iter; left time: 246.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0623876 Vali Loss: 0.0597047 Test Loss: 0.0779574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0603804\n",
      "\tspeed: 0.0341s/iter; left time: 439.7153s\n",
      "\titers: 200, epoch: 43 | loss: 0.0657060\n",
      "\tspeed: 0.0190s/iter; left time: 242.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0622967 Vali Loss: 0.0595325 Test Loss: 0.0775056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0661049\n",
      "\tspeed: 0.0340s/iter; left time: 430.9311s\n",
      "\titers: 200, epoch: 44 | loss: 0.0636315\n",
      "\tspeed: 0.0159s/iter; left time: 199.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0623053 Vali Loss: 0.0593446 Test Loss: 0.0787060\n",
      "Validation loss decreased (0.059398 --> 0.059345).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0670810\n",
      "\tspeed: 0.0335s/iter; left time: 416.3161s\n",
      "\titers: 200, epoch: 45 | loss: 0.0628282\n",
      "\tspeed: 0.0180s/iter; left time: 222.5152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0624146 Vali Loss: 0.0595850 Test Loss: 0.0776185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0668972\n",
      "\tspeed: 0.0364s/iter; left time: 444.7156s\n",
      "\titers: 200, epoch: 46 | loss: 0.0657387\n",
      "\tspeed: 0.0187s/iter; left time: 226.1885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0624402 Vali Loss: 0.0597573 Test Loss: 0.0789046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0605890\n",
      "\tspeed: 0.0315s/iter; left time: 377.5239s\n",
      "\titers: 200, epoch: 47 | loss: 0.0628887\n",
      "\tspeed: 0.0164s/iter; left time: 195.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0621471 Vali Loss: 0.0595367 Test Loss: 0.0784753\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642688\n",
      "\tspeed: 0.0344s/iter; left time: 405.5209s\n",
      "\titers: 200, epoch: 48 | loss: 0.0593611\n",
      "\tspeed: 0.0168s/iter; left time: 195.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0623013 Vali Loss: 0.0593974 Test Loss: 0.0798472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0635834\n",
      "\tspeed: 0.0327s/iter; left time: 377.2142s\n",
      "\titers: 200, epoch: 49 | loss: 0.0619003\n",
      "\tspeed: 0.0181s/iter; left time: 207.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0625203 Vali Loss: 0.0595282 Test Loss: 0.0791877\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0609761\n",
      "\tspeed: 0.0327s/iter; left time: 369.8463s\n",
      "\titers: 200, epoch: 50 | loss: 0.0622208\n",
      "\tspeed: 0.0161s/iter; left time: 180.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0622423 Vali Loss: 0.0596158 Test Loss: 0.0792489\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0619520\n",
      "\tspeed: 0.0346s/iter; left time: 384.5503s\n",
      "\titers: 200, epoch: 51 | loss: 0.0628265\n",
      "\tspeed: 0.0208s/iter; left time: 228.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0622624 Vali Loss: 0.0594051 Test Loss: 0.0773887\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0612404\n",
      "\tspeed: 0.0366s/iter; left time: 398.2263s\n",
      "\titers: 200, epoch: 52 | loss: 0.0628188\n",
      "\tspeed: 0.0143s/iter; left time: 154.1178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0623996 Vali Loss: 0.0594793 Test Loss: 0.0774014\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0643009\n",
      "\tspeed: 0.0316s/iter; left time: 336.9391s\n",
      "\titers: 200, epoch: 53 | loss: 0.0634064\n",
      "\tspeed: 0.0178s/iter; left time: 187.9674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0622669 Vali Loss: 0.0596862 Test Loss: 0.0778411\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0614927\n",
      "\tspeed: 0.0349s/iter; left time: 364.1732s\n",
      "\titers: 200, epoch: 54 | loss: 0.0631441\n",
      "\tspeed: 0.0186s/iter; left time: 191.7512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0622740 Vali Loss: 0.0595357 Test Loss: 0.0777481\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.016271354630589485, rmse:0.12755921483039856, mae:0.07870597392320633, rse:0.3753913640975952\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2892122\n",
      "\tspeed: 0.0179s/iter; left time: 399.0307s\n",
      "\titers: 200, epoch: 1 | loss: 0.2660992\n",
      "\tspeed: 0.0150s/iter; left time: 333.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.2965279 Vali Loss: 0.2202346 Test Loss: 0.2370768\n",
      "Validation loss decreased (inf --> 0.220235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1539855\n",
      "\tspeed: 0.0339s/iter; left time: 749.3284s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143376\n",
      "\tspeed: 0.0166s/iter; left time: 364.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1615120 Vali Loss: 0.0888261 Test Loss: 0.0968157\n",
      "Validation loss decreased (0.220235 --> 0.088826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0979644\n",
      "\tspeed: 0.0318s/iter; left time: 693.9139s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927927\n",
      "\tspeed: 0.0150s/iter; left time: 326.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0995892 Vali Loss: 0.0764636 Test Loss: 0.0847130\n",
      "Validation loss decreased (0.088826 --> 0.076464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897991\n",
      "\tspeed: 0.0336s/iter; left time: 726.2248s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827181\n",
      "\tspeed: 0.0167s/iter; left time: 358.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0869733 Vali Loss: 0.0734729 Test Loss: 0.0810101\n",
      "Validation loss decreased (0.076464 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815627\n",
      "\tspeed: 0.0339s/iter; left time: 726.6957s\n",
      "\titers: 200, epoch: 5 | loss: 0.0739117\n",
      "\tspeed: 0.0173s/iter; left time: 368.9728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0803262 Vali Loss: 0.0700490 Test Loss: 0.0803528\n",
      "Validation loss decreased (0.073473 --> 0.070049).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777595\n",
      "\tspeed: 0.0345s/iter; left time: 730.0524s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752439\n",
      "\tspeed: 0.0179s/iter; left time: 378.0151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0772147 Vali Loss: 0.0690502 Test Loss: 0.0800061\n",
      "Validation loss decreased (0.070049 --> 0.069050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741698\n",
      "\tspeed: 0.0356s/iter; left time: 746.0829s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786026\n",
      "\tspeed: 0.0174s/iter; left time: 362.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0746004 Vali Loss: 0.0662944 Test Loss: 0.0831919\n",
      "Validation loss decreased (0.069050 --> 0.066294).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0720962\n",
      "\tspeed: 0.0329s/iter; left time: 681.4652s\n",
      "\titers: 200, epoch: 8 | loss: 0.0674486\n",
      "\tspeed: 0.0192s/iter; left time: 395.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0723453 Vali Loss: 0.0655117 Test Loss: 0.0828428\n",
      "Validation loss decreased (0.066294 --> 0.065512).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749420\n",
      "\tspeed: 0.0347s/iter; left time: 710.7153s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707552\n",
      "\tspeed: 0.0144s/iter; left time: 293.9704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 224 | Train Loss: 0.0709444 Vali Loss: 0.0649825 Test Loss: 0.0820810\n",
      "Validation loss decreased (0.065512 --> 0.064982).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0653492\n",
      "\tspeed: 0.0330s/iter; left time: 669.2527s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728749\n",
      "\tspeed: 0.0181s/iter; left time: 364.9746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0694805 Vali Loss: 0.0637436 Test Loss: 0.0805136\n",
      "Validation loss decreased (0.064982 --> 0.063744).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0654753\n",
      "\tspeed: 0.0387s/iter; left time: 776.8824s\n",
      "\titers: 200, epoch: 11 | loss: 0.0646911\n",
      "\tspeed: 0.0197s/iter; left time: 393.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0686186 Vali Loss: 0.0641838 Test Loss: 0.0822113\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0649198\n",
      "\tspeed: 0.0328s/iter; left time: 650.0589s\n",
      "\titers: 200, epoch: 12 | loss: 0.0646746\n",
      "\tspeed: 0.0161s/iter; left time: 316.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0679764 Vali Loss: 0.0641024 Test Loss: 0.0817276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0697122\n",
      "\tspeed: 0.0307s/iter; left time: 602.8240s\n",
      "\titers: 200, epoch: 13 | loss: 0.0700299\n",
      "\tspeed: 0.0099s/iter; left time: 193.4861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0673256 Vali Loss: 0.0622702 Test Loss: 0.0806944\n",
      "Validation loss decreased (0.063744 --> 0.062270).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0658208\n",
      "\tspeed: 0.0313s/iter; left time: 605.9611s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666625\n",
      "\tspeed: 0.0159s/iter; left time: 307.3291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0666473 Vali Loss: 0.0622615 Test Loss: 0.0788437\n",
      "Validation loss decreased (0.062270 --> 0.062262).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662519\n",
      "\tspeed: 0.0331s/iter; left time: 633.5907s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660783\n",
      "\tspeed: 0.0162s/iter; left time: 308.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0663878 Vali Loss: 0.0617795 Test Loss: 0.0770767\n",
      "Validation loss decreased (0.062262 --> 0.061779).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652738\n",
      "\tspeed: 0.0356s/iter; left time: 675.0020s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645800\n",
      "\tspeed: 0.0179s/iter; left time: 337.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0657017 Vali Loss: 0.0615699 Test Loss: 0.0756564\n",
      "Validation loss decreased (0.061779 --> 0.061570).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0623387\n",
      "\tspeed: 0.0322s/iter; left time: 601.7918s\n",
      "\titers: 200, epoch: 17 | loss: 0.0682290\n",
      "\tspeed: 0.0155s/iter; left time: 288.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0653807 Vali Loss: 0.0609969 Test Loss: 0.0759708\n",
      "Validation loss decreased (0.061570 --> 0.060997).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0629665\n",
      "\tspeed: 0.0338s/iter; left time: 625.4666s\n",
      "\titers: 200, epoch: 18 | loss: 0.0660909\n",
      "\tspeed: 0.0173s/iter; left time: 319.0849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0650203 Vali Loss: 0.0611630 Test Loss: 0.0762600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0647769\n",
      "\tspeed: 0.0349s/iter; left time: 637.8426s\n",
      "\titers: 200, epoch: 19 | loss: 0.0643299\n",
      "\tspeed: 0.0156s/iter; left time: 283.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0648261 Vali Loss: 0.0609118 Test Loss: 0.0763575\n",
      "Validation loss decreased (0.060997 --> 0.060912).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0626265\n",
      "\tspeed: 0.0318s/iter; left time: 572.9716s\n",
      "\titers: 200, epoch: 20 | loss: 0.0649455\n",
      "\tspeed: 0.0157s/iter; left time: 281.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0646050 Vali Loss: 0.0608533 Test Loss: 0.0770059\n",
      "Validation loss decreased (0.060912 --> 0.060853).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0618789\n",
      "\tspeed: 0.0332s/iter; left time: 592.1758s\n",
      "\titers: 200, epoch: 21 | loss: 0.0675359\n",
      "\tspeed: 0.0186s/iter; left time: 329.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0644248 Vali Loss: 0.0606882 Test Loss: 0.0761549\n",
      "Validation loss decreased (0.060853 --> 0.060688).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0643762\n",
      "\tspeed: 0.0386s/iter; left time: 678.5458s\n",
      "\titers: 200, epoch: 22 | loss: 0.0665079\n",
      "\tspeed: 0.0219s/iter; left time: 383.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0641298 Vali Loss: 0.0605414 Test Loss: 0.0749995\n",
      "Validation loss decreased (0.060688 --> 0.060541).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0626361\n",
      "\tspeed: 0.0383s/iter; left time: 665.5295s\n",
      "\titers: 200, epoch: 23 | loss: 0.0619444\n",
      "\tspeed: 0.0193s/iter; left time: 333.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0640495 Vali Loss: 0.0600125 Test Loss: 0.0751412\n",
      "Validation loss decreased (0.060541 --> 0.060012).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0668678\n",
      "\tspeed: 0.0365s/iter; left time: 626.7898s\n",
      "\titers: 200, epoch: 24 | loss: 0.0629791\n",
      "\tspeed: 0.0121s/iter; left time: 206.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 224 | Train Loss: 0.0638809 Vali Loss: 0.0602886 Test Loss: 0.0745161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0644174\n",
      "\tspeed: 0.0330s/iter; left time: 559.2635s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646280\n",
      "\tspeed: 0.0201s/iter; left time: 337.5876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0637914 Vali Loss: 0.0599894 Test Loss: 0.0751399\n",
      "Validation loss decreased (0.060012 --> 0.059989).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0615174\n",
      "\tspeed: 0.0333s/iter; left time: 556.0216s\n",
      "\titers: 200, epoch: 26 | loss: 0.0625327\n",
      "\tspeed: 0.0155s/iter; left time: 257.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0636017 Vali Loss: 0.0598450 Test Loss: 0.0747057\n",
      "Validation loss decreased (0.059989 --> 0.059845).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0655383\n",
      "\tspeed: 0.0318s/iter; left time: 524.3757s\n",
      "\titers: 200, epoch: 27 | loss: 0.0614031\n",
      "\tspeed: 0.0102s/iter; left time: 166.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0633817 Vali Loss: 0.0599251 Test Loss: 0.0746622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0626174\n",
      "\tspeed: 0.0360s/iter; left time: 585.3081s\n",
      "\titers: 200, epoch: 28 | loss: 0.0628177\n",
      "\tspeed: 0.0191s/iter; left time: 308.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0635918 Vali Loss: 0.0596987 Test Loss: 0.0741641\n",
      "Validation loss decreased (0.059845 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0661405\n",
      "\tspeed: 0.0338s/iter; left time: 542.3381s\n",
      "\titers: 200, epoch: 29 | loss: 0.0686575\n",
      "\tspeed: 0.0163s/iter; left time: 259.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0635368 Vali Loss: 0.0600278 Test Loss: 0.0744089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0627493\n",
      "\tspeed: 0.0333s/iter; left time: 526.9533s\n",
      "\titers: 200, epoch: 30 | loss: 0.0637090\n",
      "\tspeed: 0.0159s/iter; left time: 249.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0634227 Vali Loss: 0.0599569 Test Loss: 0.0740244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0647104\n",
      "\tspeed: 0.0315s/iter; left time: 491.3461s\n",
      "\titers: 200, epoch: 31 | loss: 0.0634678\n",
      "\tspeed: 0.0176s/iter; left time: 272.4524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0631139 Vali Loss: 0.0599802 Test Loss: 0.0741277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0605536\n",
      "\tspeed: 0.0328s/iter; left time: 504.1445s\n",
      "\titers: 200, epoch: 32 | loss: 0.0625743\n",
      "\tspeed: 0.0157s/iter; left time: 240.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0631250 Vali Loss: 0.0596394 Test Loss: 0.0736590\n",
      "Validation loss decreased (0.059699 --> 0.059639).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0637135\n",
      "\tspeed: 0.0339s/iter; left time: 512.8766s\n",
      "\titers: 200, epoch: 33 | loss: 0.0634592\n",
      "\tspeed: 0.0180s/iter; left time: 270.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0629441 Vali Loss: 0.0595979 Test Loss: 0.0739759\n",
      "Validation loss decreased (0.059639 --> 0.059598).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0637110\n",
      "\tspeed: 0.0347s/iter; left time: 517.8827s\n",
      "\titers: 200, epoch: 34 | loss: 0.0658683\n",
      "\tspeed: 0.0184s/iter; left time: 271.8697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0629368 Vali Loss: 0.0595017 Test Loss: 0.0735492\n",
      "Validation loss decreased (0.059598 --> 0.059502).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0641423\n",
      "\tspeed: 0.0342s/iter; left time: 502.8893s\n",
      "\titers: 200, epoch: 35 | loss: 0.0604577\n",
      "\tspeed: 0.0182s/iter; left time: 266.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0630385 Vali Loss: 0.0598842 Test Loss: 0.0740244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0683392\n",
      "\tspeed: 0.0320s/iter; left time: 463.4408s\n",
      "\titers: 200, epoch: 36 | loss: 0.0654246\n",
      "\tspeed: 0.0157s/iter; left time: 224.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0629729 Vali Loss: 0.0594444 Test Loss: 0.0734302\n",
      "Validation loss decreased (0.059502 --> 0.059444).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0643754\n",
      "\tspeed: 0.0344s/iter; left time: 489.8046s\n",
      "\titers: 200, epoch: 37 | loss: 0.0624843\n",
      "\tspeed: 0.0167s/iter; left time: 235.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0628177 Vali Loss: 0.0594962 Test Loss: 0.0734705\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0627216\n",
      "\tspeed: 0.0337s/iter; left time: 472.1916s\n",
      "\titers: 200, epoch: 38 | loss: 0.0634602\n",
      "\tspeed: 0.0170s/iter; left time: 236.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0627659 Vali Loss: 0.0594407 Test Loss: 0.0741697\n",
      "Validation loss decreased (0.059444 --> 0.059441).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0627414\n",
      "\tspeed: 0.0345s/iter; left time: 475.9244s\n",
      "\titers: 200, epoch: 39 | loss: 0.0655835\n",
      "\tspeed: 0.0177s/iter; left time: 242.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0628943 Vali Loss: 0.0593417 Test Loss: 0.0725542\n",
      "Validation loss decreased (0.059441 --> 0.059342).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0648856\n",
      "\tspeed: 0.0337s/iter; left time: 457.3006s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608795\n",
      "\tspeed: 0.0177s/iter; left time: 238.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0628501 Vali Loss: 0.0595566 Test Loss: 0.0731153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673042\n",
      "\tspeed: 0.0325s/iter; left time: 432.9461s\n",
      "\titers: 200, epoch: 41 | loss: 0.0609992\n",
      "\tspeed: 0.0182s/iter; left time: 240.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0628100 Vali Loss: 0.0594376 Test Loss: 0.0731614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0636128\n",
      "\tspeed: 0.0332s/iter; left time: 435.4271s\n",
      "\titers: 200, epoch: 42 | loss: 0.0640302\n",
      "\tspeed: 0.0155s/iter; left time: 201.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0627291 Vali Loss: 0.0594023 Test Loss: 0.0730519\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0644562\n",
      "\tspeed: 0.0319s/iter; left time: 411.7727s\n",
      "\titers: 200, epoch: 43 | loss: 0.0621497\n",
      "\tspeed: 0.0181s/iter; left time: 231.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0627906 Vali Loss: 0.0593885 Test Loss: 0.0738827\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0639315\n",
      "\tspeed: 0.0358s/iter; left time: 453.9205s\n",
      "\titers: 200, epoch: 44 | loss: 0.0616424\n",
      "\tspeed: 0.0177s/iter; left time: 222.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0628448 Vali Loss: 0.0594930 Test Loss: 0.0731448\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0629060\n",
      "\tspeed: 0.0333s/iter; left time: 414.2851s\n",
      "\titers: 200, epoch: 45 | loss: 0.0593640\n",
      "\tspeed: 0.0181s/iter; left time: 223.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0628275 Vali Loss: 0.0595377 Test Loss: 0.0730518\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0619585\n",
      "\tspeed: 0.0338s/iter; left time: 412.4949s\n",
      "\titers: 200, epoch: 46 | loss: 0.0605217\n",
      "\tspeed: 0.0173s/iter; left time: 210.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0625891 Vali Loss: 0.0592900 Test Loss: 0.0728881\n",
      "Validation loss decreased (0.059342 --> 0.059290).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0584388\n",
      "\tspeed: 0.0344s/iter; left time: 412.4052s\n",
      "\titers: 200, epoch: 47 | loss: 0.0590488\n",
      "\tspeed: 0.0153s/iter; left time: 181.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0627148 Vali Loss: 0.0592724 Test Loss: 0.0737006\n",
      "Validation loss decreased (0.059290 --> 0.059272).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0608841\n",
      "\tspeed: 0.0326s/iter; left time: 383.4030s\n",
      "\titers: 200, epoch: 48 | loss: 0.0631235\n",
      "\tspeed: 0.0116s/iter; left time: 135.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0627695 Vali Loss: 0.0597309 Test Loss: 0.0744821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0642522\n",
      "\tspeed: 0.0346s/iter; left time: 399.4049s\n",
      "\titers: 200, epoch: 49 | loss: 0.0623665\n",
      "\tspeed: 0.0208s/iter; left time: 238.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0626723 Vali Loss: 0.0593464 Test Loss: 0.0724346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0612011\n",
      "\tspeed: 0.0321s/iter; left time: 363.1654s\n",
      "\titers: 200, epoch: 50 | loss: 0.0623087\n",
      "\tspeed: 0.0203s/iter; left time: 227.8528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0626347 Vali Loss: 0.0594473 Test Loss: 0.0730431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0632982\n",
      "\tspeed: 0.0342s/iter; left time: 379.6309s\n",
      "\titers: 200, epoch: 51 | loss: 0.0651604\n",
      "\tspeed: 0.0151s/iter; left time: 166.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0626562 Vali Loss: 0.0597073 Test Loss: 0.0732586\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0607229\n",
      "\tspeed: 0.0341s/iter; left time: 371.1308s\n",
      "\titers: 200, epoch: 52 | loss: 0.0605967\n",
      "\tspeed: 0.0161s/iter; left time: 173.7924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0626114 Vali Loss: 0.0594380 Test Loss: 0.0729210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0633354\n",
      "\tspeed: 0.0333s/iter; left time: 354.5041s\n",
      "\titers: 200, epoch: 53 | loss: 0.0660769\n",
      "\tspeed: 0.0169s/iter; left time: 178.5289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0624637 Vali Loss: 0.0592723 Test Loss: 0.0730626\n",
      "Validation loss decreased (0.059272 --> 0.059272).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0615535\n",
      "\tspeed: 0.0343s/iter; left time: 357.7827s\n",
      "\titers: 200, epoch: 54 | loss: 0.0637485\n",
      "\tspeed: 0.0152s/iter; left time: 157.4934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0626284 Vali Loss: 0.0593004 Test Loss: 0.0733065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0591436\n",
      "\tspeed: 0.0338s/iter; left time: 344.5404s\n",
      "\titers: 200, epoch: 55 | loss: 0.0630315\n",
      "\tspeed: 0.0176s/iter; left time: 178.3453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0625872 Vali Loss: 0.0594360 Test Loss: 0.0730221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0612531\n",
      "\tspeed: 0.0329s/iter; left time: 328.1104s\n",
      "\titers: 200, epoch: 56 | loss: 0.0676546\n",
      "\tspeed: 0.0170s/iter; left time: 167.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0628035 Vali Loss: 0.0596989 Test Loss: 0.0732868\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0631388\n",
      "\tspeed: 0.0327s/iter; left time: 319.2230s\n",
      "\titers: 200, epoch: 57 | loss: 0.0645748\n",
      "\tspeed: 0.0156s/iter; left time: 150.7905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0626519 Vali Loss: 0.0592509 Test Loss: 0.0726471\n",
      "Validation loss decreased (0.059272 --> 0.059251).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0647347\n",
      "\tspeed: 0.0342s/iter; left time: 325.8646s\n",
      "\titers: 200, epoch: 58 | loss: 0.0597751\n",
      "\tspeed: 0.0190s/iter; left time: 179.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0626362 Vali Loss: 0.0595850 Test Loss: 0.0732047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0642236\n",
      "\tspeed: 0.0352s/iter; left time: 327.9528s\n",
      "\titers: 200, epoch: 59 | loss: 0.0616029\n",
      "\tspeed: 0.0180s/iter; left time: 165.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0626267 Vali Loss: 0.0595027 Test Loss: 0.0740201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0653087\n",
      "\tspeed: 0.0341s/iter; left time: 309.6131s\n",
      "\titers: 200, epoch: 60 | loss: 0.0641650\n",
      "\tspeed: 0.0173s/iter; left time: 155.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0625558 Vali Loss: 0.0596241 Test Loss: 0.0735977\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0621469\n",
      "\tspeed: 0.0327s/iter; left time: 290.0337s\n",
      "\titers: 200, epoch: 61 | loss: 0.0642872\n",
      "\tspeed: 0.0183s/iter; left time: 160.6774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0625605 Vali Loss: 0.0594029 Test Loss: 0.0732548\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0598915\n",
      "\tspeed: 0.0332s/iter; left time: 286.4403s\n",
      "\titers: 200, epoch: 62 | loss: 0.0624310\n",
      "\tspeed: 0.0179s/iter; left time: 153.2185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0626801 Vali Loss: 0.0592205 Test Loss: 0.0734248\n",
      "Validation loss decreased (0.059251 --> 0.059220).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0634078\n",
      "\tspeed: 0.0341s/iter; left time: 287.2730s\n",
      "\titers: 200, epoch: 63 | loss: 0.0655695\n",
      "\tspeed: 0.0182s/iter; left time: 150.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0624523 Vali Loss: 0.0593583 Test Loss: 0.0735325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0594155\n",
      "\tspeed: 0.0267s/iter; left time: 218.2513s\n",
      "\titers: 200, epoch: 64 | loss: 0.0609248\n",
      "\tspeed: 0.0098s/iter; left time: 79.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:02.40s\n",
      "Steps: 224 | Train Loss: 0.0625074 Vali Loss: 0.0592355 Test Loss: 0.0730888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0620877\n",
      "\tspeed: 0.0309s/iter; left time: 246.2298s\n",
      "\titers: 200, epoch: 65 | loss: 0.0662895\n",
      "\tspeed: 0.0193s/iter; left time: 151.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0625421 Vali Loss: 0.0593002 Test Loss: 0.0739252\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0629772\n",
      "\tspeed: 0.0354s/iter; left time: 274.3303s\n",
      "\titers: 200, epoch: 66 | loss: 0.0667751\n",
      "\tspeed: 0.0196s/iter; left time: 149.6893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0625571 Vali Loss: 0.0592030 Test Loss: 0.0735998\n",
      "Validation loss decreased (0.059220 --> 0.059203).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0616824\n",
      "\tspeed: 0.0364s/iter; left time: 273.8199s\n",
      "\titers: 200, epoch: 67 | loss: 0.0595338\n",
      "\tspeed: 0.0188s/iter; left time: 139.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0624756 Vali Loss: 0.0594555 Test Loss: 0.0732474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0635912\n",
      "\tspeed: 0.0333s/iter; left time: 242.9955s\n",
      "\titers: 200, epoch: 68 | loss: 0.0627736\n",
      "\tspeed: 0.0174s/iter; left time: 124.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0625410 Vali Loss: 0.0594626 Test Loss: 0.0734125\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0628619\n",
      "\tspeed: 0.0314s/iter; left time: 222.0231s\n",
      "\titers: 200, epoch: 69 | loss: 0.0656136\n",
      "\tspeed: 0.0154s/iter; left time: 107.4633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0625695 Vali Loss: 0.0592243 Test Loss: 0.0731613\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0632257\n",
      "\tspeed: 0.0340s/iter; left time: 232.9569s\n",
      "\titers: 200, epoch: 70 | loss: 0.0592294\n",
      "\tspeed: 0.0156s/iter; left time: 105.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0624855 Vali Loss: 0.0591872 Test Loss: 0.0734162\n",
      "Validation loss decreased (0.059203 --> 0.059187).  Saving model ...\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0568094\n",
      "\tspeed: 0.0369s/iter; left time: 244.5106s\n",
      "\titers: 200, epoch: 71 | loss: 0.0638159\n",
      "\tspeed: 0.0159s/iter; left time: 103.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0625757 Vali Loss: 0.0593466 Test Loss: 0.0738181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0681661\n",
      "\tspeed: 0.0325s/iter; left time: 207.5964s\n",
      "\titers: 200, epoch: 72 | loss: 0.0637419\n",
      "\tspeed: 0.0158s/iter; left time: 99.5732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0626029 Vali Loss: 0.0593822 Test Loss: 0.0733891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0624777\n",
      "\tspeed: 0.0363s/iter; left time: 223.8165s\n",
      "\titers: 200, epoch: 73 | loss: 0.0605845\n",
      "\tspeed: 0.0156s/iter; left time: 94.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0625847 Vali Loss: 0.0592924 Test Loss: 0.0728329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0611291\n",
      "\tspeed: 0.0385s/iter; left time: 228.7505s\n",
      "\titers: 200, epoch: 74 | loss: 0.0594107\n",
      "\tspeed: 0.0192s/iter; left time: 112.1805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0624167 Vali Loss: 0.0593401 Test Loss: 0.0737229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0633699\n",
      "\tspeed: 0.0331s/iter; left time: 189.6040s\n",
      "\titers: 200, epoch: 75 | loss: 0.0642549\n",
      "\tspeed: 0.0183s/iter; left time: 102.6780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0625491 Vali Loss: 0.0594092 Test Loss: 0.0737538\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0590176\n",
      "\tspeed: 0.0335s/iter; left time: 184.1030s\n",
      "\titers: 200, epoch: 76 | loss: 0.0610032\n",
      "\tspeed: 0.0192s/iter; left time: 103.4365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0626779 Vali Loss: 0.0594338 Test Loss: 0.0729458\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0648241\n",
      "\tspeed: 0.0373s/iter; left time: 196.5859s\n",
      "\titers: 200, epoch: 77 | loss: 0.0645060\n",
      "\tspeed: 0.0206s/iter; left time: 106.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0625217 Vali Loss: 0.0594396 Test Loss: 0.0738457\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0643508\n",
      "\tspeed: 0.0351s/iter; left time: 177.2694s\n",
      "\titers: 200, epoch: 78 | loss: 0.0603013\n",
      "\tspeed: 0.0173s/iter; left time: 85.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0626750 Vali Loss: 0.0599028 Test Loss: 0.0742438\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0645236\n",
      "\tspeed: 0.0369s/iter; left time: 178.4122s\n",
      "\titers: 200, epoch: 79 | loss: 0.0626074\n",
      "\tspeed: 0.0193s/iter; left time: 91.4244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0626009 Vali Loss: 0.0596587 Test Loss: 0.0732343\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0632685\n",
      "\tspeed: 0.0333s/iter; left time: 153.5290s\n",
      "\titers: 200, epoch: 80 | loss: 0.0679443\n",
      "\tspeed: 0.0157s/iter; left time: 70.8485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0626053 Vali Loss: 0.0595695 Test Loss: 0.0735726\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012944619171321392, rmse:0.11377441883087158, mae:0.07341622561216354, rse:0.3348243534564972\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:31.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0384s/iter; left time: 855.2920s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0158s/iter; left time: 350.0030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0356s/iter; left time: 784.9321s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0158s/iter; left time: 346.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0371s/iter; left time: 811.6567s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0116s/iter; left time: 252.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0354s/iter; left time: 766.6316s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0195s/iter; left time: 419.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0386s/iter; left time: 825.1645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0210s/iter; left time: 447.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0386s/iter; left time: 817.5594s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0187s/iter; left time: 393.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0365s/iter; left time: 765.2289s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0182s/iter; left time: 379.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0356s/iter; left time: 738.8744s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0188s/iter; left time: 386.8846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0330s/iter; left time: 677.4789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0181s/iter; left time: 369.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0377s/iter; left time: 765.4489s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0164s/iter; left time: 330.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0334s/iter; left time: 670.4783s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0160s/iter; left time: 319.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0350s/iter; left time: 693.4610s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0132s/iter; left time: 260.0517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0312s/iter; left time: 611.5681s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0160s/iter; left time: 312.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0332s/iter; left time: 644.5833s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0175s/iter; left time: 336.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0322s/iter; left time: 616.7283s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0156s/iter; left time: 296.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0337s/iter; left time: 637.9059s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0166s/iter; left time: 312.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0339s/iter; left time: 634.1514s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0179s/iter; left time: 333.9416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0364s/iter; left time: 673.9621s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0188s/iter; left time: 346.0785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0351s/iter; left time: 640.8080s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0163s/iter; left time: 295.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0405s/iter; left time: 730.7415s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0258s/iter; left time: 463.3586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801600\n",
      "\tspeed: 0.0340s/iter; left time: 606.6066s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823245\n",
      "\tspeed: 0.0176s/iter; left time: 311.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0818866 Vali Loss: 0.0792850 Test Loss: 0.1079874\n",
      "Validation loss decreased (0.079559 --> 0.079285).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0804956\n",
      "\tspeed: 0.0346s/iter; left time: 609.6672s\n",
      "\titers: 200, epoch: 22 | loss: 0.0824744\n",
      "\tspeed: 0.0179s/iter; left time: 313.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0819721 Vali Loss: 0.0796621 Test Loss: 0.1085374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0789200\n",
      "\tspeed: 0.0331s/iter; left time: 574.7206s\n",
      "\titers: 200, epoch: 23 | loss: 0.0837181\n",
      "\tspeed: 0.0155s/iter; left time: 267.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0820333 Vali Loss: 0.0794220 Test Loss: 0.1072117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0796378\n",
      "\tspeed: 0.0390s/iter; left time: 669.6462s\n",
      "\titers: 200, epoch: 24 | loss: 0.0776479\n",
      "\tspeed: 0.0174s/iter; left time: 296.6359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0815369 Vali Loss: 0.0793501 Test Loss: 0.1082661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0819355\n",
      "\tspeed: 0.0369s/iter; left time: 623.8443s\n",
      "\titers: 200, epoch: 25 | loss: 0.0820402\n",
      "\tspeed: 0.0192s/iter; left time: 323.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0814421 Vali Loss: 0.0792631 Test Loss: 0.1074659\n",
      "Validation loss decreased (0.079285 --> 0.079263).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0819095\n",
      "\tspeed: 0.0368s/iter; left time: 615.2176s\n",
      "\titers: 200, epoch: 26 | loss: 0.0826016\n",
      "\tspeed: 0.0200s/iter; left time: 331.2486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0814282 Vali Loss: 0.0793992 Test Loss: 0.1077555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0814544\n",
      "\tspeed: 0.0370s/iter; left time: 609.4482s\n",
      "\titers: 200, epoch: 27 | loss: 0.0890747\n",
      "\tspeed: 0.0173s/iter; left time: 283.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0814238 Vali Loss: 0.0793065 Test Loss: 0.1090543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0771820\n",
      "\tspeed: 0.0370s/iter; left time: 601.0266s\n",
      "\titers: 200, epoch: 28 | loss: 0.0793767\n",
      "\tspeed: 0.0145s/iter; left time: 234.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0811177 Vali Loss: 0.0790487 Test Loss: 0.1071326\n",
      "Validation loss decreased (0.079263 --> 0.079049).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0828157\n",
      "\tspeed: 0.0332s/iter; left time: 532.8952s\n",
      "\titers: 200, epoch: 29 | loss: 0.0837944\n",
      "\tspeed: 0.0176s/iter; left time: 280.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0811892 Vali Loss: 0.0792537 Test Loss: 0.1088195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0804581\n",
      "\tspeed: 0.0360s/iter; left time: 569.0560s\n",
      "\titers: 200, epoch: 30 | loss: 0.0849867\n",
      "\tspeed: 0.0194s/iter; left time: 304.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0811638 Vali Loss: 0.0790258 Test Loss: 0.1075138\n",
      "Validation loss decreased (0.079049 --> 0.079026).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0799334\n",
      "\tspeed: 0.0376s/iter; left time: 586.0720s\n",
      "\titers: 200, epoch: 31 | loss: 0.0820784\n",
      "\tspeed: 0.0179s/iter; left time: 277.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0811456 Vali Loss: 0.0791238 Test Loss: 0.1083240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0828095\n",
      "\tspeed: 0.0343s/iter; left time: 526.7455s\n",
      "\titers: 200, epoch: 32 | loss: 0.0822255\n",
      "\tspeed: 0.0157s/iter; left time: 239.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0812526 Vali Loss: 0.0790749 Test Loss: 0.1071283\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0796983\n",
      "\tspeed: 0.0339s/iter; left time: 513.4874s\n",
      "\titers: 200, epoch: 33 | loss: 0.0805068\n",
      "\tspeed: 0.0202s/iter; left time: 304.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0810100 Vali Loss: 0.0791240 Test Loss: 0.1081686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0837967\n",
      "\tspeed: 0.0323s/iter; left time: 481.8397s\n",
      "\titers: 200, epoch: 34 | loss: 0.0864583\n",
      "\tspeed: 0.0160s/iter; left time: 237.5390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0810124 Vali Loss: 0.0791251 Test Loss: 0.1072538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0832718\n",
      "\tspeed: 0.0345s/iter; left time: 506.3651s\n",
      "\titers: 200, epoch: 35 | loss: 0.0830791\n",
      "\tspeed: 0.0161s/iter; left time: 234.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0808145 Vali Loss: 0.0791186 Test Loss: 0.1076243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0757619\n",
      "\tspeed: 0.0345s/iter; left time: 498.3570s\n",
      "\titers: 200, epoch: 36 | loss: 0.0762362\n",
      "\tspeed: 0.0203s/iter; left time: 290.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0810010 Vali Loss: 0.0790066 Test Loss: 0.1079348\n",
      "Validation loss decreased (0.079026 --> 0.079007).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0788083\n",
      "\tspeed: 0.0365s/iter; left time: 519.2067s\n",
      "\titers: 200, epoch: 37 | loss: 0.0795329\n",
      "\tspeed: 0.0170s/iter; left time: 240.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0809631 Vali Loss: 0.0789814 Test Loss: 0.1069180\n",
      "Validation loss decreased (0.079007 --> 0.078981).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0809431\n",
      "\tspeed: 0.0320s/iter; left time: 448.2272s\n",
      "\titers: 200, epoch: 38 | loss: 0.0811129\n",
      "\tspeed: 0.0150s/iter; left time: 208.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.0808095 Vali Loss: 0.0791114 Test Loss: 0.1077315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0796580\n",
      "\tspeed: 0.0329s/iter; left time: 453.3769s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785968\n",
      "\tspeed: 0.0153s/iter; left time: 209.0944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0806671 Vali Loss: 0.0789793 Test Loss: 0.1070785\n",
      "Validation loss decreased (0.078981 --> 0.078979).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0822391\n",
      "\tspeed: 0.0321s/iter; left time: 435.0489s\n",
      "\titers: 200, epoch: 40 | loss: 0.0774362\n",
      "\tspeed: 0.0162s/iter; left time: 217.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0807148 Vali Loss: 0.0789665 Test Loss: 0.1076642\n",
      "Validation loss decreased (0.078979 --> 0.078967).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0792845\n",
      "\tspeed: 0.0371s/iter; left time: 495.0997s\n",
      "\titers: 200, epoch: 41 | loss: 0.0770996\n",
      "\tspeed: 0.0214s/iter; left time: 283.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0808222 Vali Loss: 0.0790066 Test Loss: 0.1067579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0786893\n",
      "\tspeed: 0.0370s/iter; left time: 485.6974s\n",
      "\titers: 200, epoch: 42 | loss: 0.0815302\n",
      "\tspeed: 0.0183s/iter; left time: 238.6451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0809124 Vali Loss: 0.0789820 Test Loss: 0.1074727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0803642\n",
      "\tspeed: 0.0336s/iter; left time: 433.5457s\n",
      "\titers: 200, epoch: 43 | loss: 0.0818448\n",
      "\tspeed: 0.0174s/iter; left time: 223.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0807880 Vali Loss: 0.0790211 Test Loss: 0.1074443\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0829713\n",
      "\tspeed: 0.0345s/iter; left time: 437.5983s\n",
      "\titers: 200, epoch: 44 | loss: 0.0775464\n",
      "\tspeed: 0.0171s/iter; left time: 215.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0807208 Vali Loss: 0.0790137 Test Loss: 0.1075019\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0803836\n",
      "\tspeed: 0.0325s/iter; left time: 404.9819s\n",
      "\titers: 200, epoch: 45 | loss: 0.0817756\n",
      "\tspeed: 0.0156s/iter; left time: 192.1071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0809599 Vali Loss: 0.0788184 Test Loss: 0.1062304\n",
      "Validation loss decreased (0.078967 --> 0.078818).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788488\n",
      "\tspeed: 0.0343s/iter; left time: 418.8209s\n",
      "\titers: 200, epoch: 46 | loss: 0.0796075\n",
      "\tspeed: 0.0163s/iter; left time: 197.1767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0807397 Vali Loss: 0.0789614 Test Loss: 0.1072604\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0782363\n",
      "\tspeed: 0.0337s/iter; left time: 404.5281s\n",
      "\titers: 200, epoch: 47 | loss: 0.0816190\n",
      "\tspeed: 0.0184s/iter; left time: 219.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0806389 Vali Loss: 0.0791179 Test Loss: 0.1081125\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0823858\n",
      "\tspeed: 0.0393s/iter; left time: 463.1435s\n",
      "\titers: 200, epoch: 48 | loss: 0.0794778\n",
      "\tspeed: 0.0186s/iter; left time: 216.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0806543 Vali Loss: 0.0789456 Test Loss: 0.1075629\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0785191\n",
      "\tspeed: 0.0362s/iter; left time: 418.4799s\n",
      "\titers: 200, epoch: 49 | loss: 0.0791071\n",
      "\tspeed: 0.0177s/iter; left time: 203.1282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0806385 Vali Loss: 0.0789092 Test Loss: 0.1076234\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0773607\n",
      "\tspeed: 0.0314s/iter; left time: 355.9414s\n",
      "\titers: 200, epoch: 50 | loss: 0.0794940\n",
      "\tspeed: 0.0171s/iter; left time: 192.4972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0808311 Vali Loss: 0.0789006 Test Loss: 0.1068063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0820763\n",
      "\tspeed: 0.0342s/iter; left time: 380.0325s\n",
      "\titers: 200, epoch: 51 | loss: 0.0798580\n",
      "\tspeed: 0.0156s/iter; left time: 171.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0806921 Vali Loss: 0.0789968 Test Loss: 0.1068897\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0813597\n",
      "\tspeed: 0.0320s/iter; left time: 348.2259s\n",
      "\titers: 200, epoch: 52 | loss: 0.0792496\n",
      "\tspeed: 0.0175s/iter; left time: 188.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0805982 Vali Loss: 0.0788836 Test Loss: 0.1067426\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0833251\n",
      "\tspeed: 0.0321s/iter; left time: 341.6752s\n",
      "\titers: 200, epoch: 53 | loss: 0.0797060\n",
      "\tspeed: 0.0153s/iter; left time: 161.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0806178 Vali Loss: 0.0788674 Test Loss: 0.1072988\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0768501\n",
      "\tspeed: 0.0319s/iter; left time: 333.0937s\n",
      "\titers: 200, epoch: 54 | loss: 0.0811910\n",
      "\tspeed: 0.0154s/iter; left time: 159.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0806418 Vali Loss: 0.0789365 Test Loss: 0.1070738\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0768826\n",
      "\tspeed: 0.0382s/iter; left time: 389.8241s\n",
      "\titers: 200, epoch: 55 | loss: 0.0777496\n",
      "\tspeed: 0.0160s/iter; left time: 161.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0806218 Vali Loss: 0.0789265 Test Loss: 0.1077000\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02482021600008011, rmse:0.1575443297624588, mae:0.10623040050268173, rse:0.46281781792640686\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2949701\n",
      "\tspeed: 0.0221s/iter; left time: 492.1665s\n",
      "\titers: 200, epoch: 1 | loss: 0.2738535\n",
      "\tspeed: 0.0189s/iter; left time: 419.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.2943460 Vali Loss: 0.2228722 Test Loss: 0.2429076\n",
      "Validation loss decreased (inf --> 0.222872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1516856\n",
      "\tspeed: 0.0363s/iter; left time: 802.4746s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205032\n",
      "\tspeed: 0.0168s/iter; left time: 369.3660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1615071 Vali Loss: 0.1064732 Test Loss: 0.1207890\n",
      "Validation loss decreased (0.222872 --> 0.106473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1121301\n",
      "\tspeed: 0.0290s/iter; left time: 633.9783s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061030\n",
      "\tspeed: 0.0183s/iter; left time: 398.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.1100943 Vali Loss: 0.0948281 Test Loss: 0.1183062\n",
      "Validation loss decreased (0.106473 --> 0.094828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0978006\n",
      "\tspeed: 0.0371s/iter; left time: 803.0530s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954229\n",
      "\tspeed: 0.0154s/iter; left time: 331.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0970733 Vali Loss: 0.0896294 Test Loss: 0.1343081\n",
      "Validation loss decreased (0.094828 --> 0.089629).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0915815\n",
      "\tspeed: 0.0367s/iter; left time: 785.9501s\n",
      "\titers: 200, epoch: 5 | loss: 0.0912736\n",
      "\tspeed: 0.0176s/iter; left time: 374.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0920308 Vali Loss: 0.0861538 Test Loss: 0.1335911\n",
      "Validation loss decreased (0.089629 --> 0.086154).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856224\n",
      "\tspeed: 0.0353s/iter; left time: 748.2893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884811\n",
      "\tspeed: 0.0162s/iter; left time: 341.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0892304 Vali Loss: 0.0844599 Test Loss: 0.1357906\n",
      "Validation loss decreased (0.086154 --> 0.084460).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0945793\n",
      "\tspeed: 0.0385s/iter; left time: 806.1681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0873152\n",
      "\tspeed: 0.0172s/iter; left time: 359.7292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0882241 Vali Loss: 0.0833441 Test Loss: 0.1325197\n",
      "Validation loss decreased (0.084460 --> 0.083344).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843527\n",
      "\tspeed: 0.0368s/iter; left time: 763.1518s\n",
      "\titers: 200, epoch: 8 | loss: 0.0852545\n",
      "\tspeed: 0.0178s/iter; left time: 367.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0867391 Vali Loss: 0.0826206 Test Loss: 0.1371923\n",
      "Validation loss decreased (0.083344 --> 0.082621).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867780\n",
      "\tspeed: 0.0368s/iter; left time: 754.3170s\n",
      "\titers: 200, epoch: 9 | loss: 0.0851954\n",
      "\tspeed: 0.0181s/iter; left time: 369.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0855968 Vali Loss: 0.0819841 Test Loss: 0.1273202\n",
      "Validation loss decreased (0.082621 --> 0.081984).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0851445\n",
      "\tspeed: 0.0338s/iter; left time: 685.8547s\n",
      "\titers: 200, epoch: 10 | loss: 0.0842952\n",
      "\tspeed: 0.0195s/iter; left time: 394.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0847394 Vali Loss: 0.0815754 Test Loss: 0.1295356\n",
      "Validation loss decreased (0.081984 --> 0.081575).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0827668\n",
      "\tspeed: 0.0348s/iter; left time: 698.9927s\n",
      "\titers: 200, epoch: 11 | loss: 0.0849487\n",
      "\tspeed: 0.0155s/iter; left time: 309.1008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0847392 Vali Loss: 0.0812731 Test Loss: 0.1272998\n",
      "Validation loss decreased (0.081575 --> 0.081273).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0852151\n",
      "\tspeed: 0.0343s/iter; left time: 679.8637s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807062\n",
      "\tspeed: 0.0163s/iter; left time: 321.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0852808 Vali Loss: 0.0811117 Test Loss: 0.1152925\n",
      "Validation loss decreased (0.081273 --> 0.081112).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842783\n",
      "\tspeed: 0.0395s/iter; left time: 775.4427s\n",
      "\titers: 200, epoch: 13 | loss: 0.0827053\n",
      "\tspeed: 0.0174s/iter; left time: 340.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0835776 Vali Loss: 0.0807043 Test Loss: 0.1232046\n",
      "Validation loss decreased (0.081112 --> 0.080704).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841696\n",
      "\tspeed: 0.0366s/iter; left time: 710.0382s\n",
      "\titers: 200, epoch: 14 | loss: 0.0816784\n",
      "\tspeed: 0.0176s/iter; left time: 338.5969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0830525 Vali Loss: 0.0803488 Test Loss: 0.1258540\n",
      "Validation loss decreased (0.080704 --> 0.080349).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843562\n",
      "\tspeed: 0.0367s/iter; left time: 703.8377s\n",
      "\titers: 200, epoch: 15 | loss: 0.0866401\n",
      "\tspeed: 0.0146s/iter; left time: 277.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0826786 Vali Loss: 0.0800034 Test Loss: 0.1245869\n",
      "Validation loss decreased (0.080349 --> 0.080003).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0874645\n",
      "\tspeed: 0.0322s/iter; left time: 609.8836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0806157\n",
      "\tspeed: 0.0154s/iter; left time: 289.5191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0825226 Vali Loss: 0.0799668 Test Loss: 0.1231041\n",
      "Validation loss decreased (0.080003 --> 0.079967).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0779536\n",
      "\tspeed: 0.0328s/iter; left time: 614.7096s\n",
      "\titers: 200, epoch: 17 | loss: 0.0826323\n",
      "\tspeed: 0.0153s/iter; left time: 284.6748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0822895 Vali Loss: 0.0798155 Test Loss: 0.1189573\n",
      "Validation loss decreased (0.079967 --> 0.079816).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0801349\n",
      "\tspeed: 0.0347s/iter; left time: 641.4722s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788892\n",
      "\tspeed: 0.0162s/iter; left time: 298.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0819632 Vali Loss: 0.0795002 Test Loss: 0.1211235\n",
      "Validation loss decreased (0.079816 --> 0.079500).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0831867\n",
      "\tspeed: 0.0344s/iter; left time: 627.6123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855634\n",
      "\tspeed: 0.0155s/iter; left time: 281.1025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0819039 Vali Loss: 0.0795896 Test Loss: 0.1136663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806163\n",
      "\tspeed: 0.0317s/iter; left time: 571.1332s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826579\n",
      "\tspeed: 0.0185s/iter; left time: 331.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0815371 Vali Loss: 0.0793281 Test Loss: 0.1178989\n",
      "Validation loss decreased (0.079500 --> 0.079328).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801518\n",
      "\tspeed: 0.0374s/iter; left time: 666.9736s\n",
      "\titers: 200, epoch: 21 | loss: 0.0802585\n",
      "\tspeed: 0.0166s/iter; left time: 294.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0816553 Vali Loss: 0.0794146 Test Loss: 0.1150296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0819045\n",
      "\tspeed: 0.0362s/iter; left time: 637.0702s\n",
      "\titers: 200, epoch: 22 | loss: 0.0835017\n",
      "\tspeed: 0.0180s/iter; left time: 314.1193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0813633 Vali Loss: 0.0791247 Test Loss: 0.1185968\n",
      "Validation loss decreased (0.079328 --> 0.079125).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0771334\n",
      "\tspeed: 0.0446s/iter; left time: 774.9926s\n",
      "\titers: 200, epoch: 23 | loss: 0.0831374\n",
      "\tspeed: 0.0240s/iter; left time: 414.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0811816 Vali Loss: 0.0792441 Test Loss: 0.1194242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0799311\n",
      "\tspeed: 0.0432s/iter; left time: 740.2008s\n",
      "\titers: 200, epoch: 24 | loss: 0.0833221\n",
      "\tspeed: 0.0201s/iter; left time: 342.0320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0814226 Vali Loss: 0.0791263 Test Loss: 0.1155721\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0803420\n",
      "\tspeed: 0.0415s/iter; left time: 702.6602s\n",
      "\titers: 200, epoch: 25 | loss: 0.0859437\n",
      "\tspeed: 0.0247s/iter; left time: 415.3874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0810550 Vali Loss: 0.0790411 Test Loss: 0.1178999\n",
      "Validation loss decreased (0.079125 --> 0.079041).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0814237\n",
      "\tspeed: 0.0384s/iter; left time: 641.5525s\n",
      "\titers: 200, epoch: 26 | loss: 0.0782807\n",
      "\tspeed: 0.0185s/iter; left time: 307.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0810974 Vali Loss: 0.0790298 Test Loss: 0.1171177\n",
      "Validation loss decreased (0.079041 --> 0.079030).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0820360\n",
      "\tspeed: 0.0387s/iter; left time: 637.4439s\n",
      "\titers: 200, epoch: 27 | loss: 0.0814562\n",
      "\tspeed: 0.0190s/iter; left time: 311.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0809683 Vali Loss: 0.0789331 Test Loss: 0.1153629\n",
      "Validation loss decreased (0.079030 --> 0.078933).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0824465\n",
      "\tspeed: 0.0341s/iter; left time: 554.3129s\n",
      "\titers: 200, epoch: 28 | loss: 0.0807360\n",
      "\tspeed: 0.0166s/iter; left time: 268.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0806947 Vali Loss: 0.0789500 Test Loss: 0.1206281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796398\n",
      "\tspeed: 0.0343s/iter; left time: 549.3921s\n",
      "\titers: 200, epoch: 29 | loss: 0.0812451\n",
      "\tspeed: 0.0182s/iter; left time: 290.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0807283 Vali Loss: 0.0788620 Test Loss: 0.1161380\n",
      "Validation loss decreased (0.078933 --> 0.078862).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792317\n",
      "\tspeed: 0.0394s/iter; left time: 623.3394s\n",
      "\titers: 200, epoch: 30 | loss: 0.0796323\n",
      "\tspeed: 0.0238s/iter; left time: 374.1989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0805884 Vali Loss: 0.0787869 Test Loss: 0.1190568\n",
      "Validation loss decreased (0.078862 --> 0.078787).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0825548\n",
      "\tspeed: 0.0375s/iter; left time: 584.7828s\n",
      "\titers: 200, epoch: 31 | loss: 0.0785023\n",
      "\tspeed: 0.0169s/iter; left time: 262.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0808213 Vali Loss: 0.0789125 Test Loss: 0.1160532\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0826512\n",
      "\tspeed: 0.0385s/iter; left time: 591.6402s\n",
      "\titers: 200, epoch: 32 | loss: 0.0771616\n",
      "\tspeed: 0.0230s/iter; left time: 351.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0804920 Vali Loss: 0.0787618 Test Loss: 0.1174321\n",
      "Validation loss decreased (0.078787 --> 0.078762).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0789443\n",
      "\tspeed: 0.0358s/iter; left time: 541.5031s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803010\n",
      "\tspeed: 0.0152s/iter; left time: 228.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0806825 Vali Loss: 0.0787459 Test Loss: 0.1134941\n",
      "Validation loss decreased (0.078762 --> 0.078746).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0789445\n",
      "\tspeed: 0.0375s/iter; left time: 558.3834s\n",
      "\titers: 200, epoch: 34 | loss: 0.0812439\n",
      "\tspeed: 0.0225s/iter; left time: 332.8409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0804169 Vali Loss: 0.0789054 Test Loss: 0.1152394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0839198\n",
      "\tspeed: 0.0354s/iter; left time: 520.2865s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819243\n",
      "\tspeed: 0.0210s/iter; left time: 305.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0804650 Vali Loss: 0.0786934 Test Loss: 0.1144127\n",
      "Validation loss decreased (0.078746 --> 0.078693).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0802629\n",
      "\tspeed: 0.0419s/iter; left time: 605.9462s\n",
      "\titers: 200, epoch: 36 | loss: 0.0781854\n",
      "\tspeed: 0.0241s/iter; left time: 346.4100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0804494 Vali Loss: 0.0787799 Test Loss: 0.1149971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0785369\n",
      "\tspeed: 0.0356s/iter; left time: 507.1152s\n",
      "\titers: 200, epoch: 37 | loss: 0.0791697\n",
      "\tspeed: 0.0160s/iter; left time: 226.0676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0803865 Vali Loss: 0.0788539 Test Loss: 0.1158440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0820786\n",
      "\tspeed: 0.0341s/iter; left time: 478.0614s\n",
      "\titers: 200, epoch: 38 | loss: 0.0810464\n",
      "\tspeed: 0.0169s/iter; left time: 235.0733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0803231 Vali Loss: 0.0787525 Test Loss: 0.1153972\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0808926\n",
      "\tspeed: 0.0403s/iter; left time: 555.3663s\n",
      "\titers: 200, epoch: 39 | loss: 0.0804156\n",
      "\tspeed: 0.0221s/iter; left time: 302.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0803351 Vali Loss: 0.0788614 Test Loss: 0.1145321\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0813855\n",
      "\tspeed: 0.0429s/iter; left time: 582.1825s\n",
      "\titers: 200, epoch: 40 | loss: 0.0745288\n",
      "\tspeed: 0.0229s/iter; left time: 308.2431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0805143 Vali Loss: 0.0787251 Test Loss: 0.1136237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0766422\n",
      "\tspeed: 0.0378s/iter; left time: 504.2164s\n",
      "\titers: 200, epoch: 41 | loss: 0.0802586\n",
      "\tspeed: 0.0232s/iter; left time: 306.5769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0803362 Vali Loss: 0.0786872 Test Loss: 0.1146974\n",
      "Validation loss decreased (0.078693 --> 0.078687).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0831676\n",
      "\tspeed: 0.0421s/iter; left time: 552.2052s\n",
      "\titers: 200, epoch: 42 | loss: 0.0803144\n",
      "\tspeed: 0.0227s/iter; left time: 295.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0803085 Vali Loss: 0.0786738 Test Loss: 0.1136685\n",
      "Validation loss decreased (0.078687 --> 0.078674).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0776655\n",
      "\tspeed: 0.0415s/iter; left time: 534.7427s\n",
      "\titers: 200, epoch: 43 | loss: 0.0748830\n",
      "\tspeed: 0.0223s/iter; left time: 285.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0802602 Vali Loss: 0.0787125 Test Loss: 0.1163979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0814612\n",
      "\tspeed: 0.0411s/iter; left time: 520.4955s\n",
      "\titers: 200, epoch: 44 | loss: 0.0819359\n",
      "\tspeed: 0.0176s/iter; left time: 220.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0802522 Vali Loss: 0.0787630 Test Loss: 0.1159265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0778814\n",
      "\tspeed: 0.0338s/iter; left time: 420.1210s\n",
      "\titers: 200, epoch: 45 | loss: 0.0820323\n",
      "\tspeed: 0.0157s/iter; left time: 193.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0802462 Vali Loss: 0.0787794 Test Loss: 0.1148303\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788297\n",
      "\tspeed: 0.0334s/iter; left time: 407.8174s\n",
      "\titers: 200, epoch: 46 | loss: 0.0800137\n",
      "\tspeed: 0.0164s/iter; left time: 198.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0802375 Vali Loss: 0.0787176 Test Loss: 0.1158337\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0804135\n",
      "\tspeed: 0.0386s/iter; left time: 463.5838s\n",
      "\titers: 200, epoch: 47 | loss: 0.0826335\n",
      "\tspeed: 0.0205s/iter; left time: 243.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0802282 Vali Loss: 0.0786863 Test Loss: 0.1181947\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0770466\n",
      "\tspeed: 0.0384s/iter; left time: 452.4127s\n",
      "\titers: 200, epoch: 48 | loss: 0.0773087\n",
      "\tspeed: 0.0221s/iter; left time: 257.6790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0802870 Vali Loss: 0.0786488 Test Loss: 0.1158384\n",
      "Validation loss decreased (0.078674 --> 0.078649).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0772750\n",
      "\tspeed: 0.0429s/iter; left time: 495.2433s\n",
      "\titers: 200, epoch: 49 | loss: 0.0812847\n",
      "\tspeed: 0.0205s/iter; left time: 234.3825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0804005 Vali Loss: 0.0786252 Test Loss: 0.1148006\n",
      "Validation loss decreased (0.078649 --> 0.078625).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0819748\n",
      "\tspeed: 0.0395s/iter; left time: 447.4202s\n",
      "\titers: 200, epoch: 50 | loss: 0.0831465\n",
      "\tspeed: 0.0206s/iter; left time: 231.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0805817 Vali Loss: 0.0787522 Test Loss: 0.1136936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0818774\n",
      "\tspeed: 0.0340s/iter; left time: 376.9238s\n",
      "\titers: 200, epoch: 51 | loss: 0.0814776\n",
      "\tspeed: 0.0190s/iter; left time: 208.9127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0803361 Vali Loss: 0.0787344 Test Loss: 0.1140809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0815157\n",
      "\tspeed: 0.0348s/iter; left time: 378.0292s\n",
      "\titers: 200, epoch: 52 | loss: 0.0760650\n",
      "\tspeed: 0.0160s/iter; left time: 172.6217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0802124 Vali Loss: 0.0787321 Test Loss: 0.1143213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800943\n",
      "\tspeed: 0.0342s/iter; left time: 364.4124s\n",
      "\titers: 200, epoch: 53 | loss: 0.0805059\n",
      "\tspeed: 0.0178s/iter; left time: 187.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0801604 Vali Loss: 0.0787110 Test Loss: 0.1153583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0835793\n",
      "\tspeed: 0.0368s/iter; left time: 384.2308s\n",
      "\titers: 200, epoch: 54 | loss: 0.0840597\n",
      "\tspeed: 0.0190s/iter; left time: 196.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0801659 Vali Loss: 0.0787169 Test Loss: 0.1157073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0787593\n",
      "\tspeed: 0.0371s/iter; left time: 378.1037s\n",
      "\titers: 200, epoch: 55 | loss: 0.0782121\n",
      "\tspeed: 0.0216s/iter; left time: 217.8763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0801970 Vali Loss: 0.0786564 Test Loss: 0.1157790\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0776901\n",
      "\tspeed: 0.0364s/iter; left time: 363.1273s\n",
      "\titers: 200, epoch: 56 | loss: 0.0820478\n",
      "\tspeed: 0.0189s/iter; left time: 186.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0802963 Vali Loss: 0.0787426 Test Loss: 0.1163280\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0794644\n",
      "\tspeed: 0.0403s/iter; left time: 393.2071s\n",
      "\titers: 200, epoch: 57 | loss: 0.0812776\n",
      "\tspeed: 0.0170s/iter; left time: 163.8239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0801635 Vali Loss: 0.0787768 Test Loss: 0.1162051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0781011\n",
      "\tspeed: 0.0392s/iter; left time: 373.6169s\n",
      "\titers: 200, epoch: 58 | loss: 0.0803022\n",
      "\tspeed: 0.0166s/iter; left time: 156.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0801390 Vali Loss: 0.0786844 Test Loss: 0.1173877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0816328\n",
      "\tspeed: 0.0372s/iter; left time: 346.1356s\n",
      "\titers: 200, epoch: 59 | loss: 0.0806974\n",
      "\tspeed: 0.0196s/iter; left time: 180.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0803725 Vali Loss: 0.0786231 Test Loss: 0.1158899\n",
      "Validation loss decreased (0.078625 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0798175\n",
      "\tspeed: 0.0390s/iter; left time: 354.1598s\n",
      "\titers: 200, epoch: 60 | loss: 0.0841747\n",
      "\tspeed: 0.0128s/iter; left time: 114.7824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0801562 Vali Loss: 0.0787353 Test Loss: 0.1151237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0808385\n",
      "\tspeed: 0.0465s/iter; left time: 411.6649s\n",
      "\titers: 200, epoch: 61 | loss: 0.0819121\n",
      "\tspeed: 0.0280s/iter; left time: 245.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0801061 Vali Loss: 0.0786935 Test Loss: 0.1148166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0789861\n",
      "\tspeed: 0.0396s/iter; left time: 341.9938s\n",
      "\titers: 200, epoch: 62 | loss: 0.0809398\n",
      "\tspeed: 0.0243s/iter; left time: 207.7632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0801172 Vali Loss: 0.0786713 Test Loss: 0.1164873\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0836691\n",
      "\tspeed: 0.0344s/iter; left time: 289.4447s\n",
      "\titers: 200, epoch: 63 | loss: 0.0823292\n",
      "\tspeed: 0.0199s/iter; left time: 165.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0802999 Vali Loss: 0.0786390 Test Loss: 0.1152086\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0749281\n",
      "\tspeed: 0.0359s/iter; left time: 293.8880s\n",
      "\titers: 200, epoch: 64 | loss: 0.0802662\n",
      "\tspeed: 0.0163s/iter; left time: 132.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0802207 Vali Loss: 0.0787605 Test Loss: 0.1149963\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0825867\n",
      "\tspeed: 0.0328s/iter; left time: 261.4048s\n",
      "\titers: 200, epoch: 65 | loss: 0.0778804\n",
      "\tspeed: 0.0158s/iter; left time: 124.1858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0801056 Vali Loss: 0.0786383 Test Loss: 0.1165857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0803034\n",
      "\tspeed: 0.0353s/iter; left time: 273.4710s\n",
      "\titers: 200, epoch: 66 | loss: 0.0810269\n",
      "\tspeed: 0.0193s/iter; left time: 147.4007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0801883 Vali Loss: 0.0787476 Test Loss: 0.1161576\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0825353\n",
      "\tspeed: 0.0364s/iter; left time: 273.8227s\n",
      "\titers: 200, epoch: 67 | loss: 0.0824786\n",
      "\tspeed: 0.0184s/iter; left time: 136.3544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0801582 Vali Loss: 0.0787648 Test Loss: 0.1165231\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0824737\n",
      "\tspeed: 0.0360s/iter; left time: 262.8904s\n",
      "\titers: 200, epoch: 68 | loss: 0.0820768\n",
      "\tspeed: 0.0183s/iter; left time: 131.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0800938 Vali Loss: 0.0786233 Test Loss: 0.1150988\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0814223\n",
      "\tspeed: 0.0380s/iter; left time: 268.2982s\n",
      "\titers: 200, epoch: 69 | loss: 0.0758541\n",
      "\tspeed: 0.0190s/iter; left time: 132.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0803286 Vali Loss: 0.0786767 Test Loss: 0.1181150\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.034349095076322556, rmse:0.18533508479595184, mae:0.11588998138904572, rse:0.5444587469100952\n",
      "Intermediate time for ES and pred_len 96: 00h:11m:24.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0424s/iter; left time: 940.3986s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0198s/iter; left time: 438.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0374s/iter; left time: 821.0501s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0221s/iter; left time: 482.8757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0392s/iter; left time: 852.8231s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0168s/iter; left time: 363.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0362s/iter; left time: 779.1757s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0176s/iter; left time: 376.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0347s/iter; left time: 740.0442s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0170s/iter; left time: 360.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0338s/iter; left time: 711.7744s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0162s/iter; left time: 340.8485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0349s/iter; left time: 728.1388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0161s/iter; left time: 334.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0339s/iter; left time: 700.5492s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0155s/iter; left time: 319.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0340s/iter; left time: 694.9564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0231s/iter; left time: 469.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0376s/iter; left time: 759.1073s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0212s/iter; left time: 426.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0394s/iter; left time: 787.2343s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0189s/iter; left time: 376.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0358s/iter; left time: 706.5694s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0192s/iter; left time: 378.1769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0354s/iter; left time: 691.8343s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0169s/iter; left time: 328.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0348s/iter; left time: 672.0839s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0164s/iter; left time: 314.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0338s/iter; left time: 645.4372s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0164s/iter; left time: 310.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0338s/iter; left time: 636.4715s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0208s/iter; left time: 389.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0364s/iter; left time: 677.9004s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0205s/iter; left time: 380.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0342s/iter; left time: 630.4367s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0193s/iter; left time: 353.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0345s/iter; left time: 627.5432s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0206s/iter; left time: 372.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0393s/iter; left time: 705.4656s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0200s/iter; left time: 357.5027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0877162\n",
      "\tspeed: 0.0362s/iter; left time: 641.6220s\n",
      "\titers: 200, epoch: 21 | loss: 0.0856693\n",
      "\tspeed: 0.0173s/iter; left time: 305.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0858356 Vali Loss: 0.0850625 Test Loss: 0.1181478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0853307\n",
      "\tspeed: 0.0386s/iter; left time: 675.7370s\n",
      "\titers: 200, epoch: 22 | loss: 0.0857101\n",
      "\tspeed: 0.0234s/iter; left time: 407.3873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0858141 Vali Loss: 0.0848711 Test Loss: 0.1179698\n",
      "Validation loss decreased (0.085052 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0836513\n",
      "\tspeed: 0.0414s/iter; left time: 716.6766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0845700\n",
      "\tspeed: 0.0191s/iter; left time: 328.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0857552 Vali Loss: 0.0851099 Test Loss: 0.1169337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0853104\n",
      "\tspeed: 0.0349s/iter; left time: 595.2794s\n",
      "\titers: 200, epoch: 24 | loss: 0.0847234\n",
      "\tspeed: 0.0101s/iter; left time: 171.3788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 223 | Train Loss: 0.0854539 Vali Loss: 0.0847695 Test Loss: 0.1189011\n",
      "Validation loss decreased (0.084871 --> 0.084769).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0877929\n",
      "\tspeed: 0.0381s/iter; left time: 642.7568s\n",
      "\titers: 200, epoch: 25 | loss: 0.0859289\n",
      "\tspeed: 0.0188s/iter; left time: 315.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0854330 Vali Loss: 0.0852000 Test Loss: 0.1200379\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0872629\n",
      "\tspeed: 0.0362s/iter; left time: 601.9487s\n",
      "\titers: 200, epoch: 26 | loss: 0.0873879\n",
      "\tspeed: 0.0197s/iter; left time: 325.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0853350 Vali Loss: 0.0850407 Test Loss: 0.1206776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0884665\n",
      "\tspeed: 0.0376s/iter; left time: 616.8865s\n",
      "\titers: 200, epoch: 27 | loss: 0.0884702\n",
      "\tspeed: 0.0197s/iter; left time: 321.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0851529 Vali Loss: 0.0848730 Test Loss: 0.1198020\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0833811\n",
      "\tspeed: 0.0378s/iter; left time: 611.7573s\n",
      "\titers: 200, epoch: 28 | loss: 0.0875286\n",
      "\tspeed: 0.0178s/iter; left time: 286.1688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0851438 Vali Loss: 0.0848251 Test Loss: 0.1189873\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0854217\n",
      "\tspeed: 0.0288s/iter; left time: 459.1144s\n",
      "\titers: 200, epoch: 29 | loss: 0.0837402\n",
      "\tspeed: 0.0100s/iter; left time: 158.6811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.61s\n",
      "Steps: 223 | Train Loss: 0.0849345 Vali Loss: 0.0846815 Test Loss: 0.1183914\n",
      "Validation loss decreased (0.084769 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0870486\n",
      "\tspeed: 0.0370s/iter; left time: 582.7092s\n",
      "\titers: 200, epoch: 30 | loss: 0.0877254\n",
      "\tspeed: 0.0188s/iter; left time: 293.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0850217 Vali Loss: 0.0848136 Test Loss: 0.1178944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0841421\n",
      "\tspeed: 0.0338s/iter; left time: 523.6296s\n",
      "\titers: 200, epoch: 31 | loss: 0.0857176\n",
      "\tspeed: 0.0213s/iter; left time: 329.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0854421 Vali Loss: 0.0847439 Test Loss: 0.1170233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0852246\n",
      "\tspeed: 0.0400s/iter; left time: 611.7454s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857008\n",
      "\tspeed: 0.0207s/iter; left time: 313.7401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0848933 Vali Loss: 0.0847940 Test Loss: 0.1198182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0841194\n",
      "\tspeed: 0.0356s/iter; left time: 536.9753s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834450\n",
      "\tspeed: 0.0162s/iter; left time: 241.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0851093 Vali Loss: 0.0847722 Test Loss: 0.1174044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0847829\n",
      "\tspeed: 0.0347s/iter; left time: 514.3088s\n",
      "\titers: 200, epoch: 34 | loss: 0.0847453\n",
      "\tspeed: 0.0146s/iter; left time: 214.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0849649 Vali Loss: 0.0849032 Test Loss: 0.1175446\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0862751\n",
      "\tspeed: 0.0388s/iter; left time: 566.8168s\n",
      "\titers: 200, epoch: 35 | loss: 0.0876660\n",
      "\tspeed: 0.0225s/iter; left time: 326.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0849581 Vali Loss: 0.0847439 Test Loss: 0.1175975\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0852168\n",
      "\tspeed: 0.0385s/iter; left time: 554.3908s\n",
      "\titers: 200, epoch: 36 | loss: 0.0829864\n",
      "\tspeed: 0.0193s/iter; left time: 275.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0847706 Vali Loss: 0.0847675 Test Loss: 0.1177053\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0865465\n",
      "\tspeed: 0.0399s/iter; left time: 565.8620s\n",
      "\titers: 200, epoch: 37 | loss: 0.0843475\n",
      "\tspeed: 0.0202s/iter; left time: 284.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0850028 Vali Loss: 0.0848001 Test Loss: 0.1175573\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0879359\n",
      "\tspeed: 0.0375s/iter; left time: 523.7907s\n",
      "\titers: 200, epoch: 38 | loss: 0.0862375\n",
      "\tspeed: 0.0204s/iter; left time: 282.9502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0847905 Vali Loss: 0.0845725 Test Loss: 0.1166489\n",
      "Validation loss decreased (0.084681 --> 0.084572).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0824188\n",
      "\tspeed: 0.0352s/iter; left time: 482.7311s\n",
      "\titers: 200, epoch: 39 | loss: 0.0815600\n",
      "\tspeed: 0.0183s/iter; left time: 249.8268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0847708 Vali Loss: 0.0846998 Test Loss: 0.1175155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0860271\n",
      "\tspeed: 0.0363s/iter; left time: 489.8877s\n",
      "\titers: 200, epoch: 40 | loss: 0.0826182\n",
      "\tspeed: 0.0176s/iter; left time: 235.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0848839 Vali Loss: 0.0847723 Test Loss: 0.1176447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0843057\n",
      "\tspeed: 0.0330s/iter; left time: 438.4846s\n",
      "\titers: 200, epoch: 41 | loss: 0.0847831\n",
      "\tspeed: 0.0146s/iter; left time: 192.0051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0846794 Vali Loss: 0.0846801 Test Loss: 0.1177645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0818505\n",
      "\tspeed: 0.0353s/iter; left time: 460.9029s\n",
      "\titers: 200, epoch: 42 | loss: 0.0846436\n",
      "\tspeed: 0.0183s/iter; left time: 237.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0848426 Vali Loss: 0.0846002 Test Loss: 0.1167957\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0865419\n",
      "\tspeed: 0.0368s/iter; left time: 472.0430s\n",
      "\titers: 200, epoch: 43 | loss: 0.0864775\n",
      "\tspeed: 0.0166s/iter; left time: 210.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0848241 Vali Loss: 0.0847245 Test Loss: 0.1173143\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0819034\n",
      "\tspeed: 0.0337s/iter; left time: 424.8803s\n",
      "\titers: 200, epoch: 44 | loss: 0.0881165\n",
      "\tspeed: 0.0228s/iter; left time: 285.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0847846 Vali Loss: 0.0846492 Test Loss: 0.1165506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0834732\n",
      "\tspeed: 0.0380s/iter; left time: 471.2957s\n",
      "\titers: 200, epoch: 45 | loss: 0.0909516\n",
      "\tspeed: 0.0197s/iter; left time: 241.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0847154 Vali Loss: 0.0847688 Test Loss: 0.1180594\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0832654\n",
      "\tspeed: 0.0365s/iter; left time: 444.5055s\n",
      "\titers: 200, epoch: 46 | loss: 0.0856518\n",
      "\tspeed: 0.0184s/iter; left time: 222.4654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0847128 Vali Loss: 0.0847007 Test Loss: 0.1177146\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0841189\n",
      "\tspeed: 0.0350s/iter; left time: 417.8906s\n",
      "\titers: 200, epoch: 47 | loss: 0.0849763\n",
      "\tspeed: 0.0157s/iter; left time: 186.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0849872 Vali Loss: 0.0846938 Test Loss: 0.1181525\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0812110\n",
      "\tspeed: 0.0393s/iter; left time: 460.9405s\n",
      "\titers: 200, epoch: 48 | loss: 0.0827201\n",
      "\tspeed: 0.0162s/iter; left time: 188.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0852178 Vali Loss: 0.0847629 Test Loss: 0.1171869\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030208632349967957, rmse:0.1738063097000122, mae:0.11664891242980957, rse:0.510627269744873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936766\n",
      "\tspeed: 0.0225s/iter; left time: 500.1014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2709541\n",
      "\tspeed: 0.0156s/iter; left time: 344.3582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.2959534 Vali Loss: 0.2266825 Test Loss: 0.2452377\n",
      "Validation loss decreased (inf --> 0.226683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1484248\n",
      "\tspeed: 0.0396s/iter; left time: 869.3059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1285656\n",
      "\tspeed: 0.0192s/iter; left time: 419.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1607786 Vali Loss: 0.1127445 Test Loss: 0.1281586\n",
      "Validation loss decreased (0.226683 --> 0.112745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1119089\n",
      "\tspeed: 0.0364s/iter; left time: 791.0669s\n",
      "\titers: 200, epoch: 3 | loss: 0.1075492\n",
      "\tspeed: 0.0237s/iter; left time: 512.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.1122907 Vali Loss: 0.0982934 Test Loss: 0.1443596\n",
      "Validation loss decreased (0.112745 --> 0.098293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1015103\n",
      "\tspeed: 0.0376s/iter; left time: 808.9373s\n",
      "\titers: 200, epoch: 4 | loss: 0.0995555\n",
      "\tspeed: 0.0211s/iter; left time: 451.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.1016863 Vali Loss: 0.0950136 Test Loss: 0.1475585\n",
      "Validation loss decreased (0.098293 --> 0.095014).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1016375\n",
      "\tspeed: 0.0440s/iter; left time: 937.4574s\n",
      "\titers: 200, epoch: 5 | loss: 0.0967942\n",
      "\tspeed: 0.0230s/iter; left time: 488.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0967306 Vali Loss: 0.0911453 Test Loss: 0.1389572\n",
      "Validation loss decreased (0.095014 --> 0.091145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932338\n",
      "\tspeed: 0.0418s/iter; left time: 881.4590s\n",
      "\titers: 200, epoch: 6 | loss: 0.0947476\n",
      "\tspeed: 0.0200s/iter; left time: 420.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0941155 Vali Loss: 0.0897755 Test Loss: 0.1342266\n",
      "Validation loss decreased (0.091145 --> 0.089775).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0948261\n",
      "\tspeed: 0.0370s/iter; left time: 772.5180s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915033\n",
      "\tspeed: 0.0205s/iter; left time: 424.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0928360 Vali Loss: 0.0888792 Test Loss: 0.1301373\n",
      "Validation loss decreased (0.089775 --> 0.088879).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927390\n",
      "\tspeed: 0.0374s/iter; left time: 772.7773s\n",
      "\titers: 200, epoch: 8 | loss: 0.0897678\n",
      "\tspeed: 0.0177s/iter; left time: 363.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0908630 Vali Loss: 0.0870882 Test Loss: 0.1283409\n",
      "Validation loss decreased (0.088879 --> 0.087088).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0898859\n",
      "\tspeed: 0.0422s/iter; left time: 862.2709s\n",
      "\titers: 200, epoch: 9 | loss: 0.0944866\n",
      "\tspeed: 0.0189s/iter; left time: 383.1053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0899931 Vali Loss: 0.0873392 Test Loss: 0.1296829\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0860589\n",
      "\tspeed: 0.0349s/iter; left time: 704.9541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0880826\n",
      "\tspeed: 0.0172s/iter; left time: 345.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0890320 Vali Loss: 0.0880023 Test Loss: 0.1252401\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891895\n",
      "\tspeed: 0.0323s/iter; left time: 645.9626s\n",
      "\titers: 200, epoch: 11 | loss: 0.0849690\n",
      "\tspeed: 0.0190s/iter; left time: 377.8497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0884293 Vali Loss: 0.0866960 Test Loss: 0.1264054\n",
      "Validation loss decreased (0.087088 --> 0.086696).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0861983\n",
      "\tspeed: 0.0383s/iter; left time: 755.7630s\n",
      "\titers: 200, epoch: 12 | loss: 0.0884704\n",
      "\tspeed: 0.0182s/iter; left time: 357.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0879964 Vali Loss: 0.0858562 Test Loss: 0.1244201\n",
      "Validation loss decreased (0.086696 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872771\n",
      "\tspeed: 0.0359s/iter; left time: 700.5999s\n",
      "\titers: 200, epoch: 13 | loss: 0.0859470\n",
      "\tspeed: 0.0170s/iter; left time: 330.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0874375 Vali Loss: 0.0861715 Test Loss: 0.1191061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0909802\n",
      "\tspeed: 0.0373s/iter; left time: 719.1675s\n",
      "\titers: 200, epoch: 14 | loss: 0.0893463\n",
      "\tspeed: 0.0192s/iter; left time: 369.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0872263 Vali Loss: 0.0857841 Test Loss: 0.1219740\n",
      "Validation loss decreased (0.085856 --> 0.085784).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0821355\n",
      "\tspeed: 0.0397s/iter; left time: 757.7715s\n",
      "\titers: 200, epoch: 15 | loss: 0.0835384\n",
      "\tspeed: 0.0159s/iter; left time: 302.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0867242 Vali Loss: 0.0856983 Test Loss: 0.1216373\n",
      "Validation loss decreased (0.085784 --> 0.085698).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0841138\n",
      "\tspeed: 0.0354s/iter; left time: 666.9882s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816607\n",
      "\tspeed: 0.0155s/iter; left time: 290.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0865612 Vali Loss: 0.0855602 Test Loss: 0.1210224\n",
      "Validation loss decreased (0.085698 --> 0.085560).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0860154\n",
      "\tspeed: 0.0385s/iter; left time: 716.5017s\n",
      "\titers: 200, epoch: 17 | loss: 0.0875701\n",
      "\tspeed: 0.0200s/iter; left time: 369.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0863345 Vali Loss: 0.0855349 Test Loss: 0.1227551\n",
      "Validation loss decreased (0.085560 --> 0.085535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0845458\n",
      "\tspeed: 0.0398s/iter; left time: 732.6024s\n",
      "\titers: 200, epoch: 18 | loss: 0.0840099\n",
      "\tspeed: 0.0200s/iter; left time: 367.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0860312 Vali Loss: 0.0856903 Test Loss: 0.1203355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0868545\n",
      "\tspeed: 0.0416s/iter; left time: 756.6201s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866249\n",
      "\tspeed: 0.0227s/iter; left time: 409.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0859594 Vali Loss: 0.0854916 Test Loss: 0.1243568\n",
      "Validation loss decreased (0.085535 --> 0.085492).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0862166\n",
      "\tspeed: 0.0417s/iter; left time: 749.0583s\n",
      "\titers: 200, epoch: 20 | loss: 0.0874774\n",
      "\tspeed: 0.0229s/iter; left time: 409.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0860435 Vali Loss: 0.0858084 Test Loss: 0.1183013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0850150\n",
      "\tspeed: 0.0364s/iter; left time: 645.3939s\n",
      "\titers: 200, epoch: 21 | loss: 0.0864394\n",
      "\tspeed: 0.0162s/iter; left time: 285.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0856368 Vali Loss: 0.0854388 Test Loss: 0.1230027\n",
      "Validation loss decreased (0.085492 --> 0.085439).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0877366\n",
      "\tspeed: 0.0381s/iter; left time: 666.7721s\n",
      "\titers: 200, epoch: 22 | loss: 0.0863515\n",
      "\tspeed: 0.0197s/iter; left time: 342.2900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0855459 Vali Loss: 0.0853280 Test Loss: 0.1221737\n",
      "Validation loss decreased (0.085439 --> 0.085328).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0841257\n",
      "\tspeed: 0.0403s/iter; left time: 696.3513s\n",
      "\titers: 200, epoch: 23 | loss: 0.0909050\n",
      "\tspeed: 0.0219s/iter; left time: 376.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0859897 Vali Loss: 0.0850827 Test Loss: 0.1209199\n",
      "Validation loss decreased (0.085328 --> 0.085083).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0865453\n",
      "\tspeed: 0.0429s/iter; left time: 732.1651s\n",
      "\titers: 200, epoch: 24 | loss: 0.0817557\n",
      "\tspeed: 0.0222s/iter; left time: 376.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0852483 Vali Loss: 0.0851978 Test Loss: 0.1221247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0881088\n",
      "\tspeed: 0.0374s/iter; left time: 629.4297s\n",
      "\titers: 200, epoch: 25 | loss: 0.0845777\n",
      "\tspeed: 0.0173s/iter; left time: 289.3498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0852810 Vali Loss: 0.0851420 Test Loss: 0.1218498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0853654\n",
      "\tspeed: 0.0390s/iter; left time: 648.5184s\n",
      "\titers: 200, epoch: 26 | loss: 0.0871913\n",
      "\tspeed: 0.0224s/iter; left time: 370.0879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0852549 Vali Loss: 0.0853089 Test Loss: 0.1178274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0828175\n",
      "\tspeed: 0.0428s/iter; left time: 701.8585s\n",
      "\titers: 200, epoch: 27 | loss: 0.0835795\n",
      "\tspeed: 0.0189s/iter; left time: 308.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0851044 Vali Loss: 0.0852497 Test Loss: 0.1212532\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0812769\n",
      "\tspeed: 0.0428s/iter; left time: 691.8590s\n",
      "\titers: 200, epoch: 28 | loss: 0.0857387\n",
      "\tspeed: 0.0215s/iter; left time: 344.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0849103 Vali Loss: 0.0851154 Test Loss: 0.1210589\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0882356\n",
      "\tspeed: 0.0360s/iter; left time: 575.0721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0865537\n",
      "\tspeed: 0.0162s/iter; left time: 256.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0849218 Vali Loss: 0.0852312 Test Loss: 0.1212687\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0853896\n",
      "\tspeed: 0.0362s/iter; left time: 568.9594s\n",
      "\titers: 200, epoch: 30 | loss: 0.0860251\n",
      "\tspeed: 0.0181s/iter; left time: 283.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0849076 Vali Loss: 0.0850290 Test Loss: 0.1206462\n",
      "Validation loss decreased (0.085083 --> 0.085029).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0797477\n",
      "\tspeed: 0.0369s/iter; left time: 572.3880s\n",
      "\titers: 200, epoch: 31 | loss: 0.0851969\n",
      "\tspeed: 0.0235s/iter; left time: 361.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0846795 Vali Loss: 0.0850434 Test Loss: 0.1210503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0870848\n",
      "\tspeed: 0.0427s/iter; left time: 652.8088s\n",
      "\titers: 200, epoch: 32 | loss: 0.0842670\n",
      "\tspeed: 0.0217s/iter; left time: 330.0430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0847752 Vali Loss: 0.0848986 Test Loss: 0.1220104\n",
      "Validation loss decreased (0.085029 --> 0.084899).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0898801\n",
      "\tspeed: 0.0399s/iter; left time: 601.2234s\n",
      "\titers: 200, epoch: 33 | loss: 0.0836809\n",
      "\tspeed: 0.0193s/iter; left time: 288.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0847292 Vali Loss: 0.0852259 Test Loss: 0.1219195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0837929\n",
      "\tspeed: 0.0360s/iter; left time: 533.5756s\n",
      "\titers: 200, epoch: 34 | loss: 0.0836860\n",
      "\tspeed: 0.0204s/iter; left time: 300.0120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0847673 Vali Loss: 0.0849829 Test Loss: 0.1205885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0791291\n",
      "\tspeed: 0.0415s/iter; left time: 606.9102s\n",
      "\titers: 200, epoch: 35 | loss: 0.0867016\n",
      "\tspeed: 0.0182s/iter; left time: 263.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0846931 Vali Loss: 0.0847738 Test Loss: 0.1200557\n",
      "Validation loss decreased (0.084899 --> 0.084774).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0825419\n",
      "\tspeed: 0.0333s/iter; left time: 479.7949s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818884\n",
      "\tspeed: 0.0181s/iter; left time: 258.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0847716 Vali Loss: 0.0851145 Test Loss: 0.1205825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0842333\n",
      "\tspeed: 0.0411s/iter; left time: 581.9282s\n",
      "\titers: 200, epoch: 37 | loss: 0.0840733\n",
      "\tspeed: 0.0204s/iter; left time: 287.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0847814 Vali Loss: 0.0850427 Test Loss: 0.1206309\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0844751\n",
      "\tspeed: 0.0354s/iter; left time: 494.5087s\n",
      "\titers: 200, epoch: 38 | loss: 0.0847934\n",
      "\tspeed: 0.0161s/iter; left time: 222.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0846022 Vali Loss: 0.0850175 Test Loss: 0.1210655\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0868304\n",
      "\tspeed: 0.0367s/iter; left time: 503.4895s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850215\n",
      "\tspeed: 0.0231s/iter; left time: 315.0695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0846205 Vali Loss: 0.0848845 Test Loss: 0.1202597\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0842630\n",
      "\tspeed: 0.0411s/iter; left time: 554.8389s\n",
      "\titers: 200, epoch: 40 | loss: 0.0834212\n",
      "\tspeed: 0.0214s/iter; left time: 287.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0848620 Vali Loss: 0.0848508 Test Loss: 0.1195751\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0840192\n",
      "\tspeed: 0.0379s/iter; left time: 503.6775s\n",
      "\titers: 200, epoch: 41 | loss: 0.0870575\n",
      "\tspeed: 0.0176s/iter; left time: 232.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0848115 Vali Loss: 0.0849902 Test Loss: 0.1198146\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0841808\n",
      "\tspeed: 0.0360s/iter; left time: 469.6205s\n",
      "\titers: 200, epoch: 42 | loss: 0.0868494\n",
      "\tspeed: 0.0189s/iter; left time: 245.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0845862 Vali Loss: 0.0849694 Test Loss: 0.1206443\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0820462\n",
      "\tspeed: 0.0378s/iter; left time: 484.9447s\n",
      "\titers: 200, epoch: 43 | loss: 0.0855732\n",
      "\tspeed: 0.0185s/iter; left time: 236.1781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0846324 Vali Loss: 0.0848957 Test Loss: 0.1199307\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0842967\n",
      "\tspeed: 0.0349s/iter; left time: 440.4540s\n",
      "\titers: 200, epoch: 44 | loss: 0.0861039\n",
      "\tspeed: 0.0158s/iter; left time: 197.9187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0845637 Vali Loss: 0.0851495 Test Loss: 0.1212666\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0880421\n",
      "\tspeed: 0.0341s/iter; left time: 422.4127s\n",
      "\titers: 200, epoch: 45 | loss: 0.0826582\n",
      "\tspeed: 0.0173s/iter; left time: 212.0650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0844917 Vali Loss: 0.0848732 Test Loss: 0.1199118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.034120410680770874, rmse:0.1847171038389206, mae:0.1200556606054306, rse:0.5426822304725647\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:54.07s\n",
      "Intermediate time for ES: 00h:31m:49.84s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0388s/iter; left time: 864.9738s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0144s/iter; left time: 320.7482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0319s/iter; left time: 703.3876s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0160s/iter; left time: 351.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0320s/iter; left time: 698.5147s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0161s/iter; left time: 351.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0328s/iter; left time: 708.4866s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0154s/iter; left time: 332.1353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0313s/iter; left time: 669.6824s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0155s/iter; left time: 330.5334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0327s/iter; left time: 693.6673s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0151s/iter; left time: 318.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0322s/iter; left time: 674.3288s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0158s/iter; left time: 330.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0330s/iter; left time: 683.1840s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0152s/iter; left time: 313.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0354s/iter; left time: 725.3423s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0204s/iter; left time: 416.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0362s/iter; left time: 733.9353s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0156s/iter; left time: 314.5086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0325s/iter; left time: 651.0148s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0174s/iter; left time: 348.0064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0369s/iter; left time: 732.5162s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0185s/iter; left time: 365.4618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0306s/iter; left time: 601.0958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0150s/iter; left time: 292.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0316s/iter; left time: 612.2498s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0161s/iter; left time: 310.1290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0339s/iter; left time: 649.0760s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0159s/iter; left time: 303.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0389s/iter; left time: 736.7670s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0232s/iter; left time: 436.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0377s/iter; left time: 706.3987s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0161s/iter; left time: 300.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0362s/iter; left time: 669.7450s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0118s/iter; left time: 217.0465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0324s/iter; left time: 591.5499s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0176s/iter; left time: 319.3796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0339s/iter; left time: 611.7880s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0176s/iter; left time: 316.6700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0500307\n",
      "\tspeed: 0.0346s/iter; left time: 615.7330s\n",
      "\titers: 200, epoch: 21 | loss: 0.0490154\n",
      "\tspeed: 0.0154s/iter; left time: 272.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0510271 Vali Loss: 0.0585692 Test Loss: 0.0614969\n",
      "Validation loss decreased (0.058856 --> 0.058569).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0487849\n",
      "\tspeed: 0.0350s/iter; left time: 615.9994s\n",
      "\titers: 200, epoch: 22 | loss: 0.0499946\n",
      "\tspeed: 0.0097s/iter; left time: 170.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 224 | Train Loss: 0.0509135 Vali Loss: 0.0583646 Test Loss: 0.0612312\n",
      "Validation loss decreased (0.058569 --> 0.058365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511933\n",
      "\tspeed: 0.0364s/iter; left time: 632.4613s\n",
      "\titers: 200, epoch: 23 | loss: 0.0494870\n",
      "\tspeed: 0.0183s/iter; left time: 316.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0507191 Vali Loss: 0.0584055 Test Loss: 0.0613245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0491849\n",
      "\tspeed: 0.0328s/iter; left time: 562.8597s\n",
      "\titers: 200, epoch: 24 | loss: 0.0487800\n",
      "\tspeed: 0.0166s/iter; left time: 282.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0509352 Vali Loss: 0.0585210 Test Loss: 0.0614635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0493839\n",
      "\tspeed: 0.0364s/iter; left time: 615.8645s\n",
      "\titers: 200, epoch: 25 | loss: 0.0514642\n",
      "\tspeed: 0.0178s/iter; left time: 299.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0506817 Vali Loss: 0.0584098 Test Loss: 0.0612296\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0499401\n",
      "\tspeed: 0.0344s/iter; left time: 574.7235s\n",
      "\titers: 200, epoch: 26 | loss: 0.0537204\n",
      "\tspeed: 0.0174s/iter; left time: 289.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0504769 Vali Loss: 0.0582367 Test Loss: 0.0610654\n",
      "Validation loss decreased (0.058365 --> 0.058237).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0544665\n",
      "\tspeed: 0.0339s/iter; left time: 559.2697s\n",
      "\titers: 200, epoch: 27 | loss: 0.0464305\n",
      "\tspeed: 0.0172s/iter; left time: 281.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0507225 Vali Loss: 0.0584667 Test Loss: 0.0613662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0510654\n",
      "\tspeed: 0.0316s/iter; left time: 513.5278s\n",
      "\titers: 200, epoch: 28 | loss: 0.0489795\n",
      "\tspeed: 0.0156s/iter; left time: 251.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0504315 Vali Loss: 0.0583163 Test Loss: 0.0612576\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0505894\n",
      "\tspeed: 0.0338s/iter; left time: 541.2961s\n",
      "\titers: 200, epoch: 29 | loss: 0.0509785\n",
      "\tspeed: 0.0153s/iter; left time: 243.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.0504090 Vali Loss: 0.0582874 Test Loss: 0.0612145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0510114\n",
      "\tspeed: 0.0322s/iter; left time: 508.2863s\n",
      "\titers: 200, epoch: 30 | loss: 0.0490248\n",
      "\tspeed: 0.0174s/iter; left time: 273.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0503936 Vali Loss: 0.0581573 Test Loss: 0.0610772\n",
      "Validation loss decreased (0.058237 --> 0.058157).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0496442\n",
      "\tspeed: 0.0353s/iter; left time: 550.5037s\n",
      "\titers: 200, epoch: 31 | loss: 0.0525338\n",
      "\tspeed: 0.0179s/iter; left time: 276.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0502830 Vali Loss: 0.0582156 Test Loss: 0.0611820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0478567\n",
      "\tspeed: 0.0348s/iter; left time: 534.3495s\n",
      "\titers: 200, epoch: 32 | loss: 0.0482991\n",
      "\tspeed: 0.0184s/iter; left time: 281.3154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0502242 Vali Loss: 0.0581192 Test Loss: 0.0610652\n",
      "Validation loss decreased (0.058157 --> 0.058119).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0482565\n",
      "\tspeed: 0.0335s/iter; left time: 506.4377s\n",
      "\titers: 200, epoch: 33 | loss: 0.0504164\n",
      "\tspeed: 0.0171s/iter; left time: 256.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0501112 Vali Loss: 0.0580270 Test Loss: 0.0608346\n",
      "Validation loss decreased (0.058119 --> 0.058027).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0502544\n",
      "\tspeed: 0.0324s/iter; left time: 483.7105s\n",
      "\titers: 200, epoch: 34 | loss: 0.0484893\n",
      "\tspeed: 0.0160s/iter; left time: 237.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0499967 Vali Loss: 0.0579108 Test Loss: 0.0607200\n",
      "Validation loss decreased (0.058027 --> 0.057911).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510540\n",
      "\tspeed: 0.0348s/iter; left time: 511.5162s\n",
      "\titers: 200, epoch: 35 | loss: 0.0495207\n",
      "\tspeed: 0.0167s/iter; left time: 243.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0501554 Vali Loss: 0.0580440 Test Loss: 0.0608846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0460694\n",
      "\tspeed: 0.0324s/iter; left time: 467.9448s\n",
      "\titers: 200, epoch: 36 | loss: 0.0490633\n",
      "\tspeed: 0.0200s/iter; left time: 286.9270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0499619 Vali Loss: 0.0581870 Test Loss: 0.0610619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0493442\n",
      "\tspeed: 0.0349s/iter; left time: 496.5394s\n",
      "\titers: 200, epoch: 37 | loss: 0.0520324\n",
      "\tspeed: 0.0182s/iter; left time: 257.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0500377 Vali Loss: 0.0579085 Test Loss: 0.0607732\n",
      "Validation loss decreased (0.057911 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0495058\n",
      "\tspeed: 0.0340s/iter; left time: 475.9891s\n",
      "\titers: 200, epoch: 38 | loss: 0.0469532\n",
      "\tspeed: 0.0187s/iter; left time: 260.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0499961 Vali Loss: 0.0579373 Test Loss: 0.0607163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0499609\n",
      "\tspeed: 0.0362s/iter; left time: 498.9282s\n",
      "\titers: 200, epoch: 39 | loss: 0.0492594\n",
      "\tspeed: 0.0176s/iter; left time: 240.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0498864 Vali Loss: 0.0580742 Test Loss: 0.0609236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0493156\n",
      "\tspeed: 0.0354s/iter; left time: 480.0444s\n",
      "\titers: 200, epoch: 40 | loss: 0.0476659\n",
      "\tspeed: 0.0156s/iter; left time: 210.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0500837 Vali Loss: 0.0582142 Test Loss: 0.0610824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0488396\n",
      "\tspeed: 0.0367s/iter; left time: 490.1113s\n",
      "\titers: 200, epoch: 41 | loss: 0.0483784\n",
      "\tspeed: 0.0207s/iter; left time: 274.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0499609 Vali Loss: 0.0579718 Test Loss: 0.0607426\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0522610\n",
      "\tspeed: 0.0324s/iter; left time: 425.2086s\n",
      "\titers: 200, epoch: 42 | loss: 0.0530269\n",
      "\tspeed: 0.0178s/iter; left time: 231.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0498560 Vali Loss: 0.0579498 Test Loss: 0.0607294\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0493973\n",
      "\tspeed: 0.0359s/iter; left time: 462.7674s\n",
      "\titers: 200, epoch: 43 | loss: 0.0526842\n",
      "\tspeed: 0.0196s/iter; left time: 250.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0499097 Vali Loss: 0.0578594 Test Loss: 0.0606453\n",
      "Validation loss decreased (0.057909 --> 0.057859).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0515855\n",
      "\tspeed: 0.0307s/iter; left time: 389.2830s\n",
      "\titers: 200, epoch: 44 | loss: 0.0481943\n",
      "\tspeed: 0.0164s/iter; left time: 206.6407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0498872 Vali Loss: 0.0578712 Test Loss: 0.0607137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0520111\n",
      "\tspeed: 0.0309s/iter; left time: 384.5204s\n",
      "\titers: 200, epoch: 45 | loss: 0.0519452\n",
      "\tspeed: 0.0162s/iter; left time: 199.7524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0499239 Vali Loss: 0.0579881 Test Loss: 0.0608724\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0476939\n",
      "\tspeed: 0.0349s/iter; left time: 426.8148s\n",
      "\titers: 200, epoch: 46 | loss: 0.0521748\n",
      "\tspeed: 0.0181s/iter; left time: 219.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0498292 Vali Loss: 0.0580555 Test Loss: 0.0609686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0484655\n",
      "\tspeed: 0.0347s/iter; left time: 416.0644s\n",
      "\titers: 200, epoch: 47 | loss: 0.0480573\n",
      "\tspeed: 0.0179s/iter; left time: 212.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0499865 Vali Loss: 0.0583157 Test Loss: 0.0612470\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0510940\n",
      "\tspeed: 0.0330s/iter; left time: 388.6550s\n",
      "\titers: 200, epoch: 48 | loss: 0.0530471\n",
      "\tspeed: 0.0159s/iter; left time: 186.0165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0497833 Vali Loss: 0.0579604 Test Loss: 0.0608368\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0501904\n",
      "\tspeed: 0.0315s/iter; left time: 363.2420s\n",
      "\titers: 200, epoch: 49 | loss: 0.0487544\n",
      "\tspeed: 0.0157s/iter; left time: 179.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0497741 Vali Loss: 0.0577866 Test Loss: 0.0606853\n",
      "Validation loss decreased (0.057859 --> 0.057787).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0508748\n",
      "\tspeed: 0.0366s/iter; left time: 414.2281s\n",
      "\titers: 200, epoch: 50 | loss: 0.0485370\n",
      "\tspeed: 0.0168s/iter; left time: 188.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0498600 Vali Loss: 0.0578839 Test Loss: 0.0606901\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0541600\n",
      "\tspeed: 0.0330s/iter; left time: 366.3356s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510142\n",
      "\tspeed: 0.0172s/iter; left time: 188.7349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0497815 Vali Loss: 0.0579270 Test Loss: 0.0607067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0498654\n",
      "\tspeed: 0.0342s/iter; left time: 372.3267s\n",
      "\titers: 200, epoch: 52 | loss: 0.0535375\n",
      "\tspeed: 0.0174s/iter; left time: 187.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0498009 Vali Loss: 0.0578123 Test Loss: 0.0606300\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0521141\n",
      "\tspeed: 0.0368s/iter; left time: 391.9841s\n",
      "\titers: 200, epoch: 53 | loss: 0.0494763\n",
      "\tspeed: 0.0181s/iter; left time: 190.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0497956 Vali Loss: 0.0577853 Test Loss: 0.0606052\n",
      "Validation loss decreased (0.057787 --> 0.057785).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0518647\n",
      "\tspeed: 0.0320s/iter; left time: 334.0232s\n",
      "\titers: 200, epoch: 54 | loss: 0.0501313\n",
      "\tspeed: 0.0155s/iter; left time: 159.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0497809 Vali Loss: 0.0579372 Test Loss: 0.0607195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0496054\n",
      "\tspeed: 0.0353s/iter; left time: 360.1218s\n",
      "\titers: 200, epoch: 55 | loss: 0.0486854\n",
      "\tspeed: 0.0174s/iter; left time: 175.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0497393 Vali Loss: 0.0578342 Test Loss: 0.0605182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0485080\n",
      "\tspeed: 0.0339s/iter; left time: 338.2463s\n",
      "\titers: 200, epoch: 56 | loss: 0.0464521\n",
      "\tspeed: 0.0160s/iter; left time: 157.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0498971 Vali Loss: 0.0578821 Test Loss: 0.0606105\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0527421\n",
      "\tspeed: 0.0328s/iter; left time: 320.3230s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523424\n",
      "\tspeed: 0.0180s/iter; left time: 174.1106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0498499 Vali Loss: 0.0578462 Test Loss: 0.0606600\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0476605\n",
      "\tspeed: 0.0332s/iter; left time: 316.2839s\n",
      "\titers: 200, epoch: 58 | loss: 0.0482116\n",
      "\tspeed: 0.0165s/iter; left time: 155.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0497194 Vali Loss: 0.0577791 Test Loss: 0.0605505\n",
      "Validation loss decreased (0.057785 --> 0.057779).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0505652\n",
      "\tspeed: 0.0347s/iter; left time: 323.4281s\n",
      "\titers: 200, epoch: 59 | loss: 0.0538413\n",
      "\tspeed: 0.0159s/iter; left time: 146.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0497615 Vali Loss: 0.0579725 Test Loss: 0.0608881\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0523902\n",
      "\tspeed: 0.0326s/iter; left time: 295.9030s\n",
      "\titers: 200, epoch: 60 | loss: 0.0489338\n",
      "\tspeed: 0.0181s/iter; left time: 162.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0497763 Vali Loss: 0.0577925 Test Loss: 0.0605517\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0532521\n",
      "\tspeed: 0.0375s/iter; left time: 332.4871s\n",
      "\titers: 200, epoch: 61 | loss: 0.0454659\n",
      "\tspeed: 0.0187s/iter; left time: 164.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0498417 Vali Loss: 0.0578000 Test Loss: 0.0605808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0490412\n",
      "\tspeed: 0.0306s/iter; left time: 264.0944s\n",
      "\titers: 200, epoch: 62 | loss: 0.0466805\n",
      "\tspeed: 0.0146s/iter; left time: 125.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 224 | Train Loss: 0.0496877 Vali Loss: 0.0580046 Test Loss: 0.0608975\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0493944\n",
      "\tspeed: 0.0319s/iter; left time: 268.1555s\n",
      "\titers: 200, epoch: 63 | loss: 0.0473165\n",
      "\tspeed: 0.0176s/iter; left time: 146.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0497746 Vali Loss: 0.0578258 Test Loss: 0.0607631\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0499734\n",
      "\tspeed: 0.0341s/iter; left time: 278.8650s\n",
      "\titers: 200, epoch: 64 | loss: 0.0489092\n",
      "\tspeed: 0.0188s/iter; left time: 151.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0497661 Vali Loss: 0.0577920 Test Loss: 0.0605248\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0476629\n",
      "\tspeed: 0.0333s/iter; left time: 264.8654s\n",
      "\titers: 200, epoch: 65 | loss: 0.0475802\n",
      "\tspeed: 0.0176s/iter; left time: 138.5969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0497550 Vali Loss: 0.0577449 Test Loss: 0.0606460\n",
      "Validation loss decreased (0.057779 --> 0.057745).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0496131\n",
      "\tspeed: 0.0331s/iter; left time: 255.9472s\n",
      "\titers: 200, epoch: 66 | loss: 0.0514756\n",
      "\tspeed: 0.0178s/iter; left time: 136.2526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0497879 Vali Loss: 0.0578677 Test Loss: 0.0606613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0534090\n",
      "\tspeed: 0.0362s/iter; left time: 271.8309s\n",
      "\titers: 200, epoch: 67 | loss: 0.0471433\n",
      "\tspeed: 0.0175s/iter; left time: 130.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0498299 Vali Loss: 0.0578383 Test Loss: 0.0607215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0482797\n",
      "\tspeed: 0.0307s/iter; left time: 223.7490s\n",
      "\titers: 200, epoch: 68 | loss: 0.0527938\n",
      "\tspeed: 0.0154s/iter; left time: 110.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0498227 Vali Loss: 0.0578183 Test Loss: 0.0606315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0529874\n",
      "\tspeed: 0.0385s/iter; left time: 271.8347s\n",
      "\titers: 200, epoch: 69 | loss: 0.0479324\n",
      "\tspeed: 0.0164s/iter; left time: 114.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0498894 Vali Loss: 0.0577414 Test Loss: 0.0606067\n",
      "Validation loss decreased (0.057745 --> 0.057741).  Saving model ...\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0520114\n",
      "\tspeed: 0.0337s/iter; left time: 230.6531s\n",
      "\titers: 200, epoch: 70 | loss: 0.0495122\n",
      "\tspeed: 0.0157s/iter; left time: 105.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0497955 Vali Loss: 0.0576698 Test Loss: 0.0605525\n",
      "Validation loss decreased (0.057741 --> 0.057670).  Saving model ...\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0490391\n",
      "\tspeed: 0.0339s/iter; left time: 224.4821s\n",
      "\titers: 200, epoch: 71 | loss: 0.0496808\n",
      "\tspeed: 0.0158s/iter; left time: 103.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0496891 Vali Loss: 0.0578580 Test Loss: 0.0607717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0504889\n",
      "\tspeed: 0.0320s/iter; left time: 204.7305s\n",
      "\titers: 200, epoch: 72 | loss: 0.0489570\n",
      "\tspeed: 0.0160s/iter; left time: 100.6612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0498359 Vali Loss: 0.0578459 Test Loss: 0.0606254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0496917\n",
      "\tspeed: 0.0315s/iter; left time: 194.5787s\n",
      "\titers: 200, epoch: 73 | loss: 0.0486437\n",
      "\tspeed: 0.0114s/iter; left time: 68.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 224 | Train Loss: 0.0497904 Vali Loss: 0.0578623 Test Loss: 0.0606682\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0502861\n",
      "\tspeed: 0.0317s/iter; left time: 188.4502s\n",
      "\titers: 200, epoch: 74 | loss: 0.0482049\n",
      "\tspeed: 0.0177s/iter; left time: 103.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0498100 Vali Loss: 0.0577250 Test Loss: 0.0606257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0496599\n",
      "\tspeed: 0.0356s/iter; left time: 203.7866s\n",
      "\titers: 200, epoch: 75 | loss: 0.0485606\n",
      "\tspeed: 0.0179s/iter; left time: 100.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0497395 Vali Loss: 0.0578765 Test Loss: 0.0607232\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0489640\n",
      "\tspeed: 0.0324s/iter; left time: 177.9835s\n",
      "\titers: 200, epoch: 76 | loss: 0.0500719\n",
      "\tspeed: 0.0170s/iter; left time: 91.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0497012 Vali Loss: 0.0578201 Test Loss: 0.0606754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0562747\n",
      "\tspeed: 0.0342s/iter; left time: 180.2212s\n",
      "\titers: 200, epoch: 77 | loss: 0.0470544\n",
      "\tspeed: 0.0194s/iter; left time: 100.2238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0496969 Vali Loss: 0.0577695 Test Loss: 0.0605956\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0477906\n",
      "\tspeed: 0.0375s/iter; left time: 189.5116s\n",
      "\titers: 200, epoch: 78 | loss: 0.0496063\n",
      "\tspeed: 0.0178s/iter; left time: 88.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0498004 Vali Loss: 0.0579858 Test Loss: 0.0608449\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0492227\n",
      "\tspeed: 0.0355s/iter; left time: 171.3686s\n",
      "\titers: 200, epoch: 79 | loss: 0.0496928\n",
      "\tspeed: 0.0211s/iter; left time: 99.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0497735 Vali Loss: 0.0578129 Test Loss: 0.0606371\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0483101\n",
      "\tspeed: 0.0320s/iter; left time: 147.3775s\n",
      "\titers: 200, epoch: 80 | loss: 0.0474963\n",
      "\tspeed: 0.0160s/iter; left time: 72.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0497277 Vali Loss: 0.0579814 Test Loss: 0.0608682\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010923855006694794, rmse:0.10451724380254745, mae:0.060552507638931274, rse:0.4032246470451355\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2416472\n",
      "\tspeed: 0.0191s/iter; left time: 426.3905s\n",
      "\titers: 200, epoch: 1 | loss: 0.2157288\n",
      "\tspeed: 0.0173s/iter; left time: 383.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.2390083 Vali Loss: 0.1850636 Test Loss: 0.1906125\n",
      "Validation loss decreased (inf --> 0.185064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1321534\n",
      "\tspeed: 0.0360s/iter; left time: 793.8775s\n",
      "\titers: 200, epoch: 2 | loss: 0.0980146\n",
      "\tspeed: 0.0173s/iter; left time: 379.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1389367 Vali Loss: 0.0845335 Test Loss: 0.0928966\n",
      "Validation loss decreased (0.185064 --> 0.084534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0873793\n",
      "\tspeed: 0.0356s/iter; left time: 777.6006s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807172\n",
      "\tspeed: 0.0162s/iter; left time: 351.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0858602 Vali Loss: 0.0766271 Test Loss: 0.0801685\n",
      "Validation loss decreased (0.084534 --> 0.076627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0747777\n",
      "\tspeed: 0.0367s/iter; left time: 793.0740s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713048\n",
      "\tspeed: 0.0183s/iter; left time: 394.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0727825 Vali Loss: 0.0689248 Test Loss: 0.0718431\n",
      "Validation loss decreased (0.076627 --> 0.068925).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0664114\n",
      "\tspeed: 0.0379s/iter; left time: 811.5586s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626735\n",
      "\tspeed: 0.0199s/iter; left time: 424.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0665844 Vali Loss: 0.0659335 Test Loss: 0.0688953\n",
      "Validation loss decreased (0.068925 --> 0.065934).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640696\n",
      "\tspeed: 0.0372s/iter; left time: 787.3520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583320\n",
      "\tspeed: 0.0155s/iter; left time: 326.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0631395 Vali Loss: 0.0637366 Test Loss: 0.0662843\n",
      "Validation loss decreased (0.065934 --> 0.063737).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611526\n",
      "\tspeed: 0.0378s/iter; left time: 793.0525s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601704\n",
      "\tspeed: 0.0224s/iter; left time: 466.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0600838 Vali Loss: 0.0636623 Test Loss: 0.0658088\n",
      "Validation loss decreased (0.063737 --> 0.063662).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0638688\n",
      "\tspeed: 0.0341s/iter; left time: 706.5853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0564657\n",
      "\tspeed: 0.0164s/iter; left time: 337.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0582559 Vali Loss: 0.0636032 Test Loss: 0.0659900\n",
      "Validation loss decreased (0.063662 --> 0.063603).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0594054\n",
      "\tspeed: 0.0337s/iter; left time: 690.7592s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544079\n",
      "\tspeed: 0.0112s/iter; left time: 227.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0566816 Vali Loss: 0.0611874 Test Loss: 0.0644945\n",
      "Validation loss decreased (0.063603 --> 0.061187).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0531490\n",
      "\tspeed: 0.0307s/iter; left time: 623.3132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550409\n",
      "\tspeed: 0.0187s/iter; left time: 378.0664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0556962 Vali Loss: 0.0607619 Test Loss: 0.0637574\n",
      "Validation loss decreased (0.061187 --> 0.060762).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0540955\n",
      "\tspeed: 0.0339s/iter; left time: 680.7227s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529300\n",
      "\tspeed: 0.0186s/iter; left time: 370.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0546806 Vali Loss: 0.0601323 Test Loss: 0.0631922\n",
      "Validation loss decreased (0.060762 --> 0.060132).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549707\n",
      "\tspeed: 0.0333s/iter; left time: 660.3829s\n",
      "\titers: 200, epoch: 12 | loss: 0.0538874\n",
      "\tspeed: 0.0164s/iter; left time: 322.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0541219 Vali Loss: 0.0603495 Test Loss: 0.0632753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556391\n",
      "\tspeed: 0.0343s/iter; left time: 672.3475s\n",
      "\titers: 200, epoch: 13 | loss: 0.0565307\n",
      "\tspeed: 0.0163s/iter; left time: 317.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0537329 Vali Loss: 0.0602877 Test Loss: 0.0631722\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507059\n",
      "\tspeed: 0.0344s/iter; left time: 667.5166s\n",
      "\titers: 200, epoch: 14 | loss: 0.0497007\n",
      "\tspeed: 0.0152s/iter; left time: 292.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0535748 Vali Loss: 0.0596906 Test Loss: 0.0627980\n",
      "Validation loss decreased (0.060132 --> 0.059691).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0525676\n",
      "\tspeed: 0.0306s/iter; left time: 587.4026s\n",
      "\titers: 200, epoch: 15 | loss: 0.0544337\n",
      "\tspeed: 0.0114s/iter; left time: 218.1102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 224 | Train Loss: 0.0528798 Vali Loss: 0.0596838 Test Loss: 0.0626478\n",
      "Validation loss decreased (0.059691 --> 0.059684).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0518733\n",
      "\tspeed: 0.0337s/iter; left time: 637.7585s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502742\n",
      "\tspeed: 0.0155s/iter; left time: 292.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0523913 Vali Loss: 0.0595967 Test Loss: 0.0625617\n",
      "Validation loss decreased (0.059684 --> 0.059597).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0526551\n",
      "\tspeed: 0.0330s/iter; left time: 618.2923s\n",
      "\titers: 200, epoch: 17 | loss: 0.0533199\n",
      "\tspeed: 0.0168s/iter; left time: 312.7847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0521800 Vali Loss: 0.0591736 Test Loss: 0.0620432\n",
      "Validation loss decreased (0.059597 --> 0.059174).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0531408\n",
      "\tspeed: 0.0372s/iter; left time: 687.5410s\n",
      "\titers: 200, epoch: 18 | loss: 0.0512082\n",
      "\tspeed: 0.0200s/iter; left time: 368.4745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0518041 Vali Loss: 0.0590653 Test Loss: 0.0620126\n",
      "Validation loss decreased (0.059174 --> 0.059065).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0508133\n",
      "\tspeed: 0.0345s/iter; left time: 630.4036s\n",
      "\titers: 200, epoch: 19 | loss: 0.0508652\n",
      "\tspeed: 0.0182s/iter; left time: 330.9318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0516297 Vali Loss: 0.0590433 Test Loss: 0.0620764\n",
      "Validation loss decreased (0.059065 --> 0.059043).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0503310\n",
      "\tspeed: 0.0386s/iter; left time: 695.7026s\n",
      "\titers: 200, epoch: 20 | loss: 0.0477689\n",
      "\tspeed: 0.0178s/iter; left time: 318.6227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0516755 Vali Loss: 0.0588695 Test Loss: 0.0618976\n",
      "Validation loss decreased (0.059043 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0502275\n",
      "\tspeed: 0.0357s/iter; left time: 635.4142s\n",
      "\titers: 200, epoch: 21 | loss: 0.0473861\n",
      "\tspeed: 0.0159s/iter; left time: 282.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0513905 Vali Loss: 0.0589136 Test Loss: 0.0618429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0501105\n",
      "\tspeed: 0.0332s/iter; left time: 583.4617s\n",
      "\titers: 200, epoch: 22 | loss: 0.0505043\n",
      "\tspeed: 0.0154s/iter; left time: 269.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0512485 Vali Loss: 0.0587117 Test Loss: 0.0616255\n",
      "Validation loss decreased (0.058869 --> 0.058712).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0516095\n",
      "\tspeed: 0.0337s/iter; left time: 585.2679s\n",
      "\titers: 200, epoch: 23 | loss: 0.0515190\n",
      "\tspeed: 0.0199s/iter; left time: 343.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0511317 Vali Loss: 0.0588214 Test Loss: 0.0617099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492050\n",
      "\tspeed: 0.0331s/iter; left time: 566.7953s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538395\n",
      "\tspeed: 0.0182s/iter; left time: 310.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0510162 Vali Loss: 0.0590029 Test Loss: 0.0619497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0478245\n",
      "\tspeed: 0.0365s/iter; left time: 617.2707s\n",
      "\titers: 200, epoch: 25 | loss: 0.0501745\n",
      "\tspeed: 0.0204s/iter; left time: 343.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0508491 Vali Loss: 0.0588119 Test Loss: 0.0616985\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0482835\n",
      "\tspeed: 0.0347s/iter; left time: 579.7226s\n",
      "\titers: 200, epoch: 26 | loss: 0.0496864\n",
      "\tspeed: 0.0170s/iter; left time: 282.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0507353 Vali Loss: 0.0590678 Test Loss: 0.0619756\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0505852\n",
      "\tspeed: 0.0333s/iter; left time: 548.9465s\n",
      "\titers: 200, epoch: 27 | loss: 0.0507914\n",
      "\tspeed: 0.0164s/iter; left time: 269.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0505978 Vali Loss: 0.0586039 Test Loss: 0.0615524\n",
      "Validation loss decreased (0.058712 --> 0.058604).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0502958\n",
      "\tspeed: 0.0361s/iter; left time: 586.5268s\n",
      "\titers: 200, epoch: 28 | loss: 0.0489078\n",
      "\tspeed: 0.0159s/iter; left time: 257.5840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0505392 Vali Loss: 0.0587085 Test Loss: 0.0615680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0505078\n",
      "\tspeed: 0.0352s/iter; left time: 563.8575s\n",
      "\titers: 200, epoch: 29 | loss: 0.0474629\n",
      "\tspeed: 0.0163s/iter; left time: 260.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0506125 Vali Loss: 0.0583189 Test Loss: 0.0612263\n",
      "Validation loss decreased (0.058604 --> 0.058319).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523297\n",
      "\tspeed: 0.0347s/iter; left time: 549.1844s\n",
      "\titers: 200, epoch: 30 | loss: 0.0533438\n",
      "\tspeed: 0.0185s/iter; left time: 290.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0505089 Vali Loss: 0.0584156 Test Loss: 0.0612568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0503295\n",
      "\tspeed: 0.0339s/iter; left time: 528.4301s\n",
      "\titers: 200, epoch: 31 | loss: 0.0504319\n",
      "\tspeed: 0.0164s/iter; left time: 253.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0503712 Vali Loss: 0.0588283 Test Loss: 0.0617319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506263\n",
      "\tspeed: 0.0326s/iter; left time: 500.6402s\n",
      "\titers: 200, epoch: 32 | loss: 0.0477929\n",
      "\tspeed: 0.0151s/iter; left time: 230.7538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0502545 Vali Loss: 0.0583562 Test Loss: 0.0611734\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0504393\n",
      "\tspeed: 0.0330s/iter; left time: 499.6249s\n",
      "\titers: 200, epoch: 33 | loss: 0.0489511\n",
      "\tspeed: 0.0173s/iter; left time: 260.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0502463 Vali Loss: 0.0585476 Test Loss: 0.0613365\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0483616\n",
      "\tspeed: 0.0279s/iter; left time: 415.8955s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519027\n",
      "\tspeed: 0.0160s/iter; left time: 236.6668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0503158 Vali Loss: 0.0582609 Test Loss: 0.0612222\n",
      "Validation loss decreased (0.058319 --> 0.058261).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0488857\n",
      "\tspeed: 0.0325s/iter; left time: 477.5721s\n",
      "\titers: 200, epoch: 35 | loss: 0.0538403\n",
      "\tspeed: 0.0116s/iter; left time: 169.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 224 | Train Loss: 0.0501319 Vali Loss: 0.0586195 Test Loss: 0.0615450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0495875\n",
      "\tspeed: 0.0304s/iter; left time: 439.8041s\n",
      "\titers: 200, epoch: 36 | loss: 0.0497248\n",
      "\tspeed: 0.0154s/iter; left time: 221.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0501083 Vali Loss: 0.0586764 Test Loss: 0.0616085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0526582\n",
      "\tspeed: 0.0347s/iter; left time: 494.5134s\n",
      "\titers: 200, epoch: 37 | loss: 0.0501021\n",
      "\tspeed: 0.0126s/iter; left time: 177.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0501694 Vali Loss: 0.0581614 Test Loss: 0.0610229\n",
      "Validation loss decreased (0.058261 --> 0.058161).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0500558\n",
      "\tspeed: 0.0312s/iter; left time: 437.3889s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513457\n",
      "\tspeed: 0.0155s/iter; left time: 215.9520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0500217 Vali Loss: 0.0582170 Test Loss: 0.0611187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503623\n",
      "\tspeed: 0.0351s/iter; left time: 483.8113s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528996\n",
      "\tspeed: 0.0210s/iter; left time: 287.8609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0501734 Vali Loss: 0.0582744 Test Loss: 0.0611718\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0508711\n",
      "\tspeed: 0.0321s/iter; left time: 435.9089s\n",
      "\titers: 200, epoch: 40 | loss: 0.0498356\n",
      "\tspeed: 0.0108s/iter; left time: 144.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 224 | Train Loss: 0.0500942 Vali Loss: 0.0584468 Test Loss: 0.0614264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0534200\n",
      "\tspeed: 0.0303s/iter; left time: 403.6297s\n",
      "\titers: 200, epoch: 41 | loss: 0.0495634\n",
      "\tspeed: 0.0170s/iter; left time: 225.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0500160 Vali Loss: 0.0583306 Test Loss: 0.0612324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0527063\n",
      "\tspeed: 0.0359s/iter; left time: 470.4525s\n",
      "\titers: 200, epoch: 42 | loss: 0.0480693\n",
      "\tspeed: 0.0190s/iter; left time: 247.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0500439 Vali Loss: 0.0586539 Test Loss: 0.0615852\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0521657\n",
      "\tspeed: 0.0336s/iter; left time: 432.5894s\n",
      "\titers: 200, epoch: 43 | loss: 0.0497351\n",
      "\tspeed: 0.0163s/iter; left time: 208.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0501407 Vali Loss: 0.0582708 Test Loss: 0.0611153\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0491388\n",
      "\tspeed: 0.0336s/iter; left time: 426.0426s\n",
      "\titers: 200, epoch: 44 | loss: 0.0484253\n",
      "\tspeed: 0.0183s/iter; left time: 229.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0500195 Vali Loss: 0.0582583 Test Loss: 0.0611036\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0473987\n",
      "\tspeed: 0.0344s/iter; left time: 428.6609s\n",
      "\titers: 200, epoch: 45 | loss: 0.0518590\n",
      "\tspeed: 0.0155s/iter; left time: 191.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0499404 Vali Loss: 0.0584004 Test Loss: 0.0613419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0509252\n",
      "\tspeed: 0.0319s/iter; left time: 390.1522s\n",
      "\titers: 200, epoch: 46 | loss: 0.0509868\n",
      "\tspeed: 0.0165s/iter; left time: 199.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0500175 Vali Loss: 0.0583170 Test Loss: 0.0611765\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0507299\n",
      "\tspeed: 0.0285s/iter; left time: 341.7025s\n",
      "\titers: 200, epoch: 47 | loss: 0.0480615\n",
      "\tspeed: 0.0097s/iter; left time: 115.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 224 | Train Loss: 0.0500566 Vali Loss: 0.0583913 Test Loss: 0.0613157\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011083848774433136, rmse:0.10527986288070679, mae:0.061022911220788956, rse:0.40616676211357117\n",
      "Intermediate time for FR and pred_len 24: 00h:10m:53.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0377s/iter; left time: 841.3185s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0173s/iter; left time: 383.7734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0328s/iter; left time: 723.8094s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0152s/iter; left time: 333.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0339s/iter; left time: 740.9506s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0173s/iter; left time: 376.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0344s/iter; left time: 743.8304s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0175s/iter; left time: 377.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0361s/iter; left time: 773.2473s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0173s/iter; left time: 368.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0354s/iter; left time: 749.5136s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0099s/iter; left time: 209.4683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0322s/iter; left time: 675.6662s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0170s/iter; left time: 354.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0357s/iter; left time: 740.5609s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0167s/iter; left time: 344.7488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0345s/iter; left time: 707.8720s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0164s/iter; left time: 335.5276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0301s/iter; left time: 610.7200s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0118s/iter; left time: 237.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0327s/iter; left time: 656.1659s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0155s/iter; left time: 309.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0342s/iter; left time: 677.6035s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0166s/iter; left time: 327.5529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0363s/iter; left time: 712.7234s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0198s/iter; left time: 387.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0339s/iter; left time: 657.6192s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0163s/iter; left time: 314.5015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0360s/iter; left time: 690.1252s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0185s/iter; left time: 351.8334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0354s/iter; left time: 670.4980s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0153s/iter; left time: 288.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0351s/iter; left time: 656.3606s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0197s/iter; left time: 366.8612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0364s/iter; left time: 673.4571s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0162s/iter; left time: 297.4856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0323s/iter; left time: 589.1908s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0159s/iter; left time: 288.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0380s/iter; left time: 685.3307s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0210s/iter; left time: 376.7957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0612366\n",
      "\tspeed: 0.0344s/iter; left time: 612.6686s\n",
      "\titers: 200, epoch: 21 | loss: 0.0611458\n",
      "\tspeed: 0.0185s/iter; left time: 327.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0645373 Vali Loss: 0.0751285 Test Loss: 0.0847554\n",
      "Validation loss decreased (0.075269 --> 0.075128).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0651569\n",
      "\tspeed: 0.0395s/iter; left time: 694.7535s\n",
      "\titers: 200, epoch: 22 | loss: 0.0639169\n",
      "\tspeed: 0.0172s/iter; left time: 301.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0643803 Vali Loss: 0.0751306 Test Loss: 0.0848329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0624616\n",
      "\tspeed: 0.0372s/iter; left time: 646.0726s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664957\n",
      "\tspeed: 0.0204s/iter; left time: 352.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0642933 Vali Loss: 0.0750855 Test Loss: 0.0847189\n",
      "Validation loss decreased (0.075128 --> 0.075086).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0623684\n",
      "\tspeed: 0.0373s/iter; left time: 639.8563s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610922\n",
      "\tspeed: 0.0200s/iter; left time: 340.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0642667 Vali Loss: 0.0750529 Test Loss: 0.0847872\n",
      "Validation loss decreased (0.075086 --> 0.075053).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0652105\n",
      "\tspeed: 0.0332s/iter; left time: 562.6504s\n",
      "\titers: 200, epoch: 25 | loss: 0.0639769\n",
      "\tspeed: 0.0157s/iter; left time: 263.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0642460 Vali Loss: 0.0751374 Test Loss: 0.0846082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625939\n",
      "\tspeed: 0.0337s/iter; left time: 562.8130s\n",
      "\titers: 200, epoch: 26 | loss: 0.0640413\n",
      "\tspeed: 0.0167s/iter; left time: 277.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0640232 Vali Loss: 0.0749121 Test Loss: 0.0845331\n",
      "Validation loss decreased (0.075053 --> 0.074912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0642469\n",
      "\tspeed: 0.0348s/iter; left time: 572.6832s\n",
      "\titers: 200, epoch: 27 | loss: 0.0613592\n",
      "\tspeed: 0.0185s/iter; left time: 303.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0638458 Vali Loss: 0.0749898 Test Loss: 0.0846806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0614823\n",
      "\tspeed: 0.0383s/iter; left time: 622.4494s\n",
      "\titers: 200, epoch: 28 | loss: 0.0616128\n",
      "\tspeed: 0.0210s/iter; left time: 338.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0638617 Vali Loss: 0.0749273 Test Loss: 0.0846279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0627873\n",
      "\tspeed: 0.0391s/iter; left time: 626.5873s\n",
      "\titers: 200, epoch: 29 | loss: 0.0679921\n",
      "\tspeed: 0.0210s/iter; left time: 334.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0638065 Vali Loss: 0.0749684 Test Loss: 0.0847077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0666346\n",
      "\tspeed: 0.0301s/iter; left time: 475.5780s\n",
      "\titers: 200, epoch: 30 | loss: 0.0670567\n",
      "\tspeed: 0.0170s/iter; left time: 266.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0637055 Vali Loss: 0.0749422 Test Loss: 0.0846726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0660578\n",
      "\tspeed: 0.0380s/iter; left time: 592.1679s\n",
      "\titers: 200, epoch: 31 | loss: 0.0668724\n",
      "\tspeed: 0.0200s/iter; left time: 310.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0639426 Vali Loss: 0.0749136 Test Loss: 0.0845153\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0656317\n",
      "\tspeed: 0.0375s/iter; left time: 575.9219s\n",
      "\titers: 200, epoch: 32 | loss: 0.0668339\n",
      "\tspeed: 0.0171s/iter; left time: 260.2535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0636324 Vali Loss: 0.0750255 Test Loss: 0.0847232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671994\n",
      "\tspeed: 0.0361s/iter; left time: 545.8035s\n",
      "\titers: 200, epoch: 33 | loss: 0.0623513\n",
      "\tspeed: 0.0169s/iter; left time: 254.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0640435 Vali Loss: 0.0749408 Test Loss: 0.0844788\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0638304\n",
      "\tspeed: 0.0371s/iter; left time: 553.5098s\n",
      "\titers: 200, epoch: 34 | loss: 0.0659373\n",
      "\tspeed: 0.0194s/iter; left time: 288.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0636193 Vali Loss: 0.0749466 Test Loss: 0.0845033\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0619262\n",
      "\tspeed: 0.0351s/iter; left time: 515.6227s\n",
      "\titers: 200, epoch: 35 | loss: 0.0638632\n",
      "\tspeed: 0.0172s/iter; left time: 251.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0636754 Vali Loss: 0.0748628 Test Loss: 0.0844507\n",
      "Validation loss decreased (0.074912 --> 0.074863).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618416\n",
      "\tspeed: 0.0390s/iter; left time: 563.9220s\n",
      "\titers: 200, epoch: 36 | loss: 0.0602060\n",
      "\tspeed: 0.0184s/iter; left time: 264.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0635923 Vali Loss: 0.0748915 Test Loss: 0.0844548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0620921\n",
      "\tspeed: 0.0375s/iter; left time: 534.5969s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619549\n",
      "\tspeed: 0.0220s/iter; left time: 311.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0635743 Vali Loss: 0.0748421 Test Loss: 0.0845368\n",
      "Validation loss decreased (0.074863 --> 0.074842).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0627876\n",
      "\tspeed: 0.0385s/iter; left time: 540.0330s\n",
      "\titers: 200, epoch: 38 | loss: 0.0594055\n",
      "\tspeed: 0.0229s/iter; left time: 318.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0636778 Vali Loss: 0.0749182 Test Loss: 0.0845077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0634855\n",
      "\tspeed: 0.0383s/iter; left time: 528.7805s\n",
      "\titers: 200, epoch: 39 | loss: 0.0651536\n",
      "\tspeed: 0.0183s/iter; left time: 249.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0637075 Vali Loss: 0.0748838 Test Loss: 0.0845183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0661026\n",
      "\tspeed: 0.0358s/iter; left time: 485.5397s\n",
      "\titers: 200, epoch: 40 | loss: 0.0572510\n",
      "\tspeed: 0.0180s/iter; left time: 242.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0635356 Vali Loss: 0.0748458 Test Loss: 0.0844856\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0611172\n",
      "\tspeed: 0.0359s/iter; left time: 479.2574s\n",
      "\titers: 200, epoch: 41 | loss: 0.0627527\n",
      "\tspeed: 0.0171s/iter; left time: 226.8176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0637003 Vali Loss: 0.0748669 Test Loss: 0.0844824\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0648655\n",
      "\tspeed: 0.0355s/iter; left time: 466.3024s\n",
      "\titers: 200, epoch: 42 | loss: 0.0644647\n",
      "\tspeed: 0.0180s/iter; left time: 233.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0634609 Vali Loss: 0.0748767 Test Loss: 0.0845775\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0628619\n",
      "\tspeed: 0.0347s/iter; left time: 447.4538s\n",
      "\titers: 200, epoch: 43 | loss: 0.0639417\n",
      "\tspeed: 0.0187s/iter; left time: 238.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0636445 Vali Loss: 0.0749155 Test Loss: 0.0845783\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0661944\n",
      "\tspeed: 0.0352s/iter; left time: 446.0006s\n",
      "\titers: 200, epoch: 44 | loss: 0.0659364\n",
      "\tspeed: 0.0210s/iter; left time: 264.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0639953 Vali Loss: 0.0748791 Test Loss: 0.0844123\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636500\n",
      "\tspeed: 0.0373s/iter; left time: 464.6726s\n",
      "\titers: 200, epoch: 45 | loss: 0.0604052\n",
      "\tspeed: 0.0190s/iter; left time: 234.3637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0635161 Vali Loss: 0.0748828 Test Loss: 0.0845705\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0625768\n",
      "\tspeed: 0.0362s/iter; left time: 442.1906s\n",
      "\titers: 200, epoch: 46 | loss: 0.0619401\n",
      "\tspeed: 0.0212s/iter; left time: 256.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0635319 Vali Loss: 0.0748403 Test Loss: 0.0844395\n",
      "Validation loss decreased (0.074842 --> 0.074840).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0650877\n",
      "\tspeed: 0.0376s/iter; left time: 451.0013s\n",
      "\titers: 200, epoch: 47 | loss: 0.0635316\n",
      "\tspeed: 0.0209s/iter; left time: 248.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0635355 Vali Loss: 0.0748786 Test Loss: 0.0844128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0650298\n",
      "\tspeed: 0.0344s/iter; left time: 404.7000s\n",
      "\titers: 200, epoch: 48 | loss: 0.0657075\n",
      "\tspeed: 0.0193s/iter; left time: 224.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0635475 Vali Loss: 0.0748775 Test Loss: 0.0844445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0649474\n",
      "\tspeed: 0.0373s/iter; left time: 430.8019s\n",
      "\titers: 200, epoch: 49 | loss: 0.0600979\n",
      "\tspeed: 0.0179s/iter; left time: 205.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0635202 Vali Loss: 0.0748605 Test Loss: 0.0845111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0639095\n",
      "\tspeed: 0.0381s/iter; left time: 431.1170s\n",
      "\titers: 200, epoch: 50 | loss: 0.0624497\n",
      "\tspeed: 0.0171s/iter; left time: 192.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0636276 Vali Loss: 0.0748693 Test Loss: 0.0844540\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0624300\n",
      "\tspeed: 0.0354s/iter; left time: 392.6215s\n",
      "\titers: 200, epoch: 51 | loss: 0.0634616\n",
      "\tspeed: 0.0173s/iter; left time: 190.0283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0635002 Vali Loss: 0.0748973 Test Loss: 0.0845749\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0620393\n",
      "\tspeed: 0.0350s/iter; left time: 380.1946s\n",
      "\titers: 200, epoch: 52 | loss: 0.0645444\n",
      "\tspeed: 0.0187s/iter; left time: 201.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0633845 Vali Loss: 0.0748605 Test Loss: 0.0845031\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0619776\n",
      "\tspeed: 0.0394s/iter; left time: 420.1795s\n",
      "\titers: 200, epoch: 53 | loss: 0.0661225\n",
      "\tspeed: 0.0195s/iter; left time: 205.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0634164 Vali Loss: 0.0748804 Test Loss: 0.0845459\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0633279\n",
      "\tspeed: 0.0339s/iter; left time: 353.7490s\n",
      "\titers: 200, epoch: 54 | loss: 0.0645414\n",
      "\tspeed: 0.0157s/iter; left time: 162.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0634517 Vali Loss: 0.0748712 Test Loss: 0.0845036\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0650333\n",
      "\tspeed: 0.0349s/iter; left time: 356.3420s\n",
      "\titers: 200, epoch: 55 | loss: 0.0611133\n",
      "\tspeed: 0.0188s/iter; left time: 190.0733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0634390 Vali Loss: 0.0748915 Test Loss: 0.0845454\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0641902\n",
      "\tspeed: 0.0339s/iter; left time: 338.2805s\n",
      "\titers: 200, epoch: 56 | loss: 0.0604664\n",
      "\tspeed: 0.0174s/iter; left time: 171.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0635355 Vali Loss: 0.0748537 Test Loss: 0.0843582\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02091984450817108, rmse:0.14463694393634796, mae:0.0844394713640213, rse:0.559494137763977\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2446093\n",
      "\tspeed: 0.0246s/iter; left time: 548.1710s\n",
      "\titers: 200, epoch: 1 | loss: 0.2217702\n",
      "\tspeed: 0.0174s/iter; left time: 387.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.2449674 Vali Loss: 0.1815714 Test Loss: 0.1897557\n",
      "Validation loss decreased (inf --> 0.181571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1313936\n",
      "\tspeed: 0.0360s/iter; left time: 794.6332s\n",
      "\titers: 200, epoch: 2 | loss: 0.1012539\n",
      "\tspeed: 0.0241s/iter; left time: 529.7331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1350062 Vali Loss: 0.0968014 Test Loss: 0.1073580\n",
      "Validation loss decreased (0.181571 --> 0.096801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0867328\n",
      "\tspeed: 0.0373s/iter; left time: 815.3986s\n",
      "\titers: 200, epoch: 3 | loss: 0.0862665\n",
      "\tspeed: 0.0195s/iter; left time: 424.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0897080 Vali Loss: 0.0874246 Test Loss: 0.0945556\n",
      "Validation loss decreased (0.096801 --> 0.087425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0819778\n",
      "\tspeed: 0.0396s/iter; left time: 856.2242s\n",
      "\titers: 200, epoch: 4 | loss: 0.0843108\n",
      "\tspeed: 0.0183s/iter; left time: 393.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0816666 Vali Loss: 0.0834707 Test Loss: 0.0928928\n",
      "Validation loss decreased (0.087425 --> 0.083471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759629\n",
      "\tspeed: 0.0399s/iter; left time: 854.7824s\n",
      "\titers: 200, epoch: 5 | loss: 0.0718963\n",
      "\tspeed: 0.0176s/iter; left time: 374.4081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0767960 Vali Loss: 0.0799672 Test Loss: 0.0924122\n",
      "Validation loss decreased (0.083471 --> 0.079967).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0746661\n",
      "\tspeed: 0.0346s/iter; left time: 732.1125s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739022\n",
      "\tspeed: 0.0174s/iter; left time: 366.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734231 Vali Loss: 0.0790923 Test Loss: 0.0913114\n",
      "Validation loss decreased (0.079967 --> 0.079092).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694684\n",
      "\tspeed: 0.0352s/iter; left time: 738.3004s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759875\n",
      "\tspeed: 0.0162s/iter; left time: 338.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0712908 Vali Loss: 0.0781400 Test Loss: 0.0877073\n",
      "Validation loss decreased (0.079092 --> 0.078140).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0733793\n",
      "\tspeed: 0.0410s/iter; left time: 850.9109s\n",
      "\titers: 200, epoch: 8 | loss: 0.0696252\n",
      "\tspeed: 0.0208s/iter; left time: 428.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0696699 Vali Loss: 0.0776174 Test Loss: 0.0866298\n",
      "Validation loss decreased (0.078140 --> 0.077617).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690542\n",
      "\tspeed: 0.0398s/iter; left time: 816.4347s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675303\n",
      "\tspeed: 0.0179s/iter; left time: 366.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0685719 Vali Loss: 0.0774060 Test Loss: 0.0864485\n",
      "Validation loss decreased (0.077617 --> 0.077406).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0678312\n",
      "\tspeed: 0.0380s/iter; left time: 771.2927s\n",
      "\titers: 200, epoch: 10 | loss: 0.0711859\n",
      "\tspeed: 0.0168s/iter; left time: 338.1701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0677425 Vali Loss: 0.0771071 Test Loss: 0.0855391\n",
      "Validation loss decreased (0.077406 --> 0.077107).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0650157\n",
      "\tspeed: 0.0390s/iter; left time: 782.3651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0657995\n",
      "\tspeed: 0.0172s/iter; left time: 343.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0673803 Vali Loss: 0.0770425 Test Loss: 0.0861407\n",
      "Validation loss decreased (0.077107 --> 0.077042).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0680712\n",
      "\tspeed: 0.0371s/iter; left time: 735.1608s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690869\n",
      "\tspeed: 0.0180s/iter; left time: 356.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0667022 Vali Loss: 0.0766534 Test Loss: 0.0858711\n",
      "Validation loss decreased (0.077042 --> 0.076653).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0706065\n",
      "\tspeed: 0.0377s/iter; left time: 738.9574s\n",
      "\titers: 200, epoch: 13 | loss: 0.0691158\n",
      "\tspeed: 0.0203s/iter; left time: 395.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0662631 Vali Loss: 0.0766493 Test Loss: 0.0857974\n",
      "Validation loss decreased (0.076653 --> 0.076649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650391\n",
      "\tspeed: 0.0433s/iter; left time: 839.8504s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663259\n",
      "\tspeed: 0.0173s/iter; left time: 333.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0657481 Vali Loss: 0.0766774 Test Loss: 0.0856799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0691288\n",
      "\tspeed: 0.0328s/iter; left time: 628.2445s\n",
      "\titers: 200, epoch: 15 | loss: 0.0636347\n",
      "\tspeed: 0.0157s/iter; left time: 299.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0657803 Vali Loss: 0.0765203 Test Loss: 0.0855134\n",
      "Validation loss decreased (0.076649 --> 0.076520).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0623043\n",
      "\tspeed: 0.0356s/iter; left time: 673.7724s\n",
      "\titers: 200, epoch: 16 | loss: 0.0647576\n",
      "\tspeed: 0.0179s/iter; left time: 336.7410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0654336 Vali Loss: 0.0769812 Test Loss: 0.0863409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0640645\n",
      "\tspeed: 0.0343s/iter; left time: 641.1819s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624860\n",
      "\tspeed: 0.0179s/iter; left time: 332.3172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0653116 Vali Loss: 0.0767633 Test Loss: 0.0858200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0630177\n",
      "\tspeed: 0.0389s/iter; left time: 719.4118s\n",
      "\titers: 200, epoch: 18 | loss: 0.0639060\n",
      "\tspeed: 0.0206s/iter; left time: 379.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0648783 Vali Loss: 0.0761723 Test Loss: 0.0851316\n",
      "Validation loss decreased (0.076520 --> 0.076172).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0627690\n",
      "\tspeed: 0.0359s/iter; left time: 656.3431s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683923\n",
      "\tspeed: 0.0181s/iter; left time: 328.0311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0648472 Vali Loss: 0.0760337 Test Loss: 0.0852844\n",
      "Validation loss decreased (0.076172 --> 0.076034).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0623018\n",
      "\tspeed: 0.0362s/iter; left time: 652.7391s\n",
      "\titers: 200, epoch: 20 | loss: 0.0657438\n",
      "\tspeed: 0.0220s/iter; left time: 395.1394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0646764 Vali Loss: 0.0762291 Test Loss: 0.0855199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0665043\n",
      "\tspeed: 0.0361s/iter; left time: 643.9840s\n",
      "\titers: 200, epoch: 21 | loss: 0.0653400\n",
      "\tspeed: 0.0186s/iter; left time: 329.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0646404 Vali Loss: 0.0759536 Test Loss: 0.0852054\n",
      "Validation loss decreased (0.076034 --> 0.075954).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0636809\n",
      "\tspeed: 0.0388s/iter; left time: 682.3331s\n",
      "\titers: 200, epoch: 22 | loss: 0.0667308\n",
      "\tspeed: 0.0222s/iter; left time: 389.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0643446 Vali Loss: 0.0760542 Test Loss: 0.0853412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0678711\n",
      "\tspeed: 0.0380s/iter; left time: 659.5736s\n",
      "\titers: 200, epoch: 23 | loss: 0.0616475\n",
      "\tspeed: 0.0209s/iter; left time: 360.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0642238 Vali Loss: 0.0761785 Test Loss: 0.0853315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0623842\n",
      "\tspeed: 0.0355s/iter; left time: 608.5326s\n",
      "\titers: 200, epoch: 24 | loss: 0.0603101\n",
      "\tspeed: 0.0192s/iter; left time: 326.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0641477 Vali Loss: 0.0759779 Test Loss: 0.0853329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0616180\n",
      "\tspeed: 0.0352s/iter; left time: 595.3258s\n",
      "\titers: 200, epoch: 25 | loss: 0.0644377\n",
      "\tspeed: 0.0211s/iter; left time: 354.9564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0638871 Vali Loss: 0.0760421 Test Loss: 0.0853012\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0667616\n",
      "\tspeed: 0.0399s/iter; left time: 665.7238s\n",
      "\titers: 200, epoch: 26 | loss: 0.0601611\n",
      "\tspeed: 0.0184s/iter; left time: 305.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0642054 Vali Loss: 0.0758871 Test Loss: 0.0851538\n",
      "Validation loss decreased (0.075954 --> 0.075887).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0618366\n",
      "\tspeed: 0.0360s/iter; left time: 593.4644s\n",
      "\titers: 200, epoch: 27 | loss: 0.0629379\n",
      "\tspeed: 0.0200s/iter; left time: 328.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0639449 Vali Loss: 0.0758402 Test Loss: 0.0850552\n",
      "Validation loss decreased (0.075887 --> 0.075840).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0643823\n",
      "\tspeed: 0.0359s/iter; left time: 583.8597s\n",
      "\titers: 200, epoch: 28 | loss: 0.0676356\n",
      "\tspeed: 0.0183s/iter; left time: 294.8865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0639708 Vali Loss: 0.0758775 Test Loss: 0.0851740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0639481\n",
      "\tspeed: 0.0343s/iter; left time: 549.4883s\n",
      "\titers: 200, epoch: 29 | loss: 0.0630168\n",
      "\tspeed: 0.0174s/iter; left time: 276.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0637855 Vali Loss: 0.0758397 Test Loss: 0.0850368\n",
      "Validation loss decreased (0.075840 --> 0.075840).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0698281\n",
      "\tspeed: 0.0364s/iter; left time: 575.8914s\n",
      "\titers: 200, epoch: 30 | loss: 0.0636687\n",
      "\tspeed: 0.0180s/iter; left time: 282.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0637639 Vali Loss: 0.0759107 Test Loss: 0.0851402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0621104\n",
      "\tspeed: 0.0367s/iter; left time: 571.5245s\n",
      "\titers: 200, epoch: 31 | loss: 0.0663121\n",
      "\tspeed: 0.0158s/iter; left time: 244.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0636354 Vali Loss: 0.0759704 Test Loss: 0.0852528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0638244\n",
      "\tspeed: 0.0346s/iter; left time: 530.6121s\n",
      "\titers: 200, epoch: 32 | loss: 0.0607384\n",
      "\tspeed: 0.0191s/iter; left time: 291.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0636515 Vali Loss: 0.0758884 Test Loss: 0.0852065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630194\n",
      "\tspeed: 0.0389s/iter; left time: 589.2559s\n",
      "\titers: 200, epoch: 33 | loss: 0.0616903\n",
      "\tspeed: 0.0186s/iter; left time: 279.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0636816 Vali Loss: 0.0758252 Test Loss: 0.0850444\n",
      "Validation loss decreased (0.075840 --> 0.075825).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0629164\n",
      "\tspeed: 0.0384s/iter; left time: 572.1363s\n",
      "\titers: 200, epoch: 34 | loss: 0.0672251\n",
      "\tspeed: 0.0170s/iter; left time: 251.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0636950 Vali Loss: 0.0758219 Test Loss: 0.0850294\n",
      "Validation loss decreased (0.075825 --> 0.075822).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0605771\n",
      "\tspeed: 0.0385s/iter; left time: 565.6019s\n",
      "\titers: 200, epoch: 35 | loss: 0.0618750\n",
      "\tspeed: 0.0199s/iter; left time: 290.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0635444 Vali Loss: 0.0757740 Test Loss: 0.0849731\n",
      "Validation loss decreased (0.075822 --> 0.075774).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0659335\n",
      "\tspeed: 0.0357s/iter; left time: 516.1183s\n",
      "\titers: 200, epoch: 36 | loss: 0.0606605\n",
      "\tspeed: 0.0197s/iter; left time: 282.4170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0634962 Vali Loss: 0.0757112 Test Loss: 0.0848368\n",
      "Validation loss decreased (0.075774 --> 0.075711).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0652772\n",
      "\tspeed: 0.0357s/iter; left time: 508.0296s\n",
      "\titers: 200, epoch: 37 | loss: 0.0653140\n",
      "\tspeed: 0.0191s/iter; left time: 270.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0634813 Vali Loss: 0.0757189 Test Loss: 0.0849072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0617919\n",
      "\tspeed: 0.0388s/iter; left time: 544.1098s\n",
      "\titers: 200, epoch: 38 | loss: 0.0637520\n",
      "\tspeed: 0.0191s/iter; left time: 266.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0637473 Vali Loss: 0.0756917 Test Loss: 0.0848916\n",
      "Validation loss decreased (0.075711 --> 0.075692).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0670029\n",
      "\tspeed: 0.0374s/iter; left time: 515.8746s\n",
      "\titers: 200, epoch: 39 | loss: 0.0629004\n",
      "\tspeed: 0.0206s/iter; left time: 281.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0635198 Vali Loss: 0.0758105 Test Loss: 0.0851737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0631152\n",
      "\tspeed: 0.0376s/iter; left time: 510.5817s\n",
      "\titers: 200, epoch: 40 | loss: 0.0627993\n",
      "\tspeed: 0.0172s/iter; left time: 231.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0635541 Vali Loss: 0.0757038 Test Loss: 0.0848737\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0634758\n",
      "\tspeed: 0.0341s/iter; left time: 454.4328s\n",
      "\titers: 200, epoch: 41 | loss: 0.0632113\n",
      "\tspeed: 0.0165s/iter; left time: 218.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0634345 Vali Loss: 0.0757468 Test Loss: 0.0849318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0663945\n",
      "\tspeed: 0.0361s/iter; left time: 473.6701s\n",
      "\titers: 200, epoch: 42 | loss: 0.0643766\n",
      "\tspeed: 0.0204s/iter; left time: 265.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0635677 Vali Loss: 0.0757172 Test Loss: 0.0849929\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0620287\n",
      "\tspeed: 0.0399s/iter; left time: 513.7872s\n",
      "\titers: 200, epoch: 43 | loss: 0.0614852\n",
      "\tspeed: 0.0210s/iter; left time: 268.8196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0634826 Vali Loss: 0.0756523 Test Loss: 0.0847933\n",
      "Validation loss decreased (0.075692 --> 0.075652).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0605435\n",
      "\tspeed: 0.0393s/iter; left time: 498.2599s\n",
      "\titers: 200, epoch: 44 | loss: 0.0622243\n",
      "\tspeed: 0.0181s/iter; left time: 227.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0634996 Vali Loss: 0.0758664 Test Loss: 0.0852352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0618589\n",
      "\tspeed: 0.0368s/iter; left time: 458.4308s\n",
      "\titers: 200, epoch: 45 | loss: 0.0589205\n",
      "\tspeed: 0.0186s/iter; left time: 230.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0634105 Vali Loss: 0.0756402 Test Loss: 0.0847735\n",
      "Validation loss decreased (0.075652 --> 0.075640).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0646047\n",
      "\tspeed: 0.0391s/iter; left time: 477.2857s\n",
      "\titers: 200, epoch: 46 | loss: 0.0651090\n",
      "\tspeed: 0.0229s/iter; left time: 277.9883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0633994 Vali Loss: 0.0756826 Test Loss: 0.0849173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0663008\n",
      "\tspeed: 0.0364s/iter; left time: 436.2288s\n",
      "\titers: 200, epoch: 47 | loss: 0.0584326\n",
      "\tspeed: 0.0179s/iter; left time: 213.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0634844 Vali Loss: 0.0757100 Test Loss: 0.0849540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0621919\n",
      "\tspeed: 0.0353s/iter; left time: 415.6087s\n",
      "\titers: 200, epoch: 48 | loss: 0.0654387\n",
      "\tspeed: 0.0148s/iter; left time: 172.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0634977 Vali Loss: 0.0757150 Test Loss: 0.0849744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0600066\n",
      "\tspeed: 0.0388s/iter; left time: 448.1887s\n",
      "\titers: 200, epoch: 49 | loss: 0.0632528\n",
      "\tspeed: 0.0165s/iter; left time: 189.0724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0634089 Vali Loss: 0.0756841 Test Loss: 0.0849358\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0641938\n",
      "\tspeed: 0.0360s/iter; left time: 408.0631s\n",
      "\titers: 200, epoch: 50 | loss: 0.0615548\n",
      "\tspeed: 0.0183s/iter; left time: 205.2792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0634583 Vali Loss: 0.0758243 Test Loss: 0.0851934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0612334\n",
      "\tspeed: 0.0366s/iter; left time: 406.3246s\n",
      "\titers: 200, epoch: 51 | loss: 0.0604240\n",
      "\tspeed: 0.0166s/iter; left time: 183.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0634429 Vali Loss: 0.0756985 Test Loss: 0.0849937\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0625399\n",
      "\tspeed: 0.0403s/iter; left time: 438.2784s\n",
      "\titers: 200, epoch: 52 | loss: 0.0663606\n",
      "\tspeed: 0.0185s/iter; left time: 199.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0633854 Vali Loss: 0.0756513 Test Loss: 0.0848157\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0633682\n",
      "\tspeed: 0.0369s/iter; left time: 392.7963s\n",
      "\titers: 200, epoch: 53 | loss: 0.0631271\n",
      "\tspeed: 0.0213s/iter; left time: 225.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0634585 Vali Loss: 0.0759790 Test Loss: 0.0852910\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0662492\n",
      "\tspeed: 0.0350s/iter; left time: 364.8939s\n",
      "\titers: 200, epoch: 54 | loss: 0.0609465\n",
      "\tspeed: 0.0175s/iter; left time: 180.7317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0633902 Vali Loss: 0.0756668 Test Loss: 0.0847899\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0648204\n",
      "\tspeed: 0.0364s/iter; left time: 371.6511s\n",
      "\titers: 200, epoch: 55 | loss: 0.0598931\n",
      "\tspeed: 0.0226s/iter; left time: 228.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0633780 Vali Loss: 0.0757443 Test Loss: 0.0848874\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02117375284433365, rmse:0.14551202952861786, mae:0.084773488342762, rse:0.5628792643547058\n",
      "Intermediate time for FR and pred_len 96: 00h:10m:18.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0324s/iter; left time: 720.3526s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0112s/iter; left time: 246.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0327s/iter; left time: 718.4697s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0166s/iter; left time: 363.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0373s/iter; left time: 810.4951s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0162s/iter; left time: 351.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0359s/iter; left time: 773.8074s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0179s/iter; left time: 382.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0352s/iter; left time: 750.2461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0163s/iter; left time: 345.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0385s/iter; left time: 811.1611s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0173s/iter; left time: 362.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0367s/iter; left time: 765.6934s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0185s/iter; left time: 383.6864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0349s/iter; left time: 719.6483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0164s/iter; left time: 337.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0385s/iter; left time: 785.8157s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0187s/iter; left time: 380.4280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0371s/iter; left time: 749.8274s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0161s/iter; left time: 323.2393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0341s/iter; left time: 680.5904s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0210s/iter; left time: 417.4564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0351s/iter; left time: 693.0896s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0170s/iter; left time: 334.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0366s/iter; left time: 713.6645s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0180s/iter; left time: 350.0681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0392s/iter; left time: 755.7385s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0202s/iter; left time: 387.6392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0355s/iter; left time: 676.3775s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0179s/iter; left time: 339.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0361s/iter; left time: 680.0026s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0175s/iter; left time: 328.0570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0331s/iter; left time: 617.2751s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0201s/iter; left time: 372.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0371s/iter; left time: 683.8688s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0183s/iter; left time: 335.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0378s/iter; left time: 687.1811s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0207s/iter; left time: 375.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0409s/iter; left time: 733.9519s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0210s/iter; left time: 374.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0663677\n",
      "\tspeed: 0.0371s/iter; left time: 658.2489s\n",
      "\titers: 200, epoch: 21 | loss: 0.0669994\n",
      "\tspeed: 0.0211s/iter; left time: 371.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0678149 Vali Loss: 0.0784798 Test Loss: 0.0897868\n",
      "Validation loss decreased (0.078623 --> 0.078480).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0672283\n",
      "\tspeed: 0.0375s/iter; left time: 656.9539s\n",
      "\titers: 200, epoch: 22 | loss: 0.0673161\n",
      "\tspeed: 0.0174s/iter; left time: 303.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0678036 Vali Loss: 0.0785779 Test Loss: 0.0904526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0700305\n",
      "\tspeed: 0.0358s/iter; left time: 618.8468s\n",
      "\titers: 200, epoch: 23 | loss: 0.0637901\n",
      "\tspeed: 0.0165s/iter; left time: 283.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0676334 Vali Loss: 0.0785729 Test Loss: 0.0898357\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0653326\n",
      "\tspeed: 0.0401s/iter; left time: 684.0378s\n",
      "\titers: 200, epoch: 24 | loss: 0.0694274\n",
      "\tspeed: 0.0219s/iter; left time: 371.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0675952 Vali Loss: 0.0787265 Test Loss: 0.0903373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0644151\n",
      "\tspeed: 0.0401s/iter; left time: 675.3544s\n",
      "\titers: 200, epoch: 25 | loss: 0.0662949\n",
      "\tspeed: 0.0222s/iter; left time: 372.6081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0675093 Vali Loss: 0.0784429 Test Loss: 0.0896569\n",
      "Validation loss decreased (0.078480 --> 0.078443).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0658729\n",
      "\tspeed: 0.0372s/iter; left time: 619.1834s\n",
      "\titers: 200, epoch: 26 | loss: 0.0694567\n",
      "\tspeed: 0.0183s/iter; left time: 301.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0674292 Vali Loss: 0.0784964 Test Loss: 0.0899409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0686192\n",
      "\tspeed: 0.0367s/iter; left time: 601.7259s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672854\n",
      "\tspeed: 0.0211s/iter; left time: 344.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0673598 Vali Loss: 0.0786052 Test Loss: 0.0905234\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0641365\n",
      "\tspeed: 0.0388s/iter; left time: 627.8130s\n",
      "\titers: 200, epoch: 28 | loss: 0.0674382\n",
      "\tspeed: 0.0204s/iter; left time: 328.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0673135 Vali Loss: 0.0783556 Test Loss: 0.0900815\n",
      "Validation loss decreased (0.078443 --> 0.078356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0679455\n",
      "\tspeed: 0.0339s/iter; left time: 540.1892s\n",
      "\titers: 200, epoch: 29 | loss: 0.0644956\n",
      "\tspeed: 0.0170s/iter; left time: 269.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0672827 Vali Loss: 0.0783653 Test Loss: 0.0900080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0676180\n",
      "\tspeed: 0.0392s/iter; left time: 617.1948s\n",
      "\titers: 200, epoch: 30 | loss: 0.0679972\n",
      "\tspeed: 0.0191s/iter; left time: 297.9093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0672445 Vali Loss: 0.0784439 Test Loss: 0.0901915\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0669693\n",
      "\tspeed: 0.0304s/iter; left time: 472.0698s\n",
      "\titers: 200, epoch: 31 | loss: 0.0719308\n",
      "\tspeed: 0.0161s/iter; left time: 247.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.0671927 Vali Loss: 0.0783952 Test Loss: 0.0902039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0655053\n",
      "\tspeed: 0.0359s/iter; left time: 549.4724s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652533\n",
      "\tspeed: 0.0177s/iter; left time: 268.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0670878 Vali Loss: 0.0784049 Test Loss: 0.0900689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0668145\n",
      "\tspeed: 0.0337s/iter; left time: 507.4878s\n",
      "\titers: 200, epoch: 33 | loss: 0.0658785\n",
      "\tspeed: 0.0172s/iter; left time: 257.2561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0673694 Vali Loss: 0.0783459 Test Loss: 0.0896429\n",
      "Validation loss decreased (0.078356 --> 0.078346).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0639815\n",
      "\tspeed: 0.0403s/iter; left time: 597.6040s\n",
      "\titers: 200, epoch: 34 | loss: 0.0678246\n",
      "\tspeed: 0.0188s/iter; left time: 276.8007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0671238 Vali Loss: 0.0783610 Test Loss: 0.0902388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0683998\n",
      "\tspeed: 0.0345s/iter; left time: 503.9430s\n",
      "\titers: 200, epoch: 35 | loss: 0.0657174\n",
      "\tspeed: 0.0181s/iter; left time: 262.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0670835 Vali Loss: 0.0783434 Test Loss: 0.0900946\n",
      "Validation loss decreased (0.078346 --> 0.078343).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697847\n",
      "\tspeed: 0.0389s/iter; left time: 560.4992s\n",
      "\titers: 200, epoch: 36 | loss: 0.0661649\n",
      "\tspeed: 0.0199s/iter; left time: 284.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0669770 Vali Loss: 0.0783992 Test Loss: 0.0897999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0981122\n",
      "\tspeed: 0.0368s/iter; left time: 520.8675s\n",
      "\titers: 200, epoch: 37 | loss: 0.0664383\n",
      "\tspeed: 0.0185s/iter; left time: 260.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0671933 Vali Loss: 0.0784283 Test Loss: 0.0900075\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677373\n",
      "\tspeed: 0.0354s/iter; left time: 493.1909s\n",
      "\titers: 200, epoch: 38 | loss: 0.0638908\n",
      "\tspeed: 0.0185s/iter; left time: 255.7200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0670454 Vali Loss: 0.0784088 Test Loss: 0.0903903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0651423\n",
      "\tspeed: 0.0406s/iter; left time: 556.9563s\n",
      "\titers: 200, epoch: 39 | loss: 0.0655890\n",
      "\tspeed: 0.0225s/iter; left time: 306.8620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0669028 Vali Loss: 0.0783724 Test Loss: 0.0902622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0717114\n",
      "\tspeed: 0.0348s/iter; left time: 470.0485s\n",
      "\titers: 200, epoch: 40 | loss: 0.0640477\n",
      "\tspeed: 0.0162s/iter; left time: 217.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0670078 Vali Loss: 0.0785387 Test Loss: 0.0906313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0667479\n",
      "\tspeed: 0.0357s/iter; left time: 474.5439s\n",
      "\titers: 200, epoch: 41 | loss: 0.0649812\n",
      "\tspeed: 0.0204s/iter; left time: 268.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0669177 Vali Loss: 0.0783095 Test Loss: 0.0899186\n",
      "Validation loss decreased (0.078343 --> 0.078309).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0654942\n",
      "\tspeed: 0.0372s/iter; left time: 486.1441s\n",
      "\titers: 200, epoch: 42 | loss: 0.0644555\n",
      "\tspeed: 0.0179s/iter; left time: 231.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0669488 Vali Loss: 0.0783080 Test Loss: 0.0899542\n",
      "Validation loss decreased (0.078309 --> 0.078308).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0666401\n",
      "\tspeed: 0.0372s/iter; left time: 477.1175s\n",
      "\titers: 200, epoch: 43 | loss: 0.0648314\n",
      "\tspeed: 0.0176s/iter; left time: 224.7104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0669090 Vali Loss: 0.0783652 Test Loss: 0.0899487\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682370\n",
      "\tspeed: 0.0341s/iter; left time: 429.9093s\n",
      "\titers: 200, epoch: 44 | loss: 0.0707746\n",
      "\tspeed: 0.0166s/iter; left time: 207.3079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0669577 Vali Loss: 0.0783356 Test Loss: 0.0898627\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0680339\n",
      "\tspeed: 0.0371s/iter; left time: 459.4104s\n",
      "\titers: 200, epoch: 45 | loss: 0.0697346\n",
      "\tspeed: 0.0189s/iter; left time: 232.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0668898 Vali Loss: 0.0784230 Test Loss: 0.0903625\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0658358\n",
      "\tspeed: 0.0387s/iter; left time: 470.7509s\n",
      "\titers: 200, epoch: 46 | loss: 0.0662285\n",
      "\tspeed: 0.0179s/iter; left time: 216.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0670128 Vali Loss: 0.0783513 Test Loss: 0.0899156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0658982\n",
      "\tspeed: 0.0379s/iter; left time: 452.5323s\n",
      "\titers: 200, epoch: 47 | loss: 0.0626831\n",
      "\tspeed: 0.0226s/iter; left time: 267.8196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0669430 Vali Loss: 0.0782698 Test Loss: 0.0896646\n",
      "Validation loss decreased (0.078308 --> 0.078270).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642926\n",
      "\tspeed: 0.0413s/iter; left time: 484.4621s\n",
      "\titers: 200, epoch: 48 | loss: 0.0680426\n",
      "\tspeed: 0.0206s/iter; left time: 239.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0669282 Vali Loss: 0.0782521 Test Loss: 0.0898390\n",
      "Validation loss decreased (0.078270 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0623542\n",
      "\tspeed: 0.0365s/iter; left time: 419.1187s\n",
      "\titers: 200, epoch: 49 | loss: 0.0640966\n",
      "\tspeed: 0.0178s/iter; left time: 202.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0668709 Vali Loss: 0.0783011 Test Loss: 0.0900403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0661973\n",
      "\tspeed: 0.0363s/iter; left time: 409.2284s\n",
      "\titers: 200, epoch: 50 | loss: 0.0680641\n",
      "\tspeed: 0.0186s/iter; left time: 207.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0668440 Vali Loss: 0.0785972 Test Loss: 0.0904424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0662638\n",
      "\tspeed: 0.0373s/iter; left time: 412.7194s\n",
      "\titers: 200, epoch: 51 | loss: 0.0670776\n",
      "\tspeed: 0.0199s/iter; left time: 218.2598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0669221 Vali Loss: 0.0783211 Test Loss: 0.0898956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0667211\n",
      "\tspeed: 0.0316s/iter; left time: 341.8311s\n",
      "\titers: 200, epoch: 52 | loss: 0.0690121\n",
      "\tspeed: 0.0231s/iter; left time: 247.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0668981 Vali Loss: 0.0783196 Test Loss: 0.0901165\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0746985\n",
      "\tspeed: 0.0366s/iter; left time: 388.2686s\n",
      "\titers: 200, epoch: 53 | loss: 0.0683838\n",
      "\tspeed: 0.0189s/iter; left time: 198.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0668889 Vali Loss: 0.0783335 Test Loss: 0.0899625\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0674382\n",
      "\tspeed: 0.0361s/iter; left time: 374.9931s\n",
      "\titers: 200, epoch: 54 | loss: 0.0625900\n",
      "\tspeed: 0.0184s/iter; left time: 189.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0668223 Vali Loss: 0.0783967 Test Loss: 0.0901315\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0636814\n",
      "\tspeed: 0.0372s/iter; left time: 378.0894s\n",
      "\titers: 200, epoch: 55 | loss: 0.0693940\n",
      "\tspeed: 0.0162s/iter; left time: 162.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0668968 Vali Loss: 0.0782941 Test Loss: 0.0899220\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0679491\n",
      "\tspeed: 0.0338s/iter; left time: 336.1567s\n",
      "\titers: 200, epoch: 56 | loss: 0.0683673\n",
      "\tspeed: 0.0229s/iter; left time: 225.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0669053 Vali Loss: 0.0783098 Test Loss: 0.0900202\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0712342\n",
      "\tspeed: 0.0397s/iter; left time: 385.1467s\n",
      "\titers: 200, epoch: 57 | loss: 0.0715479\n",
      "\tspeed: 0.0230s/iter; left time: 221.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0668513 Vali Loss: 0.0783565 Test Loss: 0.0901037\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0657454\n",
      "\tspeed: 0.0420s/iter; left time: 398.5693s\n",
      "\titers: 200, epoch: 58 | loss: 0.0662007\n",
      "\tspeed: 0.0180s/iter; left time: 169.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0669398 Vali Loss: 0.0783188 Test Loss: 0.0900327\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022931568324565887, rmse:0.15143172442913055, mae:0.08983904868364334, rse:0.5865094661712646\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2406601\n",
      "\tspeed: 0.0233s/iter; left time: 517.6772s\n",
      "\titers: 200, epoch: 1 | loss: 0.2214315\n",
      "\tspeed: 0.0194s/iter; left time: 429.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.2439416 Vali Loss: 0.1837158 Test Loss: 0.1905165\n",
      "Validation loss decreased (inf --> 0.183716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1252717\n",
      "\tspeed: 0.0365s/iter; left time: 802.0310s\n",
      "\titers: 200, epoch: 2 | loss: 0.0997196\n",
      "\tspeed: 0.0186s/iter; left time: 406.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.1329702 Vali Loss: 0.1005373 Test Loss: 0.1107586\n",
      "Validation loss decreased (0.183716 --> 0.100537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0938255\n",
      "\tspeed: 0.0381s/iter; left time: 827.8883s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915489\n",
      "\tspeed: 0.0208s/iter; left time: 451.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0920519 Vali Loss: 0.0898683 Test Loss: 0.0971306\n",
      "Validation loss decreased (0.100537 --> 0.089868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0844332\n",
      "\tspeed: 0.0400s/iter; left time: 861.4736s\n",
      "\titers: 200, epoch: 4 | loss: 0.0842204\n",
      "\tspeed: 0.0176s/iter; left time: 378.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0845753 Vali Loss: 0.0862688 Test Loss: 0.0969242\n",
      "Validation loss decreased (0.089868 --> 0.086269).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0763465\n",
      "\tspeed: 0.0389s/iter; left time: 828.3567s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791691\n",
      "\tspeed: 0.0189s/iter; left time: 400.0253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0797177 Vali Loss: 0.0844352 Test Loss: 0.0976003\n",
      "Validation loss decreased (0.086269 --> 0.084435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713951\n",
      "\tspeed: 0.0405s/iter; left time: 853.5277s\n",
      "\titers: 200, epoch: 6 | loss: 0.0679805\n",
      "\tspeed: 0.0164s/iter; left time: 344.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0764203 Vali Loss: 0.0827516 Test Loss: 0.0963793\n",
      "Validation loss decreased (0.084435 --> 0.082752).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0725202\n",
      "\tspeed: 0.0378s/iter; left time: 788.7399s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791608\n",
      "\tspeed: 0.0206s/iter; left time: 428.2008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0741157 Vali Loss: 0.0822265 Test Loss: 0.0931080\n",
      "Validation loss decreased (0.082752 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0727222\n",
      "\tspeed: 0.0385s/iter; left time: 795.6205s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776284\n",
      "\tspeed: 0.0229s/iter; left time: 470.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0728996 Vali Loss: 0.0819361 Test Loss: 0.0931618\n",
      "Validation loss decreased (0.082226 --> 0.081936).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722199\n",
      "\tspeed: 0.0399s/iter; left time: 813.6649s\n",
      "\titers: 200, epoch: 9 | loss: 0.0721218\n",
      "\tspeed: 0.0203s/iter; left time: 411.8048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0719492 Vali Loss: 0.0817230 Test Loss: 0.0941015\n",
      "Validation loss decreased (0.081936 --> 0.081723).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692011\n",
      "\tspeed: 0.0359s/iter; left time: 724.4225s\n",
      "\titers: 200, epoch: 10 | loss: 0.0684454\n",
      "\tspeed: 0.0171s/iter; left time: 342.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0710706 Vali Loss: 0.0811354 Test Loss: 0.0919947\n",
      "Validation loss decreased (0.081723 --> 0.081135).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0705062\n",
      "\tspeed: 0.0372s/iter; left time: 743.6857s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720357\n",
      "\tspeed: 0.0183s/iter; left time: 363.6722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0706808 Vali Loss: 0.0811571 Test Loss: 0.0935414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0677823\n",
      "\tspeed: 0.0354s/iter; left time: 698.5936s\n",
      "\titers: 200, epoch: 12 | loss: 0.0713468\n",
      "\tspeed: 0.0193s/iter; left time: 378.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0702094 Vali Loss: 0.0805435 Test Loss: 0.0918307\n",
      "Validation loss decreased (0.081135 --> 0.080543).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0672536\n",
      "\tspeed: 0.0377s/iter; left time: 736.3200s\n",
      "\titers: 200, epoch: 13 | loss: 0.0710736\n",
      "\tspeed: 0.0178s/iter; left time: 346.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0696859 Vali Loss: 0.0800864 Test Loss: 0.0917039\n",
      "Validation loss decreased (0.080543 --> 0.080086).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689039\n",
      "\tspeed: 0.0367s/iter; left time: 708.2570s\n",
      "\titers: 200, epoch: 14 | loss: 0.0638955\n",
      "\tspeed: 0.0165s/iter; left time: 317.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0694748 Vali Loss: 0.0803578 Test Loss: 0.0913581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0727906\n",
      "\tspeed: 0.0390s/iter; left time: 744.1811s\n",
      "\titers: 200, epoch: 15 | loss: 0.0683623\n",
      "\tspeed: 0.0216s/iter; left time: 410.3358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0692489 Vali Loss: 0.0800969 Test Loss: 0.0916660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659739\n",
      "\tspeed: 0.0362s/iter; left time: 683.2915s\n",
      "\titers: 200, epoch: 16 | loss: 0.0716897\n",
      "\tspeed: 0.0193s/iter; left time: 361.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0689950 Vali Loss: 0.0796784 Test Loss: 0.0917495\n",
      "Validation loss decreased (0.080086 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0680219\n",
      "\tspeed: 0.0384s/iter; left time: 714.9151s\n",
      "\titers: 200, epoch: 17 | loss: 0.0684547\n",
      "\tspeed: 0.0199s/iter; left time: 368.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0686040 Vali Loss: 0.0797242 Test Loss: 0.0915967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649704\n",
      "\tspeed: 0.0366s/iter; left time: 673.6094s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645268\n",
      "\tspeed: 0.0174s/iter; left time: 318.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0684679 Vali Loss: 0.0793499 Test Loss: 0.0909014\n",
      "Validation loss decreased (0.079678 --> 0.079350).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725169\n",
      "\tspeed: 0.0365s/iter; left time: 663.7005s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669255\n",
      "\tspeed: 0.0183s/iter; left time: 331.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0683734 Vali Loss: 0.0794145 Test Loss: 0.0911406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0636134\n",
      "\tspeed: 0.0366s/iter; left time: 656.6161s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710221\n",
      "\tspeed: 0.0175s/iter; left time: 313.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0681078 Vali Loss: 0.0794197 Test Loss: 0.0915060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0663622\n",
      "\tspeed: 0.0404s/iter; left time: 717.4198s\n",
      "\titers: 200, epoch: 21 | loss: 0.0706636\n",
      "\tspeed: 0.0182s/iter; left time: 321.2969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0679490 Vali Loss: 0.0791660 Test Loss: 0.0913030\n",
      "Validation loss decreased (0.079350 --> 0.079166).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0672757\n",
      "\tspeed: 0.0369s/iter; left time: 646.4701s\n",
      "\titers: 200, epoch: 22 | loss: 0.0654413\n",
      "\tspeed: 0.0185s/iter; left time: 321.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0679040 Vali Loss: 0.0790691 Test Loss: 0.0911685\n",
      "Validation loss decreased (0.079166 --> 0.079069).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0705021\n",
      "\tspeed: 0.0319s/iter; left time: 552.1236s\n",
      "\titers: 200, epoch: 23 | loss: 0.0658691\n",
      "\tspeed: 0.0166s/iter; left time: 285.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0676912 Vali Loss: 0.0789885 Test Loss: 0.0913348\n",
      "Validation loss decreased (0.079069 --> 0.078988).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0680787\n",
      "\tspeed: 0.0370s/iter; left time: 632.1603s\n",
      "\titers: 200, epoch: 24 | loss: 0.0676106\n",
      "\tspeed: 0.0179s/iter; left time: 303.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0676924 Vali Loss: 0.0789628 Test Loss: 0.0912996\n",
      "Validation loss decreased (0.078988 --> 0.078963).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0630342\n",
      "\tspeed: 0.0399s/iter; left time: 671.7123s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705554\n",
      "\tspeed: 0.0228s/iter; left time: 381.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0676622 Vali Loss: 0.0789210 Test Loss: 0.0909457\n",
      "Validation loss decreased (0.078963 --> 0.078921).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0685104\n",
      "\tspeed: 0.0427s/iter; left time: 709.1941s\n",
      "\titers: 200, epoch: 26 | loss: 0.0672015\n",
      "\tspeed: 0.0225s/iter; left time: 372.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0674808 Vali Loss: 0.0789927 Test Loss: 0.0912139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0692352\n",
      "\tspeed: 0.0358s/iter; left time: 587.3369s\n",
      "\titers: 200, epoch: 27 | loss: 0.0706252\n",
      "\tspeed: 0.0174s/iter; left time: 283.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0674995 Vali Loss: 0.0791205 Test Loss: 0.0914404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0684496\n",
      "\tspeed: 0.0355s/iter; left time: 574.9371s\n",
      "\titers: 200, epoch: 28 | loss: 0.0698841\n",
      "\tspeed: 0.0175s/iter; left time: 282.0194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0672856 Vali Loss: 0.0788523 Test Loss: 0.0913232\n",
      "Validation loss decreased (0.078921 --> 0.078852).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0706654\n",
      "\tspeed: 0.0381s/iter; left time: 608.7529s\n",
      "\titers: 200, epoch: 29 | loss: 0.0647682\n",
      "\tspeed: 0.0194s/iter; left time: 307.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0673149 Vali Loss: 0.0787194 Test Loss: 0.0911718\n",
      "Validation loss decreased (0.078852 --> 0.078719).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0651648\n",
      "\tspeed: 0.0375s/iter; left time: 590.6350s\n",
      "\titers: 200, epoch: 30 | loss: 0.0686515\n",
      "\tspeed: 0.0190s/iter; left time: 297.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0672983 Vali Loss: 0.0787156 Test Loss: 0.0909932\n",
      "Validation loss decreased (0.078719 --> 0.078716).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0687478\n",
      "\tspeed: 0.0370s/iter; left time: 573.6480s\n",
      "\titers: 200, epoch: 31 | loss: 0.0687590\n",
      "\tspeed: 0.0188s/iter; left time: 289.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0672880 Vali Loss: 0.0787718 Test Loss: 0.0911326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0660623\n",
      "\tspeed: 0.0349s/iter; left time: 533.1619s\n",
      "\titers: 200, epoch: 32 | loss: 0.0671192\n",
      "\tspeed: 0.0161s/iter; left time: 245.1345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0672749 Vali Loss: 0.0785819 Test Loss: 0.0910790\n",
      "Validation loss decreased (0.078716 --> 0.078582).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0639599\n",
      "\tspeed: 0.0401s/iter; left time: 604.6423s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655206\n",
      "\tspeed: 0.0170s/iter; left time: 253.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0672561 Vali Loss: 0.0786775 Test Loss: 0.0909472\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0664486\n",
      "\tspeed: 0.0355s/iter; left time: 527.5007s\n",
      "\titers: 200, epoch: 34 | loss: 0.0684379\n",
      "\tspeed: 0.0170s/iter; left time: 250.0993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0671589 Vali Loss: 0.0786497 Test Loss: 0.0912211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0703295\n",
      "\tspeed: 0.0371s/iter; left time: 542.7021s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643381\n",
      "\tspeed: 0.0219s/iter; left time: 318.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0670801 Vali Loss: 0.0785995 Test Loss: 0.0909137\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0691360\n",
      "\tspeed: 0.0387s/iter; left time: 557.4977s\n",
      "\titers: 200, epoch: 36 | loss: 0.0669846\n",
      "\tspeed: 0.0175s/iter; left time: 249.9370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0670677 Vali Loss: 0.0786263 Test Loss: 0.0911508\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0679790\n",
      "\tspeed: 0.0406s/iter; left time: 575.1984s\n",
      "\titers: 200, epoch: 37 | loss: 0.0700472\n",
      "\tspeed: 0.0216s/iter; left time: 303.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0670516 Vali Loss: 0.0786052 Test Loss: 0.0908096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677164\n",
      "\tspeed: 0.0384s/iter; left time: 535.1429s\n",
      "\titers: 200, epoch: 38 | loss: 0.0702569\n",
      "\tspeed: 0.0202s/iter; left time: 279.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0670006 Vali Loss: 0.0785800 Test Loss: 0.0908754\n",
      "Validation loss decreased (0.078582 --> 0.078580).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0678545\n",
      "\tspeed: 0.0375s/iter; left time: 514.3736s\n",
      "\titers: 200, epoch: 39 | loss: 0.0676408\n",
      "\tspeed: 0.0186s/iter; left time: 253.9790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0670695 Vali Loss: 0.0787155 Test Loss: 0.0909989\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0641628\n",
      "\tspeed: 0.0359s/iter; left time: 484.6822s\n",
      "\titers: 200, epoch: 40 | loss: 0.0706587\n",
      "\tspeed: 0.0191s/iter; left time: 256.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0669401 Vali Loss: 0.0786649 Test Loss: 0.0912266\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0686898\n",
      "\tspeed: 0.0357s/iter; left time: 474.2027s\n",
      "\titers: 200, epoch: 41 | loss: 0.0689687\n",
      "\tspeed: 0.0172s/iter; left time: 227.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0669939 Vali Loss: 0.0785778 Test Loss: 0.0910469\n",
      "Validation loss decreased (0.078580 --> 0.078578).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0621686\n",
      "\tspeed: 0.0360s/iter; left time: 470.2652s\n",
      "\titers: 200, epoch: 42 | loss: 0.0651772\n",
      "\tspeed: 0.0176s/iter; left time: 228.3447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0669335 Vali Loss: 0.0784854 Test Loss: 0.0907716\n",
      "Validation loss decreased (0.078578 --> 0.078485).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0713836\n",
      "\tspeed: 0.0381s/iter; left time: 489.0809s\n",
      "\titers: 200, epoch: 43 | loss: 0.0724558\n",
      "\tspeed: 0.0159s/iter; left time: 202.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0668876 Vali Loss: 0.0784920 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0673730\n",
      "\tspeed: 0.0374s/iter; left time: 471.7750s\n",
      "\titers: 200, epoch: 44 | loss: 0.0659128\n",
      "\tspeed: 0.0211s/iter; left time: 264.4238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0670680 Vali Loss: 0.0785726 Test Loss: 0.0908339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0656723\n",
      "\tspeed: 0.0356s/iter; left time: 440.4433s\n",
      "\titers: 200, epoch: 45 | loss: 0.0675536\n",
      "\tspeed: 0.0172s/iter; left time: 211.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0669346 Vali Loss: 0.0786157 Test Loss: 0.0910247\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0690194\n",
      "\tspeed: 0.0407s/iter; left time: 494.8277s\n",
      "\titers: 200, epoch: 46 | loss: 0.0691908\n",
      "\tspeed: 0.0209s/iter; left time: 252.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0669033 Vali Loss: 0.0785442 Test Loss: 0.0909548\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0697375\n",
      "\tspeed: 0.0388s/iter; left time: 463.1928s\n",
      "\titers: 200, epoch: 47 | loss: 0.0653293\n",
      "\tspeed: 0.0137s/iter; left time: 162.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0669054 Vali Loss: 0.0786002 Test Loss: 0.0910236\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0703278\n",
      "\tspeed: 0.0366s/iter; left time: 428.7631s\n",
      "\titers: 200, epoch: 48 | loss: 0.0693457\n",
      "\tspeed: 0.0230s/iter; left time: 267.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0668152 Vali Loss: 0.0785441 Test Loss: 0.0911383\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0684838\n",
      "\tspeed: 0.0358s/iter; left time: 411.0275s\n",
      "\titers: 200, epoch: 49 | loss: 0.0639397\n",
      "\tspeed: 0.0190s/iter; left time: 216.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0668930 Vali Loss: 0.0787233 Test Loss: 0.0915537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0667185\n",
      "\tspeed: 0.0402s/iter; left time: 453.6951s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669038\n",
      "\tspeed: 0.0215s/iter; left time: 240.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0669799 Vali Loss: 0.0785361 Test Loss: 0.0908527\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0674652\n",
      "\tspeed: 0.0390s/iter; left time: 430.9827s\n",
      "\titers: 200, epoch: 51 | loss: 0.0662912\n",
      "\tspeed: 0.0181s/iter; left time: 197.7913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0668049 Vali Loss: 0.0785372 Test Loss: 0.0910803\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0629704\n",
      "\tspeed: 0.0353s/iter; left time: 382.2054s\n",
      "\titers: 200, epoch: 52 | loss: 0.0659054\n",
      "\tspeed: 0.0171s/iter; left time: 183.8209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0668427 Vali Loss: 0.0785661 Test Loss: 0.0911044\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02374291978776455, rmse:0.1540873795747757, mae:0.09077159315347672, rse:0.5967950224876404\n",
      "Intermediate time for FR and pred_len 168: 00h:10m:26.44s\n",
      "Intermediate time for FR: 00h:31m:38.69s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0363s/iter; left time: 809.5840s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0141s/iter; left time: 313.3326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0294s/iter; left time: 649.8839s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0098s/iter; left time: 215.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0314s/iter; left time: 686.2189s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0186s/iter; left time: 404.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0351s/iter; left time: 760.0351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0163s/iter; left time: 351.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0338s/iter; left time: 723.0110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0168s/iter; left time: 357.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0314s/iter; left time: 665.4200s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0157s/iter; left time: 330.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0342s/iter; left time: 717.4856s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0176s/iter; left time: 367.4511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0356s/iter; left time: 737.7888s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0181s/iter; left time: 372.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0357s/iter; left time: 732.7942s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0195s/iter; left time: 396.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0329s/iter; left time: 666.6697s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0175s/iter; left time: 352.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0345s/iter; left time: 692.6716s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0157s/iter; left time: 312.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0354s/iter; left time: 702.3626s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0211s/iter; left time: 416.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0378s/iter; left time: 740.4090s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0214s/iter; left time: 417.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0368s/iter; left time: 714.4040s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0151s/iter; left time: 291.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0370s/iter; left time: 709.2794s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0212s/iter; left time: 404.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0319s/iter; left time: 603.3889s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0160s/iter; left time: 302.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0333s/iter; left time: 623.5789s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0133s/iter; left time: 248.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0336s/iter; left time: 621.7030s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0179s/iter; left time: 329.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0365s/iter; left time: 665.9051s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0176s/iter; left time: 320.1576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0340s/iter; left time: 613.8782s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0191s/iter; left time: 342.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0636579\n",
      "\tspeed: 0.0347s/iter; left time: 618.6410s\n",
      "\titers: 200, epoch: 21 | loss: 0.0684156\n",
      "\tspeed: 0.0168s/iter; left time: 298.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0633922 Vali Loss: 0.0604795 Test Loss: 0.0628369\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0617232\n",
      "\tspeed: 0.0335s/iter; left time: 589.1841s\n",
      "\titers: 200, epoch: 22 | loss: 0.0608547\n",
      "\tspeed: 0.0173s/iter; left time: 302.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0631224 Vali Loss: 0.0599889 Test Loss: 0.0626463\n",
      "Validation loss decreased (0.060343 --> 0.059989).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592435\n",
      "\tspeed: 0.0336s/iter; left time: 583.6504s\n",
      "\titers: 200, epoch: 23 | loss: 0.0632939\n",
      "\tspeed: 0.0190s/iter; left time: 328.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0629821 Vali Loss: 0.0600816 Test Loss: 0.0626648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0598919\n",
      "\tspeed: 0.0268s/iter; left time: 458.9040s\n",
      "\titers: 200, epoch: 24 | loss: 0.0626087\n",
      "\tspeed: 0.0098s/iter; left time: 167.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0628714 Vali Loss: 0.0598187 Test Loss: 0.0625466\n",
      "Validation loss decreased (0.059989 --> 0.059819).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0609628\n",
      "\tspeed: 0.0341s/iter; left time: 577.1581s\n",
      "\titers: 200, epoch: 25 | loss: 0.0664621\n",
      "\tspeed: 0.0171s/iter; left time: 287.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0628192 Vali Loss: 0.0597902 Test Loss: 0.0625925\n",
      "Validation loss decreased (0.059819 --> 0.059790).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0608600\n",
      "\tspeed: 0.0360s/iter; left time: 601.4608s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600900\n",
      "\tspeed: 0.0182s/iter; left time: 302.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0625666 Vali Loss: 0.0595580 Test Loss: 0.0623209\n",
      "Validation loss decreased (0.059790 --> 0.059558).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0646851\n",
      "\tspeed: 0.0333s/iter; left time: 547.9827s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633536\n",
      "\tspeed: 0.0173s/iter; left time: 282.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0625305 Vali Loss: 0.0596706 Test Loss: 0.0622908\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0621080\n",
      "\tspeed: 0.0342s/iter; left time: 556.0614s\n",
      "\titers: 200, epoch: 28 | loss: 0.0643726\n",
      "\tspeed: 0.0178s/iter; left time: 286.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0626719 Vali Loss: 0.0595797 Test Loss: 0.0623563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0635776\n",
      "\tspeed: 0.0313s/iter; left time: 501.3096s\n",
      "\titers: 200, epoch: 29 | loss: 0.0622601\n",
      "\tspeed: 0.0153s/iter; left time: 244.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0623069 Vali Loss: 0.0596973 Test Loss: 0.0623452\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0631619\n",
      "\tspeed: 0.0301s/iter; left time: 476.0451s\n",
      "\titers: 200, epoch: 30 | loss: 0.0598195\n",
      "\tspeed: 0.0162s/iter; left time: 254.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0623270 Vali Loss: 0.0594776 Test Loss: 0.0621852\n",
      "Validation loss decreased (0.059558 --> 0.059478).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0625057\n",
      "\tspeed: 0.0318s/iter; left time: 496.2067s\n",
      "\titers: 200, epoch: 31 | loss: 0.0638103\n",
      "\tspeed: 0.0161s/iter; left time: 248.8607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0620483 Vali Loss: 0.0594568 Test Loss: 0.0621827\n",
      "Validation loss decreased (0.059478 --> 0.059457).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628317\n",
      "\tspeed: 0.0317s/iter; left time: 486.8540s\n",
      "\titers: 200, epoch: 32 | loss: 0.0585777\n",
      "\tspeed: 0.0166s/iter; left time: 252.6939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0620746 Vali Loss: 0.0594897 Test Loss: 0.0620980\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0628268\n",
      "\tspeed: 0.0352s/iter; left time: 532.7591s\n",
      "\titers: 200, epoch: 33 | loss: 0.0614122\n",
      "\tspeed: 0.0176s/iter; left time: 264.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0619883 Vali Loss: 0.0593070 Test Loss: 0.0620515\n",
      "Validation loss decreased (0.059457 --> 0.059307).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0656993\n",
      "\tspeed: 0.0322s/iter; left time: 480.0092s\n",
      "\titers: 200, epoch: 34 | loss: 0.0583804\n",
      "\tspeed: 0.0184s/iter; left time: 272.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0621983 Vali Loss: 0.0592014 Test Loss: 0.0620528\n",
      "Validation loss decreased (0.059307 --> 0.059201).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0630521\n",
      "\tspeed: 0.0384s/iter; left time: 564.1643s\n",
      "\titers: 200, epoch: 35 | loss: 0.0647735\n",
      "\tspeed: 0.0210s/iter; left time: 305.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0621645 Vali Loss: 0.0592880 Test Loss: 0.0621266\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0605291\n",
      "\tspeed: 0.0335s/iter; left time: 484.5323s\n",
      "\titers: 200, epoch: 36 | loss: 0.0630355\n",
      "\tspeed: 0.0163s/iter; left time: 234.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0619489 Vali Loss: 0.0592510 Test Loss: 0.0620053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628529\n",
      "\tspeed: 0.0367s/iter; left time: 523.1216s\n",
      "\titers: 200, epoch: 37 | loss: 0.0633543\n",
      "\tspeed: 0.0179s/iter; left time: 253.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0619418 Vali Loss: 0.0592681 Test Loss: 0.0620028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0632918\n",
      "\tspeed: 0.0296s/iter; left time: 414.6111s\n",
      "\titers: 200, epoch: 38 | loss: 0.0604434\n",
      "\tspeed: 0.0135s/iter; left time: 187.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 224 | Train Loss: 0.0618719 Vali Loss: 0.0592907 Test Loss: 0.0619844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0609300\n",
      "\tspeed: 0.0326s/iter; left time: 449.1192s\n",
      "\titers: 200, epoch: 39 | loss: 0.0603718\n",
      "\tspeed: 0.0174s/iter; left time: 238.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0618833 Vali Loss: 0.0591956 Test Loss: 0.0619580\n",
      "Validation loss decreased (0.059201 --> 0.059196).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0595688\n",
      "\tspeed: 0.0328s/iter; left time: 444.9928s\n",
      "\titers: 200, epoch: 40 | loss: 0.0539876\n",
      "\tspeed: 0.0167s/iter; left time: 225.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0619276 Vali Loss: 0.0590186 Test Loss: 0.0618840\n",
      "Validation loss decreased (0.059196 --> 0.059019).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0608221\n",
      "\tspeed: 0.0366s/iter; left time: 488.7861s\n",
      "\titers: 200, epoch: 41 | loss: 0.0619081\n",
      "\tspeed: 0.0151s/iter; left time: 200.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0619062 Vali Loss: 0.0592204 Test Loss: 0.0619333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0609454\n",
      "\tspeed: 0.0327s/iter; left time: 429.3284s\n",
      "\titers: 200, epoch: 42 | loss: 0.0601154\n",
      "\tspeed: 0.0195s/iter; left time: 253.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0618338 Vali Loss: 0.0591389 Test Loss: 0.0618955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0613626\n",
      "\tspeed: 0.0353s/iter; left time: 454.9465s\n",
      "\titers: 200, epoch: 43 | loss: 0.0631115\n",
      "\tspeed: 0.0187s/iter; left time: 239.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0618957 Vali Loss: 0.0590800 Test Loss: 0.0618907\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0629008\n",
      "\tspeed: 0.0318s/iter; left time: 402.3234s\n",
      "\titers: 200, epoch: 44 | loss: 0.0581203\n",
      "\tspeed: 0.0105s/iter; left time: 132.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0617152 Vali Loss: 0.0591108 Test Loss: 0.0618826\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636551\n",
      "\tspeed: 0.0332s/iter; left time: 412.8382s\n",
      "\titers: 200, epoch: 45 | loss: 0.0600598\n",
      "\tspeed: 0.0179s/iter; left time: 221.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0617799 Vali Loss: 0.0591952 Test Loss: 0.0619276\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0595757\n",
      "\tspeed: 0.0320s/iter; left time: 390.9836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0658892\n",
      "\tspeed: 0.0172s/iter; left time: 208.3616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0618534 Vali Loss: 0.0592182 Test Loss: 0.0619470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0637597\n",
      "\tspeed: 0.0329s/iter; left time: 394.1075s\n",
      "\titers: 200, epoch: 47 | loss: 0.0567419\n",
      "\tspeed: 0.0185s/iter; left time: 220.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0617180 Vali Loss: 0.0591394 Test Loss: 0.0618530\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0655076\n",
      "\tspeed: 0.0342s/iter; left time: 402.4209s\n",
      "\titers: 200, epoch: 48 | loss: 0.0621627\n",
      "\tspeed: 0.0179s/iter; left time: 208.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0616754 Vali Loss: 0.0591051 Test Loss: 0.0618874\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0585296\n",
      "\tspeed: 0.0333s/iter; left time: 384.6352s\n",
      "\titers: 200, epoch: 49 | loss: 0.0647142\n",
      "\tspeed: 0.0164s/iter; left time: 187.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0616484 Vali Loss: 0.0590416 Test Loss: 0.0618605\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0597669\n",
      "\tspeed: 0.0325s/iter; left time: 368.0314s\n",
      "\titers: 200, epoch: 50 | loss: 0.0630897\n",
      "\tspeed: 0.0178s/iter; left time: 200.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0621644 Vali Loss: 0.0590834 Test Loss: 0.0618355\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010859525762498379, rmse:0.1042090505361557, mae:0.06188397854566574, rse:0.39375466108322144\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2800024\n",
      "\tspeed: 0.0175s/iter; left time: 391.2437s\n",
      "\titers: 200, epoch: 1 | loss: 0.2565308\n",
      "\tspeed: 0.0179s/iter; left time: 397.7819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.2769537 Vali Loss: 0.1967411 Test Loss: 0.2045412\n",
      "Validation loss decreased (inf --> 0.196741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471140\n",
      "\tspeed: 0.0273s/iter; left time: 602.2628s\n",
      "\titers: 200, epoch: 2 | loss: 0.1187794\n",
      "\tspeed: 0.0118s/iter; left time: 258.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 224 | Train Loss: 0.1558379 Vali Loss: 0.0886813 Test Loss: 0.0902449\n",
      "Validation loss decreased (0.196741 --> 0.088681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994043\n",
      "\tspeed: 0.0350s/iter; left time: 765.6007s\n",
      "\titers: 200, epoch: 3 | loss: 0.0909980\n",
      "\tspeed: 0.0183s/iter; left time: 397.3917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0989681 Vali Loss: 0.0795341 Test Loss: 0.0814914\n",
      "Validation loss decreased (0.088681 --> 0.079534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0899246\n",
      "\tspeed: 0.0351s/iter; left time: 758.1873s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844858\n",
      "\tspeed: 0.0198s/iter; left time: 426.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0877668 Vali Loss: 0.0763881 Test Loss: 0.0789538\n",
      "Validation loss decreased (0.079534 --> 0.076388).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0789782\n",
      "\tspeed: 0.0352s/iter; left time: 753.2156s\n",
      "\titers: 200, epoch: 5 | loss: 0.0776984\n",
      "\tspeed: 0.0176s/iter; left time: 375.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0813410 Vali Loss: 0.0742040 Test Loss: 0.0753333\n",
      "Validation loss decreased (0.076388 --> 0.074204).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817973\n",
      "\tspeed: 0.0373s/iter; left time: 789.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0777035\n",
      "\tspeed: 0.0179s/iter; left time: 377.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0777122 Vali Loss: 0.0707489 Test Loss: 0.0715350\n",
      "Validation loss decreased (0.074204 --> 0.070749).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783837\n",
      "\tspeed: 0.0385s/iter; left time: 807.0541s\n",
      "\titers: 200, epoch: 7 | loss: 0.0750453\n",
      "\tspeed: 0.0186s/iter; left time: 388.7195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0744820 Vali Loss: 0.0677601 Test Loss: 0.0687978\n",
      "Validation loss decreased (0.070749 --> 0.067760).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782167\n",
      "\tspeed: 0.0330s/iter; left time: 684.8901s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762185\n",
      "\tspeed: 0.0196s/iter; left time: 404.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0723486 Vali Loss: 0.0665194 Test Loss: 0.0681631\n",
      "Validation loss decreased (0.067760 --> 0.066519).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0719319\n",
      "\tspeed: 0.0311s/iter; left time: 637.1896s\n",
      "\titers: 200, epoch: 9 | loss: 0.0729036\n",
      "\tspeed: 0.0166s/iter; left time: 338.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0707993 Vali Loss: 0.0652852 Test Loss: 0.0671969\n",
      "Validation loss decreased (0.066519 --> 0.065285).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0697719\n",
      "\tspeed: 0.0345s/iter; left time: 699.4742s\n",
      "\titers: 200, epoch: 10 | loss: 0.0669461\n",
      "\tspeed: 0.0194s/iter; left time: 391.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0695666 Vali Loss: 0.0644584 Test Loss: 0.0664166\n",
      "Validation loss decreased (0.065285 --> 0.064458).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657162\n",
      "\tspeed: 0.0354s/iter; left time: 710.2200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708782\n",
      "\tspeed: 0.0203s/iter; left time: 404.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0685621 Vali Loss: 0.0636904 Test Loss: 0.0658297\n",
      "Validation loss decreased (0.064458 --> 0.063690).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0681091\n",
      "\tspeed: 0.0378s/iter; left time: 749.5832s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657380\n",
      "\tspeed: 0.0173s/iter; left time: 341.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0673740 Vali Loss: 0.0629184 Test Loss: 0.0653686\n",
      "Validation loss decreased (0.063690 --> 0.062918).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0648409\n",
      "\tspeed: 0.0355s/iter; left time: 696.8751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0676044\n",
      "\tspeed: 0.0167s/iter; left time: 325.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0664828 Vali Loss: 0.0624158 Test Loss: 0.0646993\n",
      "Validation loss decreased (0.062918 --> 0.062416).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0625931\n",
      "\tspeed: 0.0355s/iter; left time: 688.4851s\n",
      "\titers: 200, epoch: 14 | loss: 0.0675450\n",
      "\tspeed: 0.0174s/iter; left time: 335.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0661881 Vali Loss: 0.0624158 Test Loss: 0.0645311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0642792\n",
      "\tspeed: 0.0363s/iter; left time: 696.4342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0630810\n",
      "\tspeed: 0.0175s/iter; left time: 333.5196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0654435 Vali Loss: 0.0616787 Test Loss: 0.0638697\n",
      "Validation loss decreased (0.062416 --> 0.061679).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659622\n",
      "\tspeed: 0.0333s/iter; left time: 631.6570s\n",
      "\titers: 200, epoch: 16 | loss: 0.0648140\n",
      "\tspeed: 0.0181s/iter; left time: 341.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0650331 Vali Loss: 0.0611787 Test Loss: 0.0635631\n",
      "Validation loss decreased (0.061679 --> 0.061179).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632138\n",
      "\tspeed: 0.0335s/iter; left time: 626.3096s\n",
      "\titers: 200, epoch: 17 | loss: 0.0657867\n",
      "\tspeed: 0.0161s/iter; left time: 300.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0648311 Vali Loss: 0.0618507 Test Loss: 0.0641396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631447\n",
      "\tspeed: 0.0331s/iter; left time: 612.0035s\n",
      "\titers: 200, epoch: 18 | loss: 0.0629477\n",
      "\tspeed: 0.0162s/iter; left time: 297.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0644778 Vali Loss: 0.0618359 Test Loss: 0.0640122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0666737\n",
      "\tspeed: 0.0337s/iter; left time: 616.0134s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644217\n",
      "\tspeed: 0.0180s/iter; left time: 327.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0642466 Vali Loss: 0.0605997 Test Loss: 0.0629325\n",
      "Validation loss decreased (0.061179 --> 0.060600).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0658719\n",
      "\tspeed: 0.0344s/iter; left time: 620.0577s\n",
      "\titers: 200, epoch: 20 | loss: 0.0618839\n",
      "\tspeed: 0.0187s/iter; left time: 335.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0637577 Vali Loss: 0.0605858 Test Loss: 0.0627764\n",
      "Validation loss decreased (0.060600 --> 0.060586).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0653563\n",
      "\tspeed: 0.0346s/iter; left time: 615.9956s\n",
      "\titers: 200, epoch: 21 | loss: 0.0624877\n",
      "\tspeed: 0.0183s/iter; left time: 324.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0636068 Vali Loss: 0.0604504 Test Loss: 0.0628039\n",
      "Validation loss decreased (0.060586 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0683355\n",
      "\tspeed: 0.0325s/iter; left time: 572.3115s\n",
      "\titers: 200, epoch: 22 | loss: 0.0639780\n",
      "\tspeed: 0.0165s/iter; left time: 288.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0633847 Vali Loss: 0.0601827 Test Loss: 0.0624981\n",
      "Validation loss decreased (0.060450 --> 0.060183).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618977\n",
      "\tspeed: 0.0354s/iter; left time: 614.8544s\n",
      "\titers: 200, epoch: 23 | loss: 0.0635058\n",
      "\tspeed: 0.0195s/iter; left time: 336.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0632648 Vali Loss: 0.0601221 Test Loss: 0.0624841\n",
      "Validation loss decreased (0.060183 --> 0.060122).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0685568\n",
      "\tspeed: 0.0319s/iter; left time: 547.7992s\n",
      "\titers: 200, epoch: 24 | loss: 0.0617276\n",
      "\tspeed: 0.0163s/iter; left time: 278.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0631657 Vali Loss: 0.0599461 Test Loss: 0.0623289\n",
      "Validation loss decreased (0.060122 --> 0.059946).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0612943\n",
      "\tspeed: 0.0367s/iter; left time: 620.5150s\n",
      "\titers: 200, epoch: 25 | loss: 0.0613715\n",
      "\tspeed: 0.0187s/iter; left time: 313.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0630194 Vali Loss: 0.0598214 Test Loss: 0.0622472\n",
      "Validation loss decreased (0.059946 --> 0.059821).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0616365\n",
      "\tspeed: 0.0365s/iter; left time: 610.3578s\n",
      "\titers: 200, epoch: 26 | loss: 0.0625531\n",
      "\tspeed: 0.0188s/iter; left time: 312.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0629436 Vali Loss: 0.0600481 Test Loss: 0.0624270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0595656\n",
      "\tspeed: 0.0399s/iter; left time: 657.2897s\n",
      "\titers: 200, epoch: 27 | loss: 0.0580215\n",
      "\tspeed: 0.0196s/iter; left time: 321.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0629101 Vali Loss: 0.0599677 Test Loss: 0.0624291\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0595673\n",
      "\tspeed: 0.0339s/iter; left time: 551.0297s\n",
      "\titers: 200, epoch: 28 | loss: 0.0604597\n",
      "\tspeed: 0.0189s/iter; left time: 306.0274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0627764 Vali Loss: 0.0597563 Test Loss: 0.0620716\n",
      "Validation loss decreased (0.059821 --> 0.059756).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0610145\n",
      "\tspeed: 0.0362s/iter; left time: 579.6246s\n",
      "\titers: 200, epoch: 29 | loss: 0.0678734\n",
      "\tspeed: 0.0193s/iter; left time: 307.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0628354 Vali Loss: 0.0596368 Test Loss: 0.0620405\n",
      "Validation loss decreased (0.059756 --> 0.059637).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0604661\n",
      "\tspeed: 0.0391s/iter; left time: 618.5613s\n",
      "\titers: 200, epoch: 30 | loss: 0.0575804\n",
      "\tspeed: 0.0218s/iter; left time: 341.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0626474 Vali Loss: 0.0598288 Test Loss: 0.0621470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0618770\n",
      "\tspeed: 0.0357s/iter; left time: 556.1371s\n",
      "\titers: 200, epoch: 31 | loss: 0.0584592\n",
      "\tspeed: 0.0191s/iter; left time: 296.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0625613 Vali Loss: 0.0598233 Test Loss: 0.0622778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0607475\n",
      "\tspeed: 0.0352s/iter; left time: 540.0544s\n",
      "\titers: 200, epoch: 32 | loss: 0.0630998\n",
      "\tspeed: 0.0188s/iter; left time: 286.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0624705 Vali Loss: 0.0598062 Test Loss: 0.0621475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0629692\n",
      "\tspeed: 0.0369s/iter; left time: 558.9205s\n",
      "\titers: 200, epoch: 33 | loss: 0.0629765\n",
      "\tspeed: 0.0169s/iter; left time: 254.6174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0624585 Vali Loss: 0.0595935 Test Loss: 0.0619383\n",
      "Validation loss decreased (0.059637 --> 0.059593).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0619376\n",
      "\tspeed: 0.0387s/iter; left time: 576.8766s\n",
      "\titers: 200, epoch: 34 | loss: 0.0628307\n",
      "\tspeed: 0.0191s/iter; left time: 282.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0623878 Vali Loss: 0.0596400 Test Loss: 0.0620877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0625874\n",
      "\tspeed: 0.0366s/iter; left time: 537.4677s\n",
      "\titers: 200, epoch: 35 | loss: 0.0600728\n",
      "\tspeed: 0.0192s/iter; left time: 279.4762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0622915 Vali Loss: 0.0595726 Test Loss: 0.0619388\n",
      "Validation loss decreased (0.059593 --> 0.059573).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0589112\n",
      "\tspeed: 0.0353s/iter; left time: 510.2816s\n",
      "\titers: 200, epoch: 36 | loss: 0.0629685\n",
      "\tspeed: 0.0178s/iter; left time: 256.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0622441 Vali Loss: 0.0594508 Test Loss: 0.0618298\n",
      "Validation loss decreased (0.059573 --> 0.059451).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0596345\n",
      "\tspeed: 0.0396s/iter; left time: 563.4152s\n",
      "\titers: 200, epoch: 37 | loss: 0.0658240\n",
      "\tspeed: 0.0176s/iter; left time: 248.5687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0621255 Vali Loss: 0.0594057 Test Loss: 0.0618365\n",
      "Validation loss decreased (0.059451 --> 0.059406).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0586868\n",
      "\tspeed: 0.0385s/iter; left time: 539.9364s\n",
      "\titers: 200, epoch: 38 | loss: 0.0643889\n",
      "\tspeed: 0.0214s/iter; left time: 298.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0621273 Vali Loss: 0.0592569 Test Loss: 0.0617459\n",
      "Validation loss decreased (0.059406 --> 0.059257).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0636054\n",
      "\tspeed: 0.0333s/iter; left time: 459.4748s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607086\n",
      "\tspeed: 0.0157s/iter; left time: 215.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.0620737 Vali Loss: 0.0593783 Test Loss: 0.0617540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0611944\n",
      "\tspeed: 0.0341s/iter; left time: 462.9152s\n",
      "\titers: 200, epoch: 40 | loss: 0.0638018\n",
      "\tspeed: 0.0170s/iter; left time: 228.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0621858 Vali Loss: 0.0594381 Test Loss: 0.0618958\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0621031\n",
      "\tspeed: 0.0336s/iter; left time: 447.7917s\n",
      "\titers: 200, epoch: 41 | loss: 0.0670178\n",
      "\tspeed: 0.0170s/iter; left time: 224.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0622197 Vali Loss: 0.0595200 Test Loss: 0.0618521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0614138\n",
      "\tspeed: 0.0313s/iter; left time: 410.1276s\n",
      "\titers: 200, epoch: 42 | loss: 0.0640670\n",
      "\tspeed: 0.0161s/iter; left time: 209.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0620228 Vali Loss: 0.0593863 Test Loss: 0.0617962\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0599074\n",
      "\tspeed: 0.0357s/iter; left time: 459.6720s\n",
      "\titers: 200, epoch: 43 | loss: 0.0657019\n",
      "\tspeed: 0.0242s/iter; left time: 309.1158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0620586 Vali Loss: 0.0593569 Test Loss: 0.0617540\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0636532\n",
      "\tspeed: 0.0402s/iter; left time: 509.0967s\n",
      "\titers: 200, epoch: 44 | loss: 0.0665709\n",
      "\tspeed: 0.0169s/iter; left time: 211.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0622552 Vali Loss: 0.0594424 Test Loss: 0.0618573\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0624063\n",
      "\tspeed: 0.0405s/iter; left time: 503.5572s\n",
      "\titers: 200, epoch: 45 | loss: 0.0637858\n",
      "\tspeed: 0.0192s/iter; left time: 236.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0619498 Vali Loss: 0.0593369 Test Loss: 0.0617740\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0607949\n",
      "\tspeed: 0.0356s/iter; left time: 434.4779s\n",
      "\titers: 200, epoch: 46 | loss: 0.0609457\n",
      "\tspeed: 0.0223s/iter; left time: 270.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0621098 Vali Loss: 0.0594001 Test Loss: 0.0618141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0665860\n",
      "\tspeed: 0.0358s/iter; left time: 429.5889s\n",
      "\titers: 200, epoch: 47 | loss: 0.0645591\n",
      "\tspeed: 0.0181s/iter; left time: 214.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0621447 Vali Loss: 0.0593360 Test Loss: 0.0617443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0594761\n",
      "\tspeed: 0.0355s/iter; left time: 418.1128s\n",
      "\titers: 200, epoch: 48 | loss: 0.0645299\n",
      "\tspeed: 0.0171s/iter; left time: 199.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0619675 Vali Loss: 0.0593532 Test Loss: 0.0618188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010799581184983253, rmse:0.10392103344202042, mae:0.06174592673778534, rse:0.39266642928123474\n",
      "Intermediate time for IT and pred_len 24: 00h:08m:40.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0392s/iter; left time: 874.4456s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0152s/iter; left time: 337.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0331s/iter; left time: 730.6298s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0112s/iter; left time: 246.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0313s/iter; left time: 684.4913s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0180s/iter; left time: 390.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0365s/iter; left time: 788.7908s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0198s/iter; left time: 425.8995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0347s/iter; left time: 742.9859s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0166s/iter; left time: 352.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0350s/iter; left time: 740.9787s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0193s/iter; left time: 406.8408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0390s/iter; left time: 818.2229s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0177s/iter; left time: 369.2691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0279s/iter; left time: 579.1547s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0199s/iter; left time: 410.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0406s/iter; left time: 832.1106s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0157s/iter; left time: 321.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0331s/iter; left time: 671.7247s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0154s/iter; left time: 310.1857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0347s/iter; left time: 696.0287s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0178s/iter; left time: 355.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0361s/iter; left time: 717.0811s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0160s/iter; left time: 316.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0358s/iter; left time: 701.4064s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0199s/iter; left time: 388.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0400s/iter; left time: 776.3265s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0226s/iter; left time: 435.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0275s/iter; left time: 526.4498s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0149s/iter; left time: 284.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0337s/iter; left time: 638.9956s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0190s/iter; left time: 358.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0368s/iter; left time: 688.6593s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0180s/iter; left time: 334.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0360s/iter; left time: 665.4394s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0184s/iter; left time: 338.6161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0345s/iter; left time: 629.8093s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0175s/iter; left time: 318.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0315s/iter; left time: 567.9111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0157s/iter; left time: 281.7805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0763154\n",
      "\tspeed: 0.0353s/iter; left time: 628.2619s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777684\n",
      "\tspeed: 0.0172s/iter; left time: 305.2657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0809238 Vali Loss: 0.0789384 Test Loss: 0.0843812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0852907\n",
      "\tspeed: 0.0312s/iter; left time: 549.4394s\n",
      "\titers: 200, epoch: 22 | loss: 0.0795436\n",
      "\tspeed: 0.0100s/iter; left time: 175.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0807206 Vali Loss: 0.0788067 Test Loss: 0.0840699\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0787717\n",
      "\tspeed: 0.0262s/iter; left time: 454.7530s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802156\n",
      "\tspeed: 0.0140s/iter; left time: 242.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 224 | Train Loss: 0.0806322 Vali Loss: 0.0787457 Test Loss: 0.0841000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0797972\n",
      "\tspeed: 0.0341s/iter; left time: 584.5463s\n",
      "\titers: 200, epoch: 24 | loss: 0.0778857\n",
      "\tspeed: 0.0188s/iter; left time: 320.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0805527 Vali Loss: 0.0787727 Test Loss: 0.0841434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0807684\n",
      "\tspeed: 0.0363s/iter; left time: 613.6460s\n",
      "\titers: 200, epoch: 25 | loss: 0.0813613\n",
      "\tspeed: 0.0200s/iter; left time: 336.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0804330 Vali Loss: 0.0782987 Test Loss: 0.0837620\n",
      "Validation loss decreased (0.078444 --> 0.078299).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0792543\n",
      "\tspeed: 0.0387s/iter; left time: 646.9471s\n",
      "\titers: 200, epoch: 26 | loss: 0.0843703\n",
      "\tspeed: 0.0202s/iter; left time: 336.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0805406 Vali Loss: 0.0788216 Test Loss: 0.0842155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819269\n",
      "\tspeed: 0.0341s/iter; left time: 562.3166s\n",
      "\titers: 200, epoch: 27 | loss: 0.0808097\n",
      "\tspeed: 0.0176s/iter; left time: 287.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0801705 Vali Loss: 0.0781294 Test Loss: 0.0835582\n",
      "Validation loss decreased (0.078299 --> 0.078129).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751514\n",
      "\tspeed: 0.0375s/iter; left time: 609.5550s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783330\n",
      "\tspeed: 0.0163s/iter; left time: 263.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0800339 Vali Loss: 0.0781661 Test Loss: 0.0836645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818948\n",
      "\tspeed: 0.0346s/iter; left time: 553.8573s\n",
      "\titers: 200, epoch: 29 | loss: 0.0784700\n",
      "\tspeed: 0.0186s/iter; left time: 296.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0803651 Vali Loss: 0.0783299 Test Loss: 0.0838469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0800727\n",
      "\tspeed: 0.0333s/iter; left time: 525.5340s\n",
      "\titers: 200, epoch: 30 | loss: 0.0784400\n",
      "\tspeed: 0.0168s/iter; left time: 263.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0800930 Vali Loss: 0.0782181 Test Loss: 0.0836337\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0822492\n",
      "\tspeed: 0.0360s/iter; left time: 560.2212s\n",
      "\titers: 200, epoch: 31 | loss: 0.0791047\n",
      "\tspeed: 0.0224s/iter; left time: 346.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0803353 Vali Loss: 0.0781956 Test Loss: 0.0836943\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776482\n",
      "\tspeed: 0.0378s/iter; left time: 580.9608s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857207\n",
      "\tspeed: 0.0176s/iter; left time: 268.3054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0799039 Vali Loss: 0.0781738 Test Loss: 0.0835756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0832403\n",
      "\tspeed: 0.0372s/iter; left time: 562.3496s\n",
      "\titers: 200, epoch: 33 | loss: 0.0803201\n",
      "\tspeed: 0.0209s/iter; left time: 314.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0802236 Vali Loss: 0.0782661 Test Loss: 0.0837127\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0800152\n",
      "\tspeed: 0.0361s/iter; left time: 538.9384s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801739\n",
      "\tspeed: 0.0162s/iter; left time: 239.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0799593 Vali Loss: 0.0782292 Test Loss: 0.0838448\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0809886\n",
      "\tspeed: 0.0395s/iter; left time: 580.3506s\n",
      "\titers: 200, epoch: 35 | loss: 0.0803972\n",
      "\tspeed: 0.0190s/iter; left time: 277.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0799808 Vali Loss: 0.0781636 Test Loss: 0.0836660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0812298\n",
      "\tspeed: 0.0370s/iter; left time: 535.4601s\n",
      "\titers: 200, epoch: 36 | loss: 0.0776353\n",
      "\tspeed: 0.0195s/iter; left time: 280.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0798419 Vali Loss: 0.0780852 Test Loss: 0.0836261\n",
      "Validation loss decreased (0.078129 --> 0.078085).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0789606\n",
      "\tspeed: 0.0385s/iter; left time: 548.4451s\n",
      "\titers: 200, epoch: 37 | loss: 0.0793518\n",
      "\tspeed: 0.0218s/iter; left time: 308.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0798107 Vali Loss: 0.0780603 Test Loss: 0.0835447\n",
      "Validation loss decreased (0.078085 --> 0.078060).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0815707\n",
      "\tspeed: 0.0390s/iter; left time: 546.5420s\n",
      "\titers: 200, epoch: 38 | loss: 0.0814658\n",
      "\tspeed: 0.0192s/iter; left time: 266.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0798724 Vali Loss: 0.0779505 Test Loss: 0.0835769\n",
      "Validation loss decreased (0.078060 --> 0.077950).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0809439\n",
      "\tspeed: 0.0332s/iter; left time: 458.3105s\n",
      "\titers: 200, epoch: 39 | loss: 0.0798386\n",
      "\tspeed: 0.0207s/iter; left time: 283.7195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0799884 Vali Loss: 0.0781336 Test Loss: 0.0835738\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0818783\n",
      "\tspeed: 0.0362s/iter; left time: 491.6608s\n",
      "\titers: 200, epoch: 40 | loss: 0.0758224\n",
      "\tspeed: 0.0190s/iter; left time: 256.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0797947 Vali Loss: 0.0780988 Test Loss: 0.0836096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0778328\n",
      "\tspeed: 0.0352s/iter; left time: 470.1374s\n",
      "\titers: 200, epoch: 41 | loss: 0.0801140\n",
      "\tspeed: 0.0174s/iter; left time: 230.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0796954 Vali Loss: 0.0780624 Test Loss: 0.0836007\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0805493\n",
      "\tspeed: 0.0338s/iter; left time: 443.0984s\n",
      "\titers: 200, epoch: 42 | loss: 0.0836331\n",
      "\tspeed: 0.0169s/iter; left time: 220.2601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0797554 Vali Loss: 0.0781244 Test Loss: 0.0836102\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0791316\n",
      "\tspeed: 0.0355s/iter; left time: 457.2775s\n",
      "\titers: 200, epoch: 43 | loss: 0.0795564\n",
      "\tspeed: 0.0167s/iter; left time: 214.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0797895 Vali Loss: 0.0779153 Test Loss: 0.0835645\n",
      "Validation loss decreased (0.077950 --> 0.077915).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0786589\n",
      "\tspeed: 0.0349s/iter; left time: 441.5740s\n",
      "\titers: 200, epoch: 44 | loss: 0.0807176\n",
      "\tspeed: 0.0178s/iter; left time: 223.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0798394 Vali Loss: 0.0781401 Test Loss: 0.0836471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0777596\n",
      "\tspeed: 0.0345s/iter; left time: 429.3880s\n",
      "\titers: 200, epoch: 45 | loss: 0.0773379\n",
      "\tspeed: 0.0162s/iter; left time: 199.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0797040 Vali Loss: 0.0781044 Test Loss: 0.0836482\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788197\n",
      "\tspeed: 0.0342s/iter; left time: 417.4831s\n",
      "\titers: 200, epoch: 46 | loss: 0.0752097\n",
      "\tspeed: 0.0196s/iter; left time: 237.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0797753 Vali Loss: 0.0781600 Test Loss: 0.0837251\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0798940\n",
      "\tspeed: 0.0344s/iter; left time: 412.6108s\n",
      "\titers: 200, epoch: 47 | loss: 0.0833324\n",
      "\tspeed: 0.0179s/iter; left time: 212.7451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0797246 Vali Loss: 0.0781052 Test Loss: 0.0836800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0797039\n",
      "\tspeed: 0.0343s/iter; left time: 403.2305s\n",
      "\titers: 200, epoch: 48 | loss: 0.0782020\n",
      "\tspeed: 0.0201s/iter; left time: 234.7711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0796517 Vali Loss: 0.0781125 Test Loss: 0.0837428\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0794461\n",
      "\tspeed: 0.0371s/iter; left time: 428.2211s\n",
      "\titers: 200, epoch: 49 | loss: 0.0769461\n",
      "\tspeed: 0.0199s/iter; left time: 228.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0795811 Vali Loss: 0.0780420 Test Loss: 0.0835775\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0785138\n",
      "\tspeed: 0.0343s/iter; left time: 388.7668s\n",
      "\titers: 200, epoch: 50 | loss: 0.0787498\n",
      "\tspeed: 0.0207s/iter; left time: 232.8600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0798084 Vali Loss: 0.0779912 Test Loss: 0.0835695\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0770917\n",
      "\tspeed: 0.0344s/iter; left time: 382.3453s\n",
      "\titers: 200, epoch: 51 | loss: 0.0809504\n",
      "\tspeed: 0.0198s/iter; left time: 218.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0797521 Vali Loss: 0.0780165 Test Loss: 0.0837333\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0788252\n",
      "\tspeed: 0.0355s/iter; left time: 386.6106s\n",
      "\titers: 200, epoch: 52 | loss: 0.0810328\n",
      "\tspeed: 0.0163s/iter; left time: 175.5022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0795092 Vali Loss: 0.0780881 Test Loss: 0.0835610\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0805817\n",
      "\tspeed: 0.0324s/iter; left time: 344.8458s\n",
      "\titers: 200, epoch: 53 | loss: 0.0836180\n",
      "\tspeed: 0.0152s/iter; left time: 160.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0795245 Vali Loss: 0.0779938 Test Loss: 0.0836681\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018397541716694832, rmse:0.1356375366449356, mae:0.08356448262929916, rse:0.5128601789474487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2867312\n",
      "\tspeed: 0.0162s/iter; left time: 360.3974s\n",
      "\titers: 200, epoch: 1 | loss: 0.2570210\n",
      "\tspeed: 0.0156s/iter; left time: 345.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.2844855 Vali Loss: 0.1995277 Test Loss: 0.2053783\n",
      "Validation loss decreased (inf --> 0.199528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503679\n",
      "\tspeed: 0.0346s/iter; left time: 764.8316s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246687\n",
      "\tspeed: 0.0166s/iter; left time: 365.8131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1605966 Vali Loss: 0.1068684 Test Loss: 0.1116115\n",
      "Validation loss decreased (0.199528 --> 0.106868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108144\n",
      "\tspeed: 0.0345s/iter; left time: 753.0889s\n",
      "\titers: 200, epoch: 3 | loss: 0.1062904\n",
      "\tspeed: 0.0179s/iter; left time: 388.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1122626 Vali Loss: 0.0963096 Test Loss: 0.0993764\n",
      "Validation loss decreased (0.106868 --> 0.096310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1009487\n",
      "\tspeed: 0.0349s/iter; left time: 754.9456s\n",
      "\titers: 200, epoch: 4 | loss: 0.0928750\n",
      "\tspeed: 0.0161s/iter; left time: 346.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1004968 Vali Loss: 0.0902124 Test Loss: 0.0933175\n",
      "Validation loss decreased (0.096310 --> 0.090212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0915100\n",
      "\tspeed: 0.0353s/iter; left time: 755.8424s\n",
      "\titers: 200, epoch: 5 | loss: 0.0918914\n",
      "\tspeed: 0.0172s/iter; left time: 365.9488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0939580 Vali Loss: 0.0866327 Test Loss: 0.0903473\n",
      "Validation loss decreased (0.090212 --> 0.086633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0892767\n",
      "\tspeed: 0.0354s/iter; left time: 749.2060s\n",
      "\titers: 200, epoch: 6 | loss: 0.0921808\n",
      "\tspeed: 0.0197s/iter; left time: 416.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0905779 Vali Loss: 0.0834123 Test Loss: 0.0880758\n",
      "Validation loss decreased (0.086633 --> 0.083412).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844191\n",
      "\tspeed: 0.0404s/iter; left time: 847.4499s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835324\n",
      "\tspeed: 0.0206s/iter; left time: 430.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0879606 Vali Loss: 0.0820798 Test Loss: 0.0869449\n",
      "Validation loss decreased (0.083412 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0874267\n",
      "\tspeed: 0.0374s/iter; left time: 775.6390s\n",
      "\titers: 200, epoch: 8 | loss: 0.0814885\n",
      "\tspeed: 0.0173s/iter; left time: 356.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0867589 Vali Loss: 0.0809498 Test Loss: 0.0858281\n",
      "Validation loss decreased (0.082080 --> 0.080950).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0933920\n",
      "\tspeed: 0.0418s/iter; left time: 857.2646s\n",
      "\titers: 200, epoch: 9 | loss: 0.0827512\n",
      "\tspeed: 0.0209s/iter; left time: 427.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0853610 Vali Loss: 0.0807581 Test Loss: 0.0854261\n",
      "Validation loss decreased (0.080950 --> 0.080758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817664\n",
      "\tspeed: 0.0346s/iter; left time: 701.7543s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848463\n",
      "\tspeed: 0.0186s/iter; left time: 375.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0847431 Vali Loss: 0.0806087 Test Loss: 0.0856584\n",
      "Validation loss decreased (0.080758 --> 0.080609).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0824439\n",
      "\tspeed: 0.0419s/iter; left time: 839.5748s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791895\n",
      "\tspeed: 0.0208s/iter; left time: 415.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0839303 Vali Loss: 0.0802963 Test Loss: 0.0848606\n",
      "Validation loss decreased (0.080609 --> 0.080296).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835976\n",
      "\tspeed: 0.0393s/iter; left time: 779.1067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0808127\n",
      "\tspeed: 0.0208s/iter; left time: 409.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0834124 Vali Loss: 0.0795981 Test Loss: 0.0842632\n",
      "Validation loss decreased (0.080296 --> 0.079598).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0824150\n",
      "\tspeed: 0.0375s/iter; left time: 735.1554s\n",
      "\titers: 200, epoch: 13 | loss: 0.0812877\n",
      "\tspeed: 0.0206s/iter; left time: 401.1865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0829858 Vali Loss: 0.0795164 Test Loss: 0.0844229\n",
      "Validation loss decreased (0.079598 --> 0.079516).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0832805\n",
      "\tspeed: 0.0359s/iter; left time: 696.1195s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815113\n",
      "\tspeed: 0.0205s/iter; left time: 395.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0823462 Vali Loss: 0.0795052 Test Loss: 0.0847822\n",
      "Validation loss decreased (0.079516 --> 0.079505).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0814073\n",
      "\tspeed: 0.0392s/iter; left time: 750.4020s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834194\n",
      "\tspeed: 0.0207s/iter; left time: 394.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0820061 Vali Loss: 0.0791578 Test Loss: 0.0840789\n",
      "Validation loss decreased (0.079505 --> 0.079158).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823351\n",
      "\tspeed: 0.0378s/iter; left time: 715.2841s\n",
      "\titers: 200, epoch: 16 | loss: 0.0828680\n",
      "\tspeed: 0.0177s/iter; left time: 332.8938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0816752 Vali Loss: 0.0791164 Test Loss: 0.0843509\n",
      "Validation loss decreased (0.079158 --> 0.079116).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0830026\n",
      "\tspeed: 0.0376s/iter; left time: 703.0711s\n",
      "\titers: 200, epoch: 17 | loss: 0.0819204\n",
      "\tspeed: 0.0191s/iter; left time: 355.8319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0815755 Vali Loss: 0.0789322 Test Loss: 0.0840984\n",
      "Validation loss decreased (0.079116 --> 0.078932).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0848534\n",
      "\tspeed: 0.0362s/iter; left time: 670.2043s\n",
      "\titers: 200, epoch: 18 | loss: 0.0779436\n",
      "\tspeed: 0.0190s/iter; left time: 349.2780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0814463 Vali Loss: 0.0784320 Test Loss: 0.0839459\n",
      "Validation loss decreased (0.078932 --> 0.078432).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0805601\n",
      "\tspeed: 0.0361s/iter; left time: 659.9750s\n",
      "\titers: 200, epoch: 19 | loss: 0.0789471\n",
      "\tspeed: 0.0206s/iter; left time: 373.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0809985 Vali Loss: 0.0785255 Test Loss: 0.0838930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0769660\n",
      "\tspeed: 0.0385s/iter; left time: 695.6112s\n",
      "\titers: 200, epoch: 20 | loss: 0.0833839\n",
      "\tspeed: 0.0177s/iter; left time: 318.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0809090 Vali Loss: 0.0787016 Test Loss: 0.0841642\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0833840\n",
      "\tspeed: 0.0303s/iter; left time: 540.3518s\n",
      "\titers: 200, epoch: 21 | loss: 0.0803781\n",
      "\tspeed: 0.0134s/iter; left time: 236.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0807736 Vali Loss: 0.0784016 Test Loss: 0.0842215\n",
      "Validation loss decreased (0.078432 --> 0.078402).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0785309\n",
      "\tspeed: 0.0360s/iter; left time: 633.7208s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797698\n",
      "\tspeed: 0.0128s/iter; left time: 223.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0805394 Vali Loss: 0.0780352 Test Loss: 0.0837218\n",
      "Validation loss decreased (0.078402 --> 0.078035).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0778489\n",
      "\tspeed: 0.0388s/iter; left time: 674.2796s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768977\n",
      "\tspeed: 0.0222s/iter; left time: 383.0538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0805633 Vali Loss: 0.0782534 Test Loss: 0.0839194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0790288\n",
      "\tspeed: 0.0375s/iter; left time: 643.0238s\n",
      "\titers: 200, epoch: 24 | loss: 0.0825477\n",
      "\tspeed: 0.0175s/iter; left time: 298.7736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0802575 Vali Loss: 0.0784502 Test Loss: 0.0844122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0778832\n",
      "\tspeed: 0.0316s/iter; left time: 534.6231s\n",
      "\titers: 200, epoch: 25 | loss: 0.0806138\n",
      "\tspeed: 0.0120s/iter; left time: 201.6850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0802751 Vali Loss: 0.0780333 Test Loss: 0.0839632\n",
      "Validation loss decreased (0.078035 --> 0.078033).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0834948\n",
      "\tspeed: 0.0364s/iter; left time: 607.1680s\n",
      "\titers: 200, epoch: 26 | loss: 0.0784085\n",
      "\tspeed: 0.0188s/iter; left time: 312.8261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0800483 Vali Loss: 0.0782701 Test Loss: 0.0841734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0825519\n",
      "\tspeed: 0.0380s/iter; left time: 625.9020s\n",
      "\titers: 200, epoch: 27 | loss: 0.0767762\n",
      "\tspeed: 0.0206s/iter; left time: 337.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0801905 Vali Loss: 0.0780979 Test Loss: 0.0839003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0778611\n",
      "\tspeed: 0.0377s/iter; left time: 613.1921s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783410\n",
      "\tspeed: 0.0193s/iter; left time: 311.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0801838 Vali Loss: 0.0780545 Test Loss: 0.0840371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0814524\n",
      "\tspeed: 0.0359s/iter; left time: 575.6245s\n",
      "\titers: 200, epoch: 29 | loss: 0.0768164\n",
      "\tspeed: 0.0177s/iter; left time: 282.4573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0802098 Vali Loss: 0.0779728 Test Loss: 0.0839870\n",
      "Validation loss decreased (0.078033 --> 0.077973).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789401\n",
      "\tspeed: 0.0389s/iter; left time: 615.5583s\n",
      "\titers: 200, epoch: 30 | loss: 0.0806723\n",
      "\tspeed: 0.0206s/iter; left time: 323.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0800947 Vali Loss: 0.0779029 Test Loss: 0.0837974\n",
      "Validation loss decreased (0.077973 --> 0.077903).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807305\n",
      "\tspeed: 0.0359s/iter; left time: 559.6627s\n",
      "\titers: 200, epoch: 31 | loss: 0.0782476\n",
      "\tspeed: 0.0171s/iter; left time: 264.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0798499 Vali Loss: 0.0779676 Test Loss: 0.0839404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0785601\n",
      "\tspeed: 0.0378s/iter; left time: 580.0984s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811478\n",
      "\tspeed: 0.0199s/iter; left time: 303.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0796981 Vali Loss: 0.0780462 Test Loss: 0.0840805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0804480\n",
      "\tspeed: 0.0384s/iter; left time: 581.7327s\n",
      "\titers: 200, epoch: 33 | loss: 0.0752403\n",
      "\tspeed: 0.0216s/iter; left time: 324.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0798107 Vali Loss: 0.0781049 Test Loss: 0.0839160\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0790258\n",
      "\tspeed: 0.0360s/iter; left time: 537.2640s\n",
      "\titers: 200, epoch: 34 | loss: 0.0790331\n",
      "\tspeed: 0.0163s/iter; left time: 241.8883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0797612 Vali Loss: 0.0779342 Test Loss: 0.0839198\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0816821\n",
      "\tspeed: 0.0351s/iter; left time: 515.9440s\n",
      "\titers: 200, epoch: 35 | loss: 0.0776742\n",
      "\tspeed: 0.0174s/iter; left time: 254.0119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0796725 Vali Loss: 0.0779767 Test Loss: 0.0840265\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0808088\n",
      "\tspeed: 0.0359s/iter; left time: 518.8644s\n",
      "\titers: 200, epoch: 36 | loss: 0.0797651\n",
      "\tspeed: 0.0218s/iter; left time: 313.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0794678 Vali Loss: 0.0777583 Test Loss: 0.0838494\n",
      "Validation loss decreased (0.077903 --> 0.077758).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0819605\n",
      "\tspeed: 0.0367s/iter; left time: 521.8336s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833865\n",
      "\tspeed: 0.0166s/iter; left time: 234.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0797223 Vali Loss: 0.0779314 Test Loss: 0.0838622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0792774\n",
      "\tspeed: 0.0348s/iter; left time: 487.3709s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777663\n",
      "\tspeed: 0.0160s/iter; left time: 223.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0795968 Vali Loss: 0.0777408 Test Loss: 0.0837811\n",
      "Validation loss decreased (0.077758 --> 0.077741).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765365\n",
      "\tspeed: 0.0343s/iter; left time: 473.1351s\n",
      "\titers: 200, epoch: 39 | loss: 0.0834238\n",
      "\tspeed: 0.0151s/iter; left time: 207.0480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0796541 Vali Loss: 0.0779488 Test Loss: 0.0839596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0825785\n",
      "\tspeed: 0.0355s/iter; left time: 481.4439s\n",
      "\titers: 200, epoch: 40 | loss: 0.0816366\n",
      "\tspeed: 0.0161s/iter; left time: 216.7222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0795348 Vali Loss: 0.0778374 Test Loss: 0.0840134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0794839\n",
      "\tspeed: 0.0376s/iter; left time: 501.9724s\n",
      "\titers: 200, epoch: 41 | loss: 0.0791382\n",
      "\tspeed: 0.0169s/iter; left time: 224.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0793831 Vali Loss: 0.0779585 Test Loss: 0.0839527\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0772628\n",
      "\tspeed: 0.0329s/iter; left time: 432.1714s\n",
      "\titers: 200, epoch: 42 | loss: 0.0762821\n",
      "\tspeed: 0.0155s/iter; left time: 201.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0794449 Vali Loss: 0.0779490 Test Loss: 0.0840200\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0802017\n",
      "\tspeed: 0.0340s/iter; left time: 438.0698s\n",
      "\titers: 200, epoch: 43 | loss: 0.0798228\n",
      "\tspeed: 0.0168s/iter; left time: 215.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0795483 Vali Loss: 0.0778165 Test Loss: 0.0839348\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0792961\n",
      "\tspeed: 0.0362s/iter; left time: 458.4003s\n",
      "\titers: 200, epoch: 44 | loss: 0.0813237\n",
      "\tspeed: 0.0160s/iter; left time: 200.7784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0794504 Vali Loss: 0.0777908 Test Loss: 0.0839736\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0743389\n",
      "\tspeed: 0.0338s/iter; left time: 420.7452s\n",
      "\titers: 200, epoch: 45 | loss: 0.0790860\n",
      "\tspeed: 0.0166s/iter; left time: 204.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0795811 Vali Loss: 0.0776809 Test Loss: 0.0839838\n",
      "Validation loss decreased (0.077741 --> 0.077681).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0809471\n",
      "\tspeed: 0.0365s/iter; left time: 445.5303s\n",
      "\titers: 200, epoch: 46 | loss: 0.0831727\n",
      "\tspeed: 0.0121s/iter; left time: 147.0237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0794175 Vali Loss: 0.0778423 Test Loss: 0.0839245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0821231\n",
      "\tspeed: 0.0284s/iter; left time: 340.6809s\n",
      "\titers: 200, epoch: 47 | loss: 0.0828227\n",
      "\tspeed: 0.0123s/iter; left time: 145.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.0794707 Vali Loss: 0.0778999 Test Loss: 0.0840461\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0751237\n",
      "\tspeed: 0.0382s/iter; left time: 449.4490s\n",
      "\titers: 200, epoch: 48 | loss: 0.0766488\n",
      "\tspeed: 0.0205s/iter; left time: 239.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0794241 Vali Loss: 0.0778052 Test Loss: 0.0839567\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0748905\n",
      "\tspeed: 0.0346s/iter; left time: 399.2962s\n",
      "\titers: 200, epoch: 49 | loss: 0.0808240\n",
      "\tspeed: 0.0161s/iter; left time: 183.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0794316 Vali Loss: 0.0777261 Test Loss: 0.0839457\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0789147\n",
      "\tspeed: 0.0344s/iter; left time: 389.4408s\n",
      "\titers: 200, epoch: 50 | loss: 0.0775464\n",
      "\tspeed: 0.0163s/iter; left time: 183.5268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0794408 Vali Loss: 0.0778124 Test Loss: 0.0839672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0750288\n",
      "\tspeed: 0.0368s/iter; left time: 408.7942s\n",
      "\titers: 200, epoch: 51 | loss: 0.0759603\n",
      "\tspeed: 0.0183s/iter; left time: 201.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0793937 Vali Loss: 0.0778719 Test Loss: 0.0840028\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0808131\n",
      "\tspeed: 0.0393s/iter; left time: 427.8345s\n",
      "\titers: 200, epoch: 52 | loss: 0.0777459\n",
      "\tspeed: 0.0204s/iter; left time: 220.2354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0794048 Vali Loss: 0.0778212 Test Loss: 0.0839871\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0793615\n",
      "\tspeed: 0.0369s/iter; left time: 392.7796s\n",
      "\titers: 200, epoch: 53 | loss: 0.0792381\n",
      "\tspeed: 0.0194s/iter; left time: 204.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0796601 Vali Loss: 0.0778423 Test Loss: 0.0840481\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0764310\n",
      "\tspeed: 0.0386s/iter; left time: 402.8259s\n",
      "\titers: 200, epoch: 54 | loss: 0.0797180\n",
      "\tspeed: 0.0216s/iter; left time: 222.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0794165 Vali Loss: 0.0780442 Test Loss: 0.0840546\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0832862\n",
      "\tspeed: 0.0345s/iter; left time: 352.0046s\n",
      "\titers: 200, epoch: 55 | loss: 0.0806227\n",
      "\tspeed: 0.0161s/iter; left time: 162.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0794011 Vali Loss: 0.0777452 Test Loss: 0.0840179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678180873394012, rmse:0.1366681456565857, mae:0.08398380130529404, rse:0.5167570114135742\n",
      "Intermediate time for IT and pred_len 96: 00h:09m:48.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0433s/iter; left time: 960.9602s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0216s/iter; left time: 478.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0398s/iter; left time: 875.8064s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0215s/iter; left time: 470.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0413s/iter; left time: 899.1106s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0207s/iter; left time: 447.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0383s/iter; left time: 824.8950s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0182s/iter; left time: 390.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0400s/iter; left time: 853.1770s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0177s/iter; left time: 374.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0370s/iter; left time: 780.7110s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0189s/iter; left time: 397.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0308s/iter; left time: 642.7045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0100s/iter; left time: 207.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.66s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0323s/iter; left time: 667.2952s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0210s/iter; left time: 431.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0345s/iter; left time: 703.3758s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0199s/iter; left time: 404.8504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0392s/iter; left time: 791.9837s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0180s/iter; left time: 361.8508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0405s/iter; left time: 808.0626s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0203s/iter; left time: 404.2017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0399s/iter; left time: 788.8607s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0215s/iter; left time: 422.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0369s/iter; left time: 719.5812s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0212s/iter; left time: 412.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0294s/iter; left time: 567.7689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0124s/iter; left time: 238.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0339s/iter; left time: 646.6669s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0178s/iter; left time: 338.0190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0279s/iter; left time: 526.4953s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0101s/iter; left time: 190.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0353s/iter; left time: 658.2517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0183s/iter; left time: 339.6249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0376s/iter; left time: 692.0986s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0184s/iter; left time: 337.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0343s/iter; left time: 624.6234s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0178s/iter; left time: 321.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0365s/iter; left time: 654.9902s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0115s/iter; left time: 205.9640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0872286\n",
      "\tspeed: 0.0323s/iter; left time: 573.6518s\n",
      "\titers: 200, epoch: 21 | loss: 0.0831704\n",
      "\tspeed: 0.0154s/iter; left time: 271.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0844322 Vali Loss: 0.0829054 Test Loss: 0.0884945\n",
      "Validation loss decreased (0.082979 --> 0.082905).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0867223\n",
      "\tspeed: 0.0339s/iter; left time: 594.0967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0876466\n",
      "\tspeed: 0.0171s/iter; left time: 297.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0842149 Vali Loss: 0.0827185 Test Loss: 0.0886369\n",
      "Validation loss decreased (0.082905 --> 0.082718).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0849737\n",
      "\tspeed: 0.0381s/iter; left time: 658.8538s\n",
      "\titers: 200, epoch: 23 | loss: 0.0807684\n",
      "\tspeed: 0.0182s/iter; left time: 313.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0843792 Vali Loss: 0.0829772 Test Loss: 0.0889734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0820991\n",
      "\tspeed: 0.0370s/iter; left time: 632.2143s\n",
      "\titers: 200, epoch: 24 | loss: 0.0875308\n",
      "\tspeed: 0.0185s/iter; left time: 314.0018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0840422 Vali Loss: 0.0827549 Test Loss: 0.0886977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0830779\n",
      "\tspeed: 0.0362s/iter; left time: 610.4851s\n",
      "\titers: 200, epoch: 25 | loss: 0.0835033\n",
      "\tspeed: 0.0194s/iter; left time: 325.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0839247 Vali Loss: 0.0831602 Test Loss: 0.0891277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0838137\n",
      "\tspeed: 0.0310s/iter; left time: 515.1812s\n",
      "\titers: 200, epoch: 26 | loss: 0.0828986\n",
      "\tspeed: 0.0118s/iter; left time: 194.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 223 | Train Loss: 0.0838142 Vali Loss: 0.0831872 Test Loss: 0.0890525\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0886685\n",
      "\tspeed: 0.0317s/iter; left time: 520.0605s\n",
      "\titers: 200, epoch: 27 | loss: 0.0831004\n",
      "\tspeed: 0.0214s/iter; left time: 349.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0837475 Vali Loss: 0.0827102 Test Loss: 0.0889502\n",
      "Validation loss decreased (0.082718 --> 0.082710).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0842732\n",
      "\tspeed: 0.0356s/iter; left time: 576.2975s\n",
      "\titers: 200, epoch: 28 | loss: 0.0843552\n",
      "\tspeed: 0.0207s/iter; left time: 333.1781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0835873 Vali Loss: 0.0828040 Test Loss: 0.0888971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0808670\n",
      "\tspeed: 0.0365s/iter; left time: 583.1508s\n",
      "\titers: 200, epoch: 29 | loss: 0.0816149\n",
      "\tspeed: 0.0212s/iter; left time: 336.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0837281 Vali Loss: 0.0828219 Test Loss: 0.0887696\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0834296\n",
      "\tspeed: 0.0337s/iter; left time: 530.6871s\n",
      "\titers: 200, epoch: 30 | loss: 0.0883300\n",
      "\tspeed: 0.0147s/iter; left time: 229.0516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0837617 Vali Loss: 0.0831965 Test Loss: 0.0890788\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0833962\n",
      "\tspeed: 0.0369s/iter; left time: 572.5327s\n",
      "\titers: 200, epoch: 31 | loss: 0.0828488\n",
      "\tspeed: 0.0194s/iter; left time: 299.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0835490 Vali Loss: 0.0828670 Test Loss: 0.0891433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0821873\n",
      "\tspeed: 0.0329s/iter; left time: 503.4884s\n",
      "\titers: 200, epoch: 32 | loss: 0.0837600\n",
      "\tspeed: 0.0208s/iter; left time: 316.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0834862 Vali Loss: 0.0826908 Test Loss: 0.0889840\n",
      "Validation loss decreased (0.082710 --> 0.082691).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0862068\n",
      "\tspeed: 0.0394s/iter; left time: 594.0940s\n",
      "\titers: 200, epoch: 33 | loss: 0.0837822\n",
      "\tspeed: 0.0174s/iter; left time: 259.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0837413 Vali Loss: 0.0832900 Test Loss: 0.0891910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0799349\n",
      "\tspeed: 0.0351s/iter; left time: 520.7244s\n",
      "\titers: 200, epoch: 34 | loss: 0.0856708\n",
      "\tspeed: 0.0209s/iter; left time: 307.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0834411 Vali Loss: 0.0829075 Test Loss: 0.0890537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0834171\n",
      "\tspeed: 0.0358s/iter; left time: 522.7362s\n",
      "\titers: 200, epoch: 35 | loss: 0.0852624\n",
      "\tspeed: 0.0199s/iter; left time: 288.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0835157 Vali Loss: 0.0826568 Test Loss: 0.0888614\n",
      "Validation loss decreased (0.082691 --> 0.082657).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0848151\n",
      "\tspeed: 0.0361s/iter; left time: 519.4551s\n",
      "\titers: 200, epoch: 36 | loss: 0.0836477\n",
      "\tspeed: 0.0207s/iter; left time: 296.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0834534 Vali Loss: 0.0828287 Test Loss: 0.0890043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0874976\n",
      "\tspeed: 0.0347s/iter; left time: 491.2309s\n",
      "\titers: 200, epoch: 37 | loss: 0.0843695\n",
      "\tspeed: 0.0185s/iter; left time: 259.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0833446 Vali Loss: 0.0827532 Test Loss: 0.0886072\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0841727\n",
      "\tspeed: 0.0349s/iter; left time: 487.4675s\n",
      "\titers: 200, epoch: 38 | loss: 0.0829164\n",
      "\tspeed: 0.0190s/iter; left time: 263.4394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0832881 Vali Loss: 0.0826775 Test Loss: 0.0891268\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0832476\n",
      "\tspeed: 0.0334s/iter; left time: 457.8488s\n",
      "\titers: 200, epoch: 39 | loss: 0.0828707\n",
      "\tspeed: 0.0194s/iter; left time: 264.4614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0832982 Vali Loss: 0.0825662 Test Loss: 0.0888992\n",
      "Validation loss decreased (0.082657 --> 0.082566).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824681\n",
      "\tspeed: 0.0363s/iter; left time: 490.3411s\n",
      "\titers: 200, epoch: 40 | loss: 0.0842423\n",
      "\tspeed: 0.0191s/iter; left time: 256.0461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0833420 Vali Loss: 0.0828394 Test Loss: 0.0891806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0862637\n",
      "\tspeed: 0.0334s/iter; left time: 444.1737s\n",
      "\titers: 200, epoch: 41 | loss: 0.0811936\n",
      "\tspeed: 0.0178s/iter; left time: 234.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0832356 Vali Loss: 0.0828865 Test Loss: 0.0889896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0822184\n",
      "\tspeed: 0.0351s/iter; left time: 458.6551s\n",
      "\titers: 200, epoch: 42 | loss: 0.0822396\n",
      "\tspeed: 0.0186s/iter; left time: 240.5706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0832139 Vali Loss: 0.0827310 Test Loss: 0.0889593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0891320\n",
      "\tspeed: 0.0379s/iter; left time: 485.9311s\n",
      "\titers: 200, epoch: 43 | loss: 0.0880181\n",
      "\tspeed: 0.0195s/iter; left time: 247.9655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0831549 Vali Loss: 0.0825689 Test Loss: 0.0887844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0825391\n",
      "\tspeed: 0.0324s/iter; left time: 408.5501s\n",
      "\titers: 200, epoch: 44 | loss: 0.0846757\n",
      "\tspeed: 0.0166s/iter; left time: 207.2355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0833335 Vali Loss: 0.0827998 Test Loss: 0.0888575\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0863253\n",
      "\tspeed: 0.0358s/iter; left time: 442.9141s\n",
      "\titers: 200, epoch: 45 | loss: 0.0848708\n",
      "\tspeed: 0.0189s/iter; left time: 232.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0831190 Vali Loss: 0.0826926 Test Loss: 0.0888961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0859408\n",
      "\tspeed: 0.0327s/iter; left time: 397.2646s\n",
      "\titers: 200, epoch: 46 | loss: 0.0854433\n",
      "\tspeed: 0.0193s/iter; left time: 232.5119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0831968 Vali Loss: 0.0827597 Test Loss: 0.0888974\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0827757\n",
      "\tspeed: 0.0353s/iter; left time: 421.3449s\n",
      "\titers: 200, epoch: 47 | loss: 0.0812759\n",
      "\tspeed: 0.0171s/iter; left time: 201.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0833034 Vali Loss: 0.0827946 Test Loss: 0.0890244\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0819633\n",
      "\tspeed: 0.0378s/iter; left time: 443.4833s\n",
      "\titers: 200, epoch: 48 | loss: 0.0808631\n",
      "\tspeed: 0.0186s/iter; left time: 215.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0831767 Vali Loss: 0.0826941 Test Loss: 0.0888983\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0814836\n",
      "\tspeed: 0.0322s/iter; left time: 370.4411s\n",
      "\titers: 200, epoch: 49 | loss: 0.0853858\n",
      "\tspeed: 0.0166s/iter; left time: 188.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0831401 Vali Loss: 0.0826110 Test Loss: 0.0886734\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020383721217513084, rmse:0.14277157187461853, mae:0.08889921009540558, rse:0.5403363704681396\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2783174\n",
      "\tspeed: 0.0202s/iter; left time: 447.8359s\n",
      "\titers: 200, epoch: 1 | loss: 0.2561924\n",
      "\tspeed: 0.0179s/iter; left time: 395.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.2809654 Vali Loss: 0.1980512 Test Loss: 0.2045336\n",
      "Validation loss decreased (inf --> 0.198051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1434797\n",
      "\tspeed: 0.0403s/iter; left time: 885.9479s\n",
      "\titers: 200, epoch: 2 | loss: 0.1269314\n",
      "\tspeed: 0.0180s/iter; left time: 394.8617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.1565996 Vali Loss: 0.1076144 Test Loss: 0.1134702\n",
      "Validation loss decreased (0.198051 --> 0.107614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089100\n",
      "\tspeed: 0.0390s/iter; left time: 848.8153s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123186\n",
      "\tspeed: 0.0172s/iter; left time: 371.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1130273 Vali Loss: 0.0991176 Test Loss: 0.1023243\n",
      "Validation loss decreased (0.107614 --> 0.099118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1033121\n",
      "\tspeed: 0.0391s/iter; left time: 840.9753s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008542\n",
      "\tspeed: 0.0181s/iter; left time: 388.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1024947 Vali Loss: 0.0934884 Test Loss: 0.0957750\n",
      "Validation loss decreased (0.099118 --> 0.093488).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0962598\n",
      "\tspeed: 0.0335s/iter; left time: 714.3015s\n",
      "\titers: 200, epoch: 5 | loss: 0.0895119\n",
      "\tspeed: 0.0200s/iter; left time: 424.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0966106 Vali Loss: 0.0892825 Test Loss: 0.0922814\n",
      "Validation loss decreased (0.093488 --> 0.089283).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0915172\n",
      "\tspeed: 0.0377s/iter; left time: 793.8959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0938353\n",
      "\tspeed: 0.0167s/iter; left time: 351.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0934706 Vali Loss: 0.0887328 Test Loss: 0.0932004\n",
      "Validation loss decreased (0.089283 --> 0.088733).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0929474\n",
      "\tspeed: 0.0358s/iter; left time: 747.2494s\n",
      "\titers: 200, epoch: 7 | loss: 0.0888825\n",
      "\tspeed: 0.0184s/iter; left time: 381.8534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0911639 Vali Loss: 0.0854874 Test Loss: 0.0899703\n",
      "Validation loss decreased (0.088733 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0920395\n",
      "\tspeed: 0.0337s/iter; left time: 694.9259s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905043\n",
      "\tspeed: 0.0159s/iter; left time: 325.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0895095 Vali Loss: 0.0845426 Test Loss: 0.0890754\n",
      "Validation loss decreased (0.085487 --> 0.084543).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0904310\n",
      "\tspeed: 0.0355s/iter; left time: 725.5410s\n",
      "\titers: 200, epoch: 9 | loss: 0.0930630\n",
      "\tspeed: 0.0183s/iter; left time: 372.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0884846 Vali Loss: 0.0844463 Test Loss: 0.0889952\n",
      "Validation loss decreased (0.084543 --> 0.084446).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0904131\n",
      "\tspeed: 0.0371s/iter; left time: 749.3392s\n",
      "\titers: 200, epoch: 10 | loss: 0.0884226\n",
      "\tspeed: 0.0116s/iter; left time: 233.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0876480 Vali Loss: 0.0838550 Test Loss: 0.0882083\n",
      "Validation loss decreased (0.084446 --> 0.083855).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0856049\n",
      "\tspeed: 0.0375s/iter; left time: 749.8821s\n",
      "\titers: 200, epoch: 11 | loss: 0.0874932\n",
      "\tspeed: 0.0187s/iter; left time: 371.9227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0871118 Vali Loss: 0.0848591 Test Loss: 0.0893165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0897286\n",
      "\tspeed: 0.0351s/iter; left time: 692.7140s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851763\n",
      "\tspeed: 0.0120s/iter; left time: 236.3907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 223 | Train Loss: 0.0866424 Vali Loss: 0.0835382 Test Loss: 0.0883652\n",
      "Validation loss decreased (0.083855 --> 0.083538).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0867814\n",
      "\tspeed: 0.0390s/iter; left time: 761.4409s\n",
      "\titers: 200, epoch: 13 | loss: 0.0884583\n",
      "\tspeed: 0.0180s/iter; left time: 349.6145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0861231 Vali Loss: 0.0830504 Test Loss: 0.0883958\n",
      "Validation loss decreased (0.083538 --> 0.083050).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0836019\n",
      "\tspeed: 0.0385s/iter; left time: 743.4683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0828435\n",
      "\tspeed: 0.0183s/iter; left time: 351.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0855190 Vali Loss: 0.0833236 Test Loss: 0.0886185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0838300\n",
      "\tspeed: 0.0381s/iter; left time: 726.0320s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792961\n",
      "\tspeed: 0.0186s/iter; left time: 352.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0854537 Vali Loss: 0.0836695 Test Loss: 0.0885660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0842091\n",
      "\tspeed: 0.0350s/iter; left time: 660.5194s\n",
      "\titers: 200, epoch: 16 | loss: 0.0849975\n",
      "\tspeed: 0.0173s/iter; left time: 324.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0849980 Vali Loss: 0.0830298 Test Loss: 0.0883334\n",
      "Validation loss decreased (0.083050 --> 0.083030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0841620\n",
      "\tspeed: 0.0373s/iter; left time: 694.3890s\n",
      "\titers: 200, epoch: 17 | loss: 0.0822852\n",
      "\tspeed: 0.0204s/iter; left time: 377.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0848464 Vali Loss: 0.0830064 Test Loss: 0.0890276\n",
      "Validation loss decreased (0.083030 --> 0.083006).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0883274\n",
      "\tspeed: 0.0352s/iter; left time: 647.3747s\n",
      "\titers: 200, epoch: 18 | loss: 0.0860604\n",
      "\tspeed: 0.0174s/iter; left time: 318.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0845813 Vali Loss: 0.0828156 Test Loss: 0.0883796\n",
      "Validation loss decreased (0.083006 --> 0.082816).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0873203\n",
      "\tspeed: 0.0386s/iter; left time: 701.3567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0868140\n",
      "\tspeed: 0.0220s/iter; left time: 397.7486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0846028 Vali Loss: 0.0832311 Test Loss: 0.0883496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0840057\n",
      "\tspeed: 0.0381s/iter; left time: 684.2389s\n",
      "\titers: 200, epoch: 20 | loss: 0.0849428\n",
      "\tspeed: 0.0185s/iter; left time: 331.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0843181 Vali Loss: 0.0831828 Test Loss: 0.0887545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0851120\n",
      "\tspeed: 0.0361s/iter; left time: 640.6760s\n",
      "\titers: 200, epoch: 21 | loss: 0.0872402\n",
      "\tspeed: 0.0161s/iter; left time: 283.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0840459 Vali Loss: 0.0823513 Test Loss: 0.0880426\n",
      "Validation loss decreased (0.082816 --> 0.082351).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0816963\n",
      "\tspeed: 0.0372s/iter; left time: 652.0709s\n",
      "\titers: 200, epoch: 22 | loss: 0.0857470\n",
      "\tspeed: 0.0204s/iter; left time: 354.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0839276 Vali Loss: 0.0829745 Test Loss: 0.0887041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0824122\n",
      "\tspeed: 0.0343s/iter; left time: 593.7071s\n",
      "\titers: 200, epoch: 23 | loss: 0.0832235\n",
      "\tspeed: 0.0172s/iter; left time: 295.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0837476 Vali Loss: 0.0830357 Test Loss: 0.0885183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0851167\n",
      "\tspeed: 0.0350s/iter; left time: 598.2205s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829545\n",
      "\tspeed: 0.0172s/iter; left time: 292.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0841662 Vali Loss: 0.0828512 Test Loss: 0.0883809\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0812404\n",
      "\tspeed: 0.0388s/iter; left time: 653.7673s\n",
      "\titers: 200, epoch: 25 | loss: 0.0869651\n",
      "\tspeed: 0.0189s/iter; left time: 317.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0835585 Vali Loss: 0.0829310 Test Loss: 0.0885424\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0795238\n",
      "\tspeed: 0.0368s/iter; left time: 612.3233s\n",
      "\titers: 200, epoch: 26 | loss: 0.0831725\n",
      "\tspeed: 0.0182s/iter; left time: 300.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0834923 Vali Loss: 0.0825120 Test Loss: 0.0883233\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789952\n",
      "\tspeed: 0.0359s/iter; left time: 589.2213s\n",
      "\titers: 200, epoch: 27 | loss: 0.0814784\n",
      "\tspeed: 0.0174s/iter; left time: 283.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0834275 Vali Loss: 0.0827407 Test Loss: 0.0885099\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819797\n",
      "\tspeed: 0.0357s/iter; left time: 578.3018s\n",
      "\titers: 200, epoch: 28 | loss: 0.0810981\n",
      "\tspeed: 0.0161s/iter; left time: 259.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0833911 Vali Loss: 0.0823007 Test Loss: 0.0884802\n",
      "Validation loss decreased (0.082351 --> 0.082301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796609\n",
      "\tspeed: 0.0347s/iter; left time: 553.0817s\n",
      "\titers: 200, epoch: 29 | loss: 0.0869515\n",
      "\tspeed: 0.0165s/iter; left time: 261.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0832785 Vali Loss: 0.0829458 Test Loss: 0.0884927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0782483\n",
      "\tspeed: 0.0304s/iter; left time: 477.9767s\n",
      "\titers: 200, epoch: 30 | loss: 0.0846682\n",
      "\tspeed: 0.0109s/iter; left time: 170.4762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0832658 Vali Loss: 0.0824568 Test Loss: 0.0882537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0836183\n",
      "\tspeed: 0.0383s/iter; left time: 594.3960s\n",
      "\titers: 200, epoch: 31 | loss: 0.0839608\n",
      "\tspeed: 0.0167s/iter; left time: 257.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0831332 Vali Loss: 0.0825714 Test Loss: 0.0884771\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0875373\n",
      "\tspeed: 0.0349s/iter; left time: 532.8647s\n",
      "\titers: 200, epoch: 32 | loss: 0.0825453\n",
      "\tspeed: 0.0201s/iter; left time: 305.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0832398 Vali Loss: 0.0825711 Test Loss: 0.0883840\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0852051\n",
      "\tspeed: 0.0352s/iter; left time: 530.2356s\n",
      "\titers: 200, epoch: 33 | loss: 0.0831327\n",
      "\tspeed: 0.0187s/iter; left time: 279.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0831097 Vali Loss: 0.0824194 Test Loss: 0.0884880\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0785666\n",
      "\tspeed: 0.0380s/iter; left time: 564.7034s\n",
      "\titers: 200, epoch: 34 | loss: 0.0842522\n",
      "\tspeed: 0.0205s/iter; left time: 302.1920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0829975 Vali Loss: 0.0823412 Test Loss: 0.0881475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825979\n",
      "\tspeed: 0.0356s/iter; left time: 520.0865s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819061\n",
      "\tspeed: 0.0162s/iter; left time: 235.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0831025 Vali Loss: 0.0829548 Test Loss: 0.0885586\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0854784\n",
      "\tspeed: 0.0348s/iter; left time: 501.1868s\n",
      "\titers: 200, epoch: 36 | loss: 0.0833845\n",
      "\tspeed: 0.0177s/iter; left time: 252.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0832238 Vali Loss: 0.0823038 Test Loss: 0.0883680\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0848935\n",
      "\tspeed: 0.0362s/iter; left time: 512.9260s\n",
      "\titers: 200, epoch: 37 | loss: 0.0834535\n",
      "\tspeed: 0.0178s/iter; left time: 251.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0830064 Vali Loss: 0.0823186 Test Loss: 0.0882934\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0849575\n",
      "\tspeed: 0.0378s/iter; left time: 527.7418s\n",
      "\titers: 200, epoch: 38 | loss: 0.0846332\n",
      "\tspeed: 0.0169s/iter; left time: 234.4939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0830837 Vali Loss: 0.0825377 Test Loss: 0.0883402\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020050713792443275, rmse:0.14160054922103882, mae:0.08848021179437637, rse:0.5359044671058655\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:00.37s\n",
      "Intermediate time for IT: 00h:26m:29.43s\n",
      "Total time: 02h:05m:24.78s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.0602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0216  0.1469  0.0907\n",
       "        96             0.0408  0.2019  0.1323\n",
       "        168            0.0424  0.2058  0.1381\n",
       "ES      24             0.0130  0.1136  0.0707\n",
       "        96             0.0260  0.1600  0.1033\n",
       "        168            0.0285  0.1679  0.1101\n",
       "FR      24             0.0107  0.1035  0.0590\n",
       "        96             0.0204  0.1428  0.0834\n",
       "        168            0.0225  0.1499  0.0891\n",
       "GB      24             0.0264  0.1625  0.1040\n",
       "        96             0.0488  0.2207  0.1484\n",
       "        168            0.0517  0.2273  0.1548\n",
       "IT      24             0.0106  0.1029  0.0602\n",
       "        96             0.0185  0.1360  0.0828\n",
       "        168            0.0203  0.1424  0.0881"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1567678\n",
      "\tspeed: 0.0533s/iter; left time: 1187.5793s\n",
      "\titers: 200, epoch: 1 | loss: 0.1433145\n",
      "\tspeed: 0.0290s/iter; left time: 642.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1576000 Vali Loss: 0.1551504 Test Loss: 0.1667591\n",
      "Validation loss decreased (inf --> 0.155150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031226\n",
      "\tspeed: 0.0580s/iter; left time: 1280.9229s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875558\n",
      "\tspeed: 0.0292s/iter; left time: 642.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.1013773 Vali Loss: 0.0982898 Test Loss: 0.0989775\n",
      "Validation loss decreased (0.155150 --> 0.098290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0797586\n",
      "\tspeed: 0.0578s/iter; left time: 1262.1354s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794722\n",
      "\tspeed: 0.0292s/iter; left time: 635.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0823492 Vali Loss: 0.0925360 Test Loss: 0.0942594\n",
      "Validation loss decreased (0.098290 --> 0.092536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760267\n",
      "\tspeed: 0.0570s/iter; left time: 1232.7638s\n",
      "\titers: 200, epoch: 4 | loss: 0.0783228\n",
      "\tspeed: 0.0289s/iter; left time: 622.9354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0784050 Vali Loss: 0.0904746 Test Loss: 0.0920334\n",
      "Validation loss decreased (0.092536 --> 0.090475).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0719172\n",
      "\tspeed: 0.0565s/iter; left time: 1209.5657s\n",
      "\titers: 200, epoch: 5 | loss: 0.0714680\n",
      "\tspeed: 0.0288s/iter; left time: 614.4115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0762039 Vali Loss: 0.0893666 Test Loss: 0.0909590\n",
      "Validation loss decreased (0.090475 --> 0.089367).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0756994\n",
      "\tspeed: 0.0578s/iter; left time: 1224.4085s\n",
      "\titers: 200, epoch: 6 | loss: 0.0780923\n",
      "\tspeed: 0.0295s/iter; left time: 622.4030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0748772 Vali Loss: 0.0882359 Test Loss: 0.0903265\n",
      "Validation loss decreased (0.089367 --> 0.088236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0710799\n",
      "\tspeed: 0.0583s/iter; left time: 1221.9730s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715732\n",
      "\tspeed: 0.0294s/iter; left time: 612.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0740736 Vali Loss: 0.0880114 Test Loss: 0.0901419\n",
      "Validation loss decreased (0.088236 --> 0.088011).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694230\n",
      "\tspeed: 0.0604s/iter; left time: 1251.5180s\n",
      "\titers: 200, epoch: 8 | loss: 0.0746452\n",
      "\tspeed: 0.0296s/iter; left time: 611.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.0733045 Vali Loss: 0.0874589 Test Loss: 0.0899554\n",
      "Validation loss decreased (0.088011 --> 0.087459).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742549\n",
      "\tspeed: 0.0590s/iter; left time: 1210.6128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728040\n",
      "\tspeed: 0.0292s/iter; left time: 595.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0727485 Vali Loss: 0.0871458 Test Loss: 0.0898097\n",
      "Validation loss decreased (0.087459 --> 0.087146).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769949\n",
      "\tspeed: 0.0572s/iter; left time: 1159.3042s\n",
      "\titers: 200, epoch: 10 | loss: 0.0757486\n",
      "\tspeed: 0.0290s/iter; left time: 584.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0723941 Vali Loss: 0.0869690 Test Loss: 0.0893965\n",
      "Validation loss decreased (0.087146 --> 0.086969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0711140\n",
      "\tspeed: 0.0568s/iter; left time: 1139.6722s\n",
      "\titers: 200, epoch: 11 | loss: 0.0674053\n",
      "\tspeed: 0.0297s/iter; left time: 593.4930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0719007 Vali Loss: 0.0871842 Test Loss: 0.0897539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0718379\n",
      "\tspeed: 0.0585s/iter; left time: 1159.7257s\n",
      "\titers: 200, epoch: 12 | loss: 0.0715494\n",
      "\tspeed: 0.0323s/iter; left time: 638.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0716341 Vali Loss: 0.0869635 Test Loss: 0.0896744\n",
      "Validation loss decreased (0.086969 --> 0.086963).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637034\n",
      "\tspeed: 0.0575s/iter; left time: 1127.8231s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712081\n",
      "\tspeed: 0.0321s/iter; left time: 626.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0713736 Vali Loss: 0.0869584 Test Loss: 0.0896179\n",
      "Validation loss decreased (0.086963 --> 0.086958).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0750033\n",
      "\tspeed: 0.0578s/iter; left time: 1120.1480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712781\n",
      "\tspeed: 0.0290s/iter; left time: 559.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0711929 Vali Loss: 0.0867721 Test Loss: 0.0895204\n",
      "Validation loss decreased (0.086958 --> 0.086772).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734930\n",
      "\tspeed: 0.0619s/iter; left time: 1186.5315s\n",
      "\titers: 200, epoch: 15 | loss: 0.0692435\n",
      "\tspeed: 0.0295s/iter; left time: 562.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 224 | Train Loss: 0.0709822 Vali Loss: 0.0867286 Test Loss: 0.0896428\n",
      "Validation loss decreased (0.086772 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0722989\n",
      "\tspeed: 0.0576s/iter; left time: 1090.8028s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687896\n",
      "\tspeed: 0.0293s/iter; left time: 552.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0707381 Vali Loss: 0.0868145 Test Loss: 0.0894336\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716818\n",
      "\tspeed: 0.0563s/iter; left time: 1053.7128s\n",
      "\titers: 200, epoch: 17 | loss: 0.0709396\n",
      "\tspeed: 0.0293s/iter; left time: 545.6489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0706003 Vali Loss: 0.0866975 Test Loss: 0.0896750\n",
      "Validation loss decreased (0.086729 --> 0.086697).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0790525\n",
      "\tspeed: 0.0573s/iter; left time: 1059.0334s\n",
      "\titers: 200, epoch: 18 | loss: 0.0712589\n",
      "\tspeed: 0.0329s/iter; left time: 604.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0704566 Vali Loss: 0.0867676 Test Loss: 0.0897200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0673314\n",
      "\tspeed: 0.0590s/iter; left time: 1077.0468s\n",
      "\titers: 200, epoch: 19 | loss: 0.0730108\n",
      "\tspeed: 0.0290s/iter; left time: 526.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0703885 Vali Loss: 0.0866267 Test Loss: 0.0896360\n",
      "Validation loss decreased (0.086697 --> 0.086627).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0742142\n",
      "\tspeed: 0.0568s/iter; left time: 1025.8334s\n",
      "\titers: 200, epoch: 20 | loss: 0.0673859\n",
      "\tspeed: 0.0290s/iter; left time: 520.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0702162 Vali Loss: 0.0865770 Test Loss: 0.0894810\n",
      "Validation loss decreased (0.086627 --> 0.086577).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711270\n",
      "\tspeed: 0.0584s/iter; left time: 1040.6138s\n",
      "\titers: 200, epoch: 21 | loss: 0.0674376\n",
      "\tspeed: 0.0289s/iter; left time: 512.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0701126 Vali Loss: 0.0866650 Test Loss: 0.0898014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0758714\n",
      "\tspeed: 0.0559s/iter; left time: 983.5099s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697313\n",
      "\tspeed: 0.0290s/iter; left time: 507.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0700234 Vali Loss: 0.0866472 Test Loss: 0.0897016\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0680106\n",
      "\tspeed: 0.0563s/iter; left time: 978.4705s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714861\n",
      "\tspeed: 0.0289s/iter; left time: 499.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0699360 Vali Loss: 0.0864538 Test Loss: 0.0896586\n",
      "Validation loss decreased (0.086577 --> 0.086454).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0713508\n",
      "\tspeed: 0.0569s/iter; left time: 975.6949s\n",
      "\titers: 200, epoch: 24 | loss: 0.0645775\n",
      "\tspeed: 0.0289s/iter; left time: 492.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0699065 Vali Loss: 0.0865917 Test Loss: 0.0895865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0656911\n",
      "\tspeed: 0.0596s/iter; left time: 1009.0676s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673770\n",
      "\tspeed: 0.0289s/iter; left time: 486.4220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0698670 Vali Loss: 0.0865750 Test Loss: 0.0896201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0688234\n",
      "\tspeed: 0.0602s/iter; left time: 1006.0288s\n",
      "\titers: 200, epoch: 26 | loss: 0.0730263\n",
      "\tspeed: 0.0304s/iter; left time: 504.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.0697629 Vali Loss: 0.0865399 Test Loss: 0.0896453\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0731791\n",
      "\tspeed: 0.0563s/iter; left time: 928.3013s\n",
      "\titers: 200, epoch: 27 | loss: 0.0624318\n",
      "\tspeed: 0.0292s/iter; left time: 478.5229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0697451 Vali Loss: 0.0866192 Test Loss: 0.0896429\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0682825\n",
      "\tspeed: 0.0564s/iter; left time: 917.3225s\n",
      "\titers: 200, epoch: 28 | loss: 0.0647125\n",
      "\tspeed: 0.0289s/iter; left time: 467.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0696791 Vali Loss: 0.0866909 Test Loss: 0.0896946\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0669331\n",
      "\tspeed: 0.0592s/iter; left time: 949.2462s\n",
      "\titers: 200, epoch: 29 | loss: 0.0722175\n",
      "\tspeed: 0.0295s/iter; left time: 470.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0696388 Vali Loss: 0.0866305 Test Loss: 0.0897158\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0732105\n",
      "\tspeed: 0.0559s/iter; left time: 883.9767s\n",
      "\titers: 200, epoch: 30 | loss: 0.0692417\n",
      "\tspeed: 0.0291s/iter; left time: 456.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0695984 Vali Loss: 0.0866061 Test Loss: 0.0898136\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0680631\n",
      "\tspeed: 0.0605s/iter; left time: 943.1460s\n",
      "\titers: 200, epoch: 31 | loss: 0.0740330\n",
      "\tspeed: 0.0331s/iter; left time: 511.8508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0695025 Vali Loss: 0.0865281 Test Loss: 0.0896295\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0718809\n",
      "\tspeed: 0.0583s/iter; left time: 895.7549s\n",
      "\titers: 200, epoch: 32 | loss: 0.0679506\n",
      "\tspeed: 0.0294s/iter; left time: 448.0951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0694685 Vali Loss: 0.0865405 Test Loss: 0.0896904\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0651930\n",
      "\tspeed: 0.0606s/iter; left time: 916.5154s\n",
      "\titers: 200, epoch: 33 | loss: 0.0680821\n",
      "\tspeed: 0.0317s/iter; left time: 476.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0694608 Vali Loss: 0.0865920 Test Loss: 0.0896916\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021422358229756355, rmse:0.1463637799024582, mae:0.08965858817100525, rse:0.5165380239486694\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1588158\n",
      "\tspeed: 0.0333s/iter; left time: 741.7775s\n",
      "\titers: 200, epoch: 1 | loss: 0.1462078\n",
      "\tspeed: 0.0291s/iter; left time: 645.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1556848 Vali Loss: 0.1538951 Test Loss: 0.1650706\n",
      "Validation loss decreased (inf --> 0.153895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1044551\n",
      "\tspeed: 0.0628s/iter; left time: 1386.1985s\n",
      "\titers: 200, epoch: 2 | loss: 0.0902647\n",
      "\tspeed: 0.0304s/iter; left time: 667.2164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.1027716 Vali Loss: 0.0997875 Test Loss: 0.1003337\n",
      "Validation loss decreased (0.153895 --> 0.099787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0824478\n",
      "\tspeed: 0.0625s/iter; left time: 1366.3003s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795311\n",
      "\tspeed: 0.0308s/iter; left time: 670.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.0832051 Vali Loss: 0.0932501 Test Loss: 0.0943893\n",
      "Validation loss decreased (0.099787 --> 0.093250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771114\n",
      "\tspeed: 0.0581s/iter; left time: 1256.2066s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817735\n",
      "\tspeed: 0.0289s/iter; left time: 622.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0789319 Vali Loss: 0.0907096 Test Loss: 0.0927320\n",
      "Validation loss decreased (0.093250 --> 0.090710).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0832051\n",
      "\tspeed: 0.0582s/iter; left time: 1246.4270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0820502\n",
      "\tspeed: 0.0291s/iter; left time: 619.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0766643 Vali Loss: 0.0888725 Test Loss: 0.0911360\n",
      "Validation loss decreased (0.090710 --> 0.088872).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765737\n",
      "\tspeed: 0.0601s/iter; left time: 1272.9441s\n",
      "\titers: 200, epoch: 6 | loss: 0.0734577\n",
      "\tspeed: 0.0291s/iter; left time: 614.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0752566 Vali Loss: 0.0884252 Test Loss: 0.0908005\n",
      "Validation loss decreased (0.088872 --> 0.088425).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0777500\n",
      "\tspeed: 0.0603s/iter; left time: 1263.1374s\n",
      "\titers: 200, epoch: 7 | loss: 0.0797281\n",
      "\tspeed: 0.0302s/iter; left time: 630.4076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0741993 Vali Loss: 0.0880915 Test Loss: 0.0901954\n",
      "Validation loss decreased (0.088425 --> 0.088092).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0741385\n",
      "\tspeed: 0.0585s/iter; left time: 1212.2425s\n",
      "\titers: 200, epoch: 8 | loss: 0.0705273\n",
      "\tspeed: 0.0298s/iter; left time: 614.0517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0735877 Vali Loss: 0.0875481 Test Loss: 0.0897876\n",
      "Validation loss decreased (0.088092 --> 0.087548).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0732181\n",
      "\tspeed: 0.0576s/iter; left time: 1181.5035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0731062\n",
      "\tspeed: 0.0291s/iter; left time: 593.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0730280 Vali Loss: 0.0872954 Test Loss: 0.0894275\n",
      "Validation loss decreased (0.087548 --> 0.087295).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0664002\n",
      "\tspeed: 0.0586s/iter; left time: 1188.1516s\n",
      "\titers: 200, epoch: 10 | loss: 0.0739182\n",
      "\tspeed: 0.0290s/iter; left time: 584.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0725404 Vali Loss: 0.0872385 Test Loss: 0.0895364\n",
      "Validation loss decreased (0.087295 --> 0.087239).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761131\n",
      "\tspeed: 0.0591s/iter; left time: 1185.5251s\n",
      "\titers: 200, epoch: 11 | loss: 0.0693401\n",
      "\tspeed: 0.0309s/iter; left time: 617.1146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0722172 Vali Loss: 0.0870346 Test Loss: 0.0894770\n",
      "Validation loss decreased (0.087239 --> 0.087035).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692497\n",
      "\tspeed: 0.0577s/iter; left time: 1144.6652s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763170\n",
      "\tspeed: 0.0291s/iter; left time: 573.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0719142 Vali Loss: 0.0870622 Test Loss: 0.0896482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0744886\n",
      "\tspeed: 0.0572s/iter; left time: 1121.1971s\n",
      "\titers: 200, epoch: 13 | loss: 0.0718388\n",
      "\tspeed: 0.0289s/iter; left time: 564.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0716550 Vali Loss: 0.0872170 Test Loss: 0.0894684\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0685262\n",
      "\tspeed: 0.0568s/iter; left time: 1101.4184s\n",
      "\titers: 200, epoch: 14 | loss: 0.0757356\n",
      "\tspeed: 0.0290s/iter; left time: 559.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0713553 Vali Loss: 0.0870770 Test Loss: 0.0893934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734810\n",
      "\tspeed: 0.0574s/iter; left time: 1100.5825s\n",
      "\titers: 200, epoch: 15 | loss: 0.0722407\n",
      "\tspeed: 0.0296s/iter; left time: 563.5784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0711921 Vali Loss: 0.0868378 Test Loss: 0.0894098\n",
      "Validation loss decreased (0.087035 --> 0.086838).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0760613\n",
      "\tspeed: 0.0589s/iter; left time: 1115.3399s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691151\n",
      "\tspeed: 0.0290s/iter; left time: 546.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0709419 Vali Loss: 0.0867526 Test Loss: 0.0892737\n",
      "Validation loss decreased (0.086838 --> 0.086753).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0729939\n",
      "\tspeed: 0.0574s/iter; left time: 1074.8622s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702369\n",
      "\tspeed: 0.0290s/iter; left time: 539.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0707928 Vali Loss: 0.0869487 Test Loss: 0.0895087\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706189\n",
      "\tspeed: 0.0570s/iter; left time: 1053.6926s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691679\n",
      "\tspeed: 0.0294s/iter; left time: 541.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0706949 Vali Loss: 0.0866396 Test Loss: 0.0892311\n",
      "Validation loss decreased (0.086753 --> 0.086640).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0686362\n",
      "\tspeed: 0.0584s/iter; left time: 1067.5750s\n",
      "\titers: 200, epoch: 19 | loss: 0.0763579\n",
      "\tspeed: 0.0290s/iter; left time: 527.0616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0705240 Vali Loss: 0.0867420 Test Loss: 0.0893185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0651333\n",
      "\tspeed: 0.0568s/iter; left time: 1024.1120s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710054\n",
      "\tspeed: 0.0291s/iter; left time: 521.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0703912 Vali Loss: 0.0866756 Test Loss: 0.0891829\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0688401\n",
      "\tspeed: 0.0570s/iter; left time: 1016.5085s\n",
      "\titers: 200, epoch: 21 | loss: 0.0710326\n",
      "\tspeed: 0.0291s/iter; left time: 516.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0703231 Vali Loss: 0.0867217 Test Loss: 0.0894164\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0684514\n",
      "\tspeed: 0.0583s/iter; left time: 1025.2686s\n",
      "\titers: 200, epoch: 22 | loss: 0.0719758\n",
      "\tspeed: 0.0290s/iter; left time: 508.2415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0701699 Vali Loss: 0.0868038 Test Loss: 0.0894152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0696870\n",
      "\tspeed: 0.0574s/iter; left time: 997.5526s\n",
      "\titers: 200, epoch: 23 | loss: 0.0710971\n",
      "\tspeed: 0.0296s/iter; left time: 510.7060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0701163 Vali Loss: 0.0865464 Test Loss: 0.0894158\n",
      "Validation loss decreased (0.086640 --> 0.086546).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0698774\n",
      "\tspeed: 0.0583s/iter; left time: 999.8322s\n",
      "\titers: 200, epoch: 24 | loss: 0.0669009\n",
      "\tspeed: 0.0292s/iter; left time: 498.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0699990 Vali Loss: 0.0867321 Test Loss: 0.0893289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0766677\n",
      "\tspeed: 0.0571s/iter; left time: 966.9282s\n",
      "\titers: 200, epoch: 25 | loss: 0.0676428\n",
      "\tspeed: 0.0289s/iter; left time: 486.8883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0698909 Vali Loss: 0.0866710 Test Loss: 0.0894732\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0665879\n",
      "\tspeed: 0.0573s/iter; left time: 957.0743s\n",
      "\titers: 200, epoch: 26 | loss: 0.0650151\n",
      "\tspeed: 0.0292s/iter; left time: 483.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0698512 Vali Loss: 0.0867411 Test Loss: 0.0893741\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0674320\n",
      "\tspeed: 0.0586s/iter; left time: 965.6754s\n",
      "\titers: 200, epoch: 27 | loss: 0.0708363\n",
      "\tspeed: 0.0306s/iter; left time: 501.8542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0698415 Vali Loss: 0.0867226 Test Loss: 0.0895468\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0698918\n",
      "\tspeed: 0.0573s/iter; left time: 931.2877s\n",
      "\titers: 200, epoch: 28 | loss: 0.0701850\n",
      "\tspeed: 0.0293s/iter; left time: 472.5171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0697301 Vali Loss: 0.0866223 Test Loss: 0.0894484\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0685595\n",
      "\tspeed: 0.0576s/iter; left time: 923.4171s\n",
      "\titers: 200, epoch: 29 | loss: 0.0727894\n",
      "\tspeed: 0.0292s/iter; left time: 465.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0697482 Vali Loss: 0.0867935 Test Loss: 0.0895863\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0766726\n",
      "\tspeed: 0.0584s/iter; left time: 923.7047s\n",
      "\titers: 200, epoch: 30 | loss: 0.0715334\n",
      "\tspeed: 0.0299s/iter; left time: 469.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0697450 Vali Loss: 0.0867889 Test Loss: 0.0895059\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0708432\n",
      "\tspeed: 0.0583s/iter; left time: 908.6458s\n",
      "\titers: 200, epoch: 31 | loss: 0.0678874\n",
      "\tspeed: 0.0290s/iter; left time: 448.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0696852 Vali Loss: 0.0866796 Test Loss: 0.0894422\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0708771\n",
      "\tspeed: 0.0573s/iter; left time: 879.7823s\n",
      "\titers: 200, epoch: 32 | loss: 0.0680556\n",
      "\tspeed: 0.0300s/iter; left time: 457.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0695893 Vali Loss: 0.0865742 Test Loss: 0.0894718\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0692809\n",
      "\tspeed: 0.0600s/iter; left time: 908.6142s\n",
      "\titers: 200, epoch: 33 | loss: 0.0734499\n",
      "\tspeed: 0.0292s/iter; left time: 439.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0696502 Vali Loss: 0.0867322 Test Loss: 0.0895046\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021318688988685608, rmse:0.14600920677185059, mae:0.08941580355167389, rse:0.5152866840362549\n",
      "Intermediate time for DE and pred_len 24: 00h:09m:50.58s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1715337\n",
      "\tspeed: 0.0558s/iter; left time: 1245.2764s\n",
      "\titers: 200, epoch: 1 | loss: 0.1585579\n",
      "\tspeed: 0.0314s/iter; left time: 696.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.1652060 Vali Loss: 0.1660529 Test Loss: 0.1809062\n",
      "Validation loss decreased (inf --> 0.166053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205626\n",
      "\tspeed: 0.0600s/iter; left time: 1323.5688s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186947\n",
      "\tspeed: 0.0303s/iter; left time: 666.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.1246657 Vali Loss: 0.1251731 Test Loss: 0.1321551\n",
      "Validation loss decreased (0.166053 --> 0.125173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1044892\n",
      "\tspeed: 0.0620s/iter; left time: 1354.6906s\n",
      "\titers: 200, epoch: 3 | loss: 0.1051909\n",
      "\tspeed: 0.0307s/iter; left time: 668.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.1088846 Vali Loss: 0.1206153 Test Loss: 0.1288252\n",
      "Validation loss decreased (0.125173 --> 0.120615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050393\n",
      "\tspeed: 0.0590s/iter; left time: 1276.9399s\n",
      "\titers: 200, epoch: 4 | loss: 0.1002400\n",
      "\tspeed: 0.0296s/iter; left time: 637.7597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1050778 Vali Loss: 0.1188297 Test Loss: 0.1277407\n",
      "Validation loss decreased (0.120615 --> 0.118830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1064784\n",
      "\tspeed: 0.0586s/iter; left time: 1254.0141s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052308\n",
      "\tspeed: 0.0293s/iter; left time: 625.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1030869 Vali Loss: 0.1183381 Test Loss: 0.1272658\n",
      "Validation loss decreased (0.118830 --> 0.118338).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961202\n",
      "\tspeed: 0.0598s/iter; left time: 1265.6051s\n",
      "\titers: 200, epoch: 6 | loss: 0.1015194\n",
      "\tspeed: 0.0306s/iter; left time: 644.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.1016476 Vali Loss: 0.1183048 Test Loss: 0.1270003\n",
      "Validation loss decreased (0.118338 --> 0.118305).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025156\n",
      "\tspeed: 0.0595s/iter; left time: 1246.7895s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025395\n",
      "\tspeed: 0.0298s/iter; left time: 621.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1005917 Vali Loss: 0.1185534 Test Loss: 0.1271381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1011636\n",
      "\tspeed: 0.0597s/iter; left time: 1237.5052s\n",
      "\titers: 200, epoch: 8 | loss: 0.1008992\n",
      "\tspeed: 0.0301s/iter; left time: 621.2981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0996272 Vali Loss: 0.1187628 Test Loss: 0.1273232\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012495\n",
      "\tspeed: 0.0625s/iter; left time: 1281.8419s\n",
      "\titers: 200, epoch: 9 | loss: 0.0997166\n",
      "\tspeed: 0.0311s/iter; left time: 634.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0987985 Vali Loss: 0.1189673 Test Loss: 0.1284143\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0935672\n",
      "\tspeed: 0.0630s/iter; left time: 1278.3025s\n",
      "\titers: 200, epoch: 10 | loss: 0.0895828\n",
      "\tspeed: 0.0307s/iter; left time: 620.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0979273 Vali Loss: 0.1193244 Test Loss: 0.1281973\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0980667\n",
      "\tspeed: 0.0644s/iter; left time: 1291.1898s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946719\n",
      "\tspeed: 0.0359s/iter; left time: 716.6355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 224 | Train Loss: 0.0972261 Vali Loss: 0.1196312 Test Loss: 0.1285315\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0912278\n",
      "\tspeed: 0.0643s/iter; left time: 1276.3464s\n",
      "\titers: 200, epoch: 12 | loss: 0.0946971\n",
      "\tspeed: 0.0353s/iter; left time: 697.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0965124 Vali Loss: 0.1197330 Test Loss: 0.1298404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995140\n",
      "\tspeed: 0.0614s/iter; left time: 1203.8718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0950678\n",
      "\tspeed: 0.0351s/iter; left time: 684.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0957131 Vali Loss: 0.1199615 Test Loss: 0.1301862\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0923465\n",
      "\tspeed: 0.0633s/iter; left time: 1227.3034s\n",
      "\titers: 200, epoch: 14 | loss: 0.0923985\n",
      "\tspeed: 0.0335s/iter; left time: 645.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0952636 Vali Loss: 0.1198808 Test Loss: 0.1305748\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0949246\n",
      "\tspeed: 0.0649s/iter; left time: 1243.4063s\n",
      "\titers: 200, epoch: 15 | loss: 0.0916991\n",
      "\tspeed: 0.0297s/iter; left time: 565.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0946896 Vali Loss: 0.1202508 Test Loss: 0.1311955\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1053880\n",
      "\tspeed: 0.0587s/iter; left time: 1111.6423s\n",
      "\titers: 200, epoch: 16 | loss: 0.0955126\n",
      "\tspeed: 0.0299s/iter; left time: 562.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0941537 Vali Loss: 0.1209353 Test Loss: 0.1311565\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03652429208159447, rmse:0.19111329317092896, mae:0.12700024247169495, rse:0.6767708659172058\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1643227\n",
      "\tspeed: 0.0333s/iter; left time: 743.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504811\n",
      "\tspeed: 0.0318s/iter; left time: 706.4088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.1647373 Vali Loss: 0.1661808 Test Loss: 0.1807638\n",
      "Validation loss decreased (inf --> 0.166181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1221283\n",
      "\tspeed: 0.0604s/iter; left time: 1333.7497s\n",
      "\titers: 200, epoch: 2 | loss: 0.1101192\n",
      "\tspeed: 0.0312s/iter; left time: 686.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.1241413 Vali Loss: 0.1250436 Test Loss: 0.1320613\n",
      "Validation loss decreased (0.166181 --> 0.125044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1066463\n",
      "\tspeed: 0.0598s/iter; left time: 1306.0090s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076917\n",
      "\tspeed: 0.0302s/iter; left time: 657.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.1089115 Vali Loss: 0.1205230 Test Loss: 0.1283665\n",
      "Validation loss decreased (0.125044 --> 0.120523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1049080\n",
      "\tspeed: 0.0626s/iter; left time: 1353.7282s\n",
      "\titers: 200, epoch: 4 | loss: 0.1068154\n",
      "\tspeed: 0.0326s/iter; left time: 700.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.1051577 Vali Loss: 0.1189645 Test Loss: 0.1273009\n",
      "Validation loss decreased (0.120523 --> 0.118964).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1082753\n",
      "\tspeed: 0.0667s/iter; left time: 1427.4088s\n",
      "\titers: 200, epoch: 5 | loss: 0.1033226\n",
      "\tspeed: 0.0358s/iter; left time: 762.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1033094 Vali Loss: 0.1183564 Test Loss: 0.1264239\n",
      "Validation loss decreased (0.118964 --> 0.118356).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1088026\n",
      "\tspeed: 0.0632s/iter; left time: 1338.1721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0962961\n",
      "\tspeed: 0.0318s/iter; left time: 669.4641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.1020219 Vali Loss: 0.1181495 Test Loss: 0.1269103\n",
      "Validation loss decreased (0.118356 --> 0.118150).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1006780\n",
      "\tspeed: 0.0642s/iter; left time: 1345.3727s\n",
      "\titers: 200, epoch: 7 | loss: 0.1005690\n",
      "\tspeed: 0.0313s/iter; left time: 653.5451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.1009357 Vali Loss: 0.1183706 Test Loss: 0.1271115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0991638\n",
      "\tspeed: 0.0624s/iter; left time: 1294.0224s\n",
      "\titers: 200, epoch: 8 | loss: 0.0987732\n",
      "\tspeed: 0.0325s/iter; left time: 671.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0999924 Vali Loss: 0.1184070 Test Loss: 0.1271562\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006600\n",
      "\tspeed: 0.0645s/iter; left time: 1322.5946s\n",
      "\titers: 200, epoch: 9 | loss: 0.0932216\n",
      "\tspeed: 0.0396s/iter; left time: 808.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0991594 Vali Loss: 0.1187752 Test Loss: 0.1274746\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0988061\n",
      "\tspeed: 0.0626s/iter; left time: 1270.2198s\n",
      "\titers: 200, epoch: 10 | loss: 0.0955911\n",
      "\tspeed: 0.0307s/iter; left time: 619.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0983651 Vali Loss: 0.1185296 Test Loss: 0.1279587\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1029924\n",
      "\tspeed: 0.0613s/iter; left time: 1229.0848s\n",
      "\titers: 200, epoch: 11 | loss: 0.1021657\n",
      "\tspeed: 0.0306s/iter; left time: 611.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0976693 Vali Loss: 0.1192601 Test Loss: 0.1286279\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0952412\n",
      "\tspeed: 0.0608s/iter; left time: 1205.8639s\n",
      "\titers: 200, epoch: 12 | loss: 0.0966135\n",
      "\tspeed: 0.0312s/iter; left time: 616.7765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0968953 Vali Loss: 0.1193702 Test Loss: 0.1287199\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0911009\n",
      "\tspeed: 0.0601s/iter; left time: 1178.5694s\n",
      "\titers: 200, epoch: 13 | loss: 0.0966560\n",
      "\tspeed: 0.0300s/iter; left time: 584.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.0962348 Vali Loss: 0.1195301 Test Loss: 0.1291977\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0915111\n",
      "\tspeed: 0.0584s/iter; left time: 1132.3400s\n",
      "\titers: 200, epoch: 14 | loss: 0.0910921\n",
      "\tspeed: 0.0301s/iter; left time: 581.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0957030 Vali Loss: 0.1198449 Test Loss: 0.1295812\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0902165\n",
      "\tspeed: 0.0599s/iter; left time: 1148.8275s\n",
      "\titers: 200, epoch: 15 | loss: 0.0922388\n",
      "\tspeed: 0.0298s/iter; left time: 568.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0950904 Vali Loss: 0.1199711 Test Loss: 0.1301276\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0961842\n",
      "\tspeed: 0.0599s/iter; left time: 1135.0331s\n",
      "\titers: 200, epoch: 16 | loss: 0.0918794\n",
      "\tspeed: 0.0306s/iter; left time: 576.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0946457 Vali Loss: 0.1204200 Test Loss: 0.1304407\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0365537628531456, rmse:0.19119037687778473, mae:0.12691019475460052, rse:0.6770438551902771\n",
      "Intermediate time for DE and pred_len 96: 00h:05m:11.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1689817\n",
      "\tspeed: 0.0540s/iter; left time: 1199.4790s\n",
      "\titers: 200, epoch: 1 | loss: 0.1642684\n",
      "\tspeed: 0.0296s/iter; left time: 653.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.1665411 Vali Loss: 0.1681140 Test Loss: 0.1834208\n",
      "Validation loss decreased (inf --> 0.168114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1266156\n",
      "\tspeed: 0.0612s/iter; left time: 1344.9822s\n",
      "\titers: 200, epoch: 2 | loss: 0.1200108\n",
      "\tspeed: 0.0310s/iter; left time: 677.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.1296155 Vali Loss: 0.1291023 Test Loss: 0.1378668\n",
      "Validation loss decreased (0.168114 --> 0.129102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1214094\n",
      "\tspeed: 0.0604s/iter; left time: 1314.1613s\n",
      "\titers: 200, epoch: 3 | loss: 0.1149558\n",
      "\tspeed: 0.0305s/iter; left time: 661.2854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.1144919 Vali Loss: 0.1243992 Test Loss: 0.1346566\n",
      "Validation loss decreased (0.129102 --> 0.124399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1130121\n",
      "\tspeed: 0.0602s/iter; left time: 1296.9719s\n",
      "\titers: 200, epoch: 4 | loss: 0.1080625\n",
      "\tspeed: 0.0302s/iter; left time: 647.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.1109701 Vali Loss: 0.1235877 Test Loss: 0.1350279\n",
      "Validation loss decreased (0.124399 --> 0.123588).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1092762\n",
      "\tspeed: 0.0613s/iter; left time: 1306.8439s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114840\n",
      "\tspeed: 0.0303s/iter; left time: 641.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 223 | Train Loss: 0.1091429 Vali Loss: 0.1233613 Test Loss: 0.1347366\n",
      "Validation loss decreased (0.123588 --> 0.123361).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1129082\n",
      "\tspeed: 0.0593s/iter; left time: 1249.7848s\n",
      "\titers: 200, epoch: 6 | loss: 0.1027416\n",
      "\tspeed: 0.0308s/iter; left time: 646.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1077531 Vali Loss: 0.1237961 Test Loss: 0.1352117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056892\n",
      "\tspeed: 0.0609s/iter; left time: 1270.7334s\n",
      "\titers: 200, epoch: 7 | loss: 0.1095061\n",
      "\tspeed: 0.0295s/iter; left time: 611.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 223 | Train Loss: 0.1066067 Vali Loss: 0.1236090 Test Loss: 0.1354179\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0993296\n",
      "\tspeed: 0.0595s/iter; left time: 1228.2051s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133994\n",
      "\tspeed: 0.0297s/iter; left time: 609.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1054562 Vali Loss: 0.1237645 Test Loss: 0.1360048\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1035121\n",
      "\tspeed: 0.0607s/iter; left time: 1240.0294s\n",
      "\titers: 200, epoch: 9 | loss: 0.0996546\n",
      "\tspeed: 0.0300s/iter; left time: 609.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.1044893 Vali Loss: 0.1240688 Test Loss: 0.1365043\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1052005\n",
      "\tspeed: 0.0623s/iter; left time: 1258.0467s\n",
      "\titers: 200, epoch: 10 | loss: 0.1107367\n",
      "\tspeed: 0.0317s/iter; left time: 636.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.1034715 Vali Loss: 0.1245504 Test Loss: 0.1374091\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1002471\n",
      "\tspeed: 0.0588s/iter; left time: 1174.1653s\n",
      "\titers: 200, epoch: 11 | loss: 0.1033231\n",
      "\tspeed: 0.0297s/iter; left time: 590.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1025271 Vali Loss: 0.1251596 Test Loss: 0.1380736\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0978731\n",
      "\tspeed: 0.0581s/iter; left time: 1146.6676s\n",
      "\titers: 200, epoch: 12 | loss: 0.0999830\n",
      "\tspeed: 0.0303s/iter; left time: 595.0910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1016559 Vali Loss: 0.1250972 Test Loss: 0.1385046\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0960645\n",
      "\tspeed: 0.0600s/iter; left time: 1171.4001s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973675\n",
      "\tspeed: 0.0324s/iter; left time: 629.2066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 223 | Train Loss: 0.1008521 Vali Loss: 0.1256543 Test Loss: 0.1380820\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1082493\n",
      "\tspeed: 0.0593s/iter; left time: 1145.5449s\n",
      "\titers: 200, epoch: 14 | loss: 0.0958933\n",
      "\tspeed: 0.0303s/iter; left time: 582.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1001738 Vali Loss: 0.1259376 Test Loss: 0.1384349\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0981032\n",
      "\tspeed: 0.0609s/iter; left time: 1162.0782s\n",
      "\titers: 200, epoch: 15 | loss: 0.1002005\n",
      "\tspeed: 0.0308s/iter; left time: 583.8947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.0995914 Vali Loss: 0.1262103 Test Loss: 0.1389035\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039026908576488495, rmse:0.19755229353904724, mae:0.13473661243915558, rse:0.6997461318969727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1635030\n",
      "\tspeed: 0.0323s/iter; left time: 718.1877s\n",
      "\titers: 200, epoch: 1 | loss: 0.1556350\n",
      "\tspeed: 0.0301s/iter; left time: 664.2393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.1656929 Vali Loss: 0.1679618 Test Loss: 0.1829477\n",
      "Validation loss decreased (inf --> 0.167962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1399003\n",
      "\tspeed: 0.0591s/iter; left time: 1298.4492s\n",
      "\titers: 200, epoch: 2 | loss: 0.1183311\n",
      "\tspeed: 0.0294s/iter; left time: 642.5992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.1302310 Vali Loss: 0.1299277 Test Loss: 0.1380411\n",
      "Validation loss decreased (0.167962 --> 0.129928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1143545\n",
      "\tspeed: 0.0636s/iter; left time: 1384.0342s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084580\n",
      "\tspeed: 0.0310s/iter; left time: 670.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 223 | Train Loss: 0.1149042 Vali Loss: 0.1254020 Test Loss: 0.1350607\n",
      "Validation loss decreased (0.129928 --> 0.125402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1089621\n",
      "\tspeed: 0.0610s/iter; left time: 1314.3154s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092948\n",
      "\tspeed: 0.0300s/iter; left time: 642.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1109863 Vali Loss: 0.1240394 Test Loss: 0.1347887\n",
      "Validation loss decreased (0.125402 --> 0.124039).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1087443\n",
      "\tspeed: 0.0601s/iter; left time: 1281.4170s\n",
      "\titers: 200, epoch: 5 | loss: 0.1055433\n",
      "\tspeed: 0.0296s/iter; left time: 627.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 223 | Train Loss: 0.1086753 Vali Loss: 0.1240155 Test Loss: 0.1350656\n",
      "Validation loss decreased (0.124039 --> 0.124015).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1100455\n",
      "\tspeed: 0.0669s/iter; left time: 1411.0853s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047747\n",
      "\tspeed: 0.0331s/iter; left time: 693.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.1070620 Vali Loss: 0.1243766 Test Loss: 0.1359679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061983\n",
      "\tspeed: 0.0600s/iter; left time: 1250.8300s\n",
      "\titers: 200, epoch: 7 | loss: 0.1051535\n",
      "\tspeed: 0.0348s/iter; left time: 722.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.1058153 Vali Loss: 0.1245024 Test Loss: 0.1364044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0961581\n",
      "\tspeed: 0.0583s/iter; left time: 1203.4943s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054811\n",
      "\tspeed: 0.0296s/iter; left time: 608.9303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1045242 Vali Loss: 0.1245116 Test Loss: 0.1373453\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1050144\n",
      "\tspeed: 0.0604s/iter; left time: 1233.4185s\n",
      "\titers: 200, epoch: 9 | loss: 0.1012946\n",
      "\tspeed: 0.0311s/iter; left time: 631.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.1035206 Vali Loss: 0.1249471 Test Loss: 0.1382416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035822\n",
      "\tspeed: 0.0634s/iter; left time: 1280.7372s\n",
      "\titers: 200, epoch: 10 | loss: 0.1043406\n",
      "\tspeed: 0.0350s/iter; left time: 703.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1023821 Vali Loss: 0.1251396 Test Loss: 0.1382025\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1056160\n",
      "\tspeed: 0.0638s/iter; left time: 1273.6250s\n",
      "\titers: 200, epoch: 11 | loss: 0.1054387\n",
      "\tspeed: 0.0346s/iter; left time: 687.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.1016366 Vali Loss: 0.1250013 Test Loss: 0.1380201\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1037386\n",
      "\tspeed: 0.0728s/iter; left time: 1437.9188s\n",
      "\titers: 200, epoch: 12 | loss: 0.1042496\n",
      "\tspeed: 0.0407s/iter; left time: 800.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.1006642 Vali Loss: 0.1258975 Test Loss: 0.1390205\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032351\n",
      "\tspeed: 0.0674s/iter; left time: 1315.2591s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019490\n",
      "\tspeed: 0.0329s/iter; left time: 639.9494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 223 | Train Loss: 0.0999700 Vali Loss: 0.1264361 Test Loss: 0.1397571\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0974630\n",
      "\tspeed: 0.0620s/iter; left time: 1196.6093s\n",
      "\titers: 200, epoch: 14 | loss: 0.1011920\n",
      "\tspeed: 0.0303s/iter; left time: 582.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.0992640 Vali Loss: 0.1266024 Test Loss: 0.1400846\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0967790\n",
      "\tspeed: 0.0616s/iter; left time: 1175.5579s\n",
      "\titers: 200, epoch: 15 | loss: 0.0985369\n",
      "\tspeed: 0.0375s/iter; left time: 712.5968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0987066 Vali Loss: 0.1266401 Test Loss: 0.1393744\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03954624384641647, rmse:0.19886237382888794, mae:0.13506567478179932, rse:0.7043865323066711\n",
      "Intermediate time for DE and pred_len 168: 00h:04m:54.68s\n",
      "Intermediate time for DE: 00h:19m:56.75s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1416442\n",
      "\tspeed: 0.0524s/iter; left time: 1169.2101s\n",
      "\titers: 200, epoch: 1 | loss: 0.1359674\n",
      "\tspeed: 0.0295s/iter; left time: 654.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.1428490 Vali Loss: 0.1416124 Test Loss: 0.1641944\n",
      "Validation loss decreased (inf --> 0.141612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982989\n",
      "\tspeed: 0.0614s/iter; left time: 1354.4811s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841241\n",
      "\tspeed: 0.0339s/iter; left time: 745.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0967408 Vali Loss: 0.0950226 Test Loss: 0.1060177\n",
      "Validation loss decreased (0.141612 --> 0.095023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0755521\n",
      "\tspeed: 0.0645s/iter; left time: 1408.9305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794114\n",
      "\tspeed: 0.0340s/iter; left time: 739.5645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0807715 Vali Loss: 0.0917419 Test Loss: 0.1033771\n",
      "Validation loss decreased (0.095023 --> 0.091742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820476\n",
      "\tspeed: 0.0672s/iter; left time: 1452.6132s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825884\n",
      "\tspeed: 0.0312s/iter; left time: 671.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0781855 Vali Loss: 0.0911295 Test Loss: 0.1026525\n",
      "Validation loss decreased (0.091742 --> 0.091129).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0787778\n",
      "\tspeed: 0.0631s/iter; left time: 1351.0644s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802914\n",
      "\tspeed: 0.0319s/iter; left time: 679.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0769637 Vali Loss: 0.0900058 Test Loss: 0.1023378\n",
      "Validation loss decreased (0.091129 --> 0.090006).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0744972\n",
      "\tspeed: 0.0578s/iter; left time: 1224.0998s\n",
      "\titers: 200, epoch: 6 | loss: 0.0772638\n",
      "\tspeed: 0.0310s/iter; left time: 652.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0760804 Vali Loss: 0.0900013 Test Loss: 0.1019079\n",
      "Validation loss decreased (0.090006 --> 0.090001).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0762442\n",
      "\tspeed: 0.0614s/iter; left time: 1287.0049s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727803\n",
      "\tspeed: 0.0296s/iter; left time: 618.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0754529 Vali Loss: 0.0896282 Test Loss: 0.1022905\n",
      "Validation loss decreased (0.090001 --> 0.089628).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801298\n",
      "\tspeed: 0.0611s/iter; left time: 1267.2882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0791657\n",
      "\tspeed: 0.0329s/iter; left time: 678.9719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0749296 Vali Loss: 0.0892004 Test Loss: 0.1020514\n",
      "Validation loss decreased (0.089628 --> 0.089200).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734463\n",
      "\tspeed: 0.0603s/iter; left time: 1237.0319s\n",
      "\titers: 200, epoch: 9 | loss: 0.0723017\n",
      "\tspeed: 0.0307s/iter; left time: 626.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0745067 Vali Loss: 0.0891742 Test Loss: 0.1021916\n",
      "Validation loss decreased (0.089200 --> 0.089174).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0807116\n",
      "\tspeed: 0.0623s/iter; left time: 1264.4877s\n",
      "\titers: 200, epoch: 10 | loss: 0.0744405\n",
      "\tspeed: 0.0330s/iter; left time: 666.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0741352 Vali Loss: 0.0890640 Test Loss: 0.1017153\n",
      "Validation loss decreased (0.089174 --> 0.089064).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733814\n",
      "\tspeed: 0.0661s/iter; left time: 1326.4339s\n",
      "\titers: 200, epoch: 11 | loss: 0.0779751\n",
      "\tspeed: 0.0312s/iter; left time: 623.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0738129 Vali Loss: 0.0889336 Test Loss: 0.1020456\n",
      "Validation loss decreased (0.089064 --> 0.088934).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787763\n",
      "\tspeed: 0.0628s/iter; left time: 1245.1343s\n",
      "\titers: 200, epoch: 12 | loss: 0.0728098\n",
      "\tspeed: 0.0315s/iter; left time: 621.2450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0735505 Vali Loss: 0.0888196 Test Loss: 0.1024022\n",
      "Validation loss decreased (0.088934 --> 0.088820).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0715337\n",
      "\tspeed: 0.0616s/iter; left time: 1207.6359s\n",
      "\titers: 200, epoch: 13 | loss: 0.0715669\n",
      "\tspeed: 0.0342s/iter; left time: 667.5352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0733221 Vali Loss: 0.0886738 Test Loss: 0.1021919\n",
      "Validation loss decreased (0.088820 --> 0.088674).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712817\n",
      "\tspeed: 0.0626s/iter; left time: 1213.1258s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718854\n",
      "\tspeed: 0.0324s/iter; left time: 624.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0731035 Vali Loss: 0.0889941 Test Loss: 0.1024620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0701052\n",
      "\tspeed: 0.0628s/iter; left time: 1203.7297s\n",
      "\titers: 200, epoch: 15 | loss: 0.0703838\n",
      "\tspeed: 0.0370s/iter; left time: 704.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0728872 Vali Loss: 0.0887056 Test Loss: 0.1023624\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703939\n",
      "\tspeed: 0.0615s/iter; left time: 1164.4454s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741787\n",
      "\tspeed: 0.0317s/iter; left time: 596.6981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0727279 Vali Loss: 0.0886003 Test Loss: 0.1021663\n",
      "Validation loss decreased (0.088674 --> 0.088600).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0698442\n",
      "\tspeed: 0.0607s/iter; left time: 1135.9221s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758607\n",
      "\tspeed: 0.0349s/iter; left time: 649.0142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0725987 Vali Loss: 0.0886171 Test Loss: 0.1021710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662590\n",
      "\tspeed: 0.0627s/iter; left time: 1158.7693s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706528\n",
      "\tspeed: 0.0327s/iter; left time: 601.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0724800 Vali Loss: 0.0888152 Test Loss: 0.1024421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0742896\n",
      "\tspeed: 0.0613s/iter; left time: 1120.4547s\n",
      "\titers: 200, epoch: 19 | loss: 0.0735393\n",
      "\tspeed: 0.0329s/iter; left time: 597.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0723689 Vali Loss: 0.0887323 Test Loss: 0.1025851\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0666809\n",
      "\tspeed: 0.0592s/iter; left time: 1068.2393s\n",
      "\titers: 200, epoch: 20 | loss: 0.0699753\n",
      "\tspeed: 0.0310s/iter; left time: 556.6959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0886836 Test Loss: 0.1025293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684471\n",
      "\tspeed: 0.0575s/iter; left time: 1025.5411s\n",
      "\titers: 200, epoch: 21 | loss: 0.0684048\n",
      "\tspeed: 0.0329s/iter; left time: 582.3293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.0721463 Vali Loss: 0.0887258 Test Loss: 0.1023708\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0765291\n",
      "\tspeed: 0.0640s/iter; left time: 1126.7938s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675473\n",
      "\tspeed: 0.0290s/iter; left time: 507.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0720907 Vali Loss: 0.0886125 Test Loss: 0.1024235\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0723928\n",
      "\tspeed: 0.0604s/iter; left time: 1049.8180s\n",
      "\titers: 200, epoch: 23 | loss: 0.0741965\n",
      "\tspeed: 0.0352s/iter; left time: 608.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0719553 Vali Loss: 0.0887272 Test Loss: 0.1024886\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0749635\n",
      "\tspeed: 0.0591s/iter; left time: 1013.1443s\n",
      "\titers: 200, epoch: 24 | loss: 0.0701271\n",
      "\tspeed: 0.0289s/iter; left time: 492.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0719256 Vali Loss: 0.0887283 Test Loss: 0.1025322\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0694996\n",
      "\tspeed: 0.0570s/iter; left time: 965.3287s\n",
      "\titers: 200, epoch: 25 | loss: 0.0689580\n",
      "\tspeed: 0.0294s/iter; left time: 494.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0717967 Vali Loss: 0.0886567 Test Loss: 0.1025829\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0677510\n",
      "\tspeed: 0.0579s/iter; left time: 966.8580s\n",
      "\titers: 200, epoch: 26 | loss: 0.0665373\n",
      "\tspeed: 0.0291s/iter; left time: 482.2817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0717434 Vali Loss: 0.0886495 Test Loss: 0.1026924\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025964142754673958, rmse:0.16113393008708954, mae:0.1021663025021553, rse:0.5558663606643677\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1389367\n",
      "\tspeed: 0.0317s/iter; left time: 706.9342s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326273\n",
      "\tspeed: 0.0292s/iter; left time: 648.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1414651 Vali Loss: 0.1399842 Test Loss: 0.1620381\n",
      "Validation loss decreased (inf --> 0.139984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1026437\n",
      "\tspeed: 0.0588s/iter; left time: 1297.1996s\n",
      "\titers: 200, epoch: 2 | loss: 0.0844824\n",
      "\tspeed: 0.0289s/iter; left time: 635.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0968839 Vali Loss: 0.0948926 Test Loss: 0.1057608\n",
      "Validation loss decreased (0.139984 --> 0.094893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0814016\n",
      "\tspeed: 0.0590s/iter; left time: 1290.1900s\n",
      "\titers: 200, epoch: 3 | loss: 0.0797990\n",
      "\tspeed: 0.0302s/iter; left time: 656.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0806235 Vali Loss: 0.0918645 Test Loss: 0.1029692\n",
      "Validation loss decreased (0.094893 --> 0.091865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0763020\n",
      "\tspeed: 0.0587s/iter; left time: 1269.8171s\n",
      "\titers: 200, epoch: 4 | loss: 0.0790892\n",
      "\tspeed: 0.0294s/iter; left time: 633.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0781237 Vali Loss: 0.0910004 Test Loss: 0.1025053\n",
      "Validation loss decreased (0.091865 --> 0.091000).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0783131\n",
      "\tspeed: 0.0581s/iter; left time: 1243.7933s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853850\n",
      "\tspeed: 0.0294s/iter; left time: 625.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0768838 Vali Loss: 0.0901625 Test Loss: 0.1025833\n",
      "Validation loss decreased (0.091000 --> 0.090162).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0743386\n",
      "\tspeed: 0.0586s/iter; left time: 1241.7546s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746445\n",
      "\tspeed: 0.0290s/iter; left time: 610.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0760748 Vali Loss: 0.0895948 Test Loss: 0.1022559\n",
      "Validation loss decreased (0.090162 --> 0.089595).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794251\n",
      "\tspeed: 0.0582s/iter; left time: 1219.1403s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810494\n",
      "\tspeed: 0.0302s/iter; left time: 629.4524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0755073 Vali Loss: 0.0896624 Test Loss: 0.1021774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728558\n",
      "\tspeed: 0.0573s/iter; left time: 1187.6699s\n",
      "\titers: 200, epoch: 8 | loss: 0.0737737\n",
      "\tspeed: 0.0298s/iter; left time: 615.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0748935 Vali Loss: 0.0893540 Test Loss: 0.1024735\n",
      "Validation loss decreased (0.089595 --> 0.089354).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805124\n",
      "\tspeed: 0.0585s/iter; left time: 1199.6390s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792667\n",
      "\tspeed: 0.0292s/iter; left time: 595.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0745959 Vali Loss: 0.0894167 Test Loss: 0.1025814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0741075\n",
      "\tspeed: 0.0574s/iter; left time: 1164.9624s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767193\n",
      "\tspeed: 0.0289s/iter; left time: 582.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0742171 Vali Loss: 0.0891405 Test Loss: 0.1021369\n",
      "Validation loss decreased (0.089354 --> 0.089141).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0698083\n",
      "\tspeed: 0.0583s/iter; left time: 1169.9165s\n",
      "\titers: 200, epoch: 11 | loss: 0.0736080\n",
      "\tspeed: 0.0304s/iter; left time: 607.1874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0738832 Vali Loss: 0.0890985 Test Loss: 0.1021175\n",
      "Validation loss decreased (0.089141 --> 0.089099).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778908\n",
      "\tspeed: 0.0589s/iter; left time: 1168.2173s\n",
      "\titers: 200, epoch: 12 | loss: 0.0774186\n",
      "\tspeed: 0.0292s/iter; left time: 575.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0736360 Vali Loss: 0.0888298 Test Loss: 0.1021405\n",
      "Validation loss decreased (0.089099 --> 0.088830).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0743443\n",
      "\tspeed: 0.0581s/iter; left time: 1139.3890s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705036\n",
      "\tspeed: 0.0290s/iter; left time: 565.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0734566 Vali Loss: 0.0890365 Test Loss: 0.1020825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783875\n",
      "\tspeed: 0.0576s/iter; left time: 1115.9748s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738926\n",
      "\tspeed: 0.0294s/iter; left time: 568.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0731924 Vali Loss: 0.0887765 Test Loss: 0.1020412\n",
      "Validation loss decreased (0.088830 --> 0.088777).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0724580\n",
      "\tspeed: 0.0595s/iter; left time: 1140.1865s\n",
      "\titers: 200, epoch: 15 | loss: 0.0683102\n",
      "\tspeed: 0.0290s/iter; left time: 553.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0730620 Vali Loss: 0.0886900 Test Loss: 0.1020451\n",
      "Validation loss decreased (0.088777 --> 0.088690).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0686071\n",
      "\tspeed: 0.0583s/iter; left time: 1103.7406s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744030\n",
      "\tspeed: 0.0289s/iter; left time: 544.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0728458 Vali Loss: 0.0887615 Test Loss: 0.1021954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690405\n",
      "\tspeed: 0.0579s/iter; left time: 1083.1016s\n",
      "\titers: 200, epoch: 17 | loss: 0.0754017\n",
      "\tspeed: 0.0292s/iter; left time: 543.8431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0727160 Vali Loss: 0.0887494 Test Loss: 0.1021768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739375\n",
      "\tspeed: 0.0575s/iter; left time: 1062.4635s\n",
      "\titers: 200, epoch: 18 | loss: 0.0732448\n",
      "\tspeed: 0.0297s/iter; left time: 545.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0725899 Vali Loss: 0.0887591 Test Loss: 0.1021518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676721\n",
      "\tspeed: 0.0583s/iter; left time: 1065.7672s\n",
      "\titers: 200, epoch: 19 | loss: 0.0749651\n",
      "\tspeed: 0.0290s/iter; left time: 527.5224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0725485 Vali Loss: 0.0887928 Test Loss: 0.1023783\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720916\n",
      "\tspeed: 0.0592s/iter; left time: 1068.0106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0713761\n",
      "\tspeed: 0.0289s/iter; left time: 519.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0724052 Vali Loss: 0.0889506 Test Loss: 0.1024654\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724897\n",
      "\tspeed: 0.0578s/iter; left time: 1030.3768s\n",
      "\titers: 200, epoch: 21 | loss: 0.0813075\n",
      "\tspeed: 0.0292s/iter; left time: 517.4974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0722758 Vali Loss: 0.0886914 Test Loss: 0.1022891\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0698621\n",
      "\tspeed: 0.0575s/iter; left time: 1012.3671s\n",
      "\titers: 200, epoch: 22 | loss: 0.0690094\n",
      "\tspeed: 0.0295s/iter; left time: 516.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0721615 Vali Loss: 0.0887351 Test Loss: 0.1023006\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0707365\n",
      "\tspeed: 0.0572s/iter; left time: 994.1569s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725962\n",
      "\tspeed: 0.0324s/iter; left time: 559.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0720291 Vali Loss: 0.0888139 Test Loss: 0.1023784\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0791492\n",
      "\tspeed: 0.0588s/iter; left time: 1008.3817s\n",
      "\titers: 200, epoch: 24 | loss: 0.0751757\n",
      "\tspeed: 0.0297s/iter; left time: 506.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0720577 Vali Loss: 0.0889034 Test Loss: 0.1024064\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0672305\n",
      "\tspeed: 0.0636s/iter; left time: 1075.6815s\n",
      "\titers: 200, epoch: 25 | loss: 0.0684188\n",
      "\tspeed: 0.0340s/iter; left time: 572.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0719830 Vali Loss: 0.0886956 Test Loss: 0.1023219\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02592809684574604, rmse:0.16102203726768494, mae:0.10204505920410156, rse:0.555480420589447\n",
      "Intermediate time for GB and pred_len 24: 00h:07m:54.60s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1509436\n",
      "\tspeed: 0.0532s/iter; left time: 1185.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1384306\n",
      "\tspeed: 0.0338s/iter; left time: 749.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.1494617 Vali Loss: 0.1517594 Test Loss: 0.1784826\n",
      "Validation loss decreased (inf --> 0.151759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1140732\n",
      "\tspeed: 0.0590s/iter; left time: 1303.3295s\n",
      "\titers: 200, epoch: 2 | loss: 0.1110358\n",
      "\tspeed: 0.0297s/iter; left time: 652.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1177922 Vali Loss: 0.1202108 Test Loss: 0.1407618\n",
      "Validation loss decreased (0.151759 --> 0.120211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1010459\n",
      "\tspeed: 0.0593s/iter; left time: 1296.5002s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007194\n",
      "\tspeed: 0.0295s/iter; left time: 641.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.1048377 Vali Loss: 0.1183033 Test Loss: 0.1404727\n",
      "Validation loss decreased (0.120211 --> 0.118303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993064\n",
      "\tspeed: 0.0591s/iter; left time: 1279.3398s\n",
      "\titers: 200, epoch: 4 | loss: 0.0927820\n",
      "\tspeed: 0.0294s/iter; left time: 633.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.1025748 Vali Loss: 0.1174855 Test Loss: 0.1413985\n",
      "Validation loss decreased (0.118303 --> 0.117486).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074209\n",
      "\tspeed: 0.0630s/iter; left time: 1348.4267s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001854\n",
      "\tspeed: 0.0304s/iter; left time: 646.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.1010666 Vali Loss: 0.1169583 Test Loss: 0.1422356\n",
      "Validation loss decreased (0.117486 --> 0.116958).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989520\n",
      "\tspeed: 0.0643s/iter; left time: 1362.2979s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977094\n",
      "\tspeed: 0.0310s/iter; left time: 653.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0997825 Vali Loss: 0.1166532 Test Loss: 0.1427568\n",
      "Validation loss decreased (0.116958 --> 0.116653).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0942127\n",
      "\tspeed: 0.0627s/iter; left time: 1314.4173s\n",
      "\titers: 200, epoch: 7 | loss: 0.0975899\n",
      "\tspeed: 0.0325s/iter; left time: 677.7321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0985532 Vali Loss: 0.1167040 Test Loss: 0.1430438\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0976923\n",
      "\tspeed: 0.0640s/iter; left time: 1327.8153s\n",
      "\titers: 200, epoch: 8 | loss: 0.0960573\n",
      "\tspeed: 0.0375s/iter; left time: 773.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 224 | Train Loss: 0.0973627 Vali Loss: 0.1159907 Test Loss: 0.1423306\n",
      "Validation loss decreased (0.116653 --> 0.115991).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0953182\n",
      "\tspeed: 0.0655s/iter; left time: 1343.9587s\n",
      "\titers: 200, epoch: 9 | loss: 0.0952382\n",
      "\tspeed: 0.0346s/iter; left time: 706.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0962679 Vali Loss: 0.1164612 Test Loss: 0.1433991\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0937599\n",
      "\tspeed: 0.0602s/iter; left time: 1220.6900s\n",
      "\titers: 200, epoch: 10 | loss: 0.0933965\n",
      "\tspeed: 0.0345s/iter; left time: 696.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0953636 Vali Loss: 0.1165707 Test Loss: 0.1438840\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0931610\n",
      "\tspeed: 0.0618s/iter; left time: 1239.9672s\n",
      "\titers: 200, epoch: 11 | loss: 0.0885064\n",
      "\tspeed: 0.0386s/iter; left time: 770.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 224 | Train Loss: 0.0946030 Vali Loss: 0.1159253 Test Loss: 0.1434017\n",
      "Validation loss decreased (0.115991 --> 0.115925).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0895501\n",
      "\tspeed: 0.0668s/iter; left time: 1324.8496s\n",
      "\titers: 200, epoch: 12 | loss: 0.0912748\n",
      "\tspeed: 0.0306s/iter; left time: 603.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0939016 Vali Loss: 0.1166419 Test Loss: 0.1436138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0973094\n",
      "\tspeed: 0.0592s/iter; left time: 1160.6325s\n",
      "\titers: 200, epoch: 13 | loss: 0.0974050\n",
      "\tspeed: 0.0294s/iter; left time: 574.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0932893 Vali Loss: 0.1173202 Test Loss: 0.1447276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0905818\n",
      "\tspeed: 0.0596s/iter; left time: 1155.7616s\n",
      "\titers: 200, epoch: 14 | loss: 0.0921348\n",
      "\tspeed: 0.0358s/iter; left time: 691.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0928849 Vali Loss: 0.1163865 Test Loss: 0.1436901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0909728\n",
      "\tspeed: 0.0653s/iter; left time: 1251.5580s\n",
      "\titers: 200, epoch: 15 | loss: 0.0944395\n",
      "\tspeed: 0.0360s/iter; left time: 686.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.0923803 Vali Loss: 0.1168629 Test Loss: 0.1441083\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0966858\n",
      "\tspeed: 0.0649s/iter; left time: 1228.3572s\n",
      "\titers: 200, epoch: 16 | loss: 0.0883803\n",
      "\tspeed: 0.0331s/iter; left time: 624.4010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0919351 Vali Loss: 0.1172677 Test Loss: 0.1449067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0877402\n",
      "\tspeed: 0.0628s/iter; left time: 1176.3239s\n",
      "\titers: 200, epoch: 17 | loss: 0.0864297\n",
      "\tspeed: 0.0311s/iter; left time: 579.0051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0915777 Vali Loss: 0.1172464 Test Loss: 0.1447186\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0901712\n",
      "\tspeed: 0.0594s/iter; left time: 1097.9543s\n",
      "\titers: 200, epoch: 18 | loss: 0.0931668\n",
      "\tspeed: 0.0292s/iter; left time: 537.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0912132 Vali Loss: 0.1169971 Test Loss: 0.1446571\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0890301\n",
      "\tspeed: 0.0580s/iter; left time: 1059.4232s\n",
      "\titers: 200, epoch: 19 | loss: 0.0909016\n",
      "\tspeed: 0.0319s/iter; left time: 580.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0909894 Vali Loss: 0.1170342 Test Loss: 0.1449162\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0906149\n",
      "\tspeed: 0.0648s/iter; left time: 1169.9141s\n",
      "\titers: 200, epoch: 20 | loss: 0.0924559\n",
      "\tspeed: 0.0384s/iter; left time: 689.6068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0907037 Vali Loss: 0.1172129 Test Loss: 0.1446804\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0920871\n",
      "\tspeed: 0.0631s/iter; left time: 1124.6521s\n",
      "\titers: 200, epoch: 21 | loss: 0.0914993\n",
      "\tspeed: 0.0304s/iter; left time: 537.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0904681 Vali Loss: 0.1170410 Test Loss: 0.1449878\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04481872543692589, rmse:0.2117043286561966, mae:0.14340177178382874, rse:0.7321031093597412\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1528422\n",
      "\tspeed: 0.0373s/iter; left time: 832.8059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1432328\n",
      "\tspeed: 0.0377s/iter; left time: 836.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.1491441 Vali Loss: 0.1518148 Test Loss: 0.1783829\n",
      "Validation loss decreased (inf --> 0.151815).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1209230\n",
      "\tspeed: 0.0656s/iter; left time: 1447.3016s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070437\n",
      "\tspeed: 0.0368s/iter; left time: 809.3725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 224 | Train Loss: 0.1185052 Vali Loss: 0.1205223 Test Loss: 0.1407342\n",
      "Validation loss decreased (0.151815 --> 0.120522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036206\n",
      "\tspeed: 0.0669s/iter; left time: 1461.3336s\n",
      "\titers: 200, epoch: 3 | loss: 0.0998485\n",
      "\tspeed: 0.0372s/iter; left time: 809.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.1050476 Vali Loss: 0.1183256 Test Loss: 0.1410274\n",
      "Validation loss decreased (0.120522 --> 0.118326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029379\n",
      "\tspeed: 0.0662s/iter; left time: 1432.7807s\n",
      "\titers: 200, epoch: 4 | loss: 0.0996977\n",
      "\tspeed: 0.0315s/iter; left time: 677.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.1025588 Vali Loss: 0.1175615 Test Loss: 0.1410190\n",
      "Validation loss decreased (0.118326 --> 0.117562).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1042620\n",
      "\tspeed: 0.0623s/iter; left time: 1332.6897s\n",
      "\titers: 200, epoch: 5 | loss: 0.0975149\n",
      "\tspeed: 0.0332s/iter; left time: 706.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.1008937 Vali Loss: 0.1170742 Test Loss: 0.1424109\n",
      "Validation loss decreased (0.117562 --> 0.117074).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0967736\n",
      "\tspeed: 0.0630s/iter; left time: 1334.1247s\n",
      "\titers: 200, epoch: 6 | loss: 0.0984031\n",
      "\tspeed: 0.0303s/iter; left time: 639.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0995236 Vali Loss: 0.1173206 Test Loss: 0.1429236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955075\n",
      "\tspeed: 0.0641s/iter; left time: 1343.8938s\n",
      "\titers: 200, epoch: 7 | loss: 0.1020706\n",
      "\tspeed: 0.0328s/iter; left time: 684.8137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0982203 Vali Loss: 0.1169116 Test Loss: 0.1421822\n",
      "Validation loss decreased (0.117074 --> 0.116912).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0928175\n",
      "\tspeed: 0.0591s/iter; left time: 1224.4043s\n",
      "\titers: 200, epoch: 8 | loss: 0.0956089\n",
      "\tspeed: 0.0300s/iter; left time: 618.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0969631 Vali Loss: 0.1178373 Test Loss: 0.1445453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0945844\n",
      "\tspeed: 0.0646s/iter; left time: 1325.8007s\n",
      "\titers: 200, epoch: 9 | loss: 0.0958513\n",
      "\tspeed: 0.0294s/iter; left time: 601.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0958829 Vali Loss: 0.1175968 Test Loss: 0.1436751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0904369\n",
      "\tspeed: 0.0584s/iter; left time: 1184.7544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0933154\n",
      "\tspeed: 0.0296s/iter; left time: 597.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0948495 Vali Loss: 0.1180482 Test Loss: 0.1449370\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0921742\n",
      "\tspeed: 0.0589s/iter; left time: 1182.4944s\n",
      "\titers: 200, epoch: 11 | loss: 0.0914332\n",
      "\tspeed: 0.0338s/iter; left time: 675.3952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0939910 Vali Loss: 0.1183347 Test Loss: 0.1451509\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0917301\n",
      "\tspeed: 0.0654s/iter; left time: 1297.9214s\n",
      "\titers: 200, epoch: 12 | loss: 0.0937187\n",
      "\tspeed: 0.0341s/iter; left time: 673.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0932116 Vali Loss: 0.1190290 Test Loss: 0.1454934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0977293\n",
      "\tspeed: 0.0629s/iter; left time: 1232.9129s\n",
      "\titers: 200, epoch: 13 | loss: 0.0916956\n",
      "\tspeed: 0.0291s/iter; left time: 567.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0925045 Vali Loss: 0.1190456 Test Loss: 0.1459329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0906347\n",
      "\tspeed: 0.0593s/iter; left time: 1150.4870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0914610\n",
      "\tspeed: 0.0291s/iter; left time: 562.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0918318 Vali Loss: 0.1191647 Test Loss: 0.1458612\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0908393\n",
      "\tspeed: 0.0583s/iter; left time: 1117.1840s\n",
      "\titers: 200, epoch: 15 | loss: 0.0942632\n",
      "\tspeed: 0.0292s/iter; left time: 556.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0912984 Vali Loss: 0.1198643 Test Loss: 0.1470557\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0908727\n",
      "\tspeed: 0.0579s/iter; left time: 1095.9755s\n",
      "\titers: 200, epoch: 16 | loss: 0.0914437\n",
      "\tspeed: 0.0292s/iter; left time: 550.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0907662 Vali Loss: 0.1201484 Test Loss: 0.1478273\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0880850\n",
      "\tspeed: 0.0584s/iter; left time: 1093.2513s\n",
      "\titers: 200, epoch: 17 | loss: 0.0912122\n",
      "\tspeed: 0.0291s/iter; left time: 541.9648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0903557 Vali Loss: 0.1201671 Test Loss: 0.1471371\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04384249448776245, rmse:0.20938599109649658, mae:0.14218220114707947, rse:0.7240859270095825\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:12.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1510125\n",
      "\tspeed: 0.0581s/iter; left time: 1289.1294s\n",
      "\titers: 200, epoch: 1 | loss: 0.1460141\n",
      "\tspeed: 0.0323s/iter; left time: 713.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.1503453 Vali Loss: 0.1539050 Test Loss: 0.1814873\n",
      "Validation loss decreased (inf --> 0.153905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1220895\n",
      "\tspeed: 0.0669s/iter; left time: 1470.3063s\n",
      "\titers: 200, epoch: 2 | loss: 0.1078975\n",
      "\tspeed: 0.0354s/iter; left time: 774.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 223 | Train Loss: 0.1217292 Vali Loss: 0.1243885 Test Loss: 0.1467298\n",
      "Validation loss decreased (0.153905 --> 0.124388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145073\n",
      "\tspeed: 0.0641s/iter; left time: 1395.5629s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081278\n",
      "\tspeed: 0.0324s/iter; left time: 702.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 223 | Train Loss: 0.1094722 Vali Loss: 0.1223220 Test Loss: 0.1469709\n",
      "Validation loss decreased (0.124388 --> 0.122322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053047\n",
      "\tspeed: 0.0637s/iter; left time: 1370.6058s\n",
      "\titers: 200, epoch: 4 | loss: 0.1045539\n",
      "\tspeed: 0.0346s/iter; left time: 741.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.1068624 Vali Loss: 0.1214676 Test Loss: 0.1486108\n",
      "Validation loss decreased (0.122322 --> 0.121468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1042434\n",
      "\tspeed: 0.0615s/iter; left time: 1310.6269s\n",
      "\titers: 200, epoch: 5 | loss: 0.1094913\n",
      "\tspeed: 0.0296s/iter; left time: 627.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.1051321 Vali Loss: 0.1207100 Test Loss: 0.1481413\n",
      "Validation loss decreased (0.121468 --> 0.120710).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052476\n",
      "\tspeed: 0.0605s/iter; left time: 1275.0874s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002916\n",
      "\tspeed: 0.0305s/iter; left time: 640.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.1036120 Vali Loss: 0.1213116 Test Loss: 0.1490655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003036\n",
      "\tspeed: 0.0587s/iter; left time: 1223.9696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1022745\n",
      "\tspeed: 0.0294s/iter; left time: 610.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1022487 Vali Loss: 0.1211078 Test Loss: 0.1485610\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0986450\n",
      "\tspeed: 0.0586s/iter; left time: 1209.1617s\n",
      "\titers: 200, epoch: 8 | loss: 0.1077900\n",
      "\tspeed: 0.0294s/iter; left time: 603.2463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1008363 Vali Loss: 0.1215522 Test Loss: 0.1486728\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0967671\n",
      "\tspeed: 0.0634s/iter; left time: 1294.8626s\n",
      "\titers: 200, epoch: 9 | loss: 0.0943255\n",
      "\tspeed: 0.0352s/iter; left time: 714.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0996088 Vali Loss: 0.1225537 Test Loss: 0.1496329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975155\n",
      "\tspeed: 0.0599s/iter; left time: 1210.5887s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030245\n",
      "\tspeed: 0.0294s/iter; left time: 590.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.0985247 Vali Loss: 0.1229634 Test Loss: 0.1504967\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0956996\n",
      "\tspeed: 0.0579s/iter; left time: 1156.7477s\n",
      "\titers: 200, epoch: 11 | loss: 0.0954031\n",
      "\tspeed: 0.0296s/iter; left time: 587.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0976670 Vali Loss: 0.1236078 Test Loss: 0.1526822\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0934977\n",
      "\tspeed: 0.0588s/iter; left time: 1161.2519s\n",
      "\titers: 200, epoch: 12 | loss: 0.0943263\n",
      "\tspeed: 0.0297s/iter; left time: 584.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.0967663 Vali Loss: 0.1231789 Test Loss: 0.1517237\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0927984\n",
      "\tspeed: 0.0591s/iter; left time: 1154.4283s\n",
      "\titers: 200, epoch: 13 | loss: 0.0925208\n",
      "\tspeed: 0.0306s/iter; left time: 593.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0961000 Vali Loss: 0.1238943 Test Loss: 0.1523646\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975284\n",
      "\tspeed: 0.0587s/iter; left time: 1132.5758s\n",
      "\titers: 200, epoch: 14 | loss: 0.0922861\n",
      "\tspeed: 0.0301s/iter; left time: 577.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0955001 Vali Loss: 0.1236882 Test Loss: 0.1524754\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0933513\n",
      "\tspeed: 0.0611s/iter; left time: 1166.5009s\n",
      "\titers: 200, epoch: 15 | loss: 0.0961646\n",
      "\tspeed: 0.0309s/iter; left time: 586.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.0948881 Vali Loss: 0.1234963 Test Loss: 0.1529992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04586709663271904, rmse:0.2141660451889038, mae:0.1481413096189499, rse:0.7425444722175598\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1484915\n",
      "\tspeed: 0.0322s/iter; left time: 715.2285s\n",
      "\titers: 200, epoch: 1 | loss: 0.1435116\n",
      "\tspeed: 0.0298s/iter; left time: 659.6319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1500073 Vali Loss: 0.1536118 Test Loss: 0.1809976\n",
      "Validation loss decreased (inf --> 0.153612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1263730\n",
      "\tspeed: 0.0617s/iter; left time: 1356.7908s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126962\n",
      "\tspeed: 0.0308s/iter; left time: 673.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.1223530 Vali Loss: 0.1246716 Test Loss: 0.1476907\n",
      "Validation loss decreased (0.153612 --> 0.124672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074800\n",
      "\tspeed: 0.0610s/iter; left time: 1326.2767s\n",
      "\titers: 200, epoch: 3 | loss: 0.1074836\n",
      "\tspeed: 0.0296s/iter; left time: 641.8954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1094656 Vali Loss: 0.1228897 Test Loss: 0.1473929\n",
      "Validation loss decreased (0.124672 --> 0.122890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1081544\n",
      "\tspeed: 0.0613s/iter; left time: 1320.3170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1076830\n",
      "\tspeed: 0.0307s/iter; left time: 657.0209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.1069529 Vali Loss: 0.1219646 Test Loss: 0.1484883\n",
      "Validation loss decreased (0.122890 --> 0.121965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1080024\n",
      "\tspeed: 0.0597s/iter; left time: 1271.2024s\n",
      "\titers: 200, epoch: 5 | loss: 0.1023990\n",
      "\tspeed: 0.0294s/iter; left time: 624.4088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1052608 Vali Loss: 0.1218475 Test Loss: 0.1491227\n",
      "Validation loss decreased (0.121965 --> 0.121848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036280\n",
      "\tspeed: 0.0598s/iter; left time: 1260.2081s\n",
      "\titers: 200, epoch: 6 | loss: 0.1059826\n",
      "\tspeed: 0.0295s/iter; left time: 619.0084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1037179 Vali Loss: 0.1218491 Test Loss: 0.1493782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026981\n",
      "\tspeed: 0.0590s/iter; left time: 1230.2367s\n",
      "\titers: 200, epoch: 7 | loss: 0.1011233\n",
      "\tspeed: 0.0295s/iter; left time: 611.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1022274 Vali Loss: 0.1216680 Test Loss: 0.1489558\n",
      "Validation loss decreased (0.121848 --> 0.121668).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960192\n",
      "\tspeed: 0.0596s/iter; left time: 1230.5933s\n",
      "\titers: 200, epoch: 8 | loss: 0.1012271\n",
      "\tspeed: 0.0295s/iter; left time: 605.3054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1008472 Vali Loss: 0.1225533 Test Loss: 0.1500781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996663\n",
      "\tspeed: 0.0602s/iter; left time: 1229.0034s\n",
      "\titers: 200, epoch: 9 | loss: 0.0983695\n",
      "\tspeed: 0.0300s/iter; left time: 609.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.0997833 Vali Loss: 0.1224898 Test Loss: 0.1514827\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1044743\n",
      "\tspeed: 0.0598s/iter; left time: 1208.5271s\n",
      "\titers: 200, epoch: 10 | loss: 0.0997800\n",
      "\tspeed: 0.0295s/iter; left time: 591.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0986526 Vali Loss: 0.1233738 Test Loss: 0.1524927\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0979586\n",
      "\tspeed: 0.0605s/iter; left time: 1207.6222s\n",
      "\titers: 200, epoch: 11 | loss: 0.1012520\n",
      "\tspeed: 0.0301s/iter; left time: 597.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0977971 Vali Loss: 0.1234017 Test Loss: 0.1534966\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0967975\n",
      "\tspeed: 0.0586s/iter; left time: 1157.0775s\n",
      "\titers: 200, epoch: 12 | loss: 0.0981619\n",
      "\tspeed: 0.0302s/iter; left time: 593.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.0969688 Vali Loss: 0.1232249 Test Loss: 0.1530467\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0983059\n",
      "\tspeed: 0.0586s/iter; left time: 1143.7671s\n",
      "\titers: 200, epoch: 13 | loss: 0.1010930\n",
      "\tspeed: 0.0294s/iter; left time: 571.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0961352 Vali Loss: 0.1235310 Test Loss: 0.1531597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920885\n",
      "\tspeed: 0.0612s/iter; left time: 1182.2100s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965579\n",
      "\tspeed: 0.0302s/iter; left time: 580.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.0955153 Vali Loss: 0.1238058 Test Loss: 0.1537561\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0939048\n",
      "\tspeed: 0.0593s/iter; left time: 1131.9074s\n",
      "\titers: 200, epoch: 15 | loss: 0.0935039\n",
      "\tspeed: 0.0294s/iter; left time: 558.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0949671 Vali Loss: 0.1234445 Test Loss: 0.1529925\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0956223\n",
      "\tspeed: 0.0589s/iter; left time: 1110.7160s\n",
      "\titers: 200, epoch: 16 | loss: 0.0923481\n",
      "\tspeed: 0.0295s/iter; left time: 552.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0945208 Vali Loss: 0.1241103 Test Loss: 0.1539525\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0888320\n",
      "\tspeed: 0.0593s/iter; left time: 1104.0975s\n",
      "\titers: 200, epoch: 17 | loss: 0.0919176\n",
      "\tspeed: 0.0316s/iter; left time: 585.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.0940548 Vali Loss: 0.1241699 Test Loss: 0.1546139\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04672815278172493, rmse:0.21616695821285248, mae:0.14895574748516083, rse:0.7494819164276123\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:06.90s\n",
      "Intermediate time for GB: 00h:19m:13.62s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1721672\n",
      "\tspeed: 0.0461s/iter; left time: 1028.7693s\n",
      "\titers: 200, epoch: 1 | loss: 0.1541415\n",
      "\tspeed: 0.0238s/iter; left time: 528.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.1675985 Vali Loss: 0.1512479 Test Loss: 0.1809724\n",
      "Validation loss decreased (inf --> 0.151248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780379\n",
      "\tspeed: 0.0494s/iter; left time: 1091.1660s\n",
      "\titers: 200, epoch: 2 | loss: 0.0692572\n",
      "\tspeed: 0.0262s/iter; left time: 574.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0879753 Vali Loss: 0.0655792 Test Loss: 0.0731002\n",
      "Validation loss decreased (0.151248 --> 0.065579).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0671448\n",
      "\tspeed: 0.0540s/iter; left time: 1180.8418s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669683\n",
      "\tspeed: 0.0346s/iter; left time: 752.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0660800 Vali Loss: 0.0612512 Test Loss: 0.0685301\n",
      "Validation loss decreased (0.065579 --> 0.061251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627315\n",
      "\tspeed: 0.0568s/iter; left time: 1229.1771s\n",
      "\titers: 200, epoch: 4 | loss: 0.0589354\n",
      "\tspeed: 0.0280s/iter; left time: 602.4275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0623051 Vali Loss: 0.0593758 Test Loss: 0.0663927\n",
      "Validation loss decreased (0.061251 --> 0.059376).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630472\n",
      "\tspeed: 0.0433s/iter; left time: 926.8955s\n",
      "\titers: 200, epoch: 5 | loss: 0.0602869\n",
      "\tspeed: 0.0255s/iter; left time: 542.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0600424 Vali Loss: 0.0578820 Test Loss: 0.0648575\n",
      "Validation loss decreased (0.059376 --> 0.057882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594011\n",
      "\tspeed: 0.0495s/iter; left time: 1047.8329s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568600\n",
      "\tspeed: 0.0245s/iter; left time: 517.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0585781 Vali Loss: 0.0568827 Test Loss: 0.0638525\n",
      "Validation loss decreased (0.057882 --> 0.056883).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563148\n",
      "\tspeed: 0.0487s/iter; left time: 1020.1666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0567453\n",
      "\tspeed: 0.0237s/iter; left time: 494.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0575676 Vali Loss: 0.0562464 Test Loss: 0.0631524\n",
      "Validation loss decreased (0.056883 --> 0.056246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0558760\n",
      "\tspeed: 0.0443s/iter; left time: 917.9178s\n",
      "\titers: 200, epoch: 8 | loss: 0.0579761\n",
      "\tspeed: 0.0244s/iter; left time: 503.1764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0568867 Vali Loss: 0.0558712 Test Loss: 0.0627775\n",
      "Validation loss decreased (0.056246 --> 0.055871).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550179\n",
      "\tspeed: 0.0495s/iter; left time: 1015.8744s\n",
      "\titers: 200, epoch: 9 | loss: 0.0563627\n",
      "\tspeed: 0.0233s/iter; left time: 476.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0563171 Vali Loss: 0.0555385 Test Loss: 0.0625146\n",
      "Validation loss decreased (0.055871 --> 0.055538).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541733\n",
      "\tspeed: 0.0480s/iter; left time: 974.5547s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585516\n",
      "\tspeed: 0.0288s/iter; left time: 581.1289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0558124 Vali Loss: 0.0551824 Test Loss: 0.0620765\n",
      "Validation loss decreased (0.055538 --> 0.055182).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569852\n",
      "\tspeed: 0.0430s/iter; left time: 862.6368s\n",
      "\titers: 200, epoch: 11 | loss: 0.0544668\n",
      "\tspeed: 0.0202s/iter; left time: 404.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0554116 Vali Loss: 0.0549211 Test Loss: 0.0618197\n",
      "Validation loss decreased (0.055182 --> 0.054921).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540032\n",
      "\tspeed: 0.0431s/iter; left time: 855.5352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546257\n",
      "\tspeed: 0.0222s/iter; left time: 438.1058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0550291 Vali Loss: 0.0545743 Test Loss: 0.0615266\n",
      "Validation loss decreased (0.054921 --> 0.054574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0511341\n",
      "\tspeed: 0.0461s/iter; left time: 905.1339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562718\n",
      "\tspeed: 0.0244s/iter; left time: 476.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0547906 Vali Loss: 0.0546620 Test Loss: 0.0614961\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0558587\n",
      "\tspeed: 0.0526s/iter; left time: 1020.3312s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546150\n",
      "\tspeed: 0.0293s/iter; left time: 564.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0545490 Vali Loss: 0.0545183 Test Loss: 0.0613927\n",
      "Validation loss decreased (0.054574 --> 0.054518).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518050\n",
      "\tspeed: 0.0500s/iter; left time: 958.1128s\n",
      "\titers: 200, epoch: 15 | loss: 0.0536502\n",
      "\tspeed: 0.0272s/iter; left time: 518.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0542878 Vali Loss: 0.0543094 Test Loss: 0.0612394\n",
      "Validation loss decreased (0.054518 --> 0.054309).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0536641\n",
      "\tspeed: 0.0507s/iter; left time: 960.5009s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557155\n",
      "\tspeed: 0.0324s/iter; left time: 610.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.0541524 Vali Loss: 0.0542523 Test Loss: 0.0609261\n",
      "Validation loss decreased (0.054309 --> 0.054252).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0548307\n",
      "\tspeed: 0.0564s/iter; left time: 1054.8835s\n",
      "\titers: 200, epoch: 17 | loss: 0.0553817\n",
      "\tspeed: 0.0307s/iter; left time: 570.7841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0540486 Vali Loss: 0.0543452 Test Loss: 0.0611064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0527278\n",
      "\tspeed: 0.0550s/iter; left time: 1016.5029s\n",
      "\titers: 200, epoch: 18 | loss: 0.0522661\n",
      "\tspeed: 0.0266s/iter; left time: 489.7045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0537799 Vali Loss: 0.0541636 Test Loss: 0.0608962\n",
      "Validation loss decreased (0.054252 --> 0.054164).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0565891\n",
      "\tspeed: 0.0502s/iter; left time: 916.5987s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534971\n",
      "\tspeed: 0.0229s/iter; left time: 416.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0536614 Vali Loss: 0.0540985 Test Loss: 0.0608358\n",
      "Validation loss decreased (0.054164 --> 0.054098).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522145\n",
      "\tspeed: 0.0473s/iter; left time: 853.7107s\n",
      "\titers: 200, epoch: 20 | loss: 0.0552006\n",
      "\tspeed: 0.0187s/iter; left time: 335.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0535905 Vali Loss: 0.0539736 Test Loss: 0.0607711\n",
      "Validation loss decreased (0.054098 --> 0.053974).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0508549\n",
      "\tspeed: 0.0515s/iter; left time: 917.6317s\n",
      "\titers: 200, epoch: 21 | loss: 0.0507478\n",
      "\tspeed: 0.0267s/iter; left time: 472.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0534782 Vali Loss: 0.0540449 Test Loss: 0.0607862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0527667\n",
      "\tspeed: 0.0490s/iter; left time: 862.2335s\n",
      "\titers: 200, epoch: 22 | loss: 0.0554709\n",
      "\tspeed: 0.0277s/iter; left time: 485.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0534237 Vali Loss: 0.0538062 Test Loss: 0.0605577\n",
      "Validation loss decreased (0.053974 --> 0.053806).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0526895\n",
      "\tspeed: 0.0452s/iter; left time: 785.9094s\n",
      "\titers: 200, epoch: 23 | loss: 0.0548000\n",
      "\tspeed: 0.0207s/iter; left time: 357.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0533545 Vali Loss: 0.0540241 Test Loss: 0.0607429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0553322\n",
      "\tspeed: 0.0538s/iter; left time: 922.1891s\n",
      "\titers: 200, epoch: 24 | loss: 0.0526196\n",
      "\tspeed: 0.0332s/iter; left time: 566.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0532674 Vali Loss: 0.0538414 Test Loss: 0.0606128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552076\n",
      "\tspeed: 0.0522s/iter; left time: 882.7611s\n",
      "\titers: 200, epoch: 25 | loss: 0.0558971\n",
      "\tspeed: 0.0295s/iter; left time: 495.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0532299 Vali Loss: 0.0538360 Test Loss: 0.0604983\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0541920\n",
      "\tspeed: 0.0496s/iter; left time: 827.5890s\n",
      "\titers: 200, epoch: 26 | loss: 0.0512586\n",
      "\tspeed: 0.0336s/iter; left time: 557.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0531372 Vali Loss: 0.0538423 Test Loss: 0.0605707\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0552980\n",
      "\tspeed: 0.0602s/iter; left time: 991.7176s\n",
      "\titers: 200, epoch: 27 | loss: 0.0546119\n",
      "\tspeed: 0.0363s/iter; left time: 594.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.0531039 Vali Loss: 0.0537299 Test Loss: 0.0604606\n",
      "Validation loss decreased (0.053806 --> 0.053730).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0542703\n",
      "\tspeed: 0.0554s/iter; left time: 900.3537s\n",
      "\titers: 200, epoch: 28 | loss: 0.0542593\n",
      "\tspeed: 0.0217s/iter; left time: 350.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0530470 Vali Loss: 0.0538652 Test Loss: 0.0605928\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0531154\n",
      "\tspeed: 0.0428s/iter; left time: 686.7075s\n",
      "\titers: 200, epoch: 29 | loss: 0.0587752\n",
      "\tspeed: 0.0257s/iter; left time: 410.0519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0530438 Vali Loss: 0.0538108 Test Loss: 0.0605678\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0532910\n",
      "\tspeed: 0.0467s/iter; left time: 737.9518s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541981\n",
      "\tspeed: 0.0303s/iter; left time: 475.6847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0530180 Vali Loss: 0.0537588 Test Loss: 0.0604486\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0539336\n",
      "\tspeed: 0.0524s/iter; left time: 816.4467s\n",
      "\titers: 200, epoch: 31 | loss: 0.0527906\n",
      "\tspeed: 0.0194s/iter; left time: 299.8852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0529693 Vali Loss: 0.0537976 Test Loss: 0.0603974\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0530251\n",
      "\tspeed: 0.0538s/iter; left time: 826.3014s\n",
      "\titers: 200, epoch: 32 | loss: 0.0534587\n",
      "\tspeed: 0.0311s/iter; left time: 474.0028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0529361 Vali Loss: 0.0537762 Test Loss: 0.0606050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0513459\n",
      "\tspeed: 0.0536s/iter; left time: 810.8710s\n",
      "\titers: 200, epoch: 33 | loss: 0.0527238\n",
      "\tspeed: 0.0237s/iter; left time: 355.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.0528643 Vali Loss: 0.0536668 Test Loss: 0.0603340\n",
      "Validation loss decreased (0.053730 --> 0.053667).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0534117\n",
      "\tspeed: 0.0514s/iter; left time: 765.6818s\n",
      "\titers: 200, epoch: 34 | loss: 0.0554972\n",
      "\tspeed: 0.0303s/iter; left time: 449.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0529084 Vali Loss: 0.0536161 Test Loss: 0.0603248\n",
      "Validation loss decreased (0.053667 --> 0.053616).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0555938\n",
      "\tspeed: 0.0452s/iter; left time: 664.1360s\n",
      "\titers: 200, epoch: 35 | loss: 0.0554922\n",
      "\tspeed: 0.0230s/iter; left time: 335.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0527991 Vali Loss: 0.0536807 Test Loss: 0.0603583\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0534741\n",
      "\tspeed: 0.0467s/iter; left time: 674.7763s\n",
      "\titers: 200, epoch: 36 | loss: 0.0507358\n",
      "\tspeed: 0.0307s/iter; left time: 441.2382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0528715 Vali Loss: 0.0537187 Test Loss: 0.0603961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0589244\n",
      "\tspeed: 0.0517s/iter; left time: 736.6141s\n",
      "\titers: 200, epoch: 37 | loss: 0.0512328\n",
      "\tspeed: 0.0279s/iter; left time: 395.0400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0528246 Vali Loss: 0.0537654 Test Loss: 0.0604676\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0534262\n",
      "\tspeed: 0.0487s/iter; left time: 682.4215s\n",
      "\titers: 200, epoch: 38 | loss: 0.0507384\n",
      "\tspeed: 0.0252s/iter; left time: 351.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0527757 Vali Loss: 0.0537237 Test Loss: 0.0604896\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0546839\n",
      "\tspeed: 0.0520s/iter; left time: 717.0599s\n",
      "\titers: 200, epoch: 39 | loss: 0.0524795\n",
      "\tspeed: 0.0346s/iter; left time: 472.9626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0527922 Vali Loss: 0.0536326 Test Loss: 0.0603556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0536014\n",
      "\tspeed: 0.0543s/iter; left time: 737.0883s\n",
      "\titers: 200, epoch: 40 | loss: 0.0521276\n",
      "\tspeed: 0.0279s/iter; left time: 375.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0527564 Vali Loss: 0.0536932 Test Loss: 0.0603453\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0498233\n",
      "\tspeed: 0.0457s/iter; left time: 609.3565s\n",
      "\titers: 200, epoch: 41 | loss: 0.0510707\n",
      "\tspeed: 0.0236s/iter; left time: 313.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0527845 Vali Loss: 0.0536267 Test Loss: 0.0603210\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0519056\n",
      "\tspeed: 0.0483s/iter; left time: 633.8983s\n",
      "\titers: 200, epoch: 42 | loss: 0.0553082\n",
      "\tspeed: 0.0312s/iter; left time: 405.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0528060 Vali Loss: 0.0537350 Test Loss: 0.0604204\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0518125\n",
      "\tspeed: 0.0548s/iter; left time: 707.0569s\n",
      "\titers: 200, epoch: 43 | loss: 0.0501898\n",
      "\tspeed: 0.0269s/iter; left time: 343.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0527499 Vali Loss: 0.0536183 Test Loss: 0.0602574\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0530317\n",
      "\tspeed: 0.0498s/iter; left time: 631.4154s\n",
      "\titers: 200, epoch: 44 | loss: 0.0552856\n",
      "\tspeed: 0.0286s/iter; left time: 360.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0527741 Vali Loss: 0.0536098 Test Loss: 0.0603290\n",
      "Validation loss decreased (0.053616 --> 0.053610).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0577163\n",
      "\tspeed: 0.0460s/iter; left time: 571.9236s\n",
      "\titers: 200, epoch: 45 | loss: 0.0532037\n",
      "\tspeed: 0.0209s/iter; left time: 257.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0527890 Vali Loss: 0.0536057 Test Loss: 0.0603109\n",
      "Validation loss decreased (0.053610 --> 0.053606).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0560924\n",
      "\tspeed: 0.0456s/iter; left time: 556.8176s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554193\n",
      "\tspeed: 0.0244s/iter; left time: 295.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0527749 Vali Loss: 0.0535805 Test Loss: 0.0603079\n",
      "Validation loss decreased (0.053606 --> 0.053580).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0526398\n",
      "\tspeed: 0.0546s/iter; left time: 655.5660s\n",
      "\titers: 200, epoch: 47 | loss: 0.0527552\n",
      "\tspeed: 0.0246s/iter; left time: 292.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0527131 Vali Loss: 0.0536683 Test Loss: 0.0602768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0510842\n",
      "\tspeed: 0.0498s/iter; left time: 585.9482s\n",
      "\titers: 200, epoch: 48 | loss: 0.0518265\n",
      "\tspeed: 0.0244s/iter; left time: 285.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0527187 Vali Loss: 0.0535588 Test Loss: 0.0602585\n",
      "Validation loss decreased (0.053580 --> 0.053559).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0533891\n",
      "\tspeed: 0.0423s/iter; left time: 488.7598s\n",
      "\titers: 200, epoch: 49 | loss: 0.0517327\n",
      "\tspeed: 0.0187s/iter; left time: 214.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0526929 Vali Loss: 0.0535987 Test Loss: 0.0602448\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0503616\n",
      "\tspeed: 0.0400s/iter; left time: 452.6482s\n",
      "\titers: 200, epoch: 50 | loss: 0.0520407\n",
      "\tspeed: 0.0187s/iter; left time: 209.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0527528 Vali Loss: 0.0535541 Test Loss: 0.0603060\n",
      "Validation loss decreased (0.053559 --> 0.053554).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0530550\n",
      "\tspeed: 0.0471s/iter; left time: 522.7510s\n",
      "\titers: 200, epoch: 51 | loss: 0.0567553\n",
      "\tspeed: 0.0284s/iter; left time: 312.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0527032 Vali Loss: 0.0535505 Test Loss: 0.0603045\n",
      "Validation loss decreased (0.053554 --> 0.053551).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0511859\n",
      "\tspeed: 0.0434s/iter; left time: 471.7346s\n",
      "\titers: 200, epoch: 52 | loss: 0.0556174\n",
      "\tspeed: 0.0206s/iter; left time: 222.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0527118 Vali Loss: 0.0536644 Test Loss: 0.0602795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0547255\n",
      "\tspeed: 0.0423s/iter; left time: 451.0082s\n",
      "\titers: 200, epoch: 53 | loss: 0.0532421\n",
      "\tspeed: 0.0202s/iter; left time: 212.6678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0526842 Vali Loss: 0.0537316 Test Loss: 0.0604937\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0506666\n",
      "\tspeed: 0.0403s/iter; left time: 420.2314s\n",
      "\titers: 200, epoch: 54 | loss: 0.0542074\n",
      "\tspeed: 0.0207s/iter; left time: 214.1550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0527096 Vali Loss: 0.0536042 Test Loss: 0.0602340\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0526950\n",
      "\tspeed: 0.0491s/iter; left time: 500.8058s\n",
      "\titers: 200, epoch: 55 | loss: 0.0564378\n",
      "\tspeed: 0.0206s/iter; left time: 207.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0526745 Vali Loss: 0.0536381 Test Loss: 0.0602850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0517075\n",
      "\tspeed: 0.0546s/iter; left time: 544.7867s\n",
      "\titers: 200, epoch: 56 | loss: 0.0560369\n",
      "\tspeed: 0.0319s/iter; left time: 315.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0526575 Vali Loss: 0.0535906 Test Loss: 0.0602776\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0536045\n",
      "\tspeed: 0.0510s/iter; left time: 498.0079s\n",
      "\titers: 200, epoch: 57 | loss: 0.0552966\n",
      "\tspeed: 0.0186s/iter; left time: 180.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0526571 Vali Loss: 0.0536229 Test Loss: 0.0603469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0559211\n",
      "\tspeed: 0.0507s/iter; left time: 483.4249s\n",
      "\titers: 200, epoch: 58 | loss: 0.0529706\n",
      "\tspeed: 0.0252s/iter; left time: 237.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0526731 Vali Loss: 0.0536168 Test Loss: 0.0603814\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0548104\n",
      "\tspeed: 0.0523s/iter; left time: 487.1594s\n",
      "\titers: 200, epoch: 59 | loss: 0.0539919\n",
      "\tspeed: 0.0295s/iter; left time: 271.5983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0527139 Vali Loss: 0.0535121 Test Loss: 0.0602561\n",
      "Validation loss decreased (0.053551 --> 0.053512).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0510202\n",
      "\tspeed: 0.0505s/iter; left time: 458.7720s\n",
      "\titers: 200, epoch: 60 | loss: 0.0523315\n",
      "\tspeed: 0.0325s/iter; left time: 292.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0526889 Vali Loss: 0.0536591 Test Loss: 0.0603492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0477654\n",
      "\tspeed: 0.0522s/iter; left time: 462.5408s\n",
      "\titers: 200, epoch: 61 | loss: 0.0505686\n",
      "\tspeed: 0.0217s/iter; left time: 190.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0526917 Vali Loss: 0.0535368 Test Loss: 0.0602524\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0520774\n",
      "\tspeed: 0.0502s/iter; left time: 433.2309s\n",
      "\titers: 200, epoch: 62 | loss: 0.0519234\n",
      "\tspeed: 0.0208s/iter; left time: 177.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0526959 Vali Loss: 0.0536708 Test Loss: 0.0602623\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0574924\n",
      "\tspeed: 0.0504s/iter; left time: 423.8989s\n",
      "\titers: 200, epoch: 63 | loss: 0.0509901\n",
      "\tspeed: 0.0293s/iter; left time: 243.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0526742 Vali Loss: 0.0535775 Test Loss: 0.0602340\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0518607\n",
      "\tspeed: 0.0534s/iter; left time: 437.6281s\n",
      "\titers: 200, epoch: 64 | loss: 0.0540926\n",
      "\tspeed: 0.0302s/iter; left time: 244.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0526507 Vali Loss: 0.0535469 Test Loss: 0.0601903\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0554833\n",
      "\tspeed: 0.0467s/iter; left time: 371.6588s\n",
      "\titers: 200, epoch: 65 | loss: 0.0519514\n",
      "\tspeed: 0.0308s/iter; left time: 242.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0526656 Vali Loss: 0.0536273 Test Loss: 0.0603179\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0524797\n",
      "\tspeed: 0.0467s/iter; left time: 361.4861s\n",
      "\titers: 200, epoch: 66 | loss: 0.0542154\n",
      "\tspeed: 0.0281s/iter; left time: 214.4974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0527117 Vali Loss: 0.0535789 Test Loss: 0.0603196\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0518035\n",
      "\tspeed: 0.0459s/iter; left time: 345.0717s\n",
      "\titers: 200, epoch: 67 | loss: 0.0543421\n",
      "\tspeed: 0.0225s/iter; left time: 166.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0526559 Vali Loss: 0.0536070 Test Loss: 0.0602322\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0524710\n",
      "\tspeed: 0.0405s/iter; left time: 295.4080s\n",
      "\titers: 200, epoch: 68 | loss: 0.0517034\n",
      "\tspeed: 0.0268s/iter; left time: 193.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0526122 Vali Loss: 0.0536740 Test Loss: 0.0604104\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0513951\n",
      "\tspeed: 0.0436s/iter; left time: 308.0068s\n",
      "\titers: 200, epoch: 69 | loss: 0.0502005\n",
      "\tspeed: 0.0198s/iter; left time: 137.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0526997 Vali Loss: 0.0535931 Test Loss: 0.0602744\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009908233769237995, rmse:0.099540114402771, mae:0.060256123542785645, rse:0.29293450713157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1673646\n",
      "\tspeed: 0.0355s/iter; left time: 791.6212s\n",
      "\titers: 200, epoch: 1 | loss: 0.1490372\n",
      "\tspeed: 0.0291s/iter; left time: 646.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.1675892 Vali Loss: 0.1511337 Test Loss: 0.1812893\n",
      "Validation loss decreased (inf --> 0.151134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0820658\n",
      "\tspeed: 0.0522s/iter; left time: 1153.1410s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693956\n",
      "\tspeed: 0.0302s/iter; left time: 664.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0891990 Vali Loss: 0.0668348 Test Loss: 0.0742519\n",
      "Validation loss decreased (0.151134 --> 0.066835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700260\n",
      "\tspeed: 0.0466s/iter; left time: 1018.6247s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639931\n",
      "\tspeed: 0.0293s/iter; left time: 636.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0663924 Vali Loss: 0.0615788 Test Loss: 0.0687149\n",
      "Validation loss decreased (0.066835 --> 0.061579).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623735\n",
      "\tspeed: 0.0518s/iter; left time: 1121.2310s\n",
      "\titers: 200, epoch: 4 | loss: 0.0584388\n",
      "\tspeed: 0.0303s/iter; left time: 652.7444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0625077 Vali Loss: 0.0595094 Test Loss: 0.0665081\n",
      "Validation loss decreased (0.061579 --> 0.059509).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635297\n",
      "\tspeed: 0.0572s/iter; left time: 1225.3662s\n",
      "\titers: 200, epoch: 5 | loss: 0.0611556\n",
      "\tspeed: 0.0336s/iter; left time: 716.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0601792 Vali Loss: 0.0579302 Test Loss: 0.0647701\n",
      "Validation loss decreased (0.059509 --> 0.057930).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0587769\n",
      "\tspeed: 0.0534s/iter; left time: 1130.4492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0594239\n",
      "\tspeed: 0.0269s/iter; left time: 567.5163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0586731 Vali Loss: 0.0571222 Test Loss: 0.0643644\n",
      "Validation loss decreased (0.057930 --> 0.057122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588252\n",
      "\tspeed: 0.0427s/iter; left time: 894.1122s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597037\n",
      "\tspeed: 0.0213s/iter; left time: 443.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0576061 Vali Loss: 0.0564190 Test Loss: 0.0634863\n",
      "Validation loss decreased (0.057122 --> 0.056419).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0559256\n",
      "\tspeed: 0.0552s/iter; left time: 1145.2323s\n",
      "\titers: 200, epoch: 8 | loss: 0.0598261\n",
      "\tspeed: 0.0272s/iter; left time: 560.7500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0568720 Vali Loss: 0.0561782 Test Loss: 0.0629609\n",
      "Validation loss decreased (0.056419 --> 0.056178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0566077\n",
      "\tspeed: 0.0562s/iter; left time: 1153.1048s\n",
      "\titers: 200, epoch: 9 | loss: 0.0582339\n",
      "\tspeed: 0.0269s/iter; left time: 549.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0562994 Vali Loss: 0.0556069 Test Loss: 0.0622403\n",
      "Validation loss decreased (0.056178 --> 0.055607).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0538270\n",
      "\tspeed: 0.0528s/iter; left time: 1070.9803s\n",
      "\titers: 200, epoch: 10 | loss: 0.0572278\n",
      "\tspeed: 0.0241s/iter; left time: 486.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0557670 Vali Loss: 0.0554182 Test Loss: 0.0620933\n",
      "Validation loss decreased (0.055607 --> 0.055418).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552691\n",
      "\tspeed: 0.0497s/iter; left time: 996.2984s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581610\n",
      "\tspeed: 0.0235s/iter; left time: 469.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0553090 Vali Loss: 0.0552593 Test Loss: 0.0621532\n",
      "Validation loss decreased (0.055418 --> 0.055259).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0544145\n",
      "\tspeed: 0.0478s/iter; left time: 947.5874s\n",
      "\titers: 200, epoch: 12 | loss: 0.0519175\n",
      "\tspeed: 0.0281s/iter; left time: 554.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0550046 Vali Loss: 0.0549740 Test Loss: 0.0616868\n",
      "Validation loss decreased (0.055259 --> 0.054974).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530055\n",
      "\tspeed: 0.0550s/iter; left time: 1078.4329s\n",
      "\titers: 200, epoch: 13 | loss: 0.0520902\n",
      "\tspeed: 0.0245s/iter; left time: 477.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0548191 Vali Loss: 0.0546951 Test Loss: 0.0615672\n",
      "Validation loss decreased (0.054974 --> 0.054695).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0549167\n",
      "\tspeed: 0.0413s/iter; left time: 799.9568s\n",
      "\titers: 200, epoch: 14 | loss: 0.0550718\n",
      "\tspeed: 0.0211s/iter; left time: 406.2802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0544927 Vali Loss: 0.0546929 Test Loss: 0.0614881\n",
      "Validation loss decreased (0.054695 --> 0.054693).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0503484\n",
      "\tspeed: 0.0508s/iter; left time: 972.7132s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595914\n",
      "\tspeed: 0.0259s/iter; left time: 492.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0543294 Vali Loss: 0.0545349 Test Loss: 0.0612051\n",
      "Validation loss decreased (0.054693 --> 0.054535).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0511701\n",
      "\tspeed: 0.0498s/iter; left time: 943.3584s\n",
      "\titers: 200, epoch: 16 | loss: 0.0545955\n",
      "\tspeed: 0.0273s/iter; left time: 514.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0540881 Vali Loss: 0.0544143 Test Loss: 0.0611612\n",
      "Validation loss decreased (0.054535 --> 0.054414).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0558501\n",
      "\tspeed: 0.0498s/iter; left time: 932.1170s\n",
      "\titers: 200, epoch: 17 | loss: 0.0533395\n",
      "\tspeed: 0.0237s/iter; left time: 441.9674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0540187 Vali Loss: 0.0544311 Test Loss: 0.0609841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542482\n",
      "\tspeed: 0.0461s/iter; left time: 852.2306s\n",
      "\titers: 200, epoch: 18 | loss: 0.0551157\n",
      "\tspeed: 0.0230s/iter; left time: 423.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0537331 Vali Loss: 0.0543684 Test Loss: 0.0611172\n",
      "Validation loss decreased (0.054414 --> 0.054368).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0528595\n",
      "\tspeed: 0.0417s/iter; left time: 762.4650s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539630\n",
      "\tspeed: 0.0221s/iter; left time: 400.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0537143 Vali Loss: 0.0541498 Test Loss: 0.0608858\n",
      "Validation loss decreased (0.054368 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0561098\n",
      "\tspeed: 0.0519s/iter; left time: 937.1171s\n",
      "\titers: 200, epoch: 20 | loss: 0.0508563\n",
      "\tspeed: 0.0247s/iter; left time: 442.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0535912 Vali Loss: 0.0541897 Test Loss: 0.0609107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0500229\n",
      "\tspeed: 0.0503s/iter; left time: 895.8408s\n",
      "\titers: 200, epoch: 21 | loss: 0.0547695\n",
      "\tspeed: 0.0278s/iter; left time: 492.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0535221 Vali Loss: 0.0541171 Test Loss: 0.0608199\n",
      "Validation loss decreased (0.054150 --> 0.054117).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0514992\n",
      "\tspeed: 0.0467s/iter; left time: 821.7255s\n",
      "\titers: 200, epoch: 22 | loss: 0.0601256\n",
      "\tspeed: 0.0274s/iter; left time: 479.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0533583 Vali Loss: 0.0540180 Test Loss: 0.0607175\n",
      "Validation loss decreased (0.054117 --> 0.054018).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0537657\n",
      "\tspeed: 0.0538s/iter; left time: 934.8541s\n",
      "\titers: 200, epoch: 23 | loss: 0.0512803\n",
      "\tspeed: 0.0257s/iter; left time: 443.3722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0532961 Vali Loss: 0.0541545 Test Loss: 0.0608584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0521242\n",
      "\tspeed: 0.0470s/iter; left time: 805.8851s\n",
      "\titers: 200, epoch: 24 | loss: 0.0543493\n",
      "\tspeed: 0.0299s/iter; left time: 510.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0532858 Vali Loss: 0.0539494 Test Loss: 0.0605272\n",
      "Validation loss decreased (0.054018 --> 0.053949).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0543228\n",
      "\tspeed: 0.0434s/iter; left time: 733.7610s\n",
      "\titers: 200, epoch: 25 | loss: 0.0534940\n",
      "\tspeed: 0.0219s/iter; left time: 367.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0531835 Vali Loss: 0.0539716 Test Loss: 0.0606157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0534218\n",
      "\tspeed: 0.0459s/iter; left time: 766.3616s\n",
      "\titers: 200, epoch: 26 | loss: 0.0581396\n",
      "\tspeed: 0.0283s/iter; left time: 469.9323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0531538 Vali Loss: 0.0540291 Test Loss: 0.0607636\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0542331\n",
      "\tspeed: 0.0480s/iter; left time: 790.4330s\n",
      "\titers: 200, epoch: 27 | loss: 0.0551762\n",
      "\tspeed: 0.0212s/iter; left time: 347.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0530916 Vali Loss: 0.0539005 Test Loss: 0.0604738\n",
      "Validation loss decreased (0.053949 --> 0.053900).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0565018\n",
      "\tspeed: 0.0518s/iter; left time: 842.6392s\n",
      "\titers: 200, epoch: 28 | loss: 0.0534845\n",
      "\tspeed: 0.0292s/iter; left time: 471.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0530536 Vali Loss: 0.0539694 Test Loss: 0.0605189\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0518491\n",
      "\tspeed: 0.0450s/iter; left time: 721.8066s\n",
      "\titers: 200, epoch: 29 | loss: 0.0503613\n",
      "\tspeed: 0.0240s/iter; left time: 382.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0530317 Vali Loss: 0.0539457 Test Loss: 0.0605343\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523239\n",
      "\tspeed: 0.0563s/iter; left time: 890.1845s\n",
      "\titers: 200, epoch: 30 | loss: 0.0535457\n",
      "\tspeed: 0.0293s/iter; left time: 460.0017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0529345 Vali Loss: 0.0538831 Test Loss: 0.0604717\n",
      "Validation loss decreased (0.053900 --> 0.053883).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0524205\n",
      "\tspeed: 0.0426s/iter; left time: 664.0178s\n",
      "\titers: 200, epoch: 31 | loss: 0.0526949\n",
      "\tspeed: 0.0277s/iter; left time: 429.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0529260 Vali Loss: 0.0538308 Test Loss: 0.0604857\n",
      "Validation loss decreased (0.053883 --> 0.053831).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0538551\n",
      "\tspeed: 0.0425s/iter; left time: 652.9969s\n",
      "\titers: 200, epoch: 32 | loss: 0.0547828\n",
      "\tspeed: 0.0204s/iter; left time: 311.7848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0528854 Vali Loss: 0.0539100 Test Loss: 0.0604796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0519553\n",
      "\tspeed: 0.0513s/iter; left time: 775.5994s\n",
      "\titers: 200, epoch: 33 | loss: 0.0553948\n",
      "\tspeed: 0.0289s/iter; left time: 434.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0528371 Vali Loss: 0.0539232 Test Loss: 0.0604207\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0515730\n",
      "\tspeed: 0.0476s/iter; left time: 708.9784s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527292\n",
      "\tspeed: 0.0272s/iter; left time: 403.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0528109 Vali Loss: 0.0537070 Test Loss: 0.0603458\n",
      "Validation loss decreased (0.053831 --> 0.053707).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0512574\n",
      "\tspeed: 0.0433s/iter; left time: 636.5853s\n",
      "\titers: 200, epoch: 35 | loss: 0.0518196\n",
      "\tspeed: 0.0279s/iter; left time: 407.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0527455 Vali Loss: 0.0538808 Test Loss: 0.0605253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0532511\n",
      "\tspeed: 0.0598s/iter; left time: 864.2035s\n",
      "\titers: 200, epoch: 36 | loss: 0.0514526\n",
      "\tspeed: 0.0346s/iter; left time: 497.5132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0528063 Vali Loss: 0.0537461 Test Loss: 0.0604080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0529842\n",
      "\tspeed: 0.0564s/iter; left time: 802.5371s\n",
      "\titers: 200, epoch: 37 | loss: 0.0539141\n",
      "\tspeed: 0.0298s/iter; left time: 420.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.0528484 Vali Loss: 0.0538330 Test Loss: 0.0604458\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0564989\n",
      "\tspeed: 0.0543s/iter; left time: 761.0911s\n",
      "\titers: 200, epoch: 38 | loss: 0.0562279\n",
      "\tspeed: 0.0306s/iter; left time: 426.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0527418 Vali Loss: 0.0540032 Test Loss: 0.0606670\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0575514\n",
      "\tspeed: 0.0564s/iter; left time: 777.2735s\n",
      "\titers: 200, epoch: 39 | loss: 0.0525915\n",
      "\tspeed: 0.0315s/iter; left time: 430.6247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0527111 Vali Loss: 0.0539463 Test Loss: 0.0605065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0520202\n",
      "\tspeed: 0.0489s/iter; left time: 662.6970s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535381\n",
      "\tspeed: 0.0188s/iter; left time: 252.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0527905 Vali Loss: 0.0537046 Test Loss: 0.0602627\n",
      "Validation loss decreased (0.053707 --> 0.053705).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0501463\n",
      "\tspeed: 0.0470s/iter; left time: 626.8869s\n",
      "\titers: 200, epoch: 41 | loss: 0.0534018\n",
      "\tspeed: 0.0264s/iter; left time: 349.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0526976 Vali Loss: 0.0538056 Test Loss: 0.0603502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0507820\n",
      "\tspeed: 0.0537s/iter; left time: 704.2233s\n",
      "\titers: 200, epoch: 42 | loss: 0.0494494\n",
      "\tspeed: 0.0305s/iter; left time: 397.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0527199 Vali Loss: 0.0537610 Test Loss: 0.0604232\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0528273\n",
      "\tspeed: 0.0518s/iter; left time: 668.4255s\n",
      "\titers: 200, epoch: 43 | loss: 0.0503805\n",
      "\tspeed: 0.0230s/iter; left time: 293.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0527138 Vali Loss: 0.0538039 Test Loss: 0.0605537\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0542963\n",
      "\tspeed: 0.0476s/iter; left time: 603.6569s\n",
      "\titers: 200, epoch: 44 | loss: 0.0530080\n",
      "\tspeed: 0.0304s/iter; left time: 382.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0527125 Vali Loss: 0.0538977 Test Loss: 0.0605407\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0541360\n",
      "\tspeed: 0.0553s/iter; left time: 688.0493s\n",
      "\titers: 200, epoch: 45 | loss: 0.0509253\n",
      "\tspeed: 0.0284s/iter; left time: 350.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0526838 Vali Loss: 0.0538788 Test Loss: 0.0604844\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0557001\n",
      "\tspeed: 0.0582s/iter; left time: 711.8541s\n",
      "\titers: 200, epoch: 46 | loss: 0.0525209\n",
      "\tspeed: 0.0345s/iter; left time: 417.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0527286 Vali Loss: 0.0538286 Test Loss: 0.0603893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0553982\n",
      "\tspeed: 0.0453s/iter; left time: 543.7188s\n",
      "\titers: 200, epoch: 47 | loss: 0.0518272\n",
      "\tspeed: 0.0296s/iter; left time: 352.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0527333 Vali Loss: 0.0536907 Test Loss: 0.0602810\n",
      "Validation loss decreased (0.053705 --> 0.053691).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0533607\n",
      "\tspeed: 0.0563s/iter; left time: 663.1830s\n",
      "\titers: 200, epoch: 48 | loss: 0.0548217\n",
      "\tspeed: 0.0304s/iter; left time: 354.6027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0527397 Vali Loss: 0.0537479 Test Loss: 0.0603296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0504825\n",
      "\tspeed: 0.0483s/iter; left time: 558.2997s\n",
      "\titers: 200, epoch: 49 | loss: 0.0522577\n",
      "\tspeed: 0.0238s/iter; left time: 272.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0526763 Vali Loss: 0.0538000 Test Loss: 0.0603761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0532289\n",
      "\tspeed: 0.0432s/iter; left time: 489.6189s\n",
      "\titers: 200, epoch: 50 | loss: 0.0540505\n",
      "\tspeed: 0.0302s/iter; left time: 339.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0526252 Vali Loss: 0.0537260 Test Loss: 0.0603250\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0528034\n",
      "\tspeed: 0.0422s/iter; left time: 468.6639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0564690\n",
      "\tspeed: 0.0189s/iter; left time: 207.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0526652 Vali Loss: 0.0537022 Test Loss: 0.0603144\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0506610\n",
      "\tspeed: 0.0527s/iter; left time: 573.3213s\n",
      "\titers: 200, epoch: 52 | loss: 0.0546506\n",
      "\tspeed: 0.0335s/iter; left time: 361.4725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0526104 Vali Loss: 0.0538159 Test Loss: 0.0604158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0526869\n",
      "\tspeed: 0.0433s/iter; left time: 461.4776s\n",
      "\titers: 200, epoch: 53 | loss: 0.0515803\n",
      "\tspeed: 0.0203s/iter; left time: 213.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0526476 Vali Loss: 0.0537371 Test Loss: 0.0602998\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0564250\n",
      "\tspeed: 0.0448s/iter; left time: 467.3446s\n",
      "\titers: 200, epoch: 54 | loss: 0.0510439\n",
      "\tspeed: 0.0241s/iter; left time: 249.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0526889 Vali Loss: 0.0538012 Test Loss: 0.0603248\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0566619\n",
      "\tspeed: 0.0454s/iter; left time: 463.2519s\n",
      "\titers: 200, epoch: 55 | loss: 0.0512023\n",
      "\tspeed: 0.0256s/iter; left time: 258.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0526704 Vali Loss: 0.0537619 Test Loss: 0.0602924\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0542790\n",
      "\tspeed: 0.0513s/iter; left time: 512.4916s\n",
      "\titers: 200, epoch: 56 | loss: 0.0510877\n",
      "\tspeed: 0.0254s/iter; left time: 251.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0526368 Vali Loss: 0.0538096 Test Loss: 0.0604733\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0558454\n",
      "\tspeed: 0.0528s/iter; left time: 515.4264s\n",
      "\titers: 200, epoch: 57 | loss: 0.0524880\n",
      "\tspeed: 0.0302s/iter; left time: 291.8968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0526508 Vali Loss: 0.0538795 Test Loss: 0.0604432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00994846224784851, rmse:0.09974198043346405, mae:0.06028098985552788, rse:0.29352858662605286\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:06.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1725521\n",
      "\tspeed: 0.0448s/iter; left time: 998.6579s\n",
      "\titers: 200, epoch: 1 | loss: 0.1565479\n",
      "\tspeed: 0.0204s/iter; left time: 452.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.1733191 Vali Loss: 0.1604159 Test Loss: 0.1920301\n",
      "Validation loss decreased (inf --> 0.160416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0971588\n",
      "\tspeed: 0.0491s/iter; left time: 1084.7102s\n",
      "\titers: 200, epoch: 2 | loss: 0.0904106\n",
      "\tspeed: 0.0277s/iter; left time: 608.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.1049145 Vali Loss: 0.0852466 Test Loss: 0.0970004\n",
      "Validation loss decreased (0.160416 --> 0.085247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0837260\n",
      "\tspeed: 0.0440s/iter; left time: 961.2678s\n",
      "\titers: 200, epoch: 3 | loss: 0.0843056\n",
      "\tspeed: 0.0211s/iter; left time: 458.5916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0858868 Vali Loss: 0.0812536 Test Loss: 0.0927678\n",
      "Validation loss decreased (0.085247 --> 0.081254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0847470\n",
      "\tspeed: 0.0518s/iter; left time: 1120.2658s\n",
      "\titers: 200, epoch: 4 | loss: 0.0795012\n",
      "\tspeed: 0.0293s/iter; left time: 630.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0821978 Vali Loss: 0.0792219 Test Loss: 0.0906864\n",
      "Validation loss decreased (0.081254 --> 0.079222).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797794\n",
      "\tspeed: 0.0517s/iter; left time: 1106.9761s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782854\n",
      "\tspeed: 0.0238s/iter; left time: 507.0523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0800650 Vali Loss: 0.0781124 Test Loss: 0.0899344\n",
      "Validation loss decreased (0.079222 --> 0.078112).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791900\n",
      "\tspeed: 0.0622s/iter; left time: 1316.8623s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792341\n",
      "\tspeed: 0.0254s/iter; left time: 534.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0788165 Vali Loss: 0.0774148 Test Loss: 0.0892412\n",
      "Validation loss decreased (0.078112 --> 0.077415).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756104\n",
      "\tspeed: 0.0486s/iter; left time: 1019.0219s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788164\n",
      "\tspeed: 0.0297s/iter; left time: 620.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0779038 Vali Loss: 0.0771728 Test Loss: 0.0889014\n",
      "Validation loss decreased (0.077415 --> 0.077173).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746468\n",
      "\tspeed: 0.0571s/iter; left time: 1184.5647s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767286\n",
      "\tspeed: 0.0297s/iter; left time: 613.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0773065 Vali Loss: 0.0771795 Test Loss: 0.0888543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0737905\n",
      "\tspeed: 0.0541s/iter; left time: 1109.1352s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749887\n",
      "\tspeed: 0.0283s/iter; left time: 577.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0766889 Vali Loss: 0.0768313 Test Loss: 0.0886019\n",
      "Validation loss decreased (0.077173 --> 0.076831).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0796218\n",
      "\tspeed: 0.0568s/iter; left time: 1152.3194s\n",
      "\titers: 200, epoch: 10 | loss: 0.0761664\n",
      "\tspeed: 0.0272s/iter; left time: 550.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0761690 Vali Loss: 0.0766745 Test Loss: 0.0885171\n",
      "Validation loss decreased (0.076831 --> 0.076674).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744708\n",
      "\tspeed: 0.0513s/iter; left time: 1029.5274s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737956\n",
      "\tspeed: 0.0288s/iter; left time: 575.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0757698 Vali Loss: 0.0763696 Test Loss: 0.0880664\n",
      "Validation loss decreased (0.076674 --> 0.076370).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777045\n",
      "\tspeed: 0.0517s/iter; left time: 1026.1396s\n",
      "\titers: 200, epoch: 12 | loss: 0.0758489\n",
      "\tspeed: 0.0306s/iter; left time: 604.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0754678 Vali Loss: 0.0762871 Test Loss: 0.0880422\n",
      "Validation loss decreased (0.076370 --> 0.076287).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761366\n",
      "\tspeed: 0.0550s/iter; left time: 1077.8812s\n",
      "\titers: 200, epoch: 13 | loss: 0.0749714\n",
      "\tspeed: 0.0333s/iter; left time: 650.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0750555 Vali Loss: 0.0764202 Test Loss: 0.0880241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738863\n",
      "\tspeed: 0.0538s/iter; left time: 1043.8996s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734386\n",
      "\tspeed: 0.0299s/iter; left time: 576.7012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0747718 Vali Loss: 0.0765696 Test Loss: 0.0884194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0754326\n",
      "\tspeed: 0.0548s/iter; left time: 1050.8704s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753600\n",
      "\tspeed: 0.0289s/iter; left time: 551.6486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0745057 Vali Loss: 0.0765277 Test Loss: 0.0880612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789264\n",
      "\tspeed: 0.0534s/iter; left time: 1010.8964s\n",
      "\titers: 200, epoch: 16 | loss: 0.0727971\n",
      "\tspeed: 0.0293s/iter; left time: 552.5908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0743405 Vali Loss: 0.0766495 Test Loss: 0.0883471\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705721\n",
      "\tspeed: 0.0514s/iter; left time: 961.5051s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726235\n",
      "\tspeed: 0.0300s/iter; left time: 557.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0740760 Vali Loss: 0.0764771 Test Loss: 0.0879456\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739691\n",
      "\tspeed: 0.0528s/iter; left time: 976.3172s\n",
      "\titers: 200, epoch: 18 | loss: 0.0765625\n",
      "\tspeed: 0.0249s/iter; left time: 458.7456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0738611 Vali Loss: 0.0765396 Test Loss: 0.0880579\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730439\n",
      "\tspeed: 0.0459s/iter; left time: 839.1952s\n",
      "\titers: 200, epoch: 19 | loss: 0.0694090\n",
      "\tspeed: 0.0240s/iter; left time: 436.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0737350 Vali Loss: 0.0764113 Test Loss: 0.0877888\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743306\n",
      "\tspeed: 0.0524s/iter; left time: 945.9381s\n",
      "\titers: 200, epoch: 20 | loss: 0.0711365\n",
      "\tspeed: 0.0350s/iter; left time: 627.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0735792 Vali Loss: 0.0766230 Test Loss: 0.0881237\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0721086\n",
      "\tspeed: 0.0508s/iter; left time: 906.0487s\n",
      "\titers: 200, epoch: 21 | loss: 0.0747205\n",
      "\tspeed: 0.0268s/iter; left time: 475.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0734074 Vali Loss: 0.0765176 Test Loss: 0.0878972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0741750\n",
      "\tspeed: 0.0523s/iter; left time: 921.1639s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754164\n",
      "\tspeed: 0.0302s/iter; left time: 529.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0732965 Vali Loss: 0.0765609 Test Loss: 0.0879351\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018859263509511948, rmse:0.13732902705669403, mae:0.0880422294139862, rse:0.40343135595321655\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1690173\n",
      "\tspeed: 0.0239s/iter; left time: 533.7526s\n",
      "\titers: 200, epoch: 1 | loss: 0.1581442\n",
      "\tspeed: 0.0244s/iter; left time: 540.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.1706542 Vali Loss: 0.1588926 Test Loss: 0.1900580\n",
      "Validation loss decreased (inf --> 0.158893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0993622\n",
      "\tspeed: 0.0522s/iter; left time: 1151.7527s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875827\n",
      "\tspeed: 0.0273s/iter; left time: 600.6751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.1054442 Vali Loss: 0.0854202 Test Loss: 0.0974075\n",
      "Validation loss decreased (0.158893 --> 0.085420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0847048\n",
      "\tspeed: 0.0488s/iter; left time: 1066.5042s\n",
      "\titers: 200, epoch: 3 | loss: 0.0844752\n",
      "\tspeed: 0.0295s/iter; left time: 641.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.0859086 Vali Loss: 0.0810077 Test Loss: 0.0928603\n",
      "Validation loss decreased (0.085420 --> 0.081008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861246\n",
      "\tspeed: 0.0580s/iter; left time: 1254.0300s\n",
      "\titers: 200, epoch: 4 | loss: 0.0798360\n",
      "\tspeed: 0.0278s/iter; left time: 598.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0822892 Vali Loss: 0.0793744 Test Loss: 0.0912973\n",
      "Validation loss decreased (0.081008 --> 0.079374).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821760\n",
      "\tspeed: 0.0469s/iter; left time: 1004.3525s\n",
      "\titers: 200, epoch: 5 | loss: 0.0747370\n",
      "\tspeed: 0.0263s/iter; left time: 560.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0800417 Vali Loss: 0.0784754 Test Loss: 0.0900637\n",
      "Validation loss decreased (0.079374 --> 0.078475).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752798\n",
      "\tspeed: 0.0529s/iter; left time: 1120.6220s\n",
      "\titers: 200, epoch: 6 | loss: 0.0734730\n",
      "\tspeed: 0.0252s/iter; left time: 530.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0787340 Vali Loss: 0.0777872 Test Loss: 0.0890976\n",
      "Validation loss decreased (0.078475 --> 0.077787).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0780378\n",
      "\tspeed: 0.0473s/iter; left time: 991.6439s\n",
      "\titers: 200, epoch: 7 | loss: 0.0816761\n",
      "\tspeed: 0.0297s/iter; left time: 620.0173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0778371 Vali Loss: 0.0776201 Test Loss: 0.0887585\n",
      "Validation loss decreased (0.077787 --> 0.077620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750418\n",
      "\tspeed: 0.0551s/iter; left time: 1141.3861s\n",
      "\titers: 200, epoch: 8 | loss: 0.0757040\n",
      "\tspeed: 0.0299s/iter; left time: 617.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0770442 Vali Loss: 0.0772252 Test Loss: 0.0885752\n",
      "Validation loss decreased (0.077620 --> 0.077225).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758669\n",
      "\tspeed: 0.0531s/iter; left time: 1089.5627s\n",
      "\titers: 200, epoch: 9 | loss: 0.0751027\n",
      "\tspeed: 0.0285s/iter; left time: 581.9037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0764374 Vali Loss: 0.0770087 Test Loss: 0.0881576\n",
      "Validation loss decreased (0.077225 --> 0.077009).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0744489\n",
      "\tspeed: 0.0575s/iter; left time: 1165.7740s\n",
      "\titers: 200, epoch: 10 | loss: 0.0740511\n",
      "\tspeed: 0.0298s/iter; left time: 600.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0759977 Vali Loss: 0.0767309 Test Loss: 0.0878704\n",
      "Validation loss decreased (0.077009 --> 0.076731).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0750019\n",
      "\tspeed: 0.0474s/iter; left time: 951.6363s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774246\n",
      "\tspeed: 0.0243s/iter; left time: 484.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0755064 Vali Loss: 0.0770157 Test Loss: 0.0880777\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777889\n",
      "\tspeed: 0.0452s/iter; left time: 896.0376s\n",
      "\titers: 200, epoch: 12 | loss: 0.0727572\n",
      "\tspeed: 0.0189s/iter; left time: 373.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0751296 Vali Loss: 0.0770508 Test Loss: 0.0880072\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761185\n",
      "\tspeed: 0.0444s/iter; left time: 870.5426s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714666\n",
      "\tspeed: 0.0234s/iter; left time: 456.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0748283 Vali Loss: 0.0769297 Test Loss: 0.0876550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0729403\n",
      "\tspeed: 0.0425s/iter; left time: 824.5782s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751988\n",
      "\tspeed: 0.0251s/iter; left time: 483.5434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0745340 Vali Loss: 0.0770198 Test Loss: 0.0876890\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0697729\n",
      "\tspeed: 0.0479s/iter; left time: 917.6452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758906\n",
      "\tspeed: 0.0210s/iter; left time: 400.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0742856 Vali Loss: 0.0770874 Test Loss: 0.0875948\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0708941\n",
      "\tspeed: 0.0488s/iter; left time: 924.8505s\n",
      "\titers: 200, epoch: 16 | loss: 0.0788890\n",
      "\tspeed: 0.0316s/iter; left time: 596.0974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0739975 Vali Loss: 0.0770794 Test Loss: 0.0876428\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733597\n",
      "\tspeed: 0.0523s/iter; left time: 978.5575s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701158\n",
      "\tspeed: 0.0230s/iter; left time: 428.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0738539 Vali Loss: 0.0771619 Test Loss: 0.0874233\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747219\n",
      "\tspeed: 0.0469s/iter; left time: 868.2054s\n",
      "\titers: 200, epoch: 18 | loss: 0.0721917\n",
      "\tspeed: 0.0262s/iter; left time: 481.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0736711 Vali Loss: 0.0770222 Test Loss: 0.0874463\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0752215\n",
      "\tspeed: 0.0521s/iter; left time: 951.2225s\n",
      "\titers: 200, epoch: 19 | loss: 0.0695629\n",
      "\tspeed: 0.0285s/iter; left time: 518.7243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0734611 Vali Loss: 0.0770458 Test Loss: 0.0875955\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746364\n",
      "\tspeed: 0.0528s/iter; left time: 952.5056s\n",
      "\titers: 200, epoch: 20 | loss: 0.0745667\n",
      "\tspeed: 0.0297s/iter; left time: 532.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0733491 Vali Loss: 0.0769950 Test Loss: 0.0874333\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01863825134932995, rmse:0.13652198016643524, mae:0.08787039667367935, rse:0.4010604918003082\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:40.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1724428\n",
      "\tspeed: 0.0432s/iter; left time: 958.5924s\n",
      "\titers: 200, epoch: 1 | loss: 0.1588923\n",
      "\tspeed: 0.0260s/iter; left time: 573.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.1736329 Vali Loss: 0.1629829 Test Loss: 0.1935919\n",
      "Validation loss decreased (inf --> 0.162983).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031059\n",
      "\tspeed: 0.0442s/iter; left time: 970.5712s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941303\n",
      "\tspeed: 0.0220s/iter; left time: 480.4598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1083642 Vali Loss: 0.0904125 Test Loss: 0.1030170\n",
      "Validation loss decreased (0.162983 --> 0.090412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933322\n",
      "\tspeed: 0.0520s/iter; left time: 1132.2336s\n",
      "\titers: 200, epoch: 3 | loss: 0.0876527\n",
      "\tspeed: 0.0265s/iter; left time: 573.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0905381 Vali Loss: 0.0867086 Test Loss: 0.0988521\n",
      "Validation loss decreased (0.090412 --> 0.086709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839370\n",
      "\tspeed: 0.0543s/iter; left time: 1169.2857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888987\n",
      "\tspeed: 0.0289s/iter; left time: 620.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0871525 Vali Loss: 0.0848498 Test Loss: 0.0969069\n",
      "Validation loss decreased (0.086709 --> 0.084850).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852654\n",
      "\tspeed: 0.0503s/iter; left time: 1071.7691s\n",
      "\titers: 200, epoch: 5 | loss: 0.0876925\n",
      "\tspeed: 0.0216s/iter; left time: 458.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0851081 Vali Loss: 0.0839559 Test Loss: 0.0959918\n",
      "Validation loss decreased (0.084850 --> 0.083956).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864237\n",
      "\tspeed: 0.0468s/iter; left time: 986.2733s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834747\n",
      "\tspeed: 0.0234s/iter; left time: 491.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 223 | Train Loss: 0.0839395 Vali Loss: 0.0839342 Test Loss: 0.0956602\n",
      "Validation loss decreased (0.083956 --> 0.083934).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0808936\n",
      "\tspeed: 0.0520s/iter; left time: 1085.6339s\n",
      "\titers: 200, epoch: 7 | loss: 0.0824597\n",
      "\tspeed: 0.0302s/iter; left time: 627.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.0830664 Vali Loss: 0.0834632 Test Loss: 0.0948906\n",
      "Validation loss decreased (0.083934 --> 0.083463).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823163\n",
      "\tspeed: 0.0467s/iter; left time: 962.9743s\n",
      "\titers: 200, epoch: 8 | loss: 0.0843908\n",
      "\tspeed: 0.0278s/iter; left time: 570.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0823626 Vali Loss: 0.0832727 Test Loss: 0.0947872\n",
      "Validation loss decreased (0.083463 --> 0.083273).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0813698\n",
      "\tspeed: 0.0491s/iter; left time: 1002.6365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757824\n",
      "\tspeed: 0.0247s/iter; left time: 502.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0817842 Vali Loss: 0.0832338 Test Loss: 0.0946435\n",
      "Validation loss decreased (0.083273 --> 0.083234).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778607\n",
      "\tspeed: 0.0519s/iter; left time: 1047.4117s\n",
      "\titers: 200, epoch: 10 | loss: 0.0814881\n",
      "\tspeed: 0.0280s/iter; left time: 562.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0812702 Vali Loss: 0.0833407 Test Loss: 0.0946731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0789123\n",
      "\tspeed: 0.0546s/iter; left time: 1090.5336s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789626\n",
      "\tspeed: 0.0285s/iter; left time: 565.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0808463 Vali Loss: 0.0833778 Test Loss: 0.0943542\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781472\n",
      "\tspeed: 0.0469s/iter; left time: 925.4289s\n",
      "\titers: 200, epoch: 12 | loss: 0.0828225\n",
      "\tspeed: 0.0211s/iter; left time: 415.4702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0803191 Vali Loss: 0.0832993 Test Loss: 0.0946182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0797154\n",
      "\tspeed: 0.0472s/iter; left time: 920.6239s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817254\n",
      "\tspeed: 0.0215s/iter; left time: 417.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0800107 Vali Loss: 0.0832920 Test Loss: 0.0947295\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0831568\n",
      "\tspeed: 0.0512s/iter; left time: 988.4105s\n",
      "\titers: 200, epoch: 14 | loss: 0.0769861\n",
      "\tspeed: 0.0300s/iter; left time: 576.7468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.0795818 Vali Loss: 0.0831941 Test Loss: 0.0945907\n",
      "Validation loss decreased (0.083234 --> 0.083194).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776958\n",
      "\tspeed: 0.0537s/iter; left time: 1023.9409s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804305\n",
      "\tspeed: 0.0302s/iter; left time: 572.5181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0793109 Vali Loss: 0.0831197 Test Loss: 0.0947189\n",
      "Validation loss decreased (0.083194 --> 0.083120).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0773943\n",
      "\tspeed: 0.0511s/iter; left time: 964.2859s\n",
      "\titers: 200, epoch: 16 | loss: 0.0784585\n",
      "\tspeed: 0.0242s/iter; left time: 453.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0790696 Vali Loss: 0.0831180 Test Loss: 0.0951498\n",
      "Validation loss decreased (0.083120 --> 0.083118).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0790858\n",
      "\tspeed: 0.0465s/iter; left time: 866.3916s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786156\n",
      "\tspeed: 0.0249s/iter; left time: 460.7697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0788158 Vali Loss: 0.0832317 Test Loss: 0.0950733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0775901\n",
      "\tspeed: 0.0498s/iter; left time: 916.6876s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769227\n",
      "\tspeed: 0.0286s/iter; left time: 523.3554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0785558 Vali Loss: 0.0831419 Test Loss: 0.0955544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0774844\n",
      "\tspeed: 0.0469s/iter; left time: 852.3038s\n",
      "\titers: 200, epoch: 19 | loss: 0.0780503\n",
      "\tspeed: 0.0297s/iter; left time: 536.3151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0783748 Vali Loss: 0.0832605 Test Loss: 0.0955217\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0776535\n",
      "\tspeed: 0.0532s/iter; left time: 955.1941s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809101\n",
      "\tspeed: 0.0298s/iter; left time: 533.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0782038 Vali Loss: 0.0833181 Test Loss: 0.0958952\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0803946\n",
      "\tspeed: 0.0468s/iter; left time: 830.6708s\n",
      "\titers: 200, epoch: 21 | loss: 0.0812383\n",
      "\tspeed: 0.0224s/iter; left time: 394.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0780557 Vali Loss: 0.0832786 Test Loss: 0.0958802\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0750945\n",
      "\tspeed: 0.0453s/iter; left time: 793.8467s\n",
      "\titers: 200, epoch: 22 | loss: 0.0768542\n",
      "\tspeed: 0.0240s/iter; left time: 418.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0779277 Vali Loss: 0.0831090 Test Loss: 0.0958919\n",
      "Validation loss decreased (0.083118 --> 0.083109).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0762498\n",
      "\tspeed: 0.0454s/iter; left time: 784.6408s\n",
      "\titers: 200, epoch: 23 | loss: 0.0775496\n",
      "\tspeed: 0.0262s/iter; left time: 450.6672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0777972 Vali Loss: 0.0832109 Test Loss: 0.0958720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0748708\n",
      "\tspeed: 0.0441s/iter; left time: 753.6446s\n",
      "\titers: 200, epoch: 24 | loss: 0.0760955\n",
      "\tspeed: 0.0231s/iter; left time: 392.8313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0776560 Vali Loss: 0.0830744 Test Loss: 0.0957235\n",
      "Validation loss decreased (0.083109 --> 0.083074).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0774695\n",
      "\tspeed: 0.0493s/iter; left time: 830.9419s\n",
      "\titers: 200, epoch: 25 | loss: 0.0766361\n",
      "\tspeed: 0.0243s/iter; left time: 407.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0775266 Vali Loss: 0.0831983 Test Loss: 0.0959940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0794978\n",
      "\tspeed: 0.0471s/iter; left time: 782.3653s\n",
      "\titers: 200, epoch: 26 | loss: 0.0788201\n",
      "\tspeed: 0.0312s/iter; left time: 516.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0774384 Vali Loss: 0.0832176 Test Loss: 0.0961135\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0784814\n",
      "\tspeed: 0.0497s/iter; left time: 815.0058s\n",
      "\titers: 200, epoch: 27 | loss: 0.0760433\n",
      "\tspeed: 0.0267s/iter; left time: 435.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0773793 Vali Loss: 0.0831427 Test Loss: 0.0964075\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0784191\n",
      "\tspeed: 0.0448s/iter; left time: 725.1695s\n",
      "\titers: 200, epoch: 28 | loss: 0.0741534\n",
      "\tspeed: 0.0213s/iter; left time: 342.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0773541 Vali Loss: 0.0831006 Test Loss: 0.0965465\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742649\n",
      "\tspeed: 0.0459s/iter; left time: 732.5921s\n",
      "\titers: 200, epoch: 29 | loss: 0.0750559\n",
      "\tspeed: 0.0232s/iter; left time: 368.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0772603 Vali Loss: 0.0831545 Test Loss: 0.0964135\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0773898\n",
      "\tspeed: 0.0505s/iter; left time: 794.4890s\n",
      "\titers: 200, epoch: 30 | loss: 0.0763509\n",
      "\tspeed: 0.0240s/iter; left time: 375.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0772365 Vali Loss: 0.0829829 Test Loss: 0.0959147\n",
      "Validation loss decreased (0.083074 --> 0.082983).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0745511\n",
      "\tspeed: 0.0480s/iter; left time: 745.1255s\n",
      "\titers: 200, epoch: 31 | loss: 0.0766674\n",
      "\tspeed: 0.0293s/iter; left time: 452.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0771739 Vali Loss: 0.0830278 Test Loss: 0.0966018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0791801\n",
      "\tspeed: 0.0482s/iter; left time: 737.1487s\n",
      "\titers: 200, epoch: 32 | loss: 0.0758082\n",
      "\tspeed: 0.0273s/iter; left time: 414.3612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0770853 Vali Loss: 0.0830984 Test Loss: 0.0966299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0785792\n",
      "\tspeed: 0.0506s/iter; left time: 761.7956s\n",
      "\titers: 200, epoch: 33 | loss: 0.0770517\n",
      "\tspeed: 0.0247s/iter; left time: 369.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0770333 Vali Loss: 0.0830998 Test Loss: 0.0966302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0810294\n",
      "\tspeed: 0.0478s/iter; left time: 710.1564s\n",
      "\titers: 200, epoch: 34 | loss: 0.0735566\n",
      "\tspeed: 0.0232s/iter; left time: 342.4401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0769715 Vali Loss: 0.0832205 Test Loss: 0.0971037\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0758926\n",
      "\tspeed: 0.0474s/iter; left time: 692.6949s\n",
      "\titers: 200, epoch: 35 | loss: 0.0765278\n",
      "\tspeed: 0.0302s/iter; left time: 439.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0769998 Vali Loss: 0.0830599 Test Loss: 0.0964539\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0768549\n",
      "\tspeed: 0.0475s/iter; left time: 684.4521s\n",
      "\titers: 200, epoch: 36 | loss: 0.0783167\n",
      "\tspeed: 0.0277s/iter; left time: 395.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0769163 Vali Loss: 0.0831433 Test Loss: 0.0964005\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0781542\n",
      "\tspeed: 0.0452s/iter; left time: 640.1023s\n",
      "\titers: 200, epoch: 37 | loss: 0.0810970\n",
      "\tspeed: 0.0235s/iter; left time: 330.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0768407 Vali Loss: 0.0832921 Test Loss: 0.0968662\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0755641\n",
      "\tspeed: 0.0471s/iter; left time: 656.5331s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763068\n",
      "\tspeed: 0.0250s/iter; left time: 346.1887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0768469 Vali Loss: 0.0830640 Test Loss: 0.0963709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0773912\n",
      "\tspeed: 0.0470s/iter; left time: 645.4889s\n",
      "\titers: 200, epoch: 39 | loss: 0.0762475\n",
      "\tspeed: 0.0299s/iter; left time: 406.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0768261 Vali Loss: 0.0831785 Test Loss: 0.0969790\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0752472\n",
      "\tspeed: 0.0477s/iter; left time: 643.5730s\n",
      "\titers: 200, epoch: 40 | loss: 0.0801499\n",
      "\tspeed: 0.0239s/iter; left time: 320.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0768621 Vali Loss: 0.0830683 Test Loss: 0.0966473\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02149221859872341, rmse:0.14660224318504333, mae:0.09591464698314667, rse:0.4307042062282562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1708149\n",
      "\tspeed: 0.0276s/iter; left time: 612.6299s\n",
      "\titers: 200, epoch: 1 | loss: 0.1599203\n",
      "\tspeed: 0.0220s/iter; left time: 486.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 223 | Train Loss: 0.1721736 Vali Loss: 0.1616235 Test Loss: 0.1920445\n",
      "Validation loss decreased (inf --> 0.161624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1018407\n",
      "\tspeed: 0.0571s/iter; left time: 1255.1917s\n",
      "\titers: 200, epoch: 2 | loss: 0.0967699\n",
      "\tspeed: 0.0283s/iter; left time: 619.4381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1081701 Vali Loss: 0.0909478 Test Loss: 0.1032547\n",
      "Validation loss decreased (0.161624 --> 0.090948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925087\n",
      "\tspeed: 0.0538s/iter; left time: 1170.0306s\n",
      "\titers: 200, epoch: 3 | loss: 0.0881282\n",
      "\tspeed: 0.0301s/iter; left time: 652.2214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.0904428 Vali Loss: 0.0870351 Test Loss: 0.0987367\n",
      "Validation loss decreased (0.090948 --> 0.087035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868527\n",
      "\tspeed: 0.0547s/iter; left time: 1178.1943s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844974\n",
      "\tspeed: 0.0256s/iter; left time: 548.6647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0871066 Vali Loss: 0.0853468 Test Loss: 0.0969912\n",
      "Validation loss decreased (0.087035 --> 0.085347).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0855386\n",
      "\tspeed: 0.0470s/iter; left time: 1001.9187s\n",
      "\titers: 200, epoch: 5 | loss: 0.0859564\n",
      "\tspeed: 0.0256s/iter; left time: 543.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0853105 Vali Loss: 0.0844506 Test Loss: 0.0961147\n",
      "Validation loss decreased (0.085347 --> 0.084451).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0822629\n",
      "\tspeed: 0.0526s/iter; left time: 1108.3464s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836451\n",
      "\tspeed: 0.0298s/iter; left time: 625.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0840812 Vali Loss: 0.0838553 Test Loss: 0.0953984\n",
      "Validation loss decreased (0.084451 --> 0.083855).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0884187\n",
      "\tspeed: 0.0524s/iter; left time: 1092.6276s\n",
      "\titers: 200, epoch: 7 | loss: 0.0843592\n",
      "\tspeed: 0.0294s/iter; left time: 610.0419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 223 | Train Loss: 0.0832219 Vali Loss: 0.0838810 Test Loss: 0.0952955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0802464\n",
      "\tspeed: 0.0548s/iter; left time: 1131.7738s\n",
      "\titers: 200, epoch: 8 | loss: 0.0870846\n",
      "\tspeed: 0.0299s/iter; left time: 614.7305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 223 | Train Loss: 0.0825875 Vali Loss: 0.0835053 Test Loss: 0.0945557\n",
      "Validation loss decreased (0.083855 --> 0.083505).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0863345\n",
      "\tspeed: 0.0460s/iter; left time: 939.8070s\n",
      "\titers: 200, epoch: 9 | loss: 0.0812391\n",
      "\tspeed: 0.0232s/iter; left time: 471.6617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0820072 Vali Loss: 0.0835904 Test Loss: 0.0947530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850176\n",
      "\tspeed: 0.0437s/iter; left time: 882.1624s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797837\n",
      "\tspeed: 0.0206s/iter; left time: 413.0787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0815543 Vali Loss: 0.0833113 Test Loss: 0.0944282\n",
      "Validation loss decreased (0.083505 --> 0.083311).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810974\n",
      "\tspeed: 0.0436s/iter; left time: 870.0876s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797822\n",
      "\tspeed: 0.0200s/iter; left time: 397.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0811382 Vali Loss: 0.0837648 Test Loss: 0.0946990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0793180\n",
      "\tspeed: 0.0426s/iter; left time: 840.4067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0797741\n",
      "\tspeed: 0.0207s/iter; left time: 407.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0807703 Vali Loss: 0.0834590 Test Loss: 0.0945953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0790005\n",
      "\tspeed: 0.0505s/iter; left time: 986.5871s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817507\n",
      "\tspeed: 0.0291s/iter; left time: 565.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0803981 Vali Loss: 0.0833770 Test Loss: 0.0946301\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0786239\n",
      "\tspeed: 0.0545s/iter; left time: 1051.0056s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815109\n",
      "\tspeed: 0.0267s/iter; left time: 512.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0800829 Vali Loss: 0.0831350 Test Loss: 0.0945702\n",
      "Validation loss decreased (0.083311 --> 0.083135).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781979\n",
      "\tspeed: 0.0469s/iter; left time: 894.6715s\n",
      "\titers: 200, epoch: 15 | loss: 0.0810940\n",
      "\tspeed: 0.0356s/iter; left time: 675.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0797348 Vali Loss: 0.0830317 Test Loss: 0.0940735\n",
      "Validation loss decreased (0.083135 --> 0.083032).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780098\n",
      "\tspeed: 0.0547s/iter; left time: 1031.9585s\n",
      "\titers: 200, epoch: 16 | loss: 0.0802081\n",
      "\tspeed: 0.0290s/iter; left time: 543.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.0794754 Vali Loss: 0.0832398 Test Loss: 0.0948703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0788479\n",
      "\tspeed: 0.0540s/iter; left time: 1005.3777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0773197\n",
      "\tspeed: 0.0204s/iter; left time: 377.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0792561 Vali Loss: 0.0830733 Test Loss: 0.0945092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0782203\n",
      "\tspeed: 0.0509s/iter; left time: 937.9575s\n",
      "\titers: 200, epoch: 18 | loss: 0.0809092\n",
      "\tspeed: 0.0280s/iter; left time: 512.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.0790581 Vali Loss: 0.0828630 Test Loss: 0.0946139\n",
      "Validation loss decreased (0.083032 --> 0.082863).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0776177\n",
      "\tspeed: 0.0580s/iter; left time: 1054.4298s\n",
      "\titers: 200, epoch: 19 | loss: 0.0765610\n",
      "\tspeed: 0.0269s/iter; left time: 485.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0788795 Vali Loss: 0.0829376 Test Loss: 0.0949911\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0794016\n",
      "\tspeed: 0.0519s/iter; left time: 931.5111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0805241\n",
      "\tspeed: 0.0276s/iter; left time: 493.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0786489 Vali Loss: 0.0830273 Test Loss: 0.0948969\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0796227\n",
      "\tspeed: 0.0534s/iter; left time: 946.6705s\n",
      "\titers: 200, epoch: 21 | loss: 0.0797441\n",
      "\tspeed: 0.0304s/iter; left time: 535.9962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.0784500 Vali Loss: 0.0829846 Test Loss: 0.0954213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0771622\n",
      "\tspeed: 0.0476s/iter; left time: 833.4349s\n",
      "\titers: 200, epoch: 22 | loss: 0.0777708\n",
      "\tspeed: 0.0297s/iter; left time: 517.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0783728 Vali Loss: 0.0829733 Test Loss: 0.0951346\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0801842\n",
      "\tspeed: 0.0436s/iter; left time: 753.2768s\n",
      "\titers: 200, epoch: 23 | loss: 0.0760271\n",
      "\tspeed: 0.0193s/iter; left time: 331.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0782402 Vali Loss: 0.0830712 Test Loss: 0.0955015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0804189\n",
      "\tspeed: 0.0520s/iter; left time: 888.3217s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780568\n",
      "\tspeed: 0.0293s/iter; left time: 497.5403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.0781626 Vali Loss: 0.0828604 Test Loss: 0.0952712\n",
      "Validation loss decreased (0.082863 --> 0.082860).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786900\n",
      "\tspeed: 0.0561s/iter; left time: 944.4848s\n",
      "\titers: 200, epoch: 25 | loss: 0.0793563\n",
      "\tspeed: 0.0265s/iter; left time: 443.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0779858 Vali Loss: 0.0830920 Test Loss: 0.0957908\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0787425\n",
      "\tspeed: 0.0552s/iter; left time: 917.3809s\n",
      "\titers: 200, epoch: 26 | loss: 0.0788386\n",
      "\tspeed: 0.0290s/iter; left time: 479.2032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0779006 Vali Loss: 0.0828819 Test Loss: 0.0954947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0795987\n",
      "\tspeed: 0.0611s/iter; left time: 1001.4632s\n",
      "\titers: 200, epoch: 27 | loss: 0.0793786\n",
      "\tspeed: 0.0250s/iter; left time: 406.7829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.0778008 Vali Loss: 0.0827857 Test Loss: 0.0954031\n",
      "Validation loss decreased (0.082860 --> 0.082786).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0769432\n",
      "\tspeed: 0.0466s/iter; left time: 754.2207s\n",
      "\titers: 200, epoch: 28 | loss: 0.0761102\n",
      "\tspeed: 0.0192s/iter; left time: 308.7070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0777797 Vali Loss: 0.0830763 Test Loss: 0.0957236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818474\n",
      "\tspeed: 0.0455s/iter; left time: 725.5179s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760184\n",
      "\tspeed: 0.0237s/iter; left time: 375.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0777188 Vali Loss: 0.0828565 Test Loss: 0.0955606\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0762338\n",
      "\tspeed: 0.0525s/iter; left time: 825.3566s\n",
      "\titers: 200, epoch: 30 | loss: 0.0759008\n",
      "\tspeed: 0.0267s/iter; left time: 418.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0776262 Vali Loss: 0.0830439 Test Loss: 0.0960314\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0791374\n",
      "\tspeed: 0.0455s/iter; left time: 705.2244s\n",
      "\titers: 200, epoch: 31 | loss: 0.0794672\n",
      "\tspeed: 0.0235s/iter; left time: 362.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0776196 Vali Loss: 0.0828579 Test Loss: 0.0956733\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0794476\n",
      "\tspeed: 0.0534s/iter; left time: 816.3794s\n",
      "\titers: 200, epoch: 32 | loss: 0.0756159\n",
      "\tspeed: 0.0351s/iter; left time: 533.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 223 | Train Loss: 0.0775582 Vali Loss: 0.0828834 Test Loss: 0.0955782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0793239\n",
      "\tspeed: 0.0555s/iter; left time: 836.1224s\n",
      "\titers: 200, epoch: 33 | loss: 0.0780990\n",
      "\tspeed: 0.0308s/iter; left time: 460.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0774957 Vali Loss: 0.0828886 Test Loss: 0.0955227\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0799308\n",
      "\tspeed: 0.0434s/iter; left time: 644.4571s\n",
      "\titers: 200, epoch: 34 | loss: 0.0781503\n",
      "\tspeed: 0.0207s/iter; left time: 305.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0774534 Vali Loss: 0.0828823 Test Loss: 0.0956909\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0780694\n",
      "\tspeed: 0.0559s/iter; left time: 817.6477s\n",
      "\titers: 200, epoch: 35 | loss: 0.0753875\n",
      "\tspeed: 0.0265s/iter; left time: 384.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0773704 Vali Loss: 0.0829326 Test Loss: 0.0958762\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769653\n",
      "\tspeed: 0.0468s/iter; left time: 674.3357s\n",
      "\titers: 200, epoch: 36 | loss: 0.0771090\n",
      "\tspeed: 0.0302s/iter; left time: 431.2580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0773731 Vali Loss: 0.0829760 Test Loss: 0.0957699\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0787782\n",
      "\tspeed: 0.0539s/iter; left time: 764.2466s\n",
      "\titers: 200, epoch: 37 | loss: 0.0811335\n",
      "\tspeed: 0.0265s/iter; left time: 373.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0774089 Vali Loss: 0.0829972 Test Loss: 0.0958956\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021352777257561684, rmse:0.1461258977651596, mae:0.09540308266878128, rse:0.42930474877357483\n",
      "Intermediate time for ES and pred_len 168: 00h:09m:56.98s\n",
      "Intermediate time for ES: 00h:31m:43.40s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1294495\n",
      "\tspeed: 0.0433s/iter; left time: 965.2448s\n",
      "\titers: 200, epoch: 1 | loss: 0.1062147\n",
      "\tspeed: 0.0207s/iter; left time: 458.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.1220942 Vali Loss: 0.1216610 Test Loss: 0.1354970\n",
      "Validation loss decreased (inf --> 0.121661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0639767\n",
      "\tspeed: 0.0418s/iter; left time: 922.8789s\n",
      "\titers: 200, epoch: 2 | loss: 0.0543063\n",
      "\tspeed: 0.0203s/iter; left time: 445.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0668089 Vali Loss: 0.0613634 Test Loss: 0.0647360\n",
      "Validation loss decreased (0.121661 --> 0.061363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0503427\n",
      "\tspeed: 0.0552s/iter; left time: 1205.4260s\n",
      "\titers: 200, epoch: 3 | loss: 0.0490987\n",
      "\tspeed: 0.0350s/iter; left time: 760.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0503591 Vali Loss: 0.0579463 Test Loss: 0.0608869\n",
      "Validation loss decreased (0.061363 --> 0.057946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0471422\n",
      "\tspeed: 0.0498s/iter; left time: 1076.8010s\n",
      "\titers: 200, epoch: 4 | loss: 0.0454242\n",
      "\tspeed: 0.0280s/iter; left time: 603.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0475197 Vali Loss: 0.0563043 Test Loss: 0.0594963\n",
      "Validation loss decreased (0.057946 --> 0.056304).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0465195\n",
      "\tspeed: 0.0538s/iter; left time: 1150.6979s\n",
      "\titers: 200, epoch: 5 | loss: 0.0459883\n",
      "\tspeed: 0.0275s/iter; left time: 586.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0459609 Vali Loss: 0.0547188 Test Loss: 0.0583823\n",
      "Validation loss decreased (0.056304 --> 0.054719).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0444707\n",
      "\tspeed: 0.0508s/iter; left time: 1076.0190s\n",
      "\titers: 200, epoch: 6 | loss: 0.0458128\n",
      "\tspeed: 0.0284s/iter; left time: 599.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0449418 Vali Loss: 0.0539698 Test Loss: 0.0577845\n",
      "Validation loss decreased (0.054719 --> 0.053970).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0439692\n",
      "\tspeed: 0.0446s/iter; left time: 934.4010s\n",
      "\titers: 200, epoch: 7 | loss: 0.0433992\n",
      "\tspeed: 0.0265s/iter; left time: 552.0963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0442236 Vali Loss: 0.0535927 Test Loss: 0.0574142\n",
      "Validation loss decreased (0.053970 --> 0.053593).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0466260\n",
      "\tspeed: 0.0524s/iter; left time: 1087.3245s\n",
      "\titers: 200, epoch: 8 | loss: 0.0438989\n",
      "\tspeed: 0.0277s/iter; left time: 570.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0436074 Vali Loss: 0.0532091 Test Loss: 0.0570019\n",
      "Validation loss decreased (0.053593 --> 0.053209).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0432463\n",
      "\tspeed: 0.0435s/iter; left time: 891.6621s\n",
      "\titers: 200, epoch: 9 | loss: 0.0419723\n",
      "\tspeed: 0.0210s/iter; left time: 428.8142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0431866 Vali Loss: 0.0528547 Test Loss: 0.0567240\n",
      "Validation loss decreased (0.053209 --> 0.052855).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0422297\n",
      "\tspeed: 0.0474s/iter; left time: 961.6393s\n",
      "\titers: 200, epoch: 10 | loss: 0.0441075\n",
      "\tspeed: 0.0230s/iter; left time: 464.8767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0428570 Vali Loss: 0.0527033 Test Loss: 0.0564517\n",
      "Validation loss decreased (0.052855 --> 0.052703).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0464948\n",
      "\tspeed: 0.0426s/iter; left time: 855.5496s\n",
      "\titers: 200, epoch: 11 | loss: 0.0453811\n",
      "\tspeed: 0.0271s/iter; left time: 540.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0425816 Vali Loss: 0.0526440 Test Loss: 0.0565030\n",
      "Validation loss decreased (0.052703 --> 0.052644).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0401720\n",
      "\tspeed: 0.0448s/iter; left time: 888.5634s\n",
      "\titers: 200, epoch: 12 | loss: 0.0404212\n",
      "\tspeed: 0.0283s/iter; left time: 558.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0422643 Vali Loss: 0.0522506 Test Loss: 0.0560284\n",
      "Validation loss decreased (0.052644 --> 0.052251).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0415695\n",
      "\tspeed: 0.0523s/iter; left time: 1025.5292s\n",
      "\titers: 200, epoch: 13 | loss: 0.0443146\n",
      "\tspeed: 0.0245s/iter; left time: 478.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0420859 Vali Loss: 0.0521906 Test Loss: 0.0561989\n",
      "Validation loss decreased (0.052251 --> 0.052191).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0405096\n",
      "\tspeed: 0.0505s/iter; left time: 979.9934s\n",
      "\titers: 200, epoch: 14 | loss: 0.0428962\n",
      "\tspeed: 0.0289s/iter; left time: 558.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0419528 Vali Loss: 0.0521557 Test Loss: 0.0560080\n",
      "Validation loss decreased (0.052191 --> 0.052156).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0439769\n",
      "\tspeed: 0.0548s/iter; left time: 1051.1059s\n",
      "\titers: 200, epoch: 15 | loss: 0.0409417\n",
      "\tspeed: 0.0294s/iter; left time: 560.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0417630 Vali Loss: 0.0522371 Test Loss: 0.0561968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0415810\n",
      "\tspeed: 0.0493s/iter; left time: 933.7900s\n",
      "\titers: 200, epoch: 16 | loss: 0.0439729\n",
      "\tspeed: 0.0292s/iter; left time: 549.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.0416330 Vali Loss: 0.0520897 Test Loss: 0.0559218\n",
      "Validation loss decreased (0.052156 --> 0.052090).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0412142\n",
      "\tspeed: 0.0509s/iter; left time: 953.0762s\n",
      "\titers: 200, epoch: 17 | loss: 0.0391558\n",
      "\tspeed: 0.0213s/iter; left time: 395.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0414791 Vali Loss: 0.0520750 Test Loss: 0.0559001\n",
      "Validation loss decreased (0.052090 --> 0.052075).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435842\n",
      "\tspeed: 0.0484s/iter; left time: 894.9421s\n",
      "\titers: 200, epoch: 18 | loss: 0.0409682\n",
      "\tspeed: 0.0275s/iter; left time: 506.3731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0413539 Vali Loss: 0.0520137 Test Loss: 0.0558166\n",
      "Validation loss decreased (0.052075 --> 0.052014).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426775\n",
      "\tspeed: 0.0525s/iter; left time: 959.2825s\n",
      "\titers: 200, epoch: 19 | loss: 0.0413912\n",
      "\tspeed: 0.0295s/iter; left time: 536.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0412634 Vali Loss: 0.0518539 Test Loss: 0.0556660\n",
      "Validation loss decreased (0.052014 --> 0.051854).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0423297\n",
      "\tspeed: 0.0527s/iter; left time: 950.2704s\n",
      "\titers: 200, epoch: 20 | loss: 0.0426290\n",
      "\tspeed: 0.0349s/iter; left time: 626.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0411589 Vali Loss: 0.0518800 Test Loss: 0.0556026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0406446\n",
      "\tspeed: 0.0581s/iter; left time: 1035.4722s\n",
      "\titers: 200, epoch: 21 | loss: 0.0402915\n",
      "\tspeed: 0.0305s/iter; left time: 540.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0410563 Vali Loss: 0.0519254 Test Loss: 0.0556582\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0444881\n",
      "\tspeed: 0.0517s/iter; left time: 909.6322s\n",
      "\titers: 200, epoch: 22 | loss: 0.0384058\n",
      "\tspeed: 0.0241s/iter; left time: 421.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0410177 Vali Loss: 0.0518836 Test Loss: 0.0555785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0363856\n",
      "\tspeed: 0.0455s/iter; left time: 789.6218s\n",
      "\titers: 200, epoch: 23 | loss: 0.0452622\n",
      "\tspeed: 0.0226s/iter; left time: 389.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0409407 Vali Loss: 0.0517715 Test Loss: 0.0555774\n",
      "Validation loss decreased (0.051854 --> 0.051771).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0420545\n",
      "\tspeed: 0.0484s/iter; left time: 829.8893s\n",
      "\titers: 200, epoch: 24 | loss: 0.0387413\n",
      "\tspeed: 0.0289s/iter; left time: 493.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0408949 Vali Loss: 0.0516342 Test Loss: 0.0554361\n",
      "Validation loss decreased (0.051771 --> 0.051634).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0402869\n",
      "\tspeed: 0.0459s/iter; left time: 776.4087s\n",
      "\titers: 200, epoch: 25 | loss: 0.0423965\n",
      "\tspeed: 0.0237s/iter; left time: 398.2753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0408265 Vali Loss: 0.0518278 Test Loss: 0.0555188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0385492\n",
      "\tspeed: 0.0482s/iter; left time: 805.6620s\n",
      "\titers: 200, epoch: 26 | loss: 0.0389443\n",
      "\tspeed: 0.0291s/iter; left time: 483.6293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0408178 Vali Loss: 0.0516883 Test Loss: 0.0555714\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0430892\n",
      "\tspeed: 0.0520s/iter; left time: 856.1027s\n",
      "\titers: 200, epoch: 27 | loss: 0.0391682\n",
      "\tspeed: 0.0227s/iter; left time: 372.0981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0407817 Vali Loss: 0.0517540 Test Loss: 0.0555627\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0412742\n",
      "\tspeed: 0.0470s/iter; left time: 764.0712s\n",
      "\titers: 200, epoch: 28 | loss: 0.0405189\n",
      "\tspeed: 0.0275s/iter; left time: 444.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0406894 Vali Loss: 0.0517068 Test Loss: 0.0555589\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0405352\n",
      "\tspeed: 0.0516s/iter; left time: 826.7500s\n",
      "\titers: 200, epoch: 29 | loss: 0.0411106\n",
      "\tspeed: 0.0323s/iter; left time: 513.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0407279 Vali Loss: 0.0517572 Test Loss: 0.0555590\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0389218\n",
      "\tspeed: 0.0531s/iter; left time: 839.7034s\n",
      "\titers: 200, epoch: 30 | loss: 0.0389672\n",
      "\tspeed: 0.0248s/iter; left time: 389.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0407143 Vali Loss: 0.0517009 Test Loss: 0.0554906\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0448252\n",
      "\tspeed: 0.0452s/iter; left time: 703.9804s\n",
      "\titers: 200, epoch: 31 | loss: 0.0423104\n",
      "\tspeed: 0.0228s/iter; left time: 352.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0406486 Vali Loss: 0.0517864 Test Loss: 0.0555325\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0394513\n",
      "\tspeed: 0.0398s/iter; left time: 610.6380s\n",
      "\titers: 200, epoch: 32 | loss: 0.0385003\n",
      "\tspeed: 0.0188s/iter; left time: 286.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0405829 Vali Loss: 0.0516988 Test Loss: 0.0554147\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0364311\n",
      "\tspeed: 0.0435s/iter; left time: 657.8243s\n",
      "\titers: 200, epoch: 33 | loss: 0.0402498\n",
      "\tspeed: 0.0268s/iter; left time: 403.0297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0405424 Vali Loss: 0.0516642 Test Loss: 0.0554344\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425342\n",
      "\tspeed: 0.0514s/iter; left time: 767.0267s\n",
      "\titers: 200, epoch: 34 | loss: 0.0415934\n",
      "\tspeed: 0.0314s/iter; left time: 464.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0405964 Vali Loss: 0.0516950 Test Loss: 0.0554143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010162579827010632, rmse:0.10080961883068085, mae:0.05543610081076622, rse:0.38892075419425964\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1221108\n",
      "\tspeed: 0.0317s/iter; left time: 707.7841s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085883\n",
      "\tspeed: 0.0270s/iter; left time: 600.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.1183581 Vali Loss: 0.1188984 Test Loss: 0.1322305\n",
      "Validation loss decreased (inf --> 0.118898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0637096\n",
      "\tspeed: 0.0513s/iter; left time: 1131.4618s\n",
      "\titers: 200, epoch: 2 | loss: 0.0557189\n",
      "\tspeed: 0.0304s/iter; left time: 667.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0675840 Vali Loss: 0.0624912 Test Loss: 0.0653505\n",
      "Validation loss decreased (0.118898 --> 0.062491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0491191\n",
      "\tspeed: 0.0538s/iter; left time: 1176.3868s\n",
      "\titers: 200, epoch: 3 | loss: 0.0521954\n",
      "\tspeed: 0.0299s/iter; left time: 649.9628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0508802 Vali Loss: 0.0578972 Test Loss: 0.0611889\n",
      "Validation loss decreased (0.062491 --> 0.057897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0511315\n",
      "\tspeed: 0.0482s/iter; left time: 1041.6921s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481324\n",
      "\tspeed: 0.0196s/iter; left time: 423.0328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0478987 Vali Loss: 0.0565889 Test Loss: 0.0598344\n",
      "Validation loss decreased (0.057897 --> 0.056589).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467008\n",
      "\tspeed: 0.0552s/iter; left time: 1182.2985s\n",
      "\titers: 200, epoch: 5 | loss: 0.0440080\n",
      "\tspeed: 0.0321s/iter; left time: 684.3124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0461396 Vali Loss: 0.0550711 Test Loss: 0.0586135\n",
      "Validation loss decreased (0.056589 --> 0.055071).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0465663\n",
      "\tspeed: 0.0563s/iter; left time: 1192.9179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0442438\n",
      "\tspeed: 0.0296s/iter; left time: 623.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0449904 Vali Loss: 0.0543326 Test Loss: 0.0577466\n",
      "Validation loss decreased (0.055071 --> 0.054333).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412001\n",
      "\tspeed: 0.0519s/iter; left time: 1087.3087s\n",
      "\titers: 200, epoch: 7 | loss: 0.0450183\n",
      "\tspeed: 0.0273s/iter; left time: 569.2450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0441991 Vali Loss: 0.0537302 Test Loss: 0.0575613\n",
      "Validation loss decreased (0.054333 --> 0.053730).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0417746\n",
      "\tspeed: 0.0465s/iter; left time: 965.0382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0438466\n",
      "\tspeed: 0.0258s/iter; left time: 531.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0436506 Vali Loss: 0.0534526 Test Loss: 0.0571487\n",
      "Validation loss decreased (0.053730 --> 0.053453).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0430239\n",
      "\tspeed: 0.0485s/iter; left time: 995.0001s\n",
      "\titers: 200, epoch: 9 | loss: 0.0412852\n",
      "\tspeed: 0.0251s/iter; left time: 512.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0431929 Vali Loss: 0.0532033 Test Loss: 0.0570494\n",
      "Validation loss decreased (0.053453 --> 0.053203).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0455298\n",
      "\tspeed: 0.0466s/iter; left time: 945.3415s\n",
      "\titers: 200, epoch: 10 | loss: 0.0398141\n",
      "\tspeed: 0.0253s/iter; left time: 510.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0427574 Vali Loss: 0.0527420 Test Loss: 0.0565366\n",
      "Validation loss decreased (0.053203 --> 0.052742).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0408645\n",
      "\tspeed: 0.0475s/iter; left time: 953.3823s\n",
      "\titers: 200, epoch: 11 | loss: 0.0456637\n",
      "\tspeed: 0.0299s/iter; left time: 596.5245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.0424918 Vali Loss: 0.0527179 Test Loss: 0.0564125\n",
      "Validation loss decreased (0.052742 --> 0.052718).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0467636\n",
      "\tspeed: 0.0554s/iter; left time: 1099.7447s\n",
      "\titers: 200, epoch: 12 | loss: 0.0430593\n",
      "\tspeed: 0.0217s/iter; left time: 427.7310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0422355 Vali Loss: 0.0525962 Test Loss: 0.0565093\n",
      "Validation loss decreased (0.052718 --> 0.052596).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0410318\n",
      "\tspeed: 0.0512s/iter; left time: 1003.9976s\n",
      "\titers: 200, epoch: 13 | loss: 0.0404481\n",
      "\tspeed: 0.0259s/iter; left time: 506.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0419801 Vali Loss: 0.0524360 Test Loss: 0.0562095\n",
      "Validation loss decreased (0.052596 --> 0.052436).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0406455\n",
      "\tspeed: 0.0453s/iter; left time: 879.0618s\n",
      "\titers: 200, epoch: 14 | loss: 0.0409844\n",
      "\tspeed: 0.0279s/iter; left time: 537.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0417984 Vali Loss: 0.0522926 Test Loss: 0.0561642\n",
      "Validation loss decreased (0.052436 --> 0.052293).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453621\n",
      "\tspeed: 0.0448s/iter; left time: 857.8129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0399984\n",
      "\tspeed: 0.0263s/iter; left time: 500.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0416430 Vali Loss: 0.0523520 Test Loss: 0.0560597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0434861\n",
      "\tspeed: 0.0439s/iter; left time: 830.6325s\n",
      "\titers: 200, epoch: 16 | loss: 0.0425630\n",
      "\tspeed: 0.0208s/iter; left time: 391.3800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0414646 Vali Loss: 0.0521480 Test Loss: 0.0558519\n",
      "Validation loss decreased (0.052293 --> 0.052148).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0401248\n",
      "\tspeed: 0.0472s/iter; left time: 883.0744s\n",
      "\titers: 200, epoch: 17 | loss: 0.0390613\n",
      "\tspeed: 0.0284s/iter; left time: 528.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0414042 Vali Loss: 0.0522191 Test Loss: 0.0559685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0434496\n",
      "\tspeed: 0.0523s/iter; left time: 966.7989s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410226\n",
      "\tspeed: 0.0294s/iter; left time: 539.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0413434 Vali Loss: 0.0520356 Test Loss: 0.0558969\n",
      "Validation loss decreased (0.052148 --> 0.052036).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0388293\n",
      "\tspeed: 0.0516s/iter; left time: 941.8725s\n",
      "\titers: 200, epoch: 19 | loss: 0.0365584\n",
      "\tspeed: 0.0300s/iter; left time: 544.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0411774 Vali Loss: 0.0520974 Test Loss: 0.0558509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0358450\n",
      "\tspeed: 0.0492s/iter; left time: 888.2923s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383419\n",
      "\tspeed: 0.0188s/iter; left time: 336.6253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0410712 Vali Loss: 0.0519874 Test Loss: 0.0556798\n",
      "Validation loss decreased (0.052036 --> 0.051987).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0401200\n",
      "\tspeed: 0.0456s/iter; left time: 813.3354s\n",
      "\titers: 200, epoch: 21 | loss: 0.0391420\n",
      "\tspeed: 0.0313s/iter; left time: 554.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0410434 Vali Loss: 0.0521144 Test Loss: 0.0558381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0436655\n",
      "\tspeed: 0.0525s/iter; left time: 923.8620s\n",
      "\titers: 200, epoch: 22 | loss: 0.0390065\n",
      "\tspeed: 0.0264s/iter; left time: 461.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0409556 Vali Loss: 0.0518695 Test Loss: 0.0556658\n",
      "Validation loss decreased (0.051987 --> 0.051870).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0410676\n",
      "\tspeed: 0.0479s/iter; left time: 831.3865s\n",
      "\titers: 200, epoch: 23 | loss: 0.0392938\n",
      "\tspeed: 0.0228s/iter; left time: 393.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0409133 Vali Loss: 0.0521160 Test Loss: 0.0557534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0409668\n",
      "\tspeed: 0.0520s/iter; left time: 891.6191s\n",
      "\titers: 200, epoch: 24 | loss: 0.0409751\n",
      "\tspeed: 0.0257s/iter; left time: 438.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0408235 Vali Loss: 0.0519229 Test Loss: 0.0556014\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0390299\n",
      "\tspeed: 0.0486s/iter; left time: 822.4618s\n",
      "\titers: 200, epoch: 25 | loss: 0.0369701\n",
      "\tspeed: 0.0301s/iter; left time: 506.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0407505 Vali Loss: 0.0519294 Test Loss: 0.0555183\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0403386\n",
      "\tspeed: 0.0532s/iter; left time: 888.4167s\n",
      "\titers: 200, epoch: 26 | loss: 0.0415921\n",
      "\tspeed: 0.0312s/iter; left time: 517.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0407244 Vali Loss: 0.0519224 Test Loss: 0.0555814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0394088\n",
      "\tspeed: 0.0460s/iter; left time: 757.7026s\n",
      "\titers: 200, epoch: 27 | loss: 0.0380522\n",
      "\tspeed: 0.0187s/iter; left time: 305.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0406739 Vali Loss: 0.0519287 Test Loss: 0.0555607\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0423153\n",
      "\tspeed: 0.0412s/iter; left time: 669.8264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0367504\n",
      "\tspeed: 0.0236s/iter; left time: 381.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0407061 Vali Loss: 0.0519594 Test Loss: 0.0556460\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0411449\n",
      "\tspeed: 0.0534s/iter; left time: 856.7129s\n",
      "\titers: 200, epoch: 29 | loss: 0.0402128\n",
      "\tspeed: 0.0279s/iter; left time: 445.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0406181 Vali Loss: 0.0519839 Test Loss: 0.0556401\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0384742\n",
      "\tspeed: 0.0520s/iter; left time: 822.3380s\n",
      "\titers: 200, epoch: 30 | loss: 0.0418098\n",
      "\tspeed: 0.0278s/iter; left time: 437.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0405757 Vali Loss: 0.0518479 Test Loss: 0.0555029\n",
      "Validation loss decreased (0.051870 --> 0.051848).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0433220\n",
      "\tspeed: 0.0498s/iter; left time: 776.1365s\n",
      "\titers: 200, epoch: 31 | loss: 0.0387234\n",
      "\tspeed: 0.0305s/iter; left time: 472.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0405993 Vali Loss: 0.0519442 Test Loss: 0.0555846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0386574\n",
      "\tspeed: 0.0517s/iter; left time: 794.7135s\n",
      "\titers: 200, epoch: 32 | loss: 0.0469979\n",
      "\tspeed: 0.0281s/iter; left time: 428.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0405311 Vali Loss: 0.0519325 Test Loss: 0.0554754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0347375\n",
      "\tspeed: 0.0469s/iter; left time: 709.3089s\n",
      "\titers: 200, epoch: 33 | loss: 0.0436045\n",
      "\tspeed: 0.0197s/iter; left time: 296.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0405639 Vali Loss: 0.0519318 Test Loss: 0.0555485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0428632\n",
      "\tspeed: 0.0497s/iter; left time: 740.2443s\n",
      "\titers: 200, epoch: 34 | loss: 0.0409272\n",
      "\tspeed: 0.0297s/iter; left time: 439.7964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0405462 Vali Loss: 0.0518552 Test Loss: 0.0555592\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0400166\n",
      "\tspeed: 0.0518s/iter; left time: 760.1431s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397628\n",
      "\tspeed: 0.0316s/iter; left time: 460.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0404969 Vali Loss: 0.0518642 Test Loss: 0.0554965\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0421109\n",
      "\tspeed: 0.0508s/iter; left time: 734.1366s\n",
      "\titers: 200, epoch: 36 | loss: 0.0419386\n",
      "\tspeed: 0.0291s/iter; left time: 417.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0404867 Vali Loss: 0.0518693 Test Loss: 0.0555817\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0409165\n",
      "\tspeed: 0.0482s/iter; left time: 686.2138s\n",
      "\titers: 200, epoch: 37 | loss: 0.0424285\n",
      "\tspeed: 0.0255s/iter; left time: 361.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0404930 Vali Loss: 0.0518073 Test Loss: 0.0555045\n",
      "Validation loss decreased (0.051848 --> 0.051807).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0398506\n",
      "\tspeed: 0.0455s/iter; left time: 637.4817s\n",
      "\titers: 200, epoch: 38 | loss: 0.0416503\n",
      "\tspeed: 0.0294s/iter; left time: 409.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0404824 Vali Loss: 0.0519076 Test Loss: 0.0555085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0412235\n",
      "\tspeed: 0.0505s/iter; left time: 696.9707s\n",
      "\titers: 200, epoch: 39 | loss: 0.0427603\n",
      "\tspeed: 0.0299s/iter; left time: 409.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0404549 Vali Loss: 0.0518895 Test Loss: 0.0555284\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0407571\n",
      "\tspeed: 0.0550s/iter; left time: 745.8098s\n",
      "\titers: 200, epoch: 40 | loss: 0.0414529\n",
      "\tspeed: 0.0272s/iter; left time: 366.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0404599 Vali Loss: 0.0517731 Test Loss: 0.0554826\n",
      "Validation loss decreased (0.051807 --> 0.051773).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416469\n",
      "\tspeed: 0.0486s/iter; left time: 648.0947s\n",
      "\titers: 200, epoch: 41 | loss: 0.0397186\n",
      "\tspeed: 0.0285s/iter; left time: 377.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0404601 Vali Loss: 0.0518309 Test Loss: 0.0554606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0416307\n",
      "\tspeed: 0.0485s/iter; left time: 635.5976s\n",
      "\titers: 200, epoch: 42 | loss: 0.0436233\n",
      "\tspeed: 0.0299s/iter; left time: 388.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0404409 Vali Loss: 0.0519078 Test Loss: 0.0555456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0416068\n",
      "\tspeed: 0.0489s/iter; left time: 630.0439s\n",
      "\titers: 200, epoch: 43 | loss: 0.0396379\n",
      "\tspeed: 0.0310s/iter; left time: 396.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0404174 Vali Loss: 0.0519750 Test Loss: 0.0555311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0373424\n",
      "\tspeed: 0.0526s/iter; left time: 666.4861s\n",
      "\titers: 200, epoch: 44 | loss: 0.0408751\n",
      "\tspeed: 0.0251s/iter; left time: 315.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0404050 Vali Loss: 0.0518562 Test Loss: 0.0554844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0380057\n",
      "\tspeed: 0.0551s/iter; left time: 685.7010s\n",
      "\titers: 200, epoch: 45 | loss: 0.0422889\n",
      "\tspeed: 0.0275s/iter; left time: 339.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0404029 Vali Loss: 0.0518200 Test Loss: 0.0554811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0413345\n",
      "\tspeed: 0.0431s/iter; left time: 527.0770s\n",
      "\titers: 200, epoch: 46 | loss: 0.0367479\n",
      "\tspeed: 0.0252s/iter; left time: 305.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0404146 Vali Loss: 0.0518810 Test Loss: 0.0555067\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0386838\n",
      "\tspeed: 0.0520s/iter; left time: 623.5754s\n",
      "\titers: 200, epoch: 47 | loss: 0.0367800\n",
      "\tspeed: 0.0297s/iter; left time: 353.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0403818 Vali Loss: 0.0517233 Test Loss: 0.0554923\n",
      "Validation loss decreased (0.051773 --> 0.051723).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0404496\n",
      "\tspeed: 0.0458s/iter; left time: 538.9475s\n",
      "\titers: 200, epoch: 48 | loss: 0.0374668\n",
      "\tspeed: 0.0217s/iter; left time: 253.7088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0404049 Vali Loss: 0.0518491 Test Loss: 0.0555111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0418223\n",
      "\tspeed: 0.0439s/iter; left time: 507.0149s\n",
      "\titers: 200, epoch: 49 | loss: 0.0428350\n",
      "\tspeed: 0.0289s/iter; left time: 330.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0404147 Vali Loss: 0.0518791 Test Loss: 0.0555230\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0405829\n",
      "\tspeed: 0.0514s/iter; left time: 582.3256s\n",
      "\titers: 200, epoch: 50 | loss: 0.0412908\n",
      "\tspeed: 0.0223s/iter; left time: 250.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0404003 Vali Loss: 0.0518906 Test Loss: 0.0555054\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0362209\n",
      "\tspeed: 0.0441s/iter; left time: 489.3860s\n",
      "\titers: 200, epoch: 51 | loss: 0.0406375\n",
      "\tspeed: 0.0228s/iter; left time: 251.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0404080 Vali Loss: 0.0518346 Test Loss: 0.0554622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0398571\n",
      "\tspeed: 0.0472s/iter; left time: 513.1487s\n",
      "\titers: 200, epoch: 52 | loss: 0.0403025\n",
      "\tspeed: 0.0245s/iter; left time: 263.6571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0404083 Vali Loss: 0.0518981 Test Loss: 0.0555092\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0412142\n",
      "\tspeed: 0.0448s/iter; left time: 477.0398s\n",
      "\titers: 200, epoch: 53 | loss: 0.0396870\n",
      "\tspeed: 0.0272s/iter; left time: 286.8874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0403601 Vali Loss: 0.0518900 Test Loss: 0.0554785\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0388449\n",
      "\tspeed: 0.0438s/iter; left time: 456.6771s\n",
      "\titers: 200, epoch: 54 | loss: 0.0397761\n",
      "\tspeed: 0.0232s/iter; left time: 240.1444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0403642 Vali Loss: 0.0518473 Test Loss: 0.0554936\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0432873\n",
      "\tspeed: 0.0510s/iter; left time: 520.7746s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409096\n",
      "\tspeed: 0.0288s/iter; left time: 290.9648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0403465 Vali Loss: 0.0518667 Test Loss: 0.0554713\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0392645\n",
      "\tspeed: 0.0549s/iter; left time: 548.3972s\n",
      "\titers: 200, epoch: 56 | loss: 0.0426386\n",
      "\tspeed: 0.0336s/iter; left time: 332.2476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0404242 Vali Loss: 0.0519378 Test Loss: 0.0555171\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0398148\n",
      "\tspeed: 0.0558s/iter; left time: 544.0736s\n",
      "\titers: 200, epoch: 57 | loss: 0.0397352\n",
      "\tspeed: 0.0277s/iter; left time: 267.0756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0403971 Vali Loss: 0.0518520 Test Loss: 0.0555052\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010201469995081425, rmse:0.10100232809782028, mae:0.05549231171607971, rse:0.3896641731262207\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:43.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265848\n",
      "\tspeed: 0.0467s/iter; left time: 1041.6277s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160576\n",
      "\tspeed: 0.0220s/iter; left time: 487.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.1267992 Vali Loss: 0.1287320 Test Loss: 0.1445993\n",
      "Validation loss decreased (inf --> 0.128732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707921\n",
      "\tspeed: 0.0496s/iter; left time: 1094.4598s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724738\n",
      "\tspeed: 0.0266s/iter; left time: 585.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0796952 Vali Loss: 0.0779081 Test Loss: 0.0857513\n",
      "Validation loss decreased (0.128732 --> 0.077908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656895\n",
      "\tspeed: 0.0441s/iter; left time: 964.7092s\n",
      "\titers: 200, epoch: 3 | loss: 0.0630336\n",
      "\tspeed: 0.0202s/iter; left time: 440.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0653353 Vali Loss: 0.0747998 Test Loss: 0.0834583\n",
      "Validation loss decreased (0.077908 --> 0.074800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0618594\n",
      "\tspeed: 0.0473s/iter; left time: 1023.9665s\n",
      "\titers: 200, epoch: 4 | loss: 0.0613811\n",
      "\tspeed: 0.0283s/iter; left time: 608.4339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0626020 Vali Loss: 0.0735094 Test Loss: 0.0832137\n",
      "Validation loss decreased (0.074800 --> 0.073509).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0624905\n",
      "\tspeed: 0.0410s/iter; left time: 877.7793s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597809\n",
      "\tspeed: 0.0239s/iter; left time: 508.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0610879 Vali Loss: 0.0732011 Test Loss: 0.0830770\n",
      "Validation loss decreased (0.073509 --> 0.073201).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602219\n",
      "\tspeed: 0.0533s/iter; left time: 1129.0057s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599985\n",
      "\tspeed: 0.0304s/iter; left time: 641.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0601473 Vali Loss: 0.0730911 Test Loss: 0.0830713\n",
      "Validation loss decreased (0.073201 --> 0.073091).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556722\n",
      "\tspeed: 0.0479s/iter; left time: 1003.0555s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570081\n",
      "\tspeed: 0.0226s/iter; left time: 471.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0593975 Vali Loss: 0.0728413 Test Loss: 0.0826903\n",
      "Validation loss decreased (0.073091 --> 0.072841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0607334\n",
      "\tspeed: 0.0581s/iter; left time: 1204.5315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572102\n",
      "\tspeed: 0.0307s/iter; left time: 633.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0587627 Vali Loss: 0.0727445 Test Loss: 0.0826892\n",
      "Validation loss decreased (0.072841 --> 0.072745).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0568982\n",
      "\tspeed: 0.0493s/iter; left time: 1011.3312s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577328\n",
      "\tspeed: 0.0301s/iter; left time: 615.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0582831 Vali Loss: 0.0729152 Test Loss: 0.0829045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0607955\n",
      "\tspeed: 0.0538s/iter; left time: 1091.2373s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549816\n",
      "\tspeed: 0.0296s/iter; left time: 597.5873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0578358 Vali Loss: 0.0725348 Test Loss: 0.0823290\n",
      "Validation loss decreased (0.072745 --> 0.072535).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0588676\n",
      "\tspeed: 0.0453s/iter; left time: 908.5440s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556585\n",
      "\tspeed: 0.0234s/iter; left time: 467.5913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0574854 Vali Loss: 0.0724202 Test Loss: 0.0824947\n",
      "Validation loss decreased (0.072535 --> 0.072420).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0541983\n",
      "\tspeed: 0.0438s/iter; left time: 869.6013s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565055\n",
      "\tspeed: 0.0260s/iter; left time: 513.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0571298 Vali Loss: 0.0725223 Test Loss: 0.0825608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571905\n",
      "\tspeed: 0.0479s/iter; left time: 938.4996s\n",
      "\titers: 200, epoch: 13 | loss: 0.0566736\n",
      "\tspeed: 0.0238s/iter; left time: 464.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0568127 Vali Loss: 0.0725568 Test Loss: 0.0825895\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0557126\n",
      "\tspeed: 0.0516s/iter; left time: 1001.0648s\n",
      "\titers: 200, epoch: 14 | loss: 0.0527579\n",
      "\tspeed: 0.0295s/iter; left time: 569.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0565760 Vali Loss: 0.0725397 Test Loss: 0.0825762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571562\n",
      "\tspeed: 0.0451s/iter; left time: 865.1117s\n",
      "\titers: 200, epoch: 15 | loss: 0.0557211\n",
      "\tspeed: 0.0232s/iter; left time: 442.5016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0563037 Vali Loss: 0.0724232 Test Loss: 0.0825011\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0610621\n",
      "\tspeed: 0.0432s/iter; left time: 819.0696s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567887\n",
      "\tspeed: 0.0190s/iter; left time: 357.3573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0561308 Vali Loss: 0.0722441 Test Loss: 0.0822556\n",
      "Validation loss decreased (0.072420 --> 0.072244).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0526743\n",
      "\tspeed: 0.0455s/iter; left time: 850.8065s\n",
      "\titers: 200, epoch: 17 | loss: 0.0538024\n",
      "\tspeed: 0.0233s/iter; left time: 433.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0559952 Vali Loss: 0.0724563 Test Loss: 0.0822722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0554455\n",
      "\tspeed: 0.0528s/iter; left time: 975.9957s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562438\n",
      "\tspeed: 0.0248s/iter; left time: 456.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0557950 Vali Loss: 0.0726438 Test Loss: 0.0824924\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546079\n",
      "\tspeed: 0.0533s/iter; left time: 972.9098s\n",
      "\titers: 200, epoch: 19 | loss: 0.0550639\n",
      "\tspeed: 0.0293s/iter; left time: 531.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0556395 Vali Loss: 0.0725970 Test Loss: 0.0822686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546348\n",
      "\tspeed: 0.0479s/iter; left time: 864.6833s\n",
      "\titers: 200, epoch: 20 | loss: 0.0527595\n",
      "\tspeed: 0.0234s/iter; left time: 419.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0554853 Vali Loss: 0.0723826 Test Loss: 0.0823606\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536114\n",
      "\tspeed: 0.0540s/iter; left time: 961.7100s\n",
      "\titers: 200, epoch: 21 | loss: 0.0562070\n",
      "\tspeed: 0.0289s/iter; left time: 511.8980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0554047 Vali Loss: 0.0723809 Test Loss: 0.0821740\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0539455\n",
      "\tspeed: 0.0524s/iter; left time: 922.5025s\n",
      "\titers: 200, epoch: 22 | loss: 0.0576140\n",
      "\tspeed: 0.0293s/iter; left time: 513.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0552727 Vali Loss: 0.0724586 Test Loss: 0.0821373\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0534697\n",
      "\tspeed: 0.0518s/iter; left time: 900.7531s\n",
      "\titers: 200, epoch: 23 | loss: 0.0542280\n",
      "\tspeed: 0.0283s/iter; left time: 489.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0551755 Vali Loss: 0.0722986 Test Loss: 0.0821218\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0550574\n",
      "\tspeed: 0.0469s/iter; left time: 803.8141s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544506\n",
      "\tspeed: 0.0238s/iter; left time: 405.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0550289 Vali Loss: 0.0725095 Test Loss: 0.0823033\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0559371\n",
      "\tspeed: 0.0430s/iter; left time: 728.1704s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550659\n",
      "\tspeed: 0.0206s/iter; left time: 346.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0549773 Vali Loss: 0.0724611 Test Loss: 0.0821319\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0564375\n",
      "\tspeed: 0.0451s/iter; left time: 753.1350s\n",
      "\titers: 200, epoch: 26 | loss: 0.0523900\n",
      "\tspeed: 0.0203s/iter; left time: 336.2462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0549174 Vali Loss: 0.0723207 Test Loss: 0.0822600\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01943235844373703, rmse:0.13939999043941498, mae:0.08225554972887039, rse:0.5392362475395203\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1285259\n",
      "\tspeed: 0.0313s/iter; left time: 698.7486s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157527\n",
      "\tspeed: 0.0304s/iter; left time: 673.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1260646 Vali Loss: 0.1285329 Test Loss: 0.1439948\n",
      "Validation loss decreased (inf --> 0.128533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0737480\n",
      "\tspeed: 0.0480s/iter; left time: 1060.6403s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709028\n",
      "\tspeed: 0.0248s/iter; left time: 544.3218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0799693 Vali Loss: 0.0783871 Test Loss: 0.0865187\n",
      "Validation loss decreased (0.128533 --> 0.078387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0628068\n",
      "\tspeed: 0.0467s/iter; left time: 1020.9461s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670821\n",
      "\tspeed: 0.0202s/iter; left time: 440.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0655666 Vali Loss: 0.0747633 Test Loss: 0.0840476\n",
      "Validation loss decreased (0.078387 --> 0.074763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0577345\n",
      "\tspeed: 0.0493s/iter; left time: 1066.9705s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616683\n",
      "\tspeed: 0.0239s/iter; left time: 514.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0627392 Vali Loss: 0.0734739 Test Loss: 0.0833009\n",
      "Validation loss decreased (0.074763 --> 0.073474).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598864\n",
      "\tspeed: 0.0465s/iter; left time: 994.9622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585785\n",
      "\tspeed: 0.0327s/iter; left time: 697.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0611391 Vali Loss: 0.0731021 Test Loss: 0.0831079\n",
      "Validation loss decreased (0.073474 --> 0.073102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0639477\n",
      "\tspeed: 0.0554s/iter; left time: 1173.0081s\n",
      "\titers: 200, epoch: 6 | loss: 0.0572115\n",
      "\tspeed: 0.0199s/iter; left time: 420.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0602145 Vali Loss: 0.0729622 Test Loss: 0.0831791\n",
      "Validation loss decreased (0.073102 --> 0.072962).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581261\n",
      "\tspeed: 0.0427s/iter; left time: 894.2076s\n",
      "\titers: 200, epoch: 7 | loss: 0.0602322\n",
      "\tspeed: 0.0304s/iter; left time: 633.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0594923 Vali Loss: 0.0726926 Test Loss: 0.0832996\n",
      "Validation loss decreased (0.072962 --> 0.072693).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0595337\n",
      "\tspeed: 0.0459s/iter; left time: 952.6319s\n",
      "\titers: 200, epoch: 8 | loss: 0.0581196\n",
      "\tspeed: 0.0203s/iter; left time: 418.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0589435 Vali Loss: 0.0726750 Test Loss: 0.0830658\n",
      "Validation loss decreased (0.072693 --> 0.072675).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0585140\n",
      "\tspeed: 0.0535s/iter; left time: 1096.4226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0575708\n",
      "\tspeed: 0.0222s/iter; left time: 453.0937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0584126 Vali Loss: 0.0726819 Test Loss: 0.0827568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0575833\n",
      "\tspeed: 0.0484s/iter; left time: 981.9240s\n",
      "\titers: 200, epoch: 10 | loss: 0.0617887\n",
      "\tspeed: 0.0293s/iter; left time: 591.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0580167 Vali Loss: 0.0726076 Test Loss: 0.0830427\n",
      "Validation loss decreased (0.072675 --> 0.072608).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0568395\n",
      "\tspeed: 0.0514s/iter; left time: 1030.2783s\n",
      "\titers: 200, epoch: 11 | loss: 0.0588150\n",
      "\tspeed: 0.0287s/iter; left time: 572.5910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0576441 Vali Loss: 0.0722485 Test Loss: 0.0824498\n",
      "Validation loss decreased (0.072608 --> 0.072249).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540427\n",
      "\tspeed: 0.0581s/iter; left time: 1153.1199s\n",
      "\titers: 200, epoch: 12 | loss: 0.0590685\n",
      "\tspeed: 0.0259s/iter; left time: 511.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0573230 Vali Loss: 0.0726320 Test Loss: 0.0831021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0588475\n",
      "\tspeed: 0.0509s/iter; left time: 998.7347s\n",
      "\titers: 200, epoch: 13 | loss: 0.0534715\n",
      "\tspeed: 0.0269s/iter; left time: 524.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0570149 Vali Loss: 0.0725357 Test Loss: 0.0825145\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0564167\n",
      "\tspeed: 0.0455s/iter; left time: 881.8960s\n",
      "\titers: 200, epoch: 14 | loss: 0.0500246\n",
      "\tspeed: 0.0300s/iter; left time: 577.9993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0567938 Vali Loss: 0.0725913 Test Loss: 0.0826711\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0535649\n",
      "\tspeed: 0.0494s/iter; left time: 946.6779s\n",
      "\titers: 200, epoch: 15 | loss: 0.0557335\n",
      "\tspeed: 0.0266s/iter; left time: 506.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0565029 Vali Loss: 0.0725140 Test Loss: 0.0828748\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541250\n",
      "\tspeed: 0.0470s/iter; left time: 890.1926s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560883\n",
      "\tspeed: 0.0273s/iter; left time: 513.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0563279 Vali Loss: 0.0725120 Test Loss: 0.0826995\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0545122\n",
      "\tspeed: 0.0481s/iter; left time: 901.0311s\n",
      "\titers: 200, epoch: 17 | loss: 0.0561961\n",
      "\tspeed: 0.0200s/iter; left time: 372.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0561081 Vali Loss: 0.0727022 Test Loss: 0.0828547\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0564165\n",
      "\tspeed: 0.0457s/iter; left time: 845.2460s\n",
      "\titers: 200, epoch: 18 | loss: 0.0565387\n",
      "\tspeed: 0.0242s/iter; left time: 445.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0559737 Vali Loss: 0.0723097 Test Loss: 0.0824553\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0591570\n",
      "\tspeed: 0.0527s/iter; left time: 963.5080s\n",
      "\titers: 200, epoch: 19 | loss: 0.0564037\n",
      "\tspeed: 0.0298s/iter; left time: 540.5517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0558208 Vali Loss: 0.0724188 Test Loss: 0.0823363\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0526029\n",
      "\tspeed: 0.0520s/iter; left time: 938.8337s\n",
      "\titers: 200, epoch: 20 | loss: 0.0531309\n",
      "\tspeed: 0.0261s/iter; left time: 468.8002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0556613 Vali Loss: 0.0726028 Test Loss: 0.0827114\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0521893\n",
      "\tspeed: 0.0503s/iter; left time: 897.1340s\n",
      "\titers: 200, epoch: 21 | loss: 0.0552713\n",
      "\tspeed: 0.0303s/iter; left time: 537.7611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0555019 Vali Loss: 0.0724759 Test Loss: 0.0825178\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019627846777439117, rmse:0.1400994211435318, mae:0.0824497863650322, rse:0.54194176197052\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:02.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1297625\n",
      "\tspeed: 0.0461s/iter; left time: 1023.2217s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218552\n",
      "\tspeed: 0.0203s/iter; left time: 448.0309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.1276988 Vali Loss: 0.1311957 Test Loss: 0.1463019\n",
      "Validation loss decreased (inf --> 0.131196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0779558\n",
      "\tspeed: 0.0437s/iter; left time: 960.2781s\n",
      "\titers: 200, epoch: 2 | loss: 0.0755704\n",
      "\tspeed: 0.0202s/iter; left time: 442.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0829580 Vali Loss: 0.0812419 Test Loss: 0.0898472\n",
      "Validation loss decreased (0.131196 --> 0.081242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0740079\n",
      "\tspeed: 0.0446s/iter; left time: 970.9886s\n",
      "\titers: 200, epoch: 3 | loss: 0.0690034\n",
      "\tspeed: 0.0276s/iter; left time: 598.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0693732 Vali Loss: 0.0784192 Test Loss: 0.0880657\n",
      "Validation loss decreased (0.081242 --> 0.078419).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0661538\n",
      "\tspeed: 0.0558s/iter; left time: 1202.1291s\n",
      "\titers: 200, epoch: 4 | loss: 0.0661210\n",
      "\tspeed: 0.0272s/iter; left time: 584.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0667746 Vali Loss: 0.0778472 Test Loss: 0.0885173\n",
      "Validation loss decreased (0.078419 --> 0.077847).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0631964\n",
      "\tspeed: 0.0514s/iter; left time: 1096.0406s\n",
      "\titers: 200, epoch: 5 | loss: 0.0674683\n",
      "\tspeed: 0.0286s/iter; left time: 605.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0651882 Vali Loss: 0.0775052 Test Loss: 0.0884320\n",
      "Validation loss decreased (0.077847 --> 0.077505).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0702235\n",
      "\tspeed: 0.0494s/iter; left time: 1041.7847s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608694\n",
      "\tspeed: 0.0259s/iter; left time: 544.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0642429 Vali Loss: 0.0770239 Test Loss: 0.0879949\n",
      "Validation loss decreased (0.077505 --> 0.077024).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0622515\n",
      "\tspeed: 0.0516s/iter; left time: 1076.9340s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645545\n",
      "\tspeed: 0.0288s/iter; left time: 597.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.0635172 Vali Loss: 0.0770736 Test Loss: 0.0880356\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0612265\n",
      "\tspeed: 0.0530s/iter; left time: 1094.9218s\n",
      "\titers: 200, epoch: 8 | loss: 0.0644453\n",
      "\tspeed: 0.0257s/iter; left time: 527.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0628146 Vali Loss: 0.0768640 Test Loss: 0.0881845\n",
      "Validation loss decreased (0.077024 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604829\n",
      "\tspeed: 0.0550s/iter; left time: 1123.0725s\n",
      "\titers: 200, epoch: 9 | loss: 0.0574445\n",
      "\tspeed: 0.0282s/iter; left time: 572.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.0622101 Vali Loss: 0.0768721 Test Loss: 0.0883375\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0619563\n",
      "\tspeed: 0.0471s/iter; left time: 952.1096s\n",
      "\titers: 200, epoch: 10 | loss: 0.0663133\n",
      "\tspeed: 0.0229s/iter; left time: 459.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 223 | Train Loss: 0.0617265 Vali Loss: 0.0767716 Test Loss: 0.0876879\n",
      "Validation loss decreased (0.076864 --> 0.076772).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0590609\n",
      "\tspeed: 0.0463s/iter; left time: 925.1079s\n",
      "\titers: 200, epoch: 11 | loss: 0.0637394\n",
      "\tspeed: 0.0211s/iter; left time: 419.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0612641 Vali Loss: 0.0764794 Test Loss: 0.0883729\n",
      "Validation loss decreased (0.076772 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0604968\n",
      "\tspeed: 0.0523s/iter; left time: 1032.7418s\n",
      "\titers: 200, epoch: 12 | loss: 0.0636662\n",
      "\tspeed: 0.0244s/iter; left time: 478.6928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0608765 Vali Loss: 0.0765738 Test Loss: 0.0885806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580173\n",
      "\tspeed: 0.0452s/iter; left time: 882.2456s\n",
      "\titers: 200, epoch: 13 | loss: 0.0592753\n",
      "\tspeed: 0.0226s/iter; left time: 439.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0605181 Vali Loss: 0.0766301 Test Loss: 0.0885519\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0642119\n",
      "\tspeed: 0.0543s/iter; left time: 1047.6251s\n",
      "\titers: 200, epoch: 14 | loss: 0.0596652\n",
      "\tspeed: 0.0346s/iter; left time: 664.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0601345 Vali Loss: 0.0768824 Test Loss: 0.0885637\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0595802\n",
      "\tspeed: 0.0523s/iter; left time: 998.6124s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610297\n",
      "\tspeed: 0.0293s/iter; left time: 555.6261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0599008 Vali Loss: 0.0767296 Test Loss: 0.0886496\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0564703\n",
      "\tspeed: 0.0507s/iter; left time: 955.6067s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578421\n",
      "\tspeed: 0.0247s/iter; left time: 463.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0596375 Vali Loss: 0.0764678 Test Loss: 0.0891664\n",
      "Validation loss decreased (0.076479 --> 0.076468).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0584689\n",
      "\tspeed: 0.0434s/iter; left time: 808.8100s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588286\n",
      "\tspeed: 0.0192s/iter; left time: 356.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0594019 Vali Loss: 0.0767071 Test Loss: 0.0888374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0585432\n",
      "\tspeed: 0.0461s/iter; left time: 849.2998s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562324\n",
      "\tspeed: 0.0241s/iter; left time: 440.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 223 | Train Loss: 0.0592314 Vali Loss: 0.0767916 Test Loss: 0.0893060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0569657\n",
      "\tspeed: 0.0437s/iter; left time: 795.6071s\n",
      "\titers: 200, epoch: 19 | loss: 0.0583235\n",
      "\tspeed: 0.0266s/iter; left time: 481.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 223 | Train Loss: 0.0590660 Vali Loss: 0.0766518 Test Loss: 0.0891056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0585008\n",
      "\tspeed: 0.0435s/iter; left time: 781.9914s\n",
      "\titers: 200, epoch: 20 | loss: 0.0610277\n",
      "\tspeed: 0.0235s/iter; left time: 419.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0588792 Vali Loss: 0.0769340 Test Loss: 0.0892387\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0578064\n",
      "\tspeed: 0.0531s/iter; left time: 941.5983s\n",
      "\titers: 200, epoch: 21 | loss: 0.0618816\n",
      "\tspeed: 0.0308s/iter; left time: 543.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.0588203 Vali Loss: 0.0765469 Test Loss: 0.0894586\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0553853\n",
      "\tspeed: 0.0492s/iter; left time: 861.0414s\n",
      "\titers: 200, epoch: 22 | loss: 0.0575760\n",
      "\tspeed: 0.0242s/iter; left time: 422.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0586740 Vali Loss: 0.0766719 Test Loss: 0.0893260\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0579219\n",
      "\tspeed: 0.0437s/iter; left time: 755.3199s\n",
      "\titers: 200, epoch: 23 | loss: 0.0554765\n",
      "\tspeed: 0.0223s/iter; left time: 383.4692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0585646 Vali Loss: 0.0767842 Test Loss: 0.0892476\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560909\n",
      "\tspeed: 0.0417s/iter; left time: 712.4973s\n",
      "\titers: 200, epoch: 24 | loss: 0.0572855\n",
      "\tspeed: 0.0284s/iter; left time: 482.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0584980 Vali Loss: 0.0764956 Test Loss: 0.0893534\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0584656\n",
      "\tspeed: 0.0507s/iter; left time: 853.9246s\n",
      "\titers: 200, epoch: 25 | loss: 0.0581847\n",
      "\tspeed: 0.0311s/iter; left time: 521.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.0583818 Vali Loss: 0.0769193 Test Loss: 0.0892344\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0598949\n",
      "\tspeed: 0.0504s/iter; left time: 838.5034s\n",
      "\titers: 200, epoch: 26 | loss: 0.0604917\n",
      "\tspeed: 0.0250s/iter; left time: 412.9771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0582837 Vali Loss: 0.0766704 Test Loss: 0.0893793\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021859269589185715, rmse:0.14784879982471466, mae:0.08916646987199783, rse:0.5726324319839478\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1301168\n",
      "\tspeed: 0.0294s/iter; left time: 652.3151s\n",
      "\titers: 200, epoch: 1 | loss: 0.1195203\n",
      "\tspeed: 0.0263s/iter; left time: 580.3333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.1269339 Vali Loss: 0.1304847 Test Loss: 0.1455707\n",
      "Validation loss decreased (inf --> 0.130485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0798014\n",
      "\tspeed: 0.0465s/iter; left time: 1021.0072s\n",
      "\titers: 200, epoch: 2 | loss: 0.0721978\n",
      "\tspeed: 0.0270s/iter; left time: 590.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.0829214 Vali Loss: 0.0815705 Test Loss: 0.0901320\n",
      "Validation loss decreased (0.130485 --> 0.081570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0674308\n",
      "\tspeed: 0.0459s/iter; left time: 999.1590s\n",
      "\titers: 200, epoch: 3 | loss: 0.0714427\n",
      "\tspeed: 0.0213s/iter; left time: 460.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0695059 Vali Loss: 0.0786466 Test Loss: 0.0891007\n",
      "Validation loss decreased (0.081570 --> 0.078647).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0681689\n",
      "\tspeed: 0.0533s/iter; left time: 1146.8479s\n",
      "\titers: 200, epoch: 4 | loss: 0.0664531\n",
      "\tspeed: 0.0302s/iter; left time: 646.2014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.0670732 Vali Loss: 0.0782593 Test Loss: 0.0888486\n",
      "Validation loss decreased (0.078647 --> 0.078259).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691977\n",
      "\tspeed: 0.0515s/iter; left time: 1097.4670s\n",
      "\titers: 200, epoch: 5 | loss: 0.0665014\n",
      "\tspeed: 0.0235s/iter; left time: 498.3657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0654339 Vali Loss: 0.0781455 Test Loss: 0.0891830\n",
      "Validation loss decreased (0.078259 --> 0.078145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631682\n",
      "\tspeed: 0.0499s/iter; left time: 1051.4248s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613020\n",
      "\tspeed: 0.0250s/iter; left time: 524.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0643129 Vali Loss: 0.0772592 Test Loss: 0.0884410\n",
      "Validation loss decreased (0.078145 --> 0.077259).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0667551\n",
      "\tspeed: 0.0487s/iter; left time: 1015.9373s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625408\n",
      "\tspeed: 0.0242s/iter; left time: 501.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0635137 Vali Loss: 0.0771631 Test Loss: 0.0882128\n",
      "Validation loss decreased (0.077259 --> 0.077163).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629090\n",
      "\tspeed: 0.0464s/iter; left time: 957.6817s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620917\n",
      "\tspeed: 0.0230s/iter; left time: 472.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.0628449 Vali Loss: 0.0771341 Test Loss: 0.0879412\n",
      "Validation loss decreased (0.077163 --> 0.077134).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654130\n",
      "\tspeed: 0.0498s/iter; left time: 1017.0668s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643348\n",
      "\tspeed: 0.0255s/iter; left time: 518.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0622534 Vali Loss: 0.0768329 Test Loss: 0.0876638\n",
      "Validation loss decreased (0.077134 --> 0.076833).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0597799\n",
      "\tspeed: 0.0492s/iter; left time: 993.0673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623296\n",
      "\tspeed: 0.0263s/iter; left time: 529.0047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0617958 Vali Loss: 0.0767802 Test Loss: 0.0876898\n",
      "Validation loss decreased (0.076833 --> 0.076780).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0624073\n",
      "\tspeed: 0.0493s/iter; left time: 984.3939s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656432\n",
      "\tspeed: 0.0252s/iter; left time: 500.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0613212 Vali Loss: 0.0767641 Test Loss: 0.0877045\n",
      "Validation loss decreased (0.076780 --> 0.076764).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0630226\n",
      "\tspeed: 0.0572s/iter; left time: 1130.5041s\n",
      "\titers: 200, epoch: 12 | loss: 0.0600577\n",
      "\tspeed: 0.0275s/iter; left time: 540.8405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0609033 Vali Loss: 0.0768320 Test Loss: 0.0877190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0606446\n",
      "\tspeed: 0.0562s/iter; left time: 1096.9071s\n",
      "\titers: 200, epoch: 13 | loss: 0.0590130\n",
      "\tspeed: 0.0259s/iter; left time: 504.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0605402 Vali Loss: 0.0768860 Test Loss: 0.0879130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0597401\n",
      "\tspeed: 0.0487s/iter; left time: 940.6727s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600763\n",
      "\tspeed: 0.0232s/iter; left time: 445.3460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 223 | Train Loss: 0.0601978 Vali Loss: 0.0766607 Test Loss: 0.0875824\n",
      "Validation loss decreased (0.076764 --> 0.076661).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0615069\n",
      "\tspeed: 0.0526s/iter; left time: 1003.5020s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595586\n",
      "\tspeed: 0.0290s/iter; left time: 550.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0599186 Vali Loss: 0.0764719 Test Loss: 0.0878627\n",
      "Validation loss decreased (0.076661 --> 0.076472).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0590916\n",
      "\tspeed: 0.0466s/iter; left time: 879.0503s\n",
      "\titers: 200, epoch: 16 | loss: 0.0598780\n",
      "\tspeed: 0.0266s/iter; left time: 498.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0596583 Vali Loss: 0.0764335 Test Loss: 0.0878878\n",
      "Validation loss decreased (0.076472 --> 0.076434).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0585503\n",
      "\tspeed: 0.0493s/iter; left time: 917.7131s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577167\n",
      "\tspeed: 0.0223s/iter; left time: 412.5478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.0594216 Vali Loss: 0.0767380 Test Loss: 0.0879419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0567542\n",
      "\tspeed: 0.0467s/iter; left time: 860.2910s\n",
      "\titers: 200, epoch: 18 | loss: 0.0573610\n",
      "\tspeed: 0.0261s/iter; left time: 477.0209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0592242 Vali Loss: 0.0768524 Test Loss: 0.0878398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0621951\n",
      "\tspeed: 0.0453s/iter; left time: 823.1689s\n",
      "\titers: 200, epoch: 19 | loss: 0.0610085\n",
      "\tspeed: 0.0219s/iter; left time: 395.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0590538 Vali Loss: 0.0768523 Test Loss: 0.0881000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0577175\n",
      "\tspeed: 0.0509s/iter; left time: 914.6554s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577191\n",
      "\tspeed: 0.0275s/iter; left time: 490.9289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0588777 Vali Loss: 0.0764985 Test Loss: 0.0877383\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0573315\n",
      "\tspeed: 0.0469s/iter; left time: 831.7540s\n",
      "\titers: 200, epoch: 21 | loss: 0.0605657\n",
      "\tspeed: 0.0208s/iter; left time: 367.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0586977 Vali Loss: 0.0767033 Test Loss: 0.0880204\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0572825\n",
      "\tspeed: 0.0573s/iter; left time: 1004.5073s\n",
      "\titers: 200, epoch: 22 | loss: 0.0596555\n",
      "\tspeed: 0.0310s/iter; left time: 540.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.0586006 Vali Loss: 0.0767886 Test Loss: 0.0879528\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0587972\n",
      "\tspeed: 0.0475s/iter; left time: 821.8961s\n",
      "\titers: 200, epoch: 23 | loss: 0.0564047\n",
      "\tspeed: 0.0225s/iter; left time: 386.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0584601 Vali Loss: 0.0766494 Test Loss: 0.0880354\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0599278\n",
      "\tspeed: 0.0482s/iter; left time: 822.4903s\n",
      "\titers: 200, epoch: 24 | loss: 0.0580933\n",
      "\tspeed: 0.0245s/iter; left time: 415.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0583935 Vali Loss: 0.0767396 Test Loss: 0.0878429\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0590948\n",
      "\tspeed: 0.0460s/iter; left time: 775.6555s\n",
      "\titers: 200, epoch: 25 | loss: 0.0553949\n",
      "\tspeed: 0.0231s/iter; left time: 386.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0583447 Vali Loss: 0.0767353 Test Loss: 0.0880920\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0554859\n",
      "\tspeed: 0.0502s/iter; left time: 834.6354s\n",
      "\titers: 200, epoch: 26 | loss: 0.0601471\n",
      "\tspeed: 0.0275s/iter; left time: 454.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0582141 Vali Loss: 0.0767430 Test Loss: 0.0882256\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021398158743977547, rmse:0.14628109335899353, mae:0.08788779377937317, rse:0.5665605068206787\n",
      "Intermediate time for FR and pred_len 168: 00h:06m:40.24s\n",
      "Intermediate time for FR: 00h:24m:26.45s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1803285\n",
      "\tspeed: 0.0520s/iter; left time: 1160.6791s\n",
      "\titers: 200, epoch: 1 | loss: 0.1561516\n",
      "\tspeed: 0.0249s/iter; left time: 552.4114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1787327 Vali Loss: 0.1493044 Test Loss: 0.1571240\n",
      "Validation loss decreased (inf --> 0.149304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0884989\n",
      "\tspeed: 0.0436s/iter; left time: 961.9114s\n",
      "\titers: 200, epoch: 2 | loss: 0.0718555\n",
      "\tspeed: 0.0227s/iter; left time: 499.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0935900 Vali Loss: 0.0657520 Test Loss: 0.0689282\n",
      "Validation loss decreased (0.149304 --> 0.065752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0687594\n",
      "\tspeed: 0.0442s/iter; left time: 966.4949s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634412\n",
      "\tspeed: 0.0291s/iter; left time: 633.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0670692 Vali Loss: 0.0613089 Test Loss: 0.0642823\n",
      "Validation loss decreased (0.065752 --> 0.061309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647866\n",
      "\tspeed: 0.0434s/iter; left time: 937.9531s\n",
      "\titers: 200, epoch: 4 | loss: 0.0620681\n",
      "\tspeed: 0.0203s/iter; left time: 436.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0628625 Vali Loss: 0.0592713 Test Loss: 0.0624793\n",
      "Validation loss decreased (0.061309 --> 0.059271).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0634824\n",
      "\tspeed: 0.0475s/iter; left time: 1017.6376s\n",
      "\titers: 200, epoch: 5 | loss: 0.0559167\n",
      "\tspeed: 0.0209s/iter; left time: 444.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0606811 Vali Loss: 0.0583014 Test Loss: 0.0612789\n",
      "Validation loss decreased (0.059271 --> 0.058301).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0618689\n",
      "\tspeed: 0.0444s/iter; left time: 940.6701s\n",
      "\titers: 200, epoch: 6 | loss: 0.0632138\n",
      "\tspeed: 0.0216s/iter; left time: 454.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0593727 Vali Loss: 0.0572041 Test Loss: 0.0602464\n",
      "Validation loss decreased (0.058301 --> 0.057204).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0580892\n",
      "\tspeed: 0.0472s/iter; left time: 988.2738s\n",
      "\titers: 200, epoch: 7 | loss: 0.0551325\n",
      "\tspeed: 0.0268s/iter; left time: 558.6917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0584159 Vali Loss: 0.0566405 Test Loss: 0.0599954\n",
      "Validation loss decreased (0.057204 --> 0.056640).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596450\n",
      "\tspeed: 0.0532s/iter; left time: 1104.0147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0521865\n",
      "\tspeed: 0.0249s/iter; left time: 512.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0576568 Vali Loss: 0.0563623 Test Loss: 0.0592458\n",
      "Validation loss decreased (0.056640 --> 0.056362).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0588039\n",
      "\tspeed: 0.0423s/iter; left time: 867.0454s\n",
      "\titers: 200, epoch: 9 | loss: 0.0572356\n",
      "\tspeed: 0.0192s/iter; left time: 392.5250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0571365 Vali Loss: 0.0558992 Test Loss: 0.0588940\n",
      "Validation loss decreased (0.056362 --> 0.055899).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591912\n",
      "\tspeed: 0.0407s/iter; left time: 824.7426s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584814\n",
      "\tspeed: 0.0201s/iter; left time: 405.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0566877 Vali Loss: 0.0556870 Test Loss: 0.0587829\n",
      "Validation loss decreased (0.055899 --> 0.055687).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596775\n",
      "\tspeed: 0.0493s/iter; left time: 988.9749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567011\n",
      "\tspeed: 0.0316s/iter; left time: 631.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0563323 Vali Loss: 0.0555266 Test Loss: 0.0586415\n",
      "Validation loss decreased (0.055687 --> 0.055527).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561975\n",
      "\tspeed: 0.0441s/iter; left time: 875.4374s\n",
      "\titers: 200, epoch: 12 | loss: 0.0497049\n",
      "\tspeed: 0.0220s/iter; left time: 433.8727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0560005 Vali Loss: 0.0553365 Test Loss: 0.0585531\n",
      "Validation loss decreased (0.055527 --> 0.055336).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533420\n",
      "\tspeed: 0.0527s/iter; left time: 1033.4151s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536150\n",
      "\tspeed: 0.0271s/iter; left time: 529.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0556909 Vali Loss: 0.0552049 Test Loss: 0.0582373\n",
      "Validation loss decreased (0.055336 --> 0.055205).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0551642\n",
      "\tspeed: 0.0452s/iter; left time: 876.8159s\n",
      "\titers: 200, epoch: 14 | loss: 0.0565335\n",
      "\tspeed: 0.0223s/iter; left time: 429.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0555313 Vali Loss: 0.0551372 Test Loss: 0.0581639\n",
      "Validation loss decreased (0.055205 --> 0.055137).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0547692\n",
      "\tspeed: 0.0429s/iter; left time: 822.3594s\n",
      "\titers: 200, epoch: 15 | loss: 0.0579177\n",
      "\tspeed: 0.0259s/iter; left time: 493.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.0554094 Vali Loss: 0.0549491 Test Loss: 0.0580422\n",
      "Validation loss decreased (0.055137 --> 0.054949).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574420\n",
      "\tspeed: 0.0449s/iter; left time: 849.5467s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558785\n",
      "\tspeed: 0.0206s/iter; left time: 388.7745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0552002 Vali Loss: 0.0549935 Test Loss: 0.0580523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0573268\n",
      "\tspeed: 0.0460s/iter; left time: 861.3878s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564547\n",
      "\tspeed: 0.0284s/iter; left time: 527.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0549727 Vali Loss: 0.0550069 Test Loss: 0.0578836\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0557826\n",
      "\tspeed: 0.0523s/iter; left time: 968.0775s\n",
      "\titers: 200, epoch: 18 | loss: 0.0533563\n",
      "\tspeed: 0.0294s/iter; left time: 540.6028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0548400 Vali Loss: 0.0548707 Test Loss: 0.0577691\n",
      "Validation loss decreased (0.054949 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0552048\n",
      "\tspeed: 0.0543s/iter; left time: 991.9288s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570209\n",
      "\tspeed: 0.0288s/iter; left time: 523.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0547510 Vali Loss: 0.0548125 Test Loss: 0.0577676\n",
      "Validation loss decreased (0.054871 --> 0.054812).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546754\n",
      "\tspeed: 0.0511s/iter; left time: 922.7219s\n",
      "\titers: 200, epoch: 20 | loss: 0.0541841\n",
      "\tspeed: 0.0316s/iter; left time: 567.0379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0547040 Vali Loss: 0.0546349 Test Loss: 0.0576870\n",
      "Validation loss decreased (0.054812 --> 0.054635).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0533855\n",
      "\tspeed: 0.0433s/iter; left time: 772.0639s\n",
      "\titers: 200, epoch: 21 | loss: 0.0545189\n",
      "\tspeed: 0.0188s/iter; left time: 332.7401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0545585 Vali Loss: 0.0545643 Test Loss: 0.0576193\n",
      "Validation loss decreased (0.054635 --> 0.054564).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0566633\n",
      "\tspeed: 0.0486s/iter; left time: 854.4513s\n",
      "\titers: 200, epoch: 22 | loss: 0.0557452\n",
      "\tspeed: 0.0249s/iter; left time: 435.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0544550 Vali Loss: 0.0545795 Test Loss: 0.0576253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0526991\n",
      "\tspeed: 0.0554s/iter; left time: 961.9057s\n",
      "\titers: 200, epoch: 23 | loss: 0.0530368\n",
      "\tspeed: 0.0319s/iter; left time: 551.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.0544430 Vali Loss: 0.0546091 Test Loss: 0.0575976\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0558559\n",
      "\tspeed: 0.0545s/iter; left time: 934.1128s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565192\n",
      "\tspeed: 0.0234s/iter; left time: 399.1230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0542557 Vali Loss: 0.0545430 Test Loss: 0.0575854\n",
      "Validation loss decreased (0.054564 --> 0.054543).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0531851\n",
      "\tspeed: 0.0541s/iter; left time: 915.1734s\n",
      "\titers: 200, epoch: 25 | loss: 0.0525974\n",
      "\tspeed: 0.0267s/iter; left time: 448.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0542084 Vali Loss: 0.0544185 Test Loss: 0.0575631\n",
      "Validation loss decreased (0.054543 --> 0.054419).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0534607\n",
      "\tspeed: 0.0433s/iter; left time: 722.8855s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546591\n",
      "\tspeed: 0.0266s/iter; left time: 441.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0542093 Vali Loss: 0.0544949 Test Loss: 0.0575231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517214\n",
      "\tspeed: 0.0448s/iter; left time: 737.4582s\n",
      "\titers: 200, epoch: 27 | loss: 0.0595438\n",
      "\tspeed: 0.0277s/iter; left time: 454.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0541670 Vali Loss: 0.0545649 Test Loss: 0.0575504\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0576463\n",
      "\tspeed: 0.0493s/iter; left time: 801.4113s\n",
      "\titers: 200, epoch: 28 | loss: 0.0535549\n",
      "\tspeed: 0.0291s/iter; left time: 469.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0541313 Vali Loss: 0.0544878 Test Loss: 0.0575179\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0548257\n",
      "\tspeed: 0.0540s/iter; left time: 866.1584s\n",
      "\titers: 200, epoch: 29 | loss: 0.0577487\n",
      "\tspeed: 0.0316s/iter; left time: 504.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0541183 Vali Loss: 0.0544807 Test Loss: 0.0575405\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0567740\n",
      "\tspeed: 0.0421s/iter; left time: 666.1309s\n",
      "\titers: 200, epoch: 30 | loss: 0.0529753\n",
      "\tspeed: 0.0257s/iter; left time: 403.5594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0540877 Vali Loss: 0.0544440 Test Loss: 0.0575391\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0556231\n",
      "\tspeed: 0.0430s/iter; left time: 670.3505s\n",
      "\titers: 200, epoch: 31 | loss: 0.0556868\n",
      "\tspeed: 0.0201s/iter; left time: 310.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0540107 Vali Loss: 0.0543910 Test Loss: 0.0574664\n",
      "Validation loss decreased (0.054419 --> 0.054391).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0558352\n",
      "\tspeed: 0.0409s/iter; left time: 628.7443s\n",
      "\titers: 200, epoch: 32 | loss: 0.0512625\n",
      "\tspeed: 0.0237s/iter; left time: 361.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0540184 Vali Loss: 0.0543182 Test Loss: 0.0574428\n",
      "Validation loss decreased (0.054391 --> 0.054318).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0513017\n",
      "\tspeed: 0.0439s/iter; left time: 663.9951s\n",
      "\titers: 200, epoch: 33 | loss: 0.0539877\n",
      "\tspeed: 0.0209s/iter; left time: 314.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0539043 Vali Loss: 0.0543268 Test Loss: 0.0574396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0537685\n",
      "\tspeed: 0.0497s/iter; left time: 741.3265s\n",
      "\titers: 200, epoch: 34 | loss: 0.0575569\n",
      "\tspeed: 0.0300s/iter; left time: 444.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0540060 Vali Loss: 0.0543566 Test Loss: 0.0574168\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0493351\n",
      "\tspeed: 0.0535s/iter; left time: 785.7368s\n",
      "\titers: 200, epoch: 35 | loss: 0.0565105\n",
      "\tspeed: 0.0277s/iter; left time: 404.4143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0539464 Vali Loss: 0.0544199 Test Loss: 0.0574306\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0546673\n",
      "\tspeed: 0.0499s/iter; left time: 721.3521s\n",
      "\titers: 200, epoch: 36 | loss: 0.0542103\n",
      "\tspeed: 0.0277s/iter; left time: 398.0616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0539130 Vali Loss: 0.0543381 Test Loss: 0.0573804\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0518580\n",
      "\tspeed: 0.0516s/iter; left time: 734.7096s\n",
      "\titers: 200, epoch: 37 | loss: 0.0539437\n",
      "\tspeed: 0.0237s/iter; left time: 334.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0539060 Vali Loss: 0.0544121 Test Loss: 0.0574268\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0555552\n",
      "\tspeed: 0.0510s/iter; left time: 714.0925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542911\n",
      "\tspeed: 0.0278s/iter; left time: 387.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0539150 Vali Loss: 0.0543212 Test Loss: 0.0573871\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0553553\n",
      "\tspeed: 0.0549s/iter; left time: 756.7713s\n",
      "\titers: 200, epoch: 39 | loss: 0.0532200\n",
      "\tspeed: 0.0300s/iter; left time: 410.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.0538976 Vali Loss: 0.0543739 Test Loss: 0.0574075\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0581001\n",
      "\tspeed: 0.0517s/iter; left time: 701.6231s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527866\n",
      "\tspeed: 0.0296s/iter; left time: 398.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0538981 Vali Loss: 0.0542806 Test Loss: 0.0573914\n",
      "Validation loss decreased (0.054318 --> 0.054281).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0526219\n",
      "\tspeed: 0.0538s/iter; left time: 717.9489s\n",
      "\titers: 200, epoch: 41 | loss: 0.0547382\n",
      "\tspeed: 0.0276s/iter; left time: 366.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0538442 Vali Loss: 0.0543554 Test Loss: 0.0573859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551084\n",
      "\tspeed: 0.0428s/iter; left time: 561.5225s\n",
      "\titers: 200, epoch: 42 | loss: 0.0525633\n",
      "\tspeed: 0.0299s/iter; left time: 389.0316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0538075 Vali Loss: 0.0544131 Test Loss: 0.0574669\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0550282\n",
      "\tspeed: 0.0498s/iter; left time: 641.6249s\n",
      "\titers: 200, epoch: 43 | loss: 0.0538918\n",
      "\tspeed: 0.0232s/iter; left time: 296.3487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0538438 Vali Loss: 0.0542591 Test Loss: 0.0573533\n",
      "Validation loss decreased (0.054281 --> 0.054259).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0570680\n",
      "\tspeed: 0.0566s/iter; left time: 716.6765s\n",
      "\titers: 200, epoch: 44 | loss: 0.0565288\n",
      "\tspeed: 0.0308s/iter; left time: 387.1533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0537991 Vali Loss: 0.0542549 Test Loss: 0.0573539\n",
      "Validation loss decreased (0.054259 --> 0.054255).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0534274\n",
      "\tspeed: 0.0463s/iter; left time: 576.4954s\n",
      "\titers: 200, epoch: 45 | loss: 0.0552185\n",
      "\tspeed: 0.0260s/iter; left time: 320.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0538886 Vali Loss: 0.0543228 Test Loss: 0.0573740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0566181\n",
      "\tspeed: 0.0473s/iter; left time: 577.6989s\n",
      "\titers: 200, epoch: 46 | loss: 0.0556923\n",
      "\tspeed: 0.0208s/iter; left time: 252.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0538540 Vali Loss: 0.0543017 Test Loss: 0.0573763\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0513694\n",
      "\tspeed: 0.0511s/iter; left time: 613.2289s\n",
      "\titers: 200, epoch: 47 | loss: 0.0533483\n",
      "\tspeed: 0.0292s/iter; left time: 346.8452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0538610 Vali Loss: 0.0542788 Test Loss: 0.0573780\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0557269\n",
      "\tspeed: 0.0522s/iter; left time: 614.5242s\n",
      "\titers: 200, epoch: 48 | loss: 0.0527016\n",
      "\tspeed: 0.0298s/iter; left time: 348.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0538580 Vali Loss: 0.0542890 Test Loss: 0.0573991\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0548188\n",
      "\tspeed: 0.0475s/iter; left time: 549.1194s\n",
      "\titers: 200, epoch: 49 | loss: 0.0552976\n",
      "\tspeed: 0.0299s/iter; left time: 342.4822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0538338 Vali Loss: 0.0542311 Test Loss: 0.0573695\n",
      "Validation loss decreased (0.054255 --> 0.054231).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0517355\n",
      "\tspeed: 0.0535s/iter; left time: 605.3738s\n",
      "\titers: 200, epoch: 50 | loss: 0.0549779\n",
      "\tspeed: 0.0285s/iter; left time: 320.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0537827 Vali Loss: 0.0543561 Test Loss: 0.0574083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0554450\n",
      "\tspeed: 0.0487s/iter; left time: 540.3819s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555603\n",
      "\tspeed: 0.0290s/iter; left time: 318.5369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0538304 Vali Loss: 0.0542570 Test Loss: 0.0573724\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0565924\n",
      "\tspeed: 0.0488s/iter; left time: 531.2649s\n",
      "\titers: 200, epoch: 52 | loss: 0.0611021\n",
      "\tspeed: 0.0225s/iter; left time: 242.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0537809 Vali Loss: 0.0542240 Test Loss: 0.0573422\n",
      "Validation loss decreased (0.054231 --> 0.054224).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0538918\n",
      "\tspeed: 0.0440s/iter; left time: 468.9669s\n",
      "\titers: 200, epoch: 53 | loss: 0.0543824\n",
      "\tspeed: 0.0288s/iter; left time: 304.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0538505 Vali Loss: 0.0543872 Test Loss: 0.0573944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0517816\n",
      "\tspeed: 0.0423s/iter; left time: 441.5049s\n",
      "\titers: 200, epoch: 54 | loss: 0.0536134\n",
      "\tspeed: 0.0253s/iter; left time: 261.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0537499 Vali Loss: 0.0542680 Test Loss: 0.0573215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0523714\n",
      "\tspeed: 0.0523s/iter; left time: 533.3110s\n",
      "\titers: 200, epoch: 55 | loss: 0.0542147\n",
      "\tspeed: 0.0299s/iter; left time: 302.0652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0537827 Vali Loss: 0.0543325 Test Loss: 0.0573627\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0527864\n",
      "\tspeed: 0.0444s/iter; left time: 442.8563s\n",
      "\titers: 200, epoch: 56 | loss: 0.0570190\n",
      "\tspeed: 0.0186s/iter; left time: 184.2499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0537166 Vali Loss: 0.0542557 Test Loss: 0.0573363\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0549011\n",
      "\tspeed: 0.0413s/iter; left time: 403.1078s\n",
      "\titers: 200, epoch: 57 | loss: 0.0562474\n",
      "\tspeed: 0.0204s/iter; left time: 197.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0538232 Vali Loss: 0.0543522 Test Loss: 0.0573925\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0562882\n",
      "\tspeed: 0.0485s/iter; left time: 462.3132s\n",
      "\titers: 200, epoch: 58 | loss: 0.0517111\n",
      "\tspeed: 0.0284s/iter; left time: 267.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0538004 Vali Loss: 0.0542433 Test Loss: 0.0573363\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0522715\n",
      "\tspeed: 0.0535s/iter; left time: 497.5905s\n",
      "\titers: 200, epoch: 59 | loss: 0.0570023\n",
      "\tspeed: 0.0300s/iter; left time: 276.1221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0537348 Vali Loss: 0.0543243 Test Loss: 0.0573705\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0560900\n",
      "\tspeed: 0.0518s/iter; left time: 470.5384s\n",
      "\titers: 200, epoch: 60 | loss: 0.0573631\n",
      "\tspeed: 0.0303s/iter; left time: 272.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0537331 Vali Loss: 0.0542877 Test Loss: 0.0573394\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0533701\n",
      "\tspeed: 0.0485s/iter; left time: 430.0952s\n",
      "\titers: 200, epoch: 61 | loss: 0.0525678\n",
      "\tspeed: 0.0260s/iter; left time: 227.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0537981 Vali Loss: 0.0541713 Test Loss: 0.0573133\n",
      "Validation loss decreased (0.054224 --> 0.054171).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0508688\n",
      "\tspeed: 0.0449s/iter; left time: 387.6548s\n",
      "\titers: 200, epoch: 62 | loss: 0.0531978\n",
      "\tspeed: 0.0284s/iter; left time: 242.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0537857 Vali Loss: 0.0542624 Test Loss: 0.0573278\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0555222\n",
      "\tspeed: 0.0538s/iter; left time: 452.8255s\n",
      "\titers: 200, epoch: 63 | loss: 0.0543878\n",
      "\tspeed: 0.0338s/iter; left time: 280.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0537807 Vali Loss: 0.0542181 Test Loss: 0.0573649\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0552975\n",
      "\tspeed: 0.0536s/iter; left time: 438.9803s\n",
      "\titers: 200, epoch: 64 | loss: 0.0549345\n",
      "\tspeed: 0.0238s/iter; left time: 192.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0537682 Vali Loss: 0.0542922 Test Loss: 0.0573385\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0539104\n",
      "\tspeed: 0.0406s/iter; left time: 323.6499s\n",
      "\titers: 200, epoch: 65 | loss: 0.0524336\n",
      "\tspeed: 0.0202s/iter; left time: 159.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0537543 Vali Loss: 0.0542445 Test Loss: 0.0573173\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0572425\n",
      "\tspeed: 0.0462s/iter; left time: 357.3436s\n",
      "\titers: 200, epoch: 66 | loss: 0.0532234\n",
      "\tspeed: 0.0260s/iter; left time: 199.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0538145 Vali Loss: 0.0540828 Test Loss: 0.0573029\n",
      "Validation loss decreased (0.054171 --> 0.054083).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0509065\n",
      "\tspeed: 0.0497s/iter; left time: 373.5591s\n",
      "\titers: 200, epoch: 67 | loss: 0.0536859\n",
      "\tspeed: 0.0290s/iter; left time: 214.9938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.0537588 Vali Loss: 0.0540890 Test Loss: 0.0573083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0551997\n",
      "\tspeed: 0.0530s/iter; left time: 386.7833s\n",
      "\titers: 200, epoch: 68 | loss: 0.0530953\n",
      "\tspeed: 0.0227s/iter; left time: 163.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0537652 Vali Loss: 0.0542315 Test Loss: 0.0573174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0535490\n",
      "\tspeed: 0.0532s/iter; left time: 376.2821s\n",
      "\titers: 200, epoch: 69 | loss: 0.0550693\n",
      "\tspeed: 0.0264s/iter; left time: 183.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0538173 Vali Loss: 0.0543377 Test Loss: 0.0573696\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0554624\n",
      "\tspeed: 0.0411s/iter; left time: 281.6365s\n",
      "\titers: 200, epoch: 70 | loss: 0.0544236\n",
      "\tspeed: 0.0187s/iter; left time: 126.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0537345 Vali Loss: 0.0543242 Test Loss: 0.0573712\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0560750\n",
      "\tspeed: 0.0412s/iter; left time: 273.0574s\n",
      "\titers: 200, epoch: 71 | loss: 0.0565089\n",
      "\tspeed: 0.0203s/iter; left time: 132.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0537047 Vali Loss: 0.0542852 Test Loss: 0.0573455\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0516230\n",
      "\tspeed: 0.0424s/iter; left time: 271.4661s\n",
      "\titers: 200, epoch: 72 | loss: 0.0525300\n",
      "\tspeed: 0.0187s/iter; left time: 117.9668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0538142 Vali Loss: 0.0541921 Test Loss: 0.0573291\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0527038\n",
      "\tspeed: 0.0452s/iter; left time: 279.1016s\n",
      "\titers: 200, epoch: 73 | loss: 0.0561674\n",
      "\tspeed: 0.0288s/iter; left time: 175.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0537516 Vali Loss: 0.0542193 Test Loss: 0.0573350\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0545170\n",
      "\tspeed: 0.0457s/iter; left time: 272.0225s\n",
      "\titers: 200, epoch: 74 | loss: 0.0536382\n",
      "\tspeed: 0.0187s/iter; left time: 109.3353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0537901 Vali Loss: 0.0542183 Test Loss: 0.0573239\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0518738\n",
      "\tspeed: 0.0408s/iter; left time: 233.7777s\n",
      "\titers: 200, epoch: 75 | loss: 0.0520937\n",
      "\tspeed: 0.0342s/iter; left time: 192.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0537448 Vali Loss: 0.0543151 Test Loss: 0.0573458\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0524126\n",
      "\tspeed: 0.0442s/iter; left time: 243.2326s\n",
      "\titers: 200, epoch: 76 | loss: 0.0537289\n",
      "\tspeed: 0.0205s/iter; left time: 110.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0537512 Vali Loss: 0.0542689 Test Loss: 0.0573322\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010236384347081184, rmse:0.10117501765489578, mae:0.05730292573571205, rse:0.3822906017303467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1738198\n",
      "\tspeed: 0.0258s/iter; left time: 575.8373s\n",
      "\titers: 200, epoch: 1 | loss: 0.1621881\n",
      "\tspeed: 0.0187s/iter; left time: 415.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.1786863 Vali Loss: 0.1485423 Test Loss: 0.1564377\n",
      "Validation loss decreased (inf --> 0.148542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0850278\n",
      "\tspeed: 0.0520s/iter; left time: 1148.3633s\n",
      "\titers: 200, epoch: 2 | loss: 0.0788847\n",
      "\tspeed: 0.0238s/iter; left time: 522.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0948193 Vali Loss: 0.0670873 Test Loss: 0.0702931\n",
      "Validation loss decreased (0.148542 --> 0.067087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0681345\n",
      "\tspeed: 0.0429s/iter; left time: 936.6222s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642335\n",
      "\tspeed: 0.0275s/iter; left time: 598.3587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0680782 Vali Loss: 0.0614492 Test Loss: 0.0645039\n",
      "Validation loss decreased (0.067087 --> 0.061449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0668391\n",
      "\tspeed: 0.0400s/iter; left time: 865.9375s\n",
      "\titers: 200, epoch: 4 | loss: 0.0596936\n",
      "\tspeed: 0.0234s/iter; left time: 504.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0634555 Vali Loss: 0.0594362 Test Loss: 0.0624195\n",
      "Validation loss decreased (0.061449 --> 0.059436).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0586804\n",
      "\tspeed: 0.0473s/iter; left time: 1012.2459s\n",
      "\titers: 200, epoch: 5 | loss: 0.0589989\n",
      "\tspeed: 0.0290s/iter; left time: 618.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0611099 Vali Loss: 0.0581458 Test Loss: 0.0613357\n",
      "Validation loss decreased (0.059436 --> 0.058146).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608906\n",
      "\tspeed: 0.0472s/iter; left time: 999.8721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0625170\n",
      "\tspeed: 0.0187s/iter; left time: 393.4921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0596767 Vali Loss: 0.0571735 Test Loss: 0.0603391\n",
      "Validation loss decreased (0.058146 --> 0.057174).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0612659\n",
      "\tspeed: 0.0494s/iter; left time: 1035.4285s\n",
      "\titers: 200, epoch: 7 | loss: 0.0618040\n",
      "\tspeed: 0.0294s/iter; left time: 612.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0586573 Vali Loss: 0.0567377 Test Loss: 0.0597808\n",
      "Validation loss decreased (0.057174 --> 0.056738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0609334\n",
      "\tspeed: 0.0518s/iter; left time: 1073.6474s\n",
      "\titers: 200, epoch: 8 | loss: 0.0601185\n",
      "\tspeed: 0.0303s/iter; left time: 625.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0579431 Vali Loss: 0.0564018 Test Loss: 0.0596036\n",
      "Validation loss decreased (0.056738 --> 0.056402).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559483\n",
      "\tspeed: 0.0489s/iter; left time: 1002.6247s\n",
      "\titers: 200, epoch: 9 | loss: 0.0557282\n",
      "\tspeed: 0.0259s/iter; left time: 528.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0574038 Vali Loss: 0.0559832 Test Loss: 0.0592274\n",
      "Validation loss decreased (0.056402 --> 0.055983).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0589161\n",
      "\tspeed: 0.0534s/iter; left time: 1083.5470s\n",
      "\titers: 200, epoch: 10 | loss: 0.0553508\n",
      "\tspeed: 0.0310s/iter; left time: 624.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0568255 Vali Loss: 0.0556976 Test Loss: 0.0588285\n",
      "Validation loss decreased (0.055983 --> 0.055698).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579341\n",
      "\tspeed: 0.0534s/iter; left time: 1071.3430s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597333\n",
      "\tspeed: 0.0314s/iter; left time: 626.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0564201 Vali Loss: 0.0556333 Test Loss: 0.0588613\n",
      "Validation loss decreased (0.055698 --> 0.055633).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558739\n",
      "\tspeed: 0.0440s/iter; left time: 873.0304s\n",
      "\titers: 200, epoch: 12 | loss: 0.0573777\n",
      "\tspeed: 0.0204s/iter; left time: 402.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0561655 Vali Loss: 0.0552432 Test Loss: 0.0583723\n",
      "Validation loss decreased (0.055633 --> 0.055243).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571236\n",
      "\tspeed: 0.0457s/iter; left time: 895.7357s\n",
      "\titers: 200, epoch: 13 | loss: 0.0541315\n",
      "\tspeed: 0.0213s/iter; left time: 414.8190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0558599 Vali Loss: 0.0552857 Test Loss: 0.0583590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0520993\n",
      "\tspeed: 0.0453s/iter; left time: 879.1422s\n",
      "\titers: 200, epoch: 14 | loss: 0.0523064\n",
      "\tspeed: 0.0275s/iter; left time: 529.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0556158 Vali Loss: 0.0548539 Test Loss: 0.0580788\n",
      "Validation loss decreased (0.055243 --> 0.054854).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587672\n",
      "\tspeed: 0.0458s/iter; left time: 877.8710s\n",
      "\titers: 200, epoch: 15 | loss: 0.0596617\n",
      "\tspeed: 0.0187s/iter; left time: 355.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0554747 Vali Loss: 0.0548942 Test Loss: 0.0580083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550260\n",
      "\tspeed: 0.0485s/iter; left time: 918.8675s\n",
      "\titers: 200, epoch: 16 | loss: 0.0532614\n",
      "\tspeed: 0.0300s/iter; left time: 565.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0552542 Vali Loss: 0.0548342 Test Loss: 0.0580338\n",
      "Validation loss decreased (0.054854 --> 0.054834).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0511707\n",
      "\tspeed: 0.0445s/iter; left time: 833.4940s\n",
      "\titers: 200, epoch: 17 | loss: 0.0561253\n",
      "\tspeed: 0.0235s/iter; left time: 438.1868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0550196 Vali Loss: 0.0547964 Test Loss: 0.0579928\n",
      "Validation loss decreased (0.054834 --> 0.054796).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0507814\n",
      "\tspeed: 0.0489s/iter; left time: 904.0127s\n",
      "\titers: 200, epoch: 18 | loss: 0.0546626\n",
      "\tspeed: 0.0292s/iter; left time: 536.8393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0548828 Vali Loss: 0.0546505 Test Loss: 0.0579136\n",
      "Validation loss decreased (0.054796 --> 0.054651).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556139\n",
      "\tspeed: 0.0499s/iter; left time: 911.7435s\n",
      "\titers: 200, epoch: 19 | loss: 0.0551542\n",
      "\tspeed: 0.0299s/iter; left time: 543.6236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0548050 Vali Loss: 0.0545218 Test Loss: 0.0578084\n",
      "Validation loss decreased (0.054651 --> 0.054522).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0548958\n",
      "\tspeed: 0.0467s/iter; left time: 842.9506s\n",
      "\titers: 200, epoch: 20 | loss: 0.0556641\n",
      "\tspeed: 0.0270s/iter; left time: 484.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0547005 Vali Loss: 0.0545369 Test Loss: 0.0577752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0556805\n",
      "\tspeed: 0.0449s/iter; left time: 800.6158s\n",
      "\titers: 200, epoch: 21 | loss: 0.0535791\n",
      "\tspeed: 0.0224s/iter; left time: 397.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0545552 Vali Loss: 0.0544767 Test Loss: 0.0577947\n",
      "Validation loss decreased (0.054522 --> 0.054477).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0510939\n",
      "\tspeed: 0.0449s/iter; left time: 790.5225s\n",
      "\titers: 200, epoch: 22 | loss: 0.0508448\n",
      "\tspeed: 0.0211s/iter; left time: 369.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0544635 Vali Loss: 0.0543127 Test Loss: 0.0576927\n",
      "Validation loss decreased (0.054477 --> 0.054313).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0527465\n",
      "\tspeed: 0.0418s/iter; left time: 726.5374s\n",
      "\titers: 200, epoch: 23 | loss: 0.0564615\n",
      "\tspeed: 0.0208s/iter; left time: 358.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0543731 Vali Loss: 0.0543572 Test Loss: 0.0576575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0525694\n",
      "\tspeed: 0.0416s/iter; left time: 714.2002s\n",
      "\titers: 200, epoch: 24 | loss: 0.0520153\n",
      "\tspeed: 0.0223s/iter; left time: 380.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0543109 Vali Loss: 0.0544609 Test Loss: 0.0577047\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0545244\n",
      "\tspeed: 0.0468s/iter; left time: 792.6068s\n",
      "\titers: 200, epoch: 25 | loss: 0.0568986\n",
      "\tspeed: 0.0226s/iter; left time: 380.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0542926 Vali Loss: 0.0544399 Test Loss: 0.0576667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0514087\n",
      "\tspeed: 0.0492s/iter; left time: 822.5070s\n",
      "\titers: 200, epoch: 26 | loss: 0.0533059\n",
      "\tspeed: 0.0257s/iter; left time: 426.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0543018 Vali Loss: 0.0543743 Test Loss: 0.0576288\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0485907\n",
      "\tspeed: 0.0435s/iter; left time: 716.1532s\n",
      "\titers: 200, epoch: 27 | loss: 0.0524569\n",
      "\tspeed: 0.0284s/iter; left time: 465.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0542236 Vali Loss: 0.0542703 Test Loss: 0.0576765\n",
      "Validation loss decreased (0.054313 --> 0.054270).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0548666\n",
      "\tspeed: 0.0463s/iter; left time: 752.3909s\n",
      "\titers: 200, epoch: 28 | loss: 0.0549345\n",
      "\tspeed: 0.0247s/iter; left time: 398.5431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0541398 Vali Loss: 0.0542925 Test Loss: 0.0575766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0541316\n",
      "\tspeed: 0.0499s/iter; left time: 799.3593s\n",
      "\titers: 200, epoch: 29 | loss: 0.0575595\n",
      "\tspeed: 0.0284s/iter; left time: 452.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0540813 Vali Loss: 0.0542012 Test Loss: 0.0575910\n",
      "Validation loss decreased (0.054270 --> 0.054201).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537054\n",
      "\tspeed: 0.0521s/iter; left time: 823.1990s\n",
      "\titers: 200, epoch: 30 | loss: 0.0543732\n",
      "\tspeed: 0.0250s/iter; left time: 392.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0540058 Vali Loss: 0.0542466 Test Loss: 0.0575606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0511169\n",
      "\tspeed: 0.0476s/iter; left time: 741.3964s\n",
      "\titers: 200, epoch: 31 | loss: 0.0534600\n",
      "\tspeed: 0.0300s/iter; left time: 463.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0539924 Vali Loss: 0.0543476 Test Loss: 0.0576100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0545178\n",
      "\tspeed: 0.0515s/iter; left time: 790.4787s\n",
      "\titers: 200, epoch: 32 | loss: 0.0521410\n",
      "\tspeed: 0.0242s/iter; left time: 369.8326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0539856 Vali Loss: 0.0542446 Test Loss: 0.0575643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0535159\n",
      "\tspeed: 0.0453s/iter; left time: 686.2523s\n",
      "\titers: 200, epoch: 33 | loss: 0.0576613\n",
      "\tspeed: 0.0236s/iter; left time: 354.9393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0540268 Vali Loss: 0.0542139 Test Loss: 0.0575368\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0503014\n",
      "\tspeed: 0.0489s/iter; left time: 729.2979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0507608\n",
      "\tspeed: 0.0292s/iter; left time: 432.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0539310 Vali Loss: 0.0541555 Test Loss: 0.0575457\n",
      "Validation loss decreased (0.054201 --> 0.054156).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0559284\n",
      "\tspeed: 0.0453s/iter; left time: 665.0864s\n",
      "\titers: 200, epoch: 35 | loss: 0.0487487\n",
      "\tspeed: 0.0265s/iter; left time: 386.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0539104 Vali Loss: 0.0542847 Test Loss: 0.0575783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0509425\n",
      "\tspeed: 0.0442s/iter; left time: 638.7943s\n",
      "\titers: 200, epoch: 36 | loss: 0.0535903\n",
      "\tspeed: 0.0238s/iter; left time: 342.0471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0538424 Vali Loss: 0.0542319 Test Loss: 0.0575458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0520858\n",
      "\tspeed: 0.0449s/iter; left time: 639.2135s\n",
      "\titers: 200, epoch: 37 | loss: 0.0529962\n",
      "\tspeed: 0.0205s/iter; left time: 289.8046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0538672 Vali Loss: 0.0541754 Test Loss: 0.0575397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0592069\n",
      "\tspeed: 0.0423s/iter; left time: 593.2709s\n",
      "\titers: 200, epoch: 38 | loss: 0.0524423\n",
      "\tspeed: 0.0209s/iter; left time: 290.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0538877 Vali Loss: 0.0541813 Test Loss: 0.0574994\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0543057\n",
      "\tspeed: 0.0478s/iter; left time: 659.7646s\n",
      "\titers: 200, epoch: 39 | loss: 0.0568190\n",
      "\tspeed: 0.0251s/iter; left time: 344.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0538440 Vali Loss: 0.0542549 Test Loss: 0.0575586\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0494391\n",
      "\tspeed: 0.0508s/iter; left time: 689.0146s\n",
      "\titers: 200, epoch: 40 | loss: 0.0543796\n",
      "\tspeed: 0.0300s/iter; left time: 403.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0538752 Vali Loss: 0.0542016 Test Loss: 0.0575493\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0546858\n",
      "\tspeed: 0.0440s/iter; left time: 587.2866s\n",
      "\titers: 200, epoch: 41 | loss: 0.0564161\n",
      "\tspeed: 0.0232s/iter; left time: 307.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0537652 Vali Loss: 0.0541129 Test Loss: 0.0575355\n",
      "Validation loss decreased (0.054156 --> 0.054113).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0522904\n",
      "\tspeed: 0.0479s/iter; left time: 627.8829s\n",
      "\titers: 200, epoch: 42 | loss: 0.0506849\n",
      "\tspeed: 0.0194s/iter; left time: 252.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0538319 Vali Loss: 0.0541942 Test Loss: 0.0575096\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0541437\n",
      "\tspeed: 0.0438s/iter; left time: 564.9395s\n",
      "\titers: 200, epoch: 43 | loss: 0.0567838\n",
      "\tspeed: 0.0282s/iter; left time: 360.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0537914 Vali Loss: 0.0541320 Test Loss: 0.0574871\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0553076\n",
      "\tspeed: 0.0440s/iter; left time: 557.0258s\n",
      "\titers: 200, epoch: 44 | loss: 0.0532477\n",
      "\tspeed: 0.0203s/iter; left time: 254.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0537928 Vali Loss: 0.0541955 Test Loss: 0.0575228\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0528331\n",
      "\tspeed: 0.0400s/iter; left time: 497.2771s\n",
      "\titers: 200, epoch: 45 | loss: 0.0513904\n",
      "\tspeed: 0.0223s/iter; left time: 274.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0538229 Vali Loss: 0.0541076 Test Loss: 0.0575051\n",
      "Validation loss decreased (0.054113 --> 0.054108).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0531792\n",
      "\tspeed: 0.0490s/iter; left time: 599.1628s\n",
      "\titers: 200, epoch: 46 | loss: 0.0572458\n",
      "\tspeed: 0.0225s/iter; left time: 272.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0537984 Vali Loss: 0.0541687 Test Loss: 0.0574937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0555248\n",
      "\tspeed: 0.0416s/iter; left time: 498.8987s\n",
      "\titers: 200, epoch: 47 | loss: 0.0523108\n",
      "\tspeed: 0.0216s/iter; left time: 257.4337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0538200 Vali Loss: 0.0540876 Test Loss: 0.0574755\n",
      "Validation loss decreased (0.054108 --> 0.054088).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0569082\n",
      "\tspeed: 0.0424s/iter; left time: 499.2792s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528245\n",
      "\tspeed: 0.0203s/iter; left time: 236.5038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0538628 Vali Loss: 0.0541930 Test Loss: 0.0574972\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0530057\n",
      "\tspeed: 0.0420s/iter; left time: 485.3007s\n",
      "\titers: 200, epoch: 49 | loss: 0.0543255\n",
      "\tspeed: 0.0201s/iter; left time: 230.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0538476 Vali Loss: 0.0541611 Test Loss: 0.0575216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0541534\n",
      "\tspeed: 0.0428s/iter; left time: 485.0169s\n",
      "\titers: 200, epoch: 50 | loss: 0.0497250\n",
      "\tspeed: 0.0205s/iter; left time: 230.0593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0537712 Vali Loss: 0.0540977 Test Loss: 0.0574794\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0562502\n",
      "\tspeed: 0.0454s/iter; left time: 503.7411s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555009\n",
      "\tspeed: 0.0209s/iter; left time: 229.7817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0537810 Vali Loss: 0.0541226 Test Loss: 0.0575006\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0536008\n",
      "\tspeed: 0.0498s/iter; left time: 541.2075s\n",
      "\titers: 200, epoch: 52 | loss: 0.0510137\n",
      "\tspeed: 0.0208s/iter; left time: 224.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0537484 Vali Loss: 0.0541493 Test Loss: 0.0574942\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0518702\n",
      "\tspeed: 0.0413s/iter; left time: 440.4881s\n",
      "\titers: 200, epoch: 53 | loss: 0.0523567\n",
      "\tspeed: 0.0221s/iter; left time: 233.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0538000 Vali Loss: 0.0540886 Test Loss: 0.0574993\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0558723\n",
      "\tspeed: 0.0412s/iter; left time: 430.0934s\n",
      "\titers: 200, epoch: 54 | loss: 0.0545240\n",
      "\tspeed: 0.0208s/iter; left time: 214.7805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0537095 Vali Loss: 0.0540830 Test Loss: 0.0575031\n",
      "Validation loss decreased (0.054088 --> 0.054083).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0551244\n",
      "\tspeed: 0.0433s/iter; left time: 441.8541s\n",
      "\titers: 200, epoch: 55 | loss: 0.0522383\n",
      "\tspeed: 0.0291s/iter; left time: 293.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0537254 Vali Loss: 0.0542041 Test Loss: 0.0575326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0541679\n",
      "\tspeed: 0.0528s/iter; left time: 526.7249s\n",
      "\titers: 200, epoch: 56 | loss: 0.0512550\n",
      "\tspeed: 0.0312s/iter; left time: 308.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0536900 Vali Loss: 0.0542186 Test Loss: 0.0575690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0512657\n",
      "\tspeed: 0.0442s/iter; left time: 431.3145s\n",
      "\titers: 200, epoch: 57 | loss: 0.0573032\n",
      "\tspeed: 0.0187s/iter; left time: 180.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0537646 Vali Loss: 0.0541780 Test Loss: 0.0575059\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0531613\n",
      "\tspeed: 0.0532s/iter; left time: 507.0501s\n",
      "\titers: 200, epoch: 58 | loss: 0.0503448\n",
      "\tspeed: 0.0292s/iter; left time: 275.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0537936 Vali Loss: 0.0542244 Test Loss: 0.0575055\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0572657\n",
      "\tspeed: 0.0435s/iter; left time: 405.3390s\n",
      "\titers: 200, epoch: 59 | loss: 0.0486912\n",
      "\tspeed: 0.0256s/iter; left time: 235.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0537835 Vali Loss: 0.0541116 Test Loss: 0.0574790\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0526895\n",
      "\tspeed: 0.0476s/iter; left time: 432.3249s\n",
      "\titers: 200, epoch: 60 | loss: 0.0532946\n",
      "\tspeed: 0.0213s/iter; left time: 190.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0537708 Vali Loss: 0.0541880 Test Loss: 0.0575242\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0537537\n",
      "\tspeed: 0.0440s/iter; left time: 390.0417s\n",
      "\titers: 200, epoch: 61 | loss: 0.0560748\n",
      "\tspeed: 0.0228s/iter; left time: 199.5171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0537737 Vali Loss: 0.0541247 Test Loss: 0.0575137\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0597955\n",
      "\tspeed: 0.0432s/iter; left time: 373.1052s\n",
      "\titers: 200, epoch: 62 | loss: 0.0528720\n",
      "\tspeed: 0.0203s/iter; left time: 173.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0537969 Vali Loss: 0.0541071 Test Loss: 0.0575024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0512931\n",
      "\tspeed: 0.0444s/iter; left time: 373.3696s\n",
      "\titers: 200, epoch: 63 | loss: 0.0558844\n",
      "\tspeed: 0.0249s/iter; left time: 206.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.0537359 Vali Loss: 0.0540898 Test Loss: 0.0574858\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0564012\n",
      "\tspeed: 0.0413s/iter; left time: 338.0727s\n",
      "\titers: 200, epoch: 64 | loss: 0.0494175\n",
      "\tspeed: 0.0271s/iter; left time: 218.8245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0537625 Vali Loss: 0.0541930 Test Loss: 0.0575240\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010298804379999638, rmse:0.10148302465677261, mae:0.05750308930873871, rse:0.3834543824195862\n",
      "Intermediate time for IT and pred_len 24: 00h:17m:02.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1897424\n",
      "\tspeed: 0.0436s/iter; left time: 973.0558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1660296\n",
      "\tspeed: 0.0263s/iter; left time: 583.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.1848700 Vali Loss: 0.1568288 Test Loss: 0.1659999\n",
      "Validation loss decreased (inf --> 0.156829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024169\n",
      "\tspeed: 0.0489s/iter; left time: 1079.7309s\n",
      "\titers: 200, epoch: 2 | loss: 0.0910956\n",
      "\tspeed: 0.0293s/iter; left time: 643.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.1107622 Vali Loss: 0.0839978 Test Loss: 0.0893387\n",
      "Validation loss decreased (0.156829 --> 0.083998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0877967\n",
      "\tspeed: 0.0471s/iter; left time: 1029.6523s\n",
      "\titers: 200, epoch: 3 | loss: 0.0845751\n",
      "\tspeed: 0.0204s/iter; left time: 444.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0868382 Vali Loss: 0.0797890 Test Loss: 0.0855101\n",
      "Validation loss decreased (0.083998 --> 0.079789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0832801\n",
      "\tspeed: 0.0424s/iter; left time: 917.0175s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838606\n",
      "\tspeed: 0.0190s/iter; left time: 408.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0830027 Vali Loss: 0.0779550 Test Loss: 0.0838770\n",
      "Validation loss decreased (0.079789 --> 0.077955).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836165\n",
      "\tspeed: 0.0504s/iter; left time: 1078.8733s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807150\n",
      "\tspeed: 0.0282s/iter; left time: 601.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0807142 Vali Loss: 0.0771537 Test Loss: 0.0831487\n",
      "Validation loss decreased (0.077955 --> 0.077154).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791843\n",
      "\tspeed: 0.0447s/iter; left time: 945.7322s\n",
      "\titers: 200, epoch: 6 | loss: 0.0823486\n",
      "\tspeed: 0.0201s/iter; left time: 423.9013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0791624 Vali Loss: 0.0759724 Test Loss: 0.0820996\n",
      "Validation loss decreased (0.077154 --> 0.075972).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760478\n",
      "\tspeed: 0.0476s/iter; left time: 997.2595s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799497\n",
      "\tspeed: 0.0229s/iter; left time: 477.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0779178 Vali Loss: 0.0754273 Test Loss: 0.0814582\n",
      "Validation loss decreased (0.075972 --> 0.075427).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771076\n",
      "\tspeed: 0.0547s/iter; left time: 1134.8613s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778728\n",
      "\tspeed: 0.0264s/iter; left time: 545.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0770985 Vali Loss: 0.0752305 Test Loss: 0.0811528\n",
      "Validation loss decreased (0.075427 --> 0.075231).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780314\n",
      "\tspeed: 0.0554s/iter; left time: 1135.6731s\n",
      "\titers: 200, epoch: 9 | loss: 0.0764838\n",
      "\tspeed: 0.0257s/iter; left time: 525.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0764028 Vali Loss: 0.0753533 Test Loss: 0.0808745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0785056\n",
      "\tspeed: 0.0523s/iter; left time: 1060.3411s\n",
      "\titers: 200, epoch: 10 | loss: 0.0828919\n",
      "\tspeed: 0.0261s/iter; left time: 526.1118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0759053 Vali Loss: 0.0748969 Test Loss: 0.0806462\n",
      "Validation loss decreased (0.075231 --> 0.074897).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739013\n",
      "\tspeed: 0.0456s/iter; left time: 914.0697s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738992\n",
      "\tspeed: 0.0222s/iter; left time: 442.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0754611 Vali Loss: 0.0747856 Test Loss: 0.0804091\n",
      "Validation loss decreased (0.074897 --> 0.074786).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0753315\n",
      "\tspeed: 0.0484s/iter; left time: 959.3140s\n",
      "\titers: 200, epoch: 12 | loss: 0.0744555\n",
      "\tspeed: 0.0225s/iter; left time: 444.4952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0751179 Vali Loss: 0.0747633 Test Loss: 0.0803175\n",
      "Validation loss decreased (0.074786 --> 0.074763).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761819\n",
      "\tspeed: 0.0447s/iter; left time: 875.7267s\n",
      "\titers: 200, epoch: 13 | loss: 0.0746646\n",
      "\tspeed: 0.0216s/iter; left time: 420.6266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0746043 Vali Loss: 0.0748485 Test Loss: 0.0802644\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0739487\n",
      "\tspeed: 0.0481s/iter; left time: 932.8879s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754596\n",
      "\tspeed: 0.0282s/iter; left time: 544.8794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0742950 Vali Loss: 0.0747813 Test Loss: 0.0801432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745794\n",
      "\tspeed: 0.0525s/iter; left time: 1006.5622s\n",
      "\titers: 200, epoch: 15 | loss: 0.0730356\n",
      "\tspeed: 0.0294s/iter; left time: 560.8775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0740151 Vali Loss: 0.0747088 Test Loss: 0.0800761\n",
      "Validation loss decreased (0.074763 --> 0.074709).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0738461\n",
      "\tspeed: 0.0456s/iter; left time: 863.4836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740163\n",
      "\tspeed: 0.0243s/iter; left time: 458.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0737508 Vali Loss: 0.0748973 Test Loss: 0.0801656\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0755595\n",
      "\tspeed: 0.0448s/iter; left time: 838.0710s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715953\n",
      "\tspeed: 0.0253s/iter; left time: 470.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0735619 Vali Loss: 0.0748916 Test Loss: 0.0801487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721768\n",
      "\tspeed: 0.0411s/iter; left time: 759.3656s\n",
      "\titers: 200, epoch: 18 | loss: 0.0739127\n",
      "\tspeed: 0.0220s/iter; left time: 403.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0732374 Vali Loss: 0.0749033 Test Loss: 0.0800379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716102\n",
      "\tspeed: 0.0539s/iter; left time: 984.7920s\n",
      "\titers: 200, epoch: 19 | loss: 0.0738876\n",
      "\tspeed: 0.0296s/iter; left time: 538.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0731215 Vali Loss: 0.0749334 Test Loss: 0.0801609\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0754706\n",
      "\tspeed: 0.0454s/iter; left time: 820.1099s\n",
      "\titers: 200, epoch: 20 | loss: 0.0715530\n",
      "\tspeed: 0.0227s/iter; left time: 407.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0729291 Vali Loss: 0.0750122 Test Loss: 0.0800666\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0733462\n",
      "\tspeed: 0.0520s/iter; left time: 927.1033s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704411\n",
      "\tspeed: 0.0254s/iter; left time: 449.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0728185 Vali Loss: 0.0749699 Test Loss: 0.0800339\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0701853\n",
      "\tspeed: 0.0481s/iter; left time: 845.6156s\n",
      "\titers: 200, epoch: 22 | loss: 0.0728290\n",
      "\tspeed: 0.0214s/iter; left time: 375.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0726273 Vali Loss: 0.0750653 Test Loss: 0.0801478\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0738237\n",
      "\tspeed: 0.0410s/iter; left time: 712.7747s\n",
      "\titers: 200, epoch: 23 | loss: 0.0744610\n",
      "\tspeed: 0.0190s/iter; left time: 328.2954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0725068 Vali Loss: 0.0749483 Test Loss: 0.0800617\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0703177\n",
      "\tspeed: 0.0421s/iter; left time: 722.5084s\n",
      "\titers: 200, epoch: 24 | loss: 0.0738277\n",
      "\tspeed: 0.0241s/iter; left time: 410.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0723925 Vali Loss: 0.0750169 Test Loss: 0.0800056\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0702073\n",
      "\tspeed: 0.0561s/iter; left time: 949.1862s\n",
      "\titers: 200, epoch: 25 | loss: 0.0686791\n",
      "\tspeed: 0.0229s/iter; left time: 385.3875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0722800 Vali Loss: 0.0751388 Test Loss: 0.0801344\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018337104469537735, rmse:0.13541457056999207, mae:0.08007606863975525, rse:0.5120170712471008\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1827738\n",
      "\tspeed: 0.0362s/iter; left time: 808.3204s\n",
      "\titers: 200, epoch: 1 | loss: 0.1624280\n",
      "\tspeed: 0.0362s/iter; left time: 804.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.1817470 Vali Loss: 0.1551836 Test Loss: 0.1637643\n",
      "Validation loss decreased (inf --> 0.155184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1113340\n",
      "\tspeed: 0.0473s/iter; left time: 1044.3146s\n",
      "\titers: 200, epoch: 2 | loss: 0.0882552\n",
      "\tspeed: 0.0231s/iter; left time: 507.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1114921 Vali Loss: 0.0848917 Test Loss: 0.0902235\n",
      "Validation loss decreased (0.155184 --> 0.084892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0827083\n",
      "\tspeed: 0.0439s/iter; left time: 959.9937s\n",
      "\titers: 200, epoch: 3 | loss: 0.0895729\n",
      "\tspeed: 0.0207s/iter; left time: 450.8177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0870747 Vali Loss: 0.0797241 Test Loss: 0.0856203\n",
      "Validation loss decreased (0.084892 --> 0.079724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790608\n",
      "\tspeed: 0.0487s/iter; left time: 1053.8257s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837609\n",
      "\tspeed: 0.0252s/iter; left time: 542.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0829489 Vali Loss: 0.0777430 Test Loss: 0.0838870\n",
      "Validation loss decreased (0.079724 --> 0.077743).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795094\n",
      "\tspeed: 0.0552s/iter; left time: 1181.2833s\n",
      "\titers: 200, epoch: 5 | loss: 0.0808254\n",
      "\tspeed: 0.0336s/iter; left time: 716.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0805618 Vali Loss: 0.0766868 Test Loss: 0.0827020\n",
      "Validation loss decreased (0.077743 --> 0.076687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774054\n",
      "\tspeed: 0.0510s/iter; left time: 1080.5496s\n",
      "\titers: 200, epoch: 6 | loss: 0.0805546\n",
      "\tspeed: 0.0208s/iter; left time: 438.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0789684 Vali Loss: 0.0761221 Test Loss: 0.0821342\n",
      "Validation loss decreased (0.076687 --> 0.076122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774688\n",
      "\tspeed: 0.0433s/iter; left time: 907.8955s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727722\n",
      "\tspeed: 0.0220s/iter; left time: 458.8727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0778567 Vali Loss: 0.0758392 Test Loss: 0.0815176\n",
      "Validation loss decreased (0.076122 --> 0.075839).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771068\n",
      "\tspeed: 0.0439s/iter; left time: 909.3781s\n",
      "\titers: 200, epoch: 8 | loss: 0.0824874\n",
      "\tspeed: 0.0205s/iter; left time: 423.9399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0770561 Vali Loss: 0.0755169 Test Loss: 0.0811791\n",
      "Validation loss decreased (0.075839 --> 0.075517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0789274\n",
      "\tspeed: 0.0459s/iter; left time: 941.9685s\n",
      "\titers: 200, epoch: 9 | loss: 0.0738139\n",
      "\tspeed: 0.0263s/iter; left time: 537.0597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0763588 Vali Loss: 0.0755447 Test Loss: 0.0811369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779462\n",
      "\tspeed: 0.0539s/iter; left time: 1092.9134s\n",
      "\titers: 200, epoch: 10 | loss: 0.0702700\n",
      "\tspeed: 0.0255s/iter; left time: 515.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0758004 Vali Loss: 0.0753209 Test Loss: 0.0808286\n",
      "Validation loss decreased (0.075517 --> 0.075321).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0723042\n",
      "\tspeed: 0.0438s/iter; left time: 879.2150s\n",
      "\titers: 200, epoch: 11 | loss: 0.0768960\n",
      "\tspeed: 0.0307s/iter; left time: 612.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0753007 Vali Loss: 0.0753609 Test Loss: 0.0806790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0745839\n",
      "\tspeed: 0.0536s/iter; left time: 1062.5929s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751421\n",
      "\tspeed: 0.0286s/iter; left time: 564.3685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0748579 Vali Loss: 0.0752615 Test Loss: 0.0805437\n",
      "Validation loss decreased (0.075321 --> 0.075262).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767439\n",
      "\tspeed: 0.0481s/iter; left time: 943.6298s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714387\n",
      "\tspeed: 0.0297s/iter; left time: 580.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0744048 Vali Loss: 0.0752695 Test Loss: 0.0805372\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0812772\n",
      "\tspeed: 0.0493s/iter; left time: 954.9337s\n",
      "\titers: 200, epoch: 14 | loss: 0.0698756\n",
      "\tspeed: 0.0280s/iter; left time: 540.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0741010 Vali Loss: 0.0750162 Test Loss: 0.0806282\n",
      "Validation loss decreased (0.075262 --> 0.075016).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730494\n",
      "\tspeed: 0.0495s/iter; left time: 948.0556s\n",
      "\titers: 200, epoch: 15 | loss: 0.0689267\n",
      "\tspeed: 0.0272s/iter; left time: 519.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0737643 Vali Loss: 0.0752641 Test Loss: 0.0805084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0752778\n",
      "\tspeed: 0.0438s/iter; left time: 829.6123s\n",
      "\titers: 200, epoch: 16 | loss: 0.0720928\n",
      "\tspeed: 0.0281s/iter; left time: 529.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0734657 Vali Loss: 0.0752829 Test Loss: 0.0805779\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0738348\n",
      "\tspeed: 0.0447s/iter; left time: 837.0790s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769251\n",
      "\tspeed: 0.0190s/iter; left time: 354.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0731761 Vali Loss: 0.0752677 Test Loss: 0.0805112\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0731803\n",
      "\tspeed: 0.0444s/iter; left time: 820.9873s\n",
      "\titers: 200, epoch: 18 | loss: 0.0719006\n",
      "\tspeed: 0.0201s/iter; left time: 370.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0730070 Vali Loss: 0.0754740 Test Loss: 0.0806912\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0701754\n",
      "\tspeed: 0.0422s/iter; left time: 771.1246s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759962\n",
      "\tspeed: 0.0202s/iter; left time: 367.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0727712 Vali Loss: 0.0752290 Test Loss: 0.0805320\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0721415\n",
      "\tspeed: 0.0417s/iter; left time: 753.2483s\n",
      "\titers: 200, epoch: 20 | loss: 0.0728425\n",
      "\tspeed: 0.0235s/iter; left time: 421.6963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0725560 Vali Loss: 0.0752777 Test Loss: 0.0806309\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0685759\n",
      "\tspeed: 0.0524s/iter; left time: 933.3836s\n",
      "\titers: 200, epoch: 21 | loss: 0.0680131\n",
      "\tspeed: 0.0295s/iter; left time: 523.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0723720 Vali Loss: 0.0755011 Test Loss: 0.0806623\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0718173\n",
      "\tspeed: 0.0460s/iter; left time: 810.2515s\n",
      "\titers: 200, epoch: 22 | loss: 0.0691799\n",
      "\tspeed: 0.0248s/iter; left time: 434.0017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0721597 Vali Loss: 0.0753126 Test Loss: 0.0806648\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0705262\n",
      "\tspeed: 0.0591s/iter; left time: 1026.1397s\n",
      "\titers: 200, epoch: 23 | loss: 0.0734291\n",
      "\tspeed: 0.0281s/iter; left time: 484.6647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.0720592 Vali Loss: 0.0755126 Test Loss: 0.0807637\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0690811\n",
      "\tspeed: 0.0483s/iter; left time: 827.5331s\n",
      "\titers: 200, epoch: 24 | loss: 0.0691510\n",
      "\tspeed: 0.0284s/iter; left time: 483.8131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0718792 Vali Loss: 0.0755178 Test Loss: 0.0806498\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018631743267178535, rmse:0.13649813830852509, mae:0.0806281715631485, rse:0.5161141753196716\n",
      "Intermediate time for IT and pred_len 96: 00h:06m:08.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1871080\n",
      "\tspeed: 0.0446s/iter; left time: 990.5383s\n",
      "\titers: 200, epoch: 1 | loss: 0.1701941\n",
      "\tspeed: 0.0203s/iter; left time: 447.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.1848148 Vali Loss: 0.1584008 Test Loss: 0.1668562\n",
      "Validation loss decreased (inf --> 0.158401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1082211\n",
      "\tspeed: 0.0480s/iter; left time: 1054.3196s\n",
      "\titers: 200, epoch: 2 | loss: 0.0961469\n",
      "\tspeed: 0.0249s/iter; left time: 545.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.1135394 Vali Loss: 0.0881948 Test Loss: 0.0930001\n",
      "Validation loss decreased (0.158401 --> 0.088195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899713\n",
      "\tspeed: 0.0495s/iter; left time: 1077.3382s\n",
      "\titers: 200, epoch: 3 | loss: 0.0872674\n",
      "\tspeed: 0.0292s/iter; left time: 632.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 223 | Train Loss: 0.0908954 Vali Loss: 0.0842529 Test Loss: 0.0897564\n",
      "Validation loss decreased (0.088195 --> 0.084253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878746\n",
      "\tspeed: 0.0452s/iter; left time: 972.5959s\n",
      "\titers: 200, epoch: 4 | loss: 0.0890932\n",
      "\tspeed: 0.0217s/iter; left time: 465.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0872191 Vali Loss: 0.0827244 Test Loss: 0.0881889\n",
      "Validation loss decreased (0.084253 --> 0.082724).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0804994\n",
      "\tspeed: 0.0484s/iter; left time: 1031.8367s\n",
      "\titers: 200, epoch: 5 | loss: 0.0868201\n",
      "\tspeed: 0.0265s/iter; left time: 562.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0849675 Vali Loss: 0.0816579 Test Loss: 0.0870870\n",
      "Validation loss decreased (0.082724 --> 0.081658).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0877921\n",
      "\tspeed: 0.0477s/iter; left time: 1004.7922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802644\n",
      "\tspeed: 0.0191s/iter; left time: 401.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0834004 Vali Loss: 0.0816223 Test Loss: 0.0867260\n",
      "Validation loss decreased (0.081658 --> 0.081622).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0802745\n",
      "\tspeed: 0.0528s/iter; left time: 1100.6361s\n",
      "\titers: 200, epoch: 7 | loss: 0.0880157\n",
      "\tspeed: 0.0255s/iter; left time: 529.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0822841 Vali Loss: 0.0809245 Test Loss: 0.0860589\n",
      "Validation loss decreased (0.081622 --> 0.080924).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823588\n",
      "\tspeed: 0.0466s/iter; left time: 962.8040s\n",
      "\titers: 200, epoch: 8 | loss: 0.0811449\n",
      "\tspeed: 0.0290s/iter; left time: 595.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0813769 Vali Loss: 0.0811670 Test Loss: 0.0860912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778788\n",
      "\tspeed: 0.0442s/iter; left time: 901.8210s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804173\n",
      "\tspeed: 0.0214s/iter; left time: 434.7922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0806823 Vali Loss: 0.0805403 Test Loss: 0.0857278\n",
      "Validation loss decreased (0.080924 --> 0.080540).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0770819\n",
      "\tspeed: 0.0465s/iter; left time: 938.3038s\n",
      "\titers: 200, epoch: 10 | loss: 0.0826294\n",
      "\tspeed: 0.0288s/iter; left time: 577.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0801259 Vali Loss: 0.0807335 Test Loss: 0.0857788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796840\n",
      "\tspeed: 0.0573s/iter; left time: 1145.1542s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764318\n",
      "\tspeed: 0.0303s/iter; left time: 602.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 223 | Train Loss: 0.0794757 Vali Loss: 0.0806652 Test Loss: 0.0857937\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0779649\n",
      "\tspeed: 0.0480s/iter; left time: 947.6762s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754844\n",
      "\tspeed: 0.0290s/iter; left time: 570.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0789886 Vali Loss: 0.0805692 Test Loss: 0.0857285\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0795467\n",
      "\tspeed: 0.0544s/iter; left time: 1062.3717s\n",
      "\titers: 200, epoch: 13 | loss: 0.0763251\n",
      "\tspeed: 0.0307s/iter; left time: 595.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.0785508 Vali Loss: 0.0807191 Test Loss: 0.0858291\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0559s/iter; left time: 1079.3876s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791975\n",
      "\tspeed: 0.0320s/iter; left time: 613.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 223 | Train Loss: 0.0781226 Vali Loss: 0.0805922 Test Loss: 0.0856806\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0760831\n",
      "\tspeed: 0.0504s/iter; left time: 961.4333s\n",
      "\titers: 200, epoch: 15 | loss: 0.0747853\n",
      "\tspeed: 0.0283s/iter; left time: 536.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0777189 Vali Loss: 0.0807949 Test Loss: 0.0857892\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0732571\n",
      "\tspeed: 0.0483s/iter; left time: 910.2189s\n",
      "\titers: 200, epoch: 16 | loss: 0.0756798\n",
      "\tspeed: 0.0250s/iter; left time: 468.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0773609 Vali Loss: 0.0807852 Test Loss: 0.0857691\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0753140\n",
      "\tspeed: 0.0446s/iter; left time: 830.6530s\n",
      "\titers: 200, epoch: 17 | loss: 0.0768818\n",
      "\tspeed: 0.0206s/iter; left time: 382.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0771312 Vali Loss: 0.0808058 Test Loss: 0.0857475\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0768754\n",
      "\tspeed: 0.0540s/iter; left time: 993.7216s\n",
      "\titers: 200, epoch: 18 | loss: 0.0721970\n",
      "\tspeed: 0.0271s/iter; left time: 496.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0768347 Vali Loss: 0.0808383 Test Loss: 0.0857581\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0776695\n",
      "\tspeed: 0.0529s/iter; left time: 961.6611s\n",
      "\titers: 200, epoch: 19 | loss: 0.0771099\n",
      "\tspeed: 0.0269s/iter; left time: 485.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0766373 Vali Loss: 0.0811134 Test Loss: 0.0859559\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019921839237213135, rmse:0.1411447525024414, mae:0.08572778850793839, rse:0.5341794490814209\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1816736\n",
      "\tspeed: 0.0312s/iter; left time: 692.3775s\n",
      "\titers: 200, epoch: 1 | loss: 0.1669765\n",
      "\tspeed: 0.0265s/iter; left time: 585.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1838783 Vali Loss: 0.1573194 Test Loss: 0.1655335\n",
      "Validation loss decreased (inf --> 0.157319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1026593\n",
      "\tspeed: 0.0558s/iter; left time: 1226.3430s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930660\n",
      "\tspeed: 0.0269s/iter; left time: 587.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 223 | Train Loss: 0.1131819 Vali Loss: 0.0886624 Test Loss: 0.0937149\n",
      "Validation loss decreased (0.157319 --> 0.088662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0915361\n",
      "\tspeed: 0.0496s/iter; left time: 1079.6910s\n",
      "\titers: 200, epoch: 3 | loss: 0.0895231\n",
      "\tspeed: 0.0282s/iter; left time: 611.5892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0911691 Vali Loss: 0.0849337 Test Loss: 0.0903517\n",
      "Validation loss decreased (0.088662 --> 0.084934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862588\n",
      "\tspeed: 0.0567s/iter; left time: 1220.0821s\n",
      "\titers: 200, epoch: 4 | loss: 0.0882206\n",
      "\tspeed: 0.0313s/iter; left time: 671.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0874352 Vali Loss: 0.0828849 Test Loss: 0.0883635\n",
      "Validation loss decreased (0.084934 --> 0.082885).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844780\n",
      "\tspeed: 0.0563s/iter; left time: 1198.9483s\n",
      "\titers: 200, epoch: 5 | loss: 0.0859491\n",
      "\tspeed: 0.0302s/iter; left time: 640.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.0852878 Vali Loss: 0.0823374 Test Loss: 0.0876971\n",
      "Validation loss decreased (0.082885 --> 0.082337).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0841684\n",
      "\tspeed: 0.0464s/iter; left time: 977.6253s\n",
      "\titers: 200, epoch: 6 | loss: 0.0840324\n",
      "\tspeed: 0.0266s/iter; left time: 558.5873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0837317 Vali Loss: 0.0820979 Test Loss: 0.0871194\n",
      "Validation loss decreased (0.082337 --> 0.082098).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0842942\n",
      "\tspeed: 0.0551s/iter; left time: 1149.5540s\n",
      "\titers: 200, epoch: 7 | loss: 0.0779059\n",
      "\tspeed: 0.0192s/iter; left time: 399.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0825489 Vali Loss: 0.0813784 Test Loss: 0.0863894\n",
      "Validation loss decreased (0.082098 --> 0.081378).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0811398\n",
      "\tspeed: 0.0530s/iter; left time: 1094.0397s\n",
      "\titers: 200, epoch: 8 | loss: 0.0801221\n",
      "\tspeed: 0.0301s/iter; left time: 618.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0817282 Vali Loss: 0.0813061 Test Loss: 0.0862801\n",
      "Validation loss decreased (0.081378 --> 0.081306).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0788420\n",
      "\tspeed: 0.0505s/iter; left time: 1031.6064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805206\n",
      "\tspeed: 0.0282s/iter; left time: 572.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0810667 Vali Loss: 0.0812916 Test Loss: 0.0860653\n",
      "Validation loss decreased (0.081306 --> 0.081292).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0785227\n",
      "\tspeed: 0.0551s/iter; left time: 1111.7588s\n",
      "\titers: 200, epoch: 10 | loss: 0.0825302\n",
      "\tspeed: 0.0230s/iter; left time: 462.9663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0804001 Vali Loss: 0.0815071 Test Loss: 0.0859425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810448\n",
      "\tspeed: 0.0465s/iter; left time: 929.2074s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828469\n",
      "\tspeed: 0.0293s/iter; left time: 581.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0798925 Vali Loss: 0.0812528 Test Loss: 0.0858475\n",
      "Validation loss decreased (0.081292 --> 0.081253).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0802267\n",
      "\tspeed: 0.0532s/iter; left time: 1051.3107s\n",
      "\titers: 200, epoch: 12 | loss: 0.0784165\n",
      "\tspeed: 0.0259s/iter; left time: 509.7511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0793688 Vali Loss: 0.0814065 Test Loss: 0.0858275\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776752\n",
      "\tspeed: 0.0485s/iter; left time: 945.9931s\n",
      "\titers: 200, epoch: 13 | loss: 0.0829622\n",
      "\tspeed: 0.0339s/iter; left time: 659.3622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.0789271 Vali Loss: 0.0813937 Test Loss: 0.0858137\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0796074\n",
      "\tspeed: 0.0537s/iter; left time: 1037.1302s\n",
      "\titers: 200, epoch: 14 | loss: 0.0809697\n",
      "\tspeed: 0.0249s/iter; left time: 478.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0784448 Vali Loss: 0.0815687 Test Loss: 0.0857783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0771293\n",
      "\tspeed: 0.0538s/iter; left time: 1025.8638s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776369\n",
      "\tspeed: 0.0345s/iter; left time: 654.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 223 | Train Loss: 0.0780975 Vali Loss: 0.0816726 Test Loss: 0.0857289\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782697\n",
      "\tspeed: 0.0502s/iter; left time: 945.7365s\n",
      "\titers: 200, epoch: 16 | loss: 0.0806615\n",
      "\tspeed: 0.0288s/iter; left time: 539.6876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0777307 Vali Loss: 0.0817458 Test Loss: 0.0858256\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0781653\n",
      "\tspeed: 0.0579s/iter; left time: 1078.5758s\n",
      "\titers: 200, epoch: 17 | loss: 0.0774504\n",
      "\tspeed: 0.0320s/iter; left time: 593.7045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 223 | Train Loss: 0.0773714 Vali Loss: 0.0820142 Test Loss: 0.0860682\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789591\n",
      "\tspeed: 0.0490s/iter; left time: 901.4839s\n",
      "\titers: 200, epoch: 18 | loss: 0.0789824\n",
      "\tspeed: 0.0200s/iter; left time: 366.4266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0771290 Vali Loss: 0.0818449 Test Loss: 0.0859780\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0802735\n",
      "\tspeed: 0.0429s/iter; left time: 780.7813s\n",
      "\titers: 200, epoch: 19 | loss: 0.0756500\n",
      "\tspeed: 0.0191s/iter; left time: 345.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0768453 Vali Loss: 0.0821504 Test Loss: 0.0860087\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0751452\n",
      "\tspeed: 0.0455s/iter; left time: 818.2319s\n",
      "\titers: 200, epoch: 20 | loss: 0.0775907\n",
      "\tspeed: 0.0244s/iter; left time: 436.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0766173 Vali Loss: 0.0823639 Test Loss: 0.0861695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0743880\n",
      "\tspeed: 0.0579s/iter; left time: 1026.4330s\n",
      "\titers: 200, epoch: 21 | loss: 0.0772368\n",
      "\tspeed: 0.0308s/iter; left time: 543.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 223 | Train Loss: 0.0763270 Vali Loss: 0.0824046 Test Loss: 0.0860958\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01997414045035839, rmse:0.14132989943027496, mae:0.08584751188755035, rse:0.5348801612854004\n",
      "Intermediate time for IT and pred_len 168: 00h:05m:22.30s\n",
      "Intermediate time for IT: 00h:28m:33.75s\n",
      "Total time: 02h:03m:53.97s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.0681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0215  0.1467  0.0904\n",
       "        96              0.0397  0.1992  0.1309\n",
       "        168             0.0416  0.2039  0.1373\n",
       "ES      24              0.0123  0.1101  0.0681\n",
       "        96              0.0242  0.1542  0.0995\n",
       "        168             0.0267  0.1625  0.1065\n",
       "FR      24              0.0106  0.1028  0.0581\n",
       "        96              0.0202  0.1420  0.0832\n",
       "        168             0.0223  0.1492  0.0890\n",
       "GB      24              0.0263  0.1622  0.1035\n",
       "        96              0.0477  0.2182  0.1470\n",
       "        168             0.0504  0.2243  0.1532\n",
       "IT      24              0.0105  0.1025  0.0595\n",
       "        96              0.0185  0.1360  0.0822\n",
       "        168             0.0202  0.1421  0.0875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TS Decomposition + No RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3197058\n",
      "\tspeed: 0.0526s/iter; left time: 1172.7339s\n",
      "\titers: 200, epoch: 1 | loss: 0.2848803\n",
      "\tspeed: 0.0288s/iter; left time: 638.5834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.3224996 Vali Loss: 0.2445201 Test Loss: 0.2496311\n",
      "Validation loss decreased (inf --> 0.244520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632958\n",
      "\tspeed: 0.0569s/iter; left time: 1255.6817s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435396\n",
      "\tspeed: 0.0287s/iter; left time: 631.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.1791550 Vali Loss: 0.1517329 Test Loss: 0.1590105\n",
      "Validation loss decreased (0.244520 --> 0.151733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1282190\n",
      "\tspeed: 0.0563s/iter; left time: 1231.3931s\n",
      "\titers: 200, epoch: 3 | loss: 0.1236127\n",
      "\tspeed: 0.0288s/iter; left time: 625.7247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.1314856 Vali Loss: 0.1271769 Test Loss: 0.1298694\n",
      "Validation loss decreased (0.151733 --> 0.127177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1127182\n",
      "\tspeed: 0.0572s/iter; left time: 1236.7713s\n",
      "\titers: 200, epoch: 4 | loss: 0.1083485\n",
      "\tspeed: 0.0288s/iter; left time: 619.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1104953 Vali Loss: 0.1135581 Test Loss: 0.1164518\n",
      "Validation loss decreased (0.127177 --> 0.113558).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994385\n",
      "\tspeed: 0.0563s/iter; left time: 1205.1099s\n",
      "\titers: 200, epoch: 5 | loss: 0.0961599\n",
      "\tspeed: 0.0287s/iter; left time: 611.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.1026559 Vali Loss: 0.1095314 Test Loss: 0.1127537\n",
      "Validation loss decreased (0.113558 --> 0.109531).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0999587\n",
      "\tspeed: 0.0560s/iter; left time: 1186.2303s\n",
      "\titers: 200, epoch: 6 | loss: 0.0995596\n",
      "\tspeed: 0.0288s/iter; left time: 606.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0984441 Vali Loss: 0.1057713 Test Loss: 0.1084825\n",
      "Validation loss decreased (0.109531 --> 0.105771).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0907515\n",
      "\tspeed: 0.0562s/iter; left time: 1178.5810s\n",
      "\titers: 200, epoch: 7 | loss: 0.0917593\n",
      "\tspeed: 0.0286s/iter; left time: 597.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0954027 Vali Loss: 0.1031872 Test Loss: 0.1064405\n",
      "Validation loss decreased (0.105771 --> 0.103187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0886695\n",
      "\tspeed: 0.0563s/iter; left time: 1167.5693s\n",
      "\titers: 200, epoch: 8 | loss: 0.0955137\n",
      "\tspeed: 0.0293s/iter; left time: 604.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0931543 Vali Loss: 0.1008810 Test Loss: 0.1040170\n",
      "Validation loss decreased (0.103187 --> 0.100881).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0916593\n",
      "\tspeed: 0.0566s/iter; left time: 1161.8332s\n",
      "\titers: 200, epoch: 9 | loss: 0.0895172\n",
      "\tspeed: 0.0287s/iter; left time: 585.1445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0904668 Vali Loss: 0.1005310 Test Loss: 0.1034304\n",
      "Validation loss decreased (0.100881 --> 0.100531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0934890\n",
      "\tspeed: 0.0558s/iter; left time: 1131.7189s\n",
      "\titers: 200, epoch: 10 | loss: 0.0902340\n",
      "\tspeed: 0.0287s/iter; left time: 579.7588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0886777 Vali Loss: 0.0990515 Test Loss: 0.1017572\n",
      "Validation loss decreased (0.100531 --> 0.099052).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0879926\n",
      "\tspeed: 0.0574s/iter; left time: 1150.9837s\n",
      "\titers: 200, epoch: 11 | loss: 0.0838314\n",
      "\tspeed: 0.0287s/iter; left time: 572.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0874012 Vali Loss: 0.0971403 Test Loss: 0.0998325\n",
      "Validation loss decreased (0.099052 --> 0.097140).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0874995\n",
      "\tspeed: 0.0560s/iter; left time: 1110.7634s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851341\n",
      "\tspeed: 0.0287s/iter; left time: 566.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0861278 Vali Loss: 0.0964099 Test Loss: 0.0993579\n",
      "Validation loss decreased (0.097140 --> 0.096410).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0777159\n",
      "\tspeed: 0.0558s/iter; left time: 1093.6054s\n",
      "\titers: 200, epoch: 13 | loss: 0.0838768\n",
      "\tspeed: 0.0286s/iter; left time: 558.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0850737 Vali Loss: 0.0961637 Test Loss: 0.0989631\n",
      "Validation loss decreased (0.096410 --> 0.096164).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0880001\n",
      "\tspeed: 0.0577s/iter; left time: 1118.8888s\n",
      "\titers: 200, epoch: 14 | loss: 0.0836521\n",
      "\tspeed: 0.0287s/iter; left time: 553.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0842551 Vali Loss: 0.0952583 Test Loss: 0.0980118\n",
      "Validation loss decreased (0.096164 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869703\n",
      "\tspeed: 0.0556s/iter; left time: 1066.4405s\n",
      "\titers: 200, epoch: 15 | loss: 0.0802809\n",
      "\tspeed: 0.0288s/iter; left time: 548.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0836535 Vali Loss: 0.0945245 Test Loss: 0.0974304\n",
      "Validation loss decreased (0.095258 --> 0.094524).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831622\n",
      "\tspeed: 0.0561s/iter; left time: 1062.7175s\n",
      "\titers: 200, epoch: 16 | loss: 0.0802412\n",
      "\tspeed: 0.0289s/iter; left time: 544.6804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0830385 Vali Loss: 0.0941433 Test Loss: 0.0969761\n",
      "Validation loss decreased (0.094524 --> 0.094143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0828111\n",
      "\tspeed: 0.0594s/iter; left time: 1112.2121s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813980\n",
      "\tspeed: 0.0287s/iter; left time: 533.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0826371 Vali Loss: 0.0938573 Test Loss: 0.0968296\n",
      "Validation loss decreased (0.094143 --> 0.093857).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0882007\n",
      "\tspeed: 0.0567s/iter; left time: 1047.9126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0830444\n",
      "\tspeed: 0.0291s/iter; left time: 535.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0820137 Vali Loss: 0.0932900 Test Loss: 0.0962584\n",
      "Validation loss decreased (0.093857 --> 0.093290).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0787852\n",
      "\tspeed: 0.0563s/iter; left time: 1028.5846s\n",
      "\titers: 200, epoch: 19 | loss: 0.0860242\n",
      "\tspeed: 0.0288s/iter; left time: 522.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0818549 Vali Loss: 0.0935120 Test Loss: 0.0964473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0869714\n",
      "\tspeed: 0.0568s/iter; left time: 1024.8404s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774314\n",
      "\tspeed: 0.0287s/iter; left time: 515.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0814949 Vali Loss: 0.0931582 Test Loss: 0.0962105\n",
      "Validation loss decreased (0.093290 --> 0.093158).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0825148\n",
      "\tspeed: 0.0555s/iter; left time: 989.4062s\n",
      "\titers: 200, epoch: 21 | loss: 0.0794281\n",
      "\tspeed: 0.0287s/iter; left time: 507.9406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0811451 Vali Loss: 0.0930023 Test Loss: 0.0961104\n",
      "Validation loss decreased (0.093158 --> 0.093002).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0850863\n",
      "\tspeed: 0.0563s/iter; left time: 990.5913s\n",
      "\titers: 200, epoch: 22 | loss: 0.0789039\n",
      "\tspeed: 0.0287s/iter; left time: 502.6583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0807854 Vali Loss: 0.0926203 Test Loss: 0.0957541\n",
      "Validation loss decreased (0.093002 --> 0.092620).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0777277\n",
      "\tspeed: 0.0558s/iter; left time: 969.9203s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805508\n",
      "\tspeed: 0.0287s/iter; left time: 495.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0806165 Vali Loss: 0.0924586 Test Loss: 0.0955393\n",
      "Validation loss decreased (0.092620 --> 0.092459).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0818478\n",
      "\tspeed: 0.0570s/iter; left time: 977.0853s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759132\n",
      "\tspeed: 0.0312s/iter; left time: 532.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0805966 Vali Loss: 0.0924166 Test Loss: 0.0954238\n",
      "Validation loss decreased (0.092459 --> 0.092417).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0760192\n",
      "\tspeed: 0.0573s/iter; left time: 969.1440s\n",
      "\titers: 200, epoch: 25 | loss: 0.0776719\n",
      "\tspeed: 0.0287s/iter; left time: 483.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0803502 Vali Loss: 0.0923302 Test Loss: 0.0953170\n",
      "Validation loss decreased (0.092417 --> 0.092330).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0785188\n",
      "\tspeed: 0.0581s/iter; left time: 969.5733s\n",
      "\titers: 200, epoch: 26 | loss: 0.0827637\n",
      "\tspeed: 0.0288s/iter; left time: 478.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0802233 Vali Loss: 0.0921991 Test Loss: 0.0953128\n",
      "Validation loss decreased (0.092330 --> 0.092199).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0847908\n",
      "\tspeed: 0.0580s/iter; left time: 955.7538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0720040\n",
      "\tspeed: 0.0308s/iter; left time: 504.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0800503 Vali Loss: 0.0921637 Test Loss: 0.0953523\n",
      "Validation loss decreased (0.092199 --> 0.092164).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0759430\n",
      "\tspeed: 0.0561s/iter; left time: 911.0646s\n",
      "\titers: 200, epoch: 28 | loss: 0.0760074\n",
      "\tspeed: 0.0293s/iter; left time: 473.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0799574 Vali Loss: 0.0922607 Test Loss: 0.0952534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0776925\n",
      "\tspeed: 0.0554s/iter; left time: 888.7387s\n",
      "\titers: 200, epoch: 29 | loss: 0.0812824\n",
      "\tspeed: 0.0287s/iter; left time: 457.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0797620 Vali Loss: 0.0920596 Test Loss: 0.0952248\n",
      "Validation loss decreased (0.092164 --> 0.092060).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0812133\n",
      "\tspeed: 0.0563s/iter; left time: 889.3908s\n",
      "\titers: 200, epoch: 30 | loss: 0.0792079\n",
      "\tspeed: 0.0299s/iter; left time: 468.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0796643 Vali Loss: 0.0920389 Test Loss: 0.0952069\n",
      "Validation loss decreased (0.092060 --> 0.092039).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0799582\n",
      "\tspeed: 0.0590s/iter; left time: 919.1546s\n",
      "\titers: 200, epoch: 31 | loss: 0.0840088\n",
      "\tspeed: 0.0289s/iter; left time: 447.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0796199 Vali Loss: 0.0922228 Test Loss: 0.0952418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0821764\n",
      "\tspeed: 0.0558s/iter; left time: 857.4093s\n",
      "\titers: 200, epoch: 32 | loss: 0.0787179\n",
      "\tspeed: 0.0287s/iter; left time: 437.5372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0794869 Vali Loss: 0.0918187 Test Loss: 0.0949897\n",
      "Validation loss decreased (0.092039 --> 0.091819).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760578\n",
      "\tspeed: 0.0611s/iter; left time: 924.0703s\n",
      "\titers: 200, epoch: 33 | loss: 0.0761508\n",
      "\tspeed: 0.0291s/iter; left time: 436.7448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0794096 Vali Loss: 0.0918569 Test Loss: 0.0949462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0791486\n",
      "\tspeed: 0.0558s/iter; left time: 832.5425s\n",
      "\titers: 200, epoch: 34 | loss: 0.0809508\n",
      "\tspeed: 0.0293s/iter; left time: 434.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0794129 Vali Loss: 0.0918419 Test Loss: 0.0949500\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0787660\n",
      "\tspeed: 0.0557s/iter; left time: 818.6025s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781807\n",
      "\tspeed: 0.0290s/iter; left time: 422.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0792987 Vali Loss: 0.0918663 Test Loss: 0.0949004\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0771136\n",
      "\tspeed: 0.0548s/iter; left time: 792.9570s\n",
      "\titers: 200, epoch: 36 | loss: 0.0856092\n",
      "\tspeed: 0.0287s/iter; left time: 412.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0792038 Vali Loss: 0.0915161 Test Loss: 0.0948589\n",
      "Validation loss decreased (0.091819 --> 0.091516).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0785164\n",
      "\tspeed: 0.0601s/iter; left time: 855.5858s\n",
      "\titers: 200, epoch: 37 | loss: 0.0798977\n",
      "\tspeed: 0.0288s/iter; left time: 406.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0791269 Vali Loss: 0.0918882 Test Loss: 0.0949401\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829379\n",
      "\tspeed: 0.0555s/iter; left time: 777.5550s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800224\n",
      "\tspeed: 0.0288s/iter; left time: 400.0732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0791323 Vali Loss: 0.0916817 Test Loss: 0.0948977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0741546\n",
      "\tspeed: 0.0563s/iter; left time: 776.5006s\n",
      "\titers: 200, epoch: 39 | loss: 0.0826714\n",
      "\tspeed: 0.0297s/iter; left time: 406.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0791458 Vali Loss: 0.0915856 Test Loss: 0.0948140\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0833881\n",
      "\tspeed: 0.0562s/iter; left time: 762.4368s\n",
      "\titers: 200, epoch: 40 | loss: 0.0781727\n",
      "\tspeed: 0.0287s/iter; left time: 386.4679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0791787 Vali Loss: 0.0916256 Test Loss: 0.0948161\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0763385\n",
      "\tspeed: 0.0575s/iter; left time: 767.1197s\n",
      "\titers: 200, epoch: 41 | loss: 0.0806893\n",
      "\tspeed: 0.0301s/iter; left time: 399.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0791443 Vali Loss: 0.0915102 Test Loss: 0.0947952\n",
      "Validation loss decreased (0.091516 --> 0.091510).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0769386\n",
      "\tspeed: 0.0583s/iter; left time: 764.5457s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760310\n",
      "\tspeed: 0.0288s/iter; left time: 374.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0791145 Vali Loss: 0.0916063 Test Loss: 0.0948531\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0757580\n",
      "\tspeed: 0.0553s/iter; left time: 713.3795s\n",
      "\titers: 200, epoch: 43 | loss: 0.0780849\n",
      "\tspeed: 0.0286s/iter; left time: 365.7841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0789973 Vali Loss: 0.0914491 Test Loss: 0.0946928\n",
      "Validation loss decreased (0.091510 --> 0.091449).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0787410\n",
      "\tspeed: 0.0569s/iter; left time: 720.2958s\n",
      "\titers: 200, epoch: 44 | loss: 0.0794743\n",
      "\tspeed: 0.0316s/iter; left time: 397.3163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0789805 Vali Loss: 0.0915053 Test Loss: 0.0946968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0823872\n",
      "\tspeed: 0.0588s/iter; left time: 731.6363s\n",
      "\titers: 200, epoch: 45 | loss: 0.0807387\n",
      "\tspeed: 0.0287s/iter; left time: 354.7095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0789996 Vali Loss: 0.0915659 Test Loss: 0.0947360\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0749114\n",
      "\tspeed: 0.0556s/iter; left time: 679.7441s\n",
      "\titers: 200, epoch: 46 | loss: 0.0768852\n",
      "\tspeed: 0.0290s/iter; left time: 351.5347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0789341 Vali Loss: 0.0915456 Test Loss: 0.0947061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0817152\n",
      "\tspeed: 0.0584s/iter; left time: 700.9530s\n",
      "\titers: 200, epoch: 47 | loss: 0.0785883\n",
      "\tspeed: 0.0292s/iter; left time: 347.1869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0788940 Vali Loss: 0.0914847 Test Loss: 0.0946725\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0807889\n",
      "\tspeed: 0.0571s/iter; left time: 672.6040s\n",
      "\titers: 200, epoch: 48 | loss: 0.0767295\n",
      "\tspeed: 0.0321s/iter; left time: 374.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 224 | Train Loss: 0.0789192 Vali Loss: 0.0914578 Test Loss: 0.0946708\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0857605\n",
      "\tspeed: 0.0581s/iter; left time: 671.0748s\n",
      "\titers: 200, epoch: 49 | loss: 0.0810973\n",
      "\tspeed: 0.0287s/iter; left time: 328.2712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0789571 Vali Loss: 0.0915737 Test Loss: 0.0946986\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0794183\n",
      "\tspeed: 0.0603s/iter; left time: 682.4317s\n",
      "\titers: 200, epoch: 50 | loss: 0.0766388\n",
      "\tspeed: 0.0312s/iter; left time: 349.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0788912 Vali Loss: 0.0915001 Test Loss: 0.0947050\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0849604\n",
      "\tspeed: 0.0578s/iter; left time: 641.4361s\n",
      "\titers: 200, epoch: 51 | loss: 0.0741145\n",
      "\tspeed: 0.0294s/iter; left time: 323.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0788211 Vali Loss: 0.0914348 Test Loss: 0.0946621\n",
      "Validation loss decreased (0.091449 --> 0.091435).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0830796\n",
      "\tspeed: 0.0607s/iter; left time: 659.9584s\n",
      "\titers: 200, epoch: 52 | loss: 0.0823928\n",
      "\tspeed: 0.0295s/iter; left time: 318.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0788608 Vali Loss: 0.0913930 Test Loss: 0.0946222\n",
      "Validation loss decreased (0.091435 --> 0.091393).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0789665\n",
      "\tspeed: 0.0579s/iter; left time: 616.6387s\n",
      "\titers: 200, epoch: 53 | loss: 0.0793159\n",
      "\tspeed: 0.0287s/iter; left time: 302.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0788881 Vali Loss: 0.0914004 Test Loss: 0.0946748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0798185\n",
      "\tspeed: 0.0550s/iter; left time: 573.8359s\n",
      "\titers: 200, epoch: 54 | loss: 0.0830526\n",
      "\tspeed: 0.0287s/iter; left time: 296.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0787800 Vali Loss: 0.0916008 Test Loss: 0.0946632\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0828118\n",
      "\tspeed: 0.0568s/iter; left time: 580.0472s\n",
      "\titers: 200, epoch: 55 | loss: 0.0808505\n",
      "\tspeed: 0.0298s/iter; left time: 300.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0788300 Vali Loss: 0.0913965 Test Loss: 0.0946106\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0775362\n",
      "\tspeed: 0.0553s/iter; left time: 552.3706s\n",
      "\titers: 200, epoch: 56 | loss: 0.0801210\n",
      "\tspeed: 0.0288s/iter; left time: 284.7070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0787747 Vali Loss: 0.0914749 Test Loss: 0.0946795\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0782517\n",
      "\tspeed: 0.0566s/iter; left time: 551.8767s\n",
      "\titers: 200, epoch: 57 | loss: 0.0774873\n",
      "\tspeed: 0.0289s/iter; left time: 278.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0787326 Vali Loss: 0.0913945 Test Loss: 0.0946023\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0792777\n",
      "\tspeed: 0.0556s/iter; left time: 529.7561s\n",
      "\titers: 200, epoch: 58 | loss: 0.0783514\n",
      "\tspeed: 0.0287s/iter; left time: 270.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0787845 Vali Loss: 0.0914567 Test Loss: 0.0946663\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0796150\n",
      "\tspeed: 0.0554s/iter; left time: 515.7825s\n",
      "\titers: 200, epoch: 59 | loss: 0.0832107\n",
      "\tspeed: 0.0291s/iter; left time: 268.3340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0788072 Vali Loss: 0.0913913 Test Loss: 0.0946407\n",
      "Validation loss decreased (0.091393 --> 0.091391).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0787231\n",
      "\tspeed: 0.0556s/iter; left time: 504.9438s\n",
      "\titers: 200, epoch: 60 | loss: 0.0755110\n",
      "\tspeed: 0.0287s/iter; left time: 257.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0788761 Vali Loss: 0.0914502 Test Loss: 0.0946623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0792017\n",
      "\tspeed: 0.0557s/iter; left time: 493.8312s\n",
      "\titers: 200, epoch: 61 | loss: 0.0777682\n",
      "\tspeed: 0.0288s/iter; left time: 252.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0788058 Vali Loss: 0.0915640 Test Loss: 0.0946574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0758587\n",
      "\tspeed: 0.0576s/iter; left time: 497.9133s\n",
      "\titers: 200, epoch: 62 | loss: 0.0815503\n",
      "\tspeed: 0.0290s/iter; left time: 247.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0788866 Vali Loss: 0.0915096 Test Loss: 0.0946490\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0797632\n",
      "\tspeed: 0.0563s/iter; left time: 473.8000s\n",
      "\titers: 200, epoch: 63 | loss: 0.0808496\n",
      "\tspeed: 0.0289s/iter; left time: 240.0772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0788368 Vali Loss: 0.0913629 Test Loss: 0.0946776\n",
      "Validation loss decreased (0.091391 --> 0.091363).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0766272\n",
      "\tspeed: 0.0564s/iter; left time: 461.6617s\n",
      "\titers: 200, epoch: 64 | loss: 0.0780533\n",
      "\tspeed: 0.0295s/iter; left time: 238.6380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0787204 Vali Loss: 0.0914930 Test Loss: 0.0947015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0808332\n",
      "\tspeed: 0.0586s/iter; left time: 466.6111s\n",
      "\titers: 200, epoch: 65 | loss: 0.0796274\n",
      "\tspeed: 0.0290s/iter; left time: 228.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0788467 Vali Loss: 0.0914963 Test Loss: 0.0946941\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0800990\n",
      "\tspeed: 0.0551s/iter; left time: 426.5446s\n",
      "\titers: 200, epoch: 66 | loss: 0.0811623\n",
      "\tspeed: 0.0286s/iter; left time: 218.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0787522 Vali Loss: 0.0914804 Test Loss: 0.0946082\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0798974\n",
      "\tspeed: 0.0576s/iter; left time: 432.6413s\n",
      "\titers: 200, epoch: 67 | loss: 0.0783523\n",
      "\tspeed: 0.0300s/iter; left time: 222.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0787842 Vali Loss: 0.0915533 Test Loss: 0.0946329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0773258\n",
      "\tspeed: 0.0561s/iter; left time: 408.9209s\n",
      "\titers: 200, epoch: 68 | loss: 0.0745670\n",
      "\tspeed: 0.0293s/iter; left time: 210.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0788522 Vali Loss: 0.0914140 Test Loss: 0.0946395\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0794564\n",
      "\tspeed: 0.0579s/iter; left time: 409.5595s\n",
      "\titers: 200, epoch: 69 | loss: 0.0822435\n",
      "\tspeed: 0.0292s/iter; left time: 203.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0788005 Vali Loss: 0.0913866 Test Loss: 0.0946446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0760092\n",
      "\tspeed: 0.0558s/iter; left time: 381.7315s\n",
      "\titers: 200, epoch: 70 | loss: 0.0810970\n",
      "\tspeed: 0.0294s/iter; left time: 198.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0788935 Vali Loss: 0.0913040 Test Loss: 0.0946113\n",
      "Validation loss decreased (0.091363 --> 0.091304).  Saving model ...\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0795894\n",
      "\tspeed: 0.0560s/iter; left time: 370.6346s\n",
      "\titers: 200, epoch: 71 | loss: 0.0807285\n",
      "\tspeed: 0.0294s/iter; left time: 191.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0787180 Vali Loss: 0.0914073 Test Loss: 0.0946281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0786863\n",
      "\tspeed: 0.0593s/iter; left time: 379.1535s\n",
      "\titers: 200, epoch: 72 | loss: 0.0766350\n",
      "\tspeed: 0.0315s/iter; left time: 198.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0788218 Vali Loss: 0.0913915 Test Loss: 0.0946555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0796424\n",
      "\tspeed: 0.0577s/iter; left time: 356.1912s\n",
      "\titers: 200, epoch: 73 | loss: 0.0824023\n",
      "\tspeed: 0.0294s/iter; left time: 178.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0787715 Vali Loss: 0.0914191 Test Loss: 0.0946625\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0803520\n",
      "\tspeed: 0.0563s/iter; left time: 335.1935s\n",
      "\titers: 200, epoch: 74 | loss: 0.0816640\n",
      "\tspeed: 0.0287s/iter; left time: 167.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0787807 Vali Loss: 0.0914418 Test Loss: 0.0946511\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0714259\n",
      "\tspeed: 0.0599s/iter; left time: 343.1501s\n",
      "\titers: 200, epoch: 75 | loss: 0.0796324\n",
      "\tspeed: 0.0310s/iter; left time: 174.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0788424 Vali Loss: 0.0914667 Test Loss: 0.0946152\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0780322\n",
      "\tspeed: 0.0551s/iter; left time: 303.3180s\n",
      "\titers: 200, epoch: 76 | loss: 0.0795050\n",
      "\tspeed: 0.0287s/iter; left time: 154.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0788126 Vali Loss: 0.0914617 Test Loss: 0.0946714\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0811248\n",
      "\tspeed: 0.0549s/iter; left time: 289.7624s\n",
      "\titers: 200, epoch: 77 | loss: 0.0778454\n",
      "\tspeed: 0.0288s/iter; left time: 148.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0787774 Vali Loss: 0.0913488 Test Loss: 0.0945676\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0792612\n",
      "\tspeed: 0.0555s/iter; left time: 280.6183s\n",
      "\titers: 200, epoch: 78 | loss: 0.0751127\n",
      "\tspeed: 0.0301s/iter; left time: 149.1174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0786944 Vali Loss: 0.0915096 Test Loss: 0.0946719\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0783654\n",
      "\tspeed: 0.0574s/iter; left time: 277.3592s\n",
      "\titers: 200, epoch: 79 | loss: 0.0802027\n",
      "\tspeed: 0.0287s/iter; left time: 135.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0788154 Vali Loss: 0.0914191 Test Loss: 0.0946124\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0772694\n",
      "\tspeed: 0.0554s/iter; left time: 255.2565s\n",
      "\titers: 200, epoch: 80 | loss: 0.0817167\n",
      "\tspeed: 0.0293s/iter; left time: 131.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0787509 Vali Loss: 0.0914975 Test Loss: 0.0946591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022526277229189873, rmse:0.15008756518363953, mae:0.09461130201816559, rse:0.5296798348426819\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3263472\n",
      "\tspeed: 0.0325s/iter; left time: 725.8834s\n",
      "\titers: 200, epoch: 1 | loss: 0.2831808\n",
      "\tspeed: 0.0309s/iter; left time: 686.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.3271924 Vali Loss: 0.2423928 Test Loss: 0.2460536\n",
      "Validation loss decreased (inf --> 0.242393).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1785267\n",
      "\tspeed: 0.0571s/iter; left time: 1260.9253s\n",
      "\titers: 200, epoch: 2 | loss: 0.1391316\n",
      "\tspeed: 0.0294s/iter; left time: 646.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.1803416 Vali Loss: 0.1517669 Test Loss: 0.1603676\n",
      "Validation loss decreased (0.242393 --> 0.151767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1325689\n",
      "\tspeed: 0.0567s/iter; left time: 1238.4431s\n",
      "\titers: 200, epoch: 3 | loss: 0.1290069\n",
      "\tspeed: 0.0288s/iter; left time: 625.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.1354342 Vali Loss: 0.1362611 Test Loss: 0.1418294\n",
      "Validation loss decreased (0.151767 --> 0.136261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190557\n",
      "\tspeed: 0.0570s/iter; left time: 1232.9289s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114113\n",
      "\tspeed: 0.0296s/iter; left time: 637.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1207447 Vali Loss: 0.1171170 Test Loss: 0.1215052\n",
      "Validation loss decreased (0.136261 --> 0.117117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029699\n",
      "\tspeed: 0.0576s/iter; left time: 1232.8748s\n",
      "\titers: 200, epoch: 5 | loss: 0.1013697\n",
      "\tspeed: 0.0297s/iter; left time: 633.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1054484 Vali Loss: 0.1088530 Test Loss: 0.1115047\n",
      "Validation loss decreased (0.117117 --> 0.108853).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1028045\n",
      "\tspeed: 0.0626s/iter; left time: 1325.4356s\n",
      "\titers: 200, epoch: 6 | loss: 0.0938682\n",
      "\tspeed: 0.0322s/iter; left time: 679.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0980081 Vali Loss: 0.1039861 Test Loss: 0.1064981\n",
      "Validation loss decreased (0.108853 --> 0.103986).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955240\n",
      "\tspeed: 0.0593s/iter; left time: 1242.4889s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900847\n",
      "\tspeed: 0.0289s/iter; left time: 603.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0936799 Vali Loss: 0.1016879 Test Loss: 0.1035878\n",
      "Validation loss decreased (0.103986 --> 0.101688).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0949643\n",
      "\tspeed: 0.0564s/iter; left time: 1169.0890s\n",
      "\titers: 200, epoch: 8 | loss: 0.0869087\n",
      "\tspeed: 0.0296s/iter; left time: 609.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0905551 Vali Loss: 0.0997545 Test Loss: 0.1019835\n",
      "Validation loss decreased (0.101688 --> 0.099754).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0918865\n",
      "\tspeed: 0.0573s/iter; left time: 1174.4788s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869490\n",
      "\tspeed: 0.0294s/iter; left time: 599.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0884243 Vali Loss: 0.0977399 Test Loss: 0.1001031\n",
      "Validation loss decreased (0.099754 --> 0.097740).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0848328\n",
      "\tspeed: 0.0575s/iter; left time: 1166.9625s\n",
      "\titers: 200, epoch: 10 | loss: 0.0829500\n",
      "\tspeed: 0.0298s/iter; left time: 600.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0868936 Vali Loss: 0.0974935 Test Loss: 0.0999301\n",
      "Validation loss decreased (0.097740 --> 0.097494).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0873060\n",
      "\tspeed: 0.0595s/iter; left time: 1194.4145s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852580\n",
      "\tspeed: 0.0292s/iter; left time: 582.3769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0857368 Vali Loss: 0.0958268 Test Loss: 0.0986456\n",
      "Validation loss decreased (0.097494 --> 0.095827).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840052\n",
      "\tspeed: 0.0594s/iter; left time: 1177.9979s\n",
      "\titers: 200, epoch: 12 | loss: 0.0831931\n",
      "\tspeed: 0.0299s/iter; left time: 589.1914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0847689 Vali Loss: 0.0958034 Test Loss: 0.0985970\n",
      "Validation loss decreased (0.095827 --> 0.095803).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0788945\n",
      "\tspeed: 0.0571s/iter; left time: 1120.2128s\n",
      "\titers: 200, epoch: 13 | loss: 0.0791491\n",
      "\tspeed: 0.0294s/iter; left time: 573.2003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0839678 Vali Loss: 0.0947187 Test Loss: 0.0973555\n",
      "Validation loss decreased (0.095803 --> 0.094719).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0832333\n",
      "\tspeed: 0.0594s/iter; left time: 1152.1187s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843071\n",
      "\tspeed: 0.0293s/iter; left time: 564.2587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0831597 Vali Loss: 0.0941363 Test Loss: 0.0965966\n",
      "Validation loss decreased (0.094719 --> 0.094136).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0847979\n",
      "\tspeed: 0.0568s/iter; left time: 1088.2434s\n",
      "\titers: 200, epoch: 15 | loss: 0.0828745\n",
      "\tspeed: 0.0294s/iter; left time: 561.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0824756 Vali Loss: 0.0939837 Test Loss: 0.0965292\n",
      "Validation loss decreased (0.094136 --> 0.093984).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829985\n",
      "\tspeed: 0.0562s/iter; left time: 1064.9200s\n",
      "\titers: 200, epoch: 16 | loss: 0.0790856\n",
      "\tspeed: 0.0289s/iter; left time: 543.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0820821 Vali Loss: 0.0946790 Test Loss: 0.0969624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0853107\n",
      "\tspeed: 0.0550s/iter; left time: 1030.3485s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790544\n",
      "\tspeed: 0.0288s/iter; left time: 535.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0818546 Vali Loss: 0.0934381 Test Loss: 0.0959753\n",
      "Validation loss decreased (0.093984 --> 0.093438).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789593\n",
      "\tspeed: 0.0567s/iter; left time: 1049.3540s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845548\n",
      "\tspeed: 0.0297s/iter; left time: 545.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0812709 Vali Loss: 0.0932484 Test Loss: 0.0957892\n",
      "Validation loss decreased (0.093438 --> 0.093248).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0812598\n",
      "\tspeed: 0.0588s/iter; left time: 1073.8265s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834953\n",
      "\tspeed: 0.0291s/iter; left time: 528.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0808894 Vali Loss: 0.0927681 Test Loss: 0.0954273\n",
      "Validation loss decreased (0.093248 --> 0.092768).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802717\n",
      "\tspeed: 0.0569s/iter; left time: 1026.8100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0782393\n",
      "\tspeed: 0.0295s/iter; left time: 529.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0808180 Vali Loss: 0.0928830 Test Loss: 0.0955176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0790999\n",
      "\tspeed: 0.0566s/iter; left time: 1008.5881s\n",
      "\titers: 200, epoch: 21 | loss: 0.0761663\n",
      "\tspeed: 0.0288s/iter; left time: 510.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0803316 Vali Loss: 0.0924831 Test Loss: 0.0951181\n",
      "Validation loss decreased (0.092768 --> 0.092483).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0795682\n",
      "\tspeed: 0.0566s/iter; left time: 996.2784s\n",
      "\titers: 200, epoch: 22 | loss: 0.0772544\n",
      "\tspeed: 0.0290s/iter; left time: 508.1041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0803066 Vali Loss: 0.0921644 Test Loss: 0.0950196\n",
      "Validation loss decreased (0.092483 --> 0.092164).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0854671\n",
      "\tspeed: 0.0562s/iter; left time: 976.6599s\n",
      "\titers: 200, epoch: 23 | loss: 0.0750080\n",
      "\tspeed: 0.0288s/iter; left time: 497.0666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0799756 Vali Loss: 0.0923926 Test Loss: 0.0949493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0875047\n",
      "\tspeed: 0.0570s/iter; left time: 977.8712s\n",
      "\titers: 200, epoch: 24 | loss: 0.0802943\n",
      "\tspeed: 0.0294s/iter; left time: 501.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0797719 Vali Loss: 0.0922511 Test Loss: 0.0948106\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0843924\n",
      "\tspeed: 0.0569s/iter; left time: 962.7444s\n",
      "\titers: 200, epoch: 25 | loss: 0.0801979\n",
      "\tspeed: 0.0294s/iter; left time: 494.6298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0796732 Vali Loss: 0.0920858 Test Loss: 0.0948346\n",
      "Validation loss decreased (0.092164 --> 0.092086).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0781173\n",
      "\tspeed: 0.0563s/iter; left time: 940.9381s\n",
      "\titers: 200, epoch: 26 | loss: 0.0802341\n",
      "\tspeed: 0.0291s/iter; left time: 482.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0795897 Vali Loss: 0.0922518 Test Loss: 0.0948390\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0788582\n",
      "\tspeed: 0.0578s/iter; left time: 953.1852s\n",
      "\titers: 200, epoch: 27 | loss: 0.0764886\n",
      "\tspeed: 0.0287s/iter; left time: 470.1627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0794389 Vali Loss: 0.0918076 Test Loss: 0.0947502\n",
      "Validation loss decreased (0.092086 --> 0.091808).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0793905\n",
      "\tspeed: 0.0597s/iter; left time: 971.1057s\n",
      "\titers: 200, epoch: 28 | loss: 0.0834006\n",
      "\tspeed: 0.0341s/iter; left time: 550.3059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0792362 Vali Loss: 0.0918235 Test Loss: 0.0946142\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0805029\n",
      "\tspeed: 0.0555s/iter; left time: 889.1261s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780155\n",
      "\tspeed: 0.0286s/iter; left time: 456.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0792512 Vali Loss: 0.0917251 Test Loss: 0.0944976\n",
      "Validation loss decreased (0.091808 --> 0.091725).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0728002\n",
      "\tspeed: 0.0568s/iter; left time: 897.3827s\n",
      "\titers: 200, epoch: 30 | loss: 0.0804029\n",
      "\tspeed: 0.0335s/iter; left time: 526.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0790658 Vali Loss: 0.0917428 Test Loss: 0.0946357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807665\n",
      "\tspeed: 0.0585s/iter; left time: 912.0717s\n",
      "\titers: 200, epoch: 31 | loss: 0.0800907\n",
      "\tspeed: 0.0301s/iter; left time: 466.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0790678 Vali Loss: 0.0916744 Test Loss: 0.0944664\n",
      "Validation loss decreased (0.091725 --> 0.091674).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0780467\n",
      "\tspeed: 0.0576s/iter; left time: 884.2116s\n",
      "\titers: 200, epoch: 32 | loss: 0.0786057\n",
      "\tspeed: 0.0289s/iter; left time: 441.3042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0790550 Vali Loss: 0.0914951 Test Loss: 0.0943741\n",
      "Validation loss decreased (0.091674 --> 0.091495).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0875213\n",
      "\tspeed: 0.0576s/iter; left time: 871.7971s\n",
      "\titers: 200, epoch: 33 | loss: 0.0794292\n",
      "\tspeed: 0.0287s/iter; left time: 431.4490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0788769 Vali Loss: 0.0915824 Test Loss: 0.0943579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0804853\n",
      "\tspeed: 0.0584s/iter; left time: 871.1005s\n",
      "\titers: 200, epoch: 34 | loss: 0.0798110\n",
      "\tspeed: 0.0302s/iter; left time: 447.8089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.0788720 Vali Loss: 0.0915288 Test Loss: 0.0943922\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0796155\n",
      "\tspeed: 0.0558s/iter; left time: 819.7516s\n",
      "\titers: 200, epoch: 35 | loss: 0.0774992\n",
      "\tspeed: 0.0288s/iter; left time: 419.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0788216 Vali Loss: 0.0915622 Test Loss: 0.0944379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0773093\n",
      "\tspeed: 0.0561s/iter; left time: 811.6329s\n",
      "\titers: 200, epoch: 36 | loss: 0.0807466\n",
      "\tspeed: 0.0303s/iter; left time: 435.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0786771 Vali Loss: 0.0915188 Test Loss: 0.0942780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0776075\n",
      "\tspeed: 0.0557s/iter; left time: 792.3162s\n",
      "\titers: 200, epoch: 37 | loss: 0.0856185\n",
      "\tspeed: 0.0290s/iter; left time: 409.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0786951 Vali Loss: 0.0915789 Test Loss: 0.0943681\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0867405\n",
      "\tspeed: 0.0590s/iter; left time: 826.4031s\n",
      "\titers: 200, epoch: 38 | loss: 0.0773064\n",
      "\tspeed: 0.0304s/iter; left time: 422.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.0786424 Vali Loss: 0.0913787 Test Loss: 0.0942713\n",
      "Validation loss decreased (0.091495 --> 0.091379).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0774720\n",
      "\tspeed: 0.0569s/iter; left time: 784.5056s\n",
      "\titers: 200, epoch: 39 | loss: 0.0796525\n",
      "\tspeed: 0.0289s/iter; left time: 395.5133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0786279 Vali Loss: 0.0914906 Test Loss: 0.0944082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0796567\n",
      "\tspeed: 0.0608s/iter; left time: 825.3140s\n",
      "\titers: 200, epoch: 40 | loss: 0.0751608\n",
      "\tspeed: 0.0286s/iter; left time: 385.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0786033 Vali Loss: 0.0914780 Test Loss: 0.0943092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0769870\n",
      "\tspeed: 0.0555s/iter; left time: 740.0601s\n",
      "\titers: 200, epoch: 41 | loss: 0.0813113\n",
      "\tspeed: 0.0288s/iter; left time: 380.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0784827 Vali Loss: 0.0914486 Test Loss: 0.0942944\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0794403\n",
      "\tspeed: 0.0567s/iter; left time: 743.7311s\n",
      "\titers: 200, epoch: 42 | loss: 0.0782751\n",
      "\tspeed: 0.0287s/iter; left time: 373.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0785137 Vali Loss: 0.0913237 Test Loss: 0.0942607\n",
      "Validation loss decreased (0.091379 --> 0.091324).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779560\n",
      "\tspeed: 0.0576s/iter; left time: 743.0019s\n",
      "\titers: 200, epoch: 43 | loss: 0.0845664\n",
      "\tspeed: 0.0293s/iter; left time: 375.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0784879 Vali Loss: 0.0914785 Test Loss: 0.0942664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0822297\n",
      "\tspeed: 0.0569s/iter; left time: 720.6046s\n",
      "\titers: 200, epoch: 44 | loss: 0.0795869\n",
      "\tspeed: 0.0287s/iter; left time: 360.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0785786 Vali Loss: 0.0914423 Test Loss: 0.0942898\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0739156\n",
      "\tspeed: 0.0573s/iter; left time: 712.9585s\n",
      "\titers: 200, epoch: 45 | loss: 0.0761787\n",
      "\tspeed: 0.0296s/iter; left time: 365.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0784919 Vali Loss: 0.0914146 Test Loss: 0.0942242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0797371\n",
      "\tspeed: 0.0593s/iter; left time: 725.1748s\n",
      "\titers: 200, epoch: 46 | loss: 0.0745949\n",
      "\tspeed: 0.0319s/iter; left time: 386.3609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.0784322 Vali Loss: 0.0914573 Test Loss: 0.0942517\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0739875\n",
      "\tspeed: 0.0592s/iter; left time: 709.8945s\n",
      "\titers: 200, epoch: 47 | loss: 0.0818133\n",
      "\tspeed: 0.0295s/iter; left time: 351.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0784160 Vali Loss: 0.0912194 Test Loss: 0.0941747\n",
      "Validation loss decreased (0.091324 --> 0.091219).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0760620\n",
      "\tspeed: 0.0581s/iter; left time: 684.2097s\n",
      "\titers: 200, epoch: 48 | loss: 0.0731401\n",
      "\tspeed: 0.0292s/iter; left time: 340.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0784866 Vali Loss: 0.0913309 Test Loss: 0.0942025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0760232\n",
      "\tspeed: 0.0552s/iter; left time: 637.7190s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752932\n",
      "\tspeed: 0.0290s/iter; left time: 331.6963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0784243 Vali Loss: 0.0913212 Test Loss: 0.0942283\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0798270\n",
      "\tspeed: 0.0570s/iter; left time: 645.1495s\n",
      "\titers: 200, epoch: 50 | loss: 0.0796964\n",
      "\tspeed: 0.0297s/iter; left time: 333.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0784274 Vali Loss: 0.0914240 Test Loss: 0.0942281\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0813033\n",
      "\tspeed: 0.0571s/iter; left time: 634.1318s\n",
      "\titers: 200, epoch: 51 | loss: 0.0755573\n",
      "\tspeed: 0.0297s/iter; left time: 327.1146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0784133 Vali Loss: 0.0911658 Test Loss: 0.0942120\n",
      "Validation loss decreased (0.091219 --> 0.091166).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0807837\n",
      "\tspeed: 0.0584s/iter; left time: 635.5716s\n",
      "\titers: 200, epoch: 52 | loss: 0.0820797\n",
      "\tspeed: 0.0289s/iter; left time: 311.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0783855 Vali Loss: 0.0913870 Test Loss: 0.0942003\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0759937\n",
      "\tspeed: 0.0554s/iter; left time: 590.2135s\n",
      "\titers: 200, epoch: 53 | loss: 0.0779143\n",
      "\tspeed: 0.0286s/iter; left time: 301.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0783710 Vali Loss: 0.0914183 Test Loss: 0.0941717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0782573\n",
      "\tspeed: 0.0561s/iter; left time: 585.0690s\n",
      "\titers: 200, epoch: 54 | loss: 0.0784503\n",
      "\tspeed: 0.0291s/iter; left time: 300.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0782528 Vali Loss: 0.0913374 Test Loss: 0.0942184\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0835186\n",
      "\tspeed: 0.0571s/iter; left time: 582.6822s\n",
      "\titers: 200, epoch: 55 | loss: 0.0844612\n",
      "\tspeed: 0.0301s/iter; left time: 304.4249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0783653 Vali Loss: 0.0912595 Test Loss: 0.0941422\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0776263\n",
      "\tspeed: 0.0564s/iter; left time: 562.6101s\n",
      "\titers: 200, epoch: 56 | loss: 0.0812678\n",
      "\tspeed: 0.0288s/iter; left time: 284.6098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0784179 Vali Loss: 0.0915022 Test Loss: 0.0942281\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0828260\n",
      "\tspeed: 0.0559s/iter; left time: 545.0624s\n",
      "\titers: 200, epoch: 57 | loss: 0.0765589\n",
      "\tspeed: 0.0294s/iter; left time: 283.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0783670 Vali Loss: 0.0913202 Test Loss: 0.0941640\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0832659\n",
      "\tspeed: 0.0571s/iter; left time: 544.7606s\n",
      "\titers: 200, epoch: 58 | loss: 0.0807410\n",
      "\tspeed: 0.0293s/iter; left time: 276.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0784922 Vali Loss: 0.0912069 Test Loss: 0.0941296\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0818268\n",
      "\tspeed: 0.0567s/iter; left time: 527.3678s\n",
      "\titers: 200, epoch: 59 | loss: 0.0809891\n",
      "\tspeed: 0.0292s/iter; left time: 268.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0783078 Vali Loss: 0.0913488 Test Loss: 0.0941889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0822840\n",
      "\tspeed: 0.0572s/iter; left time: 519.6455s\n",
      "\titers: 200, epoch: 60 | loss: 0.0795187\n",
      "\tspeed: 0.0293s/iter; left time: 263.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0783106 Vali Loss: 0.0912026 Test Loss: 0.0941443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0804471\n",
      "\tspeed: 0.0590s/iter; left time: 522.4573s\n",
      "\titers: 200, epoch: 61 | loss: 0.0774952\n",
      "\tspeed: 0.0295s/iter; left time: 258.7341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0783807 Vali Loss: 0.0914603 Test Loss: 0.0942371\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02247379533946514, rmse:0.14991262555122375, mae:0.09421197324991226, rse:0.5290623903274536\n",
      "Intermediate time for DE and pred_len 24: 00h:20m:29.58s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3305949\n",
      "\tspeed: 0.0538s/iter; left time: 1200.2638s\n",
      "\titers: 200, epoch: 1 | loss: 0.2956578\n",
      "\tspeed: 0.0290s/iter; left time: 644.4902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.3304898 Vali Loss: 0.2460313 Test Loss: 0.2522872\n",
      "Validation loss decreased (inf --> 0.246031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1738605\n",
      "\tspeed: 0.0571s/iter; left time: 1259.9949s\n",
      "\titers: 200, epoch: 2 | loss: 0.1676649\n",
      "\tspeed: 0.0293s/iter; left time: 644.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1863481 Vali Loss: 0.1649268 Test Loss: 0.1775943\n",
      "Validation loss decreased (0.246031 --> 0.164927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1428607\n",
      "\tspeed: 0.0571s/iter; left time: 1248.8697s\n",
      "\titers: 200, epoch: 3 | loss: 0.1391043\n",
      "\tspeed: 0.0290s/iter; left time: 630.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.1467414 Vali Loss: 0.1448588 Test Loss: 0.1559910\n",
      "Validation loss decreased (0.164927 --> 0.144859).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1298204\n",
      "\tspeed: 0.0602s/iter; left time: 1301.9604s\n",
      "\titers: 200, epoch: 4 | loss: 0.1236297\n",
      "\tspeed: 0.0302s/iter; left time: 650.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.1299367 Vali Loss: 0.1388450 Test Loss: 0.1505615\n",
      "Validation loss decreased (0.144859 --> 0.138845).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1246714\n",
      "\tspeed: 0.0608s/iter; left time: 1301.8211s\n",
      "\titers: 200, epoch: 5 | loss: 0.1221234\n",
      "\tspeed: 0.0290s/iter; left time: 617.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.1215292 Vali Loss: 0.1347570 Test Loss: 0.1447935\n",
      "Validation loss decreased (0.138845 --> 0.134757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116392\n",
      "\tspeed: 0.0611s/iter; left time: 1293.6058s\n",
      "\titers: 200, epoch: 6 | loss: 0.1164589\n",
      "\tspeed: 0.0299s/iter; left time: 630.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1170554 Vali Loss: 0.1323325 Test Loss: 0.1419576\n",
      "Validation loss decreased (0.134757 --> 0.132332).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1179960\n",
      "\tspeed: 0.0606s/iter; left time: 1270.4164s\n",
      "\titers: 200, epoch: 7 | loss: 0.1148745\n",
      "\tspeed: 0.0305s/iter; left time: 636.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1143025 Vali Loss: 0.1329686 Test Loss: 0.1423291\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1147837\n",
      "\tspeed: 0.0587s/iter; left time: 1217.7497s\n",
      "\titers: 200, epoch: 8 | loss: 0.1144873\n",
      "\tspeed: 0.0325s/iter; left time: 670.6763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.1126514 Vali Loss: 0.1288230 Test Loss: 0.1395905\n",
      "Validation loss decreased (0.132332 --> 0.128823).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1133409\n",
      "\tspeed: 0.0593s/iter; left time: 1216.7910s\n",
      "\titers: 200, epoch: 9 | loss: 0.1105448\n",
      "\tspeed: 0.0291s/iter; left time: 593.3884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1108414 Vali Loss: 0.1291419 Test Loss: 0.1410021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033083\n",
      "\tspeed: 0.0577s/iter; left time: 1170.7928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998180\n",
      "\tspeed: 0.0303s/iter; left time: 610.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.1096718 Vali Loss: 0.1295754 Test Loss: 0.1407565\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1091216\n",
      "\tspeed: 0.0593s/iter; left time: 1190.5704s\n",
      "\titers: 200, epoch: 11 | loss: 0.1039226\n",
      "\tspeed: 0.0306s/iter; left time: 611.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1088921 Vali Loss: 0.1282423 Test Loss: 0.1401506\n",
      "Validation loss decreased (0.128823 --> 0.128242).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034938\n",
      "\tspeed: 0.0625s/iter; left time: 1240.6292s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064432\n",
      "\tspeed: 0.0302s/iter; left time: 596.9243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1083104 Vali Loss: 0.1277135 Test Loss: 0.1397114\n",
      "Validation loss decreased (0.128242 --> 0.127714).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1134645\n",
      "\tspeed: 0.0622s/iter; left time: 1219.6970s\n",
      "\titers: 200, epoch: 13 | loss: 0.1068219\n",
      "\tspeed: 0.0311s/iter; left time: 607.5900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.1076771 Vali Loss: 0.1271697 Test Loss: 0.1411984\n",
      "Validation loss decreased (0.127714 --> 0.127170).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1027745\n",
      "\tspeed: 0.0601s/iter; left time: 1165.5227s\n",
      "\titers: 200, epoch: 14 | loss: 0.1024124\n",
      "\tspeed: 0.0301s/iter; left time: 580.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.1070298 Vali Loss: 0.1266795 Test Loss: 0.1409364\n",
      "Validation loss decreased (0.127170 --> 0.126680).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1063156\n",
      "\tspeed: 0.0596s/iter; left time: 1143.0250s\n",
      "\titers: 200, epoch: 15 | loss: 0.1051071\n",
      "\tspeed: 0.0305s/iter; left time: 581.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.1065328 Vali Loss: 0.1270111 Test Loss: 0.1420114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1201266\n",
      "\tspeed: 0.0597s/iter; left time: 1130.4849s\n",
      "\titers: 200, epoch: 16 | loss: 0.1075292\n",
      "\tspeed: 0.0306s/iter; left time: 577.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.1063653 Vali Loss: 0.1267055 Test Loss: 0.1414126\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013357\n",
      "\tspeed: 0.0639s/iter; left time: 1195.7703s\n",
      "\titers: 200, epoch: 17 | loss: 0.1006848\n",
      "\tspeed: 0.0313s/iter; left time: 583.6161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.1056272 Vali Loss: 0.1262707 Test Loss: 0.1414120\n",
      "Validation loss decreased (0.126680 --> 0.126271).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1043863\n",
      "\tspeed: 0.0597s/iter; left time: 1104.5683s\n",
      "\titers: 200, epoch: 18 | loss: 0.1103412\n",
      "\tspeed: 0.0300s/iter; left time: 552.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.1053320 Vali Loss: 0.1252308 Test Loss: 0.1395144\n",
      "Validation loss decreased (0.126271 --> 0.125231).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1047481\n",
      "\tspeed: 0.0600s/iter; left time: 1097.0516s\n",
      "\titers: 200, epoch: 19 | loss: 0.1057975\n",
      "\tspeed: 0.0307s/iter; left time: 557.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.1050644 Vali Loss: 0.1265537 Test Loss: 0.1420747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0998083\n",
      "\tspeed: 0.0595s/iter; left time: 1073.2979s\n",
      "\titers: 200, epoch: 20 | loss: 0.1027103\n",
      "\tspeed: 0.0308s/iter; left time: 552.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.1048490 Vali Loss: 0.1264704 Test Loss: 0.1424879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0986904\n",
      "\tspeed: 0.0604s/iter; left time: 1077.2789s\n",
      "\titers: 200, epoch: 21 | loss: 0.1094459\n",
      "\tspeed: 0.0304s/iter; left time: 539.2450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.1044782 Vali Loss: 0.1257665 Test Loss: 0.1416347\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1062908\n",
      "\tspeed: 0.0606s/iter; left time: 1065.7764s\n",
      "\titers: 200, epoch: 22 | loss: 0.1095122\n",
      "\tspeed: 0.0321s/iter; left time: 560.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.1041887 Vali Loss: 0.1252683 Test Loss: 0.1403740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1047204\n",
      "\tspeed: 0.0593s/iter; left time: 1030.8070s\n",
      "\titers: 200, epoch: 23 | loss: 0.0968408\n",
      "\tspeed: 0.0303s/iter; left time: 523.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1042165 Vali Loss: 0.1258086 Test Loss: 0.1419091\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1004806\n",
      "\tspeed: 0.0587s/iter; left time: 1006.7119s\n",
      "\titers: 200, epoch: 24 | loss: 0.1019825\n",
      "\tspeed: 0.0291s/iter; left time: 495.7525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1038745 Vali Loss: 0.1246254 Test Loss: 0.1394440\n",
      "Validation loss decreased (0.125231 --> 0.124625).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0986058\n",
      "\tspeed: 0.0581s/iter; left time: 982.8303s\n",
      "\titers: 200, epoch: 25 | loss: 0.1010361\n",
      "\tspeed: 0.0291s/iter; left time: 488.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1037508 Vali Loss: 0.1253648 Test Loss: 0.1415321\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1063282\n",
      "\tspeed: 0.0570s/iter; left time: 952.1412s\n",
      "\titers: 200, epoch: 26 | loss: 0.1031707\n",
      "\tspeed: 0.0319s/iter; left time: 528.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1034942 Vali Loss: 0.1260303 Test Loss: 0.1427891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1012552\n",
      "\tspeed: 0.0610s/iter; left time: 1005.2795s\n",
      "\titers: 200, epoch: 27 | loss: 0.1023142\n",
      "\tspeed: 0.0298s/iter; left time: 487.3792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1248434 Test Loss: 0.1407488\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1037954\n",
      "\tspeed: 0.0607s/iter; left time: 987.2325s\n",
      "\titers: 200, epoch: 28 | loss: 0.1057742\n",
      "\tspeed: 0.0331s/iter; left time: 534.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.1032465 Vali Loss: 0.1252263 Test Loss: 0.1409236\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1068487\n",
      "\tspeed: 0.0601s/iter; left time: 963.5629s\n",
      "\titers: 200, epoch: 29 | loss: 0.1071606\n",
      "\tspeed: 0.0313s/iter; left time: 499.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.1031037 Vali Loss: 0.1251372 Test Loss: 0.1404903\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1039845\n",
      "\tspeed: 0.0611s/iter; left time: 965.4933s\n",
      "\titers: 200, epoch: 30 | loss: 0.1037017\n",
      "\tspeed: 0.0313s/iter; left time: 491.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1031620 Vali Loss: 0.1248200 Test Loss: 0.1404025\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1048073\n",
      "\tspeed: 0.0660s/iter; left time: 1028.6314s\n",
      "\titers: 200, epoch: 31 | loss: 0.1018995\n",
      "\tspeed: 0.0315s/iter; left time: 487.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.1029588 Vali Loss: 0.1252552 Test Loss: 0.1411698\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1055704\n",
      "\tspeed: 0.0601s/iter; left time: 922.6335s\n",
      "\titers: 200, epoch: 32 | loss: 0.1082493\n",
      "\tspeed: 0.0311s/iter; left time: 475.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1029279 Vali Loss: 0.1253752 Test Loss: 0.1415430\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1049032\n",
      "\tspeed: 0.0602s/iter; left time: 910.8040s\n",
      "\titers: 200, epoch: 33 | loss: 0.1016272\n",
      "\tspeed: 0.0320s/iter; left time: 481.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.1028579 Vali Loss: 0.1251598 Test Loss: 0.1411043\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1034211\n",
      "\tspeed: 0.0595s/iter; left time: 886.3977s\n",
      "\titers: 200, epoch: 34 | loss: 0.1078069\n",
      "\tspeed: 0.0307s/iter; left time: 453.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.1027081 Vali Loss: 0.1248732 Test Loss: 0.1405568\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04538281261920929, rmse:0.21303242444992065, mae:0.13944394886493683, rse:0.7543908357620239\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3224554\n",
      "\tspeed: 0.0320s/iter; left time: 713.2239s\n",
      "\titers: 200, epoch: 1 | loss: 0.2981138\n",
      "\tspeed: 0.0304s/iter; left time: 675.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.3263071 Vali Loss: 0.2445107 Test Loss: 0.2499729\n",
      "Validation loss decreased (inf --> 0.244511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1794562\n",
      "\tspeed: 0.0621s/iter; left time: 1371.9137s\n",
      "\titers: 200, epoch: 2 | loss: 0.1580360\n",
      "\tspeed: 0.0346s/iter; left time: 760.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.1855789 Vali Loss: 0.1627476 Test Loss: 0.1778333\n",
      "Validation loss decreased (0.244511 --> 0.162748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1401491\n",
      "\tspeed: 0.0606s/iter; left time: 1323.5051s\n",
      "\titers: 200, epoch: 3 | loss: 0.1397219\n",
      "\tspeed: 0.0299s/iter; left time: 650.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.1455555 Vali Loss: 0.1461193 Test Loss: 0.1584970\n",
      "Validation loss decreased (0.162748 --> 0.146119).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1237944\n",
      "\tspeed: 0.0617s/iter; left time: 1333.9726s\n",
      "\titers: 200, epoch: 4 | loss: 0.1226882\n",
      "\tspeed: 0.0300s/iter; left time: 646.5010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1281804 Vali Loss: 0.1364224 Test Loss: 0.1483859\n",
      "Validation loss decreased (0.146119 --> 0.136422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1198295\n",
      "\tspeed: 0.0584s/iter; left time: 1249.0061s\n",
      "\titers: 200, epoch: 5 | loss: 0.1159885\n",
      "\tspeed: 0.0290s/iter; left time: 617.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.1214272 Vali Loss: 0.1320374 Test Loss: 0.1436675\n",
      "Validation loss decreased (0.136422 --> 0.132037).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141220\n",
      "\tspeed: 0.0584s/iter; left time: 1236.2684s\n",
      "\titers: 200, epoch: 6 | loss: 0.1113365\n",
      "\tspeed: 0.0290s/iter; left time: 610.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1174860 Vali Loss: 0.1319915 Test Loss: 0.1418107\n",
      "Validation loss decreased (0.132037 --> 0.131991).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1172603\n",
      "\tspeed: 0.0582s/iter; left time: 1219.8425s\n",
      "\titers: 200, epoch: 7 | loss: 0.1155569\n",
      "\tspeed: 0.0291s/iter; left time: 607.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1151701 Vali Loss: 0.1306499 Test Loss: 0.1411995\n",
      "Validation loss decreased (0.131991 --> 0.130650).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1128436\n",
      "\tspeed: 0.0586s/iter; left time: 1215.5970s\n",
      "\titers: 200, epoch: 8 | loss: 0.1087449\n",
      "\tspeed: 0.0295s/iter; left time: 607.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1136249 Vali Loss: 0.1284028 Test Loss: 0.1395226\n",
      "Validation loss decreased (0.130650 --> 0.128403).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1075512\n",
      "\tspeed: 0.0592s/iter; left time: 1214.5697s\n",
      "\titers: 200, epoch: 9 | loss: 0.1152863\n",
      "\tspeed: 0.0293s/iter; left time: 598.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.1121305 Vali Loss: 0.1274609 Test Loss: 0.1398630\n",
      "Validation loss decreased (0.128403 --> 0.127461).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1074212\n",
      "\tspeed: 0.0610s/iter; left time: 1236.4100s\n",
      "\titers: 200, epoch: 10 | loss: 0.1089275\n",
      "\tspeed: 0.0331s/iter; left time: 667.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.1111810 Vali Loss: 0.1291172 Test Loss: 0.1434133\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1183986\n",
      "\tspeed: 0.0579s/iter; left time: 1160.5694s\n",
      "\titers: 200, epoch: 11 | loss: 0.1110285\n",
      "\tspeed: 0.0290s/iter; left time: 579.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1100468 Vali Loss: 0.1260507 Test Loss: 0.1388908\n",
      "Validation loss decreased (0.127461 --> 0.126051).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1045814\n",
      "\tspeed: 0.0578s/iter; left time: 1146.6119s\n",
      "\titers: 200, epoch: 12 | loss: 0.1034563\n",
      "\tspeed: 0.0294s/iter; left time: 579.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1094202 Vali Loss: 0.1263235 Test Loss: 0.1392787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044768\n",
      "\tspeed: 0.0575s/iter; left time: 1127.8832s\n",
      "\titers: 200, epoch: 13 | loss: 0.1051001\n",
      "\tspeed: 0.0291s/iter; left time: 567.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1087860 Vali Loss: 0.1258646 Test Loss: 0.1388329\n",
      "Validation loss decreased (0.126051 --> 0.125865).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1085352\n",
      "\tspeed: 0.0582s/iter; left time: 1128.3443s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086319\n",
      "\tspeed: 0.0290s/iter; left time: 559.7495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.1082425 Vali Loss: 0.1254978 Test Loss: 0.1386336\n",
      "Validation loss decreased (0.125865 --> 0.125498).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1131735\n",
      "\tspeed: 0.0589s/iter; left time: 1128.2923s\n",
      "\titers: 200, epoch: 15 | loss: 0.1054535\n",
      "\tspeed: 0.0293s/iter; left time: 557.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1077401 Vali Loss: 0.1255376 Test Loss: 0.1367807\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1036887\n",
      "\tspeed: 0.0570s/iter; left time: 1078.8949s\n",
      "\titers: 200, epoch: 16 | loss: 0.1123559\n",
      "\tspeed: 0.0291s/iter; left time: 548.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1075364 Vali Loss: 0.1261575 Test Loss: 0.1377738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1152358\n",
      "\tspeed: 0.0571s/iter; left time: 1069.2321s\n",
      "\titers: 200, epoch: 17 | loss: 0.1115683\n",
      "\tspeed: 0.0305s/iter; left time: 568.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.1071725 Vali Loss: 0.1260942 Test Loss: 0.1377432\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1132442\n",
      "\tspeed: 0.0572s/iter; left time: 1057.1517s\n",
      "\titers: 200, epoch: 18 | loss: 0.1134832\n",
      "\tspeed: 0.0298s/iter; left time: 548.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.1068604 Vali Loss: 0.1261436 Test Loss: 0.1386894\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1067291\n",
      "\tspeed: 0.0572s/iter; left time: 1044.4000s\n",
      "\titers: 200, epoch: 19 | loss: 0.1067691\n",
      "\tspeed: 0.0295s/iter; left time: 536.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1065617 Vali Loss: 0.1273891 Test Loss: 0.1411240\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1103524\n",
      "\tspeed: 0.0617s/iter; left time: 1113.1421s\n",
      "\titers: 200, epoch: 20 | loss: 0.1105463\n",
      "\tspeed: 0.0300s/iter; left time: 539.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.1063776 Vali Loss: 0.1257873 Test Loss: 0.1381523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1044269\n",
      "\tspeed: 0.0581s/iter; left time: 1035.6904s\n",
      "\titers: 200, epoch: 21 | loss: 0.1062752\n",
      "\tspeed: 0.0294s/iter; left time: 521.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1061014 Vali Loss: 0.1253509 Test Loss: 0.1381071\n",
      "Validation loss decreased (0.125498 --> 0.125351).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1101771\n",
      "\tspeed: 0.0584s/iter; left time: 1026.9854s\n",
      "\titers: 200, epoch: 22 | loss: 0.1099546\n",
      "\tspeed: 0.0289s/iter; left time: 506.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1060104 Vali Loss: 0.1256004 Test Loss: 0.1383138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1083830\n",
      "\tspeed: 0.0567s/iter; left time: 985.0108s\n",
      "\titers: 200, epoch: 23 | loss: 0.1053460\n",
      "\tspeed: 0.0290s/iter; left time: 500.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.1057605 Vali Loss: 0.1252669 Test Loss: 0.1380749\n",
      "Validation loss decreased (0.125351 --> 0.125267).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1057874\n",
      "\tspeed: 0.0585s/iter; left time: 1003.5681s\n",
      "\titers: 200, epoch: 24 | loss: 0.1027509\n",
      "\tspeed: 0.0290s/iter; left time: 494.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1055012 Vali Loss: 0.1252397 Test Loss: 0.1375562\n",
      "Validation loss decreased (0.125267 --> 0.125240).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1058676\n",
      "\tspeed: 0.0577s/iter; left time: 976.6365s\n",
      "\titers: 200, epoch: 25 | loss: 0.1062476\n",
      "\tspeed: 0.0290s/iter; left time: 488.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1054022 Vali Loss: 0.1252352 Test Loss: 0.1384698\n",
      "Validation loss decreased (0.125240 --> 0.125235).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1011721\n",
      "\tspeed: 0.0578s/iter; left time: 965.3156s\n",
      "\titers: 200, epoch: 26 | loss: 0.0978252\n",
      "\tspeed: 0.0298s/iter; left time: 495.4777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1053225 Vali Loss: 0.1256555 Test Loss: 0.1392326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1080227\n",
      "\tspeed: 0.0603s/iter; left time: 992.9602s\n",
      "\titers: 200, epoch: 27 | loss: 0.1012826\n",
      "\tspeed: 0.0301s/iter; left time: 492.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.1053132 Vali Loss: 0.1254329 Test Loss: 0.1388854\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1032217\n",
      "\tspeed: 0.0583s/iter; left time: 946.9937s\n",
      "\titers: 200, epoch: 28 | loss: 0.1017100\n",
      "\tspeed: 0.0293s/iter; left time: 473.9077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1050607 Vali Loss: 0.1250675 Test Loss: 0.1382242\n",
      "Validation loss decreased (0.125235 --> 0.125068).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1074437\n",
      "\tspeed: 0.0584s/iter; left time: 935.8139s\n",
      "\titers: 200, epoch: 29 | loss: 0.1022892\n",
      "\tspeed: 0.0288s/iter; left time: 459.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1049521 Vali Loss: 0.1251927 Test Loss: 0.1387393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1097267\n",
      "\tspeed: 0.0572s/iter; left time: 904.4975s\n",
      "\titers: 200, epoch: 30 | loss: 0.0990133\n",
      "\tspeed: 0.0297s/iter; left time: 465.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.1050971 Vali Loss: 0.1251001 Test Loss: 0.1390187\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1007907\n",
      "\tspeed: 0.0573s/iter; left time: 892.4482s\n",
      "\titers: 200, epoch: 31 | loss: 0.1001307\n",
      "\tspeed: 0.0313s/iter; left time: 485.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.1048398 Vali Loss: 0.1247408 Test Loss: 0.1382345\n",
      "Validation loss decreased (0.125068 --> 0.124741).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1035209\n",
      "\tspeed: 0.0585s/iter; left time: 897.9491s\n",
      "\titers: 200, epoch: 32 | loss: 0.0966570\n",
      "\tspeed: 0.0306s/iter; left time: 466.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.1047887 Vali Loss: 0.1256807 Test Loss: 0.1392132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1004742\n",
      "\tspeed: 0.0581s/iter; left time: 878.5163s\n",
      "\titers: 200, epoch: 33 | loss: 0.1049183\n",
      "\tspeed: 0.0289s/iter; left time: 434.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1048257 Vali Loss: 0.1250357 Test Loss: 0.1390245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1046666\n",
      "\tspeed: 0.0576s/iter; left time: 858.3209s\n",
      "\titers: 200, epoch: 34 | loss: 0.1022655\n",
      "\tspeed: 0.0296s/iter; left time: 438.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1047203 Vali Loss: 0.1251924 Test Loss: 0.1387329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1054072\n",
      "\tspeed: 0.0567s/iter; left time: 832.2946s\n",
      "\titers: 200, epoch: 35 | loss: 0.1035120\n",
      "\tspeed: 0.0300s/iter; left time: 437.8606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1045839 Vali Loss: 0.1245248 Test Loss: 0.1377766\n",
      "Validation loss decreased (0.124741 --> 0.124525).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1060840\n",
      "\tspeed: 0.0618s/iter; left time: 894.0560s\n",
      "\titers: 200, epoch: 36 | loss: 0.1090787\n",
      "\tspeed: 0.0306s/iter; left time: 439.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.1045964 Vali Loss: 0.1250447 Test Loss: 0.1386316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1047850\n",
      "\tspeed: 0.0593s/iter; left time: 843.8793s\n",
      "\titers: 200, epoch: 37 | loss: 0.1011718\n",
      "\tspeed: 0.0295s/iter; left time: 417.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.1047085 Vali Loss: 0.1255113 Test Loss: 0.1393885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1014692\n",
      "\tspeed: 0.0585s/iter; left time: 820.0787s\n",
      "\titers: 200, epoch: 38 | loss: 0.1073594\n",
      "\tspeed: 0.0301s/iter; left time: 419.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.1046489 Vali Loss: 0.1252633 Test Loss: 0.1393883\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1111685\n",
      "\tspeed: 0.0599s/iter; left time: 826.4535s\n",
      "\titers: 200, epoch: 39 | loss: 0.1073623\n",
      "\tspeed: 0.0298s/iter; left time: 407.8890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.1045335 Vali Loss: 0.1253718 Test Loss: 0.1392919\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0996836\n",
      "\tspeed: 0.0580s/iter; left time: 786.8617s\n",
      "\titers: 200, epoch: 40 | loss: 0.0975655\n",
      "\tspeed: 0.0291s/iter; left time: 391.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1043758 Vali Loss: 0.1257558 Test Loss: 0.1393315\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0994621\n",
      "\tspeed: 0.0571s/iter; left time: 761.4114s\n",
      "\titers: 200, epoch: 41 | loss: 0.1041790\n",
      "\tspeed: 0.0290s/iter; left time: 383.5863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.1044158 Vali Loss: 0.1256922 Test Loss: 0.1388333\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1032573\n",
      "\tspeed: 0.0571s/iter; left time: 748.4070s\n",
      "\titers: 200, epoch: 42 | loss: 0.0979731\n",
      "\tspeed: 0.0296s/iter; left time: 384.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1044355 Vali Loss: 0.1252869 Test Loss: 0.1390153\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1018896\n",
      "\tspeed: 0.0573s/iter; left time: 738.4788s\n",
      "\titers: 200, epoch: 43 | loss: 0.1085087\n",
      "\tspeed: 0.0292s/iter; left time: 373.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1044237 Vali Loss: 0.1251713 Test Loss: 0.1391593\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1004209\n",
      "\tspeed: 0.0578s/iter; left time: 732.6113s\n",
      "\titers: 200, epoch: 44 | loss: 0.0979312\n",
      "\tspeed: 0.0293s/iter; left time: 367.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1043804 Vali Loss: 0.1251170 Test Loss: 0.1388983\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1128263\n",
      "\tspeed: 0.0574s/iter; left time: 714.6994s\n",
      "\titers: 200, epoch: 45 | loss: 0.1042776\n",
      "\tspeed: 0.0291s/iter; left time: 358.7324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1042954 Vali Loss: 0.1252965 Test Loss: 0.1392953\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043277692049741745, rmse:0.20803290605545044, mae:0.13777662813663483, rse:0.736686646938324\n",
      "Intermediate time for DE and pred_len 96: 00h:11m:56.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3286587\n",
      "\tspeed: 0.0529s/iter; left time: 1175.4720s\n",
      "\titers: 200, epoch: 1 | loss: 0.3013372\n",
      "\tspeed: 0.0297s/iter; left time: 656.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.3286599 Vali Loss: 0.2467528 Test Loss: 0.2530674\n",
      "Validation loss decreased (inf --> 0.246753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1765077\n",
      "\tspeed: 0.0586s/iter; left time: 1288.9297s\n",
      "\titers: 200, epoch: 2 | loss: 0.1638675\n",
      "\tspeed: 0.0295s/iter; left time: 645.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1864189 Vali Loss: 0.1629359 Test Loss: 0.1780014\n",
      "Validation loss decreased (0.246753 --> 0.162936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1551177\n",
      "\tspeed: 0.0583s/iter; left time: 1267.4757s\n",
      "\titers: 200, epoch: 3 | loss: 0.1425488\n",
      "\tspeed: 0.0296s/iter; left time: 640.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1476279 Vali Loss: 0.1472359 Test Loss: 0.1596510\n",
      "Validation loss decreased (0.162936 --> 0.147236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1331133\n",
      "\tspeed: 0.0595s/iter; left time: 1281.5427s\n",
      "\titers: 200, epoch: 4 | loss: 0.1265453\n",
      "\tspeed: 0.0293s/iter; left time: 628.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1320004 Vali Loss: 0.1415179 Test Loss: 0.1524611\n",
      "Validation loss decreased (0.147236 --> 0.141518).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1259447\n",
      "\tspeed: 0.0581s/iter; left time: 1237.7809s\n",
      "\titers: 200, epoch: 5 | loss: 0.1273993\n",
      "\tspeed: 0.0293s/iter; left time: 620.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1262169 Vali Loss: 0.1371331 Test Loss: 0.1511706\n",
      "Validation loss decreased (0.141518 --> 0.137133).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1267060\n",
      "\tspeed: 0.0586s/iter; left time: 1235.0816s\n",
      "\titers: 200, epoch: 6 | loss: 0.1168640\n",
      "\tspeed: 0.0294s/iter; left time: 616.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1231220 Vali Loss: 0.1367026 Test Loss: 0.1504243\n",
      "Validation loss decreased (0.137133 --> 0.136703).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1181977\n",
      "\tspeed: 0.0584s/iter; left time: 1217.4949s\n",
      "\titers: 200, epoch: 7 | loss: 0.1217122\n",
      "\tspeed: 0.0308s/iter; left time: 638.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1201023 Vali Loss: 0.1350890 Test Loss: 0.1480702\n",
      "Validation loss decreased (0.136703 --> 0.135089).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1119177\n",
      "\tspeed: 0.0583s/iter; left time: 1204.2327s\n",
      "\titers: 200, epoch: 8 | loss: 0.1277463\n",
      "\tspeed: 0.0293s/iter; left time: 601.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1180846 Vali Loss: 0.1334483 Test Loss: 0.1455045\n",
      "Validation loss decreased (0.135089 --> 0.133448).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1158057\n",
      "\tspeed: 0.0595s/iter; left time: 1215.5169s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110080\n",
      "\tspeed: 0.0318s/iter; left time: 646.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 223 | Train Loss: 0.1168650 Vali Loss: 0.1351943 Test Loss: 0.1486059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1218441\n",
      "\tspeed: 0.0573s/iter; left time: 1156.9660s\n",
      "\titers: 200, epoch: 10 | loss: 0.1218923\n",
      "\tspeed: 0.0299s/iter; left time: 599.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1157089 Vali Loss: 0.1341855 Test Loss: 0.1481222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1136349\n",
      "\tspeed: 0.0583s/iter; left time: 1164.0872s\n",
      "\titers: 200, epoch: 11 | loss: 0.1178679\n",
      "\tspeed: 0.0292s/iter; left time: 581.2174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1147224 Vali Loss: 0.1333909 Test Loss: 0.1478128\n",
      "Validation loss decreased (0.133448 --> 0.133391).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1089779\n",
      "\tspeed: 0.0603s/iter; left time: 1190.6875s\n",
      "\titers: 200, epoch: 12 | loss: 0.1130720\n",
      "\tspeed: 0.0299s/iter; left time: 586.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 223 | Train Loss: 0.1141470 Vali Loss: 0.1320217 Test Loss: 0.1457483\n",
      "Validation loss decreased (0.133391 --> 0.132022).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1091995\n",
      "\tspeed: 0.0579s/iter; left time: 1129.7938s\n",
      "\titers: 200, epoch: 13 | loss: 0.1105160\n",
      "\tspeed: 0.0300s/iter; left time: 583.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.1132571 Vali Loss: 0.1329884 Test Loss: 0.1476688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1213825\n",
      "\tspeed: 0.0579s/iter; left time: 1117.8031s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086435\n",
      "\tspeed: 0.0296s/iter; left time: 568.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1129378 Vali Loss: 0.1322988 Test Loss: 0.1477441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1101832\n",
      "\tspeed: 0.0602s/iter; left time: 1148.5829s\n",
      "\titers: 200, epoch: 15 | loss: 0.1128385\n",
      "\tspeed: 0.0294s/iter; left time: 558.2701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.1123634 Vali Loss: 0.1319943 Test Loss: 0.1473603\n",
      "Validation loss decreased (0.132022 --> 0.131994).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1071931\n",
      "\tspeed: 0.0599s/iter; left time: 1128.8265s\n",
      "\titers: 200, epoch: 16 | loss: 0.1116006\n",
      "\tspeed: 0.0312s/iter; left time: 584.3480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.1118787 Vali Loss: 0.1312458 Test Loss: 0.1476277\n",
      "Validation loss decreased (0.131994 --> 0.131246).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1146794\n",
      "\tspeed: 0.0590s/iter; left time: 1098.9465s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118371\n",
      "\tspeed: 0.0300s/iter; left time: 555.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1114189 Vali Loss: 0.1309584 Test Loss: 0.1475634\n",
      "Validation loss decreased (0.131246 --> 0.130958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1184363\n",
      "\tspeed: 0.0595s/iter; left time: 1094.7100s\n",
      "\titers: 200, epoch: 18 | loss: 0.1055574\n",
      "\tspeed: 0.0312s/iter; left time: 570.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 223 | Train Loss: 0.1112526 Vali Loss: 0.1306421 Test Loss: 0.1476581\n",
      "Validation loss decreased (0.130958 --> 0.130642).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1138625\n",
      "\tspeed: 0.0612s/iter; left time: 1113.8216s\n",
      "\titers: 200, epoch: 19 | loss: 0.1111660\n",
      "\tspeed: 0.0302s/iter; left time: 547.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.1107028 Vali Loss: 0.1304632 Test Loss: 0.1480525\n",
      "Validation loss decreased (0.130642 --> 0.130463).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1142451\n",
      "\tspeed: 0.0600s/iter; left time: 1077.6449s\n",
      "\titers: 200, epoch: 20 | loss: 0.1087447\n",
      "\tspeed: 0.0315s/iter; left time: 562.1372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 223 | Train Loss: 0.1103219 Vali Loss: 0.1294829 Test Loss: 0.1470253\n",
      "Validation loss decreased (0.130463 --> 0.129483).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1139536\n",
      "\tspeed: 0.0578s/iter; left time: 1025.5550s\n",
      "\titers: 200, epoch: 21 | loss: 0.1169248\n",
      "\tspeed: 0.0294s/iter; left time: 518.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1102235 Vali Loss: 0.1295167 Test Loss: 0.1474698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1054608\n",
      "\tspeed: 0.0573s/iter; left time: 1003.8168s\n",
      "\titers: 200, epoch: 22 | loss: 0.1058641\n",
      "\tspeed: 0.0302s/iter; left time: 526.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1099358 Vali Loss: 0.1303407 Test Loss: 0.1477566\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1119373\n",
      "\tspeed: 0.0572s/iter; left time: 988.7323s\n",
      "\titers: 200, epoch: 23 | loss: 0.1078318\n",
      "\tspeed: 0.0293s/iter; left time: 503.8326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1097336 Vali Loss: 0.1303999 Test Loss: 0.1482848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1123584\n",
      "\tspeed: 0.0572s/iter; left time: 976.3113s\n",
      "\titers: 200, epoch: 24 | loss: 0.1070724\n",
      "\tspeed: 0.0293s/iter; left time: 498.0361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1096773 Vali Loss: 0.1300207 Test Loss: 0.1482256\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1098245\n",
      "\tspeed: 0.0577s/iter; left time: 972.4866s\n",
      "\titers: 200, epoch: 25 | loss: 0.1099904\n",
      "\tspeed: 0.0294s/iter; left time: 492.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.1093252 Vali Loss: 0.1299023 Test Loss: 0.1470739\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1120614\n",
      "\tspeed: 0.0571s/iter; left time: 949.1462s\n",
      "\titers: 200, epoch: 26 | loss: 0.1132187\n",
      "\tspeed: 0.0293s/iter; left time: 484.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1091507 Vali Loss: 0.1300531 Test Loss: 0.1476686\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1064530\n",
      "\tspeed: 0.0590s/iter; left time: 968.3952s\n",
      "\titers: 200, epoch: 27 | loss: 0.1033797\n",
      "\tspeed: 0.0296s/iter; left time: 481.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.1090801 Vali Loss: 0.1300323 Test Loss: 0.1477532\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1067604\n",
      "\tspeed: 0.0579s/iter; left time: 937.4053s\n",
      "\titers: 200, epoch: 28 | loss: 0.1014157\n",
      "\tspeed: 0.0294s/iter; left time: 472.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1089177 Vali Loss: 0.1301284 Test Loss: 0.1483501\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1093299\n",
      "\tspeed: 0.0606s/iter; left time: 967.6642s\n",
      "\titers: 200, epoch: 29 | loss: 0.1067027\n",
      "\tspeed: 0.0299s/iter; left time: 473.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.1087491 Vali Loss: 0.1296382 Test Loss: 0.1472486\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1043644\n",
      "\tspeed: 0.0580s/iter; left time: 913.2744s\n",
      "\titers: 200, epoch: 30 | loss: 0.1142804\n",
      "\tspeed: 0.0293s/iter; left time: 458.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1087610 Vali Loss: 0.1296341 Test Loss: 0.1470364\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048888467252254486, rmse:0.2211073637008667, mae:0.14702542126178741, rse:0.7831800580024719\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3327255\n",
      "\tspeed: 0.0357s/iter; left time: 793.1652s\n",
      "\titers: 200, epoch: 1 | loss: 0.3020386\n",
      "\tspeed: 0.0331s/iter; left time: 732.4478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 223 | Train Loss: 0.3321167 Vali Loss: 0.2488649 Test Loss: 0.2547693\n",
      "Validation loss decreased (inf --> 0.248865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1762168\n",
      "\tspeed: 0.0594s/iter; left time: 1304.8145s\n",
      "\titers: 200, epoch: 2 | loss: 0.1585836\n",
      "\tspeed: 0.0292s/iter; left time: 638.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.1889159 Vali Loss: 0.1667992 Test Loss: 0.1821981\n",
      "Validation loss decreased (0.248865 --> 0.166799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1563257\n",
      "\tspeed: 0.0593s/iter; left time: 1289.1851s\n",
      "\titers: 200, epoch: 3 | loss: 0.1382369\n",
      "\tspeed: 0.0303s/iter; left time: 656.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.1488295 Vali Loss: 0.1484541 Test Loss: 0.1635070\n",
      "Validation loss decreased (0.166799 --> 0.148454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1326792\n",
      "\tspeed: 0.0598s/iter; left time: 1288.1560s\n",
      "\titers: 200, epoch: 4 | loss: 0.1249975\n",
      "\tspeed: 0.0294s/iter; left time: 630.2988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1314444 Vali Loss: 0.1393123 Test Loss: 0.1538107\n",
      "Validation loss decreased (0.148454 --> 0.139312).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1271538\n",
      "\tspeed: 0.0589s/iter; left time: 1255.2191s\n",
      "\titers: 200, epoch: 5 | loss: 0.1285745\n",
      "\tspeed: 0.0293s/iter; left time: 621.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1254290 Vali Loss: 0.1343531 Test Loss: 0.1503835\n",
      "Validation loss decreased (0.139312 --> 0.134353).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1243152\n",
      "\tspeed: 0.0615s/iter; left time: 1296.5649s\n",
      "\titers: 200, epoch: 6 | loss: 0.1254354\n",
      "\tspeed: 0.0309s/iter; left time: 648.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.1218656 Vali Loss: 0.1310072 Test Loss: 0.1445176\n",
      "Validation loss decreased (0.134353 --> 0.131007).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1180425\n",
      "\tspeed: 0.0647s/iter; left time: 1349.5510s\n",
      "\titers: 200, epoch: 7 | loss: 0.1270047\n",
      "\tspeed: 0.0294s/iter; left time: 609.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.1197627 Vali Loss: 0.1303283 Test Loss: 0.1448032\n",
      "Validation loss decreased (0.131007 --> 0.130328).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1216759\n",
      "\tspeed: 0.0623s/iter; left time: 1286.4434s\n",
      "\titers: 200, epoch: 8 | loss: 0.1195669\n",
      "\tspeed: 0.0294s/iter; left time: 603.6296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1176506 Vali Loss: 0.1303832 Test Loss: 0.1435189\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1156762\n",
      "\tspeed: 0.0592s/iter; left time: 1208.5831s\n",
      "\titers: 200, epoch: 9 | loss: 0.1144825\n",
      "\tspeed: 0.0320s/iter; left time: 650.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.1166174 Vali Loss: 0.1328702 Test Loss: 0.1459943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1176370\n",
      "\tspeed: 0.0637s/iter; left time: 1285.7168s\n",
      "\titers: 200, epoch: 10 | loss: 0.1130593\n",
      "\tspeed: 0.0297s/iter; left time: 597.7486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 223 | Train Loss: 0.1153662 Vali Loss: 0.1321610 Test Loss: 0.1449635\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1182751\n",
      "\tspeed: 0.0585s/iter; left time: 1168.1734s\n",
      "\titers: 200, epoch: 11 | loss: 0.1167127\n",
      "\tspeed: 0.0293s/iter; left time: 581.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1146640 Vali Loss: 0.1327440 Test Loss: 0.1445860\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1158619\n",
      "\tspeed: 0.0581s/iter; left time: 1148.1340s\n",
      "\titers: 200, epoch: 12 | loss: 0.1147262\n",
      "\tspeed: 0.0297s/iter; left time: 582.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1138721 Vali Loss: 0.1311277 Test Loss: 0.1441655\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1146035\n",
      "\tspeed: 0.0592s/iter; left time: 1156.2000s\n",
      "\titers: 200, epoch: 13 | loss: 0.1128461\n",
      "\tspeed: 0.0318s/iter; left time: 618.6476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.1133188 Vali Loss: 0.1312173 Test Loss: 0.1433412\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1097982\n",
      "\tspeed: 0.0587s/iter; left time: 1132.9931s\n",
      "\titers: 200, epoch: 14 | loss: 0.1126129\n",
      "\tspeed: 0.0294s/iter; left time: 565.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1126954 Vali Loss: 0.1315785 Test Loss: 0.1452215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1129119\n",
      "\tspeed: 0.0578s/iter; left time: 1103.6402s\n",
      "\titers: 200, epoch: 15 | loss: 0.1127030\n",
      "\tspeed: 0.0294s/iter; left time: 557.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1123828 Vali Loss: 0.1311950 Test Loss: 0.1444761\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1100847\n",
      "\tspeed: 0.0583s/iter; left time: 1099.8973s\n",
      "\titers: 200, epoch: 16 | loss: 0.1127317\n",
      "\tspeed: 0.0293s/iter; left time: 550.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1120580 Vali Loss: 0.1307951 Test Loss: 0.1444008\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1087146\n",
      "\tspeed: 0.0578s/iter; left time: 1077.5013s\n",
      "\titers: 200, epoch: 17 | loss: 0.1172526\n",
      "\tspeed: 0.0294s/iter; left time: 545.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1114760 Vali Loss: 0.1310233 Test Loss: 0.1455398\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0433492511510849, rmse:0.20820483565330505, mae:0.14480328559875488, rse:0.7374782562255859\n",
      "Intermediate time for DE and pred_len 168: 00h:07m:11.96s\n",
      "Intermediate time for DE: 00h:39m:38.51s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3239528\n",
      "\tspeed: 0.0534s/iter; left time: 1189.7781s\n",
      "\titers: 200, epoch: 1 | loss: 0.3033940\n",
      "\tspeed: 0.0287s/iter; left time: 637.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.3316580 Vali Loss: 0.2575737 Test Loss: 0.2757833\n",
      "Validation loss decreased (inf --> 0.257574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1560647\n",
      "\tspeed: 0.0556s/iter; left time: 1226.5819s\n",
      "\titers: 200, epoch: 2 | loss: 0.1330305\n",
      "\tspeed: 0.0287s/iter; left time: 629.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.1746304 Vali Loss: 0.1365823 Test Loss: 0.1545957\n",
      "Validation loss decreased (0.257574 --> 0.136582).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217884\n",
      "\tspeed: 0.0565s/iter; left time: 1233.8740s\n",
      "\titers: 200, epoch: 3 | loss: 0.1226198\n",
      "\tspeed: 0.0302s/iter; left time: 656.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1249406 Vali Loss: 0.1276880 Test Loss: 0.1422693\n",
      "Validation loss decreased (0.136582 --> 0.127688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1207634\n",
      "\tspeed: 0.0561s/iter; left time: 1213.1559s\n",
      "\titers: 200, epoch: 4 | loss: 0.1144840\n",
      "\tspeed: 0.0292s/iter; left time: 628.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.1158130 Vali Loss: 0.1153170 Test Loss: 0.1286238\n",
      "Validation loss decreased (0.127688 --> 0.115317).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1052632\n",
      "\tspeed: 0.0577s/iter; left time: 1235.5341s\n",
      "\titers: 200, epoch: 5 | loss: 0.1034931\n",
      "\tspeed: 0.0300s/iter; left time: 639.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.1032673 Vali Loss: 0.1062338 Test Loss: 0.1240031\n",
      "Validation loss decreased (0.115317 --> 0.106234).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0983069\n",
      "\tspeed: 0.0566s/iter; left time: 1198.1043s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024979\n",
      "\tspeed: 0.0292s/iter; left time: 614.7480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0980320 Vali Loss: 0.1041580 Test Loss: 0.1207242\n",
      "Validation loss decreased (0.106234 --> 0.104158).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0965420\n",
      "\tspeed: 0.0569s/iter; left time: 1193.4363s\n",
      "\titers: 200, epoch: 7 | loss: 0.0939151\n",
      "\tspeed: 0.0292s/iter; left time: 609.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0953881 Vali Loss: 0.1014206 Test Loss: 0.1178902\n",
      "Validation loss decreased (0.104158 --> 0.101421).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0975644\n",
      "\tspeed: 0.0583s/iter; left time: 1208.8058s\n",
      "\titers: 200, epoch: 8 | loss: 0.1016343\n",
      "\tspeed: 0.0313s/iter; left time: 645.0812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.0935245 Vali Loss: 0.1007923 Test Loss: 0.1176121\n",
      "Validation loss decreased (0.101421 --> 0.100792).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0902932\n",
      "\tspeed: 0.0584s/iter; left time: 1198.4020s\n",
      "\titers: 200, epoch: 9 | loss: 0.0904424\n",
      "\tspeed: 0.0294s/iter; left time: 600.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0924001 Vali Loss: 0.1006797 Test Loss: 0.1164299\n",
      "Validation loss decreased (0.100792 --> 0.100680).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0965946\n",
      "\tspeed: 0.0570s/iter; left time: 1156.6777s\n",
      "\titers: 200, epoch: 10 | loss: 0.0888032\n",
      "\tspeed: 0.0291s/iter; left time: 587.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0911065 Vali Loss: 0.0995127 Test Loss: 0.1151111\n",
      "Validation loss decreased (0.100680 --> 0.099513).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0901263\n",
      "\tspeed: 0.0566s/iter; left time: 1134.6670s\n",
      "\titers: 200, epoch: 11 | loss: 0.0959461\n",
      "\tspeed: 0.0288s/iter; left time: 574.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0899971 Vali Loss: 0.0993530 Test Loss: 0.1157064\n",
      "Validation loss decreased (0.099513 --> 0.099353).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0930362\n",
      "\tspeed: 0.0559s/iter; left time: 1109.7355s\n",
      "\titers: 200, epoch: 12 | loss: 0.0857455\n",
      "\tspeed: 0.0294s/iter; left time: 581.1688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0890770 Vali Loss: 0.0977133 Test Loss: 0.1146280\n",
      "Validation loss decreased (0.099353 --> 0.097713).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858697\n",
      "\tspeed: 0.0563s/iter; left time: 1104.4771s\n",
      "\titers: 200, epoch: 13 | loss: 0.0877948\n",
      "\tspeed: 0.0293s/iter; left time: 572.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0881250 Vali Loss: 0.0980751 Test Loss: 0.1147111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0851261\n",
      "\tspeed: 0.0563s/iter; left time: 1091.7407s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844360\n",
      "\tspeed: 0.0287s/iter; left time: 553.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0869829 Vali Loss: 0.0969597 Test Loss: 0.1132574\n",
      "Validation loss decreased (0.097713 --> 0.096960).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831320\n",
      "\tspeed: 0.0572s/iter; left time: 1096.6352s\n",
      "\titers: 200, epoch: 15 | loss: 0.0848908\n",
      "\tspeed: 0.0300s/iter; left time: 572.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0860614 Vali Loss: 0.0959674 Test Loss: 0.1132786\n",
      "Validation loss decreased (0.096960 --> 0.095967).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0827185\n",
      "\tspeed: 0.0630s/iter; left time: 1193.5578s\n",
      "\titers: 200, epoch: 16 | loss: 0.0866139\n",
      "\tspeed: 0.0288s/iter; left time: 543.0482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 224 | Train Loss: 0.0854626 Vali Loss: 0.0950077 Test Loss: 0.1113449\n",
      "Validation loss decreased (0.095967 --> 0.095008).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0817979\n",
      "\tspeed: 0.0562s/iter; left time: 1051.5146s\n",
      "\titers: 200, epoch: 17 | loss: 0.0858268\n",
      "\tspeed: 0.0294s/iter; left time: 547.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0846109 Vali Loss: 0.0947485 Test Loss: 0.1113595\n",
      "Validation loss decreased (0.095008 --> 0.094749).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0800059\n",
      "\tspeed: 0.0573s/iter; left time: 1060.3350s\n",
      "\titers: 200, epoch: 18 | loss: 0.0814329\n",
      "\tspeed: 0.0286s/iter; left time: 526.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0837961 Vali Loss: 0.0942703 Test Loss: 0.1104814\n",
      "Validation loss decreased (0.094749 --> 0.094270).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0824048\n",
      "\tspeed: 0.0597s/iter; left time: 1090.5185s\n",
      "\titers: 200, epoch: 19 | loss: 0.0877841\n",
      "\tspeed: 0.0323s/iter; left time: 587.3749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0834405 Vali Loss: 0.0939164 Test Loss: 0.1100721\n",
      "Validation loss decreased (0.094270 --> 0.093916).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0759753\n",
      "\tspeed: 0.0578s/iter; left time: 1043.1462s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791688\n",
      "\tspeed: 0.0292s/iter; left time: 524.4648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0830391 Vali Loss: 0.0946813 Test Loss: 0.1106669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0792025\n",
      "\tspeed: 0.0586s/iter; left time: 1044.2678s\n",
      "\titers: 200, epoch: 21 | loss: 0.0808684\n",
      "\tspeed: 0.0291s/iter; left time: 515.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0824888 Vali Loss: 0.0936953 Test Loss: 0.1099965\n",
      "Validation loss decreased (0.093916 --> 0.093695).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856975\n",
      "\tspeed: 0.0562s/iter; left time: 988.8696s\n",
      "\titers: 200, epoch: 22 | loss: 0.0786591\n",
      "\tspeed: 0.0287s/iter; left time: 501.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0821248 Vali Loss: 0.0934862 Test Loss: 0.1092233\n",
      "Validation loss decreased (0.093695 --> 0.093486).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0806319\n",
      "\tspeed: 0.0560s/iter; left time: 972.6743s\n",
      "\titers: 200, epoch: 23 | loss: 0.0823780\n",
      "\tspeed: 0.0287s/iter; left time: 495.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0818797 Vali Loss: 0.0935497 Test Loss: 0.1097693\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0824846\n",
      "\tspeed: 0.0555s/iter; left time: 951.6811s\n",
      "\titers: 200, epoch: 24 | loss: 0.0784463\n",
      "\tspeed: 0.0287s/iter; left time: 488.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0816532 Vali Loss: 0.0932439 Test Loss: 0.1093121\n",
      "Validation loss decreased (0.093486 --> 0.093244).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786119\n",
      "\tspeed: 0.0563s/iter; left time: 953.2062s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782363\n",
      "\tspeed: 0.0298s/iter; left time: 501.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0814535 Vali Loss: 0.0932810 Test Loss: 0.1092575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0787470\n",
      "\tspeed: 0.0569s/iter; left time: 949.6867s\n",
      "\titers: 200, epoch: 26 | loss: 0.0767306\n",
      "\tspeed: 0.0287s/iter; left time: 476.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0812874 Vali Loss: 0.0930413 Test Loss: 0.1087349\n",
      "Validation loss decreased (0.093244 --> 0.093041).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0812807\n",
      "\tspeed: 0.0576s/iter; left time: 948.3694s\n",
      "\titers: 200, epoch: 27 | loss: 0.0834414\n",
      "\tspeed: 0.0287s/iter; left time: 469.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0812518 Vali Loss: 0.0929233 Test Loss: 0.1086980\n",
      "Validation loss decreased (0.093041 --> 0.092923).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0816006\n",
      "\tspeed: 0.0577s/iter; left time: 938.3706s\n",
      "\titers: 200, epoch: 28 | loss: 0.0834640\n",
      "\tspeed: 0.0299s/iter; left time: 483.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0809229 Vali Loss: 0.0930010 Test Loss: 0.1085276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803625\n",
      "\tspeed: 0.0555s/iter; left time: 889.6435s\n",
      "\titers: 200, epoch: 29 | loss: 0.0809778\n",
      "\tspeed: 0.0287s/iter; left time: 457.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0808659 Vali Loss: 0.0930029 Test Loss: 0.1085462\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0782444\n",
      "\tspeed: 0.0550s/iter; left time: 869.9853s\n",
      "\titers: 200, epoch: 30 | loss: 0.0807780\n",
      "\tspeed: 0.0287s/iter; left time: 450.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0806950 Vali Loss: 0.0930697 Test Loss: 0.1087757\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0890979\n",
      "\tspeed: 0.0561s/iter; left time: 874.8515s\n",
      "\titers: 200, epoch: 31 | loss: 0.0821110\n",
      "\tspeed: 0.0286s/iter; left time: 443.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0805931 Vali Loss: 0.0931258 Test Loss: 0.1090017\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0796598\n",
      "\tspeed: 0.0552s/iter; left time: 848.3958s\n",
      "\titers: 200, epoch: 32 | loss: 0.0755581\n",
      "\tspeed: 0.0286s/iter; left time: 436.9567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0806266 Vali Loss: 0.0929877 Test Loss: 0.1085617\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0742449\n",
      "\tspeed: 0.0555s/iter; left time: 839.4462s\n",
      "\titers: 200, epoch: 33 | loss: 0.0789989\n",
      "\tspeed: 0.0291s/iter; left time: 437.0698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0805983 Vali Loss: 0.0928528 Test Loss: 0.1085464\n",
      "Validation loss decreased (0.092923 --> 0.092853).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0848028\n",
      "\tspeed: 0.0568s/iter; left time: 847.2175s\n",
      "\titers: 200, epoch: 34 | loss: 0.0816094\n",
      "\tspeed: 0.0297s/iter; left time: 439.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0804276 Vali Loss: 0.0932469 Test Loss: 0.1088341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0786597\n",
      "\tspeed: 0.0582s/iter; left time: 854.8984s\n",
      "\titers: 200, epoch: 35 | loss: 0.0817259\n",
      "\tspeed: 0.0297s/iter; left time: 433.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0803255 Vali Loss: 0.0927445 Test Loss: 0.1084905\n",
      "Validation loss decreased (0.092853 --> 0.092745).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0808103\n",
      "\tspeed: 0.0570s/iter; left time: 823.7869s\n",
      "\titers: 200, epoch: 36 | loss: 0.0811571\n",
      "\tspeed: 0.0298s/iter; left time: 428.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0803719 Vali Loss: 0.0929579 Test Loss: 0.1086671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0770571\n",
      "\tspeed: 0.0549s/iter; left time: 781.0918s\n",
      "\titers: 200, epoch: 37 | loss: 0.0823175\n",
      "\tspeed: 0.0286s/iter; left time: 404.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0803223 Vali Loss: 0.0930986 Test Loss: 0.1088875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0843690\n",
      "\tspeed: 0.0565s/iter; left time: 792.1118s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797447\n",
      "\tspeed: 0.0301s/iter; left time: 419.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0802271 Vali Loss: 0.0932068 Test Loss: 0.1089870\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0793186\n",
      "\tspeed: 0.0558s/iter; left time: 769.7972s\n",
      "\titers: 200, epoch: 39 | loss: 0.0823099\n",
      "\tspeed: 0.0289s/iter; left time: 395.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0801944 Vali Loss: 0.0927329 Test Loss: 0.1086690\n",
      "Validation loss decreased (0.092745 --> 0.092733).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0819004\n",
      "\tspeed: 0.0605s/iter; left time: 820.7408s\n",
      "\titers: 200, epoch: 40 | loss: 0.0830656\n",
      "\tspeed: 0.0297s/iter; left time: 400.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0801254 Vali Loss: 0.0928609 Test Loss: 0.1085986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0793256\n",
      "\tspeed: 0.0569s/iter; left time: 758.6905s\n",
      "\titers: 200, epoch: 41 | loss: 0.0762594\n",
      "\tspeed: 0.0286s/iter; left time: 378.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0802174 Vali Loss: 0.0927160 Test Loss: 0.1085075\n",
      "Validation loss decreased (0.092733 --> 0.092716).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0775574\n",
      "\tspeed: 0.0562s/iter; left time: 737.4969s\n",
      "\titers: 200, epoch: 42 | loss: 0.0814024\n",
      "\tspeed: 0.0294s/iter; left time: 382.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0800981 Vali Loss: 0.0928974 Test Loss: 0.1088918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0746477\n",
      "\tspeed: 0.0566s/iter; left time: 729.4783s\n",
      "\titers: 200, epoch: 43 | loss: 0.0761202\n",
      "\tspeed: 0.0287s/iter; left time: 367.5860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0800979 Vali Loss: 0.0928437 Test Loss: 0.1086506\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0831775\n",
      "\tspeed: 0.0556s/iter; left time: 704.8401s\n",
      "\titers: 200, epoch: 44 | loss: 0.0782759\n",
      "\tspeed: 0.0291s/iter; left time: 366.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0800617 Vali Loss: 0.0927473 Test Loss: 0.1087299\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0780115\n",
      "\tspeed: 0.0565s/iter; left time: 703.2683s\n",
      "\titers: 200, epoch: 45 | loss: 0.0770496\n",
      "\tspeed: 0.0286s/iter; left time: 353.6350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0800761 Vali Loss: 0.0929547 Test Loss: 0.1087985\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0846081\n",
      "\tspeed: 0.0572s/iter; left time: 699.5802s\n",
      "\titers: 200, epoch: 46 | loss: 0.0881581\n",
      "\tspeed: 0.0287s/iter; left time: 347.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0800979 Vali Loss: 0.0928747 Test Loss: 0.1085843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0773510\n",
      "\tspeed: 0.0563s/iter; left time: 675.8557s\n",
      "\titers: 200, epoch: 47 | loss: 0.0814494\n",
      "\tspeed: 0.0317s/iter; left time: 376.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0800305 Vali Loss: 0.0929528 Test Loss: 0.1088206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0804286\n",
      "\tspeed: 0.0561s/iter; left time: 660.6826s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714823\n",
      "\tspeed: 0.0287s/iter; left time: 334.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0800075 Vali Loss: 0.0926794 Test Loss: 0.1086497\n",
      "Validation loss decreased (0.092716 --> 0.092679).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0863876\n",
      "\tspeed: 0.0558s/iter; left time: 644.7889s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801173\n",
      "\tspeed: 0.0291s/iter; left time: 333.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0800099 Vali Loss: 0.0928596 Test Loss: 0.1086669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0781009\n",
      "\tspeed: 0.0556s/iter; left time: 630.1050s\n",
      "\titers: 200, epoch: 50 | loss: 0.0772324\n",
      "\tspeed: 0.0287s/iter; left time: 322.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0798935 Vali Loss: 0.0927466 Test Loss: 0.1086321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0793383\n",
      "\tspeed: 0.0559s/iter; left time: 620.3312s\n",
      "\titers: 200, epoch: 51 | loss: 0.0759275\n",
      "\tspeed: 0.0287s/iter; left time: 316.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0800235 Vali Loss: 0.0927293 Test Loss: 0.1085476\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0810493\n",
      "\tspeed: 0.0549s/iter; left time: 596.6448s\n",
      "\titers: 200, epoch: 52 | loss: 0.0863074\n",
      "\tspeed: 0.0288s/iter; left time: 310.0627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0800368 Vali Loss: 0.0927134 Test Loss: 0.1084671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0823274\n",
      "\tspeed: 0.0554s/iter; left time: 590.4036s\n",
      "\titers: 200, epoch: 53 | loss: 0.0788453\n",
      "\tspeed: 0.0288s/iter; left time: 303.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0799516 Vali Loss: 0.0925654 Test Loss: 0.1085818\n",
      "Validation loss decreased (0.092679 --> 0.092565).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0833528\n",
      "\tspeed: 0.0565s/iter; left time: 588.9999s\n",
      "\titers: 200, epoch: 54 | loss: 0.0835625\n",
      "\tspeed: 0.0289s/iter; left time: 298.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0798931 Vali Loss: 0.0927547 Test Loss: 0.1085907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0851872\n",
      "\tspeed: 0.0564s/iter; left time: 575.9271s\n",
      "\titers: 200, epoch: 55 | loss: 0.0826894\n",
      "\tspeed: 0.0287s/iter; left time: 290.2507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0799581 Vali Loss: 0.0927194 Test Loss: 0.1086591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0783015\n",
      "\tspeed: 0.0556s/iter; left time: 554.6473s\n",
      "\titers: 200, epoch: 56 | loss: 0.0797585\n",
      "\tspeed: 0.0300s/iter; left time: 296.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0799575 Vali Loss: 0.0927757 Test Loss: 0.1085013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0775262\n",
      "\tspeed: 0.0570s/iter; left time: 556.0750s\n",
      "\titers: 200, epoch: 57 | loss: 0.0823427\n",
      "\tspeed: 0.0287s/iter; left time: 277.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0799517 Vali Loss: 0.0930441 Test Loss: 0.1088273\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0770157\n",
      "\tspeed: 0.0557s/iter; left time: 531.1258s\n",
      "\titers: 200, epoch: 58 | loss: 0.0836321\n",
      "\tspeed: 0.0287s/iter; left time: 271.0788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0798659 Vali Loss: 0.0927382 Test Loss: 0.1085631\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0782911\n",
      "\tspeed: 0.0586s/iter; left time: 545.7779s\n",
      "\titers: 200, epoch: 59 | loss: 0.0782339\n",
      "\tspeed: 0.0292s/iter; left time: 269.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0800039 Vali Loss: 0.0927269 Test Loss: 0.1084282\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0794966\n",
      "\tspeed: 0.0575s/iter; left time: 521.9814s\n",
      "\titers: 200, epoch: 60 | loss: 0.0778139\n",
      "\tspeed: 0.0300s/iter; left time: 269.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0799143 Vali Loss: 0.0926843 Test Loss: 0.1085843\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0825032\n",
      "\tspeed: 0.0570s/iter; left time: 505.0646s\n",
      "\titers: 200, epoch: 61 | loss: 0.0771433\n",
      "\tspeed: 0.0288s/iter; left time: 252.2227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0799517 Vali Loss: 0.0927955 Test Loss: 0.1085061\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0765790\n",
      "\tspeed: 0.0589s/iter; left time: 508.5466s\n",
      "\titers: 200, epoch: 62 | loss: 0.0823909\n",
      "\tspeed: 0.0287s/iter; left time: 244.6578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0798910 Vali Loss: 0.0926980 Test Loss: 0.1085109\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0791849\n",
      "\tspeed: 0.0593s/iter; left time: 499.2161s\n",
      "\titers: 200, epoch: 63 | loss: 0.0833274\n",
      "\tspeed: 0.0311s/iter; left time: 258.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.0798959 Vali Loss: 0.0925926 Test Loss: 0.1085356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02795548364520073, rmse:0.16719894111156464, mae:0.10858175158500671, rse:0.5767889022827148\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3263546\n",
      "\tspeed: 0.0321s/iter; left time: 716.6531s\n",
      "\titers: 200, epoch: 1 | loss: 0.3033759\n",
      "\tspeed: 0.0288s/iter; left time: 639.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.3338654 Vali Loss: 0.2532648 Test Loss: 0.2725838\n",
      "Validation loss decreased (inf --> 0.253265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1622656\n",
      "\tspeed: 0.0571s/iter; left time: 1259.8679s\n",
      "\titers: 200, epoch: 2 | loss: 0.1375188\n",
      "\tspeed: 0.0291s/iter; left time: 640.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1762607 Vali Loss: 0.1345517 Test Loss: 0.1510844\n",
      "Validation loss decreased (0.253265 --> 0.134552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1233466\n",
      "\tspeed: 0.0568s/iter; left time: 1242.2167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1181084\n",
      "\tspeed: 0.0288s/iter; left time: 626.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1242561 Vali Loss: 0.1291316 Test Loss: 0.1425901\n",
      "Validation loss decreased (0.134552 --> 0.129132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1142696\n",
      "\tspeed: 0.0586s/iter; left time: 1267.1614s\n",
      "\titers: 200, epoch: 4 | loss: 0.1147908\n",
      "\tspeed: 0.0288s/iter; left time: 619.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1168121 Vali Loss: 0.1225252 Test Loss: 0.1383993\n",
      "Validation loss decreased (0.129132 --> 0.122525).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1139542\n",
      "\tspeed: 0.0590s/iter; left time: 1261.8554s\n",
      "\titers: 200, epoch: 5 | loss: 0.1082414\n",
      "\tspeed: 0.0294s/iter; left time: 626.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.1114651 Vali Loss: 0.1206943 Test Loss: 0.1348280\n",
      "Validation loss decreased (0.122525 --> 0.120694).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021842\n",
      "\tspeed: 0.0570s/iter; left time: 1208.1096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0938002\n",
      "\tspeed: 0.0289s/iter; left time: 608.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1045328 Vali Loss: 0.1056096 Test Loss: 0.1209389\n",
      "Validation loss decreased (0.120694 --> 0.105610).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1017401\n",
      "\tspeed: 0.0562s/iter; left time: 1176.9849s\n",
      "\titers: 200, epoch: 7 | loss: 0.1005022\n",
      "\tspeed: 0.0288s/iter; left time: 600.4934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0975340 Vali Loss: 0.1024042 Test Loss: 0.1193933\n",
      "Validation loss decreased (0.105610 --> 0.102404).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0948688\n",
      "\tspeed: 0.0571s/iter; left time: 1184.0784s\n",
      "\titers: 200, epoch: 8 | loss: 0.1000596\n",
      "\tspeed: 0.0288s/iter; left time: 594.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0934444 Vali Loss: 0.0994216 Test Loss: 0.1165976\n",
      "Validation loss decreased (0.102404 --> 0.099422).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0934406\n",
      "\tspeed: 0.0591s/iter; left time: 1213.0227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0883437\n",
      "\tspeed: 0.0321s/iter; left time: 655.9176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.0908908 Vali Loss: 0.0990675 Test Loss: 0.1177607\n",
      "Validation loss decreased (0.099422 --> 0.099067).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0887832\n",
      "\tspeed: 0.0565s/iter; left time: 1145.8530s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899321\n",
      "\tspeed: 0.0318s/iter; left time: 641.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0883627 Vali Loss: 0.0969078 Test Loss: 0.1132053\n",
      "Validation loss decreased (0.099067 --> 0.096908).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0881112\n",
      "\tspeed: 0.0577s/iter; left time: 1158.2065s\n",
      "\titers: 200, epoch: 11 | loss: 0.0945231\n",
      "\tspeed: 0.0304s/iter; left time: 606.9035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0864907 Vali Loss: 0.0953247 Test Loss: 0.1121059\n",
      "Validation loss decreased (0.096908 --> 0.095325).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0843419\n",
      "\tspeed: 0.0589s/iter; left time: 1168.1335s\n",
      "\titers: 200, epoch: 12 | loss: 0.0912391\n",
      "\tspeed: 0.0321s/iter; left time: 633.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0852969 Vali Loss: 0.0960679 Test Loss: 0.1133708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0836878\n",
      "\tspeed: 0.0559s/iter; left time: 1095.3962s\n",
      "\titers: 200, epoch: 13 | loss: 0.0875231\n",
      "\tspeed: 0.0287s/iter; left time: 560.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0846659 Vali Loss: 0.0948806 Test Loss: 0.1110438\n",
      "Validation loss decreased (0.095325 --> 0.094881).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766158\n",
      "\tspeed: 0.0563s/iter; left time: 1090.9442s\n",
      "\titers: 200, epoch: 14 | loss: 0.0830127\n",
      "\tspeed: 0.0289s/iter; left time: 558.1125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0839380 Vali Loss: 0.0950952 Test Loss: 0.1121607\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0802316\n",
      "\tspeed: 0.0571s/iter; left time: 1093.9622s\n",
      "\titers: 200, epoch: 15 | loss: 0.0908533\n",
      "\tspeed: 0.0296s/iter; left time: 565.0639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0833971 Vali Loss: 0.0946877 Test Loss: 0.1109749\n",
      "Validation loss decreased (0.094881 --> 0.094688).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0828219\n",
      "\tspeed: 0.0575s/iter; left time: 1089.7643s\n",
      "\titers: 200, epoch: 16 | loss: 0.0899052\n",
      "\tspeed: 0.0296s/iter; left time: 557.4669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0942182 Test Loss: 0.1100848\n",
      "Validation loss decreased (0.094688 --> 0.094218).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0843874\n",
      "\tspeed: 0.0562s/iter; left time: 1051.4422s\n",
      "\titers: 200, epoch: 17 | loss: 0.0783555\n",
      "\tspeed: 0.0293s/iter; left time: 545.9599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0825667 Vali Loss: 0.0938040 Test Loss: 0.1098376\n",
      "Validation loss decreased (0.094218 --> 0.093804).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0838933\n",
      "\tspeed: 0.0571s/iter; left time: 1056.0654s\n",
      "\titers: 200, epoch: 18 | loss: 0.0828639\n",
      "\tspeed: 0.0287s/iter; left time: 528.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0821785 Vali Loss: 0.0935164 Test Loss: 0.1101683\n",
      "Validation loss decreased (0.093804 --> 0.093516).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0850727\n",
      "\tspeed: 0.0576s/iter; left time: 1052.1592s\n",
      "\titers: 200, epoch: 19 | loss: 0.0809432\n",
      "\tspeed: 0.0291s/iter; left time: 528.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0816493 Vali Loss: 0.0933540 Test Loss: 0.1097036\n",
      "Validation loss decreased (0.093516 --> 0.093354).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837313\n",
      "\tspeed: 0.0560s/iter; left time: 1010.4820s\n",
      "\titers: 200, epoch: 20 | loss: 0.0828173\n",
      "\tspeed: 0.0294s/iter; left time: 527.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0812170 Vali Loss: 0.0944639 Test Loss: 0.1102860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0816318\n",
      "\tspeed: 0.0554s/iter; left time: 987.4029s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783820\n",
      "\tspeed: 0.0287s/iter; left time: 507.8599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0810404 Vali Loss: 0.0934393 Test Loss: 0.1084944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0794042\n",
      "\tspeed: 0.0552s/iter; left time: 971.4340s\n",
      "\titers: 200, epoch: 22 | loss: 0.0875820\n",
      "\tspeed: 0.0288s/iter; left time: 503.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0809224 Vali Loss: 0.0936703 Test Loss: 0.1092177\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0807245\n",
      "\tspeed: 0.0596s/iter; left time: 1035.5626s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802846\n",
      "\tspeed: 0.0322s/iter; left time: 555.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0806995 Vali Loss: 0.0934935 Test Loss: 0.1087055\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0787877\n",
      "\tspeed: 0.0567s/iter; left time: 972.2753s\n",
      "\titers: 200, epoch: 24 | loss: 0.0767248\n",
      "\tspeed: 0.0287s/iter; left time: 488.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0805229 Vali Loss: 0.0934937 Test Loss: 0.1088790\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0798116\n",
      "\tspeed: 0.0557s/iter; left time: 943.4702s\n",
      "\titers: 200, epoch: 25 | loss: 0.0819090\n",
      "\tspeed: 0.0299s/iter; left time: 503.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0805078 Vali Loss: 0.0929588 Test Loss: 0.1094698\n",
      "Validation loss decreased (0.093354 --> 0.092959).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0823269\n",
      "\tspeed: 0.0567s/iter; left time: 946.2114s\n",
      "\titers: 200, epoch: 26 | loss: 0.0798113\n",
      "\tspeed: 0.0289s/iter; left time: 480.2056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0803855 Vali Loss: 0.0927414 Test Loss: 0.1081589\n",
      "Validation loss decreased (0.092959 --> 0.092741).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0790964\n",
      "\tspeed: 0.0564s/iter; left time: 928.7901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0810004\n",
      "\tspeed: 0.0288s/iter; left time: 471.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0802783 Vali Loss: 0.0927604 Test Loss: 0.1083663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0785535\n",
      "\tspeed: 0.0560s/iter; left time: 909.4528s\n",
      "\titers: 200, epoch: 28 | loss: 0.0800566\n",
      "\tspeed: 0.0287s/iter; left time: 463.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0800824 Vali Loss: 0.0927891 Test Loss: 0.1084702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0824467\n",
      "\tspeed: 0.0558s/iter; left time: 895.1597s\n",
      "\titers: 200, epoch: 29 | loss: 0.0749914\n",
      "\tspeed: 0.0291s/iter; left time: 463.6987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0800234 Vali Loss: 0.0930075 Test Loss: 0.1087020\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0851725\n",
      "\tspeed: 0.0562s/iter; left time: 888.6111s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771379\n",
      "\tspeed: 0.0287s/iter; left time: 451.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0799518 Vali Loss: 0.0928861 Test Loss: 0.1086854\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0791548\n",
      "\tspeed: 0.0580s/iter; left time: 903.1971s\n",
      "\titers: 200, epoch: 31 | loss: 0.0856065\n",
      "\tspeed: 0.0288s/iter; left time: 446.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0798617 Vali Loss: 0.0930005 Test Loss: 0.1086721\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0829810\n",
      "\tspeed: 0.0560s/iter; left time: 859.7031s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803494\n",
      "\tspeed: 0.0287s/iter; left time: 437.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0797627 Vali Loss: 0.0925778 Test Loss: 0.1084085\n",
      "Validation loss decreased (0.092741 --> 0.092578).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0741690\n",
      "\tspeed: 0.0561s/iter; left time: 848.9781s\n",
      "\titers: 200, epoch: 33 | loss: 0.0767862\n",
      "\tspeed: 0.0292s/iter; left time: 438.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0796537 Vali Loss: 0.0929298 Test Loss: 0.1088642\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0792194\n",
      "\tspeed: 0.0559s/iter; left time: 833.5607s\n",
      "\titers: 200, epoch: 34 | loss: 0.0765002\n",
      "\tspeed: 0.0300s/iter; left time: 444.3112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0797492 Vali Loss: 0.0924148 Test Loss: 0.1081688\n",
      "Validation loss decreased (0.092578 --> 0.092415).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0811765\n",
      "\tspeed: 0.0564s/iter; left time: 827.6861s\n",
      "\titers: 200, epoch: 35 | loss: 0.0771101\n",
      "\tspeed: 0.0288s/iter; left time: 419.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0795456 Vali Loss: 0.0926273 Test Loss: 0.1082513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0838292\n",
      "\tspeed: 0.0557s/iter; left time: 804.8643s\n",
      "\titers: 200, epoch: 36 | loss: 0.0842810\n",
      "\tspeed: 0.0287s/iter; left time: 411.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0795685 Vali Loss: 0.0926306 Test Loss: 0.1081444\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0805124\n",
      "\tspeed: 0.0560s/iter; left time: 797.7228s\n",
      "\titers: 200, epoch: 37 | loss: 0.0764008\n",
      "\tspeed: 0.0288s/iter; left time: 406.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0796069 Vali Loss: 0.0926744 Test Loss: 0.1083330\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0838185\n",
      "\tspeed: 0.0556s/iter; left time: 778.9609s\n",
      "\titers: 200, epoch: 38 | loss: 0.0790809\n",
      "\tspeed: 0.0298s/iter; left time: 413.9136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0795481 Vali Loss: 0.0926521 Test Loss: 0.1083382\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0798627\n",
      "\tspeed: 0.0565s/iter; left time: 778.7612s\n",
      "\titers: 200, epoch: 39 | loss: 0.0784827\n",
      "\tspeed: 0.0296s/iter; left time: 405.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0795735 Vali Loss: 0.0924641 Test Loss: 0.1081592\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0794601\n",
      "\tspeed: 0.0567s/iter; left time: 769.0185s\n",
      "\titers: 200, epoch: 40 | loss: 0.0770109\n",
      "\tspeed: 0.0290s/iter; left time: 390.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0795276 Vali Loss: 0.0925184 Test Loss: 0.1081739\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0845513\n",
      "\tspeed: 0.0580s/iter; left time: 773.6496s\n",
      "\titers: 200, epoch: 41 | loss: 0.0787608\n",
      "\tspeed: 0.0287s/iter; left time: 379.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0794227 Vali Loss: 0.0924342 Test Loss: 0.1082191\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0851385\n",
      "\tspeed: 0.0564s/iter; left time: 739.5656s\n",
      "\titers: 200, epoch: 42 | loss: 0.0726394\n",
      "\tspeed: 0.0289s/iter; left time: 375.6130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0793880 Vali Loss: 0.0925256 Test Loss: 0.1081640\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0808362\n",
      "\tspeed: 0.0565s/iter; left time: 728.6957s\n",
      "\titers: 200, epoch: 43 | loss: 0.0785177\n",
      "\tspeed: 0.0296s/iter; left time: 378.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0794149 Vali Loss: 0.0923405 Test Loss: 0.1080182\n",
      "Validation loss decreased (0.092415 --> 0.092341).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0800935\n",
      "\tspeed: 0.0570s/iter; left time: 721.5518s\n",
      "\titers: 200, epoch: 44 | loss: 0.0805944\n",
      "\tspeed: 0.0287s/iter; left time: 361.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0794131 Vali Loss: 0.0925253 Test Loss: 0.1080764\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0780727\n",
      "\tspeed: 0.0562s/iter; left time: 699.4942s\n",
      "\titers: 200, epoch: 45 | loss: 0.0773424\n",
      "\tspeed: 0.0286s/iter; left time: 352.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0794502 Vali Loss: 0.0924763 Test Loss: 0.1081002\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0765740\n",
      "\tspeed: 0.0556s/iter; left time: 679.5649s\n",
      "\titers: 200, epoch: 46 | loss: 0.0758511\n",
      "\tspeed: 0.0287s/iter; left time: 348.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0793780 Vali Loss: 0.0923761 Test Loss: 0.1080692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0741220\n",
      "\tspeed: 0.0573s/iter; left time: 687.3605s\n",
      "\titers: 200, epoch: 47 | loss: 0.0814627\n",
      "\tspeed: 0.0300s/iter; left time: 356.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0793125 Vali Loss: 0.0925635 Test Loss: 0.1081378\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0840046\n",
      "\tspeed: 0.0561s/iter; left time: 661.0434s\n",
      "\titers: 200, epoch: 48 | loss: 0.0801558\n",
      "\tspeed: 0.0307s/iter; left time: 358.8378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0793096 Vali Loss: 0.0925548 Test Loss: 0.1080770\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0790702\n",
      "\tspeed: 0.0563s/iter; left time: 650.4749s\n",
      "\titers: 200, epoch: 49 | loss: 0.0778940\n",
      "\tspeed: 0.0287s/iter; left time: 328.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0793647 Vali Loss: 0.0924560 Test Loss: 0.1080747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0778823\n",
      "\tspeed: 0.0568s/iter; left time: 643.2612s\n",
      "\titers: 200, epoch: 50 | loss: 0.0760445\n",
      "\tspeed: 0.0288s/iter; left time: 322.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0792721 Vali Loss: 0.0922904 Test Loss: 0.1079481\n",
      "Validation loss decreased (0.092341 --> 0.092290).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0804726\n",
      "\tspeed: 0.0569s/iter; left time: 631.4179s\n",
      "\titers: 200, epoch: 51 | loss: 0.0787332\n",
      "\tspeed: 0.0288s/iter; left time: 316.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0793072 Vali Loss: 0.0924954 Test Loss: 0.1079852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0790398\n",
      "\tspeed: 0.0579s/iter; left time: 629.4743s\n",
      "\titers: 200, epoch: 52 | loss: 0.0787358\n",
      "\tspeed: 0.0297s/iter; left time: 320.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0792573 Vali Loss: 0.0924703 Test Loss: 0.1080296\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0900119\n",
      "\tspeed: 0.0556s/iter; left time: 592.8161s\n",
      "\titers: 200, epoch: 53 | loss: 0.0752347\n",
      "\tspeed: 0.0287s/iter; left time: 302.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0792959 Vali Loss: 0.0923305 Test Loss: 0.1079398\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0792841\n",
      "\tspeed: 0.0557s/iter; left time: 580.4247s\n",
      "\titers: 200, epoch: 54 | loss: 0.0825256\n",
      "\tspeed: 0.0289s/iter; left time: 298.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0792873 Vali Loss: 0.0924073 Test Loss: 0.1080818\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0781773\n",
      "\tspeed: 0.0571s/iter; left time: 582.7420s\n",
      "\titers: 200, epoch: 55 | loss: 0.0766314\n",
      "\tspeed: 0.0288s/iter; left time: 290.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0792376 Vali Loss: 0.0924195 Test Loss: 0.1080461\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0802200\n",
      "\tspeed: 0.0574s/iter; left time: 573.3976s\n",
      "\titers: 200, epoch: 56 | loss: 0.0798359\n",
      "\tspeed: 0.0288s/iter; left time: 284.1257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0792879 Vali Loss: 0.0925008 Test Loss: 0.1080550\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0767007\n",
      "\tspeed: 0.0570s/iter; left time: 556.5247s\n",
      "\titers: 200, epoch: 57 | loss: 0.0793759\n",
      "\tspeed: 0.0287s/iter; left time: 277.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0793458 Vali Loss: 0.0925170 Test Loss: 0.1081635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0802504\n",
      "\tspeed: 0.0585s/iter; left time: 557.3846s\n",
      "\titers: 200, epoch: 58 | loss: 0.0877043\n",
      "\tspeed: 0.0294s/iter; left time: 277.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0792422 Vali Loss: 0.0925055 Test Loss: 0.1080519\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0814317\n",
      "\tspeed: 0.0561s/iter; left time: 522.3504s\n",
      "\titers: 200, epoch: 59 | loss: 0.0802679\n",
      "\tspeed: 0.0290s/iter; left time: 266.7263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0792680 Vali Loss: 0.0924291 Test Loss: 0.1080143\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0793939\n",
      "\tspeed: 0.0563s/iter; left time: 511.1918s\n",
      "\titers: 200, epoch: 60 | loss: 0.0844201\n",
      "\tspeed: 0.0288s/iter; left time: 258.3232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0792484 Vali Loss: 0.0925565 Test Loss: 0.1081975\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027688894420862198, rmse:0.16639980673789978, mae:0.10794813185930252, rse:0.574032187461853\n",
      "Intermediate time for GB and pred_len 24: 00h:17m:49.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3359300\n",
      "\tspeed: 0.0526s/iter; left time: 1172.8069s\n",
      "\titers: 200, epoch: 1 | loss: 0.3055382\n",
      "\tspeed: 0.0290s/iter; left time: 644.8268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.3383009 Vali Loss: 0.2619191 Test Loss: 0.2823846\n",
      "Validation loss decreased (inf --> 0.261919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645241\n",
      "\tspeed: 0.0575s/iter; left time: 1269.2848s\n",
      "\titers: 200, epoch: 2 | loss: 0.1518169\n",
      "\tspeed: 0.0290s/iter; left time: 638.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1798169 Vali Loss: 0.1554538 Test Loss: 0.1792535\n",
      "Validation loss decreased (0.261919 --> 0.155454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1382080\n",
      "\tspeed: 0.0579s/iter; left time: 1265.9433s\n",
      "\titers: 200, epoch: 3 | loss: 0.1341432\n",
      "\tspeed: 0.0291s/iter; left time: 631.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1412312 Vali Loss: 0.1473401 Test Loss: 0.1714565\n",
      "Validation loss decreased (0.155454 --> 0.147340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1285816\n",
      "\tspeed: 0.0584s/iter; left time: 1262.2754s\n",
      "\titers: 200, epoch: 4 | loss: 0.1210611\n",
      "\tspeed: 0.0302s/iter; left time: 649.9370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.1327344 Vali Loss: 0.1408065 Test Loss: 0.1661706\n",
      "Validation loss decreased (0.147340 --> 0.140806).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1270812\n",
      "\tspeed: 0.0595s/iter; left time: 1273.1498s\n",
      "\titers: 200, epoch: 5 | loss: 0.1171009\n",
      "\tspeed: 0.0293s/iter; left time: 623.8844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.1209899 Vali Loss: 0.1331111 Test Loss: 0.1586780\n",
      "Validation loss decreased (0.140806 --> 0.133111).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146407\n",
      "\tspeed: 0.0572s/iter; left time: 1211.3576s\n",
      "\titers: 200, epoch: 6 | loss: 0.1110103\n",
      "\tspeed: 0.0293s/iter; left time: 617.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1145377 Vali Loss: 0.1320503 Test Loss: 0.1594520\n",
      "Validation loss decreased (0.133111 --> 0.132050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1034329\n",
      "\tspeed: 0.0571s/iter; left time: 1197.1052s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117046\n",
      "\tspeed: 0.0293s/iter; left time: 610.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1119251 Vali Loss: 0.1324430 Test Loss: 0.1580923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1104701\n",
      "\tspeed: 0.0572s/iter; left time: 1186.1793s\n",
      "\titers: 200, epoch: 8 | loss: 0.1084470\n",
      "\tspeed: 0.0306s/iter; left time: 632.2214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.1101401 Vali Loss: 0.1287862 Test Loss: 0.1565470\n",
      "Validation loss decreased (0.132050 --> 0.128786).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1070692\n",
      "\tspeed: 0.0580s/iter; left time: 1189.7318s\n",
      "\titers: 200, epoch: 9 | loss: 0.1071072\n",
      "\tspeed: 0.0289s/iter; left time: 590.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.1090582 Vali Loss: 0.1291053 Test Loss: 0.1570928\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1071760\n",
      "\tspeed: 0.0579s/iter; left time: 1175.4136s\n",
      "\titers: 200, epoch: 10 | loss: 0.1052107\n",
      "\tspeed: 0.0293s/iter; left time: 591.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.1077298 Vali Loss: 0.1280605 Test Loss: 0.1562621\n",
      "Validation loss decreased (0.128786 --> 0.128060).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1072934\n",
      "\tspeed: 0.0577s/iter; left time: 1158.1051s\n",
      "\titers: 200, epoch: 11 | loss: 0.1008391\n",
      "\tspeed: 0.0317s/iter; left time: 632.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1075322 Vali Loss: 0.1267957 Test Loss: 0.1560000\n",
      "Validation loss decreased (0.128060 --> 0.126796).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1015190\n",
      "\tspeed: 0.0611s/iter; left time: 1211.6897s\n",
      "\titers: 200, epoch: 12 | loss: 0.1038616\n",
      "\tspeed: 0.0290s/iter; left time: 572.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.1065964 Vali Loss: 0.1269001 Test Loss: 0.1561267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1077410\n",
      "\tspeed: 0.0594s/iter; left time: 1165.8807s\n",
      "\titers: 200, epoch: 13 | loss: 0.1095136\n",
      "\tspeed: 0.0298s/iter; left time: 581.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.1061064 Vali Loss: 0.1263930 Test Loss: 0.1561556\n",
      "Validation loss decreased (0.126796 --> 0.126393).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1006579\n",
      "\tspeed: 0.0600s/iter; left time: 1163.8486s\n",
      "\titers: 200, epoch: 14 | loss: 0.1050430\n",
      "\tspeed: 0.0318s/iter; left time: 613.0563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1056615 Vali Loss: 0.1263432 Test Loss: 0.1562384\n",
      "Validation loss decreased (0.126393 --> 0.126343).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1036151\n",
      "\tspeed: 0.0573s/iter; left time: 1098.8653s\n",
      "\titers: 200, epoch: 15 | loss: 0.1043281\n",
      "\tspeed: 0.0294s/iter; left time: 560.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1053216 Vali Loss: 0.1269479 Test Loss: 0.1575384\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1070781\n",
      "\tspeed: 0.0564s/iter; left time: 1068.0015s\n",
      "\titers: 200, epoch: 16 | loss: 0.1034022\n",
      "\tspeed: 0.0291s/iter; left time: 547.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1048783 Vali Loss: 0.1277726 Test Loss: 0.1580403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003585\n",
      "\tspeed: 0.0577s/iter; left time: 1080.6293s\n",
      "\titers: 200, epoch: 17 | loss: 0.1001033\n",
      "\tspeed: 0.0316s/iter; left time: 588.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.1045216 Vali Loss: 0.1268236 Test Loss: 0.1577196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1009254\n",
      "\tspeed: 0.0597s/iter; left time: 1103.5809s\n",
      "\titers: 200, epoch: 18 | loss: 0.1098270\n",
      "\tspeed: 0.0293s/iter; left time: 539.1057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.1045029 Vali Loss: 0.1274844 Test Loss: 0.1583436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1014802\n",
      "\tspeed: 0.0592s/iter; left time: 1080.8619s\n",
      "\titers: 200, epoch: 19 | loss: 0.1074477\n",
      "\tspeed: 0.0291s/iter; left time: 528.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1041605 Vali Loss: 0.1276784 Test Loss: 0.1590157\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1041076\n",
      "\tspeed: 0.0577s/iter; left time: 1041.4534s\n",
      "\titers: 200, epoch: 20 | loss: 0.1045305\n",
      "\tspeed: 0.0310s/iter; left time: 556.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1039412 Vali Loss: 0.1262973 Test Loss: 0.1578062\n",
      "Validation loss decreased (0.126343 --> 0.126297).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1051645\n",
      "\tspeed: 0.0600s/iter; left time: 1068.8318s\n",
      "\titers: 200, epoch: 21 | loss: 0.1051856\n",
      "\tspeed: 0.0323s/iter; left time: 572.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.1038215 Vali Loss: 0.1262325 Test Loss: 0.1585855\n",
      "Validation loss decreased (0.126297 --> 0.126232).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1055961\n",
      "\tspeed: 0.0577s/iter; left time: 1014.9434s\n",
      "\titers: 200, epoch: 22 | loss: 0.1064818\n",
      "\tspeed: 0.0291s/iter; left time: 508.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1035161 Vali Loss: 0.1280082 Test Loss: 0.1600144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1067082\n",
      "\tspeed: 0.0569s/iter; left time: 988.5767s\n",
      "\titers: 200, epoch: 23 | loss: 0.1012526\n",
      "\tspeed: 0.0290s/iter; left time: 501.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1033393 Vali Loss: 0.1265403 Test Loss: 0.1589221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1014733\n",
      "\tspeed: 0.0585s/iter; left time: 1003.8802s\n",
      "\titers: 200, epoch: 24 | loss: 0.1026502\n",
      "\tspeed: 0.0290s/iter; left time: 494.8332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1031041 Vali Loss: 0.1261224 Test Loss: 0.1583039\n",
      "Validation loss decreased (0.126232 --> 0.126122).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0981659\n",
      "\tspeed: 0.0582s/iter; left time: 984.5949s\n",
      "\titers: 200, epoch: 25 | loss: 0.1047010\n",
      "\tspeed: 0.0333s/iter; left time: 559.4806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 224 | Train Loss: 0.1032585 Vali Loss: 0.1271009 Test Loss: 0.1596650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1017167\n",
      "\tspeed: 0.0573s/iter; left time: 957.7253s\n",
      "\titers: 200, epoch: 26 | loss: 0.1062982\n",
      "\tspeed: 0.0290s/iter; left time: 481.1275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.1028747 Vali Loss: 0.1261045 Test Loss: 0.1588243\n",
      "Validation loss decreased (0.126122 --> 0.126104).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0993738\n",
      "\tspeed: 0.0575s/iter; left time: 947.4815s\n",
      "\titers: 200, epoch: 27 | loss: 0.1011657\n",
      "\tspeed: 0.0295s/iter; left time: 482.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.1028223 Vali Loss: 0.1261684 Test Loss: 0.1590412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1025169\n",
      "\tspeed: 0.0587s/iter; left time: 953.6421s\n",
      "\titers: 200, epoch: 28 | loss: 0.1023520\n",
      "\tspeed: 0.0290s/iter; left time: 468.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1027485 Vali Loss: 0.1265673 Test Loss: 0.1591919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1030190\n",
      "\tspeed: 0.0574s/iter; left time: 919.3247s\n",
      "\titers: 200, epoch: 29 | loss: 0.1061572\n",
      "\tspeed: 0.0292s/iter; left time: 464.7819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1026199 Vali Loss: 0.1270175 Test Loss: 0.1597936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1019020\n",
      "\tspeed: 0.0590s/iter; left time: 932.3124s\n",
      "\titers: 200, epoch: 30 | loss: 0.1026730\n",
      "\tspeed: 0.0303s/iter; left time: 475.1487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.1026114 Vali Loss: 0.1262178 Test Loss: 0.1593244\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1040471\n",
      "\tspeed: 0.0608s/iter; left time: 947.9396s\n",
      "\titers: 200, epoch: 31 | loss: 0.1050210\n",
      "\tspeed: 0.0313s/iter; left time: 484.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.1025998 Vali Loss: 0.1269054 Test Loss: 0.1599075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0999098\n",
      "\tspeed: 0.0586s/iter; left time: 899.2171s\n",
      "\titers: 200, epoch: 32 | loss: 0.1029469\n",
      "\tspeed: 0.0303s/iter; left time: 462.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.1024311 Vali Loss: 0.1267687 Test Loss: 0.1597762\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0999667\n",
      "\tspeed: 0.0574s/iter; left time: 868.7457s\n",
      "\titers: 200, epoch: 33 | loss: 0.1071978\n",
      "\tspeed: 0.0289s/iter; left time: 435.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1024793 Vali Loss: 0.1271253 Test Loss: 0.1602533\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1006130\n",
      "\tspeed: 0.0567s/iter; left time: 845.3331s\n",
      "\titers: 200, epoch: 34 | loss: 0.1030252\n",
      "\tspeed: 0.0291s/iter; left time: 431.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1024566 Vali Loss: 0.1270611 Test Loss: 0.1602531\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1031557\n",
      "\tspeed: 0.0578s/iter; left time: 848.7132s\n",
      "\titers: 200, epoch: 35 | loss: 0.1026185\n",
      "\tspeed: 0.0299s/iter; left time: 436.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.1023702 Vali Loss: 0.1269624 Test Loss: 0.1601274\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0980491\n",
      "\tspeed: 0.0574s/iter; left time: 830.5713s\n",
      "\titers: 200, epoch: 36 | loss: 0.1034933\n",
      "\tspeed: 0.0295s/iter; left time: 423.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1022995 Vali Loss: 0.1273532 Test Loss: 0.1606251\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.055034536868333817, rmse:0.2345944046974182, mae:0.15882423520088196, rse:0.8112601637840271\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3382944\n",
      "\tspeed: 0.0335s/iter; left time: 745.9897s\n",
      "\titers: 200, epoch: 1 | loss: 0.3088757\n",
      "\tspeed: 0.0294s/iter; left time: 652.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.3390055 Vali Loss: 0.2569903 Test Loss: 0.2774958\n",
      "Validation loss decreased (inf --> 0.256990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1647399\n",
      "\tspeed: 0.0601s/iter; left time: 1326.5700s\n",
      "\titers: 200, epoch: 2 | loss: 0.1470101\n",
      "\tspeed: 0.0291s/iter; left time: 639.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1799622 Vali Loss: 0.1558552 Test Loss: 0.1805645\n",
      "Validation loss decreased (0.256990 --> 0.155855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1392165\n",
      "\tspeed: 0.0577s/iter; left time: 1260.4429s\n",
      "\titers: 200, epoch: 3 | loss: 0.1376834\n",
      "\tspeed: 0.0291s/iter; left time: 632.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1419010 Vali Loss: 0.1476490 Test Loss: 0.1712235\n",
      "Validation loss decreased (0.155855 --> 0.147649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1335415\n",
      "\tspeed: 0.0582s/iter; left time: 1258.9691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1267459\n",
      "\tspeed: 0.0296s/iter; left time: 636.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1334124 Vali Loss: 0.1412331 Test Loss: 0.1651746\n",
      "Validation loss decreased (0.147649 --> 0.141233).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1192878\n",
      "\tspeed: 0.0598s/iter; left time: 1278.9499s\n",
      "\titers: 200, epoch: 5 | loss: 0.1201399\n",
      "\tspeed: 0.0293s/iter; left time: 623.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1225902 Vali Loss: 0.1341079 Test Loss: 0.1599404\n",
      "Validation loss decreased (0.141233 --> 0.134108).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1123025\n",
      "\tspeed: 0.0584s/iter; left time: 1235.9952s\n",
      "\titers: 200, epoch: 6 | loss: 0.1077852\n",
      "\tspeed: 0.0291s/iter; left time: 612.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1141329 Vali Loss: 0.1283782 Test Loss: 0.1533810\n",
      "Validation loss decreased (0.134108 --> 0.128378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1158050\n",
      "\tspeed: 0.0581s/iter; left time: 1217.7041s\n",
      "\titers: 200, epoch: 7 | loss: 0.1111416\n",
      "\tspeed: 0.0290s/iter; left time: 605.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1118387 Vali Loss: 0.1285268 Test Loss: 0.1541791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1044721\n",
      "\tspeed: 0.0578s/iter; left time: 1198.5440s\n",
      "\titers: 200, epoch: 8 | loss: 0.1089049\n",
      "\tspeed: 0.0299s/iter; left time: 617.6690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1094609 Vali Loss: 0.1279552 Test Loss: 0.1544364\n",
      "Validation loss decreased (0.128378 --> 0.127955).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1128018\n",
      "\tspeed: 0.0578s/iter; left time: 1184.6255s\n",
      "\titers: 200, epoch: 9 | loss: 0.1038138\n",
      "\tspeed: 0.0291s/iter; left time: 593.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1085410 Vali Loss: 0.1276643 Test Loss: 0.1544435\n",
      "Validation loss decreased (0.127955 --> 0.127664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1089916\n",
      "\tspeed: 0.0583s/iter; left time: 1182.6453s\n",
      "\titers: 200, epoch: 10 | loss: 0.1071845\n",
      "\tspeed: 0.0298s/iter; left time: 601.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.1074760 Vali Loss: 0.1253896 Test Loss: 0.1536289\n",
      "Validation loss decreased (0.127664 --> 0.125390).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1051096\n",
      "\tspeed: 0.0585s/iter; left time: 1172.7631s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087691\n",
      "\tspeed: 0.0291s/iter; left time: 580.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1064335 Vali Loss: 0.1265477 Test Loss: 0.1550157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1096761\n",
      "\tspeed: 0.0585s/iter; left time: 1160.4630s\n",
      "\titers: 200, epoch: 12 | loss: 0.1067159\n",
      "\tspeed: 0.0296s/iter; left time: 584.1338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1058718 Vali Loss: 0.1253167 Test Loss: 0.1545382\n",
      "Validation loss decreased (0.125390 --> 0.125317).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1052651\n",
      "\tspeed: 0.0597s/iter; left time: 1171.2043s\n",
      "\titers: 200, epoch: 13 | loss: 0.1067813\n",
      "\tspeed: 0.0289s/iter; left time: 564.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1054589 Vali Loss: 0.1246151 Test Loss: 0.1547630\n",
      "Validation loss decreased (0.125317 --> 0.124615).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0997767\n",
      "\tspeed: 0.0603s/iter; left time: 1168.4821s\n",
      "\titers: 200, epoch: 14 | loss: 0.1084390\n",
      "\tspeed: 0.0305s/iter; left time: 588.8947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.1049181 Vali Loss: 0.1251454 Test Loss: 0.1548447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1117538\n",
      "\tspeed: 0.0584s/iter; left time: 1119.5725s\n",
      "\titers: 200, epoch: 15 | loss: 0.1073543\n",
      "\tspeed: 0.0300s/iter; left time: 571.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.1049290 Vali Loss: 0.1254940 Test Loss: 0.1555783\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1043427\n",
      "\tspeed: 0.0599s/iter; left time: 1134.1613s\n",
      "\titers: 200, epoch: 16 | loss: 0.1064552\n",
      "\tspeed: 0.0289s/iter; left time: 545.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1049404 Vali Loss: 0.1253642 Test Loss: 0.1560015\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1026502\n",
      "\tspeed: 0.0600s/iter; left time: 1123.0669s\n",
      "\titers: 200, epoch: 17 | loss: 0.1022601\n",
      "\tspeed: 0.0305s/iter; left time: 567.6033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.1041347 Vali Loss: 0.1250820 Test Loss: 0.1563988\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1062561\n",
      "\tspeed: 0.0618s/iter; left time: 1143.7203s\n",
      "\titers: 200, epoch: 18 | loss: 0.1088515\n",
      "\tspeed: 0.0319s/iter; left time: 586.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.1037707 Vali Loss: 0.1243541 Test Loss: 0.1554476\n",
      "Validation loss decreased (0.124615 --> 0.124354).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0993068\n",
      "\tspeed: 0.0595s/iter; left time: 1087.5091s\n",
      "\titers: 200, epoch: 19 | loss: 0.1019748\n",
      "\tspeed: 0.0290s/iter; left time: 527.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.1037096 Vali Loss: 0.1256859 Test Loss: 0.1573124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1021327\n",
      "\tspeed: 0.0582s/iter; left time: 1049.6431s\n",
      "\titers: 200, epoch: 20 | loss: 0.1042501\n",
      "\tspeed: 0.0290s/iter; left time: 520.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1033165 Vali Loss: 0.1246167 Test Loss: 0.1559177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1079735\n",
      "\tspeed: 0.0572s/iter; left time: 1019.8703s\n",
      "\titers: 200, epoch: 21 | loss: 0.1024800\n",
      "\tspeed: 0.0291s/iter; left time: 515.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1033201 Vali Loss: 0.1252455 Test Loss: 0.1570356\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1035397\n",
      "\tspeed: 0.0586s/iter; left time: 1030.4569s\n",
      "\titers: 200, epoch: 22 | loss: 0.1013180\n",
      "\tspeed: 0.0292s/iter; left time: 510.8724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1030369 Vali Loss: 0.1251961 Test Loss: 0.1571349\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1032221\n",
      "\tspeed: 0.0572s/iter; left time: 994.2471s\n",
      "\titers: 200, epoch: 23 | loss: 0.1035303\n",
      "\tspeed: 0.0294s/iter; left time: 507.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.1029777 Vali Loss: 0.1247599 Test Loss: 0.1567290\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1026154\n",
      "\tspeed: 0.0598s/iter; left time: 1026.2733s\n",
      "\titers: 200, epoch: 24 | loss: 0.0989607\n",
      "\tspeed: 0.0312s/iter; left time: 531.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1027480 Vali Loss: 0.1248074 Test Loss: 0.1571890\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1040794\n",
      "\tspeed: 0.0580s/iter; left time: 980.9191s\n",
      "\titers: 200, epoch: 25 | loss: 0.0995111\n",
      "\tspeed: 0.0295s/iter; left time: 496.3614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1026216 Vali Loss: 0.1257099 Test Loss: 0.1579469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1023950\n",
      "\tspeed: 0.0575s/iter; left time: 960.6251s\n",
      "\titers: 200, epoch: 26 | loss: 0.1049756\n",
      "\tspeed: 0.0290s/iter; left time: 481.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1026662 Vali Loss: 0.1253953 Test Loss: 0.1576243\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1051858\n",
      "\tspeed: 0.0582s/iter; left time: 958.1651s\n",
      "\titers: 200, epoch: 27 | loss: 0.1014959\n",
      "\tspeed: 0.0307s/iter; left time: 503.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.1023970 Vali Loss: 0.1253553 Test Loss: 0.1575951\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1091064\n",
      "\tspeed: 0.0572s/iter; left time: 929.4024s\n",
      "\titers: 200, epoch: 28 | loss: 0.0986917\n",
      "\tspeed: 0.0291s/iter; left time: 470.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.1028671 Vali Loss: 0.1257599 Test Loss: 0.1583659\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.052698101848363876, rmse:0.22956067323684692, mae:0.15544772148132324, rse:0.7938528060913086\n",
      "Intermediate time for GB and pred_len 96: 00h:09m:36.09s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3366266\n",
      "\tspeed: 0.0539s/iter; left time: 1196.9681s\n",
      "\titers: 200, epoch: 1 | loss: 0.3121953\n",
      "\tspeed: 0.0298s/iter; left time: 657.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.3369664 Vali Loss: 0.2647370 Test Loss: 0.2830009\n",
      "Validation loss decreased (inf --> 0.264737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651093\n",
      "\tspeed: 0.0593s/iter; left time: 1304.3523s\n",
      "\titers: 200, epoch: 2 | loss: 0.1446099\n",
      "\tspeed: 0.0295s/iter; left time: 646.2656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1787822 Vali Loss: 0.1586284 Test Loss: 0.1842767\n",
      "Validation loss decreased (0.264737 --> 0.158628).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1485163\n",
      "\tspeed: 0.0583s/iter; left time: 1267.4912s\n",
      "\titers: 200, epoch: 3 | loss: 0.1400858\n",
      "\tspeed: 0.0293s/iter; left time: 634.9937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1445244 Vali Loss: 0.1465050 Test Loss: 0.1715189\n",
      "Validation loss decreased (0.158628 --> 0.146505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1308593\n",
      "\tspeed: 0.0579s/iter; left time: 1247.0180s\n",
      "\titers: 200, epoch: 4 | loss: 0.1231993\n",
      "\tspeed: 0.0295s/iter; left time: 631.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.1302476 Vali Loss: 0.1380062 Test Loss: 0.1644330\n",
      "Validation loss decreased (0.146505 --> 0.138006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1219988\n",
      "\tspeed: 0.0581s/iter; left time: 1238.1868s\n",
      "\titers: 200, epoch: 5 | loss: 0.1241196\n",
      "\tspeed: 0.0294s/iter; left time: 623.9474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1196544 Vali Loss: 0.1335753 Test Loss: 0.1605477\n",
      "Validation loss decreased (0.138006 --> 0.133575).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1183338\n",
      "\tspeed: 0.0588s/iter; left time: 1239.5786s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119973\n",
      "\tspeed: 0.0295s/iter; left time: 618.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.1171256 Vali Loss: 0.1322436 Test Loss: 0.1586682\n",
      "Validation loss decreased (0.133575 --> 0.132244).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1133875\n",
      "\tspeed: 0.0585s/iter; left time: 1221.0821s\n",
      "\titers: 200, epoch: 7 | loss: 0.1137060\n",
      "\tspeed: 0.0301s/iter; left time: 625.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1146362 Vali Loss: 0.1312758 Test Loss: 0.1601958\n",
      "Validation loss decreased (0.132244 --> 0.131276).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1116588\n",
      "\tspeed: 0.0587s/iter; left time: 1210.5936s\n",
      "\titers: 200, epoch: 8 | loss: 0.1241252\n",
      "\tspeed: 0.0293s/iter; left time: 602.1551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1129455 Vali Loss: 0.1309668 Test Loss: 0.1592294\n",
      "Validation loss decreased (0.131276 --> 0.130967).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091937\n",
      "\tspeed: 0.0597s/iter; left time: 1219.3626s\n",
      "\titers: 200, epoch: 9 | loss: 0.1055460\n",
      "\tspeed: 0.0303s/iter; left time: 615.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1121144 Vali Loss: 0.1297192 Test Loss: 0.1594340\n",
      "Validation loss decreased (0.130967 --> 0.129719).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1107557\n",
      "\tspeed: 0.0597s/iter; left time: 1206.1690s\n",
      "\titers: 200, epoch: 10 | loss: 0.1175592\n",
      "\tspeed: 0.0304s/iter; left time: 610.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 223 | Train Loss: 0.1112239 Vali Loss: 0.1295732 Test Loss: 0.1591213\n",
      "Validation loss decreased (0.129719 --> 0.129573).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1079672\n",
      "\tspeed: 0.0608s/iter; left time: 1215.0238s\n",
      "\titers: 200, epoch: 11 | loss: 0.1083318\n",
      "\tspeed: 0.0309s/iter; left time: 614.9184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.1106468 Vali Loss: 0.1309009 Test Loss: 0.1610821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1072241\n",
      "\tspeed: 0.0579s/iter; left time: 1142.6644s\n",
      "\titers: 200, epoch: 12 | loss: 0.1056165\n",
      "\tspeed: 0.0292s/iter; left time: 574.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 223 | Train Loss: 0.1101225 Vali Loss: 0.1297053 Test Loss: 0.1603713\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1043832\n",
      "\tspeed: 0.0576s/iter; left time: 1124.3874s\n",
      "\titers: 200, epoch: 13 | loss: 0.1069444\n",
      "\tspeed: 0.0293s/iter; left time: 569.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1096867 Vali Loss: 0.1322169 Test Loss: 0.1629731\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1110399\n",
      "\tspeed: 0.0575s/iter; left time: 1109.7097s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076464\n",
      "\tspeed: 0.0301s/iter; left time: 578.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.1092416 Vali Loss: 0.1294154 Test Loss: 0.1616850\n",
      "Validation loss decreased (0.129573 --> 0.129415).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1066780\n",
      "\tspeed: 0.0598s/iter; left time: 1140.8027s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097973\n",
      "\tspeed: 0.0302s/iter; left time: 573.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.1091256 Vali Loss: 0.1305313 Test Loss: 0.1634465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044781\n",
      "\tspeed: 0.0582s/iter; left time: 1097.1887s\n",
      "\titers: 200, epoch: 16 | loss: 0.1063152\n",
      "\tspeed: 0.0302s/iter; left time: 567.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.1086627 Vali Loss: 0.1311994 Test Loss: 0.1641488\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1121321\n",
      "\tspeed: 0.0588s/iter; left time: 1095.5927s\n",
      "\titers: 200, epoch: 17 | loss: 0.1099676\n",
      "\tspeed: 0.0293s/iter; left time: 543.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1086403 Vali Loss: 0.1308852 Test Loss: 0.1652794\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089587\n",
      "\tspeed: 0.0576s/iter; left time: 1059.5661s\n",
      "\titers: 200, epoch: 18 | loss: 0.1039194\n",
      "\tspeed: 0.0303s/iter; left time: 554.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1083525 Vali Loss: 0.1308944 Test Loss: 0.1648135\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1075632\n",
      "\tspeed: 0.0585s/iter; left time: 1063.1784s\n",
      "\titers: 200, epoch: 19 | loss: 0.1068872\n",
      "\tspeed: 0.0312s/iter; left time: 563.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.1078722 Vali Loss: 0.1303356 Test Loss: 0.1646044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1086246\n",
      "\tspeed: 0.0594s/iter; left time: 1066.7321s\n",
      "\titers: 200, epoch: 20 | loss: 0.1254759\n",
      "\tspeed: 0.0302s/iter; left time: 539.8073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 223 | Train Loss: 0.1076508 Vali Loss: 0.1307199 Test Loss: 0.1653773\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1084048\n",
      "\tspeed: 0.0592s/iter; left time: 1050.1783s\n",
      "\titers: 200, epoch: 21 | loss: 0.1090945\n",
      "\tspeed: 0.0294s/iter; left time: 517.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1077504 Vali Loss: 0.1300167 Test Loss: 0.1650280\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1053139\n",
      "\tspeed: 0.0615s/iter; left time: 1077.6203s\n",
      "\titers: 200, epoch: 22 | loss: 0.1030664\n",
      "\tspeed: 0.0299s/iter; left time: 521.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 223 | Train Loss: 0.1073189 Vali Loss: 0.1307178 Test Loss: 0.1656655\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1041170\n",
      "\tspeed: 0.0582s/iter; left time: 1006.8948s\n",
      "\titers: 200, epoch: 23 | loss: 0.1104432\n",
      "\tspeed: 0.0300s/iter; left time: 515.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1073729 Vali Loss: 0.1307525 Test Loss: 0.1657586\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1077704\n",
      "\tspeed: 0.0581s/iter; left time: 991.5045s\n",
      "\titers: 200, epoch: 24 | loss: 0.1035321\n",
      "\tspeed: 0.0305s/iter; left time: 518.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.1071436 Vali Loss: 0.1298546 Test Loss: 0.1652837\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05683257430791855, rmse:0.2383958399295807, mae:0.16168498992919922, rse:0.8265526294708252\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3402086\n",
      "\tspeed: 0.0321s/iter; left time: 713.0532s\n",
      "\titers: 200, epoch: 1 | loss: 0.3085034\n",
      "\tspeed: 0.0294s/iter; left time: 649.0908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.3372581 Vali Loss: 0.2569959 Test Loss: 0.2770556\n",
      "Validation loss decreased (inf --> 0.256996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1623315\n",
      "\tspeed: 0.0610s/iter; left time: 1339.6838s\n",
      "\titers: 200, epoch: 2 | loss: 0.1550021\n",
      "\tspeed: 0.0304s/iter; left time: 666.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 223 | Train Loss: 0.1784228 Vali Loss: 0.1581057 Test Loss: 0.1840390\n",
      "Validation loss decreased (0.256996 --> 0.158106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1444710\n",
      "\tspeed: 0.0602s/iter; left time: 1309.8082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1421797\n",
      "\tspeed: 0.0302s/iter; left time: 654.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 223 | Train Loss: 0.1440059 Vali Loss: 0.1467589 Test Loss: 0.1728797\n",
      "Validation loss decreased (0.158106 --> 0.146759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1259966\n",
      "\tspeed: 0.0611s/iter; left time: 1314.7005s\n",
      "\titers: 200, epoch: 4 | loss: 0.1267358\n",
      "\tspeed: 0.0302s/iter; left time: 647.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.1277859 Vali Loss: 0.1378083 Test Loss: 0.1640089\n",
      "Validation loss decreased (0.146759 --> 0.137808).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163997\n",
      "\tspeed: 0.0592s/iter; left time: 1261.4131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184118\n",
      "\tspeed: 0.0293s/iter; left time: 622.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1182865 Vali Loss: 0.1349139 Test Loss: 0.1651066\n",
      "Validation loss decreased (0.137808 --> 0.134914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1105433\n",
      "\tspeed: 0.0606s/iter; left time: 1278.1655s\n",
      "\titers: 200, epoch: 6 | loss: 0.1167092\n",
      "\tspeed: 0.0293s/iter; left time: 615.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1156634 Vali Loss: 0.1333151 Test Loss: 0.1638211\n",
      "Validation loss decreased (0.134914 --> 0.133315).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1127449\n",
      "\tspeed: 0.0604s/iter; left time: 1260.8016s\n",
      "\titers: 200, epoch: 7 | loss: 0.1125693\n",
      "\tspeed: 0.0298s/iter; left time: 618.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1140903 Vali Loss: 0.1311537 Test Loss: 0.1617662\n",
      "Validation loss decreased (0.133315 --> 0.131154).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1084685\n",
      "\tspeed: 0.0592s/iter; left time: 1221.6293s\n",
      "\titers: 200, epoch: 8 | loss: 0.1119662\n",
      "\tspeed: 0.0296s/iter; left time: 608.3471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1128098 Vali Loss: 0.1317256 Test Loss: 0.1634459\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1200939\n",
      "\tspeed: 0.0581s/iter; left time: 1186.3585s\n",
      "\titers: 200, epoch: 9 | loss: 0.1130663\n",
      "\tspeed: 0.0293s/iter; left time: 595.5163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1117651 Vali Loss: 0.1300392 Test Loss: 0.1620218\n",
      "Validation loss decreased (0.131154 --> 0.130039).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1117106\n",
      "\tspeed: 0.0584s/iter; left time: 1179.2462s\n",
      "\titers: 200, epoch: 10 | loss: 0.1125487\n",
      "\tspeed: 0.0293s/iter; left time: 588.7069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1111699 Vali Loss: 0.1306203 Test Loss: 0.1629139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1109079\n",
      "\tspeed: 0.0588s/iter; left time: 1174.7505s\n",
      "\titers: 200, epoch: 11 | loss: 0.1139422\n",
      "\tspeed: 0.0303s/iter; left time: 602.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.1106018 Vali Loss: 0.1302929 Test Loss: 0.1627319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1098226\n",
      "\tspeed: 0.0593s/iter; left time: 1170.8908s\n",
      "\titers: 200, epoch: 12 | loss: 0.1094881\n",
      "\tspeed: 0.0308s/iter; left time: 605.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.1097835 Vali Loss: 0.1305087 Test Loss: 0.1636388\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1108742\n",
      "\tspeed: 0.0596s/iter; left time: 1163.6429s\n",
      "\titers: 200, epoch: 13 | loss: 0.1088738\n",
      "\tspeed: 0.0303s/iter; left time: 588.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.1095051 Vali Loss: 0.1299647 Test Loss: 0.1634194\n",
      "Validation loss decreased (0.130039 --> 0.129965).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1109743\n",
      "\tspeed: 0.0593s/iter; left time: 1144.8269s\n",
      "\titers: 200, epoch: 14 | loss: 0.1104263\n",
      "\tspeed: 0.0319s/iter; left time: 613.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 223 | Train Loss: 0.1088347 Vali Loss: 0.1303767 Test Loss: 0.1640156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1100040\n",
      "\tspeed: 0.0589s/iter; left time: 1123.6641s\n",
      "\titers: 200, epoch: 15 | loss: 0.1055611\n",
      "\tspeed: 0.0293s/iter; left time: 555.6611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1094680 Vali Loss: 0.1308889 Test Loss: 0.1656883\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1094828\n",
      "\tspeed: 0.0586s/iter; left time: 1105.3967s\n",
      "\titers: 200, epoch: 16 | loss: 0.1123643\n",
      "\tspeed: 0.0302s/iter; left time: 566.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1083884 Vali Loss: 0.1295829 Test Loss: 0.1647080\n",
      "Validation loss decreased (0.129965 --> 0.129583).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1095983\n",
      "\tspeed: 0.0631s/iter; left time: 1175.1036s\n",
      "\titers: 200, epoch: 17 | loss: 0.1078471\n",
      "\tspeed: 0.0324s/iter; left time: 599.8567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 223 | Train Loss: 0.1081606 Vali Loss: 0.1309675 Test Loss: 0.1657950\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1098130\n",
      "\tspeed: 0.0598s/iter; left time: 1100.1994s\n",
      "\titers: 200, epoch: 18 | loss: 0.1097067\n",
      "\tspeed: 0.0305s/iter; left time: 559.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 223 | Train Loss: 0.1079682 Vali Loss: 0.1304384 Test Loss: 0.1658921\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1092179\n",
      "\tspeed: 0.0627s/iter; left time: 1140.1479s\n",
      "\titers: 200, epoch: 19 | loss: 0.1091929\n",
      "\tspeed: 0.0294s/iter; left time: 532.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.1077528 Vali Loss: 0.1300526 Test Loss: 0.1655668\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1087070\n",
      "\tspeed: 0.0580s/iter; left time: 1042.0148s\n",
      "\titers: 200, epoch: 20 | loss: 0.1053877\n",
      "\tspeed: 0.0294s/iter; left time: 524.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1075957 Vali Loss: 0.1306300 Test Loss: 0.1664931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1083791\n",
      "\tspeed: 0.0604s/iter; left time: 1070.9086s\n",
      "\titers: 200, epoch: 21 | loss: 0.1123239\n",
      "\tspeed: 0.0319s/iter; left time: 563.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.1072414 Vali Loss: 0.1308478 Test Loss: 0.1670045\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1062817\n",
      "\tspeed: 0.0582s/iter; left time: 1019.4806s\n",
      "\titers: 200, epoch: 22 | loss: 0.1068905\n",
      "\tspeed: 0.0294s/iter; left time: 511.5557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1071266 Vali Loss: 0.1304129 Test Loss: 0.1671253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1066616\n",
      "\tspeed: 0.0589s/iter; left time: 1018.0292s\n",
      "\titers: 200, epoch: 23 | loss: 0.1091782\n",
      "\tspeed: 0.0300s/iter; left time: 515.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.1070438 Vali Loss: 0.1302519 Test Loss: 0.1669248\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1085539\n",
      "\tspeed: 0.0586s/iter; left time: 1001.0140s\n",
      "\titers: 200, epoch: 24 | loss: 0.1094983\n",
      "\tspeed: 0.0298s/iter; left time: 506.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.1069335 Vali Loss: 0.1307020 Test Loss: 0.1674266\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1074903\n",
      "\tspeed: 0.0582s/iter; left time: 981.3953s\n",
      "\titers: 200, epoch: 25 | loss: 0.1070229\n",
      "\tspeed: 0.0293s/iter; left time: 491.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1066940 Vali Loss: 0.1297427 Test Loss: 0.1666635\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1061949\n",
      "\tspeed: 0.0582s/iter; left time: 967.8393s\n",
      "\titers: 200, epoch: 26 | loss: 0.1066574\n",
      "\tspeed: 0.0297s/iter; left time: 490.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1066820 Vali Loss: 0.1307136 Test Loss: 0.1678365\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.058582644909620285, rmse:0.2420385181903839, mae:0.1647079735994339, rse:0.8391822576522827\n",
      "Intermediate time for GB and pred_len 168: 00h:07m:39.39s\n",
      "Intermediate time for GB: 00h:35m:05.17s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3280331\n",
      "\tspeed: 0.0458s/iter; left time: 1022.3050s\n",
      "\titers: 200, epoch: 1 | loss: 0.3062457\n",
      "\tspeed: 0.0225s/iter; left time: 499.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.3322086 Vali Loss: 0.2327209 Test Loss: 0.2490792\n",
      "Validation loss decreased (inf --> 0.232721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1790698\n",
      "\tspeed: 0.0426s/iter; left time: 940.5603s\n",
      "\titers: 200, epoch: 2 | loss: 0.1240088\n",
      "\tspeed: 0.0252s/iter; left time: 553.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.1817373 Vali Loss: 0.0993574 Test Loss: 0.1297020\n",
      "Validation loss decreased (0.232721 --> 0.099357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1098694\n",
      "\tspeed: 0.0475s/iter; left time: 1037.6778s\n",
      "\titers: 200, epoch: 3 | loss: 0.0996033\n",
      "\tspeed: 0.0213s/iter; left time: 463.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1085433 Vali Loss: 0.0891265 Test Loss: 0.1197414\n",
      "Validation loss decreased (0.099357 --> 0.089126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0921610\n",
      "\tspeed: 0.0486s/iter; left time: 1050.8582s\n",
      "\titers: 200, epoch: 4 | loss: 0.0895967\n",
      "\tspeed: 0.0260s/iter; left time: 559.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0948460 Vali Loss: 0.0861677 Test Loss: 0.1175608\n",
      "Validation loss decreased (0.089126 --> 0.086168).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0900297\n",
      "\tspeed: 0.0445s/iter; left time: 951.6346s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834872\n",
      "\tspeed: 0.0205s/iter; left time: 437.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0862508 Vali Loss: 0.0829640 Test Loss: 0.1167970\n",
      "Validation loss decreased (0.086168 --> 0.082964).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831936\n",
      "\tspeed: 0.0527s/iter; left time: 1117.0018s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793548\n",
      "\tspeed: 0.0300s/iter; left time: 631.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0819093 Vali Loss: 0.0773864 Test Loss: 0.1101628\n",
      "Validation loss decreased (0.082964 --> 0.077386).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0755749\n",
      "\tspeed: 0.0511s/iter; left time: 1071.5606s\n",
      "\titers: 200, epoch: 7 | loss: 0.0745635\n",
      "\tspeed: 0.0302s/iter; left time: 629.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0778414 Vali Loss: 0.0777628 Test Loss: 0.1100845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761717\n",
      "\tspeed: 0.0389s/iter; left time: 806.2031s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765059\n",
      "\tspeed: 0.0241s/iter; left time: 496.3405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0762376 Vali Loss: 0.0787192 Test Loss: 0.1120105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749097\n",
      "\tspeed: 0.0431s/iter; left time: 884.4358s\n",
      "\titers: 200, epoch: 9 | loss: 0.0730209\n",
      "\tspeed: 0.0272s/iter; left time: 554.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0743153 Vali Loss: 0.0744291 Test Loss: 0.1079679\n",
      "Validation loss decreased (0.077386 --> 0.074429).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0723649\n",
      "\tspeed: 0.0475s/iter; left time: 963.8736s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749586\n",
      "\tspeed: 0.0288s/iter; left time: 580.5086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0725542 Vali Loss: 0.0720653 Test Loss: 0.1045647\n",
      "Validation loss decreased (0.074429 --> 0.072065).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0698954\n",
      "\tspeed: 0.0522s/iter; left time: 1048.0807s\n",
      "\titers: 200, epoch: 11 | loss: 0.0665099\n",
      "\tspeed: 0.0253s/iter; left time: 504.3949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0712120 Vali Loss: 0.0733315 Test Loss: 0.1072205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0686331\n",
      "\tspeed: 0.0508s/iter; left time: 1006.8860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0743411\n",
      "\tspeed: 0.0328s/iter; left time: 646.4240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.0706372 Vali Loss: 0.0697939 Test Loss: 0.1047984\n",
      "Validation loss decreased (0.072065 --> 0.069794).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659835\n",
      "\tspeed: 0.0464s/iter; left time: 909.2170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0677568\n",
      "\tspeed: 0.0200s/iter; left time: 390.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0696442 Vali Loss: 0.0698661 Test Loss: 0.1043272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0699686\n",
      "\tspeed: 0.0471s/iter; left time: 912.9660s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682936\n",
      "\tspeed: 0.0290s/iter; left time: 560.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0691257 Vali Loss: 0.0687277 Test Loss: 0.1038685\n",
      "Validation loss decreased (0.069794 --> 0.068728).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0669770\n",
      "\tspeed: 0.0513s/iter; left time: 983.0608s\n",
      "\titers: 200, epoch: 15 | loss: 0.0678553\n",
      "\tspeed: 0.0275s/iter; left time: 523.8883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.0684012 Vali Loss: 0.0678756 Test Loss: 0.1020736\n",
      "Validation loss decreased (0.068728 --> 0.067876).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683907\n",
      "\tspeed: 0.0505s/iter; left time: 955.6475s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732732\n",
      "\tspeed: 0.0323s/iter; left time: 609.2564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0679654 Vali Loss: 0.0691879 Test Loss: 0.1037720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676069\n",
      "\tspeed: 0.0538s/iter; left time: 1006.7123s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683437\n",
      "\tspeed: 0.0306s/iter; left time: 568.8844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0671994 Vali Loss: 0.0691082 Test Loss: 0.1038079\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0656383\n",
      "\tspeed: 0.0441s/iter; left time: 815.5942s\n",
      "\titers: 200, epoch: 18 | loss: 0.0635727\n",
      "\tspeed: 0.0302s/iter; left time: 554.7012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0668719 Vali Loss: 0.0675755 Test Loss: 0.1024245\n",
      "Validation loss decreased (0.067876 --> 0.067575).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0701581\n",
      "\tspeed: 0.0478s/iter; left time: 873.3210s\n",
      "\titers: 200, epoch: 19 | loss: 0.0651758\n",
      "\tspeed: 0.0249s/iter; left time: 453.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0665310 Vali Loss: 0.0670448 Test Loss: 0.1016155\n",
      "Validation loss decreased (0.067575 --> 0.067045).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650204\n",
      "\tspeed: 0.0537s/iter; left time: 968.2629s\n",
      "\titers: 200, epoch: 20 | loss: 0.0690049\n",
      "\tspeed: 0.0213s/iter; left time: 382.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0662901 Vali Loss: 0.0665436 Test Loss: 0.1012922\n",
      "Validation loss decreased (0.067045 --> 0.066544).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0633304\n",
      "\tspeed: 0.0450s/iter; left time: 802.4789s\n",
      "\titers: 200, epoch: 21 | loss: 0.0639373\n",
      "\tspeed: 0.0250s/iter; left time: 443.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0659056 Vali Loss: 0.0669865 Test Loss: 0.1019292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0660514\n",
      "\tspeed: 0.0496s/iter; left time: 872.7001s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675453\n",
      "\tspeed: 0.0292s/iter; left time: 511.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0657710 Vali Loss: 0.0658909 Test Loss: 0.1013595\n",
      "Validation loss decreased (0.066544 --> 0.065891).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0646360\n",
      "\tspeed: 0.0479s/iter; left time: 832.7651s\n",
      "\titers: 200, epoch: 23 | loss: 0.0680110\n",
      "\tspeed: 0.0255s/iter; left time: 440.3148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0655204 Vali Loss: 0.0667306 Test Loss: 0.1016468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0681066\n",
      "\tspeed: 0.0412s/iter; left time: 706.0378s\n",
      "\titers: 200, epoch: 24 | loss: 0.0641213\n",
      "\tspeed: 0.0185s/iter; left time: 314.6488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0656101 Vali Loss: 0.0660954 Test Loss: 0.1008319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0655254\n",
      "\tspeed: 0.0477s/iter; left time: 807.6923s\n",
      "\titers: 200, epoch: 25 | loss: 0.0660068\n",
      "\tspeed: 0.0300s/iter; left time: 505.5732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0654672 Vali Loss: 0.0668781 Test Loss: 0.1022342\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0674711\n",
      "\tspeed: 0.0534s/iter; left time: 891.0352s\n",
      "\titers: 200, epoch: 26 | loss: 0.0628264\n",
      "\tspeed: 0.0329s/iter; left time: 545.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.0649984 Vali Loss: 0.0658987 Test Loss: 0.1010343\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0659415\n",
      "\tspeed: 0.0508s/iter; left time: 837.3028s\n",
      "\titers: 200, epoch: 27 | loss: 0.0643070\n",
      "\tspeed: 0.0285s/iter; left time: 466.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0647696 Vali Loss: 0.0659560 Test Loss: 0.1016795\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0640729\n",
      "\tspeed: 0.0518s/iter; left time: 842.4403s\n",
      "\titers: 200, epoch: 28 | loss: 0.0645919\n",
      "\tspeed: 0.0263s/iter; left time: 424.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0646356 Vali Loss: 0.0658097 Test Loss: 0.1015644\n",
      "Validation loss decreased (0.065891 --> 0.065810).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0642772\n",
      "\tspeed: 0.0498s/iter; left time: 798.8178s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669317\n",
      "\tspeed: 0.0253s/iter; left time: 403.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0644280 Vali Loss: 0.0660114 Test Loss: 0.1015665\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0638084\n",
      "\tspeed: 0.0454s/iter; left time: 717.6656s\n",
      "\titers: 200, epoch: 30 | loss: 0.0631353\n",
      "\tspeed: 0.0228s/iter; left time: 357.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0644141 Vali Loss: 0.0659180 Test Loss: 0.1013997\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0666470\n",
      "\tspeed: 0.0428s/iter; left time: 666.5318s\n",
      "\titers: 200, epoch: 31 | loss: 0.0665298\n",
      "\tspeed: 0.0284s/iter; left time: 439.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 224 | Train Loss: 0.0645211 Vali Loss: 0.0659544 Test Loss: 0.1014630\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0629742\n",
      "\tspeed: 0.0401s/iter; left time: 615.8064s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652767\n",
      "\tspeed: 0.0271s/iter; left time: 413.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0642155 Vali Loss: 0.0652419 Test Loss: 0.1006753\n",
      "Validation loss decreased (0.065810 --> 0.065242).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0628319\n",
      "\tspeed: 0.0433s/iter; left time: 654.5234s\n",
      "\titers: 200, epoch: 33 | loss: 0.0618343\n",
      "\tspeed: 0.0275s/iter; left time: 413.5834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0639915 Vali Loss: 0.0653936 Test Loss: 0.1014698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0651274\n",
      "\tspeed: 0.0507s/iter; left time: 755.7998s\n",
      "\titers: 200, epoch: 34 | loss: 0.0702499\n",
      "\tspeed: 0.0278s/iter; left time: 411.6589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0640727 Vali Loss: 0.0658022 Test Loss: 0.1017035\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0665580\n",
      "\tspeed: 0.0512s/iter; left time: 751.7685s\n",
      "\titers: 200, epoch: 35 | loss: 0.0658012\n",
      "\tspeed: 0.0243s/iter; left time: 353.7543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0639555 Vali Loss: 0.0649638 Test Loss: 0.1011087\n",
      "Validation loss decreased (0.065242 --> 0.064964).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0636807\n",
      "\tspeed: 0.0437s/iter; left time: 631.8062s\n",
      "\titers: 200, epoch: 36 | loss: 0.0623572\n",
      "\tspeed: 0.0231s/iter; left time: 331.3521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0641383 Vali Loss: 0.0654300 Test Loss: 0.1013117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0685234\n",
      "\tspeed: 0.0402s/iter; left time: 572.3307s\n",
      "\titers: 200, epoch: 37 | loss: 0.0615247\n",
      "\tspeed: 0.0229s/iter; left time: 323.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0638891 Vali Loss: 0.0648668 Test Loss: 0.1004111\n",
      "Validation loss decreased (0.064964 --> 0.064867).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0656367\n",
      "\tspeed: 0.0496s/iter; left time: 694.7537s\n",
      "\titers: 200, epoch: 38 | loss: 0.0627297\n",
      "\tspeed: 0.0217s/iter; left time: 302.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0639694 Vali Loss: 0.0649113 Test Loss: 0.1009206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0670442\n",
      "\tspeed: 0.0476s/iter; left time: 656.3605s\n",
      "\titers: 200, epoch: 39 | loss: 0.0639190\n",
      "\tspeed: 0.0243s/iter; left time: 332.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0636989 Vali Loss: 0.0647521 Test Loss: 0.1009166\n",
      "Validation loss decreased (0.064867 --> 0.064752).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0649622\n",
      "\tspeed: 0.0531s/iter; left time: 719.6788s\n",
      "\titers: 200, epoch: 40 | loss: 0.0642344\n",
      "\tspeed: 0.0342s/iter; left time: 460.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0636871 Vali Loss: 0.0649498 Test Loss: 0.1014287\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0585922\n",
      "\tspeed: 0.0517s/iter; left time: 690.1023s\n",
      "\titers: 200, epoch: 41 | loss: 0.0635951\n",
      "\tspeed: 0.0257s/iter; left time: 339.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0636943 Vali Loss: 0.0649515 Test Loss: 0.1008845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0609365\n",
      "\tspeed: 0.0420s/iter; left time: 551.1302s\n",
      "\titers: 200, epoch: 42 | loss: 0.0662186\n",
      "\tspeed: 0.0207s/iter; left time: 269.6130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0636066 Vali Loss: 0.0648387 Test Loss: 0.1012458\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0623102\n",
      "\tspeed: 0.0477s/iter; left time: 614.5220s\n",
      "\titers: 200, epoch: 43 | loss: 0.0607994\n",
      "\tspeed: 0.0196s/iter; left time: 250.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0635751 Vali Loss: 0.0647221 Test Loss: 0.1007499\n",
      "Validation loss decreased (0.064752 --> 0.064722).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0623095\n",
      "\tspeed: 0.0426s/iter; left time: 540.1574s\n",
      "\titers: 200, epoch: 44 | loss: 0.0660763\n",
      "\tspeed: 0.0287s/iter; left time: 360.5862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0636124 Vali Loss: 0.0648727 Test Loss: 0.1004938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0678190\n",
      "\tspeed: 0.0504s/iter; left time: 627.3116s\n",
      "\titers: 200, epoch: 45 | loss: 0.0656337\n",
      "\tspeed: 0.0286s/iter; left time: 353.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0638234 Vali Loss: 0.0648475 Test Loss: 0.1010252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0684078\n",
      "\tspeed: 0.0521s/iter; left time: 636.6137s\n",
      "\titers: 200, epoch: 46 | loss: 0.0643564\n",
      "\tspeed: 0.0204s/iter; left time: 247.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0635598 Vali Loss: 0.0652909 Test Loss: 0.1009665\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0625631\n",
      "\tspeed: 0.0460s/iter; left time: 552.3441s\n",
      "\titers: 200, epoch: 47 | loss: 0.0629460\n",
      "\tspeed: 0.0212s/iter; left time: 252.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0633864 Vali Loss: 0.0646350 Test Loss: 0.1004219\n",
      "Validation loss decreased (0.064722 --> 0.064635).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642017\n",
      "\tspeed: 0.0421s/iter; left time: 495.6000s\n",
      "\titers: 200, epoch: 48 | loss: 0.0626430\n",
      "\tspeed: 0.0197s/iter; left time: 229.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0634296 Vali Loss: 0.0649049 Test Loss: 0.1012002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0625103\n",
      "\tspeed: 0.0527s/iter; left time: 609.1420s\n",
      "\titers: 200, epoch: 49 | loss: 0.0627242\n",
      "\tspeed: 0.0280s/iter; left time: 320.7321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0636284 Vali Loss: 0.0645291 Test Loss: 0.1007772\n",
      "Validation loss decreased (0.064635 --> 0.064529).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0618800\n",
      "\tspeed: 0.0439s/iter; left time: 497.0523s\n",
      "\titers: 200, epoch: 50 | loss: 0.0617399\n",
      "\tspeed: 0.0192s/iter; left time: 215.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0634818 Vali Loss: 0.0649657 Test Loss: 0.1011216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0632932\n",
      "\tspeed: 0.0490s/iter; left time: 543.5405s\n",
      "\titers: 200, epoch: 51 | loss: 0.0633144\n",
      "\tspeed: 0.0281s/iter; left time: 309.5736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0634839 Vali Loss: 0.0645256 Test Loss: 0.1008154\n",
      "Validation loss decreased (0.064529 --> 0.064526).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0619102\n",
      "\tspeed: 0.0487s/iter; left time: 529.5385s\n",
      "\titers: 200, epoch: 52 | loss: 0.0653005\n",
      "\tspeed: 0.0310s/iter; left time: 333.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0635737 Vali Loss: 0.0646385 Test Loss: 0.1007390\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0662170\n",
      "\tspeed: 0.0451s/iter; left time: 480.3393s\n",
      "\titers: 200, epoch: 53 | loss: 0.0630821\n",
      "\tspeed: 0.0219s/iter; left time: 231.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0634784 Vali Loss: 0.0647814 Test Loss: 0.1008245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0637030\n",
      "\tspeed: 0.0467s/iter; left time: 486.5544s\n",
      "\titers: 200, epoch: 54 | loss: 0.0657747\n",
      "\tspeed: 0.0236s/iter; left time: 243.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0635465 Vali Loss: 0.0647490 Test Loss: 0.1012427\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0638304\n",
      "\tspeed: 0.0492s/iter; left time: 501.9606s\n",
      "\titers: 200, epoch: 55 | loss: 0.0716538\n",
      "\tspeed: 0.0227s/iter; left time: 229.2381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0634507 Vali Loss: 0.0644673 Test Loss: 0.1007830\n",
      "Validation loss decreased (0.064526 --> 0.064467).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0635443\n",
      "\tspeed: 0.0436s/iter; left time: 435.3271s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632219\n",
      "\tspeed: 0.0192s/iter; left time: 189.3725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0635071 Vali Loss: 0.0648806 Test Loss: 0.1011156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0633882\n",
      "\tspeed: 0.0480s/iter; left time: 468.6952s\n",
      "\titers: 200, epoch: 57 | loss: 0.0644305\n",
      "\tspeed: 0.0285s/iter; left time: 274.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0634712 Vali Loss: 0.0647682 Test Loss: 0.1010359\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0677133\n",
      "\tspeed: 0.0516s/iter; left time: 492.0400s\n",
      "\titers: 200, epoch: 58 | loss: 0.0622730\n",
      "\tspeed: 0.0305s/iter; left time: 288.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0635770 Vali Loss: 0.0648909 Test Loss: 0.1011137\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0647755\n",
      "\tspeed: 0.0525s/iter; left time: 488.8162s\n",
      "\titers: 200, epoch: 59 | loss: 0.0640108\n",
      "\tspeed: 0.0338s/iter; left time: 311.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0633546 Vali Loss: 0.0646461 Test Loss: 0.1007700\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0615887\n",
      "\tspeed: 0.0492s/iter; left time: 447.0138s\n",
      "\titers: 200, epoch: 60 | loss: 0.0641040\n",
      "\tspeed: 0.0222s/iter; left time: 199.2100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0633609 Vali Loss: 0.0651419 Test Loss: 0.1010978\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0589076\n",
      "\tspeed: 0.0400s/iter; left time: 354.6384s\n",
      "\titers: 200, epoch: 61 | loss: 0.0619601\n",
      "\tspeed: 0.0201s/iter; left time: 176.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0633997 Vali Loss: 0.0646903 Test Loss: 0.1009743\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0648482\n",
      "\tspeed: 0.0438s/iter; left time: 378.2528s\n",
      "\titers: 200, epoch: 62 | loss: 0.0620727\n",
      "\tspeed: 0.0357s/iter; left time: 305.0582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0634796 Vali Loss: 0.0646930 Test Loss: 0.1007531\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0686262\n",
      "\tspeed: 0.0519s/iter; left time: 436.2977s\n",
      "\titers: 200, epoch: 63 | loss: 0.0640989\n",
      "\tspeed: 0.0202s/iter; left time: 168.3330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0634430 Vali Loss: 0.0645974 Test Loss: 0.1008506\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0597929\n",
      "\tspeed: 0.0473s/iter; left time: 387.3679s\n",
      "\titers: 200, epoch: 64 | loss: 0.0629649\n",
      "\tspeed: 0.0248s/iter; left time: 200.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0633535 Vali Loss: 0.0650004 Test Loss: 0.1014543\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0681462\n",
      "\tspeed: 0.0515s/iter; left time: 410.0934s\n",
      "\titers: 200, epoch: 65 | loss: 0.0621376\n",
      "\tspeed: 0.0222s/iter; left time: 174.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0633774 Vali Loss: 0.0642208 Test Loss: 0.1003869\n",
      "Validation loss decreased (0.064467 --> 0.064221).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0609806\n",
      "\tspeed: 0.0502s/iter; left time: 388.3267s\n",
      "\titers: 200, epoch: 66 | loss: 0.0662504\n",
      "\tspeed: 0.0334s/iter; left time: 255.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.0633659 Vali Loss: 0.0646943 Test Loss: 0.1010537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0624667\n",
      "\tspeed: 0.0576s/iter; left time: 432.9816s\n",
      "\titers: 200, epoch: 67 | loss: 0.0644781\n",
      "\tspeed: 0.0351s/iter; left time: 260.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0634545 Vali Loss: 0.0643207 Test Loss: 0.1006207\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0647675\n",
      "\tspeed: 0.0495s/iter; left time: 360.9515s\n",
      "\titers: 200, epoch: 68 | loss: 0.0612408\n",
      "\tspeed: 0.0276s/iter; left time: 198.2585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0634667 Vali Loss: 0.0646112 Test Loss: 0.1007740\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0601714\n",
      "\tspeed: 0.0486s/iter; left time: 343.6747s\n",
      "\titers: 200, epoch: 69 | loss: 0.0600936\n",
      "\tspeed: 0.0229s/iter; left time: 159.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0633030 Vali Loss: 0.0647055 Test Loss: 0.1009937\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0598235\n",
      "\tspeed: 0.0455s/iter; left time: 311.6769s\n",
      "\titers: 200, epoch: 70 | loss: 0.0598404\n",
      "\tspeed: 0.0247s/iter; left time: 166.5738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0633078 Vali Loss: 0.0647701 Test Loss: 0.1008490\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0657412\n",
      "\tspeed: 0.0503s/iter; left time: 332.9819s\n",
      "\titers: 200, epoch: 71 | loss: 0.0621673\n",
      "\tspeed: 0.0278s/iter; left time: 181.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0633967 Vali Loss: 0.0646620 Test Loss: 0.1007677\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0640415\n",
      "\tspeed: 0.0449s/iter; left time: 287.3925s\n",
      "\titers: 200, epoch: 72 | loss: 0.0624191\n",
      "\tspeed: 0.0311s/iter; left time: 195.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0633975 Vali Loss: 0.0646872 Test Loss: 0.1010092\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0608905\n",
      "\tspeed: 0.0537s/iter; left time: 331.7015s\n",
      "\titers: 200, epoch: 73 | loss: 0.0651923\n",
      "\tspeed: 0.0251s/iter; left time: 152.3634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0634649 Vali Loss: 0.0644777 Test Loss: 0.1007998\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0603427\n",
      "\tspeed: 0.0445s/iter; left time: 264.5174s\n",
      "\titers: 200, epoch: 74 | loss: 0.0623979\n",
      "\tspeed: 0.0277s/iter; left time: 161.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0633507 Vali Loss: 0.0644742 Test Loss: 0.1006727\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0624362\n",
      "\tspeed: 0.0493s/iter; left time: 282.5247s\n",
      "\titers: 200, epoch: 75 | loss: 0.0609980\n",
      "\tspeed: 0.0258s/iter; left time: 145.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.0633324 Vali Loss: 0.0649735 Test Loss: 0.1009498\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.031472545117139816, rmse:0.17740502953529358, mae:0.10038686543703079, rse:0.5220815539360046\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3241769\n",
      "\tspeed: 0.0272s/iter; left time: 607.4943s\n",
      "\titers: 200, epoch: 1 | loss: 0.3048048\n",
      "\tspeed: 0.0303s/iter; left time: 673.7145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.3319817 Vali Loss: 0.2277038 Test Loss: 0.2410462\n",
      "Validation loss decreased (inf --> 0.227704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1846789\n",
      "\tspeed: 0.0463s/iter; left time: 1022.6292s\n",
      "\titers: 200, epoch: 2 | loss: 0.1317482\n",
      "\tspeed: 0.0271s/iter; left time: 594.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.1852016 Vali Loss: 0.0983671 Test Loss: 0.1283587\n",
      "Validation loss decreased (0.227704 --> 0.098367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1130777\n",
      "\tspeed: 0.0414s/iter; left time: 904.6886s\n",
      "\titers: 200, epoch: 3 | loss: 0.1067166\n",
      "\tspeed: 0.0191s/iter; left time: 414.4431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1110824 Vali Loss: 0.0903586 Test Loss: 0.1223708\n",
      "Validation loss decreased (0.098367 --> 0.090359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962664\n",
      "\tspeed: 0.0451s/iter; left time: 975.5229s\n",
      "\titers: 200, epoch: 4 | loss: 0.0946903\n",
      "\tspeed: 0.0289s/iter; left time: 622.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0969929 Vali Loss: 0.0883349 Test Loss: 0.1230320\n",
      "Validation loss decreased (0.090359 --> 0.088335).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867227\n",
      "\tspeed: 0.0443s/iter; left time: 947.6614s\n",
      "\titers: 200, epoch: 5 | loss: 0.0863924\n",
      "\tspeed: 0.0205s/iter; left time: 436.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0880201 Vali Loss: 0.0833577 Test Loss: 0.1233900\n",
      "Validation loss decreased (0.088335 --> 0.083358).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0803946\n",
      "\tspeed: 0.0513s/iter; left time: 1085.9096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745023\n",
      "\tspeed: 0.0351s/iter; left time: 739.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0817276 Vali Loss: 0.0777255 Test Loss: 0.1144499\n",
      "Validation loss decreased (0.083358 --> 0.077726).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739422\n",
      "\tspeed: 0.0556s/iter; left time: 1165.4845s\n",
      "\titers: 200, epoch: 7 | loss: 0.0748082\n",
      "\tspeed: 0.0282s/iter; left time: 587.2086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0762473 Test Loss: 0.1122295\n",
      "Validation loss decreased (0.077726 --> 0.076247).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778073\n",
      "\tspeed: 0.0531s/iter; left time: 1101.7687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0770221\n",
      "\tspeed: 0.0263s/iter; left time: 542.6999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0758099 Vali Loss: 0.0755910 Test Loss: 0.1106603\n",
      "Validation loss decreased (0.076247 --> 0.075591).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0682038\n",
      "\tspeed: 0.0418s/iter; left time: 857.8036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788855\n",
      "\tspeed: 0.0184s/iter; left time: 376.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0737668 Vali Loss: 0.0738813 Test Loss: 0.1062540\n",
      "Validation loss decreased (0.075591 --> 0.073881).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0659325\n",
      "\tspeed: 0.0496s/iter; left time: 1006.6490s\n",
      "\titers: 200, epoch: 10 | loss: 0.0745965\n",
      "\tspeed: 0.0303s/iter; left time: 612.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0725167 Vali Loss: 0.0738356 Test Loss: 0.1059817\n",
      "Validation loss decreased (0.073881 --> 0.073836).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0690716\n",
      "\tspeed: 0.0537s/iter; left time: 1078.0730s\n",
      "\titers: 200, epoch: 11 | loss: 0.0715816\n",
      "\tspeed: 0.0288s/iter; left time: 574.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0720637 Vali Loss: 0.0713157 Test Loss: 0.1048945\n",
      "Validation loss decreased (0.073836 --> 0.071316).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0711451\n",
      "\tspeed: 0.0500s/iter; left time: 992.2878s\n",
      "\titers: 200, epoch: 12 | loss: 0.0765447\n",
      "\tspeed: 0.0222s/iter; left time: 437.9004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0705693 Vali Loss: 0.0697029 Test Loss: 0.1029371\n",
      "Validation loss decreased (0.071316 --> 0.069703).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0665726\n",
      "\tspeed: 0.0465s/iter; left time: 911.7472s\n",
      "\titers: 200, epoch: 13 | loss: 0.0718739\n",
      "\tspeed: 0.0260s/iter; left time: 507.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0697683 Vali Loss: 0.0724146 Test Loss: 0.1052417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0693825\n",
      "\tspeed: 0.0491s/iter; left time: 952.3799s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718139\n",
      "\tspeed: 0.0279s/iter; left time: 539.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.0689197 Vali Loss: 0.0681453 Test Loss: 0.1013831\n",
      "Validation loss decreased (0.069703 --> 0.068145).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0648288\n",
      "\tspeed: 0.0480s/iter; left time: 920.5433s\n",
      "\titers: 200, epoch: 15 | loss: 0.0772392\n",
      "\tspeed: 0.0213s/iter; left time: 406.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0682759 Vali Loss: 0.0687444 Test Loss: 0.1019346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0679195\n",
      "\tspeed: 0.0428s/iter; left time: 811.2370s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735221\n",
      "\tspeed: 0.0215s/iter; left time: 405.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0677724 Vali Loss: 0.0672212 Test Loss: 0.1013704\n",
      "Validation loss decreased (0.068145 --> 0.067221).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0677237\n",
      "\tspeed: 0.0513s/iter; left time: 959.5913s\n",
      "\titers: 200, epoch: 17 | loss: 0.0665844\n",
      "\tspeed: 0.0210s/iter; left time: 390.8195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0674167 Vali Loss: 0.0674030 Test Loss: 0.1009903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0654061\n",
      "\tspeed: 0.0502s/iter; left time: 928.2840s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666033\n",
      "\tspeed: 0.0304s/iter; left time: 558.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0668446 Vali Loss: 0.0672831 Test Loss: 0.1016099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0656774\n",
      "\tspeed: 0.0434s/iter; left time: 793.5453s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678768\n",
      "\tspeed: 0.0204s/iter; left time: 371.0753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0664313 Vali Loss: 0.0660761 Test Loss: 0.1010217\n",
      "Validation loss decreased (0.067221 --> 0.066076).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0664179\n",
      "\tspeed: 0.0393s/iter; left time: 709.4398s\n",
      "\titers: 200, epoch: 20 | loss: 0.0735990\n",
      "\tspeed: 0.0184s/iter; left time: 330.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0664211 Vali Loss: 0.0659928 Test Loss: 0.0994369\n",
      "Validation loss decreased (0.066076 --> 0.065993).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0645930\n",
      "\tspeed: 0.0475s/iter; left time: 847.0158s\n",
      "\titers: 200, epoch: 21 | loss: 0.0671003\n",
      "\tspeed: 0.0241s/iter; left time: 427.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0660253 Vali Loss: 0.0651813 Test Loss: 0.0995244\n",
      "Validation loss decreased (0.065993 --> 0.065181).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0692862\n",
      "\tspeed: 0.0505s/iter; left time: 888.7810s\n",
      "\titers: 200, epoch: 22 | loss: 0.0659073\n",
      "\tspeed: 0.0295s/iter; left time: 516.6359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0656233 Vali Loss: 0.0654922 Test Loss: 0.0992766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619575\n",
      "\tspeed: 0.0459s/iter; left time: 797.6171s\n",
      "\titers: 200, epoch: 23 | loss: 0.0627966\n",
      "\tspeed: 0.0250s/iter; left time: 431.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0654819 Vali Loss: 0.0648803 Test Loss: 0.0989769\n",
      "Validation loss decreased (0.065181 --> 0.064880).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0640931\n",
      "\tspeed: 0.0534s/iter; left time: 916.5670s\n",
      "\titers: 200, epoch: 24 | loss: 0.0666161\n",
      "\tspeed: 0.0308s/iter; left time: 524.9860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0652593 Vali Loss: 0.0655791 Test Loss: 0.0999375\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0752450\n",
      "\tspeed: 0.0508s/iter; left time: 860.2915s\n",
      "\titers: 200, epoch: 25 | loss: 0.0635773\n",
      "\tspeed: 0.0283s/iter; left time: 476.6150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0651366 Vali Loss: 0.0655463 Test Loss: 0.1002289\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654816\n",
      "\tspeed: 0.0584s/iter; left time: 974.5639s\n",
      "\titers: 200, epoch: 26 | loss: 0.0673981\n",
      "\tspeed: 0.0358s/iter; left time: 594.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0649291 Vali Loss: 0.0646631 Test Loss: 0.0985801\n",
      "Validation loss decreased (0.064880 --> 0.064663).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0646367\n",
      "\tspeed: 0.0443s/iter; left time: 729.1165s\n",
      "\titers: 200, epoch: 27 | loss: 0.0673261\n",
      "\tspeed: 0.0295s/iter; left time: 482.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0649199 Vali Loss: 0.0662691 Test Loss: 0.1003278\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0632755\n",
      "\tspeed: 0.0490s/iter; left time: 795.9528s\n",
      "\titers: 200, epoch: 28 | loss: 0.0655193\n",
      "\tspeed: 0.0243s/iter; left time: 392.9199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0647685 Vali Loss: 0.0646451 Test Loss: 0.0989119\n",
      "Validation loss decreased (0.064663 --> 0.064645).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0634681\n",
      "\tspeed: 0.0500s/iter; left time: 801.6498s\n",
      "\titers: 200, epoch: 29 | loss: 0.0626431\n",
      "\tspeed: 0.0302s/iter; left time: 481.7867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0644110 Vali Loss: 0.0643680 Test Loss: 0.0980134\n",
      "Validation loss decreased (0.064645 --> 0.064368).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0640724\n",
      "\tspeed: 0.0541s/iter; left time: 855.7145s\n",
      "\titers: 200, epoch: 30 | loss: 0.0642630\n",
      "\tspeed: 0.0278s/iter; left time: 435.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0644422 Vali Loss: 0.0646038 Test Loss: 0.0983605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0628087\n",
      "\tspeed: 0.0442s/iter; left time: 689.4449s\n",
      "\titers: 200, epoch: 31 | loss: 0.0646476\n",
      "\tspeed: 0.0270s/iter; left time: 417.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0644961 Vali Loss: 0.0650900 Test Loss: 0.0992738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0663295\n",
      "\tspeed: 0.0513s/iter; left time: 787.0910s\n",
      "\titers: 200, epoch: 32 | loss: 0.0698967\n",
      "\tspeed: 0.0303s/iter; left time: 461.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0644780 Vali Loss: 0.0652776 Test Loss: 0.1002855\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0680299\n",
      "\tspeed: 0.0519s/iter; left time: 785.5287s\n",
      "\titers: 200, epoch: 33 | loss: 0.0632683\n",
      "\tspeed: 0.0292s/iter; left time: 438.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0642261 Vali Loss: 0.0644184 Test Loss: 0.0984323\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0633708\n",
      "\tspeed: 0.0425s/iter; left time: 634.0489s\n",
      "\titers: 200, epoch: 34 | loss: 0.0636550\n",
      "\tspeed: 0.0256s/iter; left time: 378.9679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0643358 Vali Loss: 0.0642165 Test Loss: 0.0976166\n",
      "Validation loss decreased (0.064368 --> 0.064217).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0622609\n",
      "\tspeed: 0.0431s/iter; left time: 632.5055s\n",
      "\titers: 200, epoch: 35 | loss: 0.0669887\n",
      "\tspeed: 0.0199s/iter; left time: 290.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0640298 Vali Loss: 0.0642502 Test Loss: 0.0977860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0617984\n",
      "\tspeed: 0.0411s/iter; left time: 594.6550s\n",
      "\titers: 200, epoch: 36 | loss: 0.0603308\n",
      "\tspeed: 0.0199s/iter; left time: 285.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0641043 Vali Loss: 0.0644300 Test Loss: 0.0984703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0660640\n",
      "\tspeed: 0.0475s/iter; left time: 676.1163s\n",
      "\titers: 200, epoch: 37 | loss: 0.0617804\n",
      "\tspeed: 0.0295s/iter; left time: 416.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0641928 Vali Loss: 0.0641485 Test Loss: 0.0982216\n",
      "Validation loss decreased (0.064217 --> 0.064149).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0655331\n",
      "\tspeed: 0.0443s/iter; left time: 620.8322s\n",
      "\titers: 200, epoch: 38 | loss: 0.0623262\n",
      "\tspeed: 0.0264s/iter; left time: 366.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0640737 Vali Loss: 0.0644866 Test Loss: 0.0978939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0651701\n",
      "\tspeed: 0.0462s/iter; left time: 637.0135s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607268\n",
      "\tspeed: 0.0288s/iter; left time: 394.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0639368 Vali Loss: 0.0642508 Test Loss: 0.0982810\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0678480\n",
      "\tspeed: 0.0439s/iter; left time: 596.0555s\n",
      "\titers: 200, epoch: 40 | loss: 0.0652640\n",
      "\tspeed: 0.0282s/iter; left time: 379.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0639468 Vali Loss: 0.0643388 Test Loss: 0.0986030\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0664952\n",
      "\tspeed: 0.0468s/iter; left time: 624.8525s\n",
      "\titers: 200, epoch: 41 | loss: 0.0627219\n",
      "\tspeed: 0.0246s/iter; left time: 325.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0639860 Vali Loss: 0.0644605 Test Loss: 0.0988706\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0637797\n",
      "\tspeed: 0.0459s/iter; left time: 602.1883s\n",
      "\titers: 200, epoch: 42 | loss: 0.0733285\n",
      "\tspeed: 0.0222s/iter; left time: 288.6892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0638120 Vali Loss: 0.0644499 Test Loss: 0.0993398\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0619016\n",
      "\tspeed: 0.0475s/iter; left time: 612.3472s\n",
      "\titers: 200, epoch: 43 | loss: 0.0628845\n",
      "\tspeed: 0.0239s/iter; left time: 305.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0638302 Vali Loss: 0.0643849 Test Loss: 0.0991613\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0613818\n",
      "\tspeed: 0.0437s/iter; left time: 554.2063s\n",
      "\titers: 200, epoch: 44 | loss: 0.0637549\n",
      "\tspeed: 0.0214s/iter; left time: 269.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0638270 Vali Loss: 0.0640869 Test Loss: 0.0980290\n",
      "Validation loss decreased (0.064149 --> 0.064087).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0626596\n",
      "\tspeed: 0.0499s/iter; left time: 621.4979s\n",
      "\titers: 200, epoch: 45 | loss: 0.0653235\n",
      "\tspeed: 0.0254s/iter; left time: 313.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0637858 Vali Loss: 0.0640770 Test Loss: 0.0982585\n",
      "Validation loss decreased (0.064087 --> 0.064077).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0634499\n",
      "\tspeed: 0.0488s/iter; left time: 595.9167s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663941\n",
      "\tspeed: 0.0276s/iter; left time: 334.4179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0636097 Vali Loss: 0.0640897 Test Loss: 0.0982788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0632404\n",
      "\tspeed: 0.0540s/iter; left time: 647.9712s\n",
      "\titers: 200, epoch: 47 | loss: 0.0621434\n",
      "\tspeed: 0.0332s/iter; left time: 395.0636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0637268 Vali Loss: 0.0640484 Test Loss: 0.0982510\n",
      "Validation loss decreased (0.064077 --> 0.064048).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0679519\n",
      "\tspeed: 0.0464s/iter; left time: 545.9466s\n",
      "\titers: 200, epoch: 48 | loss: 0.0608564\n",
      "\tspeed: 0.0215s/iter; left time: 251.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0637348 Vali Loss: 0.0646517 Test Loss: 0.0998076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0661630\n",
      "\tspeed: 0.0423s/iter; left time: 488.0148s\n",
      "\titers: 200, epoch: 49 | loss: 0.0649328\n",
      "\tspeed: 0.0334s/iter; left time: 382.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0637707 Vali Loss: 0.0641371 Test Loss: 0.0986539\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0646921\n",
      "\tspeed: 0.0447s/iter; left time: 506.3147s\n",
      "\titers: 200, epoch: 50 | loss: 0.0640158\n",
      "\tspeed: 0.0216s/iter; left time: 242.6168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0637090 Vali Loss: 0.0642349 Test Loss: 0.0989493\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0649522\n",
      "\tspeed: 0.0476s/iter; left time: 528.4591s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630405\n",
      "\tspeed: 0.0300s/iter; left time: 329.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0636658 Vali Loss: 0.0642765 Test Loss: 0.0989214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0640234\n",
      "\tspeed: 0.0499s/iter; left time: 543.3035s\n",
      "\titers: 200, epoch: 52 | loss: 0.0648404\n",
      "\tspeed: 0.0262s/iter; left time: 282.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0637223 Vali Loss: 0.0642281 Test Loss: 0.0985588\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0628499\n",
      "\tspeed: 0.0487s/iter; left time: 518.6429s\n",
      "\titers: 200, epoch: 53 | loss: 0.0633499\n",
      "\tspeed: 0.0288s/iter; left time: 304.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0636616 Vali Loss: 0.0641439 Test Loss: 0.0982769\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0623522\n",
      "\tspeed: 0.0423s/iter; left time: 441.0180s\n",
      "\titers: 200, epoch: 54 | loss: 0.0639970\n",
      "\tspeed: 0.0198s/iter; left time: 204.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0636764 Vali Loss: 0.0638565 Test Loss: 0.0972804\n",
      "Validation loss decreased (0.064048 --> 0.063857).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0608114\n",
      "\tspeed: 0.0511s/iter; left time: 521.2757s\n",
      "\titers: 200, epoch: 55 | loss: 0.0671813\n",
      "\tspeed: 0.0307s/iter; left time: 310.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0636212 Vali Loss: 0.0641153 Test Loss: 0.0983178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0664187\n",
      "\tspeed: 0.0541s/iter; left time: 539.8359s\n",
      "\titers: 200, epoch: 56 | loss: 0.0674015\n",
      "\tspeed: 0.0300s/iter; left time: 296.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0636044 Vali Loss: 0.0642906 Test Loss: 0.0991021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0631292\n",
      "\tspeed: 0.0442s/iter; left time: 431.3650s\n",
      "\titers: 200, epoch: 57 | loss: 0.0608751\n",
      "\tspeed: 0.0200s/iter; left time: 192.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0635871 Vali Loss: 0.0641562 Test Loss: 0.0986072\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598121\n",
      "\tspeed: 0.0474s/iter; left time: 452.0313s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604325\n",
      "\tspeed: 0.0253s/iter; left time: 238.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0635992 Vali Loss: 0.0640185 Test Loss: 0.0980019\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0630739\n",
      "\tspeed: 0.0547s/iter; left time: 508.8386s\n",
      "\titers: 200, epoch: 59 | loss: 0.0625360\n",
      "\tspeed: 0.0290s/iter; left time: 266.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0635345 Vali Loss: 0.0640331 Test Loss: 0.0982697\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0678649\n",
      "\tspeed: 0.0460s/iter; left time: 417.5217s\n",
      "\titers: 200, epoch: 60 | loss: 0.0617192\n",
      "\tspeed: 0.0184s/iter; left time: 165.4957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0636586 Vali Loss: 0.0640161 Test Loss: 0.0980275\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0643174\n",
      "\tspeed: 0.0425s/iter; left time: 376.9863s\n",
      "\titers: 200, epoch: 61 | loss: 0.0665022\n",
      "\tspeed: 0.0224s/iter; left time: 196.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0635503 Vali Loss: 0.0640726 Test Loss: 0.0982651\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0651306\n",
      "\tspeed: 0.0455s/iter; left time: 393.0306s\n",
      "\titers: 200, epoch: 62 | loss: 0.0605059\n",
      "\tspeed: 0.0289s/iter; left time: 246.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0635559 Vali Loss: 0.0640661 Test Loss: 0.0982541\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0633171\n",
      "\tspeed: 0.0453s/iter; left time: 381.2840s\n",
      "\titers: 200, epoch: 63 | loss: 0.0634034\n",
      "\tspeed: 0.0328s/iter; left time: 272.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0636188 Vali Loss: 0.0640873 Test Loss: 0.0985330\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0649221\n",
      "\tspeed: 0.0436s/iter; left time: 356.8367s\n",
      "\titers: 200, epoch: 64 | loss: 0.0653537\n",
      "\tspeed: 0.0225s/iter; left time: 182.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0635586 Vali Loss: 0.0642710 Test Loss: 0.0991261\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028938475996255875, rmse:0.17011313140392303, mae:0.0972803607583046, rse:0.5006223320960999\n",
      "Intermediate time for ES and pred_len 24: 00h:17m:16.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3315652\n",
      "\tspeed: 0.0431s/iter; left time: 960.9836s\n",
      "\titers: 200, epoch: 1 | loss: 0.3048264\n",
      "\tspeed: 0.0208s/iter; left time: 460.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.3371278 Vali Loss: 0.2310152 Test Loss: 0.2483150\n",
      "Validation loss decreased (inf --> 0.231015).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1515196\n",
      "\tspeed: 0.0435s/iter; left time: 960.7277s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261632\n",
      "\tspeed: 0.0232s/iter; left time: 509.2304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.1680064 Vali Loss: 0.1113563 Test Loss: 0.1466127\n",
      "Validation loss decreased (0.231015 --> 0.111356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156678\n",
      "\tspeed: 0.0451s/iter; left time: 985.2617s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112574\n",
      "\tspeed: 0.0274s/iter; left time: 596.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.1180376 Vali Loss: 0.1046258 Test Loss: 0.1426476\n",
      "Validation loss decreased (0.111356 --> 0.104626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1120634\n",
      "\tspeed: 0.0469s/iter; left time: 1015.2418s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007832\n",
      "\tspeed: 0.0287s/iter; left time: 617.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1083790 Vali Loss: 0.1060640 Test Loss: 0.1551398\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0995809\n",
      "\tspeed: 0.0500s/iter; left time: 1070.5716s\n",
      "\titers: 200, epoch: 5 | loss: 0.0972068\n",
      "\tspeed: 0.0252s/iter; left time: 537.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.1011719 Vali Loss: 0.1020747 Test Loss: 0.1501847\n",
      "Validation loss decreased (0.104626 --> 0.102075).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1011587\n",
      "\tspeed: 0.0505s/iter; left time: 1070.0115s\n",
      "\titers: 200, epoch: 6 | loss: 0.0956222\n",
      "\tspeed: 0.0349s/iter; left time: 735.3486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0965476 Vali Loss: 0.0971423 Test Loss: 0.1451695\n",
      "Validation loss decreased (0.102075 --> 0.097142).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0902083\n",
      "\tspeed: 0.0565s/iter; left time: 1183.7290s\n",
      "\titers: 200, epoch: 7 | loss: 0.0930668\n",
      "\tspeed: 0.0239s/iter; left time: 498.5694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0940820 Vali Loss: 0.0942421 Test Loss: 0.1400523\n",
      "Validation loss decreased (0.097142 --> 0.094242).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0921565\n",
      "\tspeed: 0.0510s/iter; left time: 1057.4413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0899937\n",
      "\tspeed: 0.0221s/iter; left time: 455.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0912714 Vali Loss: 0.0915773 Test Loss: 0.1377201\n",
      "Validation loss decreased (0.094242 --> 0.091577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0887518\n",
      "\tspeed: 0.0531s/iter; left time: 1088.2041s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869254\n",
      "\tspeed: 0.0280s/iter; left time: 572.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0903758 Vali Loss: 0.0894141 Test Loss: 0.1365595\n",
      "Validation loss decreased (0.091577 --> 0.089414).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0930247\n",
      "\tspeed: 0.0512s/iter; left time: 1038.2857s\n",
      "\titers: 200, epoch: 10 | loss: 0.0881074\n",
      "\tspeed: 0.0209s/iter; left time: 422.0468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0888782 Vali Loss: 0.0888946 Test Loss: 0.1372542\n",
      "Validation loss decreased (0.089414 --> 0.088895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0862355\n",
      "\tspeed: 0.0512s/iter; left time: 1027.0138s\n",
      "\titers: 200, epoch: 11 | loss: 0.0870282\n",
      "\tspeed: 0.0244s/iter; left time: 487.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0880042 Vali Loss: 0.0889236 Test Loss: 0.1354891\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0872819\n",
      "\tspeed: 0.0528s/iter; left time: 1048.2450s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861812\n",
      "\tspeed: 0.0251s/iter; left time: 495.8817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0872007 Vali Loss: 0.0884258 Test Loss: 0.1340075\n",
      "Validation loss decreased (0.088895 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0887255\n",
      "\tspeed: 0.0480s/iter; left time: 940.9583s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851904\n",
      "\tspeed: 0.0215s/iter; left time: 418.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0865768 Vali Loss: 0.0902111 Test Loss: 0.1376934\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0846166\n",
      "\tspeed: 0.0475s/iter; left time: 920.3132s\n",
      "\titers: 200, epoch: 14 | loss: 0.0883543\n",
      "\tspeed: 0.0253s/iter; left time: 488.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0861572 Vali Loss: 0.0874945 Test Loss: 0.1347178\n",
      "Validation loss decreased (0.088426 --> 0.087494).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0862527\n",
      "\tspeed: 0.0489s/iter; left time: 936.5310s\n",
      "\titers: 200, epoch: 15 | loss: 0.0848772\n",
      "\tspeed: 0.0302s/iter; left time: 576.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0854270 Vali Loss: 0.0870578 Test Loss: 0.1343060\n",
      "Validation loss decreased (0.087494 --> 0.087058).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0869423\n",
      "\tspeed: 0.0472s/iter; left time: 893.2137s\n",
      "\titers: 200, epoch: 16 | loss: 0.0879444\n",
      "\tspeed: 0.0281s/iter; left time: 528.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0852942 Vali Loss: 0.0859861 Test Loss: 0.1327333\n",
      "Validation loss decreased (0.087058 --> 0.085986).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0842726\n",
      "\tspeed: 0.0508s/iter; left time: 950.7202s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838040\n",
      "\tspeed: 0.0261s/iter; left time: 486.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0847827 Vali Loss: 0.0873697 Test Loss: 0.1350182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0835783\n",
      "\tspeed: 0.0430s/iter; left time: 794.6088s\n",
      "\titers: 200, epoch: 18 | loss: 0.0864455\n",
      "\tspeed: 0.0273s/iter; left time: 501.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0846126 Vali Loss: 0.0863356 Test Loss: 0.1339827\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0833691\n",
      "\tspeed: 0.0447s/iter; left time: 817.1709s\n",
      "\titers: 200, epoch: 19 | loss: 0.0822876\n",
      "\tspeed: 0.0263s/iter; left time: 477.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0843596 Vali Loss: 0.0859072 Test Loss: 0.1321979\n",
      "Validation loss decreased (0.085986 --> 0.085907).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0847429\n",
      "\tspeed: 0.0554s/iter; left time: 999.3159s\n",
      "\titers: 200, epoch: 20 | loss: 0.0797493\n",
      "\tspeed: 0.0309s/iter; left time: 555.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0841035 Vali Loss: 0.0872152 Test Loss: 0.1352517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0843899\n",
      "\tspeed: 0.0512s/iter; left time: 913.0907s\n",
      "\titers: 200, epoch: 21 | loss: 0.0830489\n",
      "\tspeed: 0.0214s/iter; left time: 378.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0836223 Vali Loss: 0.0853096 Test Loss: 0.1325860\n",
      "Validation loss decreased (0.085907 --> 0.085310).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0844278\n",
      "\tspeed: 0.0492s/iter; left time: 866.5181s\n",
      "\titers: 200, epoch: 22 | loss: 0.0847410\n",
      "\tspeed: 0.0265s/iter; left time: 464.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0834770 Vali Loss: 0.0853605 Test Loss: 0.1332099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0849688\n",
      "\tspeed: 0.0477s/iter; left time: 827.9394s\n",
      "\titers: 200, epoch: 23 | loss: 0.0814632\n",
      "\tspeed: 0.0234s/iter; left time: 405.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0830873 Vali Loss: 0.0851018 Test Loss: 0.1322873\n",
      "Validation loss decreased (0.085310 --> 0.085102).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0782630\n",
      "\tspeed: 0.0552s/iter; left time: 946.2251s\n",
      "\titers: 200, epoch: 24 | loss: 0.0848130\n",
      "\tspeed: 0.0302s/iter; left time: 514.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0829500 Vali Loss: 0.0848667 Test Loss: 0.1325901\n",
      "Validation loss decreased (0.085102 --> 0.084867).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0825582\n",
      "\tspeed: 0.0571s/iter; left time: 967.2198s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812069\n",
      "\tspeed: 0.0288s/iter; left time: 484.3947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0829039 Vali Loss: 0.0857359 Test Loss: 0.1334892\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0805904\n",
      "\tspeed: 0.0546s/iter; left time: 912.4578s\n",
      "\titers: 200, epoch: 26 | loss: 0.0810719\n",
      "\tspeed: 0.0332s/iter; left time: 550.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0826490 Vali Loss: 0.0848753 Test Loss: 0.1325810\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789335\n",
      "\tspeed: 0.0585s/iter; left time: 963.6197s\n",
      "\titers: 200, epoch: 27 | loss: 0.0863534\n",
      "\tspeed: 0.0249s/iter; left time: 407.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0827229 Vali Loss: 0.0849310 Test Loss: 0.1330170\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0861720\n",
      "\tspeed: 0.0487s/iter; left time: 792.2405s\n",
      "\titers: 200, epoch: 28 | loss: 0.0815576\n",
      "\tspeed: 0.0323s/iter; left time: 521.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0826656 Vali Loss: 0.0848812 Test Loss: 0.1330223\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0816143\n",
      "\tspeed: 0.0411s/iter; left time: 658.3786s\n",
      "\titers: 200, epoch: 29 | loss: 0.0943053\n",
      "\tspeed: 0.0295s/iter; left time: 469.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0824236 Vali Loss: 0.0858566 Test Loss: 0.1341377\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0857651\n",
      "\tspeed: 0.0498s/iter; left time: 787.6790s\n",
      "\titers: 200, epoch: 30 | loss: 0.0800130\n",
      "\tspeed: 0.0266s/iter; left time: 417.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0823669 Vali Loss: 0.0847901 Test Loss: 0.1332328\n",
      "Validation loss decreased (0.084867 --> 0.084790).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0834664\n",
      "\tspeed: 0.0472s/iter; left time: 735.3379s\n",
      "\titers: 200, epoch: 31 | loss: 0.0786720\n",
      "\tspeed: 0.0294s/iter; left time: 455.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0823280 Vali Loss: 0.0848446 Test Loss: 0.1332748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816093\n",
      "\tspeed: 0.0580s/iter; left time: 890.4455s\n",
      "\titers: 200, epoch: 32 | loss: 0.0829070\n",
      "\tspeed: 0.0295s/iter; left time: 449.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0820926 Vali Loss: 0.0854430 Test Loss: 0.1338397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0854929\n",
      "\tspeed: 0.0482s/iter; left time: 729.4082s\n",
      "\titers: 200, epoch: 33 | loss: 0.0825283\n",
      "\tspeed: 0.0274s/iter; left time: 411.9736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0820363 Vali Loss: 0.0848694 Test Loss: 0.1327178\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0818115\n",
      "\tspeed: 0.0508s/iter; left time: 757.9311s\n",
      "\titers: 200, epoch: 34 | loss: 0.0835172\n",
      "\tspeed: 0.0247s/iter; left time: 365.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0820385 Vali Loss: 0.0844909 Test Loss: 0.1328240\n",
      "Validation loss decreased (0.084790 --> 0.084491).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825844\n",
      "\tspeed: 0.0440s/iter; left time: 646.2726s\n",
      "\titers: 200, epoch: 35 | loss: 0.0844956\n",
      "\tspeed: 0.0236s/iter; left time: 344.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0821347 Vali Loss: 0.0844986 Test Loss: 0.1324050\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0792103\n",
      "\tspeed: 0.0474s/iter; left time: 685.0750s\n",
      "\titers: 200, epoch: 36 | loss: 0.0814116\n",
      "\tspeed: 0.0202s/iter; left time: 290.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0819016 Vali Loss: 0.0846138 Test Loss: 0.1329014\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838699\n",
      "\tspeed: 0.0491s/iter; left time: 699.2988s\n",
      "\titers: 200, epoch: 37 | loss: 0.0817974\n",
      "\tspeed: 0.0293s/iter; left time: 414.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0820790 Vali Loss: 0.0847088 Test Loss: 0.1329656\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0811135\n",
      "\tspeed: 0.0559s/iter; left time: 783.7400s\n",
      "\titers: 200, epoch: 38 | loss: 0.0799544\n",
      "\tspeed: 0.0295s/iter; left time: 409.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0819101 Vali Loss: 0.0843389 Test Loss: 0.1327989\n",
      "Validation loss decreased (0.084491 --> 0.084339).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0801798\n",
      "\tspeed: 0.0584s/iter; left time: 804.7975s\n",
      "\titers: 200, epoch: 39 | loss: 0.0816311\n",
      "\tspeed: 0.0353s/iter; left time: 482.7421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0818630 Vali Loss: 0.0844190 Test Loss: 0.1327415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0806030\n",
      "\tspeed: 0.0555s/iter; left time: 753.4831s\n",
      "\titers: 200, epoch: 40 | loss: 0.0847931\n",
      "\tspeed: 0.0241s/iter; left time: 324.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0816370 Vali Loss: 0.0846988 Test Loss: 0.1345025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0855849\n",
      "\tspeed: 0.0492s/iter; left time: 656.2682s\n",
      "\titers: 200, epoch: 41 | loss: 0.0802578\n",
      "\tspeed: 0.0260s/iter; left time: 344.5756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0818509 Vali Loss: 0.0844952 Test Loss: 0.1326016\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845955\n",
      "\tspeed: 0.0505s/iter; left time: 661.9001s\n",
      "\titers: 200, epoch: 42 | loss: 0.0809223\n",
      "\tspeed: 0.0247s/iter; left time: 321.9118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0817512 Vali Loss: 0.0852790 Test Loss: 0.1341501\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0817296\n",
      "\tspeed: 0.0510s/iter; left time: 657.4681s\n",
      "\titers: 200, epoch: 43 | loss: 0.0822530\n",
      "\tspeed: 0.0313s/iter; left time: 399.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0816188 Vali Loss: 0.0846876 Test Loss: 0.1342194\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0796965\n",
      "\tspeed: 0.0491s/iter; left time: 622.2496s\n",
      "\titers: 200, epoch: 44 | loss: 0.0828959\n",
      "\tspeed: 0.0310s/iter; left time: 390.1509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0816368 Vali Loss: 0.0850495 Test Loss: 0.1336429\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0843156\n",
      "\tspeed: 0.0528s/iter; left time: 657.6225s\n",
      "\titers: 200, epoch: 45 | loss: 0.0813513\n",
      "\tspeed: 0.0255s/iter; left time: 314.2675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0816177 Vali Loss: 0.0844175 Test Loss: 0.1329554\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0839745\n",
      "\tspeed: 0.0493s/iter; left time: 602.3784s\n",
      "\titers: 200, epoch: 46 | loss: 0.0811528\n",
      "\tspeed: 0.0245s/iter; left time: 296.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0817873 Vali Loss: 0.0846246 Test Loss: 0.1334104\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0840891\n",
      "\tspeed: 0.0412s/iter; left time: 494.4725s\n",
      "\titers: 200, epoch: 47 | loss: 0.0829375\n",
      "\tspeed: 0.0210s/iter; left time: 249.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0817411 Vali Loss: 0.0848391 Test Loss: 0.1339831\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0834351\n",
      "\tspeed: 0.0422s/iter; left time: 496.3218s\n",
      "\titers: 200, epoch: 48 | loss: 0.0812959\n",
      "\tspeed: 0.0232s/iter; left time: 270.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0818461 Vali Loss: 0.0841881 Test Loss: 0.1324351\n",
      "Validation loss decreased (0.084339 --> 0.084188).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0819094\n",
      "\tspeed: 0.0529s/iter; left time: 610.5638s\n",
      "\titers: 200, epoch: 49 | loss: 0.0837604\n",
      "\tspeed: 0.0321s/iter; left time: 367.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 224 | Train Loss: 0.0816016 Vali Loss: 0.0844856 Test Loss: 0.1332514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0847947\n",
      "\tspeed: 0.0500s/iter; left time: 565.7847s\n",
      "\titers: 200, epoch: 50 | loss: 0.0805368\n",
      "\tspeed: 0.0254s/iter; left time: 284.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0816419 Vali Loss: 0.0846220 Test Loss: 0.1336295\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0780510\n",
      "\tspeed: 0.0547s/iter; left time: 606.6980s\n",
      "\titers: 200, epoch: 51 | loss: 0.0799858\n",
      "\tspeed: 0.0306s/iter; left time: 336.6941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0816814 Vali Loss: 0.0844051 Test Loss: 0.1329539\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0806405\n",
      "\tspeed: 0.0497s/iter; left time: 540.9641s\n",
      "\titers: 200, epoch: 52 | loss: 0.0810899\n",
      "\tspeed: 0.0306s/iter; left time: 329.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0816434 Vali Loss: 0.0844362 Test Loss: 0.1329614\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0766867\n",
      "\tspeed: 0.0531s/iter; left time: 565.3341s\n",
      "\titers: 200, epoch: 53 | loss: 0.0817042\n",
      "\tspeed: 0.0296s/iter; left time: 312.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0818068 Vali Loss: 0.0845303 Test Loss: 0.1332965\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0807607\n",
      "\tspeed: 0.0503s/iter; left time: 524.9773s\n",
      "\titers: 200, epoch: 54 | loss: 0.0810889\n",
      "\tspeed: 0.0278s/iter; left time: 286.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0817718 Vali Loss: 0.0845363 Test Loss: 0.1330585\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0793423\n",
      "\tspeed: 0.0547s/iter; left time: 558.3864s\n",
      "\titers: 200, epoch: 55 | loss: 0.0855337\n",
      "\tspeed: 0.0209s/iter; left time: 211.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0816733 Vali Loss: 0.0845457 Test Loss: 0.1325236\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0830111\n",
      "\tspeed: 0.0432s/iter; left time: 430.8531s\n",
      "\titers: 200, epoch: 56 | loss: 0.0848193\n",
      "\tspeed: 0.0233s/iter; left time: 229.9192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0815485 Vali Loss: 0.0845732 Test Loss: 0.1321735\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0816686\n",
      "\tspeed: 0.0446s/iter; left time: 435.2755s\n",
      "\titers: 200, epoch: 57 | loss: 0.0829241\n",
      "\tspeed: 0.0260s/iter; left time: 251.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0817010 Vali Loss: 0.0846190 Test Loss: 0.1330053\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0825960\n",
      "\tspeed: 0.0501s/iter; left time: 477.7585s\n",
      "\titers: 200, epoch: 58 | loss: 0.0845597\n",
      "\tspeed: 0.0294s/iter; left time: 277.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0816211 Vali Loss: 0.0846765 Test Loss: 0.1339925\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049221720546483994, rmse:0.22185969352722168, mae:0.13243511319160461, rse:0.651757001876831\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3254350\n",
      "\tspeed: 0.0352s/iter; left time: 785.1910s\n",
      "\titers: 200, epoch: 1 | loss: 0.2976056\n",
      "\tspeed: 0.0254s/iter; left time: 564.9197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.3281121 Vali Loss: 0.2277152 Test Loss: 0.2452187\n",
      "Validation loss decreased (inf --> 0.227715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1512388\n",
      "\tspeed: 0.0535s/iter; left time: 1181.0412s\n",
      "\titers: 200, epoch: 2 | loss: 0.1267855\n",
      "\tspeed: 0.0282s/iter; left time: 620.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.1685173 Vali Loss: 0.1133175 Test Loss: 0.1501905\n",
      "Validation loss decreased (0.227715 --> 0.113318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1176418\n",
      "\tspeed: 0.0579s/iter; left time: 1265.9710s\n",
      "\titers: 200, epoch: 3 | loss: 0.1139371\n",
      "\tspeed: 0.0287s/iter; left time: 623.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.1174496 Vali Loss: 0.1084585 Test Loss: 0.1567955\n",
      "Validation loss decreased (0.113318 --> 0.108458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1026811\n",
      "\tspeed: 0.0483s/iter; left time: 1044.9822s\n",
      "\titers: 200, epoch: 4 | loss: 0.0981443\n",
      "\tspeed: 0.0288s/iter; left time: 620.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.1047930 Vali Loss: 0.1033305 Test Loss: 0.1552434\n",
      "Validation loss decreased (0.108458 --> 0.103330).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0996471\n",
      "\tspeed: 0.0530s/iter; left time: 1134.1639s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977767\n",
      "\tspeed: 0.0286s/iter; left time: 608.2743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0982644 Vali Loss: 0.1082843 Test Loss: 0.1565416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0936621\n",
      "\tspeed: 0.0547s/iter; left time: 1157.7778s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888862\n",
      "\tspeed: 0.0286s/iter; left time: 603.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0950709 Vali Loss: 0.0946232 Test Loss: 0.1426721\n",
      "Validation loss decreased (0.103330 --> 0.094623).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0880984\n",
      "\tspeed: 0.0532s/iter; left time: 1114.7815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0899308\n",
      "\tspeed: 0.0265s/iter; left time: 551.8073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0920721 Vali Loss: 0.0925022 Test Loss: 0.1412397\n",
      "Validation loss decreased (0.094623 --> 0.092502).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0944330\n",
      "\tspeed: 0.0408s/iter; left time: 845.9965s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891010\n",
      "\tspeed: 0.0257s/iter; left time: 531.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0904734 Vali Loss: 0.0970451 Test Loss: 0.1468018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0865296\n",
      "\tspeed: 0.0475s/iter; left time: 974.6066s\n",
      "\titers: 200, epoch: 9 | loss: 0.0900960\n",
      "\tspeed: 0.0218s/iter; left time: 444.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0891642 Vali Loss: 0.0914523 Test Loss: 0.1403406\n",
      "Validation loss decreased (0.092502 --> 0.091452).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0870341\n",
      "\tspeed: 0.0513s/iter; left time: 1041.3517s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846299\n",
      "\tspeed: 0.0301s/iter; left time: 606.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0877349 Vali Loss: 0.0904437 Test Loss: 0.1386662\n",
      "Validation loss decreased (0.091452 --> 0.090444).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0866153\n",
      "\tspeed: 0.0526s/iter; left time: 1055.9488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0869300\n",
      "\tspeed: 0.0295s/iter; left time: 589.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0868322 Vali Loss: 0.0878593 Test Loss: 0.1350723\n",
      "Validation loss decreased (0.090444 --> 0.087859).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0942599\n",
      "\tspeed: 0.0527s/iter; left time: 1046.2873s\n",
      "\titers: 200, epoch: 12 | loss: 0.0862190\n",
      "\tspeed: 0.0262s/iter; left time: 516.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0867570 Vali Loss: 0.0879352 Test Loss: 0.1365106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0813389\n",
      "\tspeed: 0.0433s/iter; left time: 849.8774s\n",
      "\titers: 200, epoch: 13 | loss: 0.0875945\n",
      "\tspeed: 0.0206s/iter; left time: 402.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0854819 Vali Loss: 0.0900500 Test Loss: 0.1375589\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0857238\n",
      "\tspeed: 0.0405s/iter; left time: 784.4225s\n",
      "\titers: 200, epoch: 14 | loss: 0.0935270\n",
      "\tspeed: 0.0207s/iter; left time: 398.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0854969 Vali Loss: 0.0922922 Test Loss: 0.1396191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0837275\n",
      "\tspeed: 0.0496s/iter; left time: 950.6589s\n",
      "\titers: 200, epoch: 15 | loss: 0.0862281\n",
      "\tspeed: 0.0290s/iter; left time: 553.1888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0848837 Vali Loss: 0.0865347 Test Loss: 0.1340523\n",
      "Validation loss decreased (0.087859 --> 0.086535).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0839805\n",
      "\tspeed: 0.0530s/iter; left time: 1003.2588s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803596\n",
      "\tspeed: 0.0295s/iter; left time: 556.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0839440 Vali Loss: 0.0880111 Test Loss: 0.1353987\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792972\n",
      "\tspeed: 0.0530s/iter; left time: 992.8585s\n",
      "\titers: 200, epoch: 17 | loss: 0.0868922\n",
      "\tspeed: 0.0208s/iter; left time: 386.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0842086 Vali Loss: 0.0865724 Test Loss: 0.1347460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0824498\n",
      "\tspeed: 0.0535s/iter; left time: 989.0807s\n",
      "\titers: 200, epoch: 18 | loss: 0.0861045\n",
      "\tspeed: 0.0306s/iter; left time: 562.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0837872 Vali Loss: 0.0872990 Test Loss: 0.1353984\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0847648\n",
      "\tspeed: 0.0535s/iter; left time: 978.2806s\n",
      "\titers: 200, epoch: 19 | loss: 0.0859618\n",
      "\tspeed: 0.0322s/iter; left time: 585.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0839924 Vali Loss: 0.0865174 Test Loss: 0.1348898\n",
      "Validation loss decreased (0.086535 --> 0.086517).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0841593\n",
      "\tspeed: 0.0522s/iter; left time: 941.1899s\n",
      "\titers: 200, epoch: 20 | loss: 0.0833792\n",
      "\tspeed: 0.0296s/iter; left time: 531.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.0828524 Vali Loss: 0.0852349 Test Loss: 0.1332363\n",
      "Validation loss decreased (0.086517 --> 0.085235).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0845123\n",
      "\tspeed: 0.0471s/iter; left time: 839.5830s\n",
      "\titers: 200, epoch: 21 | loss: 0.0837300\n",
      "\tspeed: 0.0269s/iter; left time: 477.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0832287 Vali Loss: 0.0855252 Test Loss: 0.1336686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834680\n",
      "\tspeed: 0.0541s/iter; left time: 952.3292s\n",
      "\titers: 200, epoch: 22 | loss: 0.0846502\n",
      "\tspeed: 0.0296s/iter; left time: 517.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0826644 Vali Loss: 0.0862706 Test Loss: 0.1342050\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0794863\n",
      "\tspeed: 0.0478s/iter; left time: 830.3068s\n",
      "\titers: 200, epoch: 23 | loss: 0.0847797\n",
      "\tspeed: 0.0215s/iter; left time: 372.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0825850 Vali Loss: 0.0844645 Test Loss: 0.1315347\n",
      "Validation loss decreased (0.085235 --> 0.084465).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0842404\n",
      "\tspeed: 0.0439s/iter; left time: 752.6437s\n",
      "\titers: 200, epoch: 24 | loss: 0.0793785\n",
      "\tspeed: 0.0253s/iter; left time: 430.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0823216 Vali Loss: 0.0842026 Test Loss: 0.1313656\n",
      "Validation loss decreased (0.084465 --> 0.084203).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0830728\n",
      "\tspeed: 0.0431s/iter; left time: 728.6331s\n",
      "\titers: 200, epoch: 25 | loss: 0.0802397\n",
      "\tspeed: 0.0266s/iter; left time: 447.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0821536 Vali Loss: 0.0845438 Test Loss: 0.1321505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828164\n",
      "\tspeed: 0.0503s/iter; left time: 839.9405s\n",
      "\titers: 200, epoch: 26 | loss: 0.0832368\n",
      "\tspeed: 0.0258s/iter; left time: 428.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0818966 Vali Loss: 0.0855554 Test Loss: 0.1331840\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819057\n",
      "\tspeed: 0.0468s/iter; left time: 770.3114s\n",
      "\titers: 200, epoch: 27 | loss: 0.0823377\n",
      "\tspeed: 0.0205s/iter; left time: 335.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0823832 Vali Loss: 0.0846676 Test Loss: 0.1326578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0793950\n",
      "\tspeed: 0.0490s/iter; left time: 796.0694s\n",
      "\titers: 200, epoch: 28 | loss: 0.0816712\n",
      "\tspeed: 0.0254s/iter; left time: 409.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0818535 Vali Loss: 0.0855907 Test Loss: 0.1338117\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0786914\n",
      "\tspeed: 0.0516s/iter; left time: 827.1416s\n",
      "\titers: 200, epoch: 29 | loss: 0.0805732\n",
      "\tspeed: 0.0297s/iter; left time: 473.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0817168 Vali Loss: 0.0847323 Test Loss: 0.1329015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0776957\n",
      "\tspeed: 0.0420s/iter; left time: 663.7065s\n",
      "\titers: 200, epoch: 30 | loss: 0.0789133\n",
      "\tspeed: 0.0188s/iter; left time: 295.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0817205 Vali Loss: 0.0841117 Test Loss: 0.1316861\n",
      "Validation loss decreased (0.084203 --> 0.084112).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0810006\n",
      "\tspeed: 0.0489s/iter; left time: 762.5251s\n",
      "\titers: 200, epoch: 31 | loss: 0.0847628\n",
      "\tspeed: 0.0264s/iter; left time: 408.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0816817 Vali Loss: 0.0842509 Test Loss: 0.1318397\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0795909\n",
      "\tspeed: 0.0486s/iter; left time: 746.1033s\n",
      "\titers: 200, epoch: 32 | loss: 0.0835875\n",
      "\tspeed: 0.0298s/iter; left time: 455.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0816272 Vali Loss: 0.0840119 Test Loss: 0.1313235\n",
      "Validation loss decreased (0.084112 --> 0.084012).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0836346\n",
      "\tspeed: 0.0509s/iter; left time: 769.9805s\n",
      "\titers: 200, epoch: 33 | loss: 0.0856265\n",
      "\tspeed: 0.0235s/iter; left time: 353.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0817600 Vali Loss: 0.0848449 Test Loss: 0.1320077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0840439\n",
      "\tspeed: 0.0510s/iter; left time: 760.5217s\n",
      "\titers: 200, epoch: 34 | loss: 0.0822760\n",
      "\tspeed: 0.0294s/iter; left time: 435.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0814903 Vali Loss: 0.0843660 Test Loss: 0.1317566\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0810435\n",
      "\tspeed: 0.0547s/iter; left time: 802.8127s\n",
      "\titers: 200, epoch: 35 | loss: 0.0804927\n",
      "\tspeed: 0.0236s/iter; left time: 344.6091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0814767 Vali Loss: 0.0850232 Test Loss: 0.1327491\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0838261\n",
      "\tspeed: 0.0527s/iter; left time: 762.6959s\n",
      "\titers: 200, epoch: 36 | loss: 0.0846658\n",
      "\tspeed: 0.0292s/iter; left time: 419.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0814383 Vali Loss: 0.0841613 Test Loss: 0.1321278\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0811803\n",
      "\tspeed: 0.0444s/iter; left time: 631.8509s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783656\n",
      "\tspeed: 0.0272s/iter; left time: 384.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0812267 Vali Loss: 0.0846750 Test Loss: 0.1322762\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0811663\n",
      "\tspeed: 0.0489s/iter; left time: 685.7190s\n",
      "\titers: 200, epoch: 38 | loss: 0.0792341\n",
      "\tspeed: 0.0281s/iter; left time: 390.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0812587 Vali Loss: 0.0842118 Test Loss: 0.1318713\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0818738\n",
      "\tspeed: 0.0427s/iter; left time: 588.3845s\n",
      "\titers: 200, epoch: 39 | loss: 0.0796617\n",
      "\tspeed: 0.0240s/iter; left time: 328.7501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0812214 Vali Loss: 0.0841181 Test Loss: 0.1318656\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0820289\n",
      "\tspeed: 0.0508s/iter; left time: 689.6099s\n",
      "\titers: 200, epoch: 40 | loss: 0.0838513\n",
      "\tspeed: 0.0238s/iter; left time: 321.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0814939 Vali Loss: 0.0841628 Test Loss: 0.1315156\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0869659\n",
      "\tspeed: 0.0427s/iter; left time: 569.6898s\n",
      "\titers: 200, epoch: 41 | loss: 0.0842423\n",
      "\tspeed: 0.0222s/iter; left time: 294.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0815337 Vali Loss: 0.0841355 Test Loss: 0.1312754\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0850511\n",
      "\tspeed: 0.0455s/iter; left time: 596.6453s\n",
      "\titers: 200, epoch: 42 | loss: 0.0789752\n",
      "\tspeed: 0.0245s/iter; left time: 318.5770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0812954 Vali Loss: 0.0846534 Test Loss: 0.1327076\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.048760101199150085, rmse:0.22081689536571503, mae:0.13132350146770477, rse:0.6486935615539551\n",
      "Intermediate time for ES and pred_len 96: 00h:12m:53.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3272073\n",
      "\tspeed: 0.0451s/iter; left time: 1000.2204s\n",
      "\titers: 200, epoch: 1 | loss: 0.3026049\n",
      "\tspeed: 0.0239s/iter; left time: 528.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.3342721 Vali Loss: 0.2337924 Test Loss: 0.2506682\n",
      "Validation loss decreased (inf --> 0.233792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470250\n",
      "\tspeed: 0.0458s/iter; left time: 1006.4892s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291535\n",
      "\tspeed: 0.0251s/iter; left time: 548.8062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 223 | Train Loss: 0.1645171 Vali Loss: 0.1163712 Test Loss: 0.1542404\n",
      "Validation loss decreased (0.233792 --> 0.116371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1219507\n",
      "\tspeed: 0.0503s/iter; left time: 1093.4345s\n",
      "\titers: 200, epoch: 3 | loss: 0.1154138\n",
      "\tspeed: 0.0208s/iter; left time: 451.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.1199075 Vali Loss: 0.1112828 Test Loss: 0.1557654\n",
      "Validation loss decreased (0.116371 --> 0.111283).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1098431\n",
      "\tspeed: 0.0508s/iter; left time: 1092.8933s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072883\n",
      "\tspeed: 0.0264s/iter; left time: 566.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1098577 Vali Loss: 0.1073227 Test Loss: 0.1554891\n",
      "Validation loss decreased (0.111283 --> 0.107323).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1021843\n",
      "\tspeed: 0.0549s/iter; left time: 1169.5393s\n",
      "\titers: 200, epoch: 5 | loss: 0.1037903\n",
      "\tspeed: 0.0296s/iter; left time: 626.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1026884 Vali Loss: 0.1045218 Test Loss: 0.1500455\n",
      "Validation loss decreased (0.107323 --> 0.104522).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1068423\n",
      "\tspeed: 0.0525s/iter; left time: 1106.0361s\n",
      "\titers: 200, epoch: 6 | loss: 0.0974413\n",
      "\tspeed: 0.0334s/iter; left time: 701.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0986868 Vali Loss: 0.1024585 Test Loss: 0.1526809\n",
      "Validation loss decreased (0.104522 --> 0.102459).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0941754\n",
      "\tspeed: 0.0535s/iter; left time: 1116.0959s\n",
      "\titers: 200, epoch: 7 | loss: 0.0970213\n",
      "\tspeed: 0.0328s/iter; left time: 681.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.0964046 Vali Loss: 0.0974908 Test Loss: 0.1487274\n",
      "Validation loss decreased (0.102459 --> 0.097491).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0978848\n",
      "\tspeed: 0.0523s/iter; left time: 1079.9882s\n",
      "\titers: 200, epoch: 8 | loss: 0.1064261\n",
      "\tspeed: 0.0234s/iter; left time: 480.5946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0954354 Vali Loss: 0.0973079 Test Loss: 0.1464562\n",
      "Validation loss decreased (0.097491 --> 0.097308).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0910053\n",
      "\tspeed: 0.0516s/iter; left time: 1052.8375s\n",
      "\titers: 200, epoch: 9 | loss: 0.0877116\n",
      "\tspeed: 0.0307s/iter; left time: 623.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0934517 Vali Loss: 0.0933162 Test Loss: 0.1411466\n",
      "Validation loss decreased (0.097308 --> 0.093316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0917288\n",
      "\tspeed: 0.0532s/iter; left time: 1074.3510s\n",
      "\titers: 200, epoch: 10 | loss: 0.0891469\n",
      "\tspeed: 0.0300s/iter; left time: 603.5997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0928747 Vali Loss: 0.0937422 Test Loss: 0.1440561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894130\n",
      "\tspeed: 0.0579s/iter; left time: 1156.2730s\n",
      "\titers: 200, epoch: 11 | loss: 0.0897102\n",
      "\tspeed: 0.0300s/iter; left time: 596.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 223 | Train Loss: 0.0916440 Vali Loss: 0.0934271 Test Loss: 0.1425395\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0876455\n",
      "\tspeed: 0.0520s/iter; left time: 1026.8630s\n",
      "\titers: 200, epoch: 12 | loss: 0.0936328\n",
      "\tspeed: 0.0334s/iter; left time: 655.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.0904704 Vali Loss: 0.0943040 Test Loss: 0.1463207\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893361\n",
      "\tspeed: 0.0593s/iter; left time: 1157.5567s\n",
      "\titers: 200, epoch: 13 | loss: 0.0908853\n",
      "\tspeed: 0.0357s/iter; left time: 693.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0904523 Vali Loss: 0.0927199 Test Loss: 0.1441108\n",
      "Validation loss decreased (0.093316 --> 0.092720).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967873\n",
      "\tspeed: 0.0549s/iter; left time: 1058.8231s\n",
      "\titers: 200, epoch: 14 | loss: 0.0869694\n",
      "\tspeed: 0.0260s/iter; left time: 498.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0897502 Vali Loss: 0.0960521 Test Loss: 0.1475645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868967\n",
      "\tspeed: 0.0517s/iter; left time: 986.0352s\n",
      "\titers: 200, epoch: 15 | loss: 0.0878250\n",
      "\tspeed: 0.0275s/iter; left time: 522.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0895878 Vali Loss: 0.0941561 Test Loss: 0.1457388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865125\n",
      "\tspeed: 0.0515s/iter; left time: 971.6245s\n",
      "\titers: 200, epoch: 16 | loss: 0.0896552\n",
      "\tspeed: 0.0233s/iter; left time: 436.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0891077 Vali Loss: 0.0912570 Test Loss: 0.1434957\n",
      "Validation loss decreased (0.092720 --> 0.091257).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0917246\n",
      "\tspeed: 0.0507s/iter; left time: 945.3271s\n",
      "\titers: 200, epoch: 17 | loss: 0.0901025\n",
      "\tspeed: 0.0295s/iter; left time: 546.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0885562 Vali Loss: 0.0902318 Test Loss: 0.1420662\n",
      "Validation loss decreased (0.091257 --> 0.090232).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863970\n",
      "\tspeed: 0.0523s/iter; left time: 963.5039s\n",
      "\titers: 200, epoch: 18 | loss: 0.0868525\n",
      "\tspeed: 0.0291s/iter; left time: 532.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 223 | Train Loss: 0.0880472 Vali Loss: 0.0911535 Test Loss: 0.1439678\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0932073\n",
      "\tspeed: 0.0522s/iter; left time: 949.3277s\n",
      "\titers: 200, epoch: 19 | loss: 0.0869107\n",
      "\tspeed: 0.0289s/iter; left time: 523.2692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 223 | Train Loss: 0.0879256 Vali Loss: 0.0903262 Test Loss: 0.1419569\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0866946\n",
      "\tspeed: 0.0539s/iter; left time: 967.8187s\n",
      "\titers: 200, epoch: 20 | loss: 0.0920869\n",
      "\tspeed: 0.0317s/iter; left time: 566.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0874827 Vali Loss: 0.0898795 Test Loss: 0.1401584\n",
      "Validation loss decreased (0.090232 --> 0.089879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0883974\n",
      "\tspeed: 0.0586s/iter; left time: 1039.9281s\n",
      "\titers: 200, epoch: 21 | loss: 0.0882111\n",
      "\tspeed: 0.0321s/iter; left time: 565.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0873174 Vali Loss: 0.0914838 Test Loss: 0.1433935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0858136\n",
      "\tspeed: 0.0501s/iter; left time: 878.1336s\n",
      "\titers: 200, epoch: 22 | loss: 0.0874610\n",
      "\tspeed: 0.0290s/iter; left time: 505.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0873075 Vali Loss: 0.0902588 Test Loss: 0.1421778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0907908\n",
      "\tspeed: 0.0596s/iter; left time: 1031.4818s\n",
      "\titers: 200, epoch: 23 | loss: 0.0895144\n",
      "\tspeed: 0.0319s/iter; left time: 549.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 223 | Train Loss: 0.0870900 Vali Loss: 0.0902022 Test Loss: 0.1415215\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0820562\n",
      "\tspeed: 0.0566s/iter; left time: 965.5249s\n",
      "\titers: 200, epoch: 24 | loss: 0.0825121\n",
      "\tspeed: 0.0296s/iter; left time: 502.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0871726 Vali Loss: 0.0899938 Test Loss: 0.1420492\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0868284\n",
      "\tspeed: 0.0526s/iter; left time: 886.0591s\n",
      "\titers: 200, epoch: 25 | loss: 0.0853510\n",
      "\tspeed: 0.0232s/iter; left time: 387.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0867777 Vali Loss: 0.0905375 Test Loss: 0.1420782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0885085\n",
      "\tspeed: 0.0432s/iter; left time: 718.6309s\n",
      "\titers: 200, epoch: 26 | loss: 0.0895667\n",
      "\tspeed: 0.0213s/iter; left time: 352.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0868003 Vali Loss: 0.0904072 Test Loss: 0.1418968\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0867968\n",
      "\tspeed: 0.0439s/iter; left time: 719.7706s\n",
      "\titers: 200, epoch: 27 | loss: 0.0853416\n",
      "\tspeed: 0.0327s/iter; left time: 533.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0865164 Vali Loss: 0.0898078 Test Loss: 0.1410877\n",
      "Validation loss decreased (0.089879 --> 0.089808).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0870717\n",
      "\tspeed: 0.0493s/iter; left time: 798.2106s\n",
      "\titers: 200, epoch: 28 | loss: 0.0842176\n",
      "\tspeed: 0.0304s/iter; left time: 488.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0868092 Vali Loss: 0.0908727 Test Loss: 0.1436110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0854777\n",
      "\tspeed: 0.0460s/iter; left time: 733.4515s\n",
      "\titers: 200, epoch: 29 | loss: 0.0854736\n",
      "\tspeed: 0.0257s/iter; left time: 407.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0865838 Vali Loss: 0.0904990 Test Loss: 0.1429664\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0867238\n",
      "\tspeed: 0.0511s/iter; left time: 803.8968s\n",
      "\titers: 200, epoch: 30 | loss: 0.0856218\n",
      "\tspeed: 0.0372s/iter; left time: 582.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 223 | Train Loss: 0.0865102 Vali Loss: 0.0895062 Test Loss: 0.1417027\n",
      "Validation loss decreased (0.089808 --> 0.089506).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0832142\n",
      "\tspeed: 0.0483s/iter; left time: 749.6696s\n",
      "\titers: 200, epoch: 31 | loss: 0.0862358\n",
      "\tspeed: 0.0290s/iter; left time: 447.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0862936 Vali Loss: 0.0895610 Test Loss: 0.1418983\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0882667\n",
      "\tspeed: 0.0522s/iter; left time: 797.5168s\n",
      "\titers: 200, epoch: 32 | loss: 0.0836902\n",
      "\tspeed: 0.0261s/iter; left time: 395.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.0862031 Vali Loss: 0.0899757 Test Loss: 0.1427532\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0862417\n",
      "\tspeed: 0.0492s/iter; left time: 740.7893s\n",
      "\titers: 200, epoch: 33 | loss: 0.0859993\n",
      "\tspeed: 0.0295s/iter; left time: 441.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0861190 Vali Loss: 0.0897072 Test Loss: 0.1418207\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0873205\n",
      "\tspeed: 0.0532s/iter; left time: 789.1315s\n",
      "\titers: 200, epoch: 34 | loss: 0.0840096\n",
      "\tspeed: 0.0213s/iter; left time: 313.9896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0859786 Vali Loss: 0.0892789 Test Loss: 0.1415453\n",
      "Validation loss decreased (0.089506 --> 0.089279).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0859979\n",
      "\tspeed: 0.0448s/iter; left time: 655.1110s\n",
      "\titers: 200, epoch: 35 | loss: 0.0881549\n",
      "\tspeed: 0.0225s/iter; left time: 326.6253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0859538 Vali Loss: 0.0896027 Test Loss: 0.1416662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0873000\n",
      "\tspeed: 0.0484s/iter; left time: 696.5220s\n",
      "\titers: 200, epoch: 36 | loss: 0.0869755\n",
      "\tspeed: 0.0284s/iter; left time: 406.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0858802 Vali Loss: 0.0904202 Test Loss: 0.1428974\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0868471\n",
      "\tspeed: 0.0458s/iter; left time: 649.0338s\n",
      "\titers: 200, epoch: 37 | loss: 0.0901979\n",
      "\tspeed: 0.0242s/iter; left time: 340.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0859091 Vali Loss: 0.0894303 Test Loss: 0.1420479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0847625\n",
      "\tspeed: 0.0560s/iter; left time: 781.8877s\n",
      "\titers: 200, epoch: 38 | loss: 0.0840823\n",
      "\tspeed: 0.0307s/iter; left time: 425.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 223 | Train Loss: 0.0857108 Vali Loss: 0.0892582 Test Loss: 0.1411326\n",
      "Validation loss decreased (0.089279 --> 0.089258).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0843616\n",
      "\tspeed: 0.0504s/iter; left time: 692.3467s\n",
      "\titers: 200, epoch: 39 | loss: 0.0832565\n",
      "\tspeed: 0.0290s/iter; left time: 394.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0857873 Vali Loss: 0.0895958 Test Loss: 0.1420161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0847640\n",
      "\tspeed: 0.0530s/iter; left time: 715.1704s\n",
      "\titers: 200, epoch: 40 | loss: 0.0889238\n",
      "\tspeed: 0.0306s/iter; left time: 409.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0857437 Vali Loss: 0.0892087 Test Loss: 0.1414683\n",
      "Validation loss decreased (0.089258 --> 0.089209).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0864390\n",
      "\tspeed: 0.0533s/iter; left time: 707.5793s\n",
      "\titers: 200, epoch: 41 | loss: 0.0823918\n",
      "\tspeed: 0.0309s/iter; left time: 407.2185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0858038 Vali Loss: 0.0895767 Test Loss: 0.1419474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0830188\n",
      "\tspeed: 0.0542s/iter; left time: 707.3189s\n",
      "\titers: 200, epoch: 42 | loss: 0.0869732\n",
      "\tspeed: 0.0285s/iter; left time: 369.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0858320 Vali Loss: 0.0892996 Test Loss: 0.1409526\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0833766\n",
      "\tspeed: 0.0525s/iter; left time: 674.0037s\n",
      "\titers: 200, epoch: 43 | loss: 0.0852771\n",
      "\tspeed: 0.0268s/iter; left time: 340.9558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 223 | Train Loss: 0.0857134 Vali Loss: 0.0893043 Test Loss: 0.1412656\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0843954\n",
      "\tspeed: 0.0542s/iter; left time: 683.4079s\n",
      "\titers: 200, epoch: 44 | loss: 0.0867444\n",
      "\tspeed: 0.0329s/iter; left time: 411.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 223 | Train Loss: 0.0856981 Vali Loss: 0.0890570 Test Loss: 0.1408063\n",
      "Validation loss decreased (0.089209 --> 0.089057).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0857282\n",
      "\tspeed: 0.0567s/iter; left time: 702.8174s\n",
      "\titers: 200, epoch: 45 | loss: 0.0853719\n",
      "\tspeed: 0.0306s/iter; left time: 376.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.0855363 Vali Loss: 0.0890785 Test Loss: 0.1412049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0882350\n",
      "\tspeed: 0.0492s/iter; left time: 598.0558s\n",
      "\titers: 200, epoch: 46 | loss: 0.0830487\n",
      "\tspeed: 0.0273s/iter; left time: 329.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0856312 Vali Loss: 0.0892954 Test Loss: 0.1413229\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0858902\n",
      "\tspeed: 0.0438s/iter; left time: 522.9413s\n",
      "\titers: 200, epoch: 47 | loss: 0.0851377\n",
      "\tspeed: 0.0224s/iter; left time: 265.5928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0856458 Vali Loss: 0.0896470 Test Loss: 0.1415642\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0832185\n",
      "\tspeed: 0.0483s/iter; left time: 565.8450s\n",
      "\titers: 200, epoch: 48 | loss: 0.0830222\n",
      "\tspeed: 0.0299s/iter; left time: 347.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0856068 Vali Loss: 0.0893039 Test Loss: 0.1414352\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0853342\n",
      "\tspeed: 0.0502s/iter; left time: 577.5426s\n",
      "\titers: 200, epoch: 49 | loss: 0.0889738\n",
      "\tspeed: 0.0229s/iter; left time: 261.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0856692 Vali Loss: 0.0891239 Test Loss: 0.1411131\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0846178\n",
      "\tspeed: 0.0441s/iter; left time: 497.2424s\n",
      "\titers: 200, epoch: 50 | loss: 0.0913949\n",
      "\tspeed: 0.0220s/iter; left time: 246.3119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0856162 Vali Loss: 0.0898579 Test Loss: 0.1418197\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0851435\n",
      "\tspeed: 0.0430s/iter; left time: 475.5148s\n",
      "\titers: 200, epoch: 51 | loss: 0.0829299\n",
      "\tspeed: 0.0239s/iter; left time: 261.7784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0858539 Vali Loss: 0.0892497 Test Loss: 0.1413000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0840101\n",
      "\tspeed: 0.0554s/iter; left time: 600.0646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0862281\n",
      "\tspeed: 0.0334s/iter; left time: 358.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 223 | Train Loss: 0.0856212 Vali Loss: 0.0893799 Test Loss: 0.1419276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0871649\n",
      "\tspeed: 0.0538s/iter; left time: 570.5917s\n",
      "\titers: 200, epoch: 53 | loss: 0.0880948\n",
      "\tspeed: 0.0267s/iter; left time: 280.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0855651 Vali Loss: 0.0891500 Test Loss: 0.1416173\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0865331\n",
      "\tspeed: 0.0506s/iter; left time: 525.7783s\n",
      "\titers: 200, epoch: 54 | loss: 0.0851211\n",
      "\tspeed: 0.0289s/iter; left time: 297.3846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0857840 Vali Loss: 0.0892079 Test Loss: 0.1411711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.053614016622304916, rmse:0.231547012925148, mae:0.14080628752708435, rse:0.6802642345428467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3311298\n",
      "\tspeed: 0.0300s/iter; left time: 666.0485s\n",
      "\titers: 200, epoch: 1 | loss: 0.2999074\n",
      "\tspeed: 0.0287s/iter; left time: 633.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.3341808 Vali Loss: 0.2388379 Test Loss: 0.2540969\n",
      "Validation loss decreased (inf --> 0.238838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480515\n",
      "\tspeed: 0.0527s/iter; left time: 1159.1101s\n",
      "\titers: 200, epoch: 2 | loss: 0.1294611\n",
      "\tspeed: 0.0260s/iter; left time: 568.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.1667377 Vali Loss: 0.1143413 Test Loss: 0.1506566\n",
      "Validation loss decreased (0.238838 --> 0.114341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1143247\n",
      "\tspeed: 0.0543s/iter; left time: 1181.9569s\n",
      "\titers: 200, epoch: 3 | loss: 0.1105303\n",
      "\tspeed: 0.0208s/iter; left time: 451.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.1170566 Vali Loss: 0.1097882 Test Loss: 0.1505313\n",
      "Validation loss decreased (0.114341 --> 0.109788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1044519\n",
      "\tspeed: 0.0524s/iter; left time: 1128.0989s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020417\n",
      "\tspeed: 0.0259s/iter; left time: 554.4258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.1054327 Vali Loss: 0.1039859 Test Loss: 0.1464420\n",
      "Validation loss decreased (0.109788 --> 0.103986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977829\n",
      "\tspeed: 0.0542s/iter; left time: 1155.9904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0953857\n",
      "\tspeed: 0.0312s/iter; left time: 661.7781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 223 | Train Loss: 0.1009543 Vali Loss: 0.0977267 Test Loss: 0.1422860\n",
      "Validation loss decreased (0.103986 --> 0.097727).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0959308\n",
      "\tspeed: 0.0574s/iter; left time: 1210.2275s\n",
      "\titers: 200, epoch: 6 | loss: 0.0966320\n",
      "\tspeed: 0.0238s/iter; left time: 499.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0974845 Vali Loss: 0.0973338 Test Loss: 0.1428104\n",
      "Validation loss decreased (0.097727 --> 0.097334).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0965218\n",
      "\tspeed: 0.0477s/iter; left time: 995.2835s\n",
      "\titers: 200, epoch: 7 | loss: 0.0947420\n",
      "\tspeed: 0.0202s/iter; left time: 419.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0952618 Vali Loss: 0.0959367 Test Loss: 0.1417834\n",
      "Validation loss decreased (0.097334 --> 0.095937).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0902827\n",
      "\tspeed: 0.0522s/iter; left time: 1078.2937s\n",
      "\titers: 200, epoch: 8 | loss: 0.0928559\n",
      "\tspeed: 0.0282s/iter; left time: 579.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0935873 Vali Loss: 0.0935418 Test Loss: 0.1370120\n",
      "Validation loss decreased (0.095937 --> 0.093542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0921643\n",
      "\tspeed: 0.0529s/iter; left time: 1079.4404s\n",
      "\titers: 200, epoch: 9 | loss: 0.0908121\n",
      "\tspeed: 0.0276s/iter; left time: 560.8308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0925456 Vali Loss: 0.0971000 Test Loss: 0.1424666\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0933007\n",
      "\tspeed: 0.0480s/iter; left time: 968.3363s\n",
      "\titers: 200, epoch: 10 | loss: 0.0905953\n",
      "\tspeed: 0.0301s/iter; left time: 604.1280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0916222 Vali Loss: 0.0963686 Test Loss: 0.1425585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0910540\n",
      "\tspeed: 0.0510s/iter; left time: 1018.6509s\n",
      "\titers: 200, epoch: 11 | loss: 0.0923779\n",
      "\tspeed: 0.0238s/iter; left time: 472.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0908038 Vali Loss: 0.0938161 Test Loss: 0.1398570\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0900486\n",
      "\tspeed: 0.0491s/iter; left time: 968.8911s\n",
      "\titers: 200, epoch: 12 | loss: 0.0915032\n",
      "\tspeed: 0.0203s/iter; left time: 398.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0902413 Vali Loss: 0.0935317 Test Loss: 0.1378812\n",
      "Validation loss decreased (0.093542 --> 0.093532).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0890651\n",
      "\tspeed: 0.0490s/iter; left time: 956.5004s\n",
      "\titers: 200, epoch: 13 | loss: 0.0966027\n",
      "\tspeed: 0.0225s/iter; left time: 436.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0890759 Vali Loss: 0.0911995 Test Loss: 0.1357710\n",
      "Validation loss decreased (0.093532 --> 0.091199).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0903751\n",
      "\tspeed: 0.0489s/iter; left time: 944.8157s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862647\n",
      "\tspeed: 0.0272s/iter; left time: 522.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0888597 Vali Loss: 0.0910171 Test Loss: 0.1337701\n",
      "Validation loss decreased (0.091199 --> 0.091017).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0927480\n",
      "\tspeed: 0.0513s/iter; left time: 978.7017s\n",
      "\titers: 200, epoch: 15 | loss: 0.0859470\n",
      "\tspeed: 0.0254s/iter; left time: 481.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0885183 Vali Loss: 0.0903216 Test Loss: 0.1333504\n",
      "Validation loss decreased (0.091017 --> 0.090322).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0864129\n",
      "\tspeed: 0.0503s/iter; left time: 948.7593s\n",
      "\titers: 200, epoch: 16 | loss: 0.0861567\n",
      "\tspeed: 0.0298s/iter; left time: 558.3119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0883044 Vali Loss: 0.0917829 Test Loss: 0.1357272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0891885\n",
      "\tspeed: 0.0455s/iter; left time: 847.7977s\n",
      "\titers: 200, epoch: 17 | loss: 0.0906648\n",
      "\tspeed: 0.0277s/iter; left time: 512.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0879641 Vali Loss: 0.0905363 Test Loss: 0.1342341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0903881\n",
      "\tspeed: 0.0479s/iter; left time: 881.5830s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853802\n",
      "\tspeed: 0.0301s/iter; left time: 551.9815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0875343 Vali Loss: 0.0894914 Test Loss: 0.1322228\n",
      "Validation loss decreased (0.090322 --> 0.089491).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0861354\n",
      "\tspeed: 0.0550s/iter; left time: 1000.9816s\n",
      "\titers: 200, epoch: 19 | loss: 0.0847551\n",
      "\tspeed: 0.0303s/iter; left time: 548.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0872842 Vali Loss: 0.0906356 Test Loss: 0.1344624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0898410\n",
      "\tspeed: 0.0519s/iter; left time: 933.2259s\n",
      "\titers: 200, epoch: 20 | loss: 0.0897355\n",
      "\tspeed: 0.0309s/iter; left time: 551.1130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 223 | Train Loss: 0.0873265 Vali Loss: 0.0895210 Test Loss: 0.1329033\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0881358\n",
      "\tspeed: 0.0452s/iter; left time: 801.6039s\n",
      "\titers: 200, epoch: 21 | loss: 0.0851123\n",
      "\tspeed: 0.0207s/iter; left time: 365.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0869072 Vali Loss: 0.0887188 Test Loss: 0.1308548\n",
      "Validation loss decreased (0.089491 --> 0.088719).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0863800\n",
      "\tspeed: 0.0463s/iter; left time: 810.6156s\n",
      "\titers: 200, epoch: 22 | loss: 0.0854853\n",
      "\tspeed: 0.0297s/iter; left time: 517.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0866136 Vali Loss: 0.0895767 Test Loss: 0.1327415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0873482\n",
      "\tspeed: 0.0468s/iter; left time: 810.1536s\n",
      "\titers: 200, epoch: 23 | loss: 0.0888974\n",
      "\tspeed: 0.0273s/iter; left time: 469.4438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0865087 Vali Loss: 0.0894196 Test Loss: 0.1329338\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0821636\n",
      "\tspeed: 0.0471s/iter; left time: 804.7387s\n",
      "\titers: 200, epoch: 24 | loss: 0.0872085\n",
      "\tspeed: 0.0257s/iter; left time: 436.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0865087 Vali Loss: 0.0891473 Test Loss: 0.1327586\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0869138\n",
      "\tspeed: 0.0481s/iter; left time: 809.9775s\n",
      "\titers: 200, epoch: 25 | loss: 0.0842156\n",
      "\tspeed: 0.0295s/iter; left time: 493.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0864700 Vali Loss: 0.0894420 Test Loss: 0.1336804\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0832372\n",
      "\tspeed: 0.0514s/iter; left time: 855.2831s\n",
      "\titers: 200, epoch: 26 | loss: 0.0894666\n",
      "\tspeed: 0.0267s/iter; left time: 441.7555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0861937 Vali Loss: 0.0891554 Test Loss: 0.1330814\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0832856\n",
      "\tspeed: 0.0505s/iter; left time: 828.3912s\n",
      "\titers: 200, epoch: 27 | loss: 0.0887066\n",
      "\tspeed: 0.0238s/iter; left time: 388.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0861228 Vali Loss: 0.0891039 Test Loss: 0.1326919\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0875564\n",
      "\tspeed: 0.0583s/iter; left time: 943.5930s\n",
      "\titers: 200, epoch: 28 | loss: 0.0864820\n",
      "\tspeed: 0.0274s/iter; left time: 441.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.0861150 Vali Loss: 0.0887561 Test Loss: 0.1322379\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0860555\n",
      "\tspeed: 0.0440s/iter; left time: 702.7468s\n",
      "\titers: 200, epoch: 29 | loss: 0.0856455\n",
      "\tspeed: 0.0245s/iter; left time: 387.8305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0858287 Vali Loss: 0.0896040 Test Loss: 0.1338430\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0851403\n",
      "\tspeed: 0.0518s/iter; left time: 815.4989s\n",
      "\titers: 200, epoch: 30 | loss: 0.0859993\n",
      "\tspeed: 0.0305s/iter; left time: 476.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0858961 Vali Loss: 0.0886667 Test Loss: 0.1319813\n",
      "Validation loss decreased (0.088719 --> 0.088667).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0812170\n",
      "\tspeed: 0.0547s/iter; left time: 847.7311s\n",
      "\titers: 200, epoch: 31 | loss: 0.0912718\n",
      "\tspeed: 0.0302s/iter; left time: 466.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.0856385 Vali Loss: 0.0892346 Test Loss: 0.1330691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0837293\n",
      "\tspeed: 0.0535s/iter; left time: 818.0787s\n",
      "\titers: 200, epoch: 32 | loss: 0.0861499\n",
      "\tspeed: 0.0275s/iter; left time: 417.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0855448 Vali Loss: 0.0894550 Test Loss: 0.1344497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0860938\n",
      "\tspeed: 0.0529s/iter; left time: 796.4309s\n",
      "\titers: 200, epoch: 33 | loss: 0.0833114\n",
      "\tspeed: 0.0221s/iter; left time: 330.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0856789 Vali Loss: 0.0890523 Test Loss: 0.1332736\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0857930\n",
      "\tspeed: 0.0499s/iter; left time: 741.2833s\n",
      "\titers: 200, epoch: 34 | loss: 0.0881752\n",
      "\tspeed: 0.0277s/iter; left time: 408.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0855601 Vali Loss: 0.0890722 Test Loss: 0.1333978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0858681\n",
      "\tspeed: 0.0491s/iter; left time: 717.3433s\n",
      "\titers: 200, epoch: 35 | loss: 0.0844914\n",
      "\tspeed: 0.0270s/iter; left time: 392.5510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 223 | Train Loss: 0.0856916 Vali Loss: 0.0893429 Test Loss: 0.1337914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0845861\n",
      "\tspeed: 0.0527s/iter; left time: 758.7986s\n",
      "\titers: 200, epoch: 36 | loss: 0.0854212\n",
      "\tspeed: 0.0302s/iter; left time: 431.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0855944 Vali Loss: 0.0886588 Test Loss: 0.1326941\n",
      "Validation loss decreased (0.088667 --> 0.088659).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0828418\n",
      "\tspeed: 0.0557s/iter; left time: 789.6465s\n",
      "\titers: 200, epoch: 37 | loss: 0.0838270\n",
      "\tspeed: 0.0307s/iter; left time: 432.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0854993 Vali Loss: 0.0891309 Test Loss: 0.1334570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0849858\n",
      "\tspeed: 0.0479s/iter; left time: 667.6238s\n",
      "\titers: 200, epoch: 38 | loss: 0.0849944\n",
      "\tspeed: 0.0295s/iter; left time: 408.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0854414 Vali Loss: 0.0889321 Test Loss: 0.1332927\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0878356\n",
      "\tspeed: 0.0485s/iter; left time: 666.2494s\n",
      "\titers: 200, epoch: 39 | loss: 0.0877410\n",
      "\tspeed: 0.0235s/iter; left time: 320.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0856135 Vali Loss: 0.0889549 Test Loss: 0.1329249\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0825765\n",
      "\tspeed: 0.0522s/iter; left time: 704.4453s\n",
      "\titers: 200, epoch: 40 | loss: 0.0877671\n",
      "\tspeed: 0.0295s/iter; left time: 395.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.0855538 Vali Loss: 0.0888649 Test Loss: 0.1331781\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0841414\n",
      "\tspeed: 0.0542s/iter; left time: 719.5911s\n",
      "\titers: 200, epoch: 41 | loss: 0.0815569\n",
      "\tspeed: 0.0292s/iter; left time: 385.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.0853305 Vali Loss: 0.0891411 Test Loss: 0.1335190\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0872197\n",
      "\tspeed: 0.0594s/iter; left time: 775.6365s\n",
      "\titers: 200, epoch: 42 | loss: 0.0862120\n",
      "\tspeed: 0.0297s/iter; left time: 385.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 223 | Train Loss: 0.0854018 Vali Loss: 0.0887926 Test Loss: 0.1326573\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0817410\n",
      "\tspeed: 0.0465s/iter; left time: 597.1763s\n",
      "\titers: 200, epoch: 43 | loss: 0.0862479\n",
      "\tspeed: 0.0224s/iter; left time: 284.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0854168 Vali Loss: 0.0889934 Test Loss: 0.1332207\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0900127\n",
      "\tspeed: 0.0477s/iter; left time: 600.9861s\n",
      "\titers: 200, epoch: 44 | loss: 0.0893044\n",
      "\tspeed: 0.0230s/iter; left time: 287.3802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0853460 Vali Loss: 0.0887491 Test Loss: 0.1328621\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0873027\n",
      "\tspeed: 0.0481s/iter; left time: 595.7705s\n",
      "\titers: 200, epoch: 45 | loss: 0.0830045\n",
      "\tspeed: 0.0218s/iter; left time: 267.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.0854205 Vali Loss: 0.0889355 Test Loss: 0.1333370\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0828058\n",
      "\tspeed: 0.0469s/iter; left time: 570.7132s\n",
      "\titers: 200, epoch: 46 | loss: 0.0857187\n",
      "\tspeed: 0.0282s/iter; left time: 339.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0853514 Vali Loss: 0.0889499 Test Loss: 0.1335630\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04627899453043938, rmse:0.21512553095817566, mae:0.13269412517547607, rse:0.6320194602012634\n",
      "Intermediate time for ES and pred_len 168: 00h:13m:17.71s\n",
      "Intermediate time for ES: 00h:43m:27.80s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3031570\n",
      "\tspeed: 0.0442s/iter; left time: 986.0055s\n",
      "\titers: 200, epoch: 1 | loss: 0.2661880\n",
      "\tspeed: 0.0226s/iter; left time: 501.6001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.3031129 Vali Loss: 0.1975509 Test Loss: 0.2047458\n",
      "Validation loss decreased (inf --> 0.197551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1700511\n",
      "\tspeed: 0.0419s/iter; left time: 925.0567s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234627\n",
      "\tspeed: 0.0230s/iter; left time: 505.9187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.1677709 Vali Loss: 0.1246342 Test Loss: 0.1452387\n",
      "Validation loss decreased (0.197551 --> 0.124634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046241\n",
      "\tspeed: 0.0453s/iter; left time: 990.5689s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946132\n",
      "\tspeed: 0.0224s/iter; left time: 487.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.1051751 Vali Loss: 0.0900916 Test Loss: 0.1030797\n",
      "Validation loss decreased (0.124634 --> 0.090092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0793020\n",
      "\tspeed: 0.0435s/iter; left time: 941.5148s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741578\n",
      "\tspeed: 0.0240s/iter; left time: 516.7750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0806216 Vali Loss: 0.0840992 Test Loss: 0.0945809\n",
      "Validation loss decreased (0.090092 --> 0.084099).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0724940\n",
      "\tspeed: 0.0436s/iter; left time: 934.1605s\n",
      "\titers: 200, epoch: 5 | loss: 0.0706007\n",
      "\tspeed: 0.0218s/iter; left time: 464.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0701725 Vali Loss: 0.0739391 Test Loss: 0.0835122\n",
      "Validation loss decreased (0.084099 --> 0.073939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637366\n",
      "\tspeed: 0.0480s/iter; left time: 1017.5638s\n",
      "\titers: 200, epoch: 6 | loss: 0.0639374\n",
      "\tspeed: 0.0312s/iter; left time: 658.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0646443 Vali Loss: 0.0753255 Test Loss: 0.0834676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0603915\n",
      "\tspeed: 0.0419s/iter; left time: 877.4507s\n",
      "\titers: 200, epoch: 7 | loss: 0.0617729\n",
      "\tspeed: 0.0284s/iter; left time: 593.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0620678 Vali Loss: 0.0677964 Test Loss: 0.0761279\n",
      "Validation loss decreased (0.073939 --> 0.067796).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0613004\n",
      "\tspeed: 0.0452s/iter; left time: 937.7269s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569501\n",
      "\tspeed: 0.0224s/iter; left time: 461.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0598886 Vali Loss: 0.0665350 Test Loss: 0.0746689\n",
      "Validation loss decreased (0.067796 --> 0.066535).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581849\n",
      "\tspeed: 0.0446s/iter; left time: 914.7918s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587629\n",
      "\tspeed: 0.0236s/iter; left time: 482.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0589584 Vali Loss: 0.0676015 Test Loss: 0.0748784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0584715\n",
      "\tspeed: 0.0518s/iter; left time: 1049.8784s\n",
      "\titers: 200, epoch: 10 | loss: 0.0570730\n",
      "\tspeed: 0.0291s/iter; left time: 587.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0572760 Vali Loss: 0.0641024 Test Loss: 0.0710237\n",
      "Validation loss decreased (0.066535 --> 0.064102).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0610658\n",
      "\tspeed: 0.0505s/iter; left time: 1013.0485s\n",
      "\titers: 200, epoch: 11 | loss: 0.0637527\n",
      "\tspeed: 0.0275s/iter; left time: 549.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0571127 Vali Loss: 0.0646065 Test Loss: 0.0718394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540640\n",
      "\tspeed: 0.0406s/iter; left time: 805.6280s\n",
      "\titers: 200, epoch: 12 | loss: 0.0507963\n",
      "\tspeed: 0.0291s/iter; left time: 573.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0559361 Vali Loss: 0.0630240 Test Loss: 0.0695875\n",
      "Validation loss decreased (0.064102 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536563\n",
      "\tspeed: 0.0458s/iter; left time: 898.9171s\n",
      "\titers: 200, epoch: 13 | loss: 0.0561524\n",
      "\tspeed: 0.0223s/iter; left time: 435.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0555018 Vali Loss: 0.0629439 Test Loss: 0.0697007\n",
      "Validation loss decreased (0.063024 --> 0.062944).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0564091\n",
      "\tspeed: 0.0477s/iter; left time: 924.2131s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555801\n",
      "\tspeed: 0.0299s/iter; left time: 576.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0547870 Vali Loss: 0.0621768 Test Loss: 0.0686022\n",
      "Validation loss decreased (0.062944 --> 0.062177).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0559220\n",
      "\tspeed: 0.0471s/iter; left time: 901.8666s\n",
      "\titers: 200, epoch: 15 | loss: 0.0500105\n",
      "\tspeed: 0.0312s/iter; left time: 594.7634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0544496 Vali Loss: 0.0620015 Test Loss: 0.0682016\n",
      "Validation loss decreased (0.062177 --> 0.062002).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0538385\n",
      "\tspeed: 0.0467s/iter; left time: 884.2550s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594354\n",
      "\tspeed: 0.0213s/iter; left time: 402.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0542660 Vali Loss: 0.0612766 Test Loss: 0.0677436\n",
      "Validation loss decreased (0.062002 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0541625\n",
      "\tspeed: 0.0449s/iter; left time: 840.2033s\n",
      "\titers: 200, epoch: 17 | loss: 0.0515244\n",
      "\tspeed: 0.0294s/iter; left time: 547.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0538572 Vali Loss: 0.0615994 Test Loss: 0.0680216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578847\n",
      "\tspeed: 0.0442s/iter; left time: 818.0448s\n",
      "\titers: 200, epoch: 18 | loss: 0.0544322\n",
      "\tspeed: 0.0232s/iter; left time: 426.0330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0532655 Vali Loss: 0.0612200 Test Loss: 0.0676835\n",
      "Validation loss decreased (0.061277 --> 0.061220).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0533487\n",
      "\tspeed: 0.0459s/iter; left time: 838.9629s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539787\n",
      "\tspeed: 0.0289s/iter; left time: 525.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0531338 Vali Loss: 0.0608750 Test Loss: 0.0672109\n",
      "Validation loss decreased (0.061220 --> 0.060875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0544674\n",
      "\tspeed: 0.0515s/iter; left time: 930.1100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0542753\n",
      "\tspeed: 0.0259s/iter; left time: 464.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0529647 Vali Loss: 0.0616055 Test Loss: 0.0680856\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0514937\n",
      "\tspeed: 0.0490s/iter; left time: 873.4534s\n",
      "\titers: 200, epoch: 21 | loss: 0.0513042\n",
      "\tspeed: 0.0252s/iter; left time: 446.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0526310 Vali Loss: 0.0610724 Test Loss: 0.0670794\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0551537\n",
      "\tspeed: 0.0428s/iter; left time: 752.3250s\n",
      "\titers: 200, epoch: 22 | loss: 0.0500368\n",
      "\tspeed: 0.0208s/iter; left time: 363.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0524248 Vali Loss: 0.0602043 Test Loss: 0.0662143\n",
      "Validation loss decreased (0.060875 --> 0.060204).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0459508\n",
      "\tspeed: 0.0399s/iter; left time: 693.6528s\n",
      "\titers: 200, epoch: 23 | loss: 0.0567396\n",
      "\tspeed: 0.0209s/iter; left time: 360.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0520893 Vali Loss: 0.0600872 Test Loss: 0.0660076\n",
      "Validation loss decreased (0.060204 --> 0.060087).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0530791\n",
      "\tspeed: 0.0492s/iter; left time: 843.7759s\n",
      "\titers: 200, epoch: 24 | loss: 0.0495801\n",
      "\tspeed: 0.0245s/iter; left time: 417.9087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0523038 Vali Loss: 0.0602506 Test Loss: 0.0665374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0507979\n",
      "\tspeed: 0.0444s/iter; left time: 750.9321s\n",
      "\titers: 200, epoch: 25 | loss: 0.0506652\n",
      "\tspeed: 0.0219s/iter; left time: 368.6197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0519453 Vali Loss: 0.0602224 Test Loss: 0.0661231\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0488667\n",
      "\tspeed: 0.0482s/iter; left time: 804.7743s\n",
      "\titers: 200, epoch: 26 | loss: 0.0501572\n",
      "\tspeed: 0.0280s/iter; left time: 464.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0517820 Vali Loss: 0.0605021 Test Loss: 0.0664077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0518125\n",
      "\tspeed: 0.0519s/iter; left time: 855.6894s\n",
      "\titers: 200, epoch: 27 | loss: 0.0488820\n",
      "\tspeed: 0.0295s/iter; left time: 483.6145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0515541 Vali Loss: 0.0597223 Test Loss: 0.0657422\n",
      "Validation loss decreased (0.060087 --> 0.059722).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0527139\n",
      "\tspeed: 0.0524s/iter; left time: 852.2654s\n",
      "\titers: 200, epoch: 28 | loss: 0.0498113\n",
      "\tspeed: 0.0283s/iter; left time: 457.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0515702 Vali Loss: 0.0604772 Test Loss: 0.0663205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0498477\n",
      "\tspeed: 0.0446s/iter; left time: 714.2649s\n",
      "\titers: 200, epoch: 29 | loss: 0.0515595\n",
      "\tspeed: 0.0256s/iter; left time: 407.9863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0514342 Vali Loss: 0.0596494 Test Loss: 0.0655017\n",
      "Validation loss decreased (0.059722 --> 0.059649).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0485878\n",
      "\tspeed: 0.0428s/iter; left time: 677.0939s\n",
      "\titers: 200, epoch: 30 | loss: 0.0494304\n",
      "\tspeed: 0.0232s/iter; left time: 363.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0513915 Vali Loss: 0.0599748 Test Loss: 0.0656885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0526886\n",
      "\tspeed: 0.0519s/iter; left time: 808.7960s\n",
      "\titers: 200, epoch: 31 | loss: 0.0532817\n",
      "\tspeed: 0.0271s/iter; left time: 418.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0512458 Vali Loss: 0.0597129 Test Loss: 0.0654832\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510807\n",
      "\tspeed: 0.0507s/iter; left time: 778.1751s\n",
      "\titers: 200, epoch: 32 | loss: 0.0480880\n",
      "\tspeed: 0.0274s/iter; left time: 418.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0511557 Vali Loss: 0.0594103 Test Loss: 0.0652023\n",
      "Validation loss decreased (0.059649 --> 0.059410).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0462437\n",
      "\tspeed: 0.0506s/iter; left time: 764.9823s\n",
      "\titers: 200, epoch: 33 | loss: 0.0493002\n",
      "\tspeed: 0.0289s/iter; left time: 434.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0510405 Vali Loss: 0.0596160 Test Loss: 0.0654831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0573885\n",
      "\tspeed: 0.0430s/iter; left time: 641.6432s\n",
      "\titers: 200, epoch: 34 | loss: 0.0525626\n",
      "\tspeed: 0.0200s/iter; left time: 296.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0510673 Vali Loss: 0.0593962 Test Loss: 0.0653253\n",
      "Validation loss decreased (0.059410 --> 0.059396).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0491053\n",
      "\tspeed: 0.0430s/iter; left time: 630.9444s\n",
      "\titers: 200, epoch: 35 | loss: 0.0513745\n",
      "\tspeed: 0.0228s/iter; left time: 332.6628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0509830 Vali Loss: 0.0593733 Test Loss: 0.0652219\n",
      "Validation loss decreased (0.059396 --> 0.059373).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0480511\n",
      "\tspeed: 0.0483s/iter; left time: 698.5656s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518825\n",
      "\tspeed: 0.0232s/iter; left time: 333.5962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0510475 Vali Loss: 0.0593993 Test Loss: 0.0651725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0517412\n",
      "\tspeed: 0.0435s/iter; left time: 619.3120s\n",
      "\titers: 200, epoch: 37 | loss: 0.0518475\n",
      "\tspeed: 0.0229s/iter; left time: 323.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 224 | Train Loss: 0.0509438 Vali Loss: 0.0595804 Test Loss: 0.0654145\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0503242\n",
      "\tspeed: 0.0484s/iter; left time: 678.5932s\n",
      "\titers: 200, epoch: 38 | loss: 0.0496258\n",
      "\tspeed: 0.0223s/iter; left time: 310.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0508933 Vali Loss: 0.0594046 Test Loss: 0.0653044\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0511810\n",
      "\tspeed: 0.0412s/iter; left time: 568.1761s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517311\n",
      "\tspeed: 0.0244s/iter; left time: 333.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0508507 Vali Loss: 0.0592221 Test Loss: 0.0651721\n",
      "Validation loss decreased (0.059373 --> 0.059222).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552442\n",
      "\tspeed: 0.0428s/iter; left time: 580.4494s\n",
      "\titers: 200, epoch: 40 | loss: 0.0468200\n",
      "\tspeed: 0.0225s/iter; left time: 303.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0508254 Vali Loss: 0.0592902 Test Loss: 0.0651964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0510695\n",
      "\tspeed: 0.0541s/iter; left time: 721.7600s\n",
      "\titers: 200, epoch: 41 | loss: 0.0523981\n",
      "\tspeed: 0.0308s/iter; left time: 407.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0508255 Vali Loss: 0.0592795 Test Loss: 0.0650804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0488897\n",
      "\tspeed: 0.0570s/iter; left time: 747.5670s\n",
      "\titers: 200, epoch: 42 | loss: 0.0510387\n",
      "\tspeed: 0.0340s/iter; left time: 442.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0507551 Vali Loss: 0.0593380 Test Loss: 0.0652532\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0514443\n",
      "\tspeed: 0.0467s/iter; left time: 602.3724s\n",
      "\titers: 200, epoch: 43 | loss: 0.0491908\n",
      "\tspeed: 0.0229s/iter; left time: 292.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0507823 Vali Loss: 0.0591197 Test Loss: 0.0649696\n",
      "Validation loss decreased (0.059222 --> 0.059120).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0533786\n",
      "\tspeed: 0.0472s/iter; left time: 598.2996s\n",
      "\titers: 200, epoch: 44 | loss: 0.0532534\n",
      "\tspeed: 0.0258s/iter; left time: 324.5030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0506947 Vali Loss: 0.0591620 Test Loss: 0.0649663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0522345\n",
      "\tspeed: 0.0457s/iter; left time: 568.2578s\n",
      "\titers: 200, epoch: 45 | loss: 0.0526701\n",
      "\tspeed: 0.0220s/iter; left time: 271.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0506668 Vali Loss: 0.0591977 Test Loss: 0.0650459\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0527070\n",
      "\tspeed: 0.0447s/iter; left time: 546.3670s\n",
      "\titers: 200, epoch: 46 | loss: 0.0512152\n",
      "\tspeed: 0.0246s/iter; left time: 298.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0506906 Vali Loss: 0.0592361 Test Loss: 0.0649380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0515296\n",
      "\tspeed: 0.0511s/iter; left time: 612.9024s\n",
      "\titers: 200, epoch: 47 | loss: 0.0504562\n",
      "\tspeed: 0.0250s/iter; left time: 297.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0507268 Vali Loss: 0.0593002 Test Loss: 0.0651791\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0534299\n",
      "\tspeed: 0.0465s/iter; left time: 547.0607s\n",
      "\titers: 200, epoch: 48 | loss: 0.0457938\n",
      "\tspeed: 0.0241s/iter; left time: 280.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0506486 Vali Loss: 0.0592879 Test Loss: 0.0648961\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0553033\n",
      "\tspeed: 0.0418s/iter; left time: 482.9826s\n",
      "\titers: 200, epoch: 49 | loss: 0.0515600\n",
      "\tspeed: 0.0210s/iter; left time: 240.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0506831 Vali Loss: 0.0592498 Test Loss: 0.0651344\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0489566\n",
      "\tspeed: 0.0407s/iter; left time: 461.0031s\n",
      "\titers: 200, epoch: 50 | loss: 0.0490770\n",
      "\tspeed: 0.0212s/iter; left time: 237.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0507017 Vali Loss: 0.0591433 Test Loss: 0.0648456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0501130\n",
      "\tspeed: 0.0450s/iter; left time: 499.0701s\n",
      "\titers: 200, epoch: 51 | loss: 0.0541606\n",
      "\tspeed: 0.0307s/iter; left time: 337.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0506772 Vali Loss: 0.0591394 Test Loss: 0.0649791\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0508720\n",
      "\tspeed: 0.0485s/iter; left time: 527.5094s\n",
      "\titers: 200, epoch: 52 | loss: 0.0529468\n",
      "\tspeed: 0.0216s/iter; left time: 232.3855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0507274 Vali Loss: 0.0591495 Test Loss: 0.0649515\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0490709\n",
      "\tspeed: 0.0472s/iter; left time: 503.0772s\n",
      "\titers: 200, epoch: 53 | loss: 0.0535884\n",
      "\tspeed: 0.0254s/iter; left time: 268.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0505948 Vali Loss: 0.0592315 Test Loss: 0.0648893\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012313004583120346, rmse:0.11096397787332535, mae:0.06496957689523697, rse:0.4280959665775299\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2990461\n",
      "\tspeed: 0.0240s/iter; left time: 535.8488s\n",
      "\titers: 200, epoch: 1 | loss: 0.2560398\n",
      "\tspeed: 0.0273s/iter; left time: 606.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.3034510 Vali Loss: 0.1947497 Test Loss: 0.2030825\n",
      "Validation loss decreased (inf --> 0.194750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1712642\n",
      "\tspeed: 0.0494s/iter; left time: 1091.3424s\n",
      "\titers: 200, epoch: 2 | loss: 0.1312775\n",
      "\tspeed: 0.0244s/iter; left time: 535.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1685879 Vali Loss: 0.1079768 Test Loss: 0.1267913\n",
      "Validation loss decreased (0.194750 --> 0.107977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0998085\n",
      "\tspeed: 0.0526s/iter; left time: 1148.4558s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888522\n",
      "\tspeed: 0.0252s/iter; left time: 548.3707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0987535 Vali Loss: 0.0910797 Test Loss: 0.1067388\n",
      "Validation loss decreased (0.107977 --> 0.091080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839115\n",
      "\tspeed: 0.0473s/iter; left time: 1023.2647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763192\n",
      "\tspeed: 0.0305s/iter; left time: 656.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0830723 Vali Loss: 0.0845197 Test Loss: 0.0971012\n",
      "Validation loss decreased (0.091080 --> 0.084520).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0752057\n",
      "\tspeed: 0.0479s/iter; left time: 1025.1227s\n",
      "\titers: 200, epoch: 5 | loss: 0.0696344\n",
      "\tspeed: 0.0290s/iter; left time: 617.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0731580 Vali Loss: 0.0796321 Test Loss: 0.0912017\n",
      "Validation loss decreased (0.084520 --> 0.079632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0649749\n",
      "\tspeed: 0.0562s/iter; left time: 1189.7103s\n",
      "\titers: 200, epoch: 6 | loss: 0.0621326\n",
      "\tspeed: 0.0304s/iter; left time: 640.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0667993 Vali Loss: 0.0750565 Test Loss: 0.0858628\n",
      "Validation loss decreased (0.079632 --> 0.075056).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0622766\n",
      "\tspeed: 0.0498s/iter; left time: 1043.9363s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625277\n",
      "\tspeed: 0.0299s/iter; left time: 622.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0628552 Vali Loss: 0.0737750 Test Loss: 0.0831133\n",
      "Validation loss decreased (0.075056 --> 0.073775).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567624\n",
      "\tspeed: 0.0487s/iter; left time: 1010.0276s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577230\n",
      "\tspeed: 0.0303s/iter; left time: 625.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0601006 Vali Loss: 0.0721309 Test Loss: 0.0812397\n",
      "Validation loss decreased (0.073775 --> 0.072131).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0577523\n",
      "\tspeed: 0.0517s/iter; left time: 1060.6552s\n",
      "\titers: 200, epoch: 9 | loss: 0.0535913\n",
      "\tspeed: 0.0274s/iter; left time: 558.4883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0586129 Vali Loss: 0.0685326 Test Loss: 0.0778382\n",
      "Validation loss decreased (0.072131 --> 0.068533).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0566347\n",
      "\tspeed: 0.0494s/iter; left time: 1003.0726s\n",
      "\titers: 200, epoch: 10 | loss: 0.0547808\n",
      "\tspeed: 0.0298s/iter; left time: 601.5684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0573430 Vali Loss: 0.0677006 Test Loss: 0.0769045\n",
      "Validation loss decreased (0.068533 --> 0.067701).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552917\n",
      "\tspeed: 0.0448s/iter; left time: 898.0685s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567706\n",
      "\tspeed: 0.0218s/iter; left time: 436.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0564374 Vali Loss: 0.0677469 Test Loss: 0.0769155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0557264\n",
      "\tspeed: 0.0449s/iter; left time: 890.7496s\n",
      "\titers: 200, epoch: 12 | loss: 0.0620411\n",
      "\tspeed: 0.0246s/iter; left time: 485.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0551716 Vali Loss: 0.0654689 Test Loss: 0.0740172\n",
      "Validation loss decreased (0.067701 --> 0.065469).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0526591\n",
      "\tspeed: 0.0523s/iter; left time: 1026.0886s\n",
      "\titers: 200, epoch: 13 | loss: 0.0597925\n",
      "\tspeed: 0.0225s/iter; left time: 439.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0546382 Vali Loss: 0.0650690 Test Loss: 0.0733650\n",
      "Validation loss decreased (0.065469 --> 0.065069).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505651\n",
      "\tspeed: 0.0444s/iter; left time: 860.7940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0575986\n",
      "\tspeed: 0.0283s/iter; left time: 545.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0543595 Vali Loss: 0.0652249 Test Loss: 0.0737355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584320\n",
      "\tspeed: 0.0550s/iter; left time: 1054.1193s\n",
      "\titers: 200, epoch: 15 | loss: 0.0528873\n",
      "\tspeed: 0.0308s/iter; left time: 587.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0538739 Vali Loss: 0.0636303 Test Loss: 0.0715035\n",
      "Validation loss decreased (0.065069 --> 0.063630).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0559470\n",
      "\tspeed: 0.0438s/iter; left time: 829.2783s\n",
      "\titers: 200, epoch: 16 | loss: 0.0540897\n",
      "\tspeed: 0.0294s/iter; left time: 554.7982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0537273 Vali Loss: 0.0664092 Test Loss: 0.0742339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0542022\n",
      "\tspeed: 0.0511s/iter; left time: 957.0118s\n",
      "\titers: 200, epoch: 17 | loss: 0.0527402\n",
      "\tspeed: 0.0292s/iter; left time: 543.4900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0532710 Vali Loss: 0.0634942 Test Loss: 0.0711021\n",
      "Validation loss decreased (0.063630 --> 0.063494).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0519067\n",
      "\tspeed: 0.0425s/iter; left time: 785.4985s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537411\n",
      "\tspeed: 0.0226s/iter; left time: 415.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0527202 Vali Loss: 0.0632586 Test Loss: 0.0711107\n",
      "Validation loss decreased (0.063494 --> 0.063259).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0553143\n",
      "\tspeed: 0.0441s/iter; left time: 806.0676s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532262\n",
      "\tspeed: 0.0258s/iter; left time: 469.3195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0524501 Vali Loss: 0.0625505 Test Loss: 0.0702656\n",
      "Validation loss decreased (0.063259 --> 0.062550).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540973\n",
      "\tspeed: 0.0396s/iter; left time: 714.1809s\n",
      "\titers: 200, epoch: 20 | loss: 0.0598552\n",
      "\tspeed: 0.0202s/iter; left time: 362.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0525805 Vali Loss: 0.0625658 Test Loss: 0.0704756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563896\n",
      "\tspeed: 0.0537s/iter; left time: 957.4936s\n",
      "\titers: 200, epoch: 21 | loss: 0.0529715\n",
      "\tspeed: 0.0323s/iter; left time: 572.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 224 | Train Loss: 0.0522940 Vali Loss: 0.0625141 Test Loss: 0.0698685\n",
      "Validation loss decreased (0.062550 --> 0.062514).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0510315\n",
      "\tspeed: 0.0504s/iter; left time: 886.7216s\n",
      "\titers: 200, epoch: 22 | loss: 0.0505098\n",
      "\tspeed: 0.0270s/iter; left time: 472.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0521562 Vali Loss: 0.0621690 Test Loss: 0.0698445\n",
      "Validation loss decreased (0.062514 --> 0.062169).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0530316\n",
      "\tspeed: 0.0519s/iter; left time: 901.1658s\n",
      "\titers: 200, epoch: 23 | loss: 0.0535054\n",
      "\tspeed: 0.0283s/iter; left time: 489.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0520373 Vali Loss: 0.0621582 Test Loss: 0.0698455\n",
      "Validation loss decreased (0.062169 --> 0.062158).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0574052\n",
      "\tspeed: 0.0459s/iter; left time: 787.9681s\n",
      "\titers: 200, epoch: 24 | loss: 0.0524661\n",
      "\tspeed: 0.0254s/iter; left time: 433.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0518884 Vali Loss: 0.0622761 Test Loss: 0.0697536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0481613\n",
      "\tspeed: 0.0407s/iter; left time: 688.6559s\n",
      "\titers: 200, epoch: 25 | loss: 0.0510079\n",
      "\tspeed: 0.0250s/iter; left time: 420.5442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0514163 Vali Loss: 0.0622657 Test Loss: 0.0698267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0464788\n",
      "\tspeed: 0.0439s/iter; left time: 733.8835s\n",
      "\titers: 200, epoch: 26 | loss: 0.0531227\n",
      "\tspeed: 0.0277s/iter; left time: 459.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0512375 Vali Loss: 0.0614616 Test Loss: 0.0689046\n",
      "Validation loss decreased (0.062158 --> 0.061462).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0511984\n",
      "\tspeed: 0.0441s/iter; left time: 727.1830s\n",
      "\titers: 200, epoch: 27 | loss: 0.0480395\n",
      "\tspeed: 0.0211s/iter; left time: 345.7704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0510408 Vali Loss: 0.0613736 Test Loss: 0.0687954\n",
      "Validation loss decreased (0.061462 --> 0.061374).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0528045\n",
      "\tspeed: 0.0397s/iter; left time: 645.2922s\n",
      "\titers: 200, epoch: 28 | loss: 0.0470218\n",
      "\tspeed: 0.0185s/iter; left time: 298.1805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0511938 Vali Loss: 0.0617004 Test Loss: 0.0695836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0507587\n",
      "\tspeed: 0.0414s/iter; left time: 664.3748s\n",
      "\titers: 200, epoch: 29 | loss: 0.0479718\n",
      "\tspeed: 0.0223s/iter; left time: 354.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0511750 Vali Loss: 0.0615668 Test Loss: 0.0689261\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0533668\n",
      "\tspeed: 0.0406s/iter; left time: 641.1927s\n",
      "\titers: 200, epoch: 30 | loss: 0.0557600\n",
      "\tspeed: 0.0314s/iter; left time: 493.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0509345 Vali Loss: 0.0615189 Test Loss: 0.0692057\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509798\n",
      "\tspeed: 0.0514s/iter; left time: 800.7962s\n",
      "\titers: 200, epoch: 31 | loss: 0.0514633\n",
      "\tspeed: 0.0303s/iter; left time: 468.3381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0509627 Vali Loss: 0.0619284 Test Loss: 0.0694254\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0503894\n",
      "\tspeed: 0.0446s/iter; left time: 684.7647s\n",
      "\titers: 200, epoch: 32 | loss: 0.0506210\n",
      "\tspeed: 0.0263s/iter; left time: 400.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0508545 Vali Loss: 0.0611419 Test Loss: 0.0686880\n",
      "Validation loss decreased (0.061374 --> 0.061142).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0493919\n",
      "\tspeed: 0.0536s/iter; left time: 811.6267s\n",
      "\titers: 200, epoch: 33 | loss: 0.0505347\n",
      "\tspeed: 0.0284s/iter; left time: 427.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0506898 Vali Loss: 0.0612581 Test Loss: 0.0688178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0493288\n",
      "\tspeed: 0.0504s/iter; left time: 751.8592s\n",
      "\titers: 200, epoch: 34 | loss: 0.0486990\n",
      "\tspeed: 0.0304s/iter; left time: 449.6111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0506998 Vali Loss: 0.0611209 Test Loss: 0.0684797\n",
      "Validation loss decreased (0.061142 --> 0.061121).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0499498\n",
      "\tspeed: 0.0515s/iter; left time: 756.6360s\n",
      "\titers: 200, epoch: 35 | loss: 0.0498492\n",
      "\tspeed: 0.0215s/iter; left time: 313.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0506885 Vali Loss: 0.0610637 Test Loss: 0.0686337\n",
      "Validation loss decreased (0.061121 --> 0.061064).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0533342\n",
      "\tspeed: 0.0429s/iter; left time: 620.7363s\n",
      "\titers: 200, epoch: 36 | loss: 0.0517515\n",
      "\tspeed: 0.0247s/iter; left time: 354.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.0507675 Vali Loss: 0.0610669 Test Loss: 0.0684380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0494729\n",
      "\tspeed: 0.0460s/iter; left time: 655.4813s\n",
      "\titers: 200, epoch: 37 | loss: 0.0529700\n",
      "\tspeed: 0.0268s/iter; left time: 379.3884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0506226 Vali Loss: 0.0613854 Test Loss: 0.0687393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0495124\n",
      "\tspeed: 0.0464s/iter; left time: 649.5176s\n",
      "\titers: 200, epoch: 38 | loss: 0.0488354\n",
      "\tspeed: 0.0263s/iter; left time: 365.5548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0506249 Vali Loss: 0.0608366 Test Loss: 0.0682370\n",
      "Validation loss decreased (0.061064 --> 0.060837).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0504159\n",
      "\tspeed: 0.0572s/iter; left time: 788.8964s\n",
      "\titers: 200, epoch: 39 | loss: 0.0498994\n",
      "\tspeed: 0.0351s/iter; left time: 481.0080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0505742 Vali Loss: 0.0609499 Test Loss: 0.0686008\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0512367\n",
      "\tspeed: 0.0550s/iter; left time: 745.9171s\n",
      "\titers: 200, epoch: 40 | loss: 0.0515385\n",
      "\tspeed: 0.0267s/iter; left time: 359.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0506031 Vali Loss: 0.0610822 Test Loss: 0.0686265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0521875\n",
      "\tspeed: 0.0467s/iter; left time: 623.6544s\n",
      "\titers: 200, epoch: 41 | loss: 0.0499057\n",
      "\tspeed: 0.0287s/iter; left time: 380.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0507916 Vali Loss: 0.0610754 Test Loss: 0.0686375\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0534465\n",
      "\tspeed: 0.0467s/iter; left time: 612.0174s\n",
      "\titers: 200, epoch: 42 | loss: 0.0511686\n",
      "\tspeed: 0.0303s/iter; left time: 394.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0504065 Vali Loss: 0.0607061 Test Loss: 0.0682203\n",
      "Validation loss decreased (0.060837 --> 0.060706).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0471882\n",
      "\tspeed: 0.0430s/iter; left time: 553.7742s\n",
      "\titers: 200, epoch: 43 | loss: 0.0492799\n",
      "\tspeed: 0.0217s/iter; left time: 277.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0505355 Vali Loss: 0.0611617 Test Loss: 0.0687296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0504281\n",
      "\tspeed: 0.0492s/iter; left time: 623.4394s\n",
      "\titers: 200, epoch: 44 | loss: 0.0478709\n",
      "\tspeed: 0.0255s/iter; left time: 320.6803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0504877 Vali Loss: 0.0610544 Test Loss: 0.0685101\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0506696\n",
      "\tspeed: 0.0465s/iter; left time: 578.8830s\n",
      "\titers: 200, epoch: 45 | loss: 0.0526931\n",
      "\tspeed: 0.0235s/iter; left time: 290.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0503889 Vali Loss: 0.0610774 Test Loss: 0.0684187\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0505988\n",
      "\tspeed: 0.0446s/iter; left time: 545.4471s\n",
      "\titers: 200, epoch: 46 | loss: 0.0488824\n",
      "\tspeed: 0.0288s/iter; left time: 349.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0503397 Vali Loss: 0.0609147 Test Loss: 0.0682379\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0519708\n",
      "\tspeed: 0.0478s/iter; left time: 573.1964s\n",
      "\titers: 200, epoch: 47 | loss: 0.0503322\n",
      "\tspeed: 0.0300s/iter; left time: 356.4315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0505103 Vali Loss: 0.0608999 Test Loss: 0.0684249\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0498774\n",
      "\tspeed: 0.0599s/iter; left time: 704.6441s\n",
      "\titers: 200, epoch: 48 | loss: 0.0457389\n",
      "\tspeed: 0.0331s/iter; left time: 386.2475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0503683 Vali Loss: 0.0609457 Test Loss: 0.0684040\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0503486\n",
      "\tspeed: 0.0477s/iter; left time: 550.8664s\n",
      "\titers: 200, epoch: 49 | loss: 0.0474213\n",
      "\tspeed: 0.0303s/iter; left time: 346.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0504396 Vali Loss: 0.0607744 Test Loss: 0.0682673\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0512061\n",
      "\tspeed: 0.0458s/iter; left time: 518.6176s\n",
      "\titers: 200, epoch: 50 | loss: 0.0503121\n",
      "\tspeed: 0.0296s/iter; left time: 332.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0503557 Vali Loss: 0.0606592 Test Loss: 0.0680876\n",
      "Validation loss decreased (0.060706 --> 0.060659).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0533584\n",
      "\tspeed: 0.0449s/iter; left time: 498.7308s\n",
      "\titers: 200, epoch: 51 | loss: 0.0477845\n",
      "\tspeed: 0.0299s/iter; left time: 329.3240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0503707 Vali Loss: 0.0607896 Test Loss: 0.0681454\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517603\n",
      "\tspeed: 0.0438s/iter; left time: 476.4272s\n",
      "\titers: 200, epoch: 52 | loss: 0.0487291\n",
      "\tspeed: 0.0253s/iter; left time: 272.2238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0503998 Vali Loss: 0.0607620 Test Loss: 0.0682064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0490349\n",
      "\tspeed: 0.0557s/iter; left time: 593.1082s\n",
      "\titers: 200, epoch: 53 | loss: 0.0513633\n",
      "\tspeed: 0.0251s/iter; left time: 264.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0502433 Vali Loss: 0.0608678 Test Loss: 0.0683198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0489641\n",
      "\tspeed: 0.0475s/iter; left time: 494.8853s\n",
      "\titers: 200, epoch: 54 | loss: 0.0536573\n",
      "\tspeed: 0.0342s/iter; left time: 352.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0503865 Vali Loss: 0.0607577 Test Loss: 0.0681230\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0542189\n",
      "\tspeed: 0.0502s/iter; left time: 512.4125s\n",
      "\titers: 200, epoch: 55 | loss: 0.0528134\n",
      "\tspeed: 0.0300s/iter; left time: 303.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0502288 Vali Loss: 0.0607410 Test Loss: 0.0681063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0518522\n",
      "\tspeed: 0.0534s/iter; left time: 532.9951s\n",
      "\titers: 200, epoch: 56 | loss: 0.0495478\n",
      "\tspeed: 0.0243s/iter; left time: 240.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0503464 Vali Loss: 0.0609639 Test Loss: 0.0683898\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0474299\n",
      "\tspeed: 0.0419s/iter; left time: 408.7025s\n",
      "\titers: 200, epoch: 57 | loss: 0.0479687\n",
      "\tspeed: 0.0205s/iter; left time: 198.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0503854 Vali Loss: 0.0606549 Test Loss: 0.0681775\n",
      "Validation loss decreased (0.060659 --> 0.060655).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0510985\n",
      "\tspeed: 0.0484s/iter; left time: 461.5896s\n",
      "\titers: 200, epoch: 58 | loss: 0.0521480\n",
      "\tspeed: 0.0256s/iter; left time: 241.4884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0503789 Vali Loss: 0.0607867 Test Loss: 0.0681003\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0520541\n",
      "\tspeed: 0.0496s/iter; left time: 462.0540s\n",
      "\titers: 200, epoch: 59 | loss: 0.0486090\n",
      "\tspeed: 0.0271s/iter; left time: 249.4553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0504323 Vali Loss: 0.0608758 Test Loss: 0.0683641\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0529675\n",
      "\tspeed: 0.0455s/iter; left time: 412.9496s\n",
      "\titers: 200, epoch: 60 | loss: 0.0467779\n",
      "\tspeed: 0.0317s/iter; left time: 284.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0503752 Vali Loss: 0.0608450 Test Loss: 0.0681333\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0540267\n",
      "\tspeed: 0.0575s/iter; left time: 509.7994s\n",
      "\titers: 200, epoch: 61 | loss: 0.0492767\n",
      "\tspeed: 0.0350s/iter; left time: 306.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0503681 Vali Loss: 0.0606413 Test Loss: 0.0680370\n",
      "Validation loss decreased (0.060655 --> 0.060641).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0518788\n",
      "\tspeed: 0.0531s/iter; left time: 459.0446s\n",
      "\titers: 200, epoch: 62 | loss: 0.0515332\n",
      "\tspeed: 0.0307s/iter; left time: 262.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0502553 Vali Loss: 0.0609050 Test Loss: 0.0683804\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0509291\n",
      "\tspeed: 0.0446s/iter; left time: 375.4351s\n",
      "\titers: 200, epoch: 63 | loss: 0.0518885\n",
      "\tspeed: 0.0287s/iter; left time: 238.8959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0502674 Vali Loss: 0.0608754 Test Loss: 0.0680116\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0474717\n",
      "\tspeed: 0.0541s/iter; left time: 442.7297s\n",
      "\titers: 200, epoch: 64 | loss: 0.0525659\n",
      "\tspeed: 0.0300s/iter; left time: 242.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0503960 Vali Loss: 0.0609894 Test Loss: 0.0684994\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0508727\n",
      "\tspeed: 0.0473s/iter; left time: 376.6629s\n",
      "\titers: 200, epoch: 65 | loss: 0.0499758\n",
      "\tspeed: 0.0224s/iter; left time: 175.8073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0503666 Vali Loss: 0.0607882 Test Loss: 0.0680950\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0519749\n",
      "\tspeed: 0.0423s/iter; left time: 327.7409s\n",
      "\titers: 200, epoch: 66 | loss: 0.0519962\n",
      "\tspeed: 0.0257s/iter; left time: 196.5329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0503740 Vali Loss: 0.0609169 Test Loss: 0.0683158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499689\n",
      "\tspeed: 0.0436s/iter; left time: 327.6437s\n",
      "\titers: 200, epoch: 67 | loss: 0.0492724\n",
      "\tspeed: 0.0207s/iter; left time: 153.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0501549 Vali Loss: 0.0608173 Test Loss: 0.0683120\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0501580\n",
      "\tspeed: 0.0407s/iter; left time: 296.9987s\n",
      "\titers: 200, epoch: 68 | loss: 0.0484336\n",
      "\tspeed: 0.0259s/iter; left time: 186.0496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0502132 Vali Loss: 0.0607632 Test Loss: 0.0682640\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0496655\n",
      "\tspeed: 0.0569s/iter; left time: 402.0860s\n",
      "\titers: 200, epoch: 69 | loss: 0.0516614\n",
      "\tspeed: 0.0313s/iter; left time: 218.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0503174 Vali Loss: 0.0607048 Test Loss: 0.0680478\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0511412\n",
      "\tspeed: 0.0434s/iter; left time: 297.0120s\n",
      "\titers: 200, epoch: 70 | loss: 0.0504561\n",
      "\tspeed: 0.0209s/iter; left time: 140.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0502246 Vali Loss: 0.0607057 Test Loss: 0.0681456\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0513471\n",
      "\tspeed: 0.0451s/iter; left time: 298.4077s\n",
      "\titers: 200, epoch: 71 | loss: 0.0483633\n",
      "\tspeed: 0.0311s/iter; left time: 202.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0502998 Vali Loss: 0.0609832 Test Loss: 0.0685981\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.014218668453395367, rmse:0.11924205720424652, mae:0.06803694367408752, rse:0.46003252267837524\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:23.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3053247\n",
      "\tspeed: 0.0467s/iter; left time: 1042.2126s\n",
      "\titers: 200, epoch: 1 | loss: 0.2671898\n",
      "\tspeed: 0.0215s/iter; left time: 477.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.3101927 Vali Loss: 0.1949117 Test Loss: 0.2026870\n",
      "Validation loss decreased (inf --> 0.194912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1464543\n",
      "\tspeed: 0.0494s/iter; left time: 1091.2399s\n",
      "\titers: 200, epoch: 2 | loss: 0.1145843\n",
      "\tspeed: 0.0288s/iter; left time: 633.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.1510744 Vali Loss: 0.1107624 Test Loss: 0.1299908\n",
      "Validation loss decreased (0.194912 --> 0.110762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012661\n",
      "\tspeed: 0.0519s/iter; left time: 1133.8531s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927679\n",
      "\tspeed: 0.0209s/iter; left time: 455.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.1001072 Vali Loss: 0.1042898 Test Loss: 0.1226965\n",
      "Validation loss decreased (0.110762 --> 0.104290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856560\n",
      "\tspeed: 0.0461s/iter; left time: 997.2071s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805916\n",
      "\tspeed: 0.0282s/iter; left time: 607.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0878769 Vali Loss: 0.0966204 Test Loss: 0.1124682\n",
      "Validation loss decreased (0.104290 --> 0.096620).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0807854\n",
      "\tspeed: 0.0538s/iter; left time: 1151.9075s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774228\n",
      "\tspeed: 0.0264s/iter; left time: 562.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0789022 Vali Loss: 0.0915065 Test Loss: 0.1068967\n",
      "Validation loss decreased (0.096620 --> 0.091506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809742\n",
      "\tspeed: 0.0442s/iter; left time: 936.1591s\n",
      "\titers: 200, epoch: 6 | loss: 0.0763631\n",
      "\tspeed: 0.0199s/iter; left time: 420.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0754589 Vali Loss: 0.0883207 Test Loss: 0.1032911\n",
      "Validation loss decreased (0.091506 --> 0.088321).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695377\n",
      "\tspeed: 0.0416s/iter; left time: 872.0721s\n",
      "\titers: 200, epoch: 7 | loss: 0.0713625\n",
      "\tspeed: 0.0287s/iter; left time: 598.8600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0731320 Vali Loss: 0.0885737 Test Loss: 0.1044392\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743736\n",
      "\tspeed: 0.0533s/iter; left time: 1104.8419s\n",
      "\titers: 200, epoch: 8 | loss: 0.0707687\n",
      "\tspeed: 0.0300s/iter; left time: 619.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0720725 Vali Loss: 0.0876094 Test Loss: 0.1025418\n",
      "Validation loss decreased (0.088321 --> 0.087609).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704825\n",
      "\tspeed: 0.0574s/iter; left time: 1176.9688s\n",
      "\titers: 200, epoch: 9 | loss: 0.0673042\n",
      "\tspeed: 0.0235s/iter; left time: 480.1420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0707117 Vali Loss: 0.0850467 Test Loss: 0.1002401\n",
      "Validation loss decreased (0.087609 --> 0.085047).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0740139\n",
      "\tspeed: 0.0465s/iter; left time: 943.6344s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683985\n",
      "\tspeed: 0.0278s/iter; left time: 560.3447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0697940 Vali Loss: 0.0856127 Test Loss: 0.1010424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0701245\n",
      "\tspeed: 0.0449s/iter; left time: 901.0127s\n",
      "\titers: 200, epoch: 11 | loss: 0.0665256\n",
      "\tspeed: 0.0202s/iter; left time: 402.3342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0688453 Vali Loss: 0.0830623 Test Loss: 0.0977509\n",
      "Validation loss decreased (0.085047 --> 0.083062).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0666852\n",
      "\tspeed: 0.0489s/iter; left time: 970.5233s\n",
      "\titers: 200, epoch: 12 | loss: 0.0662511\n",
      "\tspeed: 0.0188s/iter; left time: 370.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0682378 Vali Loss: 0.0838902 Test Loss: 0.0993334\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0674334\n",
      "\tspeed: 0.0511s/iter; left time: 1001.8012s\n",
      "\titers: 200, epoch: 13 | loss: 0.0669474\n",
      "\tspeed: 0.0297s/iter; left time: 578.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0680135 Vali Loss: 0.0823024 Test Loss: 0.0965227\n",
      "Validation loss decreased (0.083062 --> 0.082302).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0662640\n",
      "\tspeed: 0.0478s/iter; left time: 926.6356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0642669\n",
      "\tspeed: 0.0202s/iter; left time: 390.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0673367 Vali Loss: 0.0825047 Test Loss: 0.0972182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0680349\n",
      "\tspeed: 0.0424s/iter; left time: 812.5179s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660250\n",
      "\tspeed: 0.0272s/iter; left time: 518.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0673574 Vali Loss: 0.0823004 Test Loss: 0.0961922\n",
      "Validation loss decreased (0.082302 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0733240\n",
      "\tspeed: 0.0574s/iter; left time: 1087.5852s\n",
      "\titers: 200, epoch: 16 | loss: 0.0649534\n",
      "\tspeed: 0.0299s/iter; left time: 563.4791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0667445 Vali Loss: 0.0818571 Test Loss: 0.0957230\n",
      "Validation loss decreased (0.082300 --> 0.081857).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0613340\n",
      "\tspeed: 0.0429s/iter; left time: 802.3690s\n",
      "\titers: 200, epoch: 17 | loss: 0.0651078\n",
      "\tspeed: 0.0202s/iter; left time: 375.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0668929 Vali Loss: 0.0817282 Test Loss: 0.0960675\n",
      "Validation loss decreased (0.081857 --> 0.081728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0673034\n",
      "\tspeed: 0.0481s/iter; left time: 889.8069s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666244\n",
      "\tspeed: 0.0227s/iter; left time: 417.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0662236 Vali Loss: 0.0816988 Test Loss: 0.0955875\n",
      "Validation loss decreased (0.081728 --> 0.081699).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643109\n",
      "\tspeed: 0.0543s/iter; left time: 992.8741s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676606\n",
      "\tspeed: 0.0299s/iter; left time: 542.5882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0664485 Vali Loss: 0.0816755 Test Loss: 0.0961933\n",
      "Validation loss decreased (0.081699 --> 0.081676).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0637590\n",
      "\tspeed: 0.0535s/iter; left time: 965.0418s\n",
      "\titers: 200, epoch: 20 | loss: 0.0621488\n",
      "\tspeed: 0.0277s/iter; left time: 496.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0657882 Vali Loss: 0.0817215 Test Loss: 0.0960275\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0639705\n",
      "\tspeed: 0.0466s/iter; left time: 830.5789s\n",
      "\titers: 200, epoch: 21 | loss: 0.0652836\n",
      "\tspeed: 0.0221s/iter; left time: 390.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0656000 Vali Loss: 0.0812305 Test Loss: 0.0946575\n",
      "Validation loss decreased (0.081676 --> 0.081230).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0654052\n",
      "\tspeed: 0.0520s/iter; left time: 914.8188s\n",
      "\titers: 200, epoch: 22 | loss: 0.0664869\n",
      "\tspeed: 0.0311s/iter; left time: 544.6433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0655969 Vali Loss: 0.0823089 Test Loss: 0.0968786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0628388\n",
      "\tspeed: 0.0543s/iter; left time: 943.9811s\n",
      "\titers: 200, epoch: 23 | loss: 0.0660227\n",
      "\tspeed: 0.0273s/iter; left time: 471.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0653361 Vali Loss: 0.0816697 Test Loss: 0.0959854\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0655696\n",
      "\tspeed: 0.0539s/iter; left time: 924.8209s\n",
      "\titers: 200, epoch: 24 | loss: 0.0641893\n",
      "\tspeed: 0.0337s/iter; left time: 574.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0650990 Vali Loss: 0.0808351 Test Loss: 0.0942089\n",
      "Validation loss decreased (0.081230 --> 0.080835).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0689714\n",
      "\tspeed: 0.0558s/iter; left time: 943.8972s\n",
      "\titers: 200, epoch: 25 | loss: 0.0654986\n",
      "\tspeed: 0.0302s/iter; left time: 508.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0650422 Vali Loss: 0.0810375 Test Loss: 0.0952166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0669127\n",
      "\tspeed: 0.0480s/iter; left time: 802.3726s\n",
      "\titers: 200, epoch: 26 | loss: 0.0630300\n",
      "\tspeed: 0.0328s/iter; left time: 544.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0648216 Vali Loss: 0.0807236 Test Loss: 0.0945978\n",
      "Validation loss decreased (0.080835 --> 0.080724).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0618528\n",
      "\tspeed: 0.0463s/iter; left time: 762.6014s\n",
      "\titers: 200, epoch: 27 | loss: 0.0668158\n",
      "\tspeed: 0.0293s/iter; left time: 479.5838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0647959 Vali Loss: 0.0809354 Test Loss: 0.0947109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0686699\n",
      "\tspeed: 0.0521s/iter; left time: 846.7785s\n",
      "\titers: 200, epoch: 28 | loss: 0.0649435\n",
      "\tspeed: 0.0290s/iter; left time: 468.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0646855 Vali Loss: 0.0810894 Test Loss: 0.0950045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0674166\n",
      "\tspeed: 0.0437s/iter; left time: 699.9921s\n",
      "\titers: 200, epoch: 29 | loss: 0.0670567\n",
      "\tspeed: 0.0210s/iter; left time: 334.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0645634 Vali Loss: 0.0807213 Test Loss: 0.0945283\n",
      "Validation loss decreased (0.080724 --> 0.080721).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0655118\n",
      "\tspeed: 0.0550s/iter; left time: 868.9087s\n",
      "\titers: 200, epoch: 30 | loss: 0.0651221\n",
      "\tspeed: 0.0287s/iter; left time: 450.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0645584 Vali Loss: 0.0809203 Test Loss: 0.0946965\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0656992\n",
      "\tspeed: 0.0520s/iter; left time: 809.6575s\n",
      "\titers: 200, epoch: 31 | loss: 0.0715522\n",
      "\tspeed: 0.0294s/iter; left time: 455.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0646282 Vali Loss: 0.0811775 Test Loss: 0.0949668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0667958\n",
      "\tspeed: 0.0504s/iter; left time: 774.3790s\n",
      "\titers: 200, epoch: 32 | loss: 0.0655016\n",
      "\tspeed: 0.0292s/iter; left time: 445.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.0643748 Vali Loss: 0.0808370 Test Loss: 0.0949973\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0633335\n",
      "\tspeed: 0.0537s/iter; left time: 812.0421s\n",
      "\titers: 200, epoch: 33 | loss: 0.0657134\n",
      "\tspeed: 0.0252s/iter; left time: 378.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0644758 Vali Loss: 0.0809371 Test Loss: 0.0949143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0658941\n",
      "\tspeed: 0.0537s/iter; left time: 801.3078s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686924\n",
      "\tspeed: 0.0326s/iter; left time: 482.0369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0644184 Vali Loss: 0.0806464 Test Loss: 0.0941226\n",
      "Validation loss decreased (0.080721 --> 0.080646).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0635554\n",
      "\tspeed: 0.0583s/iter; left time: 855.4183s\n",
      "\titers: 200, epoch: 35 | loss: 0.0663777\n",
      "\tspeed: 0.0273s/iter; left time: 398.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0642707 Vali Loss: 0.0809632 Test Loss: 0.0947197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0629038\n",
      "\tspeed: 0.0477s/iter; left time: 690.2703s\n",
      "\titers: 200, epoch: 36 | loss: 0.0631716\n",
      "\tspeed: 0.0214s/iter; left time: 307.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0643888 Vali Loss: 0.0809649 Test Loss: 0.0946939\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0665186\n",
      "\tspeed: 0.0479s/iter; left time: 681.3854s\n",
      "\titers: 200, epoch: 37 | loss: 0.0645781\n",
      "\tspeed: 0.0293s/iter; left time: 414.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0641662 Vali Loss: 0.0810272 Test Loss: 0.0952791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0643053\n",
      "\tspeed: 0.0503s/iter; left time: 704.4512s\n",
      "\titers: 200, epoch: 38 | loss: 0.0654931\n",
      "\tspeed: 0.0259s/iter; left time: 360.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0641514 Vali Loss: 0.0809369 Test Loss: 0.0948316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585407\n",
      "\tspeed: 0.0474s/iter; left time: 653.7990s\n",
      "\titers: 200, epoch: 39 | loss: 0.0619454\n",
      "\tspeed: 0.0236s/iter; left time: 322.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0641727 Vali Loss: 0.0809301 Test Loss: 0.0947096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0606396\n",
      "\tspeed: 0.0556s/iter; left time: 754.7624s\n",
      "\titers: 200, epoch: 40 | loss: 0.0625583\n",
      "\tspeed: 0.0315s/iter; left time: 424.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0643196 Vali Loss: 0.0810050 Test Loss: 0.0951004\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0663636\n",
      "\tspeed: 0.0536s/iter; left time: 715.0384s\n",
      "\titers: 200, epoch: 41 | loss: 0.0632043\n",
      "\tspeed: 0.0311s/iter; left time: 411.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0641644 Vali Loss: 0.0808073 Test Loss: 0.0946040\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0634502\n",
      "\tspeed: 0.0530s/iter; left time: 695.1866s\n",
      "\titers: 200, epoch: 42 | loss: 0.0599971\n",
      "\tspeed: 0.0305s/iter; left time: 397.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0640271 Vali Loss: 0.0808348 Test Loss: 0.0945198\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0622928\n",
      "\tspeed: 0.0495s/iter; left time: 637.6555s\n",
      "\titers: 200, epoch: 43 | loss: 0.0680167\n",
      "\tspeed: 0.0275s/iter; left time: 351.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0640945 Vali Loss: 0.0809766 Test Loss: 0.0951378\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0604269\n",
      "\tspeed: 0.0522s/iter; left time: 660.9206s\n",
      "\titers: 200, epoch: 44 | loss: 0.0643541\n",
      "\tspeed: 0.0230s/iter; left time: 289.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0639747 Vali Loss: 0.0806790 Test Loss: 0.0939220\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.025642767548561096, rmse:0.16013360023498535, mae:0.09412254393100739, rse:0.6194393038749695\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3080913\n",
      "\tspeed: 0.0305s/iter; left time: 679.8664s\n",
      "\titers: 200, epoch: 1 | loss: 0.2710241\n",
      "\tspeed: 0.0284s/iter; left time: 631.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.3087794 Vali Loss: 0.1965360 Test Loss: 0.2048948\n",
      "Validation loss decreased (inf --> 0.196536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520279\n",
      "\tspeed: 0.0456s/iter; left time: 1006.3083s\n",
      "\titers: 200, epoch: 2 | loss: 0.1128812\n",
      "\tspeed: 0.0202s/iter; left time: 444.0461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1552450 Vali Loss: 0.1111015 Test Loss: 0.1288724\n",
      "Validation loss decreased (0.196536 --> 0.111101).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0980031\n",
      "\tspeed: 0.0513s/iter; left time: 1120.8942s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945393\n",
      "\tspeed: 0.0298s/iter; left time: 648.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0995132 Vali Loss: 0.1048940 Test Loss: 0.1239729\n",
      "Validation loss decreased (0.111101 --> 0.104894).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0869568\n",
      "\tspeed: 0.0509s/iter; left time: 1101.9564s\n",
      "\titers: 200, epoch: 4 | loss: 0.0807237\n",
      "\tspeed: 0.0268s/iter; left time: 576.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0859621 Vali Loss: 0.1000890 Test Loss: 0.1193546\n",
      "Validation loss decreased (0.104894 --> 0.100089).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0823223\n",
      "\tspeed: 0.0446s/iter; left time: 955.0006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0789888\n",
      "\tspeed: 0.0221s/iter; left time: 469.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0789129 Vali Loss: 0.0962231 Test Loss: 0.1140730\n",
      "Validation loss decreased (0.100089 --> 0.096223).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0727845\n",
      "\tspeed: 0.0499s/iter; left time: 1056.2554s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762033\n",
      "\tspeed: 0.0297s/iter; left time: 625.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.0758133 Vali Loss: 0.0936905 Test Loss: 0.1111693\n",
      "Validation loss decreased (0.096223 --> 0.093691).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0781427\n",
      "\tspeed: 0.0458s/iter; left time: 959.9656s\n",
      "\titers: 200, epoch: 7 | loss: 0.0744278\n",
      "\tspeed: 0.0285s/iter; left time: 595.2715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0735815 Vali Loss: 0.0936315 Test Loss: 0.1105249\n",
      "Validation loss decreased (0.093691 --> 0.093632).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0723146\n",
      "\tspeed: 0.0533s/iter; left time: 1104.6311s\n",
      "\titers: 200, epoch: 8 | loss: 0.0712020\n",
      "\tspeed: 0.0310s/iter; left time: 639.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0716777 Vali Loss: 0.0891590 Test Loss: 0.1055111\n",
      "Validation loss decreased (0.093632 --> 0.089159).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0692933\n",
      "\tspeed: 0.0509s/iter; left time: 1044.7295s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747150\n",
      "\tspeed: 0.0298s/iter; left time: 607.4177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0703555 Vali Loss: 0.0889187 Test Loss: 0.1039968\n",
      "Validation loss decreased (0.089159 --> 0.088919).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725826\n",
      "\tspeed: 0.0482s/iter; left time: 978.1005s\n",
      "\titers: 200, epoch: 10 | loss: 0.0714051\n",
      "\tspeed: 0.0188s/iter; left time: 378.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0697630 Vali Loss: 0.0870219 Test Loss: 0.1014085\n",
      "Validation loss decreased (0.088919 --> 0.087022).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685585\n",
      "\tspeed: 0.0528s/iter; left time: 1059.3066s\n",
      "\titers: 200, epoch: 11 | loss: 0.0698166\n",
      "\tspeed: 0.0213s/iter; left time: 424.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0688219 Vali Loss: 0.0888015 Test Loss: 0.1030341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0678812\n",
      "\tspeed: 0.0548s/iter; left time: 1088.0208s\n",
      "\titers: 200, epoch: 12 | loss: 0.0667879\n",
      "\tspeed: 0.0237s/iter; left time: 467.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0679780 Vali Loss: 0.0853705 Test Loss: 0.0999555\n",
      "Validation loss decreased (0.087022 --> 0.085370).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0692767\n",
      "\tspeed: 0.0483s/iter; left time: 947.9543s\n",
      "\titers: 200, epoch: 13 | loss: 0.0665170\n",
      "\tspeed: 0.0276s/iter; left time: 537.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 224 | Train Loss: 0.0673123 Vali Loss: 0.0845882 Test Loss: 0.0987783\n",
      "Validation loss decreased (0.085370 --> 0.084588).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0656021\n",
      "\tspeed: 0.0443s/iter; left time: 858.7784s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672006\n",
      "\tspeed: 0.0210s/iter; left time: 404.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0669231 Vali Loss: 0.0846042 Test Loss: 0.0992363\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0694302\n",
      "\tspeed: 0.0418s/iter; left time: 800.6396s\n",
      "\titers: 200, epoch: 15 | loss: 0.0681060\n",
      "\tspeed: 0.0215s/iter; left time: 409.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0666513 Vali Loss: 0.0841773 Test Loss: 0.0984955\n",
      "Validation loss decreased (0.084588 --> 0.084177).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0661346\n",
      "\tspeed: 0.0457s/iter; left time: 864.8060s\n",
      "\titers: 200, epoch: 16 | loss: 0.0649915\n",
      "\tspeed: 0.0295s/iter; left time: 556.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0664360 Vali Loss: 0.0840184 Test Loss: 0.0988264\n",
      "Validation loss decreased (0.084177 --> 0.084018).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0671171\n",
      "\tspeed: 0.0539s/iter; left time: 1009.3615s\n",
      "\titers: 200, epoch: 17 | loss: 0.0677117\n",
      "\tspeed: 0.0274s/iter; left time: 509.7516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0660148 Vali Loss: 0.0840101 Test Loss: 0.0986678\n",
      "Validation loss decreased (0.084018 --> 0.084010).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0675118\n",
      "\tspeed: 0.0583s/iter; left time: 1077.7063s\n",
      "\titers: 200, epoch: 18 | loss: 0.0656153\n",
      "\tspeed: 0.0274s/iter; left time: 504.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0658816 Vali Loss: 0.0834030 Test Loss: 0.0977660\n",
      "Validation loss decreased (0.084010 --> 0.083403).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0714609\n",
      "\tspeed: 0.0453s/iter; left time: 826.8664s\n",
      "\titers: 200, epoch: 19 | loss: 0.0633677\n",
      "\tspeed: 0.0207s/iter; left time: 375.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0660491 Vali Loss: 0.0836082 Test Loss: 0.0981088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0693352\n",
      "\tspeed: 0.0506s/iter; left time: 913.2862s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655011\n",
      "\tspeed: 0.0274s/iter; left time: 491.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0657006 Vali Loss: 0.0847137 Test Loss: 0.0990769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0645841\n",
      "\tspeed: 0.0534s/iter; left time: 951.1276s\n",
      "\titers: 200, epoch: 21 | loss: 0.0631504\n",
      "\tspeed: 0.0275s/iter; left time: 486.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0654207 Vali Loss: 0.0844772 Test Loss: 0.0990909\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0674344\n",
      "\tspeed: 0.0521s/iter; left time: 916.3217s\n",
      "\titers: 200, epoch: 22 | loss: 0.0599366\n",
      "\tspeed: 0.0297s/iter; left time: 520.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0651621 Vali Loss: 0.0828909 Test Loss: 0.0970880\n",
      "Validation loss decreased (0.083403 --> 0.082891).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0621208\n",
      "\tspeed: 0.0523s/iter; left time: 907.9803s\n",
      "\titers: 200, epoch: 23 | loss: 0.0677267\n",
      "\tspeed: 0.0314s/iter; left time: 542.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0651345 Vali Loss: 0.0830398 Test Loss: 0.0975798\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0674354\n",
      "\tspeed: 0.0540s/iter; left time: 926.5575s\n",
      "\titers: 200, epoch: 24 | loss: 0.0686529\n",
      "\tspeed: 0.0198s/iter; left time: 337.5598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0650440 Vali Loss: 0.0838286 Test Loss: 0.0982516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0652532\n",
      "\tspeed: 0.0466s/iter; left time: 788.5079s\n",
      "\titers: 200, epoch: 25 | loss: 0.0640813\n",
      "\tspeed: 0.0209s/iter; left time: 351.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0648563 Vali Loss: 0.0832723 Test Loss: 0.0973897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0664463\n",
      "\tspeed: 0.0449s/iter; left time: 750.1042s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690113\n",
      "\tspeed: 0.0202s/iter; left time: 334.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0646453 Vali Loss: 0.0832737 Test Loss: 0.0975967\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0631676\n",
      "\tspeed: 0.0510s/iter; left time: 840.9062s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672755\n",
      "\tspeed: 0.0256s/iter; left time: 419.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0645396 Vali Loss: 0.0829245 Test Loss: 0.0974371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0645668\n",
      "\tspeed: 0.0520s/iter; left time: 845.3728s\n",
      "\titers: 200, epoch: 28 | loss: 0.0650754\n",
      "\tspeed: 0.0272s/iter; left time: 438.7374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0645215 Vali Loss: 0.0832989 Test Loss: 0.0978112\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0664593\n",
      "\tspeed: 0.0507s/iter; left time: 811.8836s\n",
      "\titers: 200, epoch: 29 | loss: 0.0644688\n",
      "\tspeed: 0.0295s/iter; left time: 469.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0644896 Vali Loss: 0.0829223 Test Loss: 0.0976826\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0644817\n",
      "\tspeed: 0.0430s/iter; left time: 679.5506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0646533\n",
      "\tspeed: 0.0269s/iter; left time: 421.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0643942 Vali Loss: 0.0829381 Test Loss: 0.0977078\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0624675\n",
      "\tspeed: 0.0542s/iter; left time: 844.0447s\n",
      "\titers: 200, epoch: 31 | loss: 0.0643884\n",
      "\tspeed: 0.0286s/iter; left time: 442.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0642532 Vali Loss: 0.0827769 Test Loss: 0.0973082\n",
      "Validation loss decreased (0.082891 --> 0.082777).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0681875\n",
      "\tspeed: 0.0556s/iter; left time: 853.2473s\n",
      "\titers: 200, epoch: 32 | loss: 0.0616113\n",
      "\tspeed: 0.0303s/iter; left time: 463.0038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0642251 Vali Loss: 0.0830671 Test Loss: 0.0975252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0641187\n",
      "\tspeed: 0.0450s/iter; left time: 680.3190s\n",
      "\titers: 200, epoch: 33 | loss: 0.0666165\n",
      "\tspeed: 0.0286s/iter; left time: 429.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0642357 Vali Loss: 0.0828618 Test Loss: 0.0970197\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0636954\n",
      "\tspeed: 0.0489s/iter; left time: 729.1244s\n",
      "\titers: 200, epoch: 34 | loss: 0.0630440\n",
      "\tspeed: 0.0247s/iter; left time: 366.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0641547 Vali Loss: 0.0824557 Test Loss: 0.0969022\n",
      "Validation loss decreased (0.082777 --> 0.082456).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0622193\n",
      "\tspeed: 0.0449s/iter; left time: 659.3299s\n",
      "\titers: 200, epoch: 35 | loss: 0.0636692\n",
      "\tspeed: 0.0226s/iter; left time: 330.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0643083 Vali Loss: 0.0828074 Test Loss: 0.0972235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0612470\n",
      "\tspeed: 0.0422s/iter; left time: 610.6660s\n",
      "\titers: 200, epoch: 36 | loss: 0.0639241\n",
      "\tspeed: 0.0202s/iter; left time: 289.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0640914 Vali Loss: 0.0827465 Test Loss: 0.0971811\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0610399\n",
      "\tspeed: 0.0400s/iter; left time: 570.0259s\n",
      "\titers: 200, epoch: 37 | loss: 0.0639980\n",
      "\tspeed: 0.0202s/iter; left time: 286.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0640214 Vali Loss: 0.0826604 Test Loss: 0.0969396\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0615456\n",
      "\tspeed: 0.0443s/iter; left time: 620.8189s\n",
      "\titers: 200, epoch: 38 | loss: 0.0634916\n",
      "\tspeed: 0.0255s/iter; left time: 355.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0639855 Vali Loss: 0.0824150 Test Loss: 0.0968775\n",
      "Validation loss decreased (0.082456 --> 0.082415).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0619426\n",
      "\tspeed: 0.0482s/iter; left time: 664.6214s\n",
      "\titers: 200, epoch: 39 | loss: 0.0632626\n",
      "\tspeed: 0.0271s/iter; left time: 370.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0639404 Vali Loss: 0.0825230 Test Loss: 0.0968823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0622384\n",
      "\tspeed: 0.0449s/iter; left time: 608.6732s\n",
      "\titers: 200, epoch: 40 | loss: 0.0653419\n",
      "\tspeed: 0.0216s/iter; left time: 291.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0639040 Vali Loss: 0.0826247 Test Loss: 0.0971827\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0622402\n",
      "\tspeed: 0.0540s/iter; left time: 720.6499s\n",
      "\titers: 200, epoch: 41 | loss: 0.0681489\n",
      "\tspeed: 0.0300s/iter; left time: 397.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0639531 Vali Loss: 0.0824845 Test Loss: 0.0970259\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0600193\n",
      "\tspeed: 0.0480s/iter; left time: 629.2928s\n",
      "\titers: 200, epoch: 42 | loss: 0.0656501\n",
      "\tspeed: 0.0314s/iter; left time: 408.4169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0639749 Vali Loss: 0.0826431 Test Loss: 0.0971799\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0648052\n",
      "\tspeed: 0.0527s/iter; left time: 679.5235s\n",
      "\titers: 200, epoch: 43 | loss: 0.0589884\n",
      "\tspeed: 0.0269s/iter; left time: 344.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0639537 Vali Loss: 0.0826725 Test Loss: 0.0971828\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0641146\n",
      "\tspeed: 0.0457s/iter; left time: 578.6822s\n",
      "\titers: 200, epoch: 44 | loss: 0.0596302\n",
      "\tspeed: 0.0188s/iter; left time: 235.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0639466 Vali Loss: 0.0823582 Test Loss: 0.0966646\n",
      "Validation loss decreased (0.082415 --> 0.082358).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0667999\n",
      "\tspeed: 0.0488s/iter; left time: 606.6940s\n",
      "\titers: 200, epoch: 45 | loss: 0.0610123\n",
      "\tspeed: 0.0287s/iter; left time: 354.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0638720 Vali Loss: 0.0826842 Test Loss: 0.0970405\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0662433\n",
      "\tspeed: 0.0465s/iter; left time: 568.6489s\n",
      "\titers: 200, epoch: 46 | loss: 0.0623408\n",
      "\tspeed: 0.0203s/iter; left time: 245.9105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0638345 Vali Loss: 0.0821321 Test Loss: 0.0965207\n",
      "Validation loss decreased (0.082358 --> 0.082132).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0666271\n",
      "\tspeed: 0.0440s/iter; left time: 527.7319s\n",
      "\titers: 200, epoch: 47 | loss: 0.0667121\n",
      "\tspeed: 0.0226s/iter; left time: 269.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0638445 Vali Loss: 0.0821554 Test Loss: 0.0965238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0633042\n",
      "\tspeed: 0.0417s/iter; left time: 490.7048s\n",
      "\titers: 200, epoch: 48 | loss: 0.0671471\n",
      "\tspeed: 0.0203s/iter; left time: 236.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0637768 Vali Loss: 0.0820908 Test Loss: 0.0964016\n",
      "Validation loss decreased (0.082132 --> 0.082091).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0634805\n",
      "\tspeed: 0.0504s/iter; left time: 582.3673s\n",
      "\titers: 200, epoch: 49 | loss: 0.0625857\n",
      "\tspeed: 0.0258s/iter; left time: 295.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0638343 Vali Loss: 0.0821824 Test Loss: 0.0965416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0606687\n",
      "\tspeed: 0.0576s/iter; left time: 652.5111s\n",
      "\titers: 200, epoch: 50 | loss: 0.0647426\n",
      "\tspeed: 0.0316s/iter; left time: 354.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0638463 Vali Loss: 0.0825070 Test Loss: 0.0968679\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0637618\n",
      "\tspeed: 0.0519s/iter; left time: 576.2444s\n",
      "\titers: 200, epoch: 51 | loss: 0.0620940\n",
      "\tspeed: 0.0314s/iter; left time: 345.4218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0637786 Vali Loss: 0.0824945 Test Loss: 0.0968915\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0640637\n",
      "\tspeed: 0.0544s/iter; left time: 591.1741s\n",
      "\titers: 200, epoch: 52 | loss: 0.0660916\n",
      "\tspeed: 0.0314s/iter; left time: 338.7630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0637567 Vali Loss: 0.0824626 Test Loss: 0.0968755\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0637561\n",
      "\tspeed: 0.0498s/iter; left time: 530.3554s\n",
      "\titers: 200, epoch: 53 | loss: 0.0647150\n",
      "\tspeed: 0.0288s/iter; left time: 303.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0637708 Vali Loss: 0.0825214 Test Loss: 0.0969042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0608237\n",
      "\tspeed: 0.0526s/iter; left time: 549.0347s\n",
      "\titers: 200, epoch: 54 | loss: 0.0656322\n",
      "\tspeed: 0.0272s/iter; left time: 280.7745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0637851 Vali Loss: 0.0821847 Test Loss: 0.0966558\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0650514\n",
      "\tspeed: 0.0502s/iter; left time: 512.6008s\n",
      "\titers: 200, epoch: 55 | loss: 0.0661974\n",
      "\tspeed: 0.0291s/iter; left time: 294.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0638444 Vali Loss: 0.0821483 Test Loss: 0.0965065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0597372\n",
      "\tspeed: 0.0478s/iter; left time: 476.8129s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632660\n",
      "\tspeed: 0.0235s/iter; left time: 232.1489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0637735 Vali Loss: 0.0823056 Test Loss: 0.0967444\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0675462\n",
      "\tspeed: 0.0503s/iter; left time: 490.5745s\n",
      "\titers: 200, epoch: 57 | loss: 0.0671721\n",
      "\tspeed: 0.0209s/iter; left time: 202.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0637652 Vali Loss: 0.0822774 Test Loss: 0.0967212\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0638920\n",
      "\tspeed: 0.0560s/iter; left time: 533.9923s\n",
      "\titers: 200, epoch: 58 | loss: 0.0661793\n",
      "\tspeed: 0.0378s/iter; left time: 356.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0637072 Vali Loss: 0.0823307 Test Loss: 0.0969368\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02761567384004593, rmse:0.16617964208126068, mae:0.0964016243815422, rse:0.642827033996582\n",
      "Intermediate time for FR and pred_len 96: 00h:13m:07.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3056463\n",
      "\tspeed: 0.0432s/iter; left time: 958.4545s\n",
      "\titers: 200, epoch: 1 | loss: 0.2750270\n",
      "\tspeed: 0.0197s/iter; left time: 434.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.3081200 Vali Loss: 0.1966147 Test Loss: 0.2026496\n",
      "Validation loss decreased (inf --> 0.196615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406024\n",
      "\tspeed: 0.0502s/iter; left time: 1103.2700s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148641\n",
      "\tspeed: 0.0218s/iter; left time: 477.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.1478834 Vali Loss: 0.1124123 Test Loss: 0.1319528\n",
      "Validation loss decreased (0.196615 --> 0.112412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1052083\n",
      "\tspeed: 0.0453s/iter; left time: 986.2718s\n",
      "\titers: 200, epoch: 3 | loss: 0.0980960\n",
      "\tspeed: 0.0230s/iter; left time: 497.2350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.1014490 Vali Loss: 0.1101401 Test Loss: 0.1290472\n",
      "Validation loss decreased (0.112412 --> 0.110140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891950\n",
      "\tspeed: 0.0460s/iter; left time: 990.0301s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838128\n",
      "\tspeed: 0.0243s/iter; left time: 520.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0888782 Vali Loss: 0.1001368 Test Loss: 0.1178571\n",
      "Validation loss decreased (0.110140 --> 0.100137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785809\n",
      "\tspeed: 0.0458s/iter; left time: 976.6296s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798440\n",
      "\tspeed: 0.0222s/iter; left time: 471.6833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0801975 Vali Loss: 0.0948170 Test Loss: 0.1117502\n",
      "Validation loss decreased (0.100137 --> 0.094817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862667\n",
      "\tspeed: 0.0475s/iter; left time: 1001.3537s\n",
      "\titers: 200, epoch: 6 | loss: 0.0743461\n",
      "\tspeed: 0.0200s/iter; left time: 419.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0784861 Vali Loss: 0.0913564 Test Loss: 0.1107985\n",
      "Validation loss decreased (0.094817 --> 0.091356).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756594\n",
      "\tspeed: 0.0435s/iter; left time: 907.6231s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737419\n",
      "\tspeed: 0.0229s/iter; left time: 475.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0754298 Vali Loss: 0.0909558 Test Loss: 0.1092427\n",
      "Validation loss decreased (0.091356 --> 0.090956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0721901\n",
      "\tspeed: 0.0472s/iter; left time: 974.0157s\n",
      "\titers: 200, epoch: 8 | loss: 0.0744981\n",
      "\tspeed: 0.0192s/iter; left time: 394.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0740356 Vali Loss: 0.0898430 Test Loss: 0.1084145\n",
      "Validation loss decreased (0.090956 --> 0.089843).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0712783\n",
      "\tspeed: 0.0448s/iter; left time: 914.1997s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681567\n",
      "\tspeed: 0.0262s/iter; left time: 532.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0729723 Vali Loss: 0.0880685 Test Loss: 0.1060141\n",
      "Validation loss decreased (0.089843 --> 0.088068).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0713213\n",
      "\tspeed: 0.0548s/iter; left time: 1107.5876s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768684\n",
      "\tspeed: 0.0304s/iter; left time: 610.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0722284 Vali Loss: 0.0871236 Test Loss: 0.1050940\n",
      "Validation loss decreased (0.088068 --> 0.087124).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0704259\n",
      "\tspeed: 0.0516s/iter; left time: 1031.3072s\n",
      "\titers: 200, epoch: 11 | loss: 0.0723021\n",
      "\tspeed: 0.0244s/iter; left time: 484.8532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0715449 Vali Loss: 0.0877762 Test Loss: 0.1076831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0695812\n",
      "\tspeed: 0.0451s/iter; left time: 890.7229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746474\n",
      "\tspeed: 0.0216s/iter; left time: 424.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0711022 Vali Loss: 0.0866286 Test Loss: 0.1063094\n",
      "Validation loss decreased (0.087124 --> 0.086629).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0669145\n",
      "\tspeed: 0.0463s/iter; left time: 904.0279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0660579\n",
      "\tspeed: 0.0281s/iter; left time: 546.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0705118 Vali Loss: 0.0863909 Test Loss: 0.1063076\n",
      "Validation loss decreased (0.086629 --> 0.086391).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0747703\n",
      "\tspeed: 0.0485s/iter; left time: 936.2687s\n",
      "\titers: 200, epoch: 14 | loss: 0.0690772\n",
      "\tspeed: 0.0210s/iter; left time: 403.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0705380 Vali Loss: 0.0877921 Test Loss: 0.1085731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0695677\n",
      "\tspeed: 0.0419s/iter; left time: 798.9642s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720575\n",
      "\tspeed: 0.0261s/iter; left time: 494.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0704207 Vali Loss: 0.0875006 Test Loss: 0.1082015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0641172\n",
      "\tspeed: 0.0479s/iter; left time: 902.9028s\n",
      "\titers: 200, epoch: 16 | loss: 0.0675112\n",
      "\tspeed: 0.0287s/iter; left time: 538.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0697628 Vali Loss: 0.0860266 Test Loss: 0.1058902\n",
      "Validation loss decreased (0.086391 --> 0.086027).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685382\n",
      "\tspeed: 0.0553s/iter; left time: 1029.6764s\n",
      "\titers: 200, epoch: 17 | loss: 0.0676206\n",
      "\tspeed: 0.0231s/iter; left time: 427.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0694674 Vali Loss: 0.0891481 Test Loss: 0.1103076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680806\n",
      "\tspeed: 0.0459s/iter; left time: 844.3212s\n",
      "\titers: 200, epoch: 18 | loss: 0.0670943\n",
      "\tspeed: 0.0276s/iter; left time: 505.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.0694200 Vali Loss: 0.0871083 Test Loss: 0.1089652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0665102\n",
      "\tspeed: 0.0508s/iter; left time: 923.5043s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682023\n",
      "\tspeed: 0.0304s/iter; left time: 549.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.0689093 Vali Loss: 0.0853713 Test Loss: 0.1053322\n",
      "Validation loss decreased (0.086027 --> 0.085371).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0679075\n",
      "\tspeed: 0.0529s/iter; left time: 949.7931s\n",
      "\titers: 200, epoch: 20 | loss: 0.0668783\n",
      "\tspeed: 0.0293s/iter; left time: 524.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 223 | Train Loss: 0.0687146 Vali Loss: 0.0857996 Test Loss: 0.1070610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0672480\n",
      "\tspeed: 0.0464s/iter; left time: 822.8238s\n",
      "\titers: 200, epoch: 21 | loss: 0.0715724\n",
      "\tspeed: 0.0253s/iter; left time: 446.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0686488 Vali Loss: 0.0860352 Test Loss: 0.1068843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0631575\n",
      "\tspeed: 0.0501s/iter; left time: 877.0614s\n",
      "\titers: 200, epoch: 22 | loss: 0.0676802\n",
      "\tspeed: 0.0294s/iter; left time: 512.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0684194 Vali Loss: 0.0857368 Test Loss: 0.1064262\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0676339\n",
      "\tspeed: 0.0518s/iter; left time: 895.4907s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664129\n",
      "\tspeed: 0.0313s/iter; left time: 537.6609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0682457 Vali Loss: 0.0859168 Test Loss: 0.1066891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0681765\n",
      "\tspeed: 0.0512s/iter; left time: 874.2927s\n",
      "\titers: 200, epoch: 24 | loss: 0.0656270\n",
      "\tspeed: 0.0279s/iter; left time: 473.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0680834 Vali Loss: 0.0859287 Test Loss: 0.1064331\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0691191\n",
      "\tspeed: 0.0438s/iter; left time: 737.6874s\n",
      "\titers: 200, epoch: 25 | loss: 0.0680214\n",
      "\tspeed: 0.0257s/iter; left time: 431.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0680672 Vali Loss: 0.0858024 Test Loss: 0.1064162\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0693632\n",
      "\tspeed: 0.0560s/iter; left time: 930.7516s\n",
      "\titers: 200, epoch: 26 | loss: 0.0709559\n",
      "\tspeed: 0.0312s/iter; left time: 516.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 223 | Train Loss: 0.0679998 Vali Loss: 0.0858554 Test Loss: 0.1063226\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0635644\n",
      "\tspeed: 0.0517s/iter; left time: 848.2680s\n",
      "\titers: 200, epoch: 27 | loss: 0.0641330\n",
      "\tspeed: 0.0199s/iter; left time: 324.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0679186 Vali Loss: 0.0856566 Test Loss: 0.1063391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0665480\n",
      "\tspeed: 0.0445s/iter; left time: 720.4938s\n",
      "\titers: 200, epoch: 28 | loss: 0.0635692\n",
      "\tspeed: 0.0213s/iter; left time: 343.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0678170 Vali Loss: 0.0862652 Test Loss: 0.1069979\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0685888\n",
      "\tspeed: 0.0495s/iter; left time: 789.2084s\n",
      "\titers: 200, epoch: 29 | loss: 0.0666688\n",
      "\tspeed: 0.0320s/iter; left time: 508.1280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.0677126 Vali Loss: 0.0856623 Test Loss: 0.1061103\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03186313062906265, rmse:0.17850247025489807, mae:0.10533218085765839, rse:0.6913569569587708\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3086566\n",
      "\tspeed: 0.0314s/iter; left time: 698.1451s\n",
      "\titers: 200, epoch: 1 | loss: 0.2695197\n",
      "\tspeed: 0.0301s/iter; left time: 665.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.3090918 Vali Loss: 0.1980705 Test Loss: 0.2037260\n",
      "Validation loss decreased (inf --> 0.198070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1526618\n",
      "\tspeed: 0.0507s/iter; left time: 1115.2961s\n",
      "\titers: 200, epoch: 2 | loss: 0.1124446\n",
      "\tspeed: 0.0239s/iter; left time: 521.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.1519749 Vali Loss: 0.1137167 Test Loss: 0.1341241\n",
      "Validation loss decreased (0.198070 --> 0.113717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0985751\n",
      "\tspeed: 0.0478s/iter; left time: 1039.5313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0913702\n",
      "\tspeed: 0.0276s/iter; left time: 598.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0992521 Vali Loss: 0.1056150 Test Loss: 0.1239647\n",
      "Validation loss decreased (0.113717 --> 0.105615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0906512\n",
      "\tspeed: 0.0544s/iter; left time: 1172.2221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797258\n",
      "\tspeed: 0.0278s/iter; left time: 595.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0855682 Vali Loss: 0.0995753 Test Loss: 0.1196666\n",
      "Validation loss decreased (0.105615 --> 0.099575).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813881\n",
      "\tspeed: 0.0454s/iter; left time: 966.8109s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773556\n",
      "\tspeed: 0.0277s/iter; left time: 586.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.0798479 Vali Loss: 0.0971744 Test Loss: 0.1152703\n",
      "Validation loss decreased (0.099575 --> 0.097174).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0781140\n",
      "\tspeed: 0.0431s/iter; left time: 909.1819s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791254\n",
      "\tspeed: 0.0210s/iter; left time: 441.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0766583 Vali Loss: 0.0947090 Test Loss: 0.1131355\n",
      "Validation loss decreased (0.097174 --> 0.094709).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0810955\n",
      "\tspeed: 0.0524s/iter; left time: 1093.0430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761113\n",
      "\tspeed: 0.0237s/iter; left time: 491.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0759859 Vali Loss: 0.0927259 Test Loss: 0.1111074\n",
      "Validation loss decreased (0.094709 --> 0.092726).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0730600\n",
      "\tspeed: 0.0453s/iter; left time: 935.2941s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758441\n",
      "\tspeed: 0.0271s/iter; left time: 557.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0733081 Vali Loss: 0.0908413 Test Loss: 0.1099726\n",
      "Validation loss decreased (0.092726 --> 0.090841).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785483\n",
      "\tspeed: 0.0471s/iter; left time: 960.6679s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748036\n",
      "\tspeed: 0.0244s/iter; left time: 494.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0726676 Vali Loss: 0.0919163 Test Loss: 0.1107082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0702548\n",
      "\tspeed: 0.0507s/iter; left time: 1023.3934s\n",
      "\titers: 200, epoch: 10 | loss: 0.0710367\n",
      "\tspeed: 0.0237s/iter; left time: 475.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0723632 Vali Loss: 0.0902203 Test Loss: 0.1087576\n",
      "Validation loss decreased (0.090841 --> 0.090220).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0724824\n",
      "\tspeed: 0.0495s/iter; left time: 989.1715s\n",
      "\titers: 200, epoch: 11 | loss: 0.0704491\n",
      "\tspeed: 0.0250s/iter; left time: 497.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0712889 Vali Loss: 0.0888398 Test Loss: 0.1067494\n",
      "Validation loss decreased (0.090220 --> 0.088840).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0708217\n",
      "\tspeed: 0.0458s/iter; left time: 904.7025s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709312\n",
      "\tspeed: 0.0189s/iter; left time: 372.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0705554 Vali Loss: 0.0888379 Test Loss: 0.1077829\n",
      "Validation loss decreased (0.088840 --> 0.088838).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0671993\n",
      "\tspeed: 0.0468s/iter; left time: 914.7262s\n",
      "\titers: 200, epoch: 13 | loss: 0.0711167\n",
      "\tspeed: 0.0229s/iter; left time: 444.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0701558 Vali Loss: 0.0895943 Test Loss: 0.1089024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0723387\n",
      "\tspeed: 0.0426s/iter; left time: 821.5076s\n",
      "\titers: 200, epoch: 14 | loss: 0.0676399\n",
      "\tspeed: 0.0198s/iter; left time: 380.9261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0698811 Vali Loss: 0.0888093 Test Loss: 0.1087146\n",
      "Validation loss decreased (0.088838 --> 0.088809).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0679977\n",
      "\tspeed: 0.0525s/iter; left time: 1001.2377s\n",
      "\titers: 200, epoch: 15 | loss: 0.0666840\n",
      "\tspeed: 0.0210s/iter; left time: 398.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0695363 Vali Loss: 0.0881017 Test Loss: 0.1077840\n",
      "Validation loss decreased (0.088809 --> 0.088102).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734538\n",
      "\tspeed: 0.0424s/iter; left time: 800.1480s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708031\n",
      "\tspeed: 0.0255s/iter; left time: 479.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0693809 Vali Loss: 0.0891334 Test Loss: 0.1089423\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0675654\n",
      "\tspeed: 0.0460s/iter; left time: 857.9154s\n",
      "\titers: 200, epoch: 17 | loss: 0.0670113\n",
      "\tspeed: 0.0307s/iter; left time: 568.1402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0692264 Vali Loss: 0.0890718 Test Loss: 0.1089065\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679698\n",
      "\tspeed: 0.0525s/iter; left time: 965.8351s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702774\n",
      "\tspeed: 0.0286s/iter; left time: 524.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 223 | Train Loss: 0.0688854 Vali Loss: 0.0884281 Test Loss: 0.1085520\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0664084\n",
      "\tspeed: 0.0496s/iter; left time: 901.2070s\n",
      "\titers: 200, epoch: 19 | loss: 0.0710102\n",
      "\tspeed: 0.0206s/iter; left time: 373.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0685317 Vali Loss: 0.0879127 Test Loss: 0.1080039\n",
      "Validation loss decreased (0.088102 --> 0.087913).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0691497\n",
      "\tspeed: 0.0491s/iter; left time: 882.7902s\n",
      "\titers: 200, epoch: 20 | loss: 0.0672635\n",
      "\tspeed: 0.0272s/iter; left time: 486.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0684710 Vali Loss: 0.0876323 Test Loss: 0.1077336\n",
      "Validation loss decreased (0.087913 --> 0.087632).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0719094\n",
      "\tspeed: 0.0497s/iter; left time: 881.2555s\n",
      "\titers: 200, epoch: 21 | loss: 0.0665062\n",
      "\tspeed: 0.0233s/iter; left time: 411.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0685669 Vali Loss: 0.0882193 Test Loss: 0.1082138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0682066\n",
      "\tspeed: 0.0449s/iter; left time: 787.2955s\n",
      "\titers: 200, epoch: 22 | loss: 0.0664069\n",
      "\tspeed: 0.0291s/iter; left time: 506.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0681166 Vali Loss: 0.0886123 Test Loss: 0.1091127\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0661859\n",
      "\tspeed: 0.0448s/iter; left time: 774.4417s\n",
      "\titers: 200, epoch: 23 | loss: 0.0701146\n",
      "\tspeed: 0.0237s/iter; left time: 407.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0681925 Vali Loss: 0.0889241 Test Loss: 0.1093656\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0683385\n",
      "\tspeed: 0.0524s/iter; left time: 894.6639s\n",
      "\titers: 200, epoch: 24 | loss: 0.0674945\n",
      "\tspeed: 0.0281s/iter; left time: 476.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0678353 Vali Loss: 0.0876623 Test Loss: 0.1077969\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0663775\n",
      "\tspeed: 0.0445s/iter; left time: 749.2741s\n",
      "\titers: 200, epoch: 25 | loss: 0.0675381\n",
      "\tspeed: 0.0257s/iter; left time: 430.7549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 223 | Train Loss: 0.0679336 Vali Loss: 0.0884676 Test Loss: 0.1086316\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0698588\n",
      "\tspeed: 0.0440s/iter; left time: 730.8667s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684635\n",
      "\tspeed: 0.0215s/iter; left time: 355.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0676934 Vali Loss: 0.0880366 Test Loss: 0.1084559\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1104503\n",
      "\tspeed: 0.0430s/iter; left time: 704.8514s\n",
      "\titers: 200, epoch: 27 | loss: 0.0674606\n",
      "\tspeed: 0.0202s/iter; left time: 329.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0678633 Vali Loss: 0.0885089 Test Loss: 0.1085655\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0703076\n",
      "\tspeed: 0.0410s/iter; left time: 662.6916s\n",
      "\titers: 200, epoch: 28 | loss: 0.0666808\n",
      "\tspeed: 0.0213s/iter; left time: 342.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0676713 Vali Loss: 0.0881881 Test Loss: 0.1080549\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0692724\n",
      "\tspeed: 0.0500s/iter; left time: 798.5132s\n",
      "\titers: 200, epoch: 29 | loss: 0.0655584\n",
      "\tspeed: 0.0282s/iter; left time: 446.4490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0675651 Vali Loss: 0.0877663 Test Loss: 0.1076566\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0627391\n",
      "\tspeed: 0.0520s/iter; left time: 818.2524s\n",
      "\titers: 200, epoch: 30 | loss: 0.0679872\n",
      "\tspeed: 0.0306s/iter; left time: 478.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0675567 Vali Loss: 0.0879854 Test Loss: 0.1077711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.033201489597558975, rmse:0.18221275508403778, mae:0.1077335923910141, rse:0.7057272791862488\n",
      "Intermediate time for FR and pred_len 168: 00h:07m:23.74s\n",
      "Intermediate time for FR: 00h:35m:54.94s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3241130\n",
      "\tspeed: 0.0455s/iter; left time: 1015.2360s\n",
      "\titers: 200, epoch: 1 | loss: 0.2924705\n",
      "\tspeed: 0.0184s/iter; left time: 408.8592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.3293812 Vali Loss: 0.2032730 Test Loss: 0.2058396\n",
      "Validation loss decreased (inf --> 0.203273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1823538\n",
      "\tspeed: 0.0463s/iter; left time: 1021.9118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1272631\n",
      "\tspeed: 0.0246s/iter; left time: 540.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.1802252 Vali Loss: 0.0967880 Test Loss: 0.1039044\n",
      "Validation loss decreased (0.203273 --> 0.096788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1102813\n",
      "\tspeed: 0.0403s/iter; left time: 880.2672s\n",
      "\titers: 200, epoch: 3 | loss: 0.1015408\n",
      "\tspeed: 0.0203s/iter; left time: 442.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.1101142 Vali Loss: 0.0867770 Test Loss: 0.0935860\n",
      "Validation loss decreased (0.096788 --> 0.086777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0987595\n",
      "\tspeed: 0.0496s/iter; left time: 1073.2602s\n",
      "\titers: 200, epoch: 4 | loss: 0.0914146\n",
      "\tspeed: 0.0256s/iter; left time: 550.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0953743 Vali Loss: 0.0836503 Test Loss: 0.0907633\n",
      "Validation loss decreased (0.086777 --> 0.083650).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0914880\n",
      "\tspeed: 0.0504s/iter; left time: 1077.9425s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797405\n",
      "\tspeed: 0.0247s/iter; left time: 525.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0867192 Vali Loss: 0.0805143 Test Loss: 0.0885993\n",
      "Validation loss decreased (0.083650 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831972\n",
      "\tspeed: 0.0504s/iter; left time: 1067.9234s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841526\n",
      "\tspeed: 0.0334s/iter; left time: 703.1924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0815772 Vali Loss: 0.0758380 Test Loss: 0.0836374\n",
      "Validation loss decreased (0.080514 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0780363\n",
      "\tspeed: 0.0429s/iter; left time: 898.7416s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747870\n",
      "\tspeed: 0.0286s/iter; left time: 596.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0782017 Vali Loss: 0.0735970 Test Loss: 0.0810491\n",
      "Validation loss decreased (0.075838 --> 0.073597).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777398\n",
      "\tspeed: 0.0475s/iter; left time: 984.4845s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721127\n",
      "\tspeed: 0.0289s/iter; left time: 596.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0758689 Vali Loss: 0.0717367 Test Loss: 0.0790521\n",
      "Validation loss decreased (0.073597 --> 0.071737).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745881\n",
      "\tspeed: 0.0471s/iter; left time: 966.3341s\n",
      "\titers: 200, epoch: 9 | loss: 0.0750067\n",
      "\tspeed: 0.0259s/iter; left time: 528.3670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0736036 Vali Loss: 0.0696429 Test Loss: 0.0766724\n",
      "Validation loss decreased (0.071737 --> 0.069643).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727063\n",
      "\tspeed: 0.0394s/iter; left time: 799.9751s\n",
      "\titers: 200, epoch: 10 | loss: 0.0740233\n",
      "\tspeed: 0.0189s/iter; left time: 381.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0722619 Vali Loss: 0.0725336 Test Loss: 0.0788293\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0735900\n",
      "\tspeed: 0.0460s/iter; left time: 923.4097s\n",
      "\titers: 200, epoch: 11 | loss: 0.0679127\n",
      "\tspeed: 0.0217s/iter; left time: 434.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0710921 Vali Loss: 0.0678468 Test Loss: 0.0742797\n",
      "Validation loss decreased (0.069643 --> 0.067847).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0689806\n",
      "\tspeed: 0.0491s/iter; left time: 974.5832s\n",
      "\titers: 200, epoch: 12 | loss: 0.0633102\n",
      "\tspeed: 0.0263s/iter; left time: 518.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0697913 Vali Loss: 0.0665521 Test Loss: 0.0731295\n",
      "Validation loss decreased (0.067847 --> 0.066552).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659795\n",
      "\tspeed: 0.0487s/iter; left time: 954.9441s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675767\n",
      "\tspeed: 0.0235s/iter; left time: 459.2929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0691679 Vali Loss: 0.0673855 Test Loss: 0.0735560\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0673730\n",
      "\tspeed: 0.0431s/iter; left time: 834.9911s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723676\n",
      "\tspeed: 0.0212s/iter; left time: 409.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0686567 Vali Loss: 0.0658610 Test Loss: 0.0721688\n",
      "Validation loss decreased (0.066552 --> 0.065861).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665028\n",
      "\tspeed: 0.0511s/iter; left time: 979.6216s\n",
      "\titers: 200, epoch: 15 | loss: 0.0716088\n",
      "\tspeed: 0.0231s/iter; left time: 439.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0676216 Vali Loss: 0.0652331 Test Loss: 0.0712755\n",
      "Validation loss decreased (0.065861 --> 0.065233).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0716273\n",
      "\tspeed: 0.0501s/iter; left time: 949.1442s\n",
      "\titers: 200, epoch: 16 | loss: 0.0693894\n",
      "\tspeed: 0.0249s/iter; left time: 469.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0673985 Vali Loss: 0.0654312 Test Loss: 0.0713966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0693793\n",
      "\tspeed: 0.0410s/iter; left time: 767.4978s\n",
      "\titers: 200, epoch: 17 | loss: 0.0694804\n",
      "\tspeed: 0.0250s/iter; left time: 466.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0664789 Vali Loss: 0.0646361 Test Loss: 0.0706474\n",
      "Validation loss decreased (0.065233 --> 0.064636).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657475\n",
      "\tspeed: 0.0495s/iter; left time: 915.1483s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641076\n",
      "\tspeed: 0.0280s/iter; left time: 514.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0663919 Vali Loss: 0.0642198 Test Loss: 0.0705100\n",
      "Validation loss decreased (0.064636 --> 0.064220).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0665292\n",
      "\tspeed: 0.0510s/iter; left time: 931.0821s\n",
      "\titers: 200, epoch: 19 | loss: 0.0665402\n",
      "\tspeed: 0.0281s/iter; left time: 510.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0659680 Vali Loss: 0.0642783 Test Loss: 0.0698895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0663938\n",
      "\tspeed: 0.0473s/iter; left time: 853.4390s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653906\n",
      "\tspeed: 0.0266s/iter; left time: 477.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0654910 Vali Loss: 0.0632012 Test Loss: 0.0692569\n",
      "Validation loss decreased (0.064220 --> 0.063201).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0623271\n",
      "\tspeed: 0.0431s/iter; left time: 767.3229s\n",
      "\titers: 200, epoch: 21 | loss: 0.0649122\n",
      "\tspeed: 0.0283s/iter; left time: 501.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0653263 Vali Loss: 0.0635679 Test Loss: 0.0690093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0663153\n",
      "\tspeed: 0.0490s/iter; left time: 862.2787s\n",
      "\titers: 200, epoch: 22 | loss: 0.0687478\n",
      "\tspeed: 0.0291s/iter; left time: 509.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0651172 Vali Loss: 0.0625556 Test Loss: 0.0682278\n",
      "Validation loss decreased (0.063201 --> 0.062556).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0634903\n",
      "\tspeed: 0.0433s/iter; left time: 751.8490s\n",
      "\titers: 200, epoch: 23 | loss: 0.0630470\n",
      "\tspeed: 0.0201s/iter; left time: 347.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0648620 Vali Loss: 0.0626798 Test Loss: 0.0682294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0678955\n",
      "\tspeed: 0.0434s/iter; left time: 743.6874s\n",
      "\titers: 200, epoch: 24 | loss: 0.0641025\n",
      "\tspeed: 0.0302s/iter; left time: 514.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0647160 Vali Loss: 0.0623281 Test Loss: 0.0676864\n",
      "Validation loss decreased (0.062556 --> 0.062328).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0647797\n",
      "\tspeed: 0.0520s/iter; left time: 879.8693s\n",
      "\titers: 200, epoch: 25 | loss: 0.0662131\n",
      "\tspeed: 0.0267s/iter; left time: 449.1398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0646598 Vali Loss: 0.0623179 Test Loss: 0.0680686\n",
      "Validation loss decreased (0.062328 --> 0.062318).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0650400\n",
      "\tspeed: 0.0428s/iter; left time: 713.9937s\n",
      "\titers: 200, epoch: 26 | loss: 0.0642696\n",
      "\tspeed: 0.0191s/iter; left time: 316.3892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0644105 Vali Loss: 0.0629346 Test Loss: 0.0684340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0605244\n",
      "\tspeed: 0.0392s/iter; left time: 645.5088s\n",
      "\titers: 200, epoch: 27 | loss: 0.0703026\n",
      "\tspeed: 0.0279s/iter; left time: 457.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0641790 Vali Loss: 0.0623579 Test Loss: 0.0675356\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0652979\n",
      "\tspeed: 0.0492s/iter; left time: 800.4165s\n",
      "\titers: 200, epoch: 28 | loss: 0.0681029\n",
      "\tspeed: 0.0220s/iter; left time: 354.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0639849 Vali Loss: 0.0625958 Test Loss: 0.0677266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0646260\n",
      "\tspeed: 0.0440s/iter; left time: 705.0246s\n",
      "\titers: 200, epoch: 29 | loss: 0.0665588\n",
      "\tspeed: 0.0258s/iter; left time: 410.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0639078 Vali Loss: 0.0623994 Test Loss: 0.0674481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0655225\n",
      "\tspeed: 0.0477s/iter; left time: 753.9369s\n",
      "\titers: 200, epoch: 30 | loss: 0.0625272\n",
      "\tspeed: 0.0261s/iter; left time: 409.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0638910 Vali Loss: 0.0624397 Test Loss: 0.0675429\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0643685\n",
      "\tspeed: 0.0511s/iter; left time: 796.8257s\n",
      "\titers: 200, epoch: 31 | loss: 0.0645201\n",
      "\tspeed: 0.0299s/iter; left time: 462.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0637819 Vali Loss: 0.0619371 Test Loss: 0.0671838\n",
      "Validation loss decreased (0.062318 --> 0.061937).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0645308\n",
      "\tspeed: 0.0473s/iter; left time: 725.7635s\n",
      "\titers: 200, epoch: 32 | loss: 0.0612825\n",
      "\tspeed: 0.0255s/iter; left time: 388.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0636294 Vali Loss: 0.0618079 Test Loss: 0.0670642\n",
      "Validation loss decreased (0.061937 --> 0.061808).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0605222\n",
      "\tspeed: 0.0452s/iter; left time: 683.2901s\n",
      "\titers: 200, epoch: 33 | loss: 0.0774714\n",
      "\tspeed: 0.0202s/iter; left time: 303.1384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0636538 Vali Loss: 0.0616663 Test Loss: 0.0670966\n",
      "Validation loss decreased (0.061808 --> 0.061666).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0642374\n",
      "\tspeed: 0.0530s/iter; left time: 790.7591s\n",
      "\titers: 200, epoch: 34 | loss: 0.0668334\n",
      "\tspeed: 0.0314s/iter; left time: 465.2121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0635042 Vali Loss: 0.0616226 Test Loss: 0.0670372\n",
      "Validation loss decreased (0.061666 --> 0.061623).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0596727\n",
      "\tspeed: 0.0461s/iter; left time: 677.2918s\n",
      "\titers: 200, epoch: 35 | loss: 0.0664613\n",
      "\tspeed: 0.0222s/iter; left time: 324.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0634919 Vali Loss: 0.0619105 Test Loss: 0.0669824\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0626855\n",
      "\tspeed: 0.0438s/iter; left time: 633.7191s\n",
      "\titers: 200, epoch: 36 | loss: 0.0639226\n",
      "\tspeed: 0.0209s/iter; left time: 300.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0633828 Vali Loss: 0.0618610 Test Loss: 0.0670171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0650331\n",
      "\tspeed: 0.0437s/iter; left time: 622.0145s\n",
      "\titers: 200, epoch: 37 | loss: 0.0655941\n",
      "\tspeed: 0.0230s/iter; left time: 324.7105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0635640 Vali Loss: 0.0616713 Test Loss: 0.0668667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0631801\n",
      "\tspeed: 0.0460s/iter; left time: 644.0157s\n",
      "\titers: 200, epoch: 38 | loss: 0.0642229\n",
      "\tspeed: 0.0300s/iter; left time: 416.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0633303 Vali Loss: 0.0616391 Test Loss: 0.0667925\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0657096\n",
      "\tspeed: 0.0488s/iter; left time: 672.6955s\n",
      "\titers: 200, epoch: 39 | loss: 0.0616686\n",
      "\tspeed: 0.0293s/iter; left time: 400.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0632752 Vali Loss: 0.0617134 Test Loss: 0.0667563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0655472\n",
      "\tspeed: 0.0464s/iter; left time: 629.8065s\n",
      "\titers: 200, epoch: 40 | loss: 0.0633535\n",
      "\tspeed: 0.0203s/iter; left time: 272.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0633293 Vali Loss: 0.0615791 Test Loss: 0.0667661\n",
      "Validation loss decreased (0.061623 --> 0.061579).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0631283\n",
      "\tspeed: 0.0490s/iter; left time: 654.1491s\n",
      "\titers: 200, epoch: 41 | loss: 0.0635965\n",
      "\tspeed: 0.0248s/iter; left time: 328.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0632867 Vali Loss: 0.0616666 Test Loss: 0.0667767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0649178\n",
      "\tspeed: 0.0409s/iter; left time: 536.9824s\n",
      "\titers: 200, epoch: 42 | loss: 0.0613284\n",
      "\tspeed: 0.0201s/iter; left time: 261.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0631745 Vali Loss: 0.0617066 Test Loss: 0.0667609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0638694\n",
      "\tspeed: 0.0557s/iter; left time: 717.9780s\n",
      "\titers: 200, epoch: 43 | loss: 0.0618264\n",
      "\tspeed: 0.0325s/iter; left time: 415.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0631894 Vali Loss: 0.0615841 Test Loss: 0.0666782\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0655750\n",
      "\tspeed: 0.0490s/iter; left time: 620.3830s\n",
      "\titers: 200, epoch: 44 | loss: 0.0669324\n",
      "\tspeed: 0.0301s/iter; left time: 378.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0631067 Vali Loss: 0.0616196 Test Loss: 0.0666347\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0624282\n",
      "\tspeed: 0.0463s/iter; left time: 575.7970s\n",
      "\titers: 200, epoch: 45 | loss: 0.0640476\n",
      "\tspeed: 0.0208s/iter; left time: 256.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0631008 Vali Loss: 0.0614231 Test Loss: 0.0666792\n",
      "Validation loss decreased (0.061579 --> 0.061423).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0674248\n",
      "\tspeed: 0.0531s/iter; left time: 649.4116s\n",
      "\titers: 200, epoch: 46 | loss: 0.0661356\n",
      "\tspeed: 0.0249s/iter; left time: 301.8947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0631145 Vali Loss: 0.0619511 Test Loss: 0.0668481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0614835\n",
      "\tspeed: 0.0453s/iter; left time: 543.5796s\n",
      "\titers: 200, epoch: 47 | loss: 0.0613391\n",
      "\tspeed: 0.0188s/iter; left time: 223.5930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0631175 Vali Loss: 0.0614797 Test Loss: 0.0665169\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0647382\n",
      "\tspeed: 0.0396s/iter; left time: 466.3848s\n",
      "\titers: 200, epoch: 48 | loss: 0.0606539\n",
      "\tspeed: 0.0234s/iter; left time: 272.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0630384 Vali Loss: 0.0614200 Test Loss: 0.0666373\n",
      "Validation loss decreased (0.061423 --> 0.061420).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0612770\n",
      "\tspeed: 0.0517s/iter; left time: 596.9767s\n",
      "\titers: 200, epoch: 49 | loss: 0.0639531\n",
      "\tspeed: 0.0264s/iter; left time: 302.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0630987 Vali Loss: 0.0614957 Test Loss: 0.0666572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0630490\n",
      "\tspeed: 0.0512s/iter; left time: 579.8451s\n",
      "\titers: 200, epoch: 50 | loss: 0.0627180\n",
      "\tspeed: 0.0317s/iter; left time: 356.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0629948 Vali Loss: 0.0615858 Test Loss: 0.0666445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0643044\n",
      "\tspeed: 0.0515s/iter; left time: 571.6213s\n",
      "\titers: 200, epoch: 51 | loss: 0.0651662\n",
      "\tspeed: 0.0302s/iter; left time: 332.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0630518 Vali Loss: 0.0615273 Test Loss: 0.0666202\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0633636\n",
      "\tspeed: 0.0417s/iter; left time: 453.8192s\n",
      "\titers: 200, epoch: 52 | loss: 0.0714201\n",
      "\tspeed: 0.0203s/iter; left time: 218.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0630121 Vali Loss: 0.0614653 Test Loss: 0.0666067\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0609582\n",
      "\tspeed: 0.0393s/iter; left time: 418.3527s\n",
      "\titers: 200, epoch: 53 | loss: 0.0633616\n",
      "\tspeed: 0.0267s/iter; left time: 282.1671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0631376 Vali Loss: 0.0616569 Test Loss: 0.0665711\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0585576\n",
      "\tspeed: 0.0511s/iter; left time: 532.4380s\n",
      "\titers: 200, epoch: 54 | loss: 0.0632546\n",
      "\tspeed: 0.0300s/iter; left time: 309.4880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0629763 Vali Loss: 0.0614803 Test Loss: 0.0666290\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0602560\n",
      "\tspeed: 0.0429s/iter; left time: 438.0859s\n",
      "\titers: 200, epoch: 55 | loss: 0.0672094\n",
      "\tspeed: 0.0184s/iter; left time: 186.0652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0630724 Vali Loss: 0.0617165 Test Loss: 0.0666758\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0619185\n",
      "\tspeed: 0.0494s/iter; left time: 493.1129s\n",
      "\titers: 200, epoch: 56 | loss: 0.0653871\n",
      "\tspeed: 0.0292s/iter; left time: 288.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0630474 Vali Loss: 0.0612681 Test Loss: 0.0665854\n",
      "Validation loss decreased (0.061420 --> 0.061268).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0649308\n",
      "\tspeed: 0.0438s/iter; left time: 427.7368s\n",
      "\titers: 200, epoch: 57 | loss: 0.0639586\n",
      "\tspeed: 0.0203s/iter; left time: 195.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0629947 Vali Loss: 0.0615242 Test Loss: 0.0665134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0686467\n",
      "\tspeed: 0.0426s/iter; left time: 405.7382s\n",
      "\titers: 200, epoch: 58 | loss: 0.0605051\n",
      "\tspeed: 0.0248s/iter; left time: 233.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0630456 Vali Loss: 0.0616305 Test Loss: 0.0666707\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0625389\n",
      "\tspeed: 0.0532s/iter; left time: 495.5588s\n",
      "\titers: 200, epoch: 59 | loss: 0.0665788\n",
      "\tspeed: 0.0267s/iter; left time: 245.5988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0628446 Vali Loss: 0.0613911 Test Loss: 0.0665266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0664822\n",
      "\tspeed: 0.0492s/iter; left time: 447.2038s\n",
      "\titers: 200, epoch: 60 | loss: 0.0651570\n",
      "\tspeed: 0.0241s/iter; left time: 216.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0629727 Vali Loss: 0.0614867 Test Loss: 0.0664578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0650977\n",
      "\tspeed: 0.0484s/iter; left time: 428.7710s\n",
      "\titers: 200, epoch: 61 | loss: 0.0602411\n",
      "\tspeed: 0.0252s/iter; left time: 220.6008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0630141 Vali Loss: 0.0611951 Test Loss: 0.0666577\n",
      "Validation loss decreased (0.061268 --> 0.061195).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0592171\n",
      "\tspeed: 0.0490s/iter; left time: 423.4738s\n",
      "\titers: 200, epoch: 62 | loss: 0.0611803\n",
      "\tspeed: 0.0194s/iter; left time: 165.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0630164 Vali Loss: 0.0616687 Test Loss: 0.0666349\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0652921\n",
      "\tspeed: 0.0514s/iter; left time: 432.0496s\n",
      "\titers: 200, epoch: 63 | loss: 0.0656076\n",
      "\tspeed: 0.0337s/iter; left time: 279.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0630275 Vali Loss: 0.0614657 Test Loss: 0.0665327\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0642084\n",
      "\tspeed: 0.0494s/iter; left time: 404.8560s\n",
      "\titers: 200, epoch: 64 | loss: 0.0634847\n",
      "\tspeed: 0.0255s/iter; left time: 206.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0630246 Vali Loss: 0.0614483 Test Loss: 0.0665723\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0596807\n",
      "\tspeed: 0.0519s/iter; left time: 413.0950s\n",
      "\titers: 200, epoch: 65 | loss: 0.0615191\n",
      "\tspeed: 0.0295s/iter; left time: 231.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0630400 Vali Loss: 0.0616599 Test Loss: 0.0665759\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0652548\n",
      "\tspeed: 0.0466s/iter; left time: 360.8860s\n",
      "\titers: 200, epoch: 66 | loss: 0.0617529\n",
      "\tspeed: 0.0275s/iter; left time: 209.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0629083 Vali Loss: 0.0615245 Test Loss: 0.0665894\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0601054\n",
      "\tspeed: 0.0425s/iter; left time: 319.8108s\n",
      "\titers: 200, epoch: 67 | loss: 0.0624820\n",
      "\tspeed: 0.0292s/iter; left time: 216.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0629163 Vali Loss: 0.0613202 Test Loss: 0.0664972\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0644628\n",
      "\tspeed: 0.0485s/iter; left time: 353.6545s\n",
      "\titers: 200, epoch: 68 | loss: 0.0616825\n",
      "\tspeed: 0.0185s/iter; left time: 133.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0629542 Vali Loss: 0.0613180 Test Loss: 0.0665440\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0636454\n",
      "\tspeed: 0.0430s/iter; left time: 303.6905s\n",
      "\titers: 200, epoch: 69 | loss: 0.0631515\n",
      "\tspeed: 0.0258s/iter; left time: 179.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0629030 Vali Loss: 0.0613177 Test Loss: 0.0666159\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0647619\n",
      "\tspeed: 0.0435s/iter; left time: 298.0702s\n",
      "\titers: 200, epoch: 70 | loss: 0.0614377\n",
      "\tspeed: 0.0216s/iter; left time: 145.8147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0629839 Vali Loss: 0.0614010 Test Loss: 0.0664651\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0641568\n",
      "\tspeed: 0.0502s/iter; left time: 332.4925s\n",
      "\titers: 200, epoch: 71 | loss: 0.0648776\n",
      "\tspeed: 0.0209s/iter; left time: 136.5002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0629476 Vali Loss: 0.0613982 Test Loss: 0.0665674\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011795281432569027, rmse:0.10860608518123627, mae:0.06665770709514618, rse:0.4103688895702362\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3258120\n",
      "\tspeed: 0.0343s/iter; left time: 765.5726s\n",
      "\titers: 200, epoch: 1 | loss: 0.2851000\n",
      "\tspeed: 0.0334s/iter; left time: 741.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.3255024 Vali Loss: 0.1981865 Test Loss: 0.2010288\n",
      "Validation loss decreased (inf --> 0.198187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1827398\n",
      "\tspeed: 0.0526s/iter; left time: 1162.3415s\n",
      "\titers: 200, epoch: 2 | loss: 0.1276549\n",
      "\tspeed: 0.0267s/iter; left time: 587.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.1788280 Vali Loss: 0.0979679 Test Loss: 0.1043482\n",
      "Validation loss decreased (0.198187 --> 0.097968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1068633\n",
      "\tspeed: 0.0516s/iter; left time: 1127.4411s\n",
      "\titers: 200, epoch: 3 | loss: 0.1053091\n",
      "\tspeed: 0.0294s/iter; left time: 640.5853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1110334 Vali Loss: 0.0904646 Test Loss: 0.0971465\n",
      "Validation loss decreased (0.097968 --> 0.090465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0930720\n",
      "\tspeed: 0.0529s/iter; left time: 1144.0918s\n",
      "\titers: 200, epoch: 4 | loss: 0.0908884\n",
      "\tspeed: 0.0250s/iter; left time: 537.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0964553 Vali Loss: 0.0866821 Test Loss: 0.0951826\n",
      "Validation loss decreased (0.090465 --> 0.086682).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0868555\n",
      "\tspeed: 0.0421s/iter; left time: 901.1109s\n",
      "\titers: 200, epoch: 5 | loss: 0.0821101\n",
      "\tspeed: 0.0210s/iter; left time: 446.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0877136 Vali Loss: 0.0809283 Test Loss: 0.0884110\n",
      "Validation loss decreased (0.086682 --> 0.080928).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794797\n",
      "\tspeed: 0.0435s/iter; left time: 921.3414s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818765\n",
      "\tspeed: 0.0205s/iter; left time: 431.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0818037 Vali Loss: 0.0786988 Test Loss: 0.0872715\n",
      "Validation loss decreased (0.080928 --> 0.078699).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0751359\n",
      "\tspeed: 0.0462s/iter; left time: 968.6304s\n",
      "\titers: 200, epoch: 7 | loss: 0.0803383\n",
      "\tspeed: 0.0239s/iter; left time: 498.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0780993 Vali Loss: 0.0746620 Test Loss: 0.0828139\n",
      "Validation loss decreased (0.078699 --> 0.074662).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749806\n",
      "\tspeed: 0.0435s/iter; left time: 902.2549s\n",
      "\titers: 200, epoch: 8 | loss: 0.0705132\n",
      "\tspeed: 0.0200s/iter; left time: 413.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0753688 Vali Loss: 0.0729065 Test Loss: 0.0795251\n",
      "Validation loss decreased (0.074662 --> 0.072907).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776110\n",
      "\tspeed: 0.0578s/iter; left time: 1186.1041s\n",
      "\titers: 200, epoch: 9 | loss: 0.0663103\n",
      "\tspeed: 0.0305s/iter; left time: 623.2589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0732443 Vali Loss: 0.0709228 Test Loss: 0.0773399\n",
      "Validation loss decreased (0.072907 --> 0.070923).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0685485\n",
      "\tspeed: 0.0519s/iter; left time: 1053.2958s\n",
      "\titers: 200, epoch: 10 | loss: 0.0702540\n",
      "\tspeed: 0.0298s/iter; left time: 601.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0722355 Vali Loss: 0.0695111 Test Loss: 0.0763614\n",
      "Validation loss decreased (0.070923 --> 0.069511).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0698180\n",
      "\tspeed: 0.0442s/iter; left time: 885.8900s\n",
      "\titers: 200, epoch: 11 | loss: 0.0721217\n",
      "\tspeed: 0.0273s/iter; left time: 544.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0713347 Vali Loss: 0.0678016 Test Loss: 0.0749871\n",
      "Validation loss decreased (0.069511 --> 0.067802).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0731305\n",
      "\tspeed: 0.0544s/iter; left time: 1079.1570s\n",
      "\titers: 200, epoch: 12 | loss: 0.0701336\n",
      "\tspeed: 0.0215s/iter; left time: 424.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0692261 Vali Loss: 0.0661294 Test Loss: 0.0724961\n",
      "Validation loss decreased (0.067802 --> 0.066129).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0687152\n",
      "\tspeed: 0.0445s/iter; left time: 872.5383s\n",
      "\titers: 200, epoch: 13 | loss: 0.0715028\n",
      "\tspeed: 0.0282s/iter; left time: 549.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0693650 Vali Loss: 0.0677449 Test Loss: 0.0741879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0668915\n",
      "\tspeed: 0.0416s/iter; left time: 807.2913s\n",
      "\titers: 200, epoch: 14 | loss: 0.0650326\n",
      "\tspeed: 0.0200s/iter; left time: 386.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0684402 Vali Loss: 0.0667540 Test Loss: 0.0735233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0700681\n",
      "\tspeed: 0.0412s/iter; left time: 789.0405s\n",
      "\titers: 200, epoch: 15 | loss: 0.0635885\n",
      "\tspeed: 0.0204s/iter; left time: 389.1911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0678480 Vali Loss: 0.0662438 Test Loss: 0.0731645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0685884\n",
      "\tspeed: 0.0522s/iter; left time: 988.1824s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708614\n",
      "\tspeed: 0.0303s/iter; left time: 570.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0673193 Vali Loss: 0.0677658 Test Loss: 0.0743847\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0656190\n",
      "\tspeed: 0.0554s/iter; left time: 1037.3114s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703265\n",
      "\tspeed: 0.0318s/iter; left time: 592.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0674118 Vali Loss: 0.0667368 Test Loss: 0.0728840\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670045\n",
      "\tspeed: 0.0545s/iter; left time: 1007.4529s\n",
      "\titers: 200, epoch: 18 | loss: 0.0649967\n",
      "\tspeed: 0.0272s/iter; left time: 500.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0667817 Vali Loss: 0.0659515 Test Loss: 0.0723879\n",
      "Validation loss decreased (0.066129 --> 0.065952).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0607930\n",
      "\tspeed: 0.0550s/iter; left time: 1003.9724s\n",
      "\titers: 200, epoch: 19 | loss: 0.0625694\n",
      "\tspeed: 0.0259s/iter; left time: 469.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0663358 Vali Loss: 0.0649521 Test Loss: 0.0708053\n",
      "Validation loss decreased (0.065952 --> 0.064952).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0686212\n",
      "\tspeed: 0.0515s/iter; left time: 929.6582s\n",
      "\titers: 200, epoch: 20 | loss: 0.0686722\n",
      "\tspeed: 0.0240s/iter; left time: 430.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0660643 Vali Loss: 0.0644376 Test Loss: 0.0708963\n",
      "Validation loss decreased (0.064952 --> 0.064438).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0633731\n",
      "\tspeed: 0.0462s/iter; left time: 823.7444s\n",
      "\titers: 200, epoch: 21 | loss: 0.0649254\n",
      "\tspeed: 0.0281s/iter; left time: 498.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0658443 Vali Loss: 0.0641358 Test Loss: 0.0702911\n",
      "Validation loss decreased (0.064438 --> 0.064136).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0625041\n",
      "\tspeed: 0.0543s/iter; left time: 955.8281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0668638\n",
      "\tspeed: 0.0235s/iter; left time: 411.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0653999 Vali Loss: 0.0636035 Test Loss: 0.0699410\n",
      "Validation loss decreased (0.064136 --> 0.063604).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0587001\n",
      "\tspeed: 0.0477s/iter; left time: 829.1428s\n",
      "\titers: 200, epoch: 23 | loss: 0.0650766\n",
      "\tspeed: 0.0213s/iter; left time: 367.8025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0650241 Vali Loss: 0.0633885 Test Loss: 0.0693305\n",
      "Validation loss decreased (0.063604 --> 0.063389).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0658394\n",
      "\tspeed: 0.0530s/iter; left time: 908.5266s\n",
      "\titers: 200, epoch: 24 | loss: 0.0650017\n",
      "\tspeed: 0.0303s/iter; left time: 516.9997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0649769 Vali Loss: 0.0635689 Test Loss: 0.0699041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0646365\n",
      "\tspeed: 0.0525s/iter; left time: 888.1159s\n",
      "\titers: 200, epoch: 25 | loss: 0.0659883\n",
      "\tspeed: 0.0320s/iter; left time: 538.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0647748 Vali Loss: 0.0633206 Test Loss: 0.0692420\n",
      "Validation loss decreased (0.063389 --> 0.063321).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0742224\n",
      "\tspeed: 0.0569s/iter; left time: 949.9763s\n",
      "\titers: 200, epoch: 26 | loss: 0.0661260\n",
      "\tspeed: 0.0313s/iter; left time: 519.8735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0644850 Vali Loss: 0.0628035 Test Loss: 0.0687131\n",
      "Validation loss decreased (0.063321 --> 0.062803).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0609507\n",
      "\tspeed: 0.0476s/iter; left time: 784.4394s\n",
      "\titers: 200, epoch: 27 | loss: 0.0615842\n",
      "\tspeed: 0.0294s/iter; left time: 480.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0649581 Vali Loss: 0.0629589 Test Loss: 0.0689832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0606146\n",
      "\tspeed: 0.0437s/iter; left time: 711.0151s\n",
      "\titers: 200, epoch: 28 | loss: 0.0667914\n",
      "\tspeed: 0.0184s/iter; left time: 297.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0647240 Vali Loss: 0.0634306 Test Loss: 0.0693182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0628809\n",
      "\tspeed: 0.0492s/iter; left time: 788.4534s\n",
      "\titers: 200, epoch: 29 | loss: 0.0625075\n",
      "\tspeed: 0.0307s/iter; left time: 489.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.0641224 Vali Loss: 0.0626767 Test Loss: 0.0686401\n",
      "Validation loss decreased (0.062803 --> 0.062677).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0638293\n",
      "\tspeed: 0.0537s/iter; left time: 848.5032s\n",
      "\titers: 200, epoch: 30 | loss: 0.0672728\n",
      "\tspeed: 0.0291s/iter; left time: 457.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.0643241 Vali Loss: 0.0636556 Test Loss: 0.0693221\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0643187\n",
      "\tspeed: 0.0434s/iter; left time: 676.0636s\n",
      "\titers: 200, epoch: 31 | loss: 0.0630511\n",
      "\tspeed: 0.0286s/iter; left time: 442.6612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0640520 Vali Loss: 0.0628885 Test Loss: 0.0685896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0575114\n",
      "\tspeed: 0.0561s/iter; left time: 861.4926s\n",
      "\titers: 200, epoch: 32 | loss: 0.0618084\n",
      "\tspeed: 0.0333s/iter; left time: 508.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0638753 Vali Loss: 0.0627269 Test Loss: 0.0684609\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0623026\n",
      "\tspeed: 0.0409s/iter; left time: 618.5656s\n",
      "\titers: 200, epoch: 33 | loss: 0.0620705\n",
      "\tspeed: 0.0185s/iter; left time: 277.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0638739 Vali Loss: 0.0626816 Test Loss: 0.0681579\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0613544\n",
      "\tspeed: 0.0535s/iter; left time: 798.0233s\n",
      "\titers: 200, epoch: 34 | loss: 0.0698127\n",
      "\tspeed: 0.0301s/iter; left time: 445.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0640109 Vali Loss: 0.0624105 Test Loss: 0.0682877\n",
      "Validation loss decreased (0.062677 --> 0.062410).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0640097\n",
      "\tspeed: 0.0548s/iter; left time: 804.1401s\n",
      "\titers: 200, epoch: 35 | loss: 0.0615817\n",
      "\tspeed: 0.0284s/iter; left time: 414.3707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0637989 Vali Loss: 0.0628897 Test Loss: 0.0687534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0616606\n",
      "\tspeed: 0.0561s/iter; left time: 810.9558s\n",
      "\titers: 200, epoch: 36 | loss: 0.0646277\n",
      "\tspeed: 0.0299s/iter; left time: 430.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0637275 Vali Loss: 0.0626828 Test Loss: 0.0681497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0614472\n",
      "\tspeed: 0.0464s/iter; left time: 660.3070s\n",
      "\titers: 200, epoch: 37 | loss: 0.0622872\n",
      "\tspeed: 0.0272s/iter; left time: 384.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0634686 Vali Loss: 0.0626686 Test Loss: 0.0686841\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0625435\n",
      "\tspeed: 0.0506s/iter; left time: 709.3190s\n",
      "\titers: 200, epoch: 38 | loss: 0.0736823\n",
      "\tspeed: 0.0213s/iter; left time: 296.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0638101 Vali Loss: 0.0624801 Test Loss: 0.0683101\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0608900\n",
      "\tspeed: 0.0502s/iter; left time: 692.8719s\n",
      "\titers: 200, epoch: 39 | loss: 0.0621955\n",
      "\tspeed: 0.0292s/iter; left time: 399.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0639557 Vali Loss: 0.0626942 Test Loss: 0.0687102\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0676548\n",
      "\tspeed: 0.0411s/iter; left time: 557.1388s\n",
      "\titers: 200, epoch: 40 | loss: 0.0570616\n",
      "\tspeed: 0.0184s/iter; left time: 248.0721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0636704 Vali Loss: 0.0626181 Test Loss: 0.0685974\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0622672\n",
      "\tspeed: 0.0441s/iter; left time: 587.7687s\n",
      "\titers: 200, epoch: 41 | loss: 0.0644980\n",
      "\tspeed: 0.0310s/iter; left time: 410.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0634431 Vali Loss: 0.0622733 Test Loss: 0.0680729\n",
      "Validation loss decreased (0.062410 --> 0.062273).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0631589\n",
      "\tspeed: 0.0520s/iter; left time: 681.9944s\n",
      "\titers: 200, epoch: 42 | loss: 0.0613354\n",
      "\tspeed: 0.0295s/iter; left time: 384.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0635634 Vali Loss: 0.0624026 Test Loss: 0.0687158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0674707\n",
      "\tspeed: 0.0433s/iter; left time: 558.5948s\n",
      "\titers: 200, epoch: 43 | loss: 0.0630676\n",
      "\tspeed: 0.0195s/iter; left time: 250.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0635535 Vali Loss: 0.0623359 Test Loss: 0.0680472\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0629912\n",
      "\tspeed: 0.0432s/iter; left time: 547.5773s\n",
      "\titers: 200, epoch: 44 | loss: 0.0629587\n",
      "\tspeed: 0.0230s/iter; left time: 289.3766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0634927 Vali Loss: 0.0624060 Test Loss: 0.0679577\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0601665\n",
      "\tspeed: 0.0485s/iter; left time: 603.7858s\n",
      "\titers: 200, epoch: 45 | loss: 0.0632155\n",
      "\tspeed: 0.0225s/iter; left time: 277.4028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0635222 Vali Loss: 0.0622785 Test Loss: 0.0683091\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0662968\n",
      "\tspeed: 0.0395s/iter; left time: 482.1732s\n",
      "\titers: 200, epoch: 46 | loss: 0.0654227\n",
      "\tspeed: 0.0197s/iter; left time: 239.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0634501 Vali Loss: 0.0630389 Test Loss: 0.0687682\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0610149\n",
      "\tspeed: 0.0442s/iter; left time: 529.7282s\n",
      "\titers: 200, epoch: 47 | loss: 0.0615973\n",
      "\tspeed: 0.0289s/iter; left time: 343.5374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0634638 Vali Loss: 0.0623389 Test Loss: 0.0680389\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0610079\n",
      "\tspeed: 0.0469s/iter; left time: 552.6204s\n",
      "\titers: 200, epoch: 48 | loss: 0.0676609\n",
      "\tspeed: 0.0328s/iter; left time: 383.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0634611 Vali Loss: 0.0624490 Test Loss: 0.0681798\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0639073\n",
      "\tspeed: 0.0474s/iter; left time: 547.7179s\n",
      "\titers: 200, epoch: 49 | loss: 0.0618999\n",
      "\tspeed: 0.0317s/iter; left time: 363.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0632360 Vali Loss: 0.0623827 Test Loss: 0.0680330\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0617002\n",
      "\tspeed: 0.0461s/iter; left time: 521.8157s\n",
      "\titers: 200, epoch: 50 | loss: 0.0612418\n",
      "\tspeed: 0.0270s/iter; left time: 302.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0635796 Vali Loss: 0.0624024 Test Loss: 0.0683015\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0634774\n",
      "\tspeed: 0.0444s/iter; left time: 493.2982s\n",
      "\titers: 200, epoch: 51 | loss: 0.0653196\n",
      "\tspeed: 0.0254s/iter; left time: 279.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0634000 Vali Loss: 0.0625818 Test Loss: 0.0685117\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012513546273112297, rmse:0.11186396330595016, mae:0.06807289272546768, rse:0.42267879843711853\n",
      "Intermediate time for IT and pred_len 24: 00h:15m:06.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3342477\n",
      "\tspeed: 0.0528s/iter; left time: 1178.1444s\n",
      "\titers: 200, epoch: 1 | loss: 0.2966344\n",
      "\tspeed: 0.0242s/iter; left time: 537.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.3351949 Vali Loss: 0.2028280 Test Loss: 0.2053291\n",
      "Validation loss decreased (inf --> 0.202828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1558569\n",
      "\tspeed: 0.0540s/iter; left time: 1192.8301s\n",
      "\titers: 200, epoch: 2 | loss: 0.1292385\n",
      "\tspeed: 0.0293s/iter; left time: 643.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.1685702 Vali Loss: 0.1075267 Test Loss: 0.1149655\n",
      "Validation loss decreased (0.202828 --> 0.107527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1244688\n",
      "\tspeed: 0.0556s/iter; left time: 1214.2068s\n",
      "\titers: 200, epoch: 3 | loss: 0.1151195\n",
      "\tspeed: 0.0321s/iter; left time: 697.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.1208200 Vali Loss: 0.1044624 Test Loss: 0.1127941\n",
      "Validation loss decreased (0.107527 --> 0.104462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077869\n",
      "\tspeed: 0.0584s/iter; left time: 1263.9031s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054402\n",
      "\tspeed: 0.0281s/iter; left time: 605.6908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.1087310 Vali Loss: 0.0986950 Test Loss: 0.1069118\n",
      "Validation loss decreased (0.104462 --> 0.098695).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027654\n",
      "\tspeed: 0.0495s/iter; left time: 1059.8818s\n",
      "\titers: 200, epoch: 5 | loss: 0.1014348\n",
      "\tspeed: 0.0250s/iter; left time: 531.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.1021137 Vali Loss: 0.0965420 Test Loss: 0.1046490\n",
      "Validation loss decreased (0.098695 --> 0.096542).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989471\n",
      "\tspeed: 0.0573s/iter; left time: 1214.5128s\n",
      "\titers: 200, epoch: 6 | loss: 0.1000381\n",
      "\tspeed: 0.0337s/iter; left time: 711.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0976498 Vali Loss: 0.0944560 Test Loss: 0.1027542\n",
      "Validation loss decreased (0.096542 --> 0.094456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0930226\n",
      "\tspeed: 0.0631s/iter; left time: 1322.2441s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953423\n",
      "\tspeed: 0.0365s/iter; left time: 760.2826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0950571 Vali Loss: 0.0902779 Test Loss: 0.0984376\n",
      "Validation loss decreased (0.094456 --> 0.090278).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901980\n",
      "\tspeed: 0.0622s/iter; left time: 1289.4620s\n",
      "\titers: 200, epoch: 8 | loss: 0.0943654\n",
      "\tspeed: 0.0362s/iter; left time: 746.1275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0927207 Vali Loss: 0.0893505 Test Loss: 0.0980295\n",
      "Validation loss decreased (0.090278 --> 0.089350).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0900329\n",
      "\tspeed: 0.0652s/iter; left time: 1337.9248s\n",
      "\titers: 200, epoch: 9 | loss: 0.0930791\n",
      "\tspeed: 0.0385s/iter; left time: 786.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 224 | Train Loss: 0.0912607 Vali Loss: 0.0872020 Test Loss: 0.0947072\n",
      "Validation loss decreased (0.089350 --> 0.087202).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0901265\n",
      "\tspeed: 0.0751s/iter; left time: 1523.7274s\n",
      "\titers: 200, epoch: 10 | loss: 0.0961293\n",
      "\tspeed: 0.0328s/iter; left time: 662.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0897692 Vali Loss: 0.0858830 Test Loss: 0.0944918\n",
      "Validation loss decreased (0.087202 --> 0.085883).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0864411\n",
      "\tspeed: 0.0627s/iter; left time: 1257.0177s\n",
      "\titers: 200, epoch: 11 | loss: 0.0874748\n",
      "\tspeed: 0.0256s/iter; left time: 510.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0889523 Vali Loss: 0.0859419 Test Loss: 0.0931551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0856065\n",
      "\tspeed: 0.0477s/iter; left time: 945.6619s\n",
      "\titers: 200, epoch: 12 | loss: 0.0859468\n",
      "\tspeed: 0.0257s/iter; left time: 507.9637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0877325 Vali Loss: 0.0861587 Test Loss: 0.0935987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0896335\n",
      "\tspeed: 0.0520s/iter; left time: 1020.5126s\n",
      "\titers: 200, epoch: 13 | loss: 0.0880722\n",
      "\tspeed: 0.0299s/iter; left time: 583.0664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0873248 Vali Loss: 0.0875621 Test Loss: 0.0946284\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1004308\n",
      "\tspeed: 0.0513s/iter; left time: 995.0061s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864576\n",
      "\tspeed: 0.0289s/iter; left time: 558.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0864875 Vali Loss: 0.0835620 Test Loss: 0.0915664\n",
      "Validation loss decreased (0.085883 --> 0.083562).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0837932\n",
      "\tspeed: 0.0584s/iter; left time: 1119.3937s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837968\n",
      "\tspeed: 0.0336s/iter; left time: 640.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 224 | Train Loss: 0.0858382 Vali Loss: 0.0836731 Test Loss: 0.0909717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0854254\n",
      "\tspeed: 0.0604s/iter; left time: 1143.1637s\n",
      "\titers: 200, epoch: 16 | loss: 0.0880396\n",
      "\tspeed: 0.0331s/iter; left time: 622.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0854107 Vali Loss: 0.0838805 Test Loss: 0.0915355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0853538\n",
      "\tspeed: 0.0533s/iter; left time: 997.4629s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814950\n",
      "\tspeed: 0.0266s/iter; left time: 494.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0850889 Vali Loss: 0.0828494 Test Loss: 0.0902955\n",
      "Validation loss decreased (0.083562 --> 0.082849).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0848045\n",
      "\tspeed: 0.0541s/iter; left time: 1000.4698s\n",
      "\titers: 200, epoch: 18 | loss: 0.0846333\n",
      "\tspeed: 0.0294s/iter; left time: 541.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0845887 Vali Loss: 0.0831546 Test Loss: 0.0906458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851608\n",
      "\tspeed: 0.0537s/iter; left time: 981.4292s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858944\n",
      "\tspeed: 0.0299s/iter; left time: 543.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0841915 Vali Loss: 0.0828417 Test Loss: 0.0905262\n",
      "Validation loss decreased (0.082849 --> 0.082842).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0963844\n",
      "\tspeed: 0.0577s/iter; left time: 1041.0916s\n",
      "\titers: 200, epoch: 20 | loss: 0.0828180\n",
      "\tspeed: 0.0321s/iter; left time: 575.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0840370 Vali Loss: 0.0831964 Test Loss: 0.0906983\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0839119\n",
      "\tspeed: 0.0534s/iter; left time: 951.9920s\n",
      "\titers: 200, epoch: 21 | loss: 0.0818773\n",
      "\tspeed: 0.0286s/iter; left time: 505.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0837654 Vali Loss: 0.0826040 Test Loss: 0.0903192\n",
      "Validation loss decreased (0.082842 --> 0.082604).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0865210\n",
      "\tspeed: 0.0607s/iter; left time: 1068.6309s\n",
      "\titers: 200, epoch: 22 | loss: 0.0842640\n",
      "\tspeed: 0.0359s/iter; left time: 628.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 224 | Train Loss: 0.0838435 Vali Loss: 0.0828541 Test Loss: 0.0904679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0848936\n",
      "\tspeed: 0.0649s/iter; left time: 1128.1728s\n",
      "\titers: 200, epoch: 23 | loss: 0.0850183\n",
      "\tspeed: 0.0273s/iter; left time: 471.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0835390 Vali Loss: 0.0823175 Test Loss: 0.0900755\n",
      "Validation loss decreased (0.082604 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0819620\n",
      "\tspeed: 0.0466s/iter; left time: 799.9384s\n",
      "\titers: 200, epoch: 24 | loss: 0.0869369\n",
      "\tspeed: 0.0318s/iter; left time: 541.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0830983 Vali Loss: 0.0821250 Test Loss: 0.0897408\n",
      "Validation loss decreased (0.082317 --> 0.082125).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0807188\n",
      "\tspeed: 0.0533s/iter; left time: 902.4405s\n",
      "\titers: 200, epoch: 25 | loss: 0.0789265\n",
      "\tspeed: 0.0315s/iter; left time: 529.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 224 | Train Loss: 0.0833877 Vali Loss: 0.0825295 Test Loss: 0.0899169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0792399\n",
      "\tspeed: 0.0580s/iter; left time: 967.9141s\n",
      "\titers: 200, epoch: 26 | loss: 0.0809061\n",
      "\tspeed: 0.0289s/iter; left time: 479.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0827640 Vali Loss: 0.0822878 Test Loss: 0.0899421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0812116\n",
      "\tspeed: 0.0566s/iter; left time: 932.3809s\n",
      "\titers: 200, epoch: 27 | loss: 0.0811940\n",
      "\tspeed: 0.0286s/iter; left time: 468.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0828549 Vali Loss: 0.0824645 Test Loss: 0.0897688\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0880182\n",
      "\tspeed: 0.0548s/iter; left time: 890.9326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0787973\n",
      "\tspeed: 0.0342s/iter; left time: 552.5520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0824284 Vali Loss: 0.0826627 Test Loss: 0.0901328\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0851634\n",
      "\tspeed: 0.0593s/iter; left time: 950.7480s\n",
      "\titers: 200, epoch: 29 | loss: 0.0847707\n",
      "\tspeed: 0.0337s/iter; left time: 537.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0825333 Vali Loss: 0.0820528 Test Loss: 0.0902676\n",
      "Validation loss decreased (0.082125 --> 0.082053).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0833068\n",
      "\tspeed: 0.0578s/iter; left time: 913.7795s\n",
      "\titers: 200, epoch: 30 | loss: 0.0842331\n",
      "\tspeed: 0.0273s/iter; left time: 428.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0824019 Vali Loss: 0.0826107 Test Loss: 0.0901840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0761964\n",
      "\tspeed: 0.0589s/iter; left time: 917.7327s\n",
      "\titers: 200, epoch: 31 | loss: 0.0788429\n",
      "\tspeed: 0.0353s/iter; left time: 546.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0822680 Vali Loss: 0.0825199 Test Loss: 0.0899459\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0865966\n",
      "\tspeed: 0.0544s/iter; left time: 835.7008s\n",
      "\titers: 200, epoch: 32 | loss: 0.0840311\n",
      "\tspeed: 0.0283s/iter; left time: 431.9405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0822506 Vali Loss: 0.0821072 Test Loss: 0.0897863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0829347\n",
      "\tspeed: 0.0499s/iter; left time: 755.3439s\n",
      "\titers: 200, epoch: 33 | loss: 0.0853713\n",
      "\tspeed: 0.0290s/iter; left time: 435.3575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0820769 Vali Loss: 0.0834153 Test Loss: 0.0908419\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0805737\n",
      "\tspeed: 0.0423s/iter; left time: 630.5705s\n",
      "\titers: 200, epoch: 34 | loss: 0.0985123\n",
      "\tspeed: 0.0311s/iter; left time: 459.9134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0820064 Vali Loss: 0.0831643 Test Loss: 0.0910287\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0865347\n",
      "\tspeed: 0.0460s/iter; left time: 675.7674s\n",
      "\titers: 200, epoch: 35 | loss: 0.0859494\n",
      "\tspeed: 0.0196s/iter; left time: 286.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0822438 Vali Loss: 0.0823014 Test Loss: 0.0900800\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0842705\n",
      "\tspeed: 0.0401s/iter; left time: 579.5680s\n",
      "\titers: 200, epoch: 36 | loss: 0.0804394\n",
      "\tspeed: 0.0199s/iter; left time: 285.2962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0819071 Vali Loss: 0.0824684 Test Loss: 0.0900509\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0841371\n",
      "\tspeed: 0.0452s/iter; left time: 644.1591s\n",
      "\titers: 200, epoch: 37 | loss: 0.0791406\n",
      "\tspeed: 0.0286s/iter; left time: 404.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0818516 Vali Loss: 0.0818177 Test Loss: 0.0896940\n",
      "Validation loss decreased (0.082053 --> 0.081818).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0792575\n",
      "\tspeed: 0.0496s/iter; left time: 695.0389s\n",
      "\titers: 200, epoch: 38 | loss: 0.0779197\n",
      "\tspeed: 0.0300s/iter; left time: 417.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0819417 Vali Loss: 0.0821002 Test Loss: 0.0895463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0773695\n",
      "\tspeed: 0.0511s/iter; left time: 704.0913s\n",
      "\titers: 200, epoch: 39 | loss: 0.0816331\n",
      "\tspeed: 0.0234s/iter; left time: 320.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0818324 Vali Loss: 0.0817532 Test Loss: 0.0894199\n",
      "Validation loss decreased (0.081818 --> 0.081753).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0848141\n",
      "\tspeed: 0.0452s/iter; left time: 612.9624s\n",
      "\titers: 200, epoch: 40 | loss: 0.0865183\n",
      "\tspeed: 0.0290s/iter; left time: 390.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0816710 Vali Loss: 0.0818239 Test Loss: 0.0895949\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0814078\n",
      "\tspeed: 0.0569s/iter; left time: 759.1723s\n",
      "\titers: 200, epoch: 41 | loss: 0.0804687\n",
      "\tspeed: 0.0335s/iter; left time: 443.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0817062 Vali Loss: 0.0817036 Test Loss: 0.0896085\n",
      "Validation loss decreased (0.081753 --> 0.081704).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0826062\n",
      "\tspeed: 0.0537s/iter; left time: 703.8717s\n",
      "\titers: 200, epoch: 42 | loss: 0.0836750\n",
      "\tspeed: 0.0286s/iter; left time: 371.8029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 224 | Train Loss: 0.0817121 Vali Loss: 0.0823484 Test Loss: 0.0900194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0818426\n",
      "\tspeed: 0.0485s/iter; left time: 624.9962s\n",
      "\titers: 200, epoch: 43 | loss: 0.0809723\n",
      "\tspeed: 0.0289s/iter; left time: 369.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0815736 Vali Loss: 0.0819366 Test Loss: 0.0895153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0793801\n",
      "\tspeed: 0.0434s/iter; left time: 549.5907s\n",
      "\titers: 200, epoch: 44 | loss: 0.0836315\n",
      "\tspeed: 0.0233s/iter; left time: 293.2297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0819036 Vali Loss: 0.0830435 Test Loss: 0.0901475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0836839\n",
      "\tspeed: 0.0465s/iter; left time: 578.9325s\n",
      "\titers: 200, epoch: 45 | loss: 0.0799100\n",
      "\tspeed: 0.0225s/iter; left time: 278.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0815311 Vali Loss: 0.0820552 Test Loss: 0.0894667\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0815396\n",
      "\tspeed: 0.0461s/iter; left time: 562.9696s\n",
      "\titers: 200, epoch: 46 | loss: 0.0831169\n",
      "\tspeed: 0.0341s/iter; left time: 413.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0815125 Vali Loss: 0.0820445 Test Loss: 0.0897428\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0810667\n",
      "\tspeed: 0.0541s/iter; left time: 649.5305s\n",
      "\titers: 200, epoch: 47 | loss: 0.0806376\n",
      "\tspeed: 0.0292s/iter; left time: 347.3607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0815237 Vali Loss: 0.0819103 Test Loss: 0.0896595\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0843306\n",
      "\tspeed: 0.0457s/iter; left time: 537.7505s\n",
      "\titers: 200, epoch: 48 | loss: 0.0827992\n",
      "\tspeed: 0.0233s/iter; left time: 271.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0814513 Vali Loss: 0.0820825 Test Loss: 0.0897138\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0887801\n",
      "\tspeed: 0.0516s/iter; left time: 596.4324s\n",
      "\titers: 200, epoch: 49 | loss: 0.0804866\n",
      "\tspeed: 0.0299s/iter; left time: 342.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0816178 Vali Loss: 0.0816005 Test Loss: 0.0895317\n",
      "Validation loss decreased (0.081704 --> 0.081601).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0825272\n",
      "\tspeed: 0.0529s/iter; left time: 599.1697s\n",
      "\titers: 200, epoch: 50 | loss: 0.0902672\n",
      "\tspeed: 0.0301s/iter; left time: 338.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0814951 Vali Loss: 0.0820070 Test Loss: 0.0897860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0822851\n",
      "\tspeed: 0.0527s/iter; left time: 584.7425s\n",
      "\titers: 200, epoch: 51 | loss: 0.0768655\n",
      "\tspeed: 0.0296s/iter; left time: 325.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0814160 Vali Loss: 0.0819262 Test Loss: 0.0895067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0829470\n",
      "\tspeed: 0.0472s/iter; left time: 513.2082s\n",
      "\titers: 200, epoch: 52 | loss: 0.0829842\n",
      "\tspeed: 0.0291s/iter; left time: 313.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0817352 Vali Loss: 0.0824514 Test Loss: 0.0897923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0812030\n",
      "\tspeed: 0.0567s/iter; left time: 603.5518s\n",
      "\titers: 200, epoch: 53 | loss: 0.0809817\n",
      "\tspeed: 0.0233s/iter; left time: 246.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0814079 Vali Loss: 0.0818408 Test Loss: 0.0894195\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0812295\n",
      "\tspeed: 0.0467s/iter; left time: 486.8811s\n",
      "\titers: 200, epoch: 54 | loss: 0.0791901\n",
      "\tspeed: 0.0187s/iter; left time: 193.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0814698 Vali Loss: 0.0815088 Test Loss: 0.0895774\n",
      "Validation loss decreased (0.081601 --> 0.081509).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0821281\n",
      "\tspeed: 0.0421s/iter; left time: 429.2949s\n",
      "\titers: 200, epoch: 55 | loss: 0.0763700\n",
      "\tspeed: 0.0207s/iter; left time: 209.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0816189 Vali Loss: 0.0821455 Test Loss: 0.0898703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0793105\n",
      "\tspeed: 0.0529s/iter; left time: 528.2097s\n",
      "\titers: 200, epoch: 56 | loss: 0.0816139\n",
      "\tspeed: 0.0291s/iter; left time: 287.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0815632 Vali Loss: 0.0819595 Test Loss: 0.0898148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0766040\n",
      "\tspeed: 0.0507s/iter; left time: 494.9138s\n",
      "\titers: 200, epoch: 57 | loss: 0.0808230\n",
      "\tspeed: 0.0256s/iter; left time: 246.8212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0814694 Vali Loss: 0.0817719 Test Loss: 0.0894790\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0833070\n",
      "\tspeed: 0.0544s/iter; left time: 518.3781s\n",
      "\titers: 200, epoch: 58 | loss: 0.0765774\n",
      "\tspeed: 0.0306s/iter; left time: 288.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.0812975 Vali Loss: 0.0817166 Test Loss: 0.0894710\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0819579\n",
      "\tspeed: 0.0587s/iter; left time: 546.0072s\n",
      "\titers: 200, epoch: 59 | loss: 0.0818156\n",
      "\tspeed: 0.0303s/iter; left time: 279.2135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0814264 Vali Loss: 0.0818570 Test Loss: 0.0894254\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0813043\n",
      "\tspeed: 0.0429s/iter; left time: 390.1436s\n",
      "\titers: 200, epoch: 60 | loss: 0.0820176\n",
      "\tspeed: 0.0193s/iter; left time: 173.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0814420 Vali Loss: 0.0822461 Test Loss: 0.0898074\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0812657\n",
      "\tspeed: 0.0532s/iter; left time: 471.3955s\n",
      "\titers: 200, epoch: 61 | loss: 0.0838158\n",
      "\tspeed: 0.0293s/iter; left time: 256.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0815329 Vali Loss: 0.0816359 Test Loss: 0.0893900\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0783300\n",
      "\tspeed: 0.0483s/iter; left time: 417.4507s\n",
      "\titers: 200, epoch: 62 | loss: 0.0809118\n",
      "\tspeed: 0.0245s/iter; left time: 209.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0814902 Vali Loss: 0.0820552 Test Loss: 0.0895988\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0832673\n",
      "\tspeed: 0.0550s/iter; left time: 462.7518s\n",
      "\titers: 200, epoch: 63 | loss: 0.0749864\n",
      "\tspeed: 0.0295s/iter; left time: 245.3788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0813406 Vali Loss: 0.0817134 Test Loss: 0.0899370\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0815333\n",
      "\tspeed: 0.0454s/iter; left time: 371.8060s\n",
      "\titers: 200, epoch: 64 | loss: 0.0828421\n",
      "\tspeed: 0.0208s/iter; left time: 168.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0814979 Vali Loss: 0.0824299 Test Loss: 0.0899528\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021137915551662445, rmse:0.14538884162902832, mae:0.0895773321390152, rse:0.5497308969497681\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3282171\n",
      "\tspeed: 0.0339s/iter; left time: 756.3137s\n",
      "\titers: 200, epoch: 1 | loss: 0.2938394\n",
      "\tspeed: 0.0278s/iter; left time: 618.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.3324231 Vali Loss: 0.1995714 Test Loss: 0.2032869\n",
      "Validation loss decreased (inf --> 0.199571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574539\n",
      "\tspeed: 0.0568s/iter; left time: 1253.2417s\n",
      "\titers: 200, epoch: 2 | loss: 0.1283370\n",
      "\tspeed: 0.0364s/iter; left time: 800.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1700163 Vali Loss: 0.1084238 Test Loss: 0.1161435\n",
      "Validation loss decreased (0.199571 --> 0.108424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1170992\n",
      "\tspeed: 0.0494s/iter; left time: 1079.7215s\n",
      "\titers: 200, epoch: 3 | loss: 0.1181307\n",
      "\tspeed: 0.0300s/iter; left time: 652.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1184368 Vali Loss: 0.1030817 Test Loss: 0.1106169\n",
      "Validation loss decreased (0.108424 --> 0.103082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1065495\n",
      "\tspeed: 0.0500s/iter; left time: 1080.6985s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004120\n",
      "\tspeed: 0.0236s/iter; left time: 507.3388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.1055265 Vali Loss: 0.0984280 Test Loss: 0.1067533\n",
      "Validation loss decreased (0.103082 --> 0.098428).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0996751\n",
      "\tspeed: 0.0544s/iter; left time: 1163.4750s\n",
      "\titers: 200, epoch: 5 | loss: 0.0998948\n",
      "\tspeed: 0.0319s/iter; left time: 679.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0987648 Vali Loss: 0.0931479 Test Loss: 0.1013061\n",
      "Validation loss decreased (0.098428 --> 0.093148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904655\n",
      "\tspeed: 0.0441s/iter; left time: 933.1444s\n",
      "\titers: 200, epoch: 6 | loss: 0.0982554\n",
      "\tspeed: 0.0186s/iter; left time: 392.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0948214 Vali Loss: 0.0914262 Test Loss: 0.0995740\n",
      "Validation loss decreased (0.093148 --> 0.091426).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0925799\n",
      "\tspeed: 0.0414s/iter; left time: 867.1205s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924049\n",
      "\tspeed: 0.0186s/iter; left time: 387.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0922354 Vali Loss: 0.0875218 Test Loss: 0.0939249\n",
      "Validation loss decreased (0.091426 --> 0.087522).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0875199\n",
      "\tspeed: 0.0449s/iter; left time: 930.7938s\n",
      "\titers: 200, epoch: 8 | loss: 0.0863444\n",
      "\tspeed: 0.0216s/iter; left time: 445.4483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0904559 Vali Loss: 0.0900727 Test Loss: 0.0973462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0933505\n",
      "\tspeed: 0.0536s/iter; left time: 1098.7120s\n",
      "\titers: 200, epoch: 9 | loss: 0.0884461\n",
      "\tspeed: 0.0294s/iter; left time: 599.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0890998 Vali Loss: 0.0850209 Test Loss: 0.0920255\n",
      "Validation loss decreased (0.087522 --> 0.085021).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849009\n",
      "\tspeed: 0.0528s/iter; left time: 1071.2867s\n",
      "\titers: 200, epoch: 10 | loss: 0.0883648\n",
      "\tspeed: 0.0303s/iter; left time: 612.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0873199 Vali Loss: 0.0863516 Test Loss: 0.0935867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0841916\n",
      "\tspeed: 0.0480s/iter; left time: 962.3107s\n",
      "\titers: 200, epoch: 11 | loss: 0.0901744\n",
      "\tspeed: 0.0234s/iter; left time: 466.6132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0868707 Vali Loss: 0.0878127 Test Loss: 0.0949341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0861708\n",
      "\tspeed: 0.0525s/iter; left time: 1041.4175s\n",
      "\titers: 200, epoch: 12 | loss: 0.0873720\n",
      "\tspeed: 0.0286s/iter; left time: 564.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0862021 Vali Loss: 0.0835381 Test Loss: 0.0914334\n",
      "Validation loss decreased (0.085021 --> 0.083538).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0848269\n",
      "\tspeed: 0.0560s/iter; left time: 1098.1660s\n",
      "\titers: 200, epoch: 13 | loss: 0.0855707\n",
      "\tspeed: 0.0246s/iter; left time: 480.5393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0853301 Vali Loss: 0.0836378 Test Loss: 0.0903539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0837165\n",
      "\tspeed: 0.0445s/iter; left time: 862.2478s\n",
      "\titers: 200, epoch: 14 | loss: 0.0873304\n",
      "\tspeed: 0.0300s/iter; left time: 578.7826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0853063 Vali Loss: 0.0838119 Test Loss: 0.0906306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0844536\n",
      "\tspeed: 0.0429s/iter; left time: 821.7290s\n",
      "\titers: 200, epoch: 15 | loss: 0.0876478\n",
      "\tspeed: 0.0186s/iter; left time: 353.7235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0843080 Vali Loss: 0.0854288 Test Loss: 0.0923264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0808478\n",
      "\tspeed: 0.0494s/iter; left time: 936.4388s\n",
      "\titers: 200, epoch: 16 | loss: 0.0869871\n",
      "\tspeed: 0.0306s/iter; left time: 577.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0844939 Vali Loss: 0.0836504 Test Loss: 0.0907716\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0852377\n",
      "\tspeed: 0.0448s/iter; left time: 838.1481s\n",
      "\titers: 200, epoch: 17 | loss: 0.0864813\n",
      "\tspeed: 0.0247s/iter; left time: 459.7871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0835698 Vali Loss: 0.0843238 Test Loss: 0.0919353\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0824032\n",
      "\tspeed: 0.0483s/iter; left time: 893.2978s\n",
      "\titers: 200, epoch: 18 | loss: 0.0891830\n",
      "\tspeed: 0.0311s/iter; left time: 572.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0846790 Vali Loss: 0.0825836 Test Loss: 0.0900171\n",
      "Validation loss decreased (0.083538 --> 0.082584).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0846897\n",
      "\tspeed: 0.0558s/iter; left time: 1018.7104s\n",
      "\titers: 200, epoch: 19 | loss: 0.0844518\n",
      "\tspeed: 0.0302s/iter; left time: 548.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0831903 Vali Loss: 0.0823626 Test Loss: 0.0895093\n",
      "Validation loss decreased (0.082584 --> 0.082363).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0844242\n",
      "\tspeed: 0.0562s/iter; left time: 1013.9058s\n",
      "\titers: 200, epoch: 20 | loss: 0.0804684\n",
      "\tspeed: 0.0296s/iter; left time: 531.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0827508 Vali Loss: 0.0829612 Test Loss: 0.0905017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0836824\n",
      "\tspeed: 0.0527s/iter; left time: 939.1300s\n",
      "\titers: 200, epoch: 21 | loss: 0.0845877\n",
      "\tspeed: 0.0259s/iter; left time: 459.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0829041 Vali Loss: 0.0822360 Test Loss: 0.0892641\n",
      "Validation loss decreased (0.082363 --> 0.082236).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0847115\n",
      "\tspeed: 0.0556s/iter; left time: 978.5027s\n",
      "\titers: 200, epoch: 22 | loss: 0.0871088\n",
      "\tspeed: 0.0296s/iter; left time: 517.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0823489 Vali Loss: 0.0828298 Test Loss: 0.0902822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0805198\n",
      "\tspeed: 0.0444s/iter; left time: 771.0616s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829067\n",
      "\tspeed: 0.0187s/iter; left time: 322.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0822127 Vali Loss: 0.0825234 Test Loss: 0.0898699\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775572\n",
      "\tspeed: 0.0511s/iter; left time: 875.7475s\n",
      "\titers: 200, epoch: 24 | loss: 0.0843309\n",
      "\tspeed: 0.0301s/iter; left time: 512.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0821953 Vali Loss: 0.0819198 Test Loss: 0.0889920\n",
      "Validation loss decreased (0.082236 --> 0.081920).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0828229\n",
      "\tspeed: 0.0524s/iter; left time: 887.6750s\n",
      "\titers: 200, epoch: 25 | loss: 0.0814569\n",
      "\tspeed: 0.0318s/iter; left time: 535.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0819263 Vali Loss: 0.0821326 Test Loss: 0.0892986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796846\n",
      "\tspeed: 0.0433s/iter; left time: 723.4284s\n",
      "\titers: 200, epoch: 26 | loss: 0.0827376\n",
      "\tspeed: 0.0186s/iter; left time: 308.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0818103 Vali Loss: 0.0823591 Test Loss: 0.0894896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0830976\n",
      "\tspeed: 0.0483s/iter; left time: 795.2675s\n",
      "\titers: 200, epoch: 27 | loss: 0.0827496\n",
      "\tspeed: 0.0259s/iter; left time: 423.7060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0816053 Vali Loss: 0.0822798 Test Loss: 0.0892729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0822377\n",
      "\tspeed: 0.0531s/iter; left time: 863.7944s\n",
      "\titers: 200, epoch: 28 | loss: 0.0811733\n",
      "\tspeed: 0.0300s/iter; left time: 484.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0815033 Vali Loss: 0.0822831 Test Loss: 0.0892842\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0816377\n",
      "\tspeed: 0.0482s/iter; left time: 772.1666s\n",
      "\titers: 200, epoch: 29 | loss: 0.0816596\n",
      "\tspeed: 0.0308s/iter; left time: 491.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0814558 Vali Loss: 0.0821478 Test Loss: 0.0892995\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0821950\n",
      "\tspeed: 0.0505s/iter; left time: 798.0946s\n",
      "\titers: 200, epoch: 30 | loss: 0.0817038\n",
      "\tspeed: 0.0217s/iter; left time: 340.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0813308 Vali Loss: 0.0820919 Test Loss: 0.0891152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0795071\n",
      "\tspeed: 0.0478s/iter; left time: 745.0890s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813417\n",
      "\tspeed: 0.0287s/iter; left time: 444.0365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0812277 Vali Loss: 0.0814891 Test Loss: 0.0886559\n",
      "Validation loss decreased (0.081920 --> 0.081489).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0800449\n",
      "\tspeed: 0.0556s/iter; left time: 853.4823s\n",
      "\titers: 200, epoch: 32 | loss: 0.0816239\n",
      "\tspeed: 0.0301s/iter; left time: 459.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0811424 Vali Loss: 0.0818686 Test Loss: 0.0890846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0825800\n",
      "\tspeed: 0.0559s/iter; left time: 846.4050s\n",
      "\titers: 200, epoch: 33 | loss: 0.0824921\n",
      "\tspeed: 0.0294s/iter; left time: 442.2507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0811423 Vali Loss: 0.0828717 Test Loss: 0.0899327\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0806394\n",
      "\tspeed: 0.0491s/iter; left time: 732.4230s\n",
      "\titers: 200, epoch: 34 | loss: 0.0803644\n",
      "\tspeed: 0.0249s/iter; left time: 368.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0812375 Vali Loss: 0.0822373 Test Loss: 0.0893068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0835815\n",
      "\tspeed: 0.0460s/iter; left time: 675.1535s\n",
      "\titers: 200, epoch: 35 | loss: 0.0818111\n",
      "\tspeed: 0.0237s/iter; left time: 345.9207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0808818 Vali Loss: 0.0817633 Test Loss: 0.0888109\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0792252\n",
      "\tspeed: 0.0468s/iter; left time: 676.3164s\n",
      "\titers: 200, epoch: 36 | loss: 0.0783416\n",
      "\tspeed: 0.0212s/iter; left time: 304.9147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0808672 Vali Loss: 0.0820217 Test Loss: 0.0893016\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786795\n",
      "\tspeed: 0.0451s/iter; left time: 641.6838s\n",
      "\titers: 200, epoch: 37 | loss: 0.0773999\n",
      "\tspeed: 0.0217s/iter; left time: 307.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0810459 Vali Loss: 0.0822422 Test Loss: 0.0893402\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0816924\n",
      "\tspeed: 0.0451s/iter; left time: 631.6697s\n",
      "\titers: 200, epoch: 38 | loss: 0.0846077\n",
      "\tspeed: 0.0250s/iter; left time: 347.2829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0808839 Vali Loss: 0.0820049 Test Loss: 0.0890369\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0787816\n",
      "\tspeed: 0.0459s/iter; left time: 633.3110s\n",
      "\titers: 200, epoch: 39 | loss: 0.0818508\n",
      "\tspeed: 0.0221s/iter; left time: 301.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0812214 Vali Loss: 0.0825272 Test Loss: 0.0896686\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0821159\n",
      "\tspeed: 0.0470s/iter; left time: 637.3460s\n",
      "\titers: 200, epoch: 40 | loss: 0.0811688\n",
      "\tspeed: 0.0249s/iter; left time: 335.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0807712 Vali Loss: 0.0816657 Test Loss: 0.0891511\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0815683\n",
      "\tspeed: 0.0533s/iter; left time: 711.3193s\n",
      "\titers: 200, epoch: 41 | loss: 0.0802722\n",
      "\tspeed: 0.0300s/iter; left time: 397.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0807110 Vali Loss: 0.0816553 Test Loss: 0.0890062\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02100452408194542, rmse:0.14492937922477722, mae:0.08865588903427124, rse:0.5479936003684998\n",
      "Intermediate time for IT and pred_len 96: 00h:14m:07.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3299916\n",
      "\tspeed: 0.0462s/iter; left time: 1026.0678s\n",
      "\titers: 200, epoch: 1 | loss: 0.3000069\n",
      "\tspeed: 0.0218s/iter; left time: 482.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.3321474 Vali Loss: 0.2036837 Test Loss: 0.2054069\n",
      "Validation loss decreased (inf --> 0.203684).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1536698\n",
      "\tspeed: 0.0493s/iter; left time: 1083.5704s\n",
      "\titers: 200, epoch: 2 | loss: 0.1333364\n",
      "\tspeed: 0.0250s/iter; left time: 547.4404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.1655924 Vali Loss: 0.1104899 Test Loss: 0.1182266\n",
      "Validation loss decreased (0.203684 --> 0.110490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1203284\n",
      "\tspeed: 0.0490s/iter; left time: 1066.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.1173807\n",
      "\tspeed: 0.0254s/iter; left time: 549.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.1221578 Vali Loss: 0.1053292 Test Loss: 0.1129497\n",
      "Validation loss decreased (0.110490 --> 0.105329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1070902\n",
      "\tspeed: 0.0470s/iter; left time: 1011.9311s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064659\n",
      "\tspeed: 0.0293s/iter; left time: 627.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.1101036 Vali Loss: 0.1003444 Test Loss: 0.1065617\n",
      "Validation loss decreased (0.105329 --> 0.100344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0988737\n",
      "\tspeed: 0.0503s/iter; left time: 1071.8563s\n",
      "\titers: 200, epoch: 5 | loss: 0.1036142\n",
      "\tspeed: 0.0240s/iter; left time: 509.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.1026914 Vali Loss: 0.0987232 Test Loss: 0.1058409\n",
      "Validation loss decreased (0.100344 --> 0.098723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1027035\n",
      "\tspeed: 0.0580s/iter; left time: 1223.2481s\n",
      "\titers: 200, epoch: 6 | loss: 0.0965298\n",
      "\tspeed: 0.0310s/iter; left time: 651.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.0990277 Vali Loss: 0.0968072 Test Loss: 0.1045042\n",
      "Validation loss decreased (0.098723 --> 0.096807).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958492\n",
      "\tspeed: 0.0561s/iter; left time: 1170.4790s\n",
      "\titers: 200, epoch: 7 | loss: 0.1004818\n",
      "\tspeed: 0.0317s/iter; left time: 657.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 223 | Train Loss: 0.0961664 Vali Loss: 0.0936732 Test Loss: 0.0995967\n",
      "Validation loss decreased (0.096807 --> 0.093673).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0938658\n",
      "\tspeed: 0.0570s/iter; left time: 1177.3238s\n",
      "\titers: 200, epoch: 8 | loss: 0.0944194\n",
      "\tspeed: 0.0323s/iter; left time: 663.3042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0952811 Vali Loss: 0.0935394 Test Loss: 0.1003524\n",
      "Validation loss decreased (0.093673 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0896352\n",
      "\tspeed: 0.0599s/iter; left time: 1222.9716s\n",
      "\titers: 200, epoch: 9 | loss: 0.0914407\n",
      "\tspeed: 0.0316s/iter; left time: 641.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.0927135 Vali Loss: 0.0923371 Test Loss: 0.0988408\n",
      "Validation loss decreased (0.093539 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0901856\n",
      "\tspeed: 0.0540s/iter; left time: 1091.3805s\n",
      "\titers: 200, epoch: 10 | loss: 0.0936390\n",
      "\tspeed: 0.0306s/iter; left time: 615.4580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.0917986 Vali Loss: 0.0901431 Test Loss: 0.0960062\n",
      "Validation loss decreased (0.092337 --> 0.090143).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0899440\n",
      "\tspeed: 0.0550s/iter; left time: 1099.0958s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883214\n",
      "\tspeed: 0.0275s/iter; left time: 545.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0911774 Vali Loss: 0.0913543 Test Loss: 0.0972036\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0899939\n",
      "\tspeed: 0.0489s/iter; left time: 965.1450s\n",
      "\titers: 200, epoch: 12 | loss: 0.0857778\n",
      "\tspeed: 0.0288s/iter; left time: 566.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0901367 Vali Loss: 0.0889537 Test Loss: 0.0949218\n",
      "Validation loss decreased (0.090143 --> 0.088954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893306\n",
      "\tspeed: 0.0504s/iter; left time: 984.2650s\n",
      "\titers: 200, epoch: 13 | loss: 0.0863610\n",
      "\tspeed: 0.0251s/iter; left time: 488.1896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0891761 Vali Loss: 0.0884308 Test Loss: 0.0943324\n",
      "Validation loss decreased (0.088954 --> 0.088431).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0908454\n",
      "\tspeed: 0.0555s/iter; left time: 1070.9250s\n",
      "\titers: 200, epoch: 14 | loss: 0.0903270\n",
      "\tspeed: 0.0306s/iter; left time: 587.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0885082 Vali Loss: 0.0893701 Test Loss: 0.0943574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0879544\n",
      "\tspeed: 0.0526s/iter; left time: 1003.2387s\n",
      "\titers: 200, epoch: 15 | loss: 0.0859830\n",
      "\tspeed: 0.0304s/iter; left time: 577.7161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.0881688 Vali Loss: 0.0887465 Test Loss: 0.0948149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0832802\n",
      "\tspeed: 0.0477s/iter; left time: 899.9706s\n",
      "\titers: 200, epoch: 16 | loss: 0.0854839\n",
      "\tspeed: 0.0233s/iter; left time: 436.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 223 | Train Loss: 0.0878722 Vali Loss: 0.0877291 Test Loss: 0.0933230\n",
      "Validation loss decreased (0.088431 --> 0.087729).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0858911\n",
      "\tspeed: 0.0554s/iter; left time: 1032.8344s\n",
      "\titers: 200, epoch: 17 | loss: 0.0860742\n",
      "\tspeed: 0.0299s/iter; left time: 554.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0874662 Vali Loss: 0.0889209 Test Loss: 0.0942997\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0854234\n",
      "\tspeed: 0.0444s/iter; left time: 816.7202s\n",
      "\titers: 200, epoch: 18 | loss: 0.0837145\n",
      "\tspeed: 0.0228s/iter; left time: 417.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0870829 Vali Loss: 0.0906566 Test Loss: 0.0963612\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0852829\n",
      "\tspeed: 0.0490s/iter; left time: 891.4207s\n",
      "\titers: 200, epoch: 19 | loss: 0.0859199\n",
      "\tspeed: 0.0266s/iter; left time: 481.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0867489 Vali Loss: 0.0890158 Test Loss: 0.0946742\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0866870\n",
      "\tspeed: 0.0510s/iter; left time: 916.3302s\n",
      "\titers: 200, epoch: 20 | loss: 0.0881107\n",
      "\tspeed: 0.0316s/iter; left time: 564.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0864305 Vali Loss: 0.0892794 Test Loss: 0.0948846\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0886777\n",
      "\tspeed: 0.0577s/iter; left time: 1023.5820s\n",
      "\titers: 200, epoch: 21 | loss: 0.0865534\n",
      "\tspeed: 0.0322s/iter; left time: 568.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 223 | Train Loss: 0.0863069 Vali Loss: 0.0896760 Test Loss: 0.0953626\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0870153\n",
      "\tspeed: 0.0551s/iter; left time: 965.6910s\n",
      "\titers: 200, epoch: 22 | loss: 0.0867573\n",
      "\tspeed: 0.0263s/iter; left time: 457.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0866826 Vali Loss: 0.0895520 Test Loss: 0.0944531\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0896195\n",
      "\tspeed: 0.0552s/iter; left time: 953.8537s\n",
      "\titers: 200, epoch: 23 | loss: 0.0852326\n",
      "\tspeed: 0.0310s/iter; left time: 533.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.0867930 Vali Loss: 0.0887141 Test Loss: 0.0943946\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0859464\n",
      "\tspeed: 0.0555s/iter; left time: 947.6995s\n",
      "\titers: 200, epoch: 24 | loss: 0.0841803\n",
      "\tspeed: 0.0302s/iter; left time: 513.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 223 | Train Loss: 0.0859055 Vali Loss: 0.0883401 Test Loss: 0.0939587\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0829458\n",
      "\tspeed: 0.0451s/iter; left time: 759.3298s\n",
      "\titers: 200, epoch: 25 | loss: 0.0802960\n",
      "\tspeed: 0.0269s/iter; left time: 450.9521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 223 | Train Loss: 0.0855547 Vali Loss: 0.0885006 Test Loss: 0.0940825\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0886725\n",
      "\tspeed: 0.0478s/iter; left time: 795.1888s\n",
      "\titers: 200, epoch: 26 | loss: 0.0845164\n",
      "\tspeed: 0.0262s/iter; left time: 432.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0856572 Vali Loss: 0.0879737 Test Loss: 0.0934940\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02238144911825657, rmse:0.14960430562496185, mae:0.09332302957773209, rse:0.5661956667900085\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3274738\n",
      "\tspeed: 0.0321s/iter; left time: 712.2248s\n",
      "\titers: 200, epoch: 1 | loss: 0.2939182\n",
      "\tspeed: 0.0313s/iter; left time: 691.9132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.3303096 Vali Loss: 0.2036743 Test Loss: 0.2055091\n",
      "Validation loss decreased (inf --> 0.203674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1508875\n",
      "\tspeed: 0.0481s/iter; left time: 1057.1249s\n",
      "\titers: 200, epoch: 2 | loss: 0.1324100\n",
      "\tspeed: 0.0270s/iter; left time: 590.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.1659303 Vali Loss: 0.1109600 Test Loss: 0.1188641\n",
      "Validation loss decreased (0.203674 --> 0.110960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1182288\n",
      "\tspeed: 0.0599s/iter; left time: 1303.4242s\n",
      "\titers: 200, epoch: 3 | loss: 0.1156359\n",
      "\tspeed: 0.0311s/iter; left time: 672.4315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 223 | Train Loss: 0.1183670 Vali Loss: 0.1051606 Test Loss: 0.1122743\n",
      "Validation loss decreased (0.110960 --> 0.105161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086090\n",
      "\tspeed: 0.0566s/iter; left time: 1219.6650s\n",
      "\titers: 200, epoch: 4 | loss: 0.1055736\n",
      "\tspeed: 0.0319s/iter; left time: 684.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 223 | Train Loss: 0.1068190 Vali Loss: 0.1004016 Test Loss: 0.1068559\n",
      "Validation loss decreased (0.105161 --> 0.100402).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1009567\n",
      "\tspeed: 0.0651s/iter; left time: 1387.4371s\n",
      "\titers: 200, epoch: 5 | loss: 0.0983994\n",
      "\tspeed: 0.0332s/iter; left time: 703.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.1012320 Vali Loss: 0.0990146 Test Loss: 0.1067856\n",
      "Validation loss decreased (0.100402 --> 0.099015).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0973382\n",
      "\tspeed: 0.0590s/iter; left time: 1243.4276s\n",
      "\titers: 200, epoch: 6 | loss: 0.1096378\n",
      "\tspeed: 0.0311s/iter; left time: 652.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0991406 Vali Loss: 0.0955675 Test Loss: 0.1030715\n",
      "Validation loss decreased (0.099015 --> 0.095568).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0973908\n",
      "\tspeed: 0.0481s/iter; left time: 1004.3495s\n",
      "\titers: 200, epoch: 7 | loss: 0.0957352\n",
      "\tspeed: 0.0315s/iter; left time: 654.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0957085 Vali Loss: 0.0934825 Test Loss: 0.1009847\n",
      "Validation loss decreased (0.095568 --> 0.093483).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0914249\n",
      "\tspeed: 0.0623s/iter; left time: 1286.1490s\n",
      "\titers: 200, epoch: 8 | loss: 0.0914910\n",
      "\tspeed: 0.0345s/iter; left time: 708.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0938212 Vali Loss: 0.0900435 Test Loss: 0.0977560\n",
      "Validation loss decreased (0.093483 --> 0.090043).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0969158\n",
      "\tspeed: 0.0573s/iter; left time: 1170.8180s\n",
      "\titers: 200, epoch: 9 | loss: 0.0952721\n",
      "\tspeed: 0.0330s/iter; left time: 669.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 223 | Train Loss: 0.0930346 Vali Loss: 0.0944901 Test Loss: 0.1017400\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0915176\n",
      "\tspeed: 0.0554s/iter; left time: 1117.9638s\n",
      "\titers: 200, epoch: 10 | loss: 0.0902691\n",
      "\tspeed: 0.0233s/iter; left time: 468.1914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0916078 Vali Loss: 0.0945042 Test Loss: 0.1012674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0915790\n",
      "\tspeed: 0.0433s/iter; left time: 864.9968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0921399\n",
      "\tspeed: 0.0198s/iter; left time: 392.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0906748 Vali Loss: 0.0882098 Test Loss: 0.0954525\n",
      "Validation loss decreased (0.090043 --> 0.088210).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0888568\n",
      "\tspeed: 0.0444s/iter; left time: 877.7820s\n",
      "\titers: 200, epoch: 12 | loss: 0.0889237\n",
      "\tspeed: 0.0230s/iter; left time: 451.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0896931 Vali Loss: 0.0890873 Test Loss: 0.0962800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0899733\n",
      "\tspeed: 0.0480s/iter; left time: 936.5446s\n",
      "\titers: 200, epoch: 13 | loss: 0.0917390\n",
      "\tspeed: 0.0205s/iter; left time: 398.3054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0897441 Vali Loss: 0.0878103 Test Loss: 0.0949804\n",
      "Validation loss decreased (0.088210 --> 0.087810).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0857677\n",
      "\tspeed: 0.0427s/iter; left time: 825.1410s\n",
      "\titers: 200, epoch: 14 | loss: 0.0875059\n",
      "\tspeed: 0.0206s/iter; left time: 395.9815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0886025 Vali Loss: 0.0883880 Test Loss: 0.0947822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854913\n",
      "\tspeed: 0.0522s/iter; left time: 995.6378s\n",
      "\titers: 200, epoch: 15 | loss: 0.0873562\n",
      "\tspeed: 0.0282s/iter; left time: 534.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.0880795 Vali Loss: 0.0875004 Test Loss: 0.0941577\n",
      "Validation loss decreased (0.087810 --> 0.087500).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0877052\n",
      "\tspeed: 0.0525s/iter; left time: 989.5533s\n",
      "\titers: 200, epoch: 16 | loss: 0.0883855\n",
      "\tspeed: 0.0292s/iter; left time: 547.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 223 | Train Loss: 0.0875604 Vali Loss: 0.0865318 Test Loss: 0.0932173\n",
      "Validation loss decreased (0.087500 --> 0.086532).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0847704\n",
      "\tspeed: 0.0477s/iter; left time: 889.0905s\n",
      "\titers: 200, epoch: 17 | loss: 0.0816629\n",
      "\tspeed: 0.0217s/iter; left time: 402.4127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0870397 Vali Loss: 0.0868166 Test Loss: 0.0931589\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0861665\n",
      "\tspeed: 0.0493s/iter; left time: 907.0553s\n",
      "\titers: 200, epoch: 18 | loss: 0.0859466\n",
      "\tspeed: 0.0320s/iter; left time: 586.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.0868295 Vali Loss: 0.0865952 Test Loss: 0.0931692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0846673\n",
      "\tspeed: 0.0550s/iter; left time: 1000.8283s\n",
      "\titers: 200, epoch: 19 | loss: 0.0894428\n",
      "\tspeed: 0.0296s/iter; left time: 535.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.0863929 Vali Loss: 0.0875889 Test Loss: 0.0942658\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811957\n",
      "\tspeed: 0.0490s/iter; left time: 879.5499s\n",
      "\titers: 200, epoch: 20 | loss: 0.0818428\n",
      "\tspeed: 0.0320s/iter; left time: 571.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.0858660 Vali Loss: 0.0863225 Test Loss: 0.0924673\n",
      "Validation loss decreased (0.086532 --> 0.086323).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0854587\n",
      "\tspeed: 0.0526s/iter; left time: 932.6113s\n",
      "\titers: 200, epoch: 21 | loss: 0.0869556\n",
      "\tspeed: 0.0244s/iter; left time: 430.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0858865 Vali Loss: 0.0868287 Test Loss: 0.0933170\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0853215\n",
      "\tspeed: 0.0479s/iter; left time: 838.8154s\n",
      "\titers: 200, epoch: 22 | loss: 0.0868122\n",
      "\tspeed: 0.0339s/iter; left time: 590.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.0855991 Vali Loss: 0.0868944 Test Loss: 0.0932348\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0863309\n",
      "\tspeed: 0.0516s/iter; left time: 891.7634s\n",
      "\titers: 200, epoch: 23 | loss: 0.0844264\n",
      "\tspeed: 0.0242s/iter; left time: 416.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0856433 Vali Loss: 0.0865154 Test Loss: 0.0925937\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0878550\n",
      "\tspeed: 0.0439s/iter; left time: 748.7707s\n",
      "\titers: 200, epoch: 24 | loss: 0.0864117\n",
      "\tspeed: 0.0308s/iter; left time: 523.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0853009 Vali Loss: 0.0860250 Test Loss: 0.0920176\n",
      "Validation loss decreased (0.086323 --> 0.086025).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0850207\n",
      "\tspeed: 0.0559s/iter; left time: 942.6289s\n",
      "\titers: 200, epoch: 25 | loss: 0.0869325\n",
      "\tspeed: 0.0290s/iter; left time: 486.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0856931 Vali Loss: 0.0872585 Test Loss: 0.0936503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0836976\n",
      "\tspeed: 0.0531s/iter; left time: 882.5347s\n",
      "\titers: 200, epoch: 26 | loss: 0.0875092\n",
      "\tspeed: 0.0293s/iter; left time: 484.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0850139 Vali Loss: 0.0870115 Test Loss: 0.0926384\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0871197\n",
      "\tspeed: 0.0573s/iter; left time: 939.7497s\n",
      "\titers: 200, epoch: 27 | loss: 0.0815758\n",
      "\tspeed: 0.0345s/iter; left time: 562.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 223 | Train Loss: 0.0849000 Vali Loss: 0.0864799 Test Loss: 0.0929938\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0846432\n",
      "\tspeed: 0.0506s/iter; left time: 818.3489s\n",
      "\titers: 200, epoch: 28 | loss: 0.0855859\n",
      "\tspeed: 0.0210s/iter; left time: 336.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0847834 Vali Loss: 0.0866640 Test Loss: 0.0928136\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0850936\n",
      "\tspeed: 0.0527s/iter; left time: 841.5144s\n",
      "\titers: 200, epoch: 29 | loss: 0.0834354\n",
      "\tspeed: 0.0294s/iter; left time: 466.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0846088 Vali Loss: 0.0869811 Test Loss: 0.0933653\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0830241\n",
      "\tspeed: 0.0452s/iter; left time: 711.1582s\n",
      "\titers: 200, epoch: 30 | loss: 0.0857412\n",
      "\tspeed: 0.0217s/iter; left time: 339.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0845593 Vali Loss: 0.0869336 Test Loss: 0.0930836\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850076\n",
      "\tspeed: 0.0443s/iter; left time: 687.3227s\n",
      "\titers: 200, epoch: 31 | loss: 0.0875192\n",
      "\tspeed: 0.0207s/iter; left time: 318.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0844200 Vali Loss: 0.0865963 Test Loss: 0.0927902\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0870794\n",
      "\tspeed: 0.0466s/iter; left time: 713.0808s\n",
      "\titers: 200, epoch: 32 | loss: 0.0830671\n",
      "\tspeed: 0.0251s/iter; left time: 380.8697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0843197 Vali Loss: 0.0860254 Test Loss: 0.0922234\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0815549\n",
      "\tspeed: 0.0516s/iter; left time: 776.6973s\n",
      "\titers: 200, epoch: 33 | loss: 0.0827839\n",
      "\tspeed: 0.0188s/iter; left time: 281.8846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0848689 Vali Loss: 0.0867193 Test Loss: 0.0928429\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0832416\n",
      "\tspeed: 0.0523s/iter; left time: 775.5610s\n",
      "\titers: 200, epoch: 34 | loss: 0.0860843\n",
      "\tspeed: 0.0305s/iter; left time: 449.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.0842872 Vali Loss: 0.0864855 Test Loss: 0.0927452\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021622739732265472, rmse:0.14704672992229462, mae:0.09201756864786148, rse:0.5565162301063538\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:09.49s\n",
      "Intermediate time for IT: 00h:37m:23.07s\n",
      "Total time: 03h:11m:29.50s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN + Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.0925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            -RevIN + Decomposition                 \n",
       "Metrics                              MSE    RMSE     MAE\n",
       "Country Pred_len                                        \n",
       "DE      24                        0.0217  0.1474  0.0912\n",
       "        96                        0.0407  0.2015  0.1325\n",
       "        168                       0.0425  0.2060  0.1390\n",
       "ES      24                        0.0158  0.1228  0.0743\n",
       "        96                        0.0291  0.1677  0.1059\n",
       "        168                       0.0314  0.1747  0.1126\n",
       "FR      24                        0.0111  0.1053  0.0598\n",
       "        96                        0.0215  0.1463  0.0856\n",
       "        168                       0.0243  0.1554  0.0925\n",
       "GB      24                        0.0266  0.1631  0.1045\n",
       "        96                        0.0489  0.2210  0.1490\n",
       "        168                       0.0518  0.2275  0.1552\n",
       "IT      24                        0.0108  0.1041  0.0611\n",
       "        96                        0.0190  0.1378  0.0836\n",
       "        168                       0.0206  0.1434  0.0886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN + Decomposition '], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
