{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 1 epoch run_main.py with gradient accumulation (without additional steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 00:58:31,752] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 00:58:33,017] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 00:58:33,017] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 00:58:33,017] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 00:58:33,919] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 00:58:33,920] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 00:58:34,578] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 00:58:34,580] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 00:58:34,580] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 00:58:34,582] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 00:58:34,582] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 00:58:34,583] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 00:58:34,583] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 00:58:34,583] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 00:58:34,583] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 00:58:34,583] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 00:58:34,963] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 00:58:34,965] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 00:58:34,965] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.09 GB, percent = 20.2%\n",
      "[2024-05-20 00:58:35,146] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 00:58:35,147] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 00:58:35,147] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.1 GB, percent = 20.2%\n",
      "[2024-05-20 00:58:35,147] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 00:58:35,304] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 00:58:35,305] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 00:58:35,305] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.3 GB, percent = 20.2%\n",
      "[2024-05-20 00:58:35,306] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 00:58:35,306] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 00:58:35,306] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 00:58:35,306] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 00:58:35,307] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4226279e50>\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 00:58:35,308] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 00:58:35,309] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 00:58:35,310] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:05, 23.79it/s]\titers: 100, epoch: 1 | loss: 1.2100023\n",
      "\tspeed: 0.0963s/iter; left time: 1417.9794s\n",
      "198it [00:09, 22.59it/s]\titers: 200, epoch: 1 | loss: 0.4719745\n",
      "\tspeed: 0.0420s/iter; left time: 614.2851s\n",
      "297it [00:14, 20.74it/s]\titers: 300, epoch: 1 | loss: 0.8270715\n",
      "\tspeed: 0.0470s/iter; left time: 682.5964s\n",
      "397it [00:19, 20.47it/s]\titers: 400, epoch: 1 | loss: 0.8933063\n",
      "\tspeed: 0.0488s/iter; left time: 703.7424s\n",
      "498it [00:23, 24.43it/s]\titers: 500, epoch: 1 | loss: 1.1096756\n",
      "\tspeed: 0.0464s/iter; left time: 664.1039s\n",
      "597it [00:28, 21.69it/s]\titers: 600, epoch: 1 | loss: 1.0732007\n",
      "\tspeed: 0.0434s/iter; left time: 617.1328s\n",
      "699it [00:32, 21.34it/s]\titers: 700, epoch: 1 | loss: 0.6724876\n",
      "\tspeed: 0.0466s/iter; left time: 657.8183s\n",
      "797it [00:37, 21.87it/s]\titers: 800, epoch: 1 | loss: 0.4488840\n",
      "\tspeed: 0.0484s/iter; left time: 678.9164s\n",
      "899it [00:41, 23.89it/s]\titers: 900, epoch: 1 | loss: 0.4415597\n",
      "\tspeed: 0.0421s/iter; left time: 585.4964s\n",
      "998it [00:46, 24.11it/s]\titers: 1000, epoch: 1 | loss: 0.5833146\n",
      "\tspeed: 0.0417s/iter; left time: 576.8128s\n",
      "1097it [00:50, 20.79it/s]\titers: 1100, epoch: 1 | loss: 0.4452401\n",
      "\tspeed: 0.0450s/iter; left time: 617.1774s\n",
      "1199it [00:55, 19.70it/s]\titers: 1200, epoch: 1 | loss: 0.4246193\n",
      "\tspeed: 0.0519s/iter; left time: 707.1897s\n",
      "1299it [01:00, 21.62it/s]\titers: 1300, epoch: 1 | loss: 0.8128982\n",
      "\tspeed: 0.0506s/iter; left time: 683.7003s\n",
      "1399it [01:05, 22.88it/s]\titers: 1400, epoch: 1 | loss: 0.5363386\n",
      "\tspeed: 0.0445s/iter; left time: 597.3789s\n",
      "1497it [01:10, 18.35it/s]\titers: 1500, epoch: 1 | loss: 0.8632331\n",
      "\tspeed: 0.0538s/iter; left time: 717.0989s\n",
      "1597it [01:15, 24.18it/s]\titers: 1600, epoch: 1 | loss: 0.4425161\n",
      "\tspeed: 0.0476s/iter; left time: 629.2996s\n",
      "1699it [01:19, 24.71it/s]\titers: 1700, epoch: 1 | loss: 0.9049737\n",
      "\tspeed: 0.0410s/iter; left time: 537.9326s\n",
      "1798it [01:23, 23.27it/s]\titers: 1800, epoch: 1 | loss: 0.6961403\n",
      "\tspeed: 0.0416s/iter; left time: 542.0930s\n",
      "1897it [01:28, 19.98it/s]\titers: 1900, epoch: 1 | loss: 0.7065306\n",
      "\tspeed: 0.0448s/iter; left time: 578.6890s\n",
      "1998it [01:33, 18.00it/s]\titers: 2000, epoch: 1 | loss: 0.2669930\n",
      "\tspeed: 0.0527s/iter; left time: 675.8498s\n",
      "2099it [01:38, 22.02it/s]\titers: 2100, epoch: 1 | loss: 0.4881725\n",
      "\tspeed: 0.0500s/iter; left time: 636.2950s\n",
      "2197it [01:43, 18.28it/s]\titers: 2200, epoch: 1 | loss: 0.8746573\n",
      "\tspeed: 0.0517s/iter; left time: 652.5089s\n",
      "2299it [01:47, 24.01it/s]\titers: 2300, epoch: 1 | loss: 1.1616392\n",
      "\tspeed: 0.0427s/iter; left time: 533.9784s\n",
      "2398it [01:52, 24.98it/s]\titers: 2400, epoch: 1 | loss: 0.2961538\n",
      "\tspeed: 0.0416s/iter; left time: 517.1068s\n",
      "2497it [01:56, 24.39it/s]\titers: 2500, epoch: 1 | loss: 0.4981700\n",
      "\tspeed: 0.0413s/iter; left time: 509.0205s\n",
      "2599it [02:00, 23.70it/s]\titers: 2600, epoch: 1 | loss: 1.0616041\n",
      "\tspeed: 0.0416s/iter; left time: 508.0767s\n",
      "2698it [02:04, 20.61it/s]\titers: 2700, epoch: 1 | loss: 0.9184409\n",
      "\tspeed: 0.0462s/iter; left time: 560.2501s\n",
      "2798it [02:10, 17.84it/s]\titers: 2800, epoch: 1 | loss: 0.7068489\n",
      "\tspeed: 0.0518s/iter; left time: 622.1871s\n",
      "2897it [02:14, 24.79it/s]\titers: 2900, epoch: 1 | loss: 0.5155199\n",
      "\tspeed: 0.0472s/iter; left time: 562.2970s\n",
      "2999it [02:19, 24.51it/s]\titers: 3000, epoch: 1 | loss: 0.3697930\n",
      "\tspeed: 0.0411s/iter; left time: 485.5484s\n",
      "3098it [02:23, 24.44it/s]\titers: 3100, epoch: 1 | loss: 1.7031286\n",
      "\tspeed: 0.0409s/iter; left time: 479.5403s\n",
      "3197it [02:27, 24.12it/s]\titers: 3200, epoch: 1 | loss: 0.3750121\n",
      "\tspeed: 0.0411s/iter; left time: 477.0861s\n",
      "3299it [02:31, 23.68it/s]\titers: 3300, epoch: 1 | loss: 0.1839736\n",
      "\tspeed: 0.0410s/iter; left time: 472.3448s\n",
      "3398it [02:35, 22.69it/s]\titers: 3400, epoch: 1 | loss: 1.0785438\n",
      "\tspeed: 0.0435s/iter; left time: 496.3546s\n",
      "3499it [02:40, 17.65it/s]\titers: 3500, epoch: 1 | loss: 0.6788548\n",
      "\tspeed: 0.0490s/iter; left time: 555.0700s\n",
      "3598it [02:45, 19.01it/s]\titers: 3600, epoch: 1 | loss: 0.8473063\n",
      "\tspeed: 0.0528s/iter; left time: 592.8159s\n",
      "3698it [02:50, 23.76it/s]\titers: 3700, epoch: 1 | loss: 0.3364809\n",
      "\tspeed: 0.0493s/iter; left time: 548.1320s\n",
      "3797it [02:54, 23.82it/s]\titers: 3800, epoch: 1 | loss: 0.4078275\n",
      "\tspeed: 0.0416s/iter; left time: 458.6876s\n",
      "3899it [02:59, 25.43it/s]\titers: 3900, epoch: 1 | loss: 0.6516296\n",
      "\tspeed: 0.0416s/iter; left time: 454.0202s\n",
      "3998it [03:03, 23.07it/s]\titers: 4000, epoch: 1 | loss: 0.6825324\n",
      "\tspeed: 0.0422s/iter; left time: 456.0757s\n",
      "4097it [03:07, 20.07it/s]\titers: 4100, epoch: 1 | loss: 0.4433888\n",
      "\tspeed: 0.0434s/iter; left time: 464.8924s\n",
      "4199it [03:12, 21.29it/s]\titers: 4200, epoch: 1 | loss: 0.9938721\n",
      "\tspeed: 0.0469s/iter; left time: 497.6165s\n",
      "4298it [03:16, 23.70it/s]\titers: 4300, epoch: 1 | loss: 0.3262190\n",
      "\tspeed: 0.0432s/iter; left time: 454.4710s\n",
      "4398it [03:21, 19.16it/s]\titers: 4400, epoch: 1 | loss: 0.4855730\n",
      "\tspeed: 0.0532s/iter; left time: 554.0978s\n",
      "4499it [03:26, 24.15it/s]\titers: 4500, epoch: 1 | loss: 0.1956166\n",
      "\tspeed: 0.0488s/iter; left time: 503.4509s\n",
      "4598it [03:30, 24.04it/s]\titers: 4600, epoch: 1 | loss: 0.2855468\n",
      "\tspeed: 0.0416s/iter; left time: 425.2414s\n",
      "4697it [03:35, 25.31it/s]\titers: 4700, epoch: 1 | loss: 1.2788696\n",
      "\tspeed: 0.0415s/iter; left time: 419.8280s\n",
      "4799it [03:39, 20.45it/s]\titers: 4800, epoch: 1 | loss: 0.3046062\n",
      "\tspeed: 0.0433s/iter; left time: 433.4373s\n",
      "4898it [03:44, 17.84it/s]\titers: 4900, epoch: 1 | loss: 0.4774517\n",
      "\tspeed: 0.0519s/iter; left time: 515.0238s\n",
      "4997it [03:48, 23.28it/s]\titers: 5000, epoch: 1 | loss: 0.5055078\n",
      "\tspeed: 0.0424s/iter; left time: 415.9708s\n",
      "5099it [03:53, 22.63it/s]\titers: 5100, epoch: 1 | loss: 0.7752290\n",
      "\tspeed: 0.0429s/iter; left time: 417.0904s\n",
      "5199it [03:58, 22.62it/s]\titers: 5200, epoch: 1 | loss: 0.3553796\n",
      "\tspeed: 0.0482s/iter; left time: 463.5612s\n",
      "5299it [04:02, 20.84it/s]\titers: 5300, epoch: 1 | loss: 1.2170597\n",
      "\tspeed: 0.0484s/iter; left time: 460.2523s\n",
      "5398it [04:06, 25.52it/s]\titers: 5400, epoch: 1 | loss: 0.3382396\n",
      "\tspeed: 0.0404s/iter; left time: 380.6779s\n",
      "5497it [04:11, 22.35it/s]\titers: 5500, epoch: 1 | loss: 0.1891921\n",
      "\tspeed: 0.0432s/iter; left time: 402.4225s\n",
      "5598it [04:16, 18.39it/s]\titers: 5600, epoch: 1 | loss: 0.2955888\n",
      "\tspeed: 0.0508s/iter; left time: 468.6288s\n",
      "5699it [04:21, 18.38it/s]\titers: 5700, epoch: 1 | loss: 0.2907146\n",
      "\tspeed: 0.0515s/iter; left time: 469.6083s\n",
      "5799it [04:25, 22.09it/s]\titers: 5800, epoch: 1 | loss: 0.4387524\n",
      "\tspeed: 0.0423s/iter; left time: 381.4633s\n",
      "5898it [04:30, 21.55it/s]\titers: 5900, epoch: 1 | loss: 0.2277153\n",
      "\tspeed: 0.0434s/iter; left time: 387.2150s\n",
      "5998it [04:35, 20.31it/s]\titers: 6000, epoch: 1 | loss: 0.1939872\n",
      "\tspeed: 0.0504s/iter; left time: 444.4182s\n",
      "6099it [04:40, 23.58it/s]\titers: 6100, epoch: 1 | loss: 0.2317864\n",
      "\tspeed: 0.0514s/iter; left time: 447.6946s\n",
      "6198it [04:44, 24.35it/s]\titers: 6200, epoch: 1 | loss: 0.5303420\n",
      "\tspeed: 0.0408s/iter; left time: 351.8391s\n",
      "6298it [04:48, 19.41it/s]\titers: 6300, epoch: 1 | loss: 0.4089229\n",
      "\tspeed: 0.0453s/iter; left time: 385.4108s\n",
      "6399it [04:53, 22.78it/s]\titers: 6400, epoch: 1 | loss: 0.1928583\n",
      "\tspeed: 0.0504s/iter; left time: 424.4263s\n",
      "6498it [04:57, 24.45it/s]\titers: 6500, epoch: 1 | loss: 0.2946931\n",
      "\tspeed: 0.0413s/iter; left time: 343.8428s\n",
      "6597it [05:02, 23.73it/s]\titers: 6600, epoch: 1 | loss: 0.6640747\n",
      "\tspeed: 0.0415s/iter; left time: 341.1039s\n",
      "6699it [05:06, 22.15it/s]\titers: 6700, epoch: 1 | loss: 0.2682841\n",
      "\tspeed: 0.0437s/iter; left time: 354.6770s\n",
      "6797it [05:11, 18.05it/s]\titers: 6800, epoch: 1 | loss: 0.2828879\n",
      "\tspeed: 0.0521s/iter; left time: 417.9791s\n",
      "6897it [05:16, 21.39it/s]\titers: 6900, epoch: 1 | loss: 0.5458733\n",
      "\tspeed: 0.0496s/iter; left time: 392.3952s\n",
      "6999it [05:21, 19.60it/s]\titers: 7000, epoch: 1 | loss: 0.2802522\n",
      "\tspeed: 0.0482s/iter; left time: 376.6935s\n",
      "7099it [05:26, 24.93it/s]\titers: 7100, epoch: 1 | loss: 0.3009359\n",
      "\tspeed: 0.0467s/iter; left time: 360.3670s\n",
      "7198it [05:30, 24.76it/s]\titers: 7200, epoch: 1 | loss: 0.2249059\n",
      "\tspeed: 0.0412s/iter; left time: 313.5004s\n",
      "7297it [05:34, 23.28it/s]\titers: 7300, epoch: 1 | loss: 0.7087804\n",
      "\tspeed: 0.0416s/iter; left time: 312.9929s\n",
      "7399it [05:38, 24.26it/s]\titers: 7400, epoch: 1 | loss: 0.4487431\n",
      "\tspeed: 0.0422s/iter; left time: 312.9529s\n",
      "7498it [05:42, 21.88it/s]\titers: 7500, epoch: 1 | loss: 0.3811559\n",
      "\tspeed: 0.0425s/iter; left time: 311.0498s\n",
      "7598it [05:47, 20.55it/s]\titers: 7600, epoch: 1 | loss: 0.4741640\n",
      "\tspeed: 0.0492s/iter; left time: 355.0661s\n",
      "7698it [05:53, 18.01it/s]\titers: 7700, epoch: 1 | loss: 0.2948685\n",
      "\tspeed: 0.0550s/iter; left time: 391.5625s\n",
      "7798it [05:58, 17.97it/s]\titers: 7800, epoch: 1 | loss: 0.1803007\n",
      "\tspeed: 0.0521s/iter; left time: 365.7529s\n",
      "7898it [06:02, 24.21it/s]\titers: 7900, epoch: 1 | loss: 0.3735719\n",
      "\tspeed: 0.0427s/iter; left time: 295.0706s\n",
      "7997it [06:06, 24.13it/s]\titers: 8000, epoch: 1 | loss: 0.1715254\n",
      "\tspeed: 0.0417s/iter; left time: 284.1640s\n",
      "8099it [06:11, 23.37it/s]\titers: 8100, epoch: 1 | loss: 0.1723867\n",
      "\tspeed: 0.0414s/iter; left time: 277.8556s\n",
      "8198it [06:15, 24.12it/s]\titers: 8200, epoch: 1 | loss: 0.8741489\n",
      "\tspeed: 0.0417s/iter; left time: 275.6074s\n",
      "8297it [06:19, 21.35it/s]\titers: 8300, epoch: 1 | loss: 0.5079411\n",
      "\tspeed: 0.0437s/iter; left time: 284.7410s\n",
      "8399it [06:24, 18.56it/s]\titers: 8400, epoch: 1 | loss: 0.4221446\n",
      "\tspeed: 0.0512s/iter; left time: 328.4384s\n",
      "8499it [06:30, 22.58it/s]\titers: 8500, epoch: 1 | loss: 0.5190887\n",
      "\tspeed: 0.0553s/iter; left time: 349.6302s\n",
      "8598it [06:34, 25.90it/s]\titers: 8600, epoch: 1 | loss: 0.5163773\n",
      "\tspeed: 0.0406s/iter; left time: 252.3463s\n",
      "8697it [06:38, 24.60it/s]\titers: 8700, epoch: 1 | loss: 0.2107243\n",
      "\tspeed: 0.0414s/iter; left time: 253.3915s\n",
      "8799it [06:42, 24.82it/s]\titers: 8800, epoch: 1 | loss: 1.8230904\n",
      "\tspeed: 0.0420s/iter; left time: 252.4172s\n",
      "8898it [06:46, 23.82it/s]\titers: 8900, epoch: 1 | loss: 0.7863830\n",
      "\tspeed: 0.0416s/iter; left time: 246.2217s\n",
      "8997it [06:51, 23.44it/s]\titers: 9000, epoch: 1 | loss: 0.1825612\n",
      "\tspeed: 0.0424s/iter; left time: 246.6071s\n",
      "9099it [06:55, 21.13it/s]\titers: 9100, epoch: 1 | loss: 0.1264677\n",
      "\tspeed: 0.0464s/iter; left time: 265.2147s\n",
      "9199it [07:00, 20.46it/s]\titers: 9200, epoch: 1 | loss: 0.5377688\n",
      "\tspeed: 0.0501s/iter; left time: 281.1535s\n",
      "9299it [07:06, 18.77it/s]\titers: 9300, epoch: 1 | loss: 0.8846996\n",
      "\tspeed: 0.0547s/iter; left time: 301.8624s\n",
      "9397it [07:10, 23.91it/s]\titers: 9400, epoch: 1 | loss: 0.7158275\n",
      "\tspeed: 0.0413s/iter; left time: 223.7440s\n",
      "9499it [07:14, 24.17it/s]\titers: 9500, epoch: 1 | loss: 0.2976035\n",
      "\tspeed: 0.0411s/iter; left time: 218.5840s\n",
      "9598it [07:18, 24.94it/s]\titers: 9600, epoch: 1 | loss: 0.3770229\n",
      "\tspeed: 0.0415s/iter; left time: 216.4080s\n",
      "9697it [07:22, 23.89it/s]\titers: 9700, epoch: 1 | loss: 0.4641332\n",
      "\tspeed: 0.0410s/iter; left time: 209.9162s\n",
      "9798it [07:27, 18.47it/s]\titers: 9800, epoch: 1 | loss: 0.3670942\n",
      "\tspeed: 0.0493s/iter; left time: 247.4633s\n",
      "9898it [07:32, 23.01it/s]\titers: 9900, epoch: 1 | loss: 0.4804549\n",
      "\tspeed: 0.0459s/iter; left time: 225.8487s\n",
      "9998it [07:37, 21.17it/s]\titers: 10000, epoch: 1 | loss: 0.4358552\n",
      "\tspeed: 0.0481s/iter; left time: 231.4751s\n",
      "10099it [07:42, 19.17it/s]\titers: 10100, epoch: 1 | loss: 0.2683017\n",
      "\tspeed: 0.0508s/iter; left time: 239.6410s\n",
      "10197it [07:46, 25.09it/s]\titers: 10200, epoch: 1 | loss: 0.2550182\n",
      "\tspeed: 0.0424s/iter; left time: 195.8285s\n",
      "10299it [07:50, 23.93it/s]\titers: 10300, epoch: 1 | loss: 0.3009215\n",
      "\tspeed: 0.0415s/iter; left time: 187.2381s\n",
      "10398it [07:54, 22.49it/s]\titers: 10400, epoch: 1 | loss: 0.2636962\n",
      "\tspeed: 0.0419s/iter; left time: 185.2443s\n",
      "10497it [07:59, 19.82it/s]\titers: 10500, epoch: 1 | loss: 0.3230118\n",
      "\tspeed: 0.0485s/iter; left time: 209.4237s\n",
      "10599it [08:03, 24.57it/s]\titers: 10600, epoch: 1 | loss: 0.1425342\n",
      "\tspeed: 0.0436s/iter; left time: 183.8938s\n",
      "10698it [08:08, 23.03it/s]\titers: 10700, epoch: 1 | loss: 0.0943355\n",
      "\tspeed: 0.0421s/iter; left time: 173.4677s\n",
      "10798it [08:12, 20.28it/s]\titers: 10800, epoch: 1 | loss: 0.1555537\n",
      "\tspeed: 0.0481s/iter; left time: 193.1015s\n",
      "10897it [08:17, 19.91it/s]\titers: 10900, epoch: 1 | loss: 0.4060164\n",
      "\tspeed: 0.0501s/iter; left time: 196.4038s\n",
      "10999it [08:22, 25.92it/s]\titers: 11000, epoch: 1 | loss: 0.1792986\n",
      "\tspeed: 0.0447s/iter; left time: 170.6651s\n",
      "11098it [08:26, 24.27it/s]\titers: 11100, epoch: 1 | loss: 0.1975928\n",
      "\tspeed: 0.0427s/iter; left time: 158.6948s\n",
      "11198it [08:31, 19.83it/s]\titers: 11200, epoch: 1 | loss: 1.1800880\n",
      "\tspeed: 0.0507s/iter; left time: 183.3547s\n",
      "11299it [08:36, 23.87it/s]\titers: 11300, epoch: 1 | loss: 0.5712709\n",
      "\tspeed: 0.0449s/iter; left time: 157.9973s\n",
      "11398it [08:40, 24.58it/s]\titers: 11400, epoch: 1 | loss: 0.1855741\n",
      "\tspeed: 0.0412s/iter; left time: 140.7612s\n",
      "11497it [08:44, 24.10it/s]\titers: 11500, epoch: 1 | loss: 0.1726841\n",
      "\tspeed: 0.0411s/iter; left time: 136.2973s\n",
      "11599it [08:49, 18.92it/s]\titers: 11600, epoch: 1 | loss: 0.1752069\n",
      "\tspeed: 0.0471s/iter; left time: 151.4239s\n",
      "11697it [08:54, 18.49it/s]\titers: 11700, epoch: 1 | loss: 0.4001184\n",
      "\tspeed: 0.0518s/iter; left time: 161.6125s\n",
      "11798it [08:59, 24.79it/s]\titers: 11800, epoch: 1 | loss: 0.2365575\n",
      "\tspeed: 0.0469s/iter; left time: 141.4448s\n",
      "11899it [09:03, 21.86it/s]\titers: 11900, epoch: 1 | loss: 0.2805452\n",
      "\tspeed: 0.0476s/iter; left time: 138.8426s\n",
      "11999it [09:08, 20.86it/s]\titers: 12000, epoch: 1 | loss: 0.6049389\n",
      "\tspeed: 0.0509s/iter; left time: 143.2921s\n",
      "12098it [09:13, 23.97it/s]\titers: 12100, epoch: 1 | loss: 0.2734621\n",
      "\tspeed: 0.0430s/iter; left time: 116.7595s\n",
      "12197it [09:17, 22.81it/s]\titers: 12200, epoch: 1 | loss: 0.1548900\n",
      "\tspeed: 0.0418s/iter; left time: 109.3110s\n",
      "12299it [09:21, 24.65it/s]\titers: 12300, epoch: 1 | loss: 0.1988429\n",
      "\tspeed: 0.0426s/iter; left time: 107.2338s\n",
      "12397it [09:26, 23.36it/s]\titers: 12400, epoch: 1 | loss: 0.5242033\n",
      "\tspeed: 0.0455s/iter; left time: 110.0208s\n",
      "12499it [09:31, 19.03it/s]\titers: 12500, epoch: 1 | loss: 0.5833334\n",
      "\tspeed: 0.0505s/iter; left time: 117.0290s\n",
      "12597it [09:36, 18.94it/s]\titers: 12600, epoch: 1 | loss: 0.5361513\n",
      "\tspeed: 0.0496s/iter; left time: 109.8900s\n",
      "12699it [09:41, 23.60it/s]\titers: 12700, epoch: 1 | loss: 0.2606279\n",
      "\tspeed: 0.0490s/iter; left time: 103.6389s\n",
      "12798it [09:45, 22.30it/s]\titers: 12800, epoch: 1 | loss: 0.2270386\n",
      "\tspeed: 0.0425s/iter; left time: 85.8109s\n",
      "12897it [09:49, 23.90it/s]\titers: 12900, epoch: 1 | loss: 0.2341306\n",
      "\tspeed: 0.0416s/iter; left time: 79.7304s\n",
      "12999it [09:53, 24.86it/s]\titers: 13000, epoch: 1 | loss: 0.2403391\n",
      "\tspeed: 0.0408s/iter; left time: 74.0596s\n",
      "13098it [09:57, 23.04it/s]\titers: 13100, epoch: 1 | loss: 0.1335177\n",
      "\tspeed: 0.0425s/iter; left time: 72.9307s\n",
      "13197it [10:02, 21.70it/s]\titers: 13200, epoch: 1 | loss: 0.4476753\n",
      "\tspeed: 0.0467s/iter; left time: 75.5831s\n",
      "13299it [10:08, 15.86it/s]\titers: 13300, epoch: 1 | loss: 0.8063035\n",
      "\tspeed: 0.0554s/iter; left time: 83.9942s\n",
      "13398it [10:13, 22.03it/s]\titers: 13400, epoch: 1 | loss: 0.4766203\n",
      "\tspeed: 0.0507s/iter; left time: 71.7805s\n",
      "13497it [10:17, 24.54it/s]\titers: 13500, epoch: 1 | loss: 0.3440460\n",
      "\tspeed: 0.0434s/iter; left time: 57.1604s\n",
      "13599it [10:21, 24.46it/s]\titers: 13600, epoch: 1 | loss: 0.1265269\n",
      "\tspeed: 0.0414s/iter; left time: 50.4377s\n",
      "13698it [10:25, 23.79it/s]\titers: 13700, epoch: 1 | loss: 0.5715402\n",
      "\tspeed: 0.0416s/iter; left time: 46.4323s\n",
      "13797it [10:29, 24.59it/s]\titers: 13800, epoch: 1 | loss: 0.3003829\n",
      "\tspeed: 0.0416s/iter; left time: 42.3184s\n",
      "13899it [10:34, 23.98it/s]\titers: 13900, epoch: 1 | loss: 0.2409656\n",
      "\tspeed: 0.0414s/iter; left time: 37.9722s\n",
      "13999it [10:38, 19.56it/s]\titers: 14000, epoch: 1 | loss: 0.2682968\n",
      "\tspeed: 0.0480s/iter; left time: 39.1902s\n",
      "14098it [10:44, 17.36it/s]\titers: 14100, epoch: 1 | loss: 0.2582831\n",
      "\tspeed: 0.0592s/iter; left time: 42.4769s\n",
      "14199it [10:49, 23.86it/s]\titers: 14200, epoch: 1 | loss: 0.2974715\n",
      "\tspeed: 0.0433s/iter; left time: 26.7237s\n",
      "14298it [10:53, 23.48it/s]\titers: 14300, epoch: 1 | loss: 0.2119940\n",
      "\tspeed: 0.0416s/iter; left time: 21.4869s\n",
      "14397it [10:57, 24.24it/s]\titers: 14400, epoch: 1 | loss: 0.1829525\n",
      "\tspeed: 0.0410s/iter; left time: 17.1089s\n",
      "14499it [11:01, 25.40it/s]\titers: 14500, epoch: 1 | loss: 0.2604047\n",
      "\tspeed: 0.0415s/iter; left time: 13.1687s\n",
      "14598it [11:05, 24.66it/s]\titers: 14600, epoch: 1 | loss: 0.5738366\n",
      "\tspeed: 0.0406s/iter; left time: 8.8203s\n",
      "14697it [11:09, 22.50it/s]\titers: 14700, epoch: 1 | loss: 0.3689606\n",
      "\tspeed: 0.0447s/iter; left time: 5.2309s\n",
      "14798it [11:15, 18.25it/s]\titers: 14800, epoch: 1 | loss: 0.3793266\n",
      "\tspeed: 0.0532s/iter; left time: 0.9048s\n",
      "14816it [11:16, 21.90it/s]\n",
      "Epoch: 1 cost time: 676.4159572124481\n",
      "3204it [01:17, 41.38it/s]\n",
      "3192it [01:16, 41.59it/s]\n",
      "Epoch: 1 | Train Loss: 0.4955682 Vali Loss: 0.4804414 Test Loss: 0.6038412 MAE Loss: 0.4934117\n",
      "Validation loss decreased (inf --> 0.480441).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "3192it [01:17, 40.98it/s]\n",
      "mse:0.6038412146199084, mae:0.4934116760852343\n",
      "train_losses [0.49556824458726795]\n",
      "val_losses [0.48044138019451044]\n",
      "Total time: 15.689397823810577 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 1 epoch run_main_copy_copy.py with gradient accumulation (with additional steps)\n",
    "# There is also scheduler step after each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 01:14:13,824] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 01:14:14,779] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 01:14:14,779] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 01:14:14,780] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 01:14:15,666] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 01:14:15,667] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 01:14:16,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 01:14:16,317] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 01:14:16,317] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 01:14:16,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 01:14:16,318] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 01:14:16,318] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 01:14:16,318] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 01:14:16,318] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 01:14:16,318] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 01:14:16,318] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 01:14:16,724] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 01:14:16,725] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:14:16,725] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.94 GB, percent = 21.2%\n",
      "[2024-05-20 01:14:16,885] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 01:14:16,886] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:14:16,887] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.96 GB, percent = 21.2%\n",
      "[2024-05-20 01:14:16,887] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 01:14:17,048] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 01:14:17,049] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:14:17,050] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 160.23 GB, percent = 21.2%\n",
      "[2024-05-20 01:14:17,050] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 01:14:17,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 01:14:17,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 01:14:17,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 01:14:17,051] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0e80cc6050>\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 01:14:17,052] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 01:14:17,053] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 01:14:17,054] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 01:14:17,055] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "14816it [11:45, 21.01it/s]\n",
      "Epoch: 1 cost time: 705.1928253173828\n",
      "3204it [01:52, 28.36it/s]\n",
      "3192it [01:53, 28.05it/s]\n",
      "Epoch: 1 | Train Loss: 0.7882620 Vali Loss: 1.1285441 Test Loss: 1.4325190 MAE Loss: 0.9197873\n",
      "lr = 0.0000000220\n",
      "Updating learning rate to 2.1984296638666193e-08\n",
      "Total time: 16.17130666176478 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main_copy_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 50 epochs run_main.py with gradient accumulation (without additional steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 01:40:49,260] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 01:40:50,224] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 01:40:50,224] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 01:40:50,224] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 01:40:51,125] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 01:40:51,125] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 01:40:52,236] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 01:40:52,236] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 01:40:52,236] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 01:40:52,237] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 01:40:52,237] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 01:40:52,237] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 01:40:52,237] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 01:40:52,238] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 01:40:52,238] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 01:40:52,238] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 01:40:52,596] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 01:40:52,597] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:40:52,597] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 148.08 GB, percent = 19.6%\n",
      "[2024-05-20 01:40:52,739] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 01:40:52,740] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:40:52,740] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 148.11 GB, percent = 19.6%\n",
      "[2024-05-20 01:40:52,740] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 01:40:52,883] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 01:40:52,884] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 01:40:52,884] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 148.11 GB, percent = 19.6%\n",
      "[2024-05-20 01:40:52,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 01:40:52,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 01:40:52,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 01:40:52,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 01:40:52,886] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2be00f3bd0>\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 01:40:52,887] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 01:40:52,888] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 01:40:52,889] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "98it [00:07, 12.85it/s]\titers: 100, epoch: 1 | loss: 1.2100023\n",
      "\tspeed: 0.1121s/iter; left time: 83018.8290s\n",
      "198it [00:13, 17.48it/s]\titers: 200, epoch: 1 | loss: 0.4719745\n",
      "\tspeed: 0.0633s/iter; left time: 46883.0462s\n",
      "298it [00:20, 20.64it/s]\titers: 300, epoch: 1 | loss: 0.8270715\n",
      "\tspeed: 0.0734s/iter; left time: 54321.9685s\n",
      "398it [00:26, 12.22it/s]\titers: 400, epoch: 1 | loss: 0.8933063\n",
      "\tspeed: 0.0595s/iter; left time: 44036.2197s\n",
      "499it [00:32, 19.95it/s]\titers: 500, epoch: 1 | loss: 1.1096756\n",
      "\tspeed: 0.0568s/iter; left time: 42029.5339s\n",
      "598it [00:39, 12.85it/s]\titers: 600, epoch: 1 | loss: 1.0732007\n",
      "\tspeed: 0.0686s/iter; left time: 50798.1798s\n",
      "698it [00:44, 13.54it/s]\titers: 700, epoch: 1 | loss: 0.6724876\n",
      "\tspeed: 0.0538s/iter; left time: 39849.4504s\n",
      "797it [00:50, 23.16it/s]\titers: 800, epoch: 1 | loss: 0.4488840\n",
      "\tspeed: 0.0627s/iter; left time: 46418.9854s\n",
      "899it [00:56, 15.46it/s]\titers: 900, epoch: 1 | loss: 0.4415597\n",
      "\tspeed: 0.0606s/iter; left time: 44854.0919s\n",
      "999it [01:03, 13.94it/s]\titers: 1000, epoch: 1 | loss: 0.5833146\n",
      "\tspeed: 0.0678s/iter; left time: 50188.1186s\n",
      "1099it [01:09, 16.26it/s]\titers: 1100, epoch: 1 | loss: 0.4452401\n",
      "\tspeed: 0.0576s/iter; left time: 42594.6335s\n",
      "1199it [01:16, 13.67it/s]\titers: 1200, epoch: 1 | loss: 0.4246193\n",
      "\tspeed: 0.0660s/iter; left time: 48813.3638s\n",
      "1298it [01:22, 14.78it/s]\titers: 1300, epoch: 1 | loss: 0.8128982\n",
      "\tspeed: 0.0626s/iter; left time: 46282.6035s\n",
      "1398it [01:29, 17.49it/s]\titers: 1400, epoch: 1 | loss: 0.5363386\n",
      "\tspeed: 0.0731s/iter; left time: 54081.1123s\n",
      "1499it [01:35, 12.92it/s]\titers: 1500, epoch: 1 | loss: 0.8632331\n",
      "\tspeed: 0.0597s/iter; left time: 44102.6213s\n",
      "1598it [01:41, 18.74it/s]\titers: 1600, epoch: 1 | loss: 0.4425161\n",
      "\tspeed: 0.0610s/iter; left time: 45119.6084s\n",
      "1698it [01:49, 18.06it/s]\titers: 1700, epoch: 1 | loss: 0.9049737\n",
      "\tspeed: 0.0731s/iter; left time: 53997.5948s\n",
      "1798it [01:55, 12.65it/s]\titers: 1800, epoch: 1 | loss: 0.6961403\n",
      "\tspeed: 0.0609s/iter; left time: 44997.1946s\n",
      "1898it [02:01, 20.14it/s]\titers: 1900, epoch: 1 | loss: 0.7065306\n",
      "\tspeed: 0.0590s/iter; left time: 43589.7690s\n",
      "1998it [02:07, 16.82it/s]\titers: 2000, epoch: 1 | loss: 0.2669930\n",
      "\tspeed: 0.0695s/iter; left time: 51343.0519s\n",
      "2099it [02:13, 13.14it/s]\titers: 2100, epoch: 1 | loss: 0.4881725\n",
      "\tspeed: 0.0538s/iter; left time: 39738.4267s\n",
      "2199it [02:19, 20.51it/s]\titers: 2200, epoch: 1 | loss: 0.8746573\n",
      "\tspeed: 0.0644s/iter; left time: 47586.2651s\n",
      "2299it [02:25, 13.86it/s]\titers: 2300, epoch: 1 | loss: 1.1616392\n",
      "\tspeed: 0.0613s/iter; left time: 45289.9027s\n",
      "2399it [02:30, 20.61it/s]\titers: 2400, epoch: 1 | loss: 0.2961538\n",
      "\tspeed: 0.0487s/iter; left time: 35996.9801s\n",
      "2499it [02:37, 18.43it/s]\titers: 2500, epoch: 1 | loss: 0.4981700\n",
      "\tspeed: 0.0651s/iter; left time: 48084.5286s\n",
      "2599it [02:44, 17.51it/s]\titers: 2600, epoch: 1 | loss: 1.0616041\n",
      "\tspeed: 0.0694s/iter; left time: 51237.3486s\n",
      "2699it [02:50, 16.53it/s]\titers: 2700, epoch: 1 | loss: 0.9184409\n",
      "\tspeed: 0.0647s/iter; left time: 47723.9342s\n",
      "2799it [02:57, 13.09it/s]\titers: 2800, epoch: 1 | loss: 0.7068489\n",
      "\tspeed: 0.0671s/iter; left time: 49508.2351s\n",
      "2899it [03:03, 20.14it/s]\titers: 2900, epoch: 1 | loss: 0.5155199\n",
      "\tspeed: 0.0557s/iter; left time: 41093.6557s\n",
      "2999it [03:10, 17.50it/s]\titers: 3000, epoch: 1 | loss: 0.3697930\n",
      "\tspeed: 0.0715s/iter; left time: 52717.1953s\n",
      "3098it [03:16, 12.82it/s]\titers: 3100, epoch: 1 | loss: 1.7031286\n",
      "\tspeed: 0.0651s/iter; left time: 48005.5579s\n",
      "3198it [03:22, 12.13it/s]\titers: 3200, epoch: 1 | loss: 0.3750121\n",
      "\tspeed: 0.0609s/iter; left time: 44916.5818s\n",
      "3298it [03:30, 18.47it/s]\titers: 3300, epoch: 1 | loss: 0.1839736\n",
      "\tspeed: 0.0755s/iter; left time: 55690.0377s\n",
      "3399it [03:36, 12.05it/s]\titers: 3400, epoch: 1 | loss: 1.0785438\n",
      "\tspeed: 0.0647s/iter; left time: 47729.2913s\n",
      "3498it [03:43, 21.95it/s]\titers: 3500, epoch: 1 | loss: 0.6788548\n",
      "\tspeed: 0.0642s/iter; left time: 47344.3789s\n",
      "3599it [03:50, 12.28it/s]\titers: 3600, epoch: 1 | loss: 0.8473063\n",
      "\tspeed: 0.0776s/iter; left time: 57203.7182s\n",
      "3698it [03:56, 13.16it/s]\titers: 3700, epoch: 1 | loss: 0.3364809\n",
      "\tspeed: 0.0598s/iter; left time: 44064.7619s\n",
      "3798it [04:03, 18.45it/s]\titers: 3800, epoch: 1 | loss: 0.4078275\n",
      "\tspeed: 0.0673s/iter; left time: 49635.5827s\n",
      "3898it [04:10, 13.88it/s]\titers: 3900, epoch: 1 | loss: 0.6516296\n",
      "\tspeed: 0.0716s/iter; left time: 52749.5240s\n",
      "3999it [04:16, 14.10it/s]\titers: 4000, epoch: 1 | loss: 0.6825324\n",
      "\tspeed: 0.0571s/iter; left time: 42071.1705s\n",
      "4099it [04:23, 18.84it/s]\titers: 4100, epoch: 1 | loss: 0.4433888\n",
      "\tspeed: 0.0661s/iter; left time: 48732.5710s\n",
      "4199it [04:30, 11.52it/s]\titers: 4200, epoch: 1 | loss: 0.9938721\n",
      "\tspeed: 0.0754s/iter; left time: 55546.3834s\n",
      "4299it [04:36, 12.98it/s]\titers: 4300, epoch: 1 | loss: 0.3262190\n",
      "\tspeed: 0.0617s/iter; left time: 45454.7200s\n",
      "4399it [04:43, 17.42it/s]\titers: 4400, epoch: 1 | loss: 0.4855730\n",
      "\tspeed: 0.0631s/iter; left time: 46477.6951s\n",
      "4499it [04:50, 20.05it/s]\titers: 4500, epoch: 1 | loss: 0.1956166\n",
      "\tspeed: 0.0704s/iter; left time: 51813.8239s\n",
      "4598it [04:56, 12.24it/s]\titers: 4600, epoch: 1 | loss: 0.2855468\n",
      "\tspeed: 0.0649s/iter; left time: 47750.0394s\n",
      "4697it [05:02, 20.96it/s]\titers: 4700, epoch: 1 | loss: 1.2788696\n",
      "\tspeed: 0.0611s/iter; left time: 44976.5513s\n",
      "4799it [05:09, 22.18it/s]\titers: 4800, epoch: 1 | loss: 0.3046062\n",
      "\tspeed: 0.0675s/iter; left time: 49664.9748s\n",
      "4898it [05:16, 13.13it/s]\titers: 4900, epoch: 1 | loss: 0.4774517\n",
      "\tspeed: 0.0700s/iter; left time: 51480.4692s\n",
      "4999it [05:22, 21.01it/s]\titers: 5000, epoch: 1 | loss: 0.5055078\n",
      "\tspeed: 0.0550s/iter; left time: 40451.8437s\n",
      "5099it [05:30, 16.36it/s]\titers: 5100, epoch: 1 | loss: 0.7752290\n",
      "\tspeed: 0.0828s/iter; left time: 60900.3579s\n",
      "5199it [05:37, 12.33it/s]\titers: 5200, epoch: 1 | loss: 0.3553796\n",
      "\tspeed: 0.0710s/iter; left time: 52254.6351s\n",
      "5299it [05:43, 18.52it/s]\titers: 5300, epoch: 1 | loss: 1.2170597\n",
      "\tspeed: 0.0600s/iter; left time: 44130.1950s\n",
      "5399it [05:50, 19.10it/s]\titers: 5400, epoch: 1 | loss: 0.3382396\n",
      "\tspeed: 0.0689s/iter; left time: 50667.8480s\n",
      "5499it [05:56, 13.20it/s]\titers: 5500, epoch: 1 | loss: 0.1891921\n",
      "\tspeed: 0.0582s/iter; left time: 42804.9013s\n",
      "5598it [06:03, 16.01it/s]\titers: 5600, epoch: 1 | loss: 0.2955888\n",
      "\tspeed: 0.0705s/iter; left time: 51795.6858s\n",
      "5698it [06:09, 18.24it/s]\titers: 5700, epoch: 1 | loss: 0.2907146\n",
      "\tspeed: 0.0661s/iter; left time: 48615.1554s\n",
      "5799it [06:16, 12.06it/s]\titers: 5800, epoch: 1 | loss: 0.4387524\n",
      "\tspeed: 0.0641s/iter; left time: 47087.1844s\n",
      "5898it [06:22, 17.85it/s]\titers: 5900, epoch: 1 | loss: 0.2277153\n",
      "\tspeed: 0.0631s/iter; left time: 46374.4726s\n",
      "5997it [06:29, 16.86it/s]\titers: 6000, epoch: 1 | loss: 0.1939872\n",
      "\tspeed: 0.0686s/iter; left time: 50416.6644s\n",
      "6099it [06:36, 17.51it/s]\titers: 6100, epoch: 1 | loss: 0.2317864\n",
      "\tspeed: 0.0687s/iter; left time: 50494.0915s\n",
      "6198it [06:43, 12.34it/s]\titers: 6200, epoch: 1 | loss: 0.5303420\n",
      "\tspeed: 0.0700s/iter; left time: 51392.2940s\n",
      "6299it [06:49, 19.45it/s]\titers: 6300, epoch: 1 | loss: 0.4089229\n",
      "\tspeed: 0.0587s/iter; left time: 43134.3028s\n",
      "6399it [06:56, 20.65it/s]\titers: 6400, epoch: 1 | loss: 0.1928583\n",
      "\tspeed: 0.0701s/iter; left time: 51448.5869s\n",
      "6498it [07:03, 11.85it/s]\titers: 6500, epoch: 1 | loss: 0.2946931\n",
      "\tspeed: 0.0714s/iter; left time: 52397.0104s\n",
      "6599it [07:09, 12.21it/s]\titers: 6600, epoch: 1 | loss: 0.6640747\n",
      "\tspeed: 0.0627s/iter; left time: 46064.5159s\n",
      "6697it [07:16, 24.43it/s]\titers: 6700, epoch: 1 | loss: 0.2682841\n",
      "\tspeed: 0.0691s/iter; left time: 50691.1388s\n",
      "6799it [07:22, 11.76it/s]\titers: 6800, epoch: 1 | loss: 0.2828879\n",
      "\tspeed: 0.0654s/iter; left time: 47984.7722s\n",
      "6898it [07:28, 19.39it/s]\titers: 6900, epoch: 1 | loss: 0.5458733\n",
      "\tspeed: 0.0578s/iter; left time: 42428.2159s\n",
      "6999it [07:36, 18.56it/s]\titers: 7000, epoch: 1 | loss: 0.2802522\n",
      "\tspeed: 0.0721s/iter; left time: 52879.0059s\n",
      "7098it [07:41, 12.57it/s]\titers: 7100, epoch: 1 | loss: 0.3009359\n",
      "\tspeed: 0.0522s/iter; left time: 38276.1439s\n",
      "7198it [07:47, 20.05it/s]\titers: 7200, epoch: 1 | loss: 0.2249059\n",
      "\tspeed: 0.0643s/iter; left time: 47200.0704s\n",
      "7299it [07:53, 20.17it/s]\titers: 7300, epoch: 1 | loss: 0.7087804\n",
      "\tspeed: 0.0620s/iter; left time: 45449.5939s\n",
      "7398it [07:59, 12.89it/s]\titers: 7400, epoch: 1 | loss: 0.4487431\n",
      "\tspeed: 0.0603s/iter; left time: 44247.3622s\n",
      "7498it [08:06, 19.94it/s]\titers: 7500, epoch: 1 | loss: 0.3811559\n",
      "\tspeed: 0.0639s/iter; left time: 46885.4026s\n",
      "7599it [08:12, 17.56it/s]\titers: 7600, epoch: 1 | loss: 0.4741640\n",
      "\tspeed: 0.0652s/iter; left time: 47830.6344s\n",
      "7699it [08:19, 22.43it/s]\titers: 7700, epoch: 1 | loss: 0.2948685\n",
      "\tspeed: 0.0671s/iter; left time: 49220.6405s\n",
      "7798it [08:26, 11.99it/s]\titers: 7800, epoch: 1 | loss: 0.1803007\n",
      "\tspeed: 0.0687s/iter; left time: 50324.5330s\n",
      "7898it [08:32, 19.67it/s]\titers: 7900, epoch: 1 | loss: 0.3735719\n",
      "\tspeed: 0.0574s/iter; left time: 42094.0466s\n",
      "7997it [08:39, 20.83it/s]\titers: 8000, epoch: 1 | loss: 0.1715254\n",
      "\tspeed: 0.0709s/iter; left time: 51924.7114s\n",
      "8098it [08:45, 11.54it/s]\titers: 8100, epoch: 1 | loss: 0.1723867\n",
      "\tspeed: 0.0672s/iter; left time: 49257.4308s\n",
      "8199it [08:51, 15.33it/s]\titers: 8200, epoch: 1 | loss: 0.8741489\n",
      "\tspeed: 0.0590s/iter; left time: 43233.2794s\n",
      "8298it [08:58, 18.70it/s]\titers: 8300, epoch: 1 | loss: 0.5079411\n",
      "\tspeed: 0.0711s/iter; left time: 52099.7463s\n",
      "8399it [09:04, 12.02it/s]\titers: 8400, epoch: 1 | loss: 0.4221446\n",
      "\tspeed: 0.0605s/iter; left time: 44315.1477s\n",
      "8498it [09:11, 19.24it/s]\titers: 8500, epoch: 1 | loss: 0.5190887\n",
      "\tspeed: 0.0623s/iter; left time: 45640.4334s\n",
      "8599it [09:18, 13.94it/s]\titers: 8600, epoch: 1 | loss: 0.5163773\n",
      "\tspeed: 0.0682s/iter; left time: 49901.1936s\n",
      "8698it [09:23, 14.51it/s]\titers: 8700, epoch: 1 | loss: 0.2107243\n",
      "\tspeed: 0.0512s/iter; left time: 37510.5936s\n",
      "8798it [09:29, 18.36it/s]\titers: 8800, epoch: 1 | loss: 1.8230904\n",
      "\tspeed: 0.0670s/iter; left time: 49019.2380s\n",
      "8899it [09:36, 16.61it/s]\titers: 8900, epoch: 1 | loss: 0.7863830\n",
      "\tspeed: 0.0640s/iter; left time: 46839.3142s\n",
      "8998it [09:42, 12.60it/s]\titers: 9000, epoch: 1 | loss: 0.1825612\n",
      "\tspeed: 0.0619s/iter; left time: 45269.6329s\n",
      "9098it [09:48, 14.98it/s]\titers: 9100, epoch: 1 | loss: 0.1264677\n",
      "\tspeed: 0.0615s/iter; left time: 45032.6131s\n",
      "9199it [09:55, 14.26it/s]\titers: 9200, epoch: 1 | loss: 0.5377688\n",
      "\tspeed: 0.0678s/iter; left time: 49575.6335s\n",
      "9299it [10:01, 23.97it/s]\titers: 9300, epoch: 1 | loss: 0.8846996\n",
      "\tspeed: 0.0633s/iter; left time: 46284.0401s\n",
      "9398it [10:09, 17.22it/s]\titers: 9400, epoch: 1 | loss: 0.7158275\n",
      "\tspeed: 0.0766s/iter; left time: 56042.6122s\n",
      "9498it [10:14, 12.19it/s]\titers: 9500, epoch: 1 | loss: 0.2976035\n",
      "\tspeed: 0.0571s/iter; left time: 41748.4441s\n",
      "9598it [10:21, 16.97it/s]\titers: 9600, epoch: 1 | loss: 0.3770229\n",
      "\tspeed: 0.0653s/iter; left time: 47718.2350s\n",
      "9698it [10:28, 16.67it/s]\titers: 9700, epoch: 1 | loss: 0.4641332\n",
      "\tspeed: 0.0715s/iter; left time: 52303.0513s\n",
      "9798it [10:35, 12.69it/s]\titers: 9800, epoch: 1 | loss: 0.3670942\n",
      "\tspeed: 0.0634s/iter; left time: 46338.3293s\n",
      "9897it [10:41, 19.20it/s]\titers: 9900, epoch: 1 | loss: 0.4804549\n",
      "\tspeed: 0.0606s/iter; left time: 44293.5011s\n",
      "9999it [10:48, 16.45it/s]\titers: 10000, epoch: 1 | loss: 0.4358552\n",
      "\tspeed: 0.0711s/iter; left time: 51932.3373s\n",
      "10098it [10:54, 14.20it/s]\titers: 10100, epoch: 1 | loss: 0.2683017\n",
      "\tspeed: 0.0622s/iter; left time: 45429.6760s\n",
      "10199it [11:00, 20.27it/s]\titers: 10200, epoch: 1 | loss: 0.2550182\n",
      "\tspeed: 0.0641s/iter; left time: 46802.1966s\n",
      "10299it [11:07, 13.84it/s]\titers: 10300, epoch: 1 | loss: 0.3009215\n",
      "\tspeed: 0.0679s/iter; left time: 49584.0766s\n",
      "10398it [11:12, 15.76it/s]\titers: 10400, epoch: 1 | loss: 0.2636962\n",
      "\tspeed: 0.0507s/iter; left time: 37015.6227s\n",
      "10498it [11:18, 19.98it/s]\titers: 10500, epoch: 1 | loss: 0.3230118\n",
      "\tspeed: 0.0600s/iter; left time: 43840.5542s\n",
      "10597it [11:25, 16.90it/s]\titers: 10600, epoch: 1 | loss: 0.1425342\n",
      "\tspeed: 0.0715s/iter; left time: 52243.5955s\n",
      "10698it [11:32, 12.21it/s]\titers: 10700, epoch: 1 | loss: 0.0943355\n",
      "\tspeed: 0.0647s/iter; left time: 47272.8310s\n",
      "10798it [11:38, 15.65it/s]\titers: 10800, epoch: 1 | loss: 0.1555537\n",
      "\tspeed: 0.0658s/iter; left time: 48049.4439s\n",
      "10898it [11:45, 12.04it/s]\titers: 10900, epoch: 1 | loss: 0.4060164\n",
      "\tspeed: 0.0692s/iter; left time: 50518.2302s\n",
      "10999it [11:51, 18.77it/s]\titers: 11000, epoch: 1 | loss: 0.1792986\n",
      "\tspeed: 0.0550s/iter; left time: 40138.4808s\n",
      "11098it [11:58, 17.47it/s]\titers: 11100, epoch: 1 | loss: 0.1975928\n",
      "\tspeed: 0.0721s/iter; left time: 52602.2809s\n",
      "11198it [12:05, 12.94it/s]\titers: 11200, epoch: 1 | loss: 1.1800880\n",
      "\tspeed: 0.0695s/iter; left time: 50688.4519s\n",
      "11299it [12:10, 14.62it/s]\titers: 11300, epoch: 1 | loss: 0.5712709\n",
      "\tspeed: 0.0547s/iter; left time: 39875.4123s\n",
      "11399it [12:17, 18.95it/s]\titers: 11400, epoch: 1 | loss: 0.1855741\n",
      "\tspeed: 0.0672s/iter; left time: 49049.9993s\n",
      "11498it [12:24, 12.67it/s]\titers: 11500, epoch: 1 | loss: 0.1726841\n",
      "\tspeed: 0.0637s/iter; left time: 46485.0725s\n",
      "11598it [12:29, 17.38it/s]\titers: 11600, epoch: 1 | loss: 0.1752069\n",
      "\tspeed: 0.0577s/iter; left time: 42047.8822s\n",
      "11699it [12:37, 17.26it/s]\titers: 11700, epoch: 1 | loss: 0.4001184\n",
      "\tspeed: 0.0743s/iter; left time: 54203.4701s\n",
      "11798it [12:43, 14.78it/s]\titers: 11800, epoch: 1 | loss: 0.2365575\n",
      "\tspeed: 0.0621s/iter; left time: 45245.5413s\n",
      "11899it [12:49, 14.65it/s]\titers: 11900, epoch: 1 | loss: 0.2805452\n",
      "\tspeed: 0.0602s/iter; left time: 43902.1608s\n",
      "11998it [12:55, 15.04it/s]\titers: 12000, epoch: 1 | loss: 0.6049389\n",
      "\tspeed: 0.0644s/iter; left time: 46970.3517s\n",
      "12099it [13:02, 17.40it/s]\titers: 12100, epoch: 1 | loss: 0.2734621\n",
      "\tspeed: 0.0667s/iter; left time: 48625.8831s\n",
      "12198it [13:08, 14.72it/s]\titers: 12200, epoch: 1 | loss: 0.1548900\n",
      "\tspeed: 0.0614s/iter; left time: 44724.6042s\n",
      "12298it [13:14, 14.93it/s]\titers: 12300, epoch: 1 | loss: 0.1988429\n",
      "\tspeed: 0.0540s/iter; left time: 39305.5450s\n",
      "12398it [13:20, 19.17it/s]\titers: 12400, epoch: 1 | loss: 0.5242033\n",
      "\tspeed: 0.0601s/iter; left time: 43793.7628s\n",
      "12499it [13:27, 12.32it/s]\titers: 12500, epoch: 1 | loss: 0.5833334\n",
      "\tspeed: 0.0697s/iter; left time: 50744.4796s\n",
      "12598it [13:33, 11.93it/s]\titers: 12600, epoch: 1 | loss: 0.5361513\n",
      "\tspeed: 0.0602s/iter; left time: 43834.3562s\n",
      "12698it [13:39, 14.17it/s]\titers: 12700, epoch: 1 | loss: 0.2606279\n",
      "\tspeed: 0.0682s/iter; left time: 49621.6980s\n",
      "12799it [13:47, 16.53it/s]\titers: 12800, epoch: 1 | loss: 0.2270386\n",
      "\tspeed: 0.0780s/iter; left time: 56766.0438s\n",
      "12898it [13:53, 12.76it/s]\titers: 12900, epoch: 1 | loss: 0.2341306\n",
      "\tspeed: 0.0618s/iter; left time: 44959.7413s\n",
      "12999it [14:00, 19.56it/s]\titers: 13000, epoch: 1 | loss: 0.2403391\n",
      "\tspeed: 0.0671s/iter; left time: 48837.9686s\n",
      "13099it [14:08, 11.82it/s]\titers: 13100, epoch: 1 | loss: 0.1335177\n",
      "\tspeed: 0.0745s/iter; left time: 54233.6927s\n",
      "13198it [14:14, 12.46it/s]\titers: 13200, epoch: 1 | loss: 0.4476753\n",
      "\tspeed: 0.0643s/iter; left time: 46755.6377s\n",
      "13299it [14:21, 19.51it/s]\titers: 13300, epoch: 1 | loss: 0.8063035\n",
      "\tspeed: 0.0690s/iter; left time: 50205.9144s\n",
      "13398it [14:28, 12.19it/s]\titers: 13400, epoch: 1 | loss: 0.4766203\n",
      "\tspeed: 0.0680s/iter; left time: 49499.2032s\n",
      "13499it [14:34, 15.01it/s]\titers: 13500, epoch: 1 | loss: 0.3440460\n",
      "\tspeed: 0.0597s/iter; left time: 43385.1860s\n",
      "13598it [14:40, 17.13it/s]\titers: 13600, epoch: 1 | loss: 0.1265269\n",
      "\tspeed: 0.0681s/iter; left time: 49532.4280s\n",
      "13698it [14:48, 12.15it/s]\titers: 13700, epoch: 1 | loss: 0.5715402\n",
      "\tspeed: 0.0764s/iter; left time: 55543.6315s\n",
      "13798it [14:54, 14.25it/s]\titers: 13800, epoch: 1 | loss: 0.3003829\n",
      "\tspeed: 0.0615s/iter; left time: 44701.4970s\n",
      "13897it [15:01, 19.24it/s]\titers: 13900, epoch: 1 | loss: 0.2409656\n",
      "\tspeed: 0.0643s/iter; left time: 46704.5605s\n",
      "13998it [15:07, 25.76it/s]\titers: 14000, epoch: 1 | loss: 0.2682968\n",
      "\tspeed: 0.0673s/iter; left time: 48880.7924s\n",
      "14099it [15:14, 12.89it/s]\titers: 14100, epoch: 1 | loss: 0.2582831\n",
      "\tspeed: 0.0683s/iter; left time: 49640.2009s\n",
      "14198it [15:21, 13.42it/s]\titers: 14200, epoch: 1 | loss: 0.2974715\n",
      "\tspeed: 0.0639s/iter; left time: 46456.7046s\n",
      "14298it [15:27, 23.10it/s]\titers: 14300, epoch: 1 | loss: 0.2119940\n",
      "\tspeed: 0.0628s/iter; left time: 45617.0206s\n",
      "14398it [15:34, 12.16it/s]\titers: 14400, epoch: 1 | loss: 0.1829525\n",
      "\tspeed: 0.0737s/iter; left time: 53542.3392s\n",
      "14498it [15:40, 14.30it/s]\titers: 14500, epoch: 1 | loss: 0.2604047\n",
      "\tspeed: 0.0545s/iter; left time: 39587.9106s\n",
      "14599it [15:47, 17.42it/s]\titers: 14600, epoch: 1 | loss: 0.5738366\n",
      "\tspeed: 0.0739s/iter; left time: 53683.9755s\n",
      "14699it [15:55, 12.35it/s]\titers: 14700, epoch: 1 | loss: 0.3689606\n",
      "\tspeed: 0.0734s/iter; left time: 53280.2168s\n",
      "14798it [16:00, 24.07it/s]\titers: 14800, epoch: 1 | loss: 0.3793266\n",
      "\tspeed: 0.0511s/iter; left time: 37088.7547s\n",
      "14816it [16:01, 15.42it/s]\n",
      "Epoch: 1 cost time: 961.0720410346985\n",
      "3204it [01:49, 29.13it/s]\n",
      "3192it [01:49, 29.07it/s]\n",
      "Epoch: 1 | Train Loss: 0.4955682 Vali Loss: 0.4804414 Test Loss: 0.6038412 MAE Loss: 0.4934117\n",
      "Validation loss decreased (inf --> 0.480441).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:07, 18.34it/s]\titers: 100, epoch: 2 | loss: 0.4087486\n",
      "\tspeed: 2.3455s/iter; left time: 1702553.0252s\n",
      "199it [00:12, 15.09it/s]\titers: 200, epoch: 2 | loss: 0.2096149\n",
      "\tspeed: 0.0560s/iter; left time: 40668.7387s\n",
      "299it [00:19, 13.33it/s]\titers: 300, epoch: 2 | loss: 0.6823894\n",
      "\tspeed: 0.0692s/iter; left time: 50241.8879s\n",
      "399it [00:26, 12.61it/s]\titers: 400, epoch: 2 | loss: 0.4070836\n",
      "\tspeed: 0.0703s/iter; left time: 51034.5033s\n",
      "499it [00:33, 19.26it/s]\titers: 500, epoch: 2 | loss: 0.2560939\n",
      "\tspeed: 0.0631s/iter; left time: 45762.3456s\n",
      "599it [00:40, 13.57it/s]\titers: 600, epoch: 2 | loss: 0.2489785\n",
      "\tspeed: 0.0700s/iter; left time: 50785.8722s\n",
      "698it [00:46, 12.58it/s]\titers: 700, epoch: 2 | loss: 0.2296976\n",
      "\tspeed: 0.0589s/iter; left time: 42747.3092s\n",
      "798it [00:52, 18.54it/s]\titers: 800, epoch: 2 | loss: 0.3975549\n",
      "\tspeed: 0.0642s/iter; left time: 46587.1243s\n",
      "899it [00:59, 17.06it/s]\titers: 900, epoch: 2 | loss: 0.4848240\n",
      "\tspeed: 0.0736s/iter; left time: 53354.9908s\n",
      "999it [01:05, 12.78it/s]\titers: 1000, epoch: 2 | loss: 0.1795153\n",
      "\tspeed: 0.0521s/iter; left time: 37775.6598s\n",
      "1098it [01:11, 19.99it/s]\titers: 1100, epoch: 2 | loss: 0.1902396\n",
      "\tspeed: 0.0647s/iter; left time: 46867.2158s\n",
      "1199it [01:17, 12.14it/s]\titers: 1200, epoch: 2 | loss: 0.4005301\n",
      "\tspeed: 0.0636s/iter; left time: 46072.0759s\n",
      "1298it [01:23, 18.84it/s]\titers: 1300, epoch: 2 | loss: 0.4403698\n",
      "\tspeed: 0.0576s/iter; left time: 41721.0482s\n",
      "1399it [01:31, 17.64it/s]\titers: 1400, epoch: 2 | loss: 0.1817827\n",
      "\tspeed: 0.0727s/iter; left time: 52661.9991s\n",
      "1498it [01:36, 15.71it/s]\titers: 1500, epoch: 2 | loss: 0.2190758\n",
      "\tspeed: 0.0516s/iter; left time: 37409.0029s\n",
      "1598it [01:41, 20.90it/s]\titers: 1600, epoch: 2 | loss: 0.2425815\n",
      "\tspeed: 0.0539s/iter; left time: 39026.1334s\n",
      "1699it [01:48, 23.21it/s]\titers: 1700, epoch: 2 | loss: 0.2168809\n",
      "\tspeed: 0.0684s/iter; left time: 49557.9213s\n",
      "1799it [01:54, 12.68it/s]\titers: 1800, epoch: 2 | loss: 0.1285856\n",
      "\tspeed: 0.0636s/iter; left time: 46023.2743s\n",
      "1898it [02:00, 12.70it/s]\titers: 1900, epoch: 2 | loss: 0.7902218\n",
      "\tspeed: 0.0586s/iter; left time: 42395.6275s\n",
      "1999it [02:07, 12.06it/s]\titers: 2000, epoch: 2 | loss: 0.6439389\n",
      "\tspeed: 0.0680s/iter; left time: 49246.8668s\n",
      "2097it [02:12, 22.04it/s]\titers: 2100, epoch: 2 | loss: 0.4022671\n",
      "\tspeed: 0.0555s/iter; left time: 40184.8316s\n",
      "2199it [02:19, 18.41it/s]\titers: 2200, epoch: 2 | loss: 0.0857176\n",
      "\tspeed: 0.0669s/iter; left time: 48435.3723s\n",
      "2299it [02:25, 13.77it/s]\titers: 2300, epoch: 2 | loss: 0.4685104\n",
      "\tspeed: 0.0591s/iter; left time: 42753.3669s\n",
      "2399it [02:31, 24.05it/s]\titers: 2400, epoch: 2 | loss: 0.2601773\n",
      "\tspeed: 0.0565s/iter; left time: 40878.1092s\n",
      "2499it [02:38, 18.45it/s]\titers: 2500, epoch: 2 | loss: 0.4417733\n",
      "\tspeed: 0.0723s/iter; left time: 52296.0067s\n",
      "2598it [02:44, 12.48it/s]\titers: 2600, epoch: 2 | loss: 0.5574515\n",
      "\tspeed: 0.0628s/iter; left time: 45393.4029s\n",
      "2698it [02:50, 20.05it/s]\titers: 2700, epoch: 2 | loss: 0.4352033\n",
      "\tspeed: 0.0590s/iter; left time: 42701.4534s\n",
      "2798it [02:57, 12.38it/s]\titers: 2800, epoch: 2 | loss: 0.2201878\n",
      "\tspeed: 0.0736s/iter; left time: 53247.1368s\n",
      "2898it [03:03, 13.82it/s]\titers: 2900, epoch: 2 | loss: 0.2412534\n",
      "\tspeed: 0.0530s/iter; left time: 38338.8359s\n",
      "2998it [03:09, 17.19it/s]\titers: 3000, epoch: 2 | loss: 0.7555633\n",
      "\tspeed: 0.0676s/iter; left time: 48905.5681s\n",
      "3099it [03:15, 22.45it/s]\titers: 3100, epoch: 2 | loss: 0.4107915\n",
      "\tspeed: 0.0593s/iter; left time: 42902.4626s\n",
      "3198it [03:22, 13.57it/s]\titers: 3200, epoch: 2 | loss: 0.3677379\n",
      "\tspeed: 0.0656s/iter; left time: 47444.2235s\n",
      "3298it [03:28, 14.11it/s]\titers: 3300, epoch: 2 | loss: 0.8528661\n",
      "\tspeed: 0.0559s/iter; left time: 40417.3663s\n",
      "3399it [03:34, 19.01it/s]\titers: 3400, epoch: 2 | loss: 0.2455551\n",
      "\tspeed: 0.0599s/iter; left time: 43247.8451s\n",
      "3498it [03:41, 16.69it/s]\titers: 3500, epoch: 2 | loss: 0.2114689\n",
      "\tspeed: 0.0698s/iter; left time: 50421.0850s\n",
      "3598it [03:47, 13.07it/s]\titers: 3600, epoch: 2 | loss: 0.2566910\n",
      "\tspeed: 0.0604s/iter; left time: 43640.8633s\n",
      "3697it [03:52, 22.22it/s]\titers: 3700, epoch: 2 | loss: 0.6274682\n",
      "\tspeed: 0.0557s/iter; left time: 40241.0364s\n",
      "3798it [03:59, 16.76it/s]\titers: 3800, epoch: 2 | loss: 0.2936935\n",
      "\tspeed: 0.0692s/iter; left time: 49995.9522s\n",
      "3899it [04:05, 13.04it/s]\titers: 3900, epoch: 2 | loss: 0.1358667\n",
      "\tspeed: 0.0595s/iter; left time: 42977.8581s\n",
      "3998it [04:12, 18.08it/s]\titers: 4000, epoch: 2 | loss: 0.3150377\n",
      "\tspeed: 0.0698s/iter; left time: 50379.0541s\n",
      "4098it [04:18, 13.25it/s]\titers: 4100, epoch: 2 | loss: 0.3238904\n",
      "\tspeed: 0.0622s/iter; left time: 44931.8606s\n",
      "4198it [04:24, 21.46it/s]\titers: 4200, epoch: 2 | loss: 0.3327637\n",
      "\tspeed: 0.0556s/iter; left time: 40097.5251s\n",
      "4299it [04:31, 14.07it/s]\titers: 4300, epoch: 2 | loss: 0.3811989\n",
      "\tspeed: 0.0742s/iter; left time: 53527.3235s\n",
      "4399it [04:36, 14.03it/s]\titers: 4400, epoch: 2 | loss: 0.5556164\n",
      "\tspeed: 0.0504s/iter; left time: 36348.0184s\n",
      "4498it [04:44, 19.16it/s]\titers: 4500, epoch: 2 | loss: 0.7829426\n",
      "\tspeed: 0.0731s/iter; left time: 52732.4838s\n",
      "4599it [04:50, 13.03it/s]\titers: 4600, epoch: 2 | loss: 0.1537062\n",
      "\tspeed: 0.0687s/iter; left time: 49576.2653s\n",
      "4697it [04:56, 20.41it/s]\titers: 4700, epoch: 2 | loss: 0.5796785\n",
      "\tspeed: 0.0570s/iter; left time: 41103.7372s\n",
      "4797it [05:03, 21.06it/s]\titers: 4800, epoch: 2 | loss: 0.1229288\n",
      "\tspeed: 0.0694s/iter; left time: 50034.2744s\n",
      "4898it [05:08, 14.02it/s]\titers: 4900, epoch: 2 | loss: 0.2861868\n",
      "\tspeed: 0.0532s/iter; left time: 38367.1783s\n",
      "4998it [05:15, 17.59it/s]\titers: 5000, epoch: 2 | loss: 0.1743478\n",
      "\tspeed: 0.0704s/iter; left time: 50791.9516s\n",
      "5097it [05:22, 18.32it/s]\titers: 5100, epoch: 2 | loss: 0.8171138\n",
      "\tspeed: 0.0660s/iter; left time: 47598.1093s\n",
      "5198it [05:28, 13.42it/s]\titers: 5200, epoch: 2 | loss: 0.7649007\n",
      "\tspeed: 0.0613s/iter; left time: 44213.3115s\n",
      "5299it [05:34, 13.57it/s]\titers: 5300, epoch: 2 | loss: 0.7802441\n",
      "\tspeed: 0.0556s/iter; left time: 40078.0016s\n",
      "5399it [05:40, 18.81it/s]\titers: 5400, epoch: 2 | loss: 0.8983614\n",
      "\tspeed: 0.0668s/iter; left time: 48102.0446s\n",
      "5499it [05:47, 12.68it/s]\titers: 5500, epoch: 2 | loss: 0.5329815\n",
      "\tspeed: 0.0616s/iter; left time: 44365.6299s\n",
      "5598it [05:53, 14.06it/s]\titers: 5600, epoch: 2 | loss: 0.0842553\n",
      "\tspeed: 0.0625s/iter; left time: 44988.5010s\n",
      "5698it [06:00, 23.03it/s]\titers: 5700, epoch: 2 | loss: 0.3948147\n",
      "\tspeed: 0.0713s/iter; left time: 51323.3802s\n",
      "5798it [06:06, 12.94it/s]\titers: 5800, epoch: 2 | loss: 0.1870982\n",
      "\tspeed: 0.0596s/iter; left time: 42945.5575s\n",
      "5897it [06:12, 19.09it/s]\titers: 5900, epoch: 2 | loss: 0.5340365\n",
      "\tspeed: 0.0639s/iter; left time: 46026.1161s\n",
      "5998it [06:19, 11.93it/s]\titers: 6000, epoch: 2 | loss: 0.0910232\n",
      "\tspeed: 0.0672s/iter; left time: 48406.4819s\n",
      "6099it [06:24, 20.11it/s]\titers: 6100, epoch: 2 | loss: 0.6611117\n",
      "\tspeed: 0.0483s/iter; left time: 34744.7599s\n",
      "6198it [06:31, 11.91it/s]\titers: 6200, epoch: 2 | loss: 0.1685711\n",
      "\tspeed: 0.0762s/iter; left time: 54857.4237s\n",
      "6299it [06:37, 11.95it/s]\titers: 6300, epoch: 2 | loss: 0.3941843\n",
      "\tspeed: 0.0585s/iter; left time: 42066.0277s\n",
      "6399it [06:44, 19.82it/s]\titers: 6400, epoch: 2 | loss: 0.5534138\n",
      "\tspeed: 0.0681s/iter; left time: 48987.8686s\n",
      "6498it [06:51, 11.80it/s]\titers: 6500, epoch: 2 | loss: 1.2748663\n",
      "\tspeed: 0.0681s/iter; left time: 49019.7341s\n",
      "6599it [06:56, 13.47it/s]\titers: 6600, epoch: 2 | loss: 0.2111511\n",
      "\tspeed: 0.0544s/iter; left time: 39154.7557s\n",
      "6699it [07:04, 18.54it/s]\titers: 6700, epoch: 2 | loss: 0.2078537\n",
      "\tspeed: 0.0731s/iter; left time: 52558.1304s\n",
      "6798it [07:10, 13.14it/s]\titers: 6800, epoch: 2 | loss: 0.2163189\n",
      "\tspeed: 0.0624s/iter; left time: 44848.5296s\n",
      "6899it [07:16, 12.28it/s]\titers: 6900, epoch: 2 | loss: 0.1972964\n",
      "\tspeed: 0.0650s/iter; left time: 46758.7151s\n",
      "6998it [07:22, 13.10it/s]\titers: 7000, epoch: 2 | loss: 0.3914500\n",
      "\tspeed: 0.0569s/iter; left time: 40883.9580s\n",
      "7099it [07:29, 23.05it/s]\titers: 7100, epoch: 2 | loss: 0.4291026\n",
      "\tspeed: 0.0670s/iter; left time: 48167.8560s\n",
      "7199it [07:35, 13.48it/s]\titers: 7200, epoch: 2 | loss: 0.1522719\n",
      "\tspeed: 0.0621s/iter; left time: 44610.1558s\n",
      "7299it [07:41, 12.67it/s]\titers: 7300, epoch: 2 | loss: 0.1461294\n",
      "\tspeed: 0.0607s/iter; left time: 43610.9493s\n",
      "7398it [07:48, 20.22it/s]\titers: 7400, epoch: 2 | loss: 0.2227389\n",
      "\tspeed: 0.0716s/iter; left time: 51459.1397s\n",
      "7498it [07:55, 12.58it/s]\titers: 7500, epoch: 2 | loss: 0.2863886\n",
      "\tspeed: 0.0632s/iter; left time: 45405.2366s\n",
      "7598it [08:00, 23.47it/s]\titers: 7600, epoch: 2 | loss: 0.1712186\n",
      "\tspeed: 0.0570s/iter; left time: 40937.6345s\n",
      "7699it [08:08, 12.45it/s]\titers: 7700, epoch: 2 | loss: 0.2930794\n",
      "\tspeed: 0.0729s/iter; left time: 52385.0935s\n",
      "7798it [08:12, 16.15it/s]\titers: 7800, epoch: 2 | loss: 0.2070568\n",
      "\tspeed: 0.0480s/iter; left time: 34443.6715s\n",
      "7899it [08:20, 19.13it/s]\titers: 7900, epoch: 2 | loss: 0.1014684\n",
      "\tspeed: 0.0724s/iter; left time: 52011.0354s\n",
      "7999it [08:25, 12.37it/s]\titers: 8000, epoch: 2 | loss: 0.1183595\n",
      "\tspeed: 0.0573s/iter; left time: 41153.8996s\n",
      "8098it [08:32, 19.99it/s]\titers: 8100, epoch: 2 | loss: 0.3919929\n",
      "\tspeed: 0.0651s/iter; left time: 46758.4740s\n",
      "8199it [08:39, 12.40it/s]\titers: 8200, epoch: 2 | loss: 0.6860974\n",
      "\tspeed: 0.0689s/iter; left time: 49432.6659s\n",
      "8298it [08:44, 16.29it/s]\titers: 8300, epoch: 2 | loss: 0.1721449\n",
      "\tspeed: 0.0502s/iter; left time: 36024.7274s\n",
      "8398it [08:51, 17.38it/s]\titers: 8400, epoch: 2 | loss: 0.3088490\n",
      "\tspeed: 0.0715s/iter; left time: 51295.7765s\n",
      "8498it [08:58, 17.60it/s]\titers: 8500, epoch: 2 | loss: 0.3709345\n",
      "\tspeed: 0.0662s/iter; left time: 47488.7803s\n",
      "8599it [09:04, 12.96it/s]\titers: 8600, epoch: 2 | loss: 0.2256505\n",
      "\tspeed: 0.0659s/iter; left time: 47297.5022s\n",
      "8699it [09:10, 13.62it/s]\titers: 8700, epoch: 2 | loss: 0.6709492\n",
      "\tspeed: 0.0607s/iter; left time: 43540.1516s\n",
      "8797it [09:16, 19.17it/s]\titers: 8800, epoch: 2 | loss: 0.4607559\n",
      "\tspeed: 0.0618s/iter; left time: 44345.3326s\n",
      "8898it [09:23, 17.79it/s]\titers: 8900, epoch: 2 | loss: 0.2527392\n",
      "\tspeed: 0.0671s/iter; left time: 48097.9668s\n",
      "8999it [09:30, 11.94it/s]\titers: 9000, epoch: 2 | loss: 0.2914466\n",
      "\tspeed: 0.0650s/iter; left time: 46636.0357s\n",
      "9097it [09:35, 20.17it/s]\titers: 9100, epoch: 2 | loss: 0.3053622\n",
      "\tspeed: 0.0584s/iter; left time: 41858.0946s\n",
      "9199it [09:43, 17.46it/s]\titers: 9200, epoch: 2 | loss: 0.6432325\n",
      "\tspeed: 0.0704s/iter; left time: 50460.4008s\n",
      "9299it [09:48, 13.32it/s]\titers: 9300, epoch: 2 | loss: 0.2271413\n",
      "\tspeed: 0.0502s/iter; left time: 35989.7067s\n",
      "9398it [09:54, 17.63it/s]\titers: 9400, epoch: 2 | loss: 0.3936445\n",
      "\tspeed: 0.0690s/iter; left time: 49478.1165s\n",
      "9499it [10:01, 13.07it/s]\titers: 9500, epoch: 2 | loss: 0.1458180\n",
      "\tspeed: 0.0621s/iter; left time: 44511.9900s\n",
      "9598it [10:07, 22.31it/s]\titers: 9600, epoch: 2 | loss: 0.4312429\n",
      "\tspeed: 0.0612s/iter; left time: 43814.5127s\n",
      "9698it [10:14, 12.29it/s]\titers: 9700, epoch: 2 | loss: 0.1829334\n",
      "\tspeed: 0.0723s/iter; left time: 51803.8206s\n",
      "9798it [10:19, 14.21it/s]\titers: 9800, epoch: 2 | loss: 0.1492081\n",
      "\tspeed: 0.0513s/iter; left time: 36709.9402s\n",
      "9899it [10:25, 20.15it/s]\titers: 9900, epoch: 2 | loss: 0.3498560\n",
      "\tspeed: 0.0607s/iter; left time: 43464.7149s\n",
      "9999it [10:32, 13.53it/s]\titers: 10000, epoch: 2 | loss: 0.6769270\n",
      "\tspeed: 0.0700s/iter; left time: 50098.9605s\n",
      "10098it [10:38, 14.43it/s]\titers: 10100, epoch: 2 | loss: 0.2849993\n",
      "\tspeed: 0.0553s/iter; left time: 39602.3115s\n",
      "10198it [10:44, 13.09it/s]\titers: 10200, epoch: 2 | loss: 0.5098151\n",
      "\tspeed: 0.0642s/iter; left time: 45931.9068s\n",
      "10299it [10:51, 12.22it/s]\titers: 10300, epoch: 2 | loss: 0.3397285\n",
      "\tspeed: 0.0655s/iter; left time: 46857.0551s\n",
      "10399it [10:57, 20.85it/s]\titers: 10400, epoch: 2 | loss: 0.2402358\n",
      "\tspeed: 0.0664s/iter; left time: 47525.4566s\n",
      "10498it [11:04, 13.34it/s]\titers: 10500, epoch: 2 | loss: 0.1471602\n",
      "\tspeed: 0.0642s/iter; left time: 45966.4276s\n",
      "10597it [11:09, 22.32it/s]\titers: 10600, epoch: 2 | loss: 0.2194155\n",
      "\tspeed: 0.0552s/iter; left time: 39501.1314s\n",
      "10699it [11:16, 19.94it/s]\titers: 10700, epoch: 2 | loss: 0.2499068\n",
      "\tspeed: 0.0705s/iter; left time: 50403.3844s\n",
      "10799it [11:22, 12.37it/s]\titers: 10800, epoch: 2 | loss: 0.1901600\n",
      "\tspeed: 0.0595s/iter; left time: 42559.3991s\n",
      "10898it [11:28, 20.55it/s]\titers: 10900, epoch: 2 | loss: 0.4498950\n",
      "\tspeed: 0.0605s/iter; left time: 43271.8333s\n",
      "10998it [11:35, 17.97it/s]\titers: 11000, epoch: 2 | loss: 0.4764846\n",
      "\tspeed: 0.0707s/iter; left time: 50516.5937s\n",
      "11098it [11:40, 13.33it/s]\titers: 11100, epoch: 2 | loss: 0.7763655\n",
      "\tspeed: 0.0504s/iter; left time: 36053.7417s\n",
      "11199it [11:48, 18.77it/s]\titers: 11200, epoch: 2 | loss: 0.3156588\n",
      "\tspeed: 0.0740s/iter; left time: 52895.0229s\n",
      "11299it [11:54, 12.66it/s]\titers: 11300, epoch: 2 | loss: 0.3827136\n",
      "\tspeed: 0.0607s/iter; left time: 43352.2518s\n",
      "11397it [12:00, 19.38it/s]\titers: 11400, epoch: 2 | loss: 0.2400607\n",
      "\tspeed: 0.0608s/iter; left time: 43468.6345s\n",
      "11499it [12:06, 19.55it/s]\titers: 11500, epoch: 2 | loss: 0.1821827\n",
      "\tspeed: 0.0619s/iter; left time: 44221.1759s\n",
      "11598it [12:13, 14.38it/s]\titers: 11600, epoch: 2 | loss: 0.1977159\n",
      "\tspeed: 0.0664s/iter; left time: 47403.2241s\n",
      "11699it [12:18, 16.16it/s]\titers: 11700, epoch: 2 | loss: 0.3947483\n",
      "\tspeed: 0.0536s/iter; left time: 38258.4887s\n",
      "11798it [12:25, 13.44it/s]\titers: 11800, epoch: 2 | loss: 0.3039238\n",
      "\tspeed: 0.0716s/iter; left time: 51126.6799s\n",
      "11898it [12:32, 12.84it/s]\titers: 11900, epoch: 2 | loss: 0.2637303\n",
      "\tspeed: 0.0708s/iter; left time: 50527.2839s\n",
      "11998it [12:38, 24.32it/s]\titers: 12000, epoch: 2 | loss: 0.8668292\n",
      "\tspeed: 0.0588s/iter; left time: 41995.0518s\n",
      "12099it [12:45, 16.64it/s]\titers: 12100, epoch: 2 | loss: 1.1623813\n",
      "\tspeed: 0.0679s/iter; left time: 48470.9530s\n",
      "12199it [12:50, 12.96it/s]\titers: 12200, epoch: 2 | loss: 0.2492280\n",
      "\tspeed: 0.0540s/iter; left time: 38564.0294s\n",
      "12298it [12:57, 18.50it/s]\titers: 12300, epoch: 2 | loss: 0.4222909\n",
      "\tspeed: 0.0624s/iter; left time: 44555.3820s\n",
      "12399it [13:04, 12.49it/s]\titers: 12400, epoch: 2 | loss: 0.3873922\n",
      "\tspeed: 0.0682s/iter; left time: 48674.3872s\n",
      "12498it [13:09, 17.12it/s]\titers: 12500, epoch: 2 | loss: 0.4062331\n",
      "\tspeed: 0.0521s/iter; left time: 37178.4103s\n",
      "12598it [13:16, 18.74it/s]\titers: 12600, epoch: 2 | loss: 0.2179781\n",
      "\tspeed: 0.0720s/iter; left time: 51342.2897s\n",
      "12699it [13:22, 14.04it/s]\titers: 12700, epoch: 2 | loss: 0.2200585\n",
      "\tspeed: 0.0600s/iter; left time: 42777.5346s\n",
      "12798it [13:28, 18.15it/s]\titers: 12800, epoch: 2 | loss: 0.6219527\n",
      "\tspeed: 0.0627s/iter; left time: 44717.7213s\n",
      "12898it [13:36, 17.47it/s]\titers: 12900, epoch: 2 | loss: 0.6864708\n",
      "\tspeed: 0.0741s/iter; left time: 52850.2606s\n",
      "12998it [13:41, 13.13it/s]\titers: 13000, epoch: 2 | loss: 1.4778383\n",
      "\tspeed: 0.0556s/iter; left time: 39656.2685s\n",
      "13099it [13:47, 14.87it/s]\titers: 13100, epoch: 2 | loss: 0.6315655\n",
      "\tspeed: 0.0561s/iter; left time: 39977.7124s\n",
      "13199it [13:53, 21.23it/s]\titers: 13200, epoch: 2 | loss: 0.6674256\n",
      "\tspeed: 0.0638s/iter; left time: 45498.2146s\n",
      "13298it [13:59, 18.38it/s]\titers: 13300, epoch: 2 | loss: 0.5571383\n",
      "\tspeed: 0.0635s/iter; left time: 45282.4253s\n",
      "13398it [14:06, 11.96it/s]\titers: 13400, epoch: 2 | loss: 0.2359023\n",
      "\tspeed: 0.0638s/iter; left time: 45466.3557s\n",
      "13498it [14:12, 13.33it/s]\titers: 13500, epoch: 2 | loss: 0.1902592\n",
      "\tspeed: 0.0623s/iter; left time: 44363.5633s\n",
      "13598it [14:18, 21.13it/s]\titers: 13600, epoch: 2 | loss: 0.1783268\n",
      "\tspeed: 0.0602s/iter; left time: 42870.2279s\n",
      "13698it [14:24, 14.13it/s]\titers: 13700, epoch: 2 | loss: 0.6540186\n",
      "\tspeed: 0.0637s/iter; left time: 45388.1671s\n",
      "13798it [14:30, 25.52it/s]\titers: 13800, epoch: 2 | loss: 0.2894026\n",
      "\tspeed: 0.0515s/iter; left time: 36703.4784s\n",
      "13898it [14:37, 12.98it/s]\titers: 13900, epoch: 2 | loss: 0.2001352\n",
      "\tspeed: 0.0785s/iter; left time: 55877.9729s\n",
      "13998it [14:43, 12.21it/s]\titers: 14000, epoch: 2 | loss: 0.1808207\n",
      "\tspeed: 0.0596s/iter; left time: 42426.9153s\n",
      "14097it [14:50, 20.56it/s]\titers: 14100, epoch: 2 | loss: 0.3034558\n",
      "\tspeed: 0.0691s/iter; left time: 49195.7654s\n",
      "14198it [14:57, 12.28it/s]\titers: 14200, epoch: 2 | loss: 0.2607985\n",
      "\tspeed: 0.0690s/iter; left time: 49107.8455s\n",
      "14298it [15:03, 20.96it/s]\titers: 14300, epoch: 2 | loss: 0.3144494\n",
      "\tspeed: 0.0574s/iter; left time: 40819.1571s\n",
      "14399it [15:11, 14.34it/s]\titers: 14400, epoch: 2 | loss: 0.3484701\n",
      "\tspeed: 0.0776s/iter; left time: 55206.7655s\n",
      "14499it [15:18, 12.47it/s]\titers: 14500, epoch: 2 | loss: 0.6493134\n",
      "\tspeed: 0.0678s/iter; left time: 48261.2862s\n",
      "14598it [15:24, 22.66it/s]\titers: 14600, epoch: 2 | loss: 0.1240453\n",
      "\tspeed: 0.0607s/iter; left time: 43170.9011s\n",
      "14698it [15:31, 13.12it/s]\titers: 14700, epoch: 2 | loss: 0.2639467\n",
      "\tspeed: 0.0730s/iter; left time: 51890.5273s\n",
      "14798it [15:36, 12.71it/s]\titers: 14800, epoch: 2 | loss: 0.2713909\n",
      "\tspeed: 0.0547s/iter; left time: 38895.4900s\n",
      "14816it [15:38, 15.79it/s]\n",
      "Epoch: 2 cost time: 938.2876217365265\n",
      "3204it [01:42, 31.14it/s]\n",
      "3192it [01:42, 31.02it/s]\n",
      "Epoch: 2 | Train Loss: 0.3856661 Vali Loss: 0.4719015 Test Loss: 0.5948117 MAE Loss: 0.4796047\n",
      "Validation loss decreased (0.480441 --> 0.471902).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "98it [00:07, 23.26it/s]\titers: 100, epoch: 3 | loss: 0.5278946\n",
      "\tspeed: 2.1634s/iter; left time: 1538301.8901s\n",
      "198it [00:12, 13.32it/s]\titers: 200, epoch: 3 | loss: 0.8207273\n",
      "\tspeed: 0.0597s/iter; left time: 42439.2574s\n",
      "299it [00:19, 12.18it/s]\titers: 300, epoch: 3 | loss: 0.3020312\n",
      "\tspeed: 0.0615s/iter; left time: 43735.1791s\n",
      "399it [00:24, 15.94it/s]\titers: 400, epoch: 3 | loss: 0.1920633\n",
      "\tspeed: 0.0487s/iter; left time: 34607.3101s\n",
      "497it [00:30, 20.64it/s]\titers: 500, epoch: 3 | loss: 0.9825035\n",
      "\tspeed: 0.0654s/iter; left time: 46449.6174s\n",
      "599it [00:36, 16.05it/s]\titers: 600, epoch: 3 | loss: 0.1032447\n",
      "\tspeed: 0.0584s/iter; left time: 41475.3730s\n",
      "697it [00:41, 22.50it/s]\titers: 700, epoch: 3 | loss: 0.3477395\n",
      "\tspeed: 0.0544s/iter; left time: 38650.3406s\n",
      "798it [00:48, 16.94it/s]\titers: 800, epoch: 3 | loss: 0.2135506\n",
      "\tspeed: 0.0703s/iter; left time: 49915.8103s\n",
      "899it [00:54, 12.65it/s]\titers: 900, epoch: 3 | loss: 0.3669769\n",
      "\tspeed: 0.0521s/iter; left time: 37012.7067s\n",
      "999it [01:00, 20.89it/s]\titers: 1000, epoch: 3 | loss: 0.3838996\n",
      "\tspeed: 0.0668s/iter; left time: 47461.2315s\n",
      "1099it [01:07, 12.55it/s]\titers: 1100, epoch: 3 | loss: 0.5435354\n",
      "\tspeed: 0.0689s/iter; left time: 48920.2014s\n",
      "1198it [01:12, 21.51it/s]\titers: 1200, epoch: 3 | loss: 0.7445388\n",
      "\tspeed: 0.0530s/iter; left time: 37630.0849s\n",
      "1298it [01:20, 12.84it/s]\titers: 1300, epoch: 3 | loss: 0.1728254\n",
      "\tspeed: 0.0745s/iter; left time: 52850.7265s\n",
      "1398it [01:26, 12.99it/s]\titers: 1400, epoch: 3 | loss: 0.3940254\n",
      "\tspeed: 0.0589s/iter; left time: 41809.7032s\n",
      "1499it [01:33, 20.46it/s]\titers: 1500, epoch: 3 | loss: 0.2250404\n",
      "\tspeed: 0.0695s/iter; left time: 49293.7956s\n",
      "1598it [01:40, 12.34it/s]\titers: 1600, epoch: 3 | loss: 0.2748400\n",
      "\tspeed: 0.0692s/iter; left time: 49104.1648s\n",
      "1699it [01:45, 15.31it/s]\titers: 1700, epoch: 3 | loss: 0.2805447\n",
      "\tspeed: 0.0578s/iter; left time: 41036.6184s\n",
      "1799it [01:52, 22.27it/s]\titers: 1800, epoch: 3 | loss: 0.4070167\n",
      "\tspeed: 0.0678s/iter; left time: 48071.7229s\n",
      "1899it [01:59, 16.23it/s]\titers: 1900, epoch: 3 | loss: 1.0162226\n",
      "\tspeed: 0.0654s/iter; left time: 46407.6177s\n",
      "1999it [02:05, 13.79it/s]\titers: 2000, epoch: 3 | loss: 0.2068892\n",
      "\tspeed: 0.0653s/iter; left time: 46295.9278s\n",
      "2098it [02:12, 13.98it/s]\titers: 2100, epoch: 3 | loss: 0.7390379\n",
      "\tspeed: 0.0628s/iter; left time: 44546.4368s\n",
      "2199it [02:17, 25.09it/s]\titers: 2200, epoch: 3 | loss: 0.2942721\n",
      "\tspeed: 0.0533s/iter; left time: 37801.1420s\n",
      "2298it [02:24, 17.56it/s]\titers: 2300, epoch: 3 | loss: 0.6117713\n",
      "\tspeed: 0.0667s/iter; left time: 47289.6870s\n",
      "2398it [02:30, 12.32it/s]\titers: 2400, epoch: 3 | loss: 0.4906154\n",
      "\tspeed: 0.0667s/iter; left time: 47249.8005s\n",
      "2498it [02:36, 19.47it/s]\titers: 2500, epoch: 3 | loss: 0.2343832\n",
      "\tspeed: 0.0557s/iter; left time: 39456.9485s\n",
      "2597it [02:43, 20.56it/s]\titers: 2600, epoch: 3 | loss: 0.2465896\n",
      "\tspeed: 0.0683s/iter; left time: 48407.7837s\n",
      "2698it [02:48, 12.05it/s]\titers: 2700, epoch: 3 | loss: 0.2719182\n",
      "\tspeed: 0.0546s/iter; left time: 38678.4974s\n",
      "2797it [02:55, 22.90it/s]\titers: 2800, epoch: 3 | loss: 0.2718423\n",
      "\tspeed: 0.0680s/iter; left time: 48154.8814s\n",
      "2899it [03:02, 12.73it/s]\titers: 2900, epoch: 3 | loss: 0.2264480\n",
      "\tspeed: 0.0684s/iter; left time: 48428.0489s\n",
      "2998it [03:08, 13.85it/s]\titers: 3000, epoch: 3 | loss: 0.6651196\n",
      "\tspeed: 0.0660s/iter; left time: 46756.2062s\n",
      "3098it [03:15, 21.75it/s]\titers: 3100, epoch: 3 | loss: 0.4750513\n",
      "\tspeed: 0.0664s/iter; left time: 47045.2949s\n",
      "3199it [03:21, 12.43it/s]\titers: 3200, epoch: 3 | loss: 0.2118996\n",
      "\tspeed: 0.0640s/iter; left time: 45344.2816s\n",
      "3298it [03:27, 13.03it/s]\titers: 3300, epoch: 3 | loss: 0.2685755\n",
      "\tspeed: 0.0578s/iter; left time: 40893.9951s\n",
      "3398it [03:34, 18.04it/s]\titers: 3400, epoch: 3 | loss: 0.1952534\n",
      "\tspeed: 0.0643s/iter; left time: 45542.9604s\n",
      "3498it [03:40, 17.97it/s]\titers: 3500, epoch: 3 | loss: 0.1592045\n",
      "\tspeed: 0.0667s/iter; left time: 47181.0266s\n",
      "3597it [03:47, 18.82it/s]\titers: 3600, epoch: 3 | loss: 0.1376058\n",
      "\tspeed: 0.0653s/iter; left time: 46189.2617s\n",
      "3699it [03:54, 19.47it/s]\titers: 3700, epoch: 3 | loss: 0.3417158\n",
      "\tspeed: 0.0683s/iter; left time: 48293.3721s\n",
      "3799it [04:00, 15.20it/s]\titers: 3800, epoch: 3 | loss: 0.2010016\n",
      "\tspeed: 0.0609s/iter; left time: 43088.7235s\n",
      "3899it [04:05, 23.02it/s]\titers: 3900, epoch: 3 | loss: 0.2762576\n",
      "\tspeed: 0.0533s/iter; left time: 37682.6925s\n",
      "3999it [04:12, 16.97it/s]\titers: 4000, epoch: 3 | loss: 0.2668163\n",
      "\tspeed: 0.0696s/iter; left time: 49243.3746s\n",
      "4099it [04:18, 12.50it/s]\titers: 4100, epoch: 3 | loss: 0.4664470\n",
      "\tspeed: 0.0566s/iter; left time: 39987.9581s\n",
      "4198it [04:23, 25.27it/s]\titers: 4200, epoch: 3 | loss: 0.2821302\n",
      "\tspeed: 0.0575s/iter; left time: 40628.7346s\n",
      "4298it [04:30, 12.31it/s]\titers: 4300, epoch: 3 | loss: 0.2216893\n",
      "\tspeed: 0.0694s/iter; left time: 49022.0203s\n",
      "4399it [04:36, 19.26it/s]\titers: 4400, epoch: 3 | loss: 0.6813632\n",
      "\tspeed: 0.0604s/iter; left time: 42718.7067s\n",
      "4498it [04:44, 13.63it/s]\titers: 4500, epoch: 3 | loss: 0.4053993\n",
      "\tspeed: 0.0742s/iter; left time: 52470.1038s\n",
      "4598it [04:49, 13.53it/s]\titers: 4600, epoch: 3 | loss: 0.5449346\n",
      "\tspeed: 0.0475s/iter; left time: 33575.9136s\n",
      "4697it [04:55, 21.14it/s]\titers: 4700, epoch: 3 | loss: 0.1417733\n",
      "\tspeed: 0.0662s/iter; left time: 46791.3732s\n",
      "4799it [05:01, 13.44it/s]\titers: 4800, epoch: 3 | loss: 0.4134873\n",
      "\tspeed: 0.0614s/iter; left time: 43371.8977s\n",
      "4898it [05:08, 13.75it/s]\titers: 4900, epoch: 3 | loss: 0.1342873\n",
      "\tspeed: 0.0624s/iter; left time: 44092.6248s\n",
      "4999it [05:13, 17.91it/s]\titers: 5000, epoch: 3 | loss: 0.2668993\n",
      "\tspeed: 0.0544s/iter; left time: 38404.2951s\n",
      "5098it [05:18, 17.04it/s]\titers: 5100, epoch: 3 | loss: 0.2242403\n",
      "\tspeed: 0.0512s/iter; left time: 36151.3953s\n",
      "5198it [05:23, 22.68it/s]\titers: 5200, epoch: 3 | loss: 0.2863150\n",
      "\tspeed: 0.0517s/iter; left time: 36518.2471s\n",
      "5297it [05:28, 20.59it/s]\titers: 5300, epoch: 3 | loss: 0.3189879\n",
      "\tspeed: 0.0456s/iter; left time: 32176.9697s\n",
      "5399it [05:33, 17.66it/s]\titers: 5400, epoch: 3 | loss: 0.1649878\n",
      "\tspeed: 0.0515s/iter; left time: 36316.8377s\n",
      "5499it [05:37, 26.86it/s]\titers: 5500, epoch: 3 | loss: 0.1443393\n",
      "\tspeed: 0.0435s/iter; left time: 30680.8632s\n",
      "5598it [05:41, 25.68it/s]\titers: 5600, epoch: 3 | loss: 0.5971522\n",
      "\tspeed: 0.0392s/iter; left time: 27675.4622s\n",
      "5697it [05:45, 24.36it/s]\titers: 5700, epoch: 3 | loss: 0.1794433\n",
      "\tspeed: 0.0405s/iter; left time: 28588.3895s\n",
      "5799it [05:50, 19.40it/s]\titers: 5800, epoch: 3 | loss: 0.2927238\n",
      "\tspeed: 0.0497s/iter; left time: 35027.3134s\n",
      "5898it [05:55, 26.31it/s]\titers: 5900, epoch: 3 | loss: 0.2892492\n",
      "\tspeed: 0.0420s/iter; left time: 29622.8487s\n",
      "5997it [05:59, 24.74it/s]\titers: 6000, epoch: 3 | loss: 0.6258401\n",
      "\tspeed: 0.0410s/iter; left time: 28935.7904s\n",
      "6099it [06:03, 21.44it/s]\titers: 6100, epoch: 3 | loss: 0.1255925\n",
      "\tspeed: 0.0437s/iter; left time: 30786.7716s\n",
      "6199it [06:08, 19.12it/s]\titers: 6200, epoch: 3 | loss: 0.2011451\n",
      "\tspeed: 0.0512s/iter; left time: 36107.6330s\n",
      "6298it [06:13, 20.73it/s]\titers: 6300, epoch: 3 | loss: 0.1631622\n",
      "\tspeed: 0.0530s/iter; left time: 37383.9756s\n",
      "6399it [06:17, 26.59it/s]\titers: 6400, epoch: 3 | loss: 1.0322512\n",
      "\tspeed: 0.0393s/iter; left time: 27690.9480s\n",
      "6499it [06:22, 21.93it/s]\titers: 6500, epoch: 3 | loss: 0.1643804\n",
      "\tspeed: 0.0477s/iter; left time: 33616.1519s\n",
      "6598it [06:26, 25.29it/s]\titers: 6600, epoch: 3 | loss: 0.4169674\n",
      "\tspeed: 0.0426s/iter; left time: 30004.7553s\n",
      "6698it [06:30, 25.95it/s]\titers: 6700, epoch: 3 | loss: 0.7656648\n",
      "\tspeed: 0.0390s/iter; left time: 27492.6831s\n",
      "6797it [06:34, 26.54it/s]\titers: 6800, epoch: 3 | loss: 0.1958673\n",
      "\tspeed: 0.0386s/iter; left time: 27160.9334s\n",
      "6899it [06:38, 24.66it/s]\titers: 6900, epoch: 3 | loss: 0.2114542\n",
      "\tspeed: 0.0391s/iter; left time: 27542.7769s\n",
      "6997it [06:43, 18.31it/s]\titers: 7000, epoch: 3 | loss: 0.2414893\n",
      "\tspeed: 0.0497s/iter; left time: 34966.9715s\n",
      "7098it [06:48, 21.48it/s]\titers: 7100, epoch: 3 | loss: 0.3681656\n",
      "\tspeed: 0.0514s/iter; left time: 36194.2168s\n",
      "7199it [06:53, 22.06it/s]\titers: 7200, epoch: 3 | loss: 0.1848322\n",
      "\tspeed: 0.0478s/iter; left time: 33630.4685s\n",
      "7299it [06:57, 26.53it/s]\titers: 7300, epoch: 3 | loss: 0.1709398\n",
      "\tspeed: 0.0414s/iter; left time: 29149.2310s\n",
      "7398it [07:01, 24.86it/s]\titers: 7400, epoch: 3 | loss: 0.1456491\n",
      "\tspeed: 0.0397s/iter; left time: 27942.6313s\n",
      "7497it [07:05, 25.73it/s]\titers: 7500, epoch: 3 | loss: 0.5621200\n",
      "\tspeed: 0.0390s/iter; left time: 27447.1500s\n",
      "7599it [07:09, 25.96it/s]\titers: 7600, epoch: 3 | loss: 0.3474715\n",
      "\tspeed: 0.0392s/iter; left time: 27590.4497s\n",
      "7698it [07:13, 25.27it/s]\titers: 7700, epoch: 3 | loss: 0.1956635\n",
      "\tspeed: 0.0405s/iter; left time: 28490.5831s\n",
      "7798it [07:17, 21.78it/s]\titers: 7800, epoch: 3 | loss: 0.4275600\n",
      "\tspeed: 0.0456s/iter; left time: 32085.9835s\n",
      "7899it [07:23, 17.51it/s]\titers: 7900, epoch: 3 | loss: 0.2851394\n",
      "\tspeed: 0.0543s/iter; left time: 38215.2217s\n",
      "7998it [07:28, 20.19it/s]\titers: 8000, epoch: 3 | loss: 0.2245116\n",
      "\tspeed: 0.0540s/iter; left time: 37964.3838s\n",
      "8097it [07:32, 24.96it/s]\titers: 8100, epoch: 3 | loss: 0.1938531\n",
      "\tspeed: 0.0425s/iter; left time: 29872.9162s\n",
      "8199it [07:37, 25.01it/s]\titers: 8200, epoch: 3 | loss: 0.1447303\n",
      "\tspeed: 0.0401s/iter; left time: 28162.0480s\n",
      "8299it [07:41, 24.29it/s]\titers: 8300, epoch: 3 | loss: 0.1698615\n",
      "\tspeed: 0.0396s/iter; left time: 27832.2100s\n",
      "8398it [07:44, 23.94it/s]\titers: 8400, epoch: 3 | loss: 0.7653539\n",
      "\tspeed: 0.0391s/iter; left time: 27491.2924s\n",
      "8497it [07:48, 25.39it/s]\titers: 8500, epoch: 3 | loss: 0.2308053\n",
      "\tspeed: 0.0395s/iter; left time: 27776.8528s\n",
      "8597it [07:53, 20.07it/s]\titers: 8600, epoch: 3 | loss: 0.1168003\n",
      "\tspeed: 0.0450s/iter; left time: 31609.4207s\n",
      "8698it [07:58, 16.83it/s]\titers: 8700, epoch: 3 | loss: 0.3043092\n",
      "\tspeed: 0.0531s/iter; left time: 37283.6017s\n",
      "8799it [08:03, 25.47it/s]\titers: 8800, epoch: 3 | loss: 0.2185405\n",
      "\tspeed: 0.0480s/iter; left time: 33705.1797s\n",
      "8899it [08:07, 26.17it/s]\titers: 8900, epoch: 3 | loss: 0.3558585\n",
      "\tspeed: 0.0387s/iter; left time: 27202.2883s\n",
      "8998it [08:11, 26.25it/s]\titers: 9000, epoch: 3 | loss: 0.5111861\n",
      "\tspeed: 0.0387s/iter; left time: 27152.5194s\n",
      "9097it [08:15, 25.67it/s]\titers: 9100, epoch: 3 | loss: 0.2670048\n",
      "\tspeed: 0.0394s/iter; left time: 27678.8502s\n",
      "9199it [08:19, 23.85it/s]\titers: 9200, epoch: 3 | loss: 0.2093480\n",
      "\tspeed: 0.0393s/iter; left time: 27582.8400s\n",
      "9298it [08:23, 25.36it/s]\titers: 9300, epoch: 3 | loss: 0.1875816\n",
      "\tspeed: 0.0399s/iter; left time: 27998.3766s\n",
      "9398it [08:27, 23.00it/s]\titers: 9400, epoch: 3 | loss: 0.2303696\n",
      "\tspeed: 0.0446s/iter; left time: 31322.3954s\n",
      "9499it [08:33, 17.33it/s]\titers: 9500, epoch: 3 | loss: 0.3136583\n",
      "\tspeed: 0.0565s/iter; left time: 39630.5980s\n",
      "9599it [08:38, 20.54it/s]\titers: 9600, epoch: 3 | loss: 0.5310749\n",
      "\tspeed: 0.0526s/iter; left time: 36922.1715s\n",
      "9698it [08:42, 25.53it/s]\titers: 9700, epoch: 3 | loss: 0.3456270\n",
      "\tspeed: 0.0396s/iter; left time: 27783.7385s\n",
      "9797it [08:46, 25.70it/s]\titers: 9800, epoch: 3 | loss: 0.7199041\n",
      "\tspeed: 0.0395s/iter; left time: 27688.5646s\n",
      "9899it [08:50, 25.55it/s]\titers: 9900, epoch: 3 | loss: 0.2460739\n",
      "\tspeed: 0.0393s/iter; left time: 27588.6248s\n",
      "9998it [08:54, 26.27it/s]\titers: 10000, epoch: 3 | loss: 0.2356671\n",
      "\tspeed: 0.0384s/iter; left time: 26929.0884s\n",
      "10097it [08:58, 25.68it/s]\titers: 10100, epoch: 3 | loss: 0.7194166\n",
      "\tspeed: 0.0395s/iter; left time: 27671.8188s\n",
      "10199it [09:02, 19.37it/s]\titers: 10200, epoch: 3 | loss: 0.3378266\n",
      "\tspeed: 0.0439s/iter; left time: 30744.8156s\n",
      "10298it [09:07, 19.70it/s]\titers: 10300, epoch: 3 | loss: 0.2597840\n",
      "\tspeed: 0.0496s/iter; left time: 34754.4034s\n",
      "10398it [09:12, 19.50it/s]\titers: 10400, epoch: 3 | loss: 0.6424517\n",
      "\tspeed: 0.0487s/iter; left time: 34110.1137s\n",
      "10498it [09:17, 25.53it/s]\titers: 10500, epoch: 3 | loss: 0.4517760\n",
      "\tspeed: 0.0474s/iter; left time: 33181.7515s\n",
      "10597it [09:20, 25.70it/s]\titers: 10600, epoch: 3 | loss: 0.4337007\n",
      "\tspeed: 0.0387s/iter; left time: 27104.0906s\n",
      "10699it [09:24, 24.92it/s]\titers: 10700, epoch: 3 | loss: 0.5268267\n",
      "\tspeed: 0.0385s/iter; left time: 26937.5808s\n",
      "10799it [09:28, 24.49it/s]\titers: 10800, epoch: 3 | loss: 0.3841441\n",
      "\tspeed: 0.0394s/iter; left time: 27572.6912s\n",
      "10899it [09:33, 20.35it/s]\titers: 10900, epoch: 3 | loss: 0.6265694\n",
      "\tspeed: 0.0463s/iter; left time: 32397.0780s\n",
      "10998it [09:37, 24.50it/s]\titers: 11000, epoch: 3 | loss: 0.3437184\n",
      "\tspeed: 0.0454s/iter; left time: 31779.8098s\n",
      "11097it [09:42, 21.61it/s]\titers: 11100, epoch: 3 | loss: 0.2992541\n",
      "\tspeed: 0.0423s/iter; left time: 29587.8273s\n",
      "11197it [09:47, 18.42it/s]\titers: 11200, epoch: 3 | loss: 0.1864961\n",
      "\tspeed: 0.0512s/iter; left time: 35836.4945s\n",
      "11298it [09:52, 17.26it/s]\titers: 11300, epoch: 3 | loss: 0.1861633\n",
      "\tspeed: 0.0523s/iter; left time: 36592.7634s\n",
      "11397it [09:56, 26.00it/s]\titers: 11400, epoch: 3 | loss: 0.2976792\n",
      "\tspeed: 0.0391s/iter; left time: 27342.6347s\n",
      "11499it [10:00, 24.09it/s]\titers: 11500, epoch: 3 | loss: 0.8139990\n",
      "\tspeed: 0.0394s/iter; left time: 27537.7182s\n",
      "11599it [10:04, 20.22it/s]\titers: 11600, epoch: 3 | loss: 0.5404238\n",
      "\tspeed: 0.0463s/iter; left time: 32417.7777s\n",
      "11697it [10:09, 20.43it/s]\titers: 11700, epoch: 3 | loss: 0.2384695\n",
      "\tspeed: 0.0508s/iter; left time: 35533.1014s\n",
      "11797it [10:14, 24.71it/s]\titers: 11800, epoch: 3 | loss: 0.3080744\n",
      "\tspeed: 0.0490s/iter; left time: 34245.4859s\n",
      "11899it [10:19, 24.24it/s]\titers: 11900, epoch: 3 | loss: 0.0802430\n",
      "\tspeed: 0.0412s/iter; left time: 28842.9957s\n",
      "11998it [10:23, 22.84it/s]\titers: 12000, epoch: 3 | loss: 0.5011000\n",
      "\tspeed: 0.0486s/iter; left time: 33967.4006s\n",
      "12098it [10:28, 19.10it/s]\titers: 12100, epoch: 3 | loss: 0.1537029\n",
      "\tspeed: 0.0494s/iter; left time: 34567.2099s\n",
      "12197it [10:32, 25.71it/s]\titers: 12200, epoch: 3 | loss: 0.4255113\n",
      "\tspeed: 0.0421s/iter; left time: 29400.5049s\n",
      "12299it [10:37, 23.95it/s]\titers: 12300, epoch: 3 | loss: 0.9904142\n",
      "\tspeed: 0.0402s/iter; left time: 28078.3962s\n",
      "12398it [10:41, 20.15it/s]\titers: 12400, epoch: 3 | loss: 1.0774645\n",
      "\tspeed: 0.0458s/iter; left time: 31995.4813s\n",
      "12497it [10:45, 25.18it/s]\titers: 12500, epoch: 3 | loss: 0.5872955\n",
      "\tspeed: 0.0443s/iter; left time: 30961.9812s\n",
      "12599it [10:49, 25.52it/s]\titers: 12600, epoch: 3 | loss: 0.3935277\n",
      "\tspeed: 0.0390s/iter; left time: 27252.7208s\n",
      "12698it [10:53, 26.01it/s]\titers: 12700, epoch: 3 | loss: 0.0795868\n",
      "\tspeed: 0.0393s/iter; left time: 27444.4317s\n",
      "12797it [10:58, 20.37it/s]\titers: 12800, epoch: 3 | loss: 0.2197041\n",
      "\tspeed: 0.0427s/iter; left time: 29829.0077s\n",
      "12898it [11:03, 18.73it/s]\titers: 12900, epoch: 3 | loss: 0.1848470\n",
      "\tspeed: 0.0518s/iter; left time: 36177.4617s\n",
      "12997it [11:08, 22.53it/s]\titers: 13000, epoch: 3 | loss: 0.2561437\n",
      "\tspeed: 0.0519s/iter; left time: 36224.5513s\n",
      "13098it [11:13, 20.82it/s]\titers: 13100, epoch: 3 | loss: 0.1731838\n",
      "\tspeed: 0.0492s/iter; left time: 34322.7183s\n",
      "13199it [11:17, 27.06it/s]\titers: 13200, epoch: 3 | loss: 0.4000860\n",
      "\tspeed: 0.0423s/iter; left time: 29495.6629s\n",
      "13298it [11:21, 26.70it/s]\titers: 13300, epoch: 3 | loss: 0.3544185\n",
      "\tspeed: 0.0394s/iter; left time: 27520.6590s\n",
      "13397it [11:25, 25.83it/s]\titers: 13400, epoch: 3 | loss: 0.5769793\n",
      "\tspeed: 0.0390s/iter; left time: 27245.7299s\n",
      "13499it [11:29, 26.05it/s]\titers: 13500, epoch: 3 | loss: 0.7402129\n",
      "\tspeed: 0.0391s/iter; left time: 27249.8759s\n",
      "13598it [11:33, 22.30it/s]\titers: 13600, epoch: 3 | loss: 0.1976167\n",
      "\tspeed: 0.0415s/iter; left time: 28974.9127s\n",
      "13697it [11:38, 18.62it/s]\titers: 13700, epoch: 3 | loss: 0.1592570\n",
      "\tspeed: 0.0508s/iter; left time: 35408.3836s\n",
      "13799it [11:44, 17.39it/s]\titers: 13800, epoch: 3 | loss: 0.1752078\n",
      "\tspeed: 0.0558s/iter; left time: 38882.8828s\n",
      "13899it [11:48, 26.25it/s]\titers: 13900, epoch: 3 | loss: 0.3869770\n",
      "\tspeed: 0.0404s/iter; left time: 28169.9333s\n",
      "13998it [11:52, 25.53it/s]\titers: 14000, epoch: 3 | loss: 0.1496625\n",
      "\tspeed: 0.0391s/iter; left time: 27264.7804s\n",
      "14097it [11:55, 26.37it/s]\titers: 14100, epoch: 3 | loss: 0.1255860\n",
      "\tspeed: 0.0387s/iter; left time: 26959.1656s\n",
      "14199it [11:59, 26.61it/s]\titers: 14200, epoch: 3 | loss: 0.1351347\n",
      "\tspeed: 0.0388s/iter; left time: 27023.3366s\n",
      "14298it [12:03, 25.70it/s]\titers: 14300, epoch: 3 | loss: 0.2117765\n",
      "\tspeed: 0.0392s/iter; left time: 27302.8073s\n",
      "14397it [12:07, 23.20it/s]\titers: 14400, epoch: 3 | loss: 0.2427612\n",
      "\tspeed: 0.0412s/iter; left time: 28713.5419s\n",
      "14498it [12:12, 19.09it/s]\titers: 14500, epoch: 3 | loss: 0.8061271\n",
      "\tspeed: 0.0453s/iter; left time: 31590.9649s\n",
      "14597it [12:17, 18.17it/s]\titers: 14600, epoch: 3 | loss: 0.2729841\n",
      "\tspeed: 0.0528s/iter; left time: 36810.3491s\n",
      "14697it [12:22, 24.92it/s]\titers: 14700, epoch: 3 | loss: 0.2496898\n",
      "\tspeed: 0.0470s/iter; left time: 32719.3578s\n",
      "14799it [12:26, 26.87it/s]\titers: 14800, epoch: 3 | loss: 0.3250307\n",
      "\tspeed: 0.0388s/iter; left time: 27051.4169s\n",
      "14816it [12:27, 19.83it/s]\n",
      "Epoch: 3 cost time: 747.1040940284729\n",
      "3204it [01:11, 44.79it/s]\n",
      "3192it [01:09, 45.67it/s]\n",
      "Epoch: 3 | Train Loss: 0.3709007 Vali Loss: 0.4646254 Test Loss: 0.5988673 MAE Loss: 0.4916651\n",
      "Validation loss decreased (0.471902 --> 0.464625).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:04, 24.39it/s]\titers: 100, epoch: 4 | loss: 0.1626250\n",
      "\tspeed: 1.4785s/iter; left time: 1029389.1754s\n",
      "198it [00:08, 25.60it/s]\titers: 200, epoch: 4 | loss: 0.2022431\n",
      "\tspeed: 0.0390s/iter; left time: 27173.3055s\n",
      "297it [00:12, 25.67it/s]\titers: 300, epoch: 4 | loss: 0.4598480\n",
      "\tspeed: 0.0394s/iter; left time: 27406.8247s\n",
      "399it [00:16, 25.83it/s]\titers: 400, epoch: 4 | loss: 0.5798229\n",
      "\tspeed: 0.0389s/iter; left time: 27049.8917s\n",
      "498it [00:20, 23.13it/s]\titers: 500, epoch: 4 | loss: 0.1326764\n",
      "\tspeed: 0.0407s/iter; left time: 28319.1146s\n",
      "597it [00:24, 19.84it/s]\titers: 600, epoch: 4 | loss: 0.1967918\n",
      "\tspeed: 0.0457s/iter; left time: 31766.6752s\n",
      "698it [00:30, 17.48it/s]\titers: 700, epoch: 4 | loss: 0.3609470\n",
      "\tspeed: 0.0556s/iter; left time: 38695.0977s\n",
      "798it [00:34, 25.11it/s]\titers: 800, epoch: 4 | loss: 0.3166209\n",
      "\tspeed: 0.0400s/iter; left time: 27828.7832s\n",
      "897it [00:38, 23.91it/s]\titers: 900, epoch: 4 | loss: 0.5740969\n",
      "\tspeed: 0.0395s/iter; left time: 27503.5805s\n",
      "999it [00:42, 25.42it/s]\titers: 1000, epoch: 4 | loss: 0.1984566\n",
      "\tspeed: 0.0397s/iter; left time: 27637.6866s\n",
      "1098it [00:46, 23.79it/s]\titers: 1100, epoch: 4 | loss: 0.3934523\n",
      "\tspeed: 0.0401s/iter; left time: 27901.0699s\n",
      "1197it [00:50, 25.67it/s]\titers: 1200, epoch: 4 | loss: 0.4173949\n",
      "\tspeed: 0.0397s/iter; left time: 27614.1696s\n",
      "1299it [00:54, 20.65it/s]\titers: 1300, epoch: 4 | loss: 0.5176777\n",
      "\tspeed: 0.0410s/iter; left time: 28462.4984s\n",
      "1398it [00:59, 19.13it/s]\titers: 1400, epoch: 4 | loss: 0.2067561\n",
      "\tspeed: 0.0480s/iter; left time: 33365.6239s\n",
      "1499it [01:04, 16.96it/s]\titers: 1500, epoch: 4 | loss: 0.3225462\n",
      "\tspeed: 0.0571s/iter; left time: 39702.7175s\n",
      "1599it [01:09, 25.04it/s]\titers: 1600, epoch: 4 | loss: 0.3932137\n",
      "\tspeed: 0.0487s/iter; left time: 33853.0471s\n",
      "1698it [01:13, 26.00it/s]\titers: 1700, epoch: 4 | loss: 0.1678384\n",
      "\tspeed: 0.0391s/iter; left time: 27126.6317s\n",
      "1797it [01:17, 25.39it/s]\titers: 1800, epoch: 4 | loss: 0.2228955\n",
      "\tspeed: 0.0400s/iter; left time: 27766.6850s\n",
      "1899it [01:21, 25.00it/s]\titers: 1900, epoch: 4 | loss: 0.2714488\n",
      "\tspeed: 0.0398s/iter; left time: 27640.2892s\n",
      "1998it [01:25, 25.31it/s]\titers: 2000, epoch: 4 | loss: 0.3282716\n",
      "\tspeed: 0.0390s/iter; left time: 27061.8141s\n",
      "2097it [01:29, 26.59it/s]\titers: 2100, epoch: 4 | loss: 0.5041998\n",
      "\tspeed: 0.0395s/iter; left time: 27390.4554s\n",
      "2196it [01:32, 27.58it/s]\titers: 2200, epoch: 4 | loss: 0.2559320\n",
      "\tspeed: 0.0369s/iter; left time: 25628.0802s\n",
      "2299it [01:37, 25.84it/s]\titers: 2300, epoch: 4 | loss: 0.2062184\n",
      "\tspeed: 0.0404s/iter; left time: 28041.5926s\n",
      "2399it [01:41, 27.91it/s]\titers: 2400, epoch: 4 | loss: 0.5267666\n",
      "\tspeed: 0.0390s/iter; left time: 27096.1428s\n",
      "2499it [01:46, 20.28it/s]\titers: 2500, epoch: 4 | loss: 0.4842477\n",
      "\tspeed: 0.0544s/iter; left time: 37718.6158s\n",
      "2598it [01:50, 25.84it/s]\titers: 2600, epoch: 4 | loss: 0.7529700\n",
      "\tspeed: 0.0395s/iter; left time: 27421.4382s\n",
      "2697it [01:54, 24.57it/s]\titers: 2700, epoch: 4 | loss: 0.1168044\n",
      "\tspeed: 0.0394s/iter; left time: 27319.1376s\n",
      "2799it [01:58, 26.32it/s]\titers: 2800, epoch: 4 | loss: 0.1384799\n",
      "\tspeed: 0.0393s/iter; left time: 27264.4845s\n",
      "2898it [02:02, 25.32it/s]\titers: 2900, epoch: 4 | loss: 0.2483453\n",
      "\tspeed: 0.0394s/iter; left time: 27306.8744s\n",
      "2997it [02:06, 25.38it/s]\titers: 3000, epoch: 4 | loss: 0.3224004\n",
      "\tspeed: 0.0399s/iter; left time: 27670.3127s\n",
      "3099it [02:10, 22.10it/s]\titers: 3100, epoch: 4 | loss: 0.2620616\n",
      "\tspeed: 0.0419s/iter; left time: 29068.7220s\n",
      "3197it [02:15, 17.42it/s]\titers: 3200, epoch: 4 | loss: 0.4142838\n",
      "\tspeed: 0.0499s/iter; left time: 34585.6873s\n",
      "3298it [02:20, 19.92it/s]\titers: 3300, epoch: 4 | loss: 0.2170057\n",
      "\tspeed: 0.0529s/iter; left time: 36686.1339s\n",
      "3397it [02:25, 25.79it/s]\titers: 3400, epoch: 4 | loss: 0.1696144\n",
      "\tspeed: 0.0445s/iter; left time: 30809.9351s\n",
      "3499it [02:29, 25.03it/s]\titers: 3500, epoch: 4 | loss: 0.7560053\n",
      "\tspeed: 0.0397s/iter; left time: 27537.8914s\n",
      "3598it [02:32, 26.22it/s]\titers: 3600, epoch: 4 | loss: 0.4330556\n",
      "\tspeed: 0.0384s/iter; left time: 26602.3373s\n",
      "3697it [02:36, 25.31it/s]\titers: 3700, epoch: 4 | loss: 0.2990661\n",
      "\tspeed: 0.0392s/iter; left time: 27182.0588s\n",
      "3798it [02:41, 20.12it/s]\titers: 3800, epoch: 4 | loss: 0.4807670\n",
      "\tspeed: 0.0453s/iter; left time: 31356.7400s\n",
      "3898it [02:46, 19.32it/s]\titers: 3900, epoch: 4 | loss: 0.3955661\n",
      "\tspeed: 0.0507s/iter; left time: 35125.9809s\n",
      "3998it [02:51, 18.30it/s]\titers: 4000, epoch: 4 | loss: 0.2707709\n",
      "\tspeed: 0.0489s/iter; left time: 33885.7271s\n",
      "4098it [02:56, 17.73it/s]\titers: 4100, epoch: 4 | loss: 0.2177304\n",
      "\tspeed: 0.0488s/iter; left time: 33790.6187s\n",
      "4198it [03:01, 23.77it/s]\titers: 4200, epoch: 4 | loss: 0.4702105\n",
      "\tspeed: 0.0510s/iter; left time: 35282.2473s\n",
      "4297it [03:05, 26.06it/s]\titers: 4300, epoch: 4 | loss: 0.4923164\n",
      "\tspeed: 0.0383s/iter; left time: 26471.5473s\n",
      "4399it [03:08, 26.45it/s]\titers: 4400, epoch: 4 | loss: 0.2345471\n",
      "\tspeed: 0.0383s/iter; left time: 26515.0320s\n",
      "4499it [03:13, 24.41it/s]\titers: 4500, epoch: 4 | loss: 0.3321971\n",
      "\tspeed: 0.0404s/iter; left time: 27920.9208s\n",
      "4598it [03:17, 21.06it/s]\titers: 4600, epoch: 4 | loss: 0.3117181\n",
      "\tspeed: 0.0473s/iter; left time: 32736.3124s\n",
      "4699it [03:22, 26.30it/s]\titers: 4700, epoch: 4 | loss: 0.2367174\n",
      "\tspeed: 0.0430s/iter; left time: 29774.5375s\n",
      "4798it [03:26, 25.76it/s]\titers: 4800, epoch: 4 | loss: 0.1028031\n",
      "\tspeed: 0.0399s/iter; left time: 27577.0952s\n",
      "4898it [03:30, 20.13it/s]\titers: 4900, epoch: 4 | loss: 0.6673850\n",
      "\tspeed: 0.0474s/iter; left time: 32760.5266s\n",
      "4999it [03:35, 20.66it/s]\titers: 5000, epoch: 4 | loss: 0.2865047\n",
      "\tspeed: 0.0515s/iter; left time: 35574.0990s\n",
      "5097it [03:40, 26.73it/s]\titers: 5100, epoch: 4 | loss: 0.2150929\n",
      "\tspeed: 0.0434s/iter; left time: 30026.6219s\n",
      "5199it [03:44, 24.30it/s]\titers: 5200, epoch: 4 | loss: 0.1405899\n",
      "\tspeed: 0.0391s/iter; left time: 27027.6999s\n",
      "5297it [03:49, 23.26it/s]\titers: 5300, epoch: 4 | loss: 0.3389138\n",
      "\tspeed: 0.0490s/iter; left time: 33873.0963s\n",
      "5398it [03:54, 18.81it/s]\titers: 5400, epoch: 4 | loss: 0.1850120\n",
      "\tspeed: 0.0511s/iter; left time: 35297.4296s\n",
      "5498it [03:58, 24.47it/s]\titers: 5500, epoch: 4 | loss: 0.2476273\n",
      "\tspeed: 0.0429s/iter; left time: 29649.7377s\n",
      "5597it [04:02, 24.55it/s]\titers: 5600, epoch: 4 | loss: 0.1880543\n",
      "\tspeed: 0.0390s/iter; left time: 26946.1660s\n",
      "5699it [04:06, 20.80it/s]\titers: 5700, epoch: 4 | loss: 0.7938313\n",
      "\tspeed: 0.0421s/iter; left time: 29106.7338s\n",
      "5799it [04:11, 18.98it/s]\titers: 5800, epoch: 4 | loss: 0.2925030\n",
      "\tspeed: 0.0468s/iter; left time: 32326.8439s\n",
      "5899it [04:16, 24.61it/s]\titers: 5900, epoch: 4 | loss: 0.2032930\n",
      "\tspeed: 0.0486s/iter; left time: 33584.9597s\n",
      "5998it [04:20, 24.57it/s]\titers: 6000, epoch: 4 | loss: 0.2319914\n",
      "\tspeed: 0.0398s/iter; left time: 27473.9707s\n",
      "6097it [04:24, 24.17it/s]\titers: 6100, epoch: 4 | loss: 0.1932314\n",
      "\tspeed: 0.0419s/iter; left time: 28939.8979s\n",
      "6199it [04:28, 25.59it/s]\titers: 6200, epoch: 4 | loss: 0.1821531\n",
      "\tspeed: 0.0412s/iter; left time: 28415.7026s\n",
      "6298it [04:32, 26.42it/s]\titers: 6300, epoch: 4 | loss: 0.5295746\n",
      "\tspeed: 0.0389s/iter; left time: 26865.6677s\n",
      "6397it [04:36, 25.61it/s]\titers: 6400, epoch: 4 | loss: 0.1748666\n",
      "\tspeed: 0.0392s/iter; left time: 27077.1248s\n",
      "6499it [04:40, 24.77it/s]\titers: 6500, epoch: 4 | loss: 0.7527309\n",
      "\tspeed: 0.0411s/iter; left time: 28349.2405s\n",
      "6598it [04:45, 18.94it/s]\titers: 6600, epoch: 4 | loss: 0.5236177\n",
      "\tspeed: 0.0475s/iter; left time: 32786.9138s\n",
      "6697it [04:49, 23.05it/s]\titers: 6700, epoch: 4 | loss: 0.3865529\n",
      "\tspeed: 0.0457s/iter; left time: 31518.2417s\n",
      "6797it [04:54, 22.72it/s]\titers: 6800, epoch: 4 | loss: 0.3114258\n",
      "\tspeed: 0.0482s/iter; left time: 33269.3231s\n",
      "6897it [04:58, 25.33it/s]\titers: 6900, epoch: 4 | loss: 0.2576486\n",
      "\tspeed: 0.0448s/iter; left time: 30869.2107s\n",
      "6999it [05:02, 25.25it/s]\titers: 7000, epoch: 4 | loss: 0.3224902\n",
      "\tspeed: 0.0396s/iter; left time: 27305.8309s\n",
      "7098it [05:06, 25.47it/s]\titers: 7100, epoch: 4 | loss: 0.3550968\n",
      "\tspeed: 0.0403s/iter; left time: 27767.0753s\n",
      "7197it [05:10, 26.47it/s]\titers: 7200, epoch: 4 | loss: 0.1952577\n",
      "\tspeed: 0.0393s/iter; left time: 27059.2875s\n",
      "7299it [05:14, 25.80it/s]\titers: 7300, epoch: 4 | loss: 0.4378886\n",
      "\tspeed: 0.0386s/iter; left time: 26570.4550s\n",
      "7398it [05:19, 19.49it/s]\titers: 7400, epoch: 4 | loss: 0.1974247\n",
      "\tspeed: 0.0442s/iter; left time: 30430.4351s\n",
      "7497it [05:23, 24.32it/s]\titers: 7500, epoch: 4 | loss: 0.3388119\n",
      "\tspeed: 0.0480s/iter; left time: 33060.7622s\n",
      "7598it [05:29, 22.11it/s]\titers: 7600, epoch: 4 | loss: 0.1495921\n",
      "\tspeed: 0.0543s/iter; left time: 37428.9975s\n",
      "7697it [05:33, 21.50it/s]\titers: 7700, epoch: 4 | loss: 0.3614186\n",
      "\tspeed: 0.0443s/iter; left time: 30537.2713s\n",
      "7797it [05:38, 19.57it/s]\titers: 7800, epoch: 4 | loss: 0.3088455\n",
      "\tspeed: 0.0484s/iter; left time: 33299.6672s\n",
      "7899it [05:42, 26.01it/s]\titers: 7900, epoch: 4 | loss: 0.1491339\n",
      "\tspeed: 0.0393s/iter; left time: 27037.8525s\n",
      "7999it [05:46, 26.84it/s]\titers: 8000, epoch: 4 | loss: 0.5961709\n",
      "\tspeed: 0.0383s/iter; left time: 26373.4923s\n",
      "8098it [05:50, 24.92it/s]\titers: 8100, epoch: 4 | loss: 0.1923337\n",
      "\tspeed: 0.0388s/iter; left time: 26725.1390s\n",
      "8197it [05:54, 23.90it/s]\titers: 8200, epoch: 4 | loss: 0.1876185\n",
      "\tspeed: 0.0391s/iter; left time: 26893.0717s\n",
      "8299it [05:59, 19.01it/s]\titers: 8300, epoch: 4 | loss: 0.2311641\n",
      "\tspeed: 0.0482s/iter; left time: 33133.9355s\n",
      "8399it [06:04, 17.51it/s]\titers: 8400, epoch: 4 | loss: 0.1094585\n",
      "\tspeed: 0.0503s/iter; left time: 34571.9450s\n",
      "8498it [06:08, 22.34it/s]\titers: 8500, epoch: 4 | loss: 0.5112658\n",
      "\tspeed: 0.0491s/iter; left time: 33751.0186s\n",
      "8597it [06:12, 25.88it/s]\titers: 8600, epoch: 4 | loss: 0.8517913\n",
      "\tspeed: 0.0403s/iter; left time: 27735.9618s\n",
      "8699it [06:17, 25.61it/s]\titers: 8700, epoch: 4 | loss: 0.5551071\n",
      "\tspeed: 0.0399s/iter; left time: 27414.1379s\n",
      "8798it [06:20, 25.11it/s]\titers: 8800, epoch: 4 | loss: 0.7695784\n",
      "\tspeed: 0.0394s/iter; left time: 27115.8331s\n",
      "8897it [06:24, 25.61it/s]\titers: 8900, epoch: 4 | loss: 0.2341888\n",
      "\tspeed: 0.0391s/iter; left time: 26846.7703s\n",
      "8999it [06:28, 24.49it/s]\titers: 9000, epoch: 4 | loss: 0.1800662\n",
      "\tspeed: 0.0395s/iter; left time: 27121.2851s\n",
      "9098it [06:32, 25.93it/s]\titers: 9100, epoch: 4 | loss: 0.1074979\n",
      "\tspeed: 0.0381s/iter; left time: 26195.3319s\n",
      "9199it [06:37, 17.83it/s]\titers: 9200, epoch: 4 | loss: 0.3280586\n",
      "\tspeed: 0.0457s/iter; left time: 31379.5147s\n",
      "9298it [06:42, 23.29it/s]\titers: 9300, epoch: 4 | loss: 0.4468344\n",
      "\tspeed: 0.0517s/iter; left time: 35525.4729s\n",
      "9398it [06:46, 26.83it/s]\titers: 9400, epoch: 4 | loss: 0.3205627\n",
      "\tspeed: 0.0409s/iter; left time: 28075.9666s\n",
      "9497it [06:50, 25.63it/s]\titers: 9500, epoch: 4 | loss: 0.2715108\n",
      "\tspeed: 0.0388s/iter; left time: 26635.8402s\n",
      "9599it [06:54, 25.13it/s]\titers: 9600, epoch: 4 | loss: 0.7816707\n",
      "\tspeed: 0.0389s/iter; left time: 26714.6777s\n",
      "9698it [06:58, 24.55it/s]\titers: 9700, epoch: 4 | loss: 0.3189777\n",
      "\tspeed: 0.0394s/iter; left time: 27026.9428s\n",
      "9797it [07:02, 24.03it/s]\titers: 9800, epoch: 4 | loss: 0.3257591\n",
      "\tspeed: 0.0395s/iter; left time: 27146.3007s\n",
      "9899it [07:06, 23.02it/s]\titers: 9900, epoch: 4 | loss: 0.4948491\n",
      "\tspeed: 0.0436s/iter; left time: 29918.2570s\n",
      "9997it [07:10, 21.40it/s]\titers: 10000, epoch: 4 | loss: 0.5580814\n",
      "\tspeed: 0.0450s/iter; left time: 30854.5481s\n",
      "10098it [07:15, 27.97it/s]\titers: 10100, epoch: 4 | loss: 0.5118344\n",
      "\tspeed: 0.0482s/iter; left time: 33055.7674s\n",
      "10198it [07:20, 24.00it/s]\titers: 10200, epoch: 4 | loss: 0.1615215\n",
      "\tspeed: 0.0492s/iter; left time: 33791.1912s\n",
      "10297it [07:24, 26.94it/s]\titers: 10300, epoch: 4 | loss: 0.3331116\n",
      "\tspeed: 0.0385s/iter; left time: 26425.9682s\n",
      "10399it [07:28, 24.84it/s]\titers: 10400, epoch: 4 | loss: 0.2779110\n",
      "\tspeed: 0.0391s/iter; left time: 26798.7008s\n",
      "10498it [07:32, 25.82it/s]\titers: 10500, epoch: 4 | loss: 0.1683977\n",
      "\tspeed: 0.0386s/iter; left time: 26466.8855s\n",
      "10597it [07:36, 24.50it/s]\titers: 10600, epoch: 4 | loss: 0.8855260\n",
      "\tspeed: 0.0392s/iter; left time: 26876.0165s\n",
      "10699it [07:40, 21.44it/s]\titers: 10700, epoch: 4 | loss: 0.1622652\n",
      "\tspeed: 0.0416s/iter; left time: 28533.6096s\n",
      "10797it [07:44, 23.01it/s]\titers: 10800, epoch: 4 | loss: 0.2489486\n",
      "\tspeed: 0.0452s/iter; left time: 30989.9784s\n",
      "10899it [07:49, 19.40it/s]\titers: 10900, epoch: 4 | loss: 0.0938203\n",
      "\tspeed: 0.0500s/iter; left time: 34269.2491s\n",
      "10997it [07:54, 18.56it/s]\titers: 11000, epoch: 4 | loss: 0.2342716\n",
      "\tspeed: 0.0512s/iter; left time: 35068.0235s\n",
      "11097it [07:59, 25.37it/s]\titers: 11100, epoch: 4 | loss: 0.3211882\n",
      "\tspeed: 0.0436s/iter; left time: 29854.2128s\n",
      "11199it [08:03, 26.33it/s]\titers: 11200, epoch: 4 | loss: 0.2170032\n",
      "\tspeed: 0.0381s/iter; left time: 26106.3316s\n",
      "11298it [08:07, 23.23it/s]\titers: 11300, epoch: 4 | loss: 0.3801545\n",
      "\tspeed: 0.0393s/iter; left time: 26904.8589s\n",
      "11397it [08:11, 21.18it/s]\titers: 11400, epoch: 4 | loss: 0.2316433\n",
      "\tspeed: 0.0413s/iter; left time: 28276.1893s\n",
      "11497it [08:16, 20.12it/s]\titers: 11500, epoch: 4 | loss: 0.7608374\n",
      "\tspeed: 0.0506s/iter; left time: 34664.6809s\n",
      "11599it [08:20, 24.53it/s]\titers: 11600, epoch: 4 | loss: 0.4211630\n",
      "\tspeed: 0.0399s/iter; left time: 27333.1365s\n",
      "11698it [08:24, 23.25it/s]\titers: 11700, epoch: 4 | loss: 0.2846328\n",
      "\tspeed: 0.0441s/iter; left time: 30181.3895s\n",
      "11799it [08:29, 19.92it/s]\titers: 11800, epoch: 4 | loss: 0.6524413\n",
      "\tspeed: 0.0508s/iter; left time: 34767.5133s\n",
      "11899it [08:34, 25.54it/s]\titers: 11900, epoch: 4 | loss: 0.6007652\n",
      "\tspeed: 0.0506s/iter; left time: 34629.9630s\n",
      "11997it [08:38, 27.51it/s]\titers: 12000, epoch: 4 | loss: 0.9528483\n",
      "\tspeed: 0.0390s/iter; left time: 26666.6965s\n",
      "12099it [08:42, 21.42it/s]\titers: 12100, epoch: 4 | loss: 0.2187259\n",
      "\tspeed: 0.0420s/iter; left time: 28755.1751s\n",
      "12197it [08:47, 23.80it/s]\titers: 12200, epoch: 4 | loss: 0.3670602\n",
      "\tspeed: 0.0470s/iter; left time: 32183.3139s\n",
      "12299it [08:52, 21.86it/s]\titers: 12300, epoch: 4 | loss: 0.3197168\n",
      "\tspeed: 0.0493s/iter; left time: 33702.1989s\n",
      "12398it [08:56, 25.56it/s]\titers: 12400, epoch: 4 | loss: 0.3553059\n",
      "\tspeed: 0.0399s/iter; left time: 27285.6318s\n",
      "12498it [09:00, 22.08it/s]\titers: 12500, epoch: 4 | loss: 0.1944313\n",
      "\tspeed: 0.0410s/iter; left time: 28009.7528s\n",
      "12599it [09:05, 19.19it/s]\titers: 12600, epoch: 4 | loss: 0.2476454\n",
      "\tspeed: 0.0487s/iter; left time: 33289.5744s\n",
      "12699it [09:10, 20.31it/s]\titers: 12700, epoch: 4 | loss: 0.3414422\n",
      "\tspeed: 0.0499s/iter; left time: 34137.4774s\n",
      "12797it [09:14, 23.75it/s]\titers: 12800, epoch: 4 | loss: 0.1749693\n",
      "\tspeed: 0.0414s/iter; left time: 28309.6147s\n",
      "12899it [09:19, 20.20it/s]\titers: 12900, epoch: 4 | loss: 0.3390207\n",
      "\tspeed: 0.0442s/iter; left time: 30228.9476s\n",
      "12998it [09:24, 23.12it/s]\titers: 13000, epoch: 4 | loss: 0.5696311\n",
      "\tspeed: 0.0513s/iter; left time: 35059.8759s\n",
      "13097it [09:27, 25.15it/s]\titers: 13100, epoch: 4 | loss: 0.6844093\n",
      "\tspeed: 0.0386s/iter; left time: 26390.2656s\n",
      "13199it [09:32, 24.75it/s]\titers: 13200, epoch: 4 | loss: 0.1756243\n",
      "\tspeed: 0.0404s/iter; left time: 27592.8887s\n",
      "13298it [09:36, 24.51it/s]\titers: 13300, epoch: 4 | loss: 0.3554517\n",
      "\tspeed: 0.0400s/iter; left time: 27290.1341s\n",
      "13398it [09:40, 22.56it/s]\titers: 13400, epoch: 4 | loss: 0.3102037\n",
      "\tspeed: 0.0481s/iter; left time: 32855.8405s\n",
      "13498it [09:45, 20.39it/s]\titers: 13500, epoch: 4 | loss: 0.1527738\n",
      "\tspeed: 0.0479s/iter; left time: 32714.2508s\n",
      "13598it [09:50, 19.83it/s]\titers: 13600, epoch: 4 | loss: 0.1615803\n",
      "\tspeed: 0.0461s/iter; left time: 31492.3236s\n",
      "13697it [09:54, 26.14it/s]\titers: 13700, epoch: 4 | loss: 0.5721961\n",
      "\tspeed: 0.0451s/iter; left time: 30763.9658s\n",
      "13799it [09:58, 25.54it/s]\titers: 13800, epoch: 4 | loss: 0.2614636\n",
      "\tspeed: 0.0384s/iter; left time: 26212.9540s\n",
      "13898it [10:02, 25.62it/s]\titers: 13900, epoch: 4 | loss: 0.2688888\n",
      "\tspeed: 0.0392s/iter; left time: 26747.6771s\n",
      "13997it [10:06, 25.94it/s]\titers: 14000, epoch: 4 | loss: 0.2451988\n",
      "\tspeed: 0.0394s/iter; left time: 26868.9476s\n",
      "14099it [10:10, 24.13it/s]\titers: 14100, epoch: 4 | loss: 0.4797363\n",
      "\tspeed: 0.0391s/iter; left time: 26680.6246s\n",
      "14198it [10:14, 22.88it/s]\titers: 14200, epoch: 4 | loss: 0.4740672\n",
      "\tspeed: 0.0408s/iter; left time: 27836.9015s\n",
      "14299it [10:19, 17.77it/s]\titers: 14300, epoch: 4 | loss: 0.4097959\n",
      "\tspeed: 0.0491s/iter; left time: 33495.3432s\n",
      "14399it [10:24, 16.83it/s]\titers: 14400, epoch: 4 | loss: 0.3076765\n",
      "\tspeed: 0.0554s/iter; left time: 37747.3348s\n",
      "14498it [10:29, 23.58it/s]\titers: 14500, epoch: 4 | loss: 0.1715812\n",
      "\tspeed: 0.0468s/iter; left time: 31908.9343s\n",
      "14597it [10:33, 25.09it/s]\titers: 14600, epoch: 4 | loss: 0.2668757\n",
      "\tspeed: 0.0389s/iter; left time: 26488.4641s\n",
      "14699it [10:37, 26.13it/s]\titers: 14700, epoch: 4 | loss: 0.5848483\n",
      "\tspeed: 0.0390s/iter; left time: 26563.0396s\n",
      "14798it [10:41, 24.02it/s]\titers: 14800, epoch: 4 | loss: 0.4444878\n",
      "\tspeed: 0.0403s/iter; left time: 27475.5408s\n",
      "14816it [10:42, 23.07it/s]\n",
      "Epoch: 4 cost time: 642.2037568092346\n",
      "3204it [01:08, 46.74it/s]\n",
      "3192it [01:11, 44.92it/s]\n",
      "Epoch: 4 | Train Loss: 0.3587150 Vali Loss: 0.4554109 Test Loss: 0.5913868 MAE Loss: 0.4858288\n",
      "Validation loss decreased (0.464625 --> 0.455411).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:05, 23.48it/s]\titers: 100, epoch: 5 | loss: 0.2305460\n",
      "\tspeed: 1.4707s/iter; left time: 1002166.4843s\n",
      "198it [00:09, 25.79it/s]\titers: 200, epoch: 5 | loss: 0.3015937\n",
      "\tspeed: 0.0396s/iter; left time: 26981.3987s\n",
      "297it [00:13, 25.51it/s]\titers: 300, epoch: 5 | loss: 0.2217310\n",
      "\tspeed: 0.0413s/iter; left time: 28144.7057s\n",
      "399it [00:17, 20.33it/s]\titers: 400, epoch: 5 | loss: 0.1750264\n",
      "\tspeed: 0.0452s/iter; left time: 30797.2643s\n",
      "499it [00:23, 21.13it/s]\titers: 500, epoch: 5 | loss: 0.1464007\n",
      "\tspeed: 0.0510s/iter; left time: 34754.3925s\n",
      "597it [00:27, 25.22it/s]\titers: 600, epoch: 5 | loss: 0.5857660\n",
      "\tspeed: 0.0474s/iter; left time: 32260.0135s\n",
      "699it [00:32, 19.83it/s]\titers: 700, epoch: 5 | loss: 0.2663194\n",
      "\tspeed: 0.0436s/iter; left time: 29702.2540s\n",
      "797it [00:36, 23.68it/s]\titers: 800, epoch: 5 | loss: 0.7587684\n",
      "\tspeed: 0.0470s/iter; left time: 31994.0372s\n",
      "899it [00:40, 25.97it/s]\titers: 900, epoch: 5 | loss: 0.8071168\n",
      "\tspeed: 0.0395s/iter; left time: 26869.8802s\n",
      "998it [00:44, 25.62it/s]\titers: 1000, epoch: 5 | loss: 0.1965312\n",
      "\tspeed: 0.0403s/iter; left time: 27450.8014s\n",
      "1097it [00:48, 25.18it/s]\titers: 1100, epoch: 5 | loss: 0.5681382\n",
      "\tspeed: 0.0395s/iter; left time: 26902.0991s\n",
      "1199it [00:52, 23.32it/s]\titers: 1200, epoch: 5 | loss: 0.4995774\n",
      "\tspeed: 0.0417s/iter; left time: 28351.1273s\n",
      "1298it [00:57, 23.28it/s]\titers: 1300, epoch: 5 | loss: 0.2595541\n",
      "\tspeed: 0.0457s/iter; left time: 31097.2765s\n",
      "1399it [01:02, 16.79it/s]\titers: 1400, epoch: 5 | loss: 0.6290879\n",
      "\tspeed: 0.0524s/iter; left time: 35647.0694s\n",
      "1499it [01:07, 20.33it/s]\titers: 1500, epoch: 5 | loss: 0.1669912\n",
      "\tspeed: 0.0483s/iter; left time: 32817.6580s\n",
      "1597it [01:11, 23.86it/s]\titers: 1600, epoch: 5 | loss: 0.3762224\n",
      "\tspeed: 0.0449s/iter; left time: 30548.2841s\n",
      "1699it [01:15, 25.51it/s]\titers: 1700, epoch: 5 | loss: 0.3205333\n",
      "\tspeed: 0.0391s/iter; left time: 26573.9801s\n",
      "1798it [01:19, 24.20it/s]\titers: 1800, epoch: 5 | loss: 0.3452498\n",
      "\tspeed: 0.0393s/iter; left time: 26705.5793s\n",
      "1897it [01:23, 25.01it/s]\titers: 1900, epoch: 5 | loss: 0.3985712\n",
      "\tspeed: 0.0400s/iter; left time: 27177.7119s\n",
      "1999it [01:27, 24.77it/s]\titers: 2000, epoch: 5 | loss: 0.2490063\n",
      "\tspeed: 0.0403s/iter; left time: 27406.2861s\n",
      "2098it [01:32, 19.53it/s]\titers: 2100, epoch: 5 | loss: 0.2194353\n",
      "\tspeed: 0.0465s/iter; left time: 31599.5475s\n",
      "2199it [01:37, 17.10it/s]\titers: 2200, epoch: 5 | loss: 0.1179004\n",
      "\tspeed: 0.0497s/iter; left time: 33776.3903s\n",
      "2299it [01:42, 23.55it/s]\titers: 2300, epoch: 5 | loss: 0.1489922\n",
      "\tspeed: 0.0470s/iter; left time: 31934.1782s\n",
      "2398it [01:46, 25.69it/s]\titers: 2400, epoch: 5 | loss: 0.4922327\n",
      "\tspeed: 0.0396s/iter; left time: 26881.9358s\n",
      "2497it [01:50, 23.49it/s]\titers: 2500, epoch: 5 | loss: 0.6501368\n",
      "\tspeed: 0.0414s/iter; left time: 28088.7727s\n",
      "2599it [01:54, 23.90it/s]\titers: 2600, epoch: 5 | loss: 0.6103395\n",
      "\tspeed: 0.0405s/iter; left time: 27504.5934s\n",
      "2698it [01:58, 25.17it/s]\titers: 2700, epoch: 5 | loss: 0.1558691\n",
      "\tspeed: 0.0395s/iter; left time: 26783.7106s\n",
      "2797it [02:02, 25.47it/s]\titers: 2800, epoch: 5 | loss: 0.1937745\n",
      "\tspeed: 0.0396s/iter; left time: 26896.7813s\n",
      "2899it [02:06, 19.54it/s]\titers: 2900, epoch: 5 | loss: 0.2215296\n",
      "\tspeed: 0.0423s/iter; left time: 28704.3535s\n",
      "2997it [02:11, 22.01it/s]\titers: 3000, epoch: 5 | loss: 0.3014736\n",
      "\tspeed: 0.0504s/iter; left time: 34184.8016s\n",
      "3099it [02:16, 18.18it/s]\titers: 3100, epoch: 5 | loss: 0.0991576\n",
      "\tspeed: 0.0529s/iter; left time: 35914.3304s\n",
      "3199it [02:21, 25.63it/s]\titers: 3200, epoch: 5 | loss: 0.2663908\n",
      "\tspeed: 0.0416s/iter; left time: 28246.0499s\n",
      "3298it [02:24, 24.45it/s]\titers: 3300, epoch: 5 | loss: 0.1465067\n",
      "\tspeed: 0.0400s/iter; left time: 27145.5178s\n",
      "3397it [02:28, 24.59it/s]\titers: 3400, epoch: 5 | loss: 0.5886030\n",
      "\tspeed: 0.0387s/iter; left time: 26266.1969s\n",
      "3499it [02:32, 23.91it/s]\titers: 3500, epoch: 5 | loss: 0.1948348\n",
      "\tspeed: 0.0400s/iter; left time: 27133.9292s\n",
      "3598it [02:37, 23.65it/s]\titers: 3600, epoch: 5 | loss: 0.2542295\n",
      "\tspeed: 0.0432s/iter; left time: 29279.9584s\n",
      "3697it [02:41, 26.15it/s]\titers: 3700, epoch: 5 | loss: 0.1513371\n",
      "\tspeed: 0.0432s/iter; left time: 29305.9492s\n",
      "3799it [02:45, 21.27it/s]\titers: 3800, epoch: 5 | loss: 0.1162978\n",
      "\tspeed: 0.0419s/iter; left time: 28372.9058s\n",
      "3899it [02:50, 19.63it/s]\titers: 3900, epoch: 5 | loss: 0.2993306\n",
      "\tspeed: 0.0467s/iter; left time: 31635.0920s\n",
      "3999it [02:55, 25.77it/s]\titers: 4000, epoch: 5 | loss: 0.2700831\n",
      "\tspeed: 0.0475s/iter; left time: 32208.4642s\n",
      "4098it [02:59, 25.30it/s]\titers: 4100, epoch: 5 | loss: 0.5472832\n",
      "\tspeed: 0.0390s/iter; left time: 26439.9453s\n",
      "4197it [03:02, 25.40it/s]\titers: 4200, epoch: 5 | loss: 0.1980574\n",
      "\tspeed: 0.0390s/iter; left time: 26392.0849s\n",
      "4299it [03:07, 20.62it/s]\titers: 4300, epoch: 5 | loss: 0.2478197\n",
      "\tspeed: 0.0436s/iter; left time: 29532.3668s\n",
      "4398it [03:11, 22.66it/s]\titers: 4400, epoch: 5 | loss: 0.2503526\n",
      "\tspeed: 0.0434s/iter; left time: 29364.1650s\n",
      "4498it [03:16, 21.17it/s]\titers: 4500, epoch: 5 | loss: 0.5079444\n",
      "\tspeed: 0.0490s/iter; left time: 33204.1805s\n",
      "4597it [03:20, 24.25it/s]\titers: 4600, epoch: 5 | loss: 0.3260390\n",
      "\tspeed: 0.0411s/iter; left time: 27847.1665s\n",
      "4697it [03:25, 19.22it/s]\titers: 4700, epoch: 5 | loss: 0.2476656\n",
      "\tspeed: 0.0479s/iter; left time: 32389.3346s\n",
      "4797it [03:30, 19.46it/s]\titers: 4800, epoch: 5 | loss: 0.6840523\n",
      "\tspeed: 0.0524s/iter; left time: 35480.0142s\n",
      "4897it [03:34, 25.30it/s]\titers: 4900, epoch: 5 | loss: 0.3117846\n",
      "\tspeed: 0.0435s/iter; left time: 29421.2660s\n",
      "4999it [03:38, 25.45it/s]\titers: 5000, epoch: 5 | loss: 0.4344593\n",
      "\tspeed: 0.0391s/iter; left time: 26428.5444s\n",
      "5098it [03:42, 25.02it/s]\titers: 5100, epoch: 5 | loss: 0.5087878\n",
      "\tspeed: 0.0406s/iter; left time: 27434.2300s\n",
      "5197it [03:47, 20.67it/s]\titers: 5200, epoch: 5 | loss: 0.4104542\n",
      "\tspeed: 0.0479s/iter; left time: 32421.8827s\n",
      "5298it [03:51, 25.31it/s]\titers: 5300, epoch: 5 | loss: 0.2145871\n",
      "\tspeed: 0.0417s/iter; left time: 28214.2049s\n",
      "5397it [03:55, 25.38it/s]\titers: 5400, epoch: 5 | loss: 0.1686769\n",
      "\tspeed: 0.0406s/iter; left time: 27447.0672s\n",
      "5498it [04:00, 21.53it/s]\titers: 5500, epoch: 5 | loss: 0.2485573\n",
      "\tspeed: 0.0450s/iter; left time: 30391.2552s\n",
      "5597it [04:05, 18.96it/s]\titers: 5600, epoch: 5 | loss: 0.3030496\n",
      "\tspeed: 0.0487s/iter; left time: 32920.5162s\n",
      "5698it [04:10, 20.36it/s]\titers: 5700, epoch: 5 | loss: 0.5883042\n",
      "\tspeed: 0.0529s/iter; left time: 35750.0030s\n",
      "5798it [04:14, 23.59it/s]\titers: 5800, epoch: 5 | loss: 0.3044241\n",
      "\tspeed: 0.0404s/iter; left time: 27306.0755s\n",
      "5898it [04:19, 19.59it/s]\titers: 5900, epoch: 5 | loss: 0.3543423\n",
      "\tspeed: 0.0490s/iter; left time: 33073.7535s\n",
      "5998it [04:24, 18.96it/s]\titers: 6000, epoch: 5 | loss: 0.1771447\n",
      "\tspeed: 0.0482s/iter; left time: 32571.3390s\n",
      "6099it [04:28, 25.98it/s]\titers: 6100, epoch: 5 | loss: 1.1993849\n",
      "\tspeed: 0.0436s/iter; left time: 29451.7611s\n",
      "6198it [04:32, 24.91it/s]\titers: 6200, epoch: 5 | loss: 0.3741126\n",
      "\tspeed: 0.0401s/iter; left time: 27091.6002s\n",
      "6297it [04:36, 21.31it/s]\titers: 6300, epoch: 5 | loss: 0.3426784\n",
      "\tspeed: 0.0414s/iter; left time: 27936.3020s\n",
      "6397it [04:41, 19.94it/s]\titers: 6400, epoch: 5 | loss: 0.3751390\n",
      "\tspeed: 0.0480s/iter; left time: 32414.0670s\n",
      "6499it [04:46, 18.35it/s]\titers: 6500, epoch: 5 | loss: 0.6135153\n",
      "\tspeed: 0.0516s/iter; left time: 34857.9469s\n",
      "6598it [04:51, 25.38it/s]\titers: 6600, epoch: 5 | loss: 0.7251038\n",
      "\tspeed: 0.0445s/iter; left time: 30004.5650s\n",
      "6698it [04:55, 19.92it/s]\titers: 6700, epoch: 5 | loss: 0.3376411\n",
      "\tspeed: 0.0466s/iter; left time: 31449.2229s\n",
      "6797it [05:00, 24.43it/s]\titers: 6800, epoch: 5 | loss: 0.6778505\n",
      "\tspeed: 0.0438s/iter; left time: 29586.3053s\n",
      "6899it [05:04, 26.69it/s]\titers: 6900, epoch: 5 | loss: 0.2367867\n",
      "\tspeed: 0.0403s/iter; left time: 27200.6662s\n",
      "6998it [05:08, 24.25it/s]\titers: 7000, epoch: 5 | loss: 0.2824425\n",
      "\tspeed: 0.0399s/iter; left time: 26903.2851s\n",
      "7097it [05:12, 25.95it/s]\titers: 7100, epoch: 5 | loss: 0.2987415\n",
      "\tspeed: 0.0391s/iter; left time: 26367.4112s\n",
      "7198it [05:16, 18.71it/s]\titers: 7200, epoch: 5 | loss: 0.2920209\n",
      "\tspeed: 0.0456s/iter; left time: 30749.7974s\n",
      "7299it [05:21, 18.78it/s]\titers: 7300, epoch: 5 | loss: 0.3355755\n",
      "\tspeed: 0.0483s/iter; left time: 32559.5236s\n",
      "7397it [05:25, 26.45it/s]\titers: 7400, epoch: 5 | loss: 0.1615517\n",
      "\tspeed: 0.0434s/iter; left time: 29275.3329s\n",
      "7499it [05:30, 21.58it/s]\titers: 7500, epoch: 5 | loss: 0.1993215\n",
      "\tspeed: 0.0467s/iter; left time: 31463.6806s\n",
      "7598it [05:35, 25.01it/s]\titers: 7600, epoch: 5 | loss: 0.1791057\n",
      "\tspeed: 0.0444s/iter; left time: 29917.9137s\n",
      "7697it [05:39, 26.26it/s]\titers: 7700, epoch: 5 | loss: 0.2397955\n",
      "\tspeed: 0.0389s/iter; left time: 26223.6280s\n",
      "7799it [05:43, 24.27it/s]\titers: 7800, epoch: 5 | loss: 0.3109130\n",
      "\tspeed: 0.0402s/iter; left time: 27072.5172s\n",
      "7898it [05:47, 25.32it/s]\titers: 7900, epoch: 5 | loss: 0.2148320\n",
      "\tspeed: 0.0398s/iter; left time: 26804.7733s\n",
      "7997it [05:51, 23.82it/s]\titers: 8000, epoch: 5 | loss: 0.4989042\n",
      "\tspeed: 0.0405s/iter; left time: 27290.2534s\n",
      "8097it [05:55, 20.17it/s]\titers: 8100, epoch: 5 | loss: 0.3480837\n",
      "\tspeed: 0.0483s/iter; left time: 32523.0263s\n",
      "8199it [06:01, 19.01it/s]\titers: 8200, epoch: 5 | loss: 0.4272659\n",
      "\tspeed: 0.0511s/iter; left time: 34420.5555s\n",
      "8298it [06:05, 25.35it/s]\titers: 8300, epoch: 5 | loss: 0.1894694\n",
      "\tspeed: 0.0439s/iter; left time: 29572.3761s\n",
      "8397it [06:09, 25.49it/s]\titers: 8400, epoch: 5 | loss: 0.2339215\n",
      "\tspeed: 0.0394s/iter; left time: 26488.4236s\n",
      "8499it [06:13, 24.51it/s]\titers: 8500, epoch: 5 | loss: 0.1826598\n",
      "\tspeed: 0.0400s/iter; left time: 26918.2498s\n",
      "8598it [06:17, 26.96it/s]\titers: 8600, epoch: 5 | loss: 0.3120426\n",
      "\tspeed: 0.0396s/iter; left time: 26618.7090s\n",
      "8697it [06:21, 26.50it/s]\titers: 8700, epoch: 5 | loss: 0.1870272\n",
      "\tspeed: 0.0387s/iter; left time: 26030.1030s\n",
      "8799it [06:25, 25.03it/s]\titers: 8800, epoch: 5 | loss: 0.4092231\n",
      "\tspeed: 0.0396s/iter; left time: 26641.4697s\n",
      "8898it [06:28, 23.88it/s]\titers: 8900, epoch: 5 | loss: 0.2540069\n",
      "\tspeed: 0.0357s/iter; left time: 24029.2800s\n",
      "8998it [06:33, 17.53it/s]\titers: 9000, epoch: 5 | loss: 0.2610779\n",
      "\tspeed: 0.0448s/iter; left time: 30106.2233s\n",
      "9098it [06:38, 18.78it/s]\titers: 9100, epoch: 5 | loss: 0.3918426\n",
      "\tspeed: 0.0553s/iter; left time: 37189.9920s\n",
      "9199it [06:43, 25.88it/s]\titers: 9200, epoch: 5 | loss: 0.1907782\n",
      "\tspeed: 0.0447s/iter; left time: 30021.3549s\n",
      "9298it [06:47, 23.71it/s]\titers: 9300, epoch: 5 | loss: 0.2491984\n",
      "\tspeed: 0.0395s/iter; left time: 26554.5062s\n",
      "9397it [06:50, 24.82it/s]\titers: 9400, epoch: 5 | loss: 0.3234518\n",
      "\tspeed: 0.0388s/iter; left time: 26061.2264s\n",
      "9499it [06:54, 25.79it/s]\titers: 9500, epoch: 5 | loss: 0.2897208\n",
      "\tspeed: 0.0388s/iter; left time: 26043.7666s\n",
      "9598it [06:59, 23.72it/s]\titers: 9600, epoch: 5 | loss: 0.5611585\n",
      "\tspeed: 0.0416s/iter; left time: 27920.0411s\n",
      "9698it [07:04, 18.34it/s]\titers: 9700, epoch: 5 | loss: 0.8563988\n",
      "\tspeed: 0.0508s/iter; left time: 34105.1337s\n",
      "9799it [07:08, 24.23it/s]\titers: 9800, epoch: 5 | loss: 0.2080276\n",
      "\tspeed: 0.0454s/iter; left time: 30510.8426s\n",
      "9897it [07:13, 19.52it/s]\titers: 9900, epoch: 5 | loss: 0.3435356\n",
      "\tspeed: 0.0506s/iter; left time: 33966.7098s\n",
      "9999it [07:18, 20.94it/s]\titers: 10000, epoch: 5 | loss: 0.2092636\n",
      "\tspeed: 0.0493s/iter; left time: 33105.6314s\n",
      "10099it [07:22, 23.87it/s]\titers: 10100, epoch: 5 | loss: 0.1853700\n",
      "\tspeed: 0.0406s/iter; left time: 27244.1302s\n",
      "10198it [07:26, 26.22it/s]\titers: 10200, epoch: 5 | loss: 0.1514463\n",
      "\tspeed: 0.0404s/iter; left time: 27135.9797s\n",
      "10297it [07:30, 24.30it/s]\titers: 10300, epoch: 5 | loss: 0.5476085\n",
      "\tspeed: 0.0398s/iter; left time: 26706.3396s\n",
      "10399it [07:35, 21.84it/s]\titers: 10400, epoch: 5 | loss: 0.3843063\n",
      "\tspeed: 0.0427s/iter; left time: 28659.3291s\n",
      "10497it [07:39, 24.60it/s]\titers: 10500, epoch: 5 | loss: 0.7951134\n",
      "\tspeed: 0.0433s/iter; left time: 29055.3384s\n",
      "10599it [07:43, 25.45it/s]\titers: 10600, epoch: 5 | loss: 0.3617176\n",
      "\tspeed: 0.0399s/iter; left time: 26763.6279s\n",
      "10697it [07:47, 18.43it/s]\titers: 10700, epoch: 5 | loss: 0.2927218\n",
      "\tspeed: 0.0463s/iter; left time: 31029.3637s\n",
      "10799it [07:53, 18.82it/s]\titers: 10800, epoch: 5 | loss: 0.1279743\n",
      "\tspeed: 0.0524s/iter; left time: 35122.0030s\n",
      "10898it [07:57, 26.50it/s]\titers: 10900, epoch: 5 | loss: 0.3055369\n",
      "\tspeed: 0.0476s/iter; left time: 31936.2669s\n",
      "10997it [08:01, 25.61it/s]\titers: 11000, epoch: 5 | loss: 0.7323479\n",
      "\tspeed: 0.0401s/iter; left time: 26902.2679s\n",
      "11099it [08:06, 18.85it/s]\titers: 11100, epoch: 5 | loss: 0.4227690\n",
      "\tspeed: 0.0482s/iter; left time: 32319.7608s\n",
      "11199it [08:11, 20.52it/s]\titers: 11200, epoch: 5 | loss: 0.2236375\n",
      "\tspeed: 0.0487s/iter; left time: 32643.1017s\n",
      "11298it [08:15, 25.72it/s]\titers: 11300, epoch: 5 | loss: 0.2621760\n",
      "\tspeed: 0.0428s/iter; left time: 28707.5754s\n",
      "11397it [08:19, 25.81it/s]\titers: 11400, epoch: 5 | loss: 0.1581541\n",
      "\tspeed: 0.0390s/iter; left time: 26122.8733s\n",
      "11499it [08:23, 22.53it/s]\titers: 11500, epoch: 5 | loss: 0.5420423\n",
      "\tspeed: 0.0411s/iter; left time: 27566.6630s\n",
      "11597it [08:28, 23.79it/s]\titers: 11600, epoch: 5 | loss: 0.1728089\n",
      "\tspeed: 0.0513s/iter; left time: 34363.3892s\n",
      "11697it [08:33, 26.83it/s]\titers: 11700, epoch: 5 | loss: 0.2506289\n",
      "\tspeed: 0.0440s/iter; left time: 29489.3913s\n",
      "11799it [08:37, 23.70it/s]\titers: 11800, epoch: 5 | loss: 0.5162008\n",
      "\tspeed: 0.0397s/iter; left time: 26607.0977s\n",
      "11898it [08:41, 21.20it/s]\titers: 11900, epoch: 5 | loss: 0.2943844\n",
      "\tspeed: 0.0440s/iter; left time: 29470.4196s\n",
      "11999it [08:46, 24.56it/s]\titers: 12000, epoch: 5 | loss: 0.2897620\n",
      "\tspeed: 0.0481s/iter; left time: 32192.1345s\n",
      "12098it [08:50, 25.18it/s]\titers: 12100, epoch: 5 | loss: 0.4426323\n",
      "\tspeed: 0.0392s/iter; left time: 26259.1125s\n",
      "12197it [08:54, 25.83it/s]\titers: 12200, epoch: 5 | loss: 0.5539030\n",
      "\tspeed: 0.0394s/iter; left time: 26374.3581s\n",
      "12299it [08:58, 21.96it/s]\titers: 12300, epoch: 5 | loss: 0.1596682\n",
      "\tspeed: 0.0424s/iter; left time: 28371.1780s\n",
      "12397it [09:03, 21.33it/s]\titers: 12400, epoch: 5 | loss: 0.1075682\n",
      "\tspeed: 0.0489s/iter; left time: 32745.4417s\n",
      "12497it [09:08, 18.19it/s]\titers: 12500, epoch: 5 | loss: 0.8833743\n",
      "\tspeed: 0.0526s/iter; left time: 35211.5067s\n",
      "12598it [09:13, 20.60it/s]\titers: 12600, epoch: 5 | loss: 0.1542282\n",
      "\tspeed: 0.0464s/iter; left time: 31056.2625s\n",
      "12699it [09:17, 25.71it/s]\titers: 12700, epoch: 5 | loss: 0.1995778\n",
      "\tspeed: 0.0440s/iter; left time: 29432.5537s\n",
      "12798it [09:21, 25.69it/s]\titers: 12800, epoch: 5 | loss: 0.9572430\n",
      "\tspeed: 0.0398s/iter; left time: 26632.9203s\n",
      "12897it [09:25, 25.62it/s]\titers: 12900, epoch: 5 | loss: 0.4034707\n",
      "\tspeed: 0.0393s/iter; left time: 26261.4213s\n",
      "12999it [09:29, 25.51it/s]\titers: 13000, epoch: 5 | loss: 0.6003628\n",
      "\tspeed: 0.0384s/iter; left time: 25676.8650s\n",
      "13098it [09:33, 24.36it/s]\titers: 13100, epoch: 5 | loss: 0.3156387\n",
      "\tspeed: 0.0400s/iter; left time: 26749.9601s\n",
      "13199it [09:38, 19.01it/s]\titers: 13200, epoch: 5 | loss: 0.3121930\n",
      "\tspeed: 0.0456s/iter; left time: 30507.5146s\n",
      "13298it [09:43, 17.18it/s]\titers: 13300, epoch: 5 | loss: 0.5606303\n",
      "\tspeed: 0.0531s/iter; left time: 35494.5670s\n",
      "13397it [09:48, 20.30it/s]\titers: 13400, epoch: 5 | loss: 0.9160708\n",
      "\tspeed: 0.0510s/iter; left time: 34051.8725s\n",
      "13497it [09:53, 23.89it/s]\titers: 13500, epoch: 5 | loss: 0.1423665\n",
      "\tspeed: 0.0460s/iter; left time: 30749.1565s\n",
      "13599it [09:57, 25.68it/s]\titers: 13600, epoch: 5 | loss: 0.4108829\n",
      "\tspeed: 0.0396s/iter; left time: 26451.6830s\n",
      "13698it [10:01, 26.25it/s]\titers: 13700, epoch: 5 | loss: 0.2306906\n",
      "\tspeed: 0.0386s/iter; left time: 25805.7986s\n",
      "13797it [10:04, 25.53it/s]\titers: 13800, epoch: 5 | loss: 0.3975872\n",
      "\tspeed: 0.0393s/iter; left time: 26250.6184s\n",
      "13899it [10:08, 25.20it/s]\titers: 13900, epoch: 5 | loss: 0.0969111\n",
      "\tspeed: 0.0390s/iter; left time: 26022.4369s\n",
      "13999it [10:13, 19.66it/s]\titers: 14000, epoch: 5 | loss: 0.4403995\n",
      "\tspeed: 0.0453s/iter; left time: 30246.7629s\n",
      "14098it [10:18, 18.90it/s]\titers: 14100, epoch: 5 | loss: 0.4403400\n",
      "\tspeed: 0.0483s/iter; left time: 32237.0172s\n",
      "14199it [10:23, 24.91it/s]\titers: 14200, epoch: 5 | loss: 0.6731554\n",
      "\tspeed: 0.0510s/iter; left time: 34014.2488s\n",
      "14299it [10:27, 26.43it/s]\titers: 14300, epoch: 5 | loss: 0.1631805\n",
      "\tspeed: 0.0378s/iter; left time: 25253.7375s\n",
      "14398it [10:31, 25.20it/s]\titers: 14400, epoch: 5 | loss: 0.3029134\n",
      "\tspeed: 0.0386s/iter; left time: 25777.9595s\n",
      "14497it [10:34, 25.27it/s]\titers: 14500, epoch: 5 | loss: 0.4262111\n",
      "\tspeed: 0.0396s/iter; left time: 26441.9605s\n",
      "14599it [10:39, 25.52it/s]\titers: 14600, epoch: 5 | loss: 0.9286230\n",
      "\tspeed: 0.0399s/iter; left time: 26602.9551s\n",
      "14698it [10:42, 24.80it/s]\titers: 14700, epoch: 5 | loss: 0.6335403\n",
      "\tspeed: 0.0398s/iter; left time: 26563.6681s\n",
      "14798it [10:47, 22.31it/s]\titers: 14800, epoch: 5 | loss: 0.2591784\n",
      "\tspeed: 0.0415s/iter; left time: 27685.7510s\n",
      "14816it [10:48, 22.86it/s]\n",
      "Epoch: 5 cost time: 648.0199255943298\n",
      "3204it [01:10, 45.68it/s]\n",
      "3192it [01:10, 45.20it/s]\n",
      "Epoch: 5 | Train Loss: 0.3519023 Vali Loss: 0.4574203 Test Loss: 0.5933794 MAE Loss: 0.4816362\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000400000\n",
      "97it [00:05, 21.92it/s]\titers: 100, epoch: 6 | loss: 0.2936621\n",
      "\tspeed: 1.4681s/iter; left time: 978650.1817s\n",
      "198it [00:10, 19.38it/s]\titers: 200, epoch: 6 | loss: 0.3793704\n",
      "\tspeed: 0.0511s/iter; left time: 34089.2931s\n",
      "297it [00:14, 23.88it/s]\titers: 300, epoch: 6 | loss: 0.1651248\n",
      "\tspeed: 0.0440s/iter; left time: 29318.5540s\n",
      "399it [00:19, 21.28it/s]\titers: 400, epoch: 6 | loss: 0.1877437\n",
      "\tspeed: 0.0483s/iter; left time: 32194.8103s\n",
      "499it [00:24, 20.54it/s]\titers: 500, epoch: 6 | loss: 0.1496411\n",
      "\tspeed: 0.0487s/iter; left time: 32426.1490s\n",
      "598it [00:28, 24.52it/s]\titers: 600, epoch: 6 | loss: 0.1438605\n",
      "\tspeed: 0.0429s/iter; left time: 28555.4840s\n",
      "697it [00:32, 26.36it/s]\titers: 700, epoch: 6 | loss: 0.1959265\n",
      "\tspeed: 0.0393s/iter; left time: 26199.1384s\n",
      "799it [00:36, 24.55it/s]\titers: 800, epoch: 6 | loss: 0.2477929\n",
      "\tspeed: 0.0403s/iter; left time: 26832.4516s\n",
      "898it [00:41, 19.01it/s]\titers: 900, epoch: 6 | loss: 0.1364804\n",
      "\tspeed: 0.0464s/iter; left time: 30884.7736s\n",
      "998it [00:46, 18.51it/s]\titers: 1000, epoch: 6 | loss: 0.4619678\n",
      "\tspeed: 0.0519s/iter; left time: 34542.7652s\n",
      "1097it [00:50, 25.56it/s]\titers: 1100, epoch: 6 | loss: 0.5164634\n",
      "\tspeed: 0.0450s/iter; left time: 29939.6843s\n",
      "1197it [00:55, 19.86it/s]\titers: 1200, epoch: 6 | loss: 0.5240765\n",
      "\tspeed: 0.0494s/iter; left time: 32901.4494s\n",
      "1299it [01:00, 24.71it/s]\titers: 1300, epoch: 6 | loss: 0.3654906\n",
      "\tspeed: 0.0425s/iter; left time: 28309.5109s\n",
      "1399it [01:04, 26.38it/s]\titers: 1400, epoch: 6 | loss: 0.2032688\n",
      "\tspeed: 0.0396s/iter; left time: 26313.7020s\n",
      "1498it [01:08, 25.16it/s]\titers: 1500, epoch: 6 | loss: 0.5962573\n",
      "\tspeed: 0.0395s/iter; left time: 26252.3683s\n",
      "1597it [01:11, 25.10it/s]\titers: 1600, epoch: 6 | loss: 0.3283030\n",
      "\tspeed: 0.0396s/iter; left time: 26319.9672s\n",
      "1699it [01:16, 20.74it/s]\titers: 1700, epoch: 6 | loss: 0.7703698\n",
      "\tspeed: 0.0435s/iter; left time: 28949.5560s\n",
      "1799it [01:20, 19.92it/s]\titers: 1800, epoch: 6 | loss: 0.1270316\n",
      "\tspeed: 0.0459s/iter; left time: 30528.4514s\n",
      "1899it [01:26, 19.46it/s]\titers: 1900, epoch: 6 | loss: 0.2055087\n",
      "\tspeed: 0.0552s/iter; left time: 36719.3572s\n",
      "1998it [01:30, 25.36it/s]\titers: 2000, epoch: 6 | loss: 0.3011176\n",
      "\tspeed: 0.0401s/iter; left time: 26686.7247s\n",
      "2097it [01:34, 25.54it/s]\titers: 2100, epoch: 6 | loss: 0.3628902\n",
      "\tspeed: 0.0394s/iter; left time: 26216.0987s\n",
      "2199it [01:38, 24.80it/s]\titers: 2200, epoch: 6 | loss: 0.1563153\n",
      "\tspeed: 0.0405s/iter; left time: 26918.2097s\n",
      "2298it [01:42, 26.95it/s]\titers: 2300, epoch: 6 | loss: 0.5818335\n",
      "\tspeed: 0.0388s/iter; left time: 25807.7009s\n",
      "2397it [01:46, 24.17it/s]\titers: 2400, epoch: 6 | loss: 0.1276182\n",
      "\tspeed: 0.0401s/iter; left time: 26634.8182s\n",
      "2497it [01:50, 27.05it/s]\titers: 2500, epoch: 6 | loss: 0.1287532\n",
      "\tspeed: 0.0393s/iter; left time: 26136.2329s\n",
      "2597it [01:54, 26.05it/s]\titers: 2600, epoch: 6 | loss: 0.3227880\n",
      "\tspeed: 0.0372s/iter; left time: 24672.2703s\n",
      "2698it [01:57, 24.65it/s]\titers: 2700, epoch: 6 | loss: 0.2729033\n",
      "\tspeed: 0.0356s/iter; left time: 23630.6932s\n",
      "2799it [02:03, 18.40it/s]\titers: 2800, epoch: 6 | loss: 0.1627519\n",
      "\tspeed: 0.0548s/iter; left time: 36411.1433s\n",
      "2897it [02:07, 25.51it/s]\titers: 2900, epoch: 6 | loss: 0.1535499\n",
      "\tspeed: 0.0477s/iter; left time: 31631.4828s\n",
      "2999it [02:11, 25.13it/s]\titers: 3000, epoch: 6 | loss: 0.2275990\n",
      "\tspeed: 0.0395s/iter; left time: 26193.2844s\n",
      "3098it [02:15, 24.58it/s]\titers: 3100, epoch: 6 | loss: 1.1220491\n",
      "\tspeed: 0.0395s/iter; left time: 26209.8939s\n",
      "3199it [02:19, 26.11it/s]\titers: 3200, epoch: 6 | loss: 0.2358331\n",
      "\tspeed: 0.0384s/iter; left time: 25479.6171s\n",
      "3298it [02:23, 25.39it/s]\titers: 3300, epoch: 6 | loss: 0.7284061\n",
      "\tspeed: 0.0405s/iter; left time: 26837.8807s\n",
      "3398it [02:28, 17.76it/s]\titers: 3400, epoch: 6 | loss: 0.2569742\n",
      "\tspeed: 0.0489s/iter; left time: 32404.7727s\n",
      "3498it [02:33, 19.02it/s]\titers: 3500, epoch: 6 | loss: 0.5395100\n",
      "\tspeed: 0.0492s/iter; left time: 32617.5550s\n",
      "3598it [02:38, 21.21it/s]\titers: 3600, epoch: 6 | loss: 1.0083261\n",
      "\tspeed: 0.0497s/iter; left time: 32960.0040s\n",
      "3699it [02:43, 20.14it/s]\titers: 3700, epoch: 6 | loss: 0.5627854\n",
      "\tspeed: 0.0464s/iter; left time: 30768.9838s\n",
      "3797it [02:46, 26.45it/s]\titers: 3800, epoch: 6 | loss: 0.1625243\n",
      "\tspeed: 0.0401s/iter; left time: 26596.1382s\n",
      "3899it [02:51, 25.13it/s]\titers: 3900, epoch: 6 | loss: 0.2268854\n",
      "\tspeed: 0.0396s/iter; left time: 26252.8715s\n",
      "3998it [02:54, 25.01it/s]\titers: 4000, epoch: 6 | loss: 0.2085600\n",
      "\tspeed: 0.0396s/iter; left time: 26267.5095s\n",
      "4099it [02:59, 18.33it/s]\titers: 4100, epoch: 6 | loss: 0.1260192\n",
      "\tspeed: 0.0462s/iter; left time: 30609.2742s\n",
      "4197it [03:03, 24.45it/s]\titers: 4200, epoch: 6 | loss: 0.4300714\n",
      "\tspeed: 0.0422s/iter; left time: 27949.2264s\n",
      "4299it [03:07, 25.32it/s]\titers: 4300, epoch: 6 | loss: 1.1589379\n",
      "\tspeed: 0.0406s/iter; left time: 26877.3002s\n",
      "4398it [03:12, 20.70it/s]\titers: 4400, epoch: 6 | loss: 0.1630382\n",
      "\tspeed: 0.0470s/iter; left time: 31120.3154s\n",
      "4498it [03:17, 19.14it/s]\titers: 4500, epoch: 6 | loss: 0.6785685\n",
      "\tspeed: 0.0516s/iter; left time: 34196.3506s\n",
      "4597it [03:21, 26.16it/s]\titers: 4600, epoch: 6 | loss: 0.4801625\n",
      "\tspeed: 0.0416s/iter; left time: 27572.1047s\n",
      "4699it [03:25, 23.35it/s]\titers: 4700, epoch: 6 | loss: 0.5838231\n",
      "\tspeed: 0.0408s/iter; left time: 27007.8409s\n",
      "4799it [03:30, 19.75it/s]\titers: 4800, epoch: 6 | loss: 0.1668066\n",
      "\tspeed: 0.0478s/iter; left time: 31614.2324s\n",
      "4899it [03:35, 18.45it/s]\titers: 4900, epoch: 6 | loss: 0.5862921\n",
      "\tspeed: 0.0509s/iter; left time: 33669.0395s\n",
      "4997it [03:40, 23.83it/s]\titers: 5000, epoch: 6 | loss: 0.0810052\n",
      "\tspeed: 0.0458s/iter; left time: 30339.1145s\n",
      "5099it [03:44, 24.86it/s]\titers: 5100, epoch: 6 | loss: 0.4239528\n",
      "\tspeed: 0.0405s/iter; left time: 26766.0734s\n",
      "5197it [03:48, 23.36it/s]\titers: 5200, epoch: 6 | loss: 0.4956626\n",
      "\tspeed: 0.0462s/iter; left time: 30539.0548s\n",
      "5298it [03:54, 20.62it/s]\titers: 5300, epoch: 6 | loss: 0.1790583\n",
      "\tspeed: 0.0519s/iter; left time: 34343.3321s\n",
      "5398it [03:58, 27.17it/s]\titers: 5400, epoch: 6 | loss: 0.4217979\n",
      "\tspeed: 0.0457s/iter; left time: 30208.9735s\n",
      "5497it [04:02, 23.20it/s]\titers: 5500, epoch: 6 | loss: 0.4433869\n",
      "\tspeed: 0.0410s/iter; left time: 27135.5157s\n",
      "5598it [04:07, 20.65it/s]\titers: 5600, epoch: 6 | loss: 0.3065561\n",
      "\tspeed: 0.0494s/iter; left time: 32629.2071s\n",
      "5697it [04:11, 25.85it/s]\titers: 5700, epoch: 6 | loss: 0.4730638\n",
      "\tspeed: 0.0413s/iter; left time: 27328.8354s\n",
      "5799it [04:15, 24.86it/s]\titers: 5800, epoch: 6 | loss: 0.1743535\n",
      "\tspeed: 0.0396s/iter; left time: 26157.2091s\n",
      "5899it [04:20, 23.72it/s]\titers: 5900, epoch: 6 | loss: 0.2382679\n",
      "\tspeed: 0.0408s/iter; left time: 26946.9448s\n",
      "5998it [04:24, 21.67it/s]\titers: 6000, epoch: 6 | loss: 0.1520603\n",
      "\tspeed: 0.0426s/iter; left time: 28156.8452s\n",
      "6098it [04:29, 17.28it/s]\titers: 6100, epoch: 6 | loss: 0.1954198\n",
      "\tspeed: 0.0521s/iter; left time: 34447.0737s\n",
      "6198it [04:34, 23.48it/s]\titers: 6200, epoch: 6 | loss: 0.3519773\n",
      "\tspeed: 0.0483s/iter; left time: 31918.9433s\n",
      "6297it [04:38, 22.97it/s]\titers: 6300, epoch: 6 | loss: 0.2497960\n",
      "\tspeed: 0.0443s/iter; left time: 29246.1342s\n",
      "6399it [04:43, 25.54it/s]\titers: 6400, epoch: 6 | loss: 0.1775334\n",
      "\tspeed: 0.0421s/iter; left time: 27827.8932s\n",
      "6498it [04:46, 24.58it/s]\titers: 6500, epoch: 6 | loss: 0.3431976\n",
      "\tspeed: 0.0398s/iter; left time: 26266.1079s\n",
      "6598it [04:50, 24.26it/s]\titers: 6600, epoch: 6 | loss: 0.2618109\n",
      "\tspeed: 0.0399s/iter; left time: 26349.5160s\n",
      "6697it [04:54, 25.31it/s]\titers: 6700, epoch: 6 | loss: 0.3587041\n",
      "\tspeed: 0.0401s/iter; left time: 26470.9995s\n",
      "6799it [04:58, 25.49it/s]\titers: 6800, epoch: 6 | loss: 0.2328700\n",
      "\tspeed: 0.0396s/iter; left time: 26104.4536s\n",
      "6897it [05:03, 21.16it/s]\titers: 6900, epoch: 6 | loss: 0.1720991\n",
      "\tspeed: 0.0470s/iter; left time: 31031.2594s\n",
      "6998it [05:09, 18.69it/s]\titers: 7000, epoch: 6 | loss: 0.5401449\n",
      "\tspeed: 0.0559s/iter; left time: 36848.6441s\n",
      "7097it [05:13, 24.91it/s]\titers: 7100, epoch: 6 | loss: 0.2133241\n",
      "\tspeed: 0.0417s/iter; left time: 27526.8295s\n",
      "7199it [05:17, 26.32it/s]\titers: 7200, epoch: 6 | loss: 0.4142926\n",
      "\tspeed: 0.0389s/iter; left time: 25648.0385s\n",
      "7299it [05:21, 24.91it/s]\titers: 7300, epoch: 6 | loss: 0.2929332\n",
      "\tspeed: 0.0396s/iter; left time: 26120.5602s\n",
      "7399it [05:25, 26.23it/s]\titers: 7400, epoch: 6 | loss: 0.3556245\n",
      "\tspeed: 0.0387s/iter; left time: 25512.9868s\n",
      "7498it [05:29, 25.56it/s]\titers: 7500, epoch: 6 | loss: 0.3289596\n",
      "\tspeed: 0.0396s/iter; left time: 26132.1600s\n",
      "7599it [05:33, 17.70it/s]\titers: 7600, epoch: 6 | loss: 0.3496481\n",
      "\tspeed: 0.0447s/iter; left time: 29478.8840s\n",
      "7698it [05:38, 17.67it/s]\titers: 7700, epoch: 6 | loss: 0.6006637\n",
      "\tspeed: 0.0488s/iter; left time: 32164.1960s\n",
      "7798it [05:43, 19.25it/s]\titers: 7800, epoch: 6 | loss: 0.1452258\n",
      "\tspeed: 0.0533s/iter; left time: 35143.8431s\n",
      "7897it [05:48, 25.22it/s]\titers: 7900, epoch: 6 | loss: 0.2795610\n",
      "\tspeed: 0.0483s/iter; left time: 31790.5844s\n",
      "7997it [05:52, 26.60it/s]\titers: 8000, epoch: 6 | loss: 0.2979641\n",
      "\tspeed: 0.0388s/iter; left time: 25562.5248s\n",
      "8099it [05:56, 25.04it/s]\titers: 8100, epoch: 6 | loss: 0.2077766\n",
      "\tspeed: 0.0399s/iter; left time: 26250.5748s\n",
      "8198it [06:00, 24.02it/s]\titers: 8200, epoch: 6 | loss: 0.8426862\n",
      "\tspeed: 0.0394s/iter; left time: 25971.3131s\n",
      "8299it [06:05, 20.36it/s]\titers: 8300, epoch: 6 | loss: 0.2698816\n",
      "\tspeed: 0.0473s/iter; left time: 31111.7416s\n",
      "8398it [06:10, 20.16it/s]\titers: 8400, epoch: 6 | loss: 0.1402520\n",
      "\tspeed: 0.0511s/iter; left time: 33664.2214s\n",
      "8498it [06:14, 23.74it/s]\titers: 8500, epoch: 6 | loss: 0.3197338\n",
      "\tspeed: 0.0427s/iter; left time: 28131.0170s\n",
      "8599it [06:19, 17.65it/s]\titers: 8600, epoch: 6 | loss: 0.1842752\n",
      "\tspeed: 0.0503s/iter; left time: 33107.2111s\n",
      "8699it [06:24, 19.09it/s]\titers: 8700, epoch: 6 | loss: 0.2353677\n",
      "\tspeed: 0.0487s/iter; left time: 32037.7228s\n",
      "8797it [06:28, 25.69it/s]\titers: 8800, epoch: 6 | loss: 0.1752538\n",
      "\tspeed: 0.0399s/iter; left time: 26264.3435s\n",
      "8899it [06:32, 24.16it/s]\titers: 8900, epoch: 6 | loss: 0.5719410\n",
      "\tspeed: 0.0399s/iter; left time: 26238.0524s\n",
      "8998it [06:36, 18.11it/s]\titers: 9000, epoch: 6 | loss: 0.3139502\n",
      "\tspeed: 0.0450s/iter; left time: 29611.5707s\n",
      "9097it [06:41, 22.99it/s]\titers: 9100, epoch: 6 | loss: 0.3432649\n",
      "\tspeed: 0.0476s/iter; left time: 31307.4240s\n",
      "9199it [06:45, 25.93it/s]\titers: 9200, epoch: 6 | loss: 0.3073975\n",
      "\tspeed: 0.0397s/iter; left time: 26119.5755s\n",
      "9298it [06:49, 24.15it/s]\titers: 9300, epoch: 6 | loss: 0.2497945\n",
      "\tspeed: 0.0400s/iter; left time: 26302.4780s\n",
      "9397it [06:54, 20.60it/s]\titers: 9400, epoch: 6 | loss: 0.9610624\n",
      "\tspeed: 0.0478s/iter; left time: 31416.8281s\n",
      "9497it [06:59, 21.59it/s]\titers: 9500, epoch: 6 | loss: 0.3059777\n",
      "\tspeed: 0.0515s/iter; left time: 33846.0422s\n",
      "9597it [07:03, 23.75it/s]\titers: 9600, epoch: 6 | loss: 0.3568260\n",
      "\tspeed: 0.0448s/iter; left time: 29460.6508s\n",
      "9698it [07:08, 18.45it/s]\titers: 9700, epoch: 6 | loss: 0.2868703\n",
      "\tspeed: 0.0469s/iter; left time: 30794.8721s\n",
      "9799it [07:13, 25.25it/s]\titers: 9800, epoch: 6 | loss: 0.5306049\n",
      "\tspeed: 0.0472s/iter; left time: 31020.6343s\n",
      "9898it [07:17, 25.19it/s]\titers: 9900, epoch: 6 | loss: 0.4852527\n",
      "\tspeed: 0.0398s/iter; left time: 26167.2035s\n",
      "9997it [07:21, 23.47it/s]\titers: 10000, epoch: 6 | loss: 0.8940011\n",
      "\tspeed: 0.0400s/iter; left time: 26299.7776s\n",
      "10099it [07:25, 25.10it/s]\titers: 10100, epoch: 6 | loss: 0.1049932\n",
      "\tspeed: 0.0400s/iter; left time: 26278.4521s\n",
      "10199it [07:29, 24.70it/s]\titers: 10200, epoch: 6 | loss: 0.1990149\n",
      "\tspeed: 0.0419s/iter; left time: 27483.6070s\n",
      "10298it [07:34, 19.04it/s]\titers: 10300, epoch: 6 | loss: 0.2065516\n",
      "\tspeed: 0.0525s/iter; left time: 34458.1571s\n",
      "10399it [07:40, 20.96it/s]\titers: 10400, epoch: 6 | loss: 0.5556059\n",
      "\tspeed: 0.0528s/iter; left time: 34641.5385s\n",
      "10499it [07:44, 24.03it/s]\titers: 10500, epoch: 6 | loss: 0.2600691\n",
      "\tspeed: 0.0422s/iter; left time: 27704.3575s\n",
      "10598it [07:48, 25.77it/s]\titers: 10600, epoch: 6 | loss: 0.5026081\n",
      "\tspeed: 0.0395s/iter; left time: 25907.9555s\n",
      "10697it [07:52, 25.35it/s]\titers: 10700, epoch: 6 | loss: 0.6008983\n",
      "\tspeed: 0.0403s/iter; left time: 26465.2958s\n",
      "10799it [07:56, 24.27it/s]\titers: 10800, epoch: 6 | loss: 0.3918109\n",
      "\tspeed: 0.0395s/iter; left time: 25897.7093s\n",
      "10898it [08:00, 25.78it/s]\titers: 10900, epoch: 6 | loss: 0.2753001\n",
      "\tspeed: 0.0397s/iter; left time: 26041.6994s\n",
      "10997it [08:04, 25.01it/s]\titers: 11000, epoch: 6 | loss: 0.2037680\n",
      "\tspeed: 0.0398s/iter; left time: 26099.1592s\n",
      "11097it [08:08, 23.43it/s]\titers: 11100, epoch: 6 | loss: 0.3278367\n",
      "\tspeed: 0.0435s/iter; left time: 28521.5418s\n",
      "11199it [08:13, 19.90it/s]\titers: 11200, epoch: 6 | loss: 0.5594113\n",
      "\tspeed: 0.0482s/iter; left time: 31600.6941s\n",
      "11297it [08:18, 24.07it/s]\titers: 11300, epoch: 6 | loss: 0.2514786\n",
      "\tspeed: 0.0511s/iter; left time: 33512.1752s\n",
      "11396it [08:22, 26.03it/s]\titers: 11400, epoch: 6 | loss: 0.4271148\n",
      "\tspeed: 0.0391s/iter; left time: 25616.3536s\n",
      "11499it [08:26, 26.14it/s]\titers: 11500, epoch: 6 | loss: 0.8611218\n",
      "\tspeed: 0.0394s/iter; left time: 25812.3085s\n",
      "11598it [08:30, 24.91it/s]\titers: 11600, epoch: 6 | loss: 0.1509242\n",
      "\tspeed: 0.0389s/iter; left time: 25508.5831s\n",
      "11698it [08:34, 25.82it/s]\titers: 11700, epoch: 6 | loss: 0.3071425\n",
      "\tspeed: 0.0389s/iter; left time: 25460.3186s\n",
      "11798it [08:38, 25.23it/s]\titers: 11800, epoch: 6 | loss: 0.2980071\n",
      "\tspeed: 0.0400s/iter; left time: 26167.6393s\n",
      "11897it [08:42, 22.16it/s]\titers: 11900, epoch: 6 | loss: 0.4376500\n",
      "\tspeed: 0.0431s/iter; left time: 28204.5888s\n",
      "11999it [08:47, 18.98it/s]\titers: 12000, epoch: 6 | loss: 0.1367847\n",
      "\tspeed: 0.0523s/iter; left time: 34249.5853s\n",
      "12099it [08:52, 18.88it/s]\titers: 12100, epoch: 6 | loss: 0.6643260\n",
      "\tspeed: 0.0515s/iter; left time: 33741.7200s\n",
      "12198it [08:56, 26.63it/s]\titers: 12200, epoch: 6 | loss: 0.2391578\n",
      "\tspeed: 0.0394s/iter; left time: 25776.6331s\n",
      "12297it [09:00, 25.38it/s]\titers: 12300, epoch: 6 | loss: 0.9236857\n",
      "\tspeed: 0.0396s/iter; left time: 25920.6030s\n",
      "12399it [09:04, 25.90it/s]\titers: 12400, epoch: 6 | loss: 0.2929742\n",
      "\tspeed: 0.0400s/iter; left time: 26169.2925s\n",
      "12498it [09:08, 24.37it/s]\titers: 12500, epoch: 6 | loss: 0.2784688\n",
      "\tspeed: 0.0393s/iter; left time: 25683.1699s\n",
      "12597it [09:13, 19.50it/s]\titers: 12600, epoch: 6 | loss: 0.8288008\n",
      "\tspeed: 0.0464s/iter; left time: 30358.9847s\n",
      "12699it [09:18, 21.36it/s]\titers: 12700, epoch: 6 | loss: 0.1513814\n",
      "\tspeed: 0.0492s/iter; left time: 32193.6981s\n",
      "12798it [09:22, 23.15it/s]\titers: 12800, epoch: 6 | loss: 0.1796747\n",
      "\tspeed: 0.0443s/iter; left time: 28991.7625s\n",
      "12899it [09:28, 17.72it/s]\titers: 12900, epoch: 6 | loss: 0.3083021\n",
      "\tspeed: 0.0531s/iter; left time: 34696.1007s\n",
      "12999it [09:32, 24.93it/s]\titers: 13000, epoch: 6 | loss: 1.0637782\n",
      "\tspeed: 0.0461s/iter; left time: 30122.8919s\n",
      "13098it [09:36, 24.52it/s]\titers: 13100, epoch: 6 | loss: 0.1053766\n",
      "\tspeed: 0.0399s/iter; left time: 26049.8038s\n",
      "13197it [09:40, 23.06it/s]\titers: 13200, epoch: 6 | loss: 0.2976939\n",
      "\tspeed: 0.0399s/iter; left time: 26081.8731s\n",
      "13297it [09:44, 21.51it/s]\titers: 13300, epoch: 6 | loss: 0.1187241\n",
      "\tspeed: 0.0437s/iter; left time: 28528.1221s\n",
      "13398it [09:49, 25.07it/s]\titers: 13400, epoch: 6 | loss: 0.3437259\n",
      "\tspeed: 0.0477s/iter; left time: 31137.2230s\n",
      "13497it [09:53, 27.07it/s]\titers: 13500, epoch: 6 | loss: 0.3218561\n",
      "\tspeed: 0.0400s/iter; left time: 26147.4104s\n",
      "13599it [09:58, 22.69it/s]\titers: 13600, epoch: 6 | loss: 0.1428437\n",
      "\tspeed: 0.0426s/iter; left time: 27820.1843s\n",
      "13697it [10:02, 20.00it/s]\titers: 13700, epoch: 6 | loss: 0.4624282\n",
      "\tspeed: 0.0506s/iter; left time: 33013.7369s\n",
      "13799it [10:08, 23.04it/s]\titers: 13800, epoch: 6 | loss: 0.5054744\n",
      "\tspeed: 0.0522s/iter; left time: 34060.7155s\n",
      "13898it [10:12, 24.54it/s]\titers: 13900, epoch: 6 | loss: 0.5861977\n",
      "\tspeed: 0.0393s/iter; left time: 25631.0155s\n",
      "13996it [10:16, 23.51it/s]\titers: 14000, epoch: 6 | loss: 0.1766035\n",
      "\tspeed: 0.0450s/iter; left time: 29377.8124s\n",
      "14098it [10:21, 20.63it/s]\titers: 14100, epoch: 6 | loss: 0.2653042\n",
      "\tspeed: 0.0506s/iter; left time: 33011.8767s\n",
      "14197it [10:26, 25.16it/s]\titers: 14200, epoch: 6 | loss: 0.3900846\n",
      "\tspeed: 0.0468s/iter; left time: 30567.5344s\n",
      "14299it [10:30, 23.93it/s]\titers: 14300, epoch: 6 | loss: 0.1860855\n",
      "\tspeed: 0.0397s/iter; left time: 25901.8232s\n",
      "14398it [10:34, 21.53it/s]\titers: 14400, epoch: 6 | loss: 0.4388477\n",
      "\tspeed: 0.0423s/iter; left time: 27607.5225s\n",
      "14499it [10:39, 19.11it/s]\titers: 14500, epoch: 6 | loss: 0.1878115\n",
      "\tspeed: 0.0497s/iter; left time: 32442.0820s\n",
      "14598it [10:44, 25.01it/s]\titers: 14600, epoch: 6 | loss: 0.5059304\n",
      "\tspeed: 0.0518s/iter; left time: 33766.9605s\n",
      "14698it [10:48, 25.26it/s]\titers: 14700, epoch: 6 | loss: 0.3248606\n",
      "\tspeed: 0.0404s/iter; left time: 26364.2216s\n",
      "14797it [10:53, 20.28it/s]\titers: 14800, epoch: 6 | loss: 0.4456968\n",
      "\tspeed: 0.0428s/iter; left time: 27929.1562s\n",
      "14816it [10:54, 22.65it/s]\n",
      "Epoch: 6 cost time: 654.0340111255646\n",
      "3204it [01:11, 44.79it/s]\n",
      "3192it [01:11, 44.77it/s]\n",
      "Epoch: 6 | Train Loss: 0.3437630 Vali Loss: 0.4572568 Test Loss: 0.6066124 MAE Loss: 0.4924767\n",
      "EarlyStopping counter: 2 out of 3\n",
      "lr = 0.0000400000\n",
      "97it [00:04, 24.86it/s]\titers: 100, epoch: 7 | loss: 0.2061352\n",
      "\tspeed: 1.4801s/iter; left time: 964713.2452s\n",
      "199it [00:08, 25.25it/s]\titers: 200, epoch: 7 | loss: 0.1492809\n",
      "\tspeed: 0.0395s/iter; left time: 25739.9488s\n",
      "298it [00:12, 23.41it/s]\titers: 300, epoch: 7 | loss: 0.1744678\n",
      "\tspeed: 0.0413s/iter; left time: 26926.2122s\n",
      "397it [00:16, 22.48it/s]\titers: 400, epoch: 7 | loss: 0.3547266\n",
      "\tspeed: 0.0428s/iter; left time: 27911.7816s\n",
      "497it [00:21, 20.86it/s]\titers: 500, epoch: 7 | loss: 0.3505725\n",
      "\tspeed: 0.0507s/iter; left time: 33023.6363s\n",
      "599it [00:26, 21.34it/s]\titers: 600, epoch: 7 | loss: 0.3296242\n",
      "\tspeed: 0.0529s/iter; left time: 34424.1034s\n",
      "699it [00:30, 26.06it/s]\titers: 700, epoch: 7 | loss: 0.2482217\n",
      "\tspeed: 0.0378s/iter; left time: 24620.3758s\n",
      "799it [00:34, 23.77it/s]\titers: 800, epoch: 7 | loss: 0.2576041\n",
      "\tspeed: 0.0399s/iter; left time: 25966.8912s\n",
      "898it [00:38, 25.36it/s]\titers: 900, epoch: 7 | loss: 0.5618296\n",
      "\tspeed: 0.0401s/iter; left time: 26134.0472s\n",
      "997it [00:42, 24.26it/s]\titers: 1000, epoch: 7 | loss: 0.1278328\n",
      "\tspeed: 0.0394s/iter; left time: 25662.7001s\n",
      "1097it [00:47, 20.25it/s]\titers: 1100, epoch: 7 | loss: 0.1957707\n",
      "\tspeed: 0.0480s/iter; left time: 31231.4153s\n",
      "1198it [00:52, 23.50it/s]\titers: 1200, epoch: 7 | loss: 0.2251699\n",
      "\tspeed: 0.0480s/iter; left time: 31230.2373s\n",
      "1297it [00:56, 20.74it/s]\titers: 1300, epoch: 7 | loss: 0.3276539\n",
      "\tspeed: 0.0465s/iter; left time: 30259.2509s\n",
      "1398it [01:01, 24.79it/s]\titers: 1400, epoch: 7 | loss: 0.5077925\n",
      "\tspeed: 0.0492s/iter; left time: 32013.8481s\n",
      "1499it [01:06, 25.68it/s]\titers: 1500, epoch: 7 | loss: 1.1199661\n",
      "\tspeed: 0.0438s/iter; left time: 28503.5149s\n",
      "1598it [01:10, 27.06it/s]\titers: 1600, epoch: 7 | loss: 0.6054173\n",
      "\tspeed: 0.0395s/iter; left time: 25680.2786s\n",
      "1698it [01:14, 25.24it/s]\titers: 1700, epoch: 7 | loss: 0.2082248\n",
      "\tspeed: 0.0394s/iter; left time: 25589.9287s\n",
      "1797it [01:18, 23.81it/s]\titers: 1800, epoch: 7 | loss: 0.2912822\n",
      "\tspeed: 0.0407s/iter; left time: 26442.6124s\n",
      "1899it [01:22, 19.73it/s]\titers: 1900, epoch: 7 | loss: 0.1564337\n",
      "\tspeed: 0.0434s/iter; left time: 28182.6947s\n",
      "1997it [01:27, 25.15it/s]\titers: 2000, epoch: 7 | loss: 0.6411785\n",
      "\tspeed: 0.0465s/iter; left time: 30188.9889s\n",
      "2098it [01:31, 18.56it/s]\titers: 2100, epoch: 7 | loss: 0.7515437\n",
      "\tspeed: 0.0453s/iter; left time: 29414.8826s\n",
      "2199it [01:36, 18.24it/s]\titers: 2200, epoch: 7 | loss: 0.2337615\n",
      "\tspeed: 0.0521s/iter; left time: 33834.3683s\n",
      "2298it [01:41, 27.31it/s]\titers: 2300, epoch: 7 | loss: 0.2829054\n",
      "\tspeed: 0.0470s/iter; left time: 30541.8447s\n",
      "2397it [01:45, 25.17it/s]\titers: 2400, epoch: 7 | loss: 0.4957013\n",
      "\tspeed: 0.0396s/iter; left time: 25701.9180s\n",
      "2499it [01:49, 25.08it/s]\titers: 2500, epoch: 7 | loss: 0.3569604\n",
      "\tspeed: 0.0404s/iter; left time: 26225.1856s\n",
      "2597it [01:54, 21.10it/s]\titers: 2600, epoch: 7 | loss: 0.2215834\n",
      "\tspeed: 0.0458s/iter; left time: 29760.7780s\n",
      "2698it [01:59, 22.30it/s]\titers: 2700, epoch: 7 | loss: 0.2588252\n",
      "\tspeed: 0.0494s/iter; left time: 32096.6349s\n",
      "2798it [02:03, 25.24it/s]\titers: 2800, epoch: 7 | loss: 0.6688654\n",
      "\tspeed: 0.0479s/iter; left time: 31071.0031s\n",
      "2897it [02:07, 23.44it/s]\titers: 2900, epoch: 7 | loss: 0.9793714\n",
      "\tspeed: 0.0415s/iter; left time: 26913.9655s\n",
      "2999it [02:13, 18.73it/s]\titers: 3000, epoch: 7 | loss: 0.6038197\n",
      "\tspeed: 0.0506s/iter; left time: 32843.1605s\n",
      "3097it [02:17, 24.86it/s]\titers: 3100, epoch: 7 | loss: 0.1702218\n",
      "\tspeed: 0.0463s/iter; left time: 30049.2304s\n",
      "3199it [02:21, 25.88it/s]\titers: 3200, epoch: 7 | loss: 0.1000403\n",
      "\tspeed: 0.0392s/iter; left time: 25427.0944s\n",
      "3298it [02:25, 26.22it/s]\titers: 3300, epoch: 7 | loss: 0.3862249\n",
      "\tspeed: 0.0397s/iter; left time: 25763.4636s\n",
      "3398it [02:30, 19.43it/s]\titers: 3400, epoch: 7 | loss: 0.3112553\n",
      "\tspeed: 0.0510s/iter; left time: 33091.3264s\n",
      "3497it [02:34, 25.75it/s]\titers: 3500, epoch: 7 | loss: 0.5032834\n",
      "\tspeed: 0.0431s/iter; left time: 27947.7392s\n",
      "3599it [02:39, 25.50it/s]\titers: 3600, epoch: 7 | loss: 0.1775182\n",
      "\tspeed: 0.0398s/iter; left time: 25776.8762s\n",
      "3699it [02:43, 23.29it/s]\titers: 3700, epoch: 7 | loss: 0.4232211\n",
      "\tspeed: 0.0412s/iter; left time: 26721.8458s\n",
      "3798it [02:48, 18.70it/s]\titers: 3800, epoch: 7 | loss: 0.3518757\n",
      "\tspeed: 0.0504s/iter; left time: 32671.9504s\n",
      "3898it [02:53, 19.01it/s]\titers: 3900, epoch: 7 | loss: 0.2076869\n",
      "\tspeed: 0.0509s/iter; left time: 32969.7733s\n",
      "3997it [02:57, 24.37it/s]\titers: 4000, epoch: 7 | loss: 0.1553333\n",
      "\tspeed: 0.0397s/iter; left time: 25720.2948s\n",
      "4098it [03:01, 21.53it/s]\titers: 4100, epoch: 7 | loss: 0.1716274\n",
      "\tspeed: 0.0457s/iter; left time: 29587.5551s\n",
      "4197it [03:06, 23.89it/s]\titers: 4200, epoch: 7 | loss: 0.9326766\n",
      "\tspeed: 0.0433s/iter; left time: 28071.9014s\n",
      "4299it [03:10, 24.76it/s]\titers: 4300, epoch: 7 | loss: 0.5520208\n",
      "\tspeed: 0.0400s/iter; left time: 25932.2871s\n",
      "4398it [03:14, 24.86it/s]\titers: 4400, epoch: 7 | loss: 0.2177991\n",
      "\tspeed: 0.0408s/iter; left time: 26411.9559s\n",
      "4497it [03:18, 25.57it/s]\titers: 4500, epoch: 7 | loss: 0.8518427\n",
      "\tspeed: 0.0396s/iter; left time: 25631.6429s\n",
      "4598it [03:22, 20.44it/s]\titers: 4600, epoch: 7 | loss: 0.2635543\n",
      "\tspeed: 0.0460s/iter; left time: 29800.7252s\n",
      "4698it [03:27, 20.74it/s]\titers: 4700, epoch: 7 | loss: 0.3085926\n",
      "\tspeed: 0.0524s/iter; left time: 33913.2551s\n",
      "4799it [03:33, 21.26it/s]\titers: 4800, epoch: 7 | loss: 0.3452523\n",
      "\tspeed: 0.0513s/iter; left time: 33199.4001s\n",
      "4898it [03:37, 24.01it/s]\titers: 4900, epoch: 7 | loss: 0.1251037\n",
      "\tspeed: 0.0408s/iter; left time: 26428.4839s\n",
      "4997it [03:41, 25.02it/s]\titers: 5000, epoch: 7 | loss: 0.2402746\n",
      "\tspeed: 0.0397s/iter; left time: 25694.0016s\n",
      "5099it [03:45, 26.49it/s]\titers: 5100, epoch: 7 | loss: 0.2091964\n",
      "\tspeed: 0.0402s/iter; left time: 25973.4607s\n",
      "5198it [03:49, 25.10it/s]\titers: 5200, epoch: 7 | loss: 0.1738313\n",
      "\tspeed: 0.0399s/iter; left time: 25795.5581s\n",
      "5297it [03:53, 25.92it/s]\titers: 5300, epoch: 7 | loss: 0.2107864\n",
      "\tspeed: 0.0391s/iter; left time: 25266.0597s\n",
      "5397it [03:56, 30.86it/s]\titers: 5400, epoch: 7 | loss: 0.1662270\n",
      "\tspeed: 0.0357s/iter; left time: 23059.9234s\n",
      "5498it [04:00, 22.82it/s]\titers: 5500, epoch: 7 | loss: 0.1820056\n",
      "\tspeed: 0.0386s/iter; left time: 24937.1077s\n",
      "5599it [04:05, 18.47it/s]\titers: 5600, epoch: 7 | loss: 0.3769056\n",
      "\tspeed: 0.0527s/iter; left time: 34041.6992s\n",
      "5697it [04:10, 24.81it/s]\titers: 5700, epoch: 7 | loss: 0.2021551\n",
      "\tspeed: 0.0504s/iter; left time: 32600.3587s\n",
      "5799it [04:14, 24.74it/s]\titers: 5800, epoch: 7 | loss: 0.2627917\n",
      "\tspeed: 0.0389s/iter; left time: 25138.3437s\n",
      "5898it [04:18, 25.63it/s]\titers: 5900, epoch: 7 | loss: 0.3476965\n",
      "\tspeed: 0.0388s/iter; left time: 25085.6934s\n",
      "5997it [04:22, 25.29it/s]\titers: 6000, epoch: 7 | loss: 0.0932383\n",
      "\tspeed: 0.0393s/iter; left time: 25411.5660s\n",
      "6099it [04:26, 22.57it/s]\titers: 6100, epoch: 7 | loss: 0.4212391\n",
      "\tspeed: 0.0402s/iter; left time: 25929.4132s\n",
      "6198it [04:30, 24.56it/s]\titers: 6200, epoch: 7 | loss: 0.4929882\n",
      "\tspeed: 0.0396s/iter; left time: 25589.9654s\n",
      "6297it [04:35, 22.82it/s]\titers: 6300, epoch: 7 | loss: 0.7664613\n",
      "\tspeed: 0.0453s/iter; left time: 29247.6872s\n",
      "6398it [04:40, 18.58it/s]\titers: 6400, epoch: 7 | loss: 0.4065951\n",
      "\tspeed: 0.0527s/iter; left time: 34037.2786s\n",
      "6499it [04:45, 18.88it/s]\titers: 6500, epoch: 7 | loss: 0.5762184\n",
      "\tspeed: 0.0534s/iter; left time: 34461.8444s\n",
      "6597it [04:49, 26.01it/s]\titers: 6600, epoch: 7 | loss: 0.4624008\n",
      "\tspeed: 0.0411s/iter; left time: 26491.7428s\n",
      "6699it [04:53, 24.83it/s]\titers: 6700, epoch: 7 | loss: 0.3262244\n",
      "\tspeed: 0.0396s/iter; left time: 25558.4696s\n",
      "6798it [04:57, 24.88it/s]\titers: 6800, epoch: 7 | loss: 0.0749407\n",
      "\tspeed: 0.0384s/iter; left time: 24800.5100s\n",
      "6897it [05:01, 26.48it/s]\titers: 6900, epoch: 7 | loss: 0.8002842\n",
      "\tspeed: 0.0398s/iter; left time: 25675.5219s\n",
      "6999it [05:05, 21.97it/s]\titers: 7000, epoch: 7 | loss: 0.0972029\n",
      "\tspeed: 0.0414s/iter; left time: 26682.4188s\n",
      "7098it [05:10, 19.04it/s]\titers: 7100, epoch: 7 | loss: 0.1567652\n",
      "\tspeed: 0.0484s/iter; left time: 31215.0413s\n",
      "7199it [05:15, 18.46it/s]\titers: 7200, epoch: 7 | loss: 1.1104420\n",
      "\tspeed: 0.0515s/iter; left time: 33217.1642s\n",
      "7298it [05:20, 17.49it/s]\titers: 7300, epoch: 7 | loss: 0.4224286\n",
      "\tspeed: 0.0519s/iter; left time: 33483.9543s\n",
      "7399it [05:25, 27.44it/s]\titers: 7400, epoch: 7 | loss: 0.2227494\n",
      "\tspeed: 0.0464s/iter; left time: 29890.7314s\n",
      "7498it [05:29, 26.13it/s]\titers: 7500, epoch: 7 | loss: 0.5746579\n",
      "\tspeed: 0.0392s/iter; left time: 25269.0575s\n",
      "7597it [05:33, 25.14it/s]\titers: 7600, epoch: 7 | loss: 0.0980566\n",
      "\tspeed: 0.0401s/iter; left time: 25829.8760s\n",
      "7699it [05:37, 25.63it/s]\titers: 7700, epoch: 7 | loss: 0.3678572\n",
      "\tspeed: 0.0395s/iter; left time: 25459.9670s\n",
      "7798it [05:41, 19.25it/s]\titers: 7800, epoch: 7 | loss: 0.1180477\n",
      "\tspeed: 0.0455s/iter; left time: 29328.9937s\n",
      "7899it [05:46, 25.44it/s]\titers: 7900, epoch: 7 | loss: 0.3764383\n",
      "\tspeed: 0.0472s/iter; left time: 30425.3786s\n",
      "7998it [05:50, 22.87it/s]\titers: 8000, epoch: 7 | loss: 0.2359436\n",
      "\tspeed: 0.0419s/iter; left time: 26994.7722s\n",
      "8098it [05:55, 18.86it/s]\titers: 8100, epoch: 7 | loss: 0.2247208\n",
      "\tspeed: 0.0496s/iter; left time: 31914.4286s\n",
      "8198it [06:00, 20.87it/s]\titers: 8200, epoch: 7 | loss: 0.1762336\n",
      "\tspeed: 0.0493s/iter; left time: 31739.1889s\n",
      "8297it [06:04, 26.04it/s]\titers: 8300, epoch: 7 | loss: 0.1332155\n",
      "\tspeed: 0.0398s/iter; left time: 25599.9303s\n",
      "8399it [06:08, 26.26it/s]\titers: 8400, epoch: 7 | loss: 0.2984656\n",
      "\tspeed: 0.0391s/iter; left time: 25149.8645s\n",
      "8498it [06:12, 21.48it/s]\titers: 8500, epoch: 7 | loss: 0.1494697\n",
      "\tspeed: 0.0432s/iter; left time: 27824.4762s\n",
      "8597it [06:17, 23.76it/s]\titers: 8600, epoch: 7 | loss: 0.1985261\n",
      "\tspeed: 0.0479s/iter; left time: 30811.2939s\n",
      "8699it [06:21, 23.96it/s]\titers: 8700, epoch: 7 | loss: 0.3714769\n",
      "\tspeed: 0.0393s/iter; left time: 25270.2633s\n",
      "8798it [06:25, 23.03it/s]\titers: 8800, epoch: 7 | loss: 0.3761960\n",
      "\tspeed: 0.0411s/iter; left time: 26451.7177s\n",
      "8897it [06:30, 18.75it/s]\titers: 8900, epoch: 7 | loss: 0.1884747\n",
      "\tspeed: 0.0457s/iter; left time: 29386.6373s\n",
      "8999it [06:35, 18.79it/s]\titers: 9000, epoch: 7 | loss: 0.3542597\n",
      "\tspeed: 0.0541s/iter; left time: 34791.3803s\n",
      "9097it [06:40, 22.98it/s]\titers: 9100, epoch: 7 | loss: 0.1789340\n",
      "\tspeed: 0.0449s/iter; left time: 28843.8787s\n",
      "9199it [06:45, 18.76it/s]\titers: 9200, epoch: 7 | loss: 0.1939666\n",
      "\tspeed: 0.0480s/iter; left time: 30829.0368s\n",
      "9299it [06:50, 23.59it/s]\titers: 9300, epoch: 7 | loss: 0.2708960\n",
      "\tspeed: 0.0504s/iter; left time: 32413.3388s\n",
      "9398it [06:54, 25.48it/s]\titers: 9400, epoch: 7 | loss: 0.1739665\n",
      "\tspeed: 0.0391s/iter; left time: 25113.0628s\n",
      "9497it [06:57, 25.57it/s]\titers: 9500, epoch: 7 | loss: 0.2477606\n",
      "\tspeed: 0.0397s/iter; left time: 25477.7920s\n",
      "9599it [07:01, 25.48it/s]\titers: 9600, epoch: 7 | loss: 0.5268415\n",
      "\tspeed: 0.0393s/iter; left time: 25215.3147s\n",
      "9697it [07:06, 19.87it/s]\titers: 9700, epoch: 7 | loss: 0.1729533\n",
      "\tspeed: 0.0455s/iter; left time: 29247.3517s\n",
      "9798it [07:11, 17.63it/s]\titers: 9800, epoch: 7 | loss: 0.5499197\n",
      "\tspeed: 0.0521s/iter; left time: 33431.4804s\n",
      "9899it [07:16, 21.22it/s]\titers: 9900, epoch: 7 | loss: 0.8000079\n",
      "\tspeed: 0.0508s/iter; left time: 32589.4456s\n",
      "9998it [07:21, 24.46it/s]\titers: 10000, epoch: 7 | loss: 0.2899543\n",
      "\tspeed: 0.0445s/iter; left time: 28538.8398s\n",
      "10097it [07:25, 25.87it/s]\titers: 10100, epoch: 7 | loss: 0.2432822\n",
      "\tspeed: 0.0396s/iter; left time: 25403.6132s\n",
      "10198it [07:29, 24.02it/s]\titers: 10200, epoch: 7 | loss: 0.3450607\n",
      "\tspeed: 0.0397s/iter; left time: 25470.4609s\n",
      "10297it [07:32, 26.03it/s]\titers: 10300, epoch: 7 | loss: 1.0253131\n",
      "\tspeed: 0.0389s/iter; left time: 24972.8144s\n",
      "10399it [07:37, 25.49it/s]\titers: 10400, epoch: 7 | loss: 0.2905190\n",
      "\tspeed: 0.0394s/iter; left time: 25251.6686s\n",
      "10497it [07:40, 30.82it/s]\titers: 10500, epoch: 7 | loss: 0.2694618\n",
      "\tspeed: 0.0372s/iter; left time: 23850.2253s\n",
      "10599it [07:44, 31.05it/s]\titers: 10600, epoch: 7 | loss: 0.2316165\n",
      "\tspeed: 0.0356s/iter; left time: 22802.6300s\n",
      "10698it [07:48, 18.68it/s]\titers: 10700, epoch: 7 | loss: 0.2141968\n",
      "\tspeed: 0.0418s/iter; left time: 26791.7553s\n",
      "10797it [07:53, 20.17it/s]\titers: 10800, epoch: 7 | loss: 0.3522015\n",
      "\tspeed: 0.0537s/iter; left time: 34424.2120s\n",
      "10898it [07:58, 25.25it/s]\titers: 10900, epoch: 7 | loss: 0.3374667\n",
      "\tspeed: 0.0453s/iter; left time: 29024.6277s\n",
      "10997it [08:02, 25.57it/s]\titers: 11000, epoch: 7 | loss: 0.1943067\n",
      "\tspeed: 0.0389s/iter; left time: 24953.9026s\n",
      "11097it [08:06, 26.32it/s]\titers: 11100, epoch: 7 | loss: 0.3565352\n",
      "\tspeed: 0.0389s/iter; left time: 24951.9540s\n",
      "11199it [08:10, 25.72it/s]\titers: 11200, epoch: 7 | loss: 0.4984118\n",
      "\tspeed: 0.0390s/iter; left time: 24966.1373s\n",
      "11298it [08:14, 24.86it/s]\titers: 11300, epoch: 7 | loss: 0.2385790\n",
      "\tspeed: 0.0403s/iter; left time: 25818.8036s\n",
      "11399it [08:18, 20.90it/s]\titers: 11400, epoch: 7 | loss: 0.4285795\n",
      "\tspeed: 0.0487s/iter; left time: 31164.2837s\n",
      "11499it [08:23, 19.29it/s]\titers: 11500, epoch: 7 | loss: 0.1883947\n",
      "\tspeed: 0.0443s/iter; left time: 28384.5828s\n",
      "11599it [08:28, 18.24it/s]\titers: 11600, epoch: 7 | loss: 0.1820312\n",
      "\tspeed: 0.0488s/iter; left time: 31258.8014s\n",
      "11697it [08:33, 21.17it/s]\titers: 11700, epoch: 7 | loss: 0.3442618\n",
      "\tspeed: 0.0512s/iter; left time: 32748.5479s\n",
      "11799it [08:37, 25.34it/s]\titers: 11800, epoch: 7 | loss: 0.1274621\n",
      "\tspeed: 0.0380s/iter; left time: 24296.3545s\n",
      "11898it [08:41, 24.97it/s]\titers: 11900, epoch: 7 | loss: 0.6483110\n",
      "\tspeed: 0.0400s/iter; left time: 25606.5263s\n",
      "11997it [08:45, 21.28it/s]\titers: 12000, epoch: 7 | loss: 0.3093668\n",
      "\tspeed: 0.0422s/iter; left time: 27023.0740s\n",
      "12098it [08:50, 19.53it/s]\titers: 12100, epoch: 7 | loss: 0.3244457\n",
      "\tspeed: 0.0500s/iter; left time: 31969.4678s\n",
      "12199it [08:54, 24.13it/s]\titers: 12200, epoch: 7 | loss: 0.1916038\n",
      "\tspeed: 0.0416s/iter; left time: 26614.8247s\n",
      "12298it [08:58, 22.38it/s]\titers: 12300, epoch: 7 | loss: 0.4360396\n",
      "\tspeed: 0.0408s/iter; left time: 26114.0577s\n",
      "12398it [09:03, 18.94it/s]\titers: 12400, epoch: 7 | loss: 0.3630174\n",
      "\tspeed: 0.0470s/iter; left time: 30074.4767s\n",
      "12499it [09:08, 18.85it/s]\titers: 12500, epoch: 7 | loss: 0.2466213\n",
      "\tspeed: 0.0536s/iter; left time: 34253.2802s\n",
      "12597it [09:12, 27.33it/s]\titers: 12600, epoch: 7 | loss: 0.6397215\n",
      "\tspeed: 0.0426s/iter; left time: 27219.2208s\n",
      "12697it [09:17, 25.48it/s]\titers: 12700, epoch: 7 | loss: 0.3691167\n",
      "\tspeed: 0.0430s/iter; left time: 27517.4480s\n",
      "12798it [09:22, 19.35it/s]\titers: 12800, epoch: 7 | loss: 0.5446955\n",
      "\tspeed: 0.0503s/iter; left time: 32120.4849s\n",
      "12897it [09:27, 22.11it/s]\titers: 12900, epoch: 7 | loss: 0.2748612\n",
      "\tspeed: 0.0494s/iter; left time: 31588.2267s\n",
      "12999it [09:31, 25.17it/s]\titers: 13000, epoch: 7 | loss: 0.3710177\n",
      "\tspeed: 0.0398s/iter; left time: 25457.8517s\n",
      "13098it [09:35, 24.38it/s]\titers: 13100, epoch: 7 | loss: 0.4076060\n",
      "\tspeed: 0.0408s/iter; left time: 26050.5612s\n",
      "13198it [09:39, 19.45it/s]\titers: 13200, epoch: 7 | loss: 0.1781192\n",
      "\tspeed: 0.0454s/iter; left time: 28975.6532s\n",
      "13299it [09:45, 17.48it/s]\titers: 13300, epoch: 7 | loss: 0.7656618\n",
      "\tspeed: 0.0550s/iter; left time: 35099.7500s\n",
      "13398it [09:49, 26.20it/s]\titers: 13400, epoch: 7 | loss: 0.3765477\n",
      "\tspeed: 0.0452s/iter; left time: 28876.2031s\n",
      "13499it [09:54, 22.15it/s]\titers: 13500, epoch: 7 | loss: 0.4614994\n",
      "\tspeed: 0.0471s/iter; left time: 30079.9747s\n",
      "13597it [09:58, 25.74it/s]\titers: 13600, epoch: 7 | loss: 0.8298718\n",
      "\tspeed: 0.0439s/iter; left time: 27998.8570s\n",
      "13699it [10:02, 24.98it/s]\titers: 13700, epoch: 7 | loss: 0.4083237\n",
      "\tspeed: 0.0393s/iter; left time: 25091.4554s\n",
      "13798it [10:06, 23.92it/s]\titers: 13800, epoch: 7 | loss: 0.4874321\n",
      "\tspeed: 0.0411s/iter; left time: 26231.3787s\n",
      "13897it [10:10, 25.77it/s]\titers: 13900, epoch: 7 | loss: 0.2220180\n",
      "\tspeed: 0.0399s/iter; left time: 25442.8114s\n",
      "13999it [10:15, 23.43it/s]\titers: 14000, epoch: 7 | loss: 0.1326617\n",
      "\tspeed: 0.0405s/iter; left time: 25826.0330s\n",
      "14097it [10:19, 21.39it/s]\titers: 14100, epoch: 7 | loss: 0.1337051\n",
      "\tspeed: 0.0499s/iter; left time: 31804.3548s\n",
      "14197it [10:25, 21.32it/s]\titers: 14200, epoch: 7 | loss: 0.2059281\n",
      "\tspeed: 0.0518s/iter; left time: 33056.2220s\n",
      "14297it [10:29, 26.87it/s]\titers: 14300, epoch: 7 | loss: 0.3434809\n",
      "\tspeed: 0.0419s/iter; left time: 26721.2456s\n",
      "14399it [10:33, 24.12it/s]\titers: 14400, epoch: 7 | loss: 0.1509789\n",
      "\tspeed: 0.0397s/iter; left time: 25283.3394s\n",
      "14498it [10:37, 25.27it/s]\titers: 14500, epoch: 7 | loss: 0.2624492\n",
      "\tspeed: 0.0397s/iter; left time: 25329.8576s\n",
      "14597it [10:41, 25.72it/s]\titers: 14600, epoch: 7 | loss: 0.2205295\n",
      "\tspeed: 0.0391s/iter; left time: 24930.8455s\n",
      "14699it [10:45, 24.88it/s]\titers: 14700, epoch: 7 | loss: 0.6361473\n",
      "\tspeed: 0.0393s/iter; left time: 25035.6137s\n",
      "14796it [10:49, 24.69it/s]\titers: 14800, epoch: 7 | loss: 0.2303627\n",
      "\tspeed: 0.0409s/iter; left time: 26036.9298s\n",
      "14816it [10:49, 22.80it/s]\n",
      "Epoch: 7 cost time: 649.8433609008789\n",
      "3204it [01:09, 46.04it/s]\n",
      "3192it [01:11, 44.41it/s]\n",
      "Epoch: 7 | Train Loss: 0.3381199 Vali Loss: 0.4597676 Test Loss: 0.6031608 MAE Loss: 0.4857795\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "loading model...\n",
      "3192it [01:18, 40.60it/s]\n",
      "mse:0.5913868171996192, mae:0.48582875262712477\n",
      "train_losses [0.49556824458726795, 0.38566614542791083, 0.37090074034034604, 0.3587150347806799, 0.3519022889117475, 0.34376297366466435]\n",
      "val_losses [0.48044138019451044, 0.47190154611613233, 0.4646253559352381, 0.4554108617624987, 0.457420284647062, 0.45725677044278523]\n",
      "Total time: 108.09034833113353 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=50\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 50 epochs run_main_copy_copy.py with gradient accumulation (with additional steps)\n",
    "# There is also scheduler step after each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 03:28:58,953] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 03:29:00,062] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 03:29:00,062] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 03:29:00,062] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 03:29:01,000] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 03:29:01,000] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 03:29:01,642] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 03:29:01,643] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 03:29:01,643] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 03:29:01,644] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 03:29:01,644] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 03:29:01,644] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 03:29:01,644] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 03:29:01,644] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 03:29:01,644] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 03:29:01,644] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 03:29:02,046] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 03:29:02,047] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 03:29:02,047] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.42 GB, percent = 20.3%\n",
      "[2024-05-20 03:29:02,213] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 03:29:02,214] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 03:29:02,214] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.48 GB, percent = 20.3%\n",
      "[2024-05-20 03:29:02,214] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 03:29:02,373] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 03:29:02,374] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 03:29:02,374] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.48 GB, percent = 20.3%\n",
      "[2024-05-20 03:29:02,375] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 03:29:02,375] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 03:29:02,375] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 03:29:02,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 03:29:02,376] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 03:29:02,376] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2b21f00f10>\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 03:29:02,377] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 03:29:02,378] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 03:29:02,379] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "14816it [11:26, 21.57it/s]\n",
      "Epoch: 1 cost time: 686.9049127101898\n",
      "3204it [01:18, 40.88it/s]\n",
      "3192it [01:19, 40.34it/s]\n",
      "Epoch: 1 | Train Loss: 0.4507872 Vali Loss: 0.4932623 Test Loss: 0.6139988 MAE Loss: 0.5087899\n",
      "lr = 0.0004217013\n",
      "Updating learning rate to 0.0004217013098216749\n",
      "14816it [10:46, 22.91it/s]\n",
      "Epoch: 2 cost time: 646.787740945816\n",
      "3204it [01:11, 45.08it/s]\n",
      "3192it [01:11, 44.38it/s]\n",
      "Epoch: 2 | Train Loss: 0.3698603 Vali Loss: 0.4796726 Test Loss: 0.5988436 MAE Loss: 0.4989363\n",
      "Updating learning rate to 0.00021085065491083745\n",
      "14816it [10:45, 22.97it/s]\n",
      "Epoch: 3 cost time: 645.114351272583\n",
      "3204it [01:10, 45.46it/s]\n",
      "3192it [01:13, 43.39it/s]\n",
      "Epoch: 3 | Train Loss: 0.3675457 Vali Loss: 0.4836136 Test Loss: 0.6115616 MAE Loss: 0.5013936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.00010542532745541873\n",
      "14816it [10:57, 22.55it/s]\n",
      "Epoch: 4 cost time: 657.0129384994507\n",
      "3204it [01:10, 45.20it/s]\n",
      "3192it [01:11, 44.57it/s]\n",
      "Epoch: 4 | Train Loss: 0.3563788 Vali Loss: 0.4729380 Test Loss: 0.5978185 MAE Loss: 0.4900007\n",
      "Updating learning rate to 5.271266372770936e-05\n",
      "14816it [10:51, 22.74it/s]\n",
      "Epoch: 5 cost time: 651.6318218708038\n",
      "3204it [01:11, 45.10it/s]\n",
      "3192it [01:12, 44.15it/s]\n",
      "Epoch: 5 | Train Loss: 0.3490101 Vali Loss: 0.4775669 Test Loss: 0.5985036 MAE Loss: 0.4973588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.635633186385468e-05\n",
      "14816it [10:54, 22.64it/s]\n",
      "Epoch: 6 cost time: 654.3836915493011\n",
      "3204it [01:11, 44.73it/s]\n",
      "3192it [01:12, 43.82it/s]\n",
      "Epoch: 6 | Train Loss: 0.3439824 Vali Loss: 0.4773531 Test Loss: 0.6064298 MAE Loss: 0.4944997\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.317816593192734e-05\n",
      "14816it [10:58, 22.50it/s]\n",
      "Epoch: 7 cost time: 658.4522840976715\n",
      "3204it [01:09, 45.90it/s]\n",
      "3192it [01:11, 44.42it/s]\n",
      "Epoch: 7 | Train Loss: 0.3399175 Vali Loss: 0.4715961 Test Loss: 0.5984216 MAE Loss: 0.4937186\n",
      "Updating learning rate to 6.58908296596367e-06\n",
      "14816it [10:48, 22.86it/s]\n",
      "Epoch: 8 cost time: 648.0842633247375\n",
      "3204it [01:11, 45.03it/s]\n",
      "3192it [01:12, 44.04it/s]\n",
      "Epoch: 8 | Train Loss: 0.3362676 Vali Loss: 0.4718025 Test Loss: 0.6006082 MAE Loss: 0.4900439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.294541482981835e-06\n",
      "14816it [10:45, 22.94it/s]\n",
      "Epoch: 9 cost time: 645.8591520786285\n",
      "3204it [01:11, 45.01it/s]\n",
      "3192it [01:12, 43.95it/s]\n",
      "Epoch: 9 | Train Loss: 0.3348257 Vali Loss: 0.4706117 Test Loss: 0.6028995 MAE Loss: 0.4932286\n",
      "Updating learning rate to 1.6472707414909176e-06\n",
      "14816it [10:54, 22.65it/s]\n",
      "Epoch: 10 cost time: 654.0667817592621\n",
      "3204it [01:11, 44.80it/s]\n",
      "3192it [01:11, 44.95it/s]\n",
      "Epoch: 10 | Train Loss: 0.3343778 Vali Loss: 0.4714329 Test Loss: 0.6024176 MAE Loss: 0.4913798\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.236353707454588e-07\n",
      "14816it [10:50, 22.76it/s]\n",
      "Epoch: 11 cost time: 650.9854154586792\n",
      "3204it [01:10, 45.53it/s]\n",
      "3192it [01:12, 44.18it/s]\n",
      "Epoch: 11 | Train Loss: 0.3333301 Vali Loss: 0.4711432 Test Loss: 0.6020652 MAE Loss: 0.4913071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.118176853727294e-07\n",
      "14816it [10:47, 22.88it/s]\n",
      "Epoch: 12 cost time: 647.6127679347992\n",
      "3204it [01:11, 44.87it/s]\n",
      "3192it [01:11, 44.54it/s]\n",
      "Epoch: 12 | Train Loss: 0.3334377 Vali Loss: 0.4712109 Test Loss: 0.6021290 MAE Loss: 0.4902239\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.059088426863647e-07\n",
      "14816it [10:47, 22.88it/s]\n",
      "Epoch: 13 cost time: 647.5158507823944\n",
      "3204it [01:11, 45.02it/s]\n",
      "3192it [01:12, 44.01it/s]\n",
      "Epoch: 13 | Train Loss: 0.3332503 Vali Loss: 0.4713050 Test Loss: 0.6021595 MAE Loss: 0.4911636\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0295442134318235e-07\n",
      "14816it [10:52, 22.71it/s]\n",
      "Epoch: 14 cost time: 652.390857219696\n",
      "3204it [01:11, 44.67it/s]\n",
      "3192it [01:12, 44.09it/s]\n",
      "Epoch: 14 | Train Loss: 0.3327685 Vali Loss: 0.4713916 Test Loss: 0.6023432 MAE Loss: 0.4914492\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.1477210671591174e-08\n",
      "14816it [10:46, 22.92it/s]\n",
      "Epoch: 15 cost time: 646.466362953186\n",
      "3204it [01:10, 45.31it/s]\n",
      "3192it [01:12, 44.26it/s]\n",
      "Epoch: 15 | Train Loss: 0.3331403 Vali Loss: 0.4713612 Test Loss: 0.6022305 MAE Loss: 0.4912447\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.5738605335795587e-08\n",
      "14816it [10:45, 22.96it/s]\n",
      "Epoch: 16 cost time: 645.4330382347107\n",
      "3204it [01:10, 45.18it/s]\n",
      "3192it [01:12, 44.19it/s]\n",
      "Epoch: 16 | Train Loss: 0.3331488 Vali Loss: 0.4712994 Test Loss: 0.6022113 MAE Loss: 0.4913100\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2869302667897794e-08\n",
      "14816it [11:15, 21.94it/s]\n",
      "Epoch: 17 cost time: 675.4093120098114\n",
      "3204it [01:07, 47.30it/s]\n",
      "3192it [01:09, 46.15it/s]\n",
      "Epoch: 17 | Train Loss: 0.3330072 Vali Loss: 0.4712930 Test Loss: 0.6022041 MAE Loss: 0.4913125\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.434651333948897e-09\n",
      "14816it [12:26, 19.85it/s]\n",
      "Epoch: 18 cost time: 746.2150812149048\n",
      "3204it [01:08, 46.48it/s]\n",
      "3192it [01:09, 45.84it/s]\n",
      "Epoch: 18 | Train Loss: 0.3333021 Vali Loss: 0.4713448 Test Loss: 0.6022253 MAE Loss: 0.4913501\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.2173256669744484e-09\n",
      "14816it [12:24, 19.90it/s]\n",
      "Epoch: 19 cost time: 744.4291541576385\n",
      "3204it [01:08, 46.93it/s]\n",
      "3192it [01:09, 45.90it/s]\n",
      "Epoch: 19 | Train Loss: 0.3331715 Vali Loss: 0.4713497 Test Loss: 0.6022169 MAE Loss: 0.4913360\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Total time: 256.03672412236534 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=50\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main_copy_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 50 epochs run_main.py WITHOUT gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 12:26:54,498] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 12:26:55,671] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 12:26:55,671] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 12:26:55,671] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 12:26:56,518] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 12:26:56,518] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 12:26:57,618] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 12:26:57,620] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 12:26:57,620] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 12:26:57,621] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 12:26:57,621] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 12:26:57,621] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 12:26:57,621] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 12:26:57,621] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 12:26:57,621] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 12:26:57,621] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 12:26:58,026] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 12:26:58,027] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 12:26:58,027] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 149.81 GB, percent = 19.9%\n",
      "[2024-05-20 12:26:58,180] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 12:26:58,182] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 12:26:58,182] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 149.88 GB, percent = 19.9%\n",
      "[2024-05-20 12:26:58,182] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 12:26:58,334] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 12:26:58,335] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 12:26:58,335] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 149.94 GB, percent = 19.9%\n",
      "[2024-05-20 12:26:58,336] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 12:26:58,336] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 12:26:58,336] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 12:26:58,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 12:26:58,337] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2fdd9720d0>\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 12:26:58,338] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  192\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 12:26:58,339] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 12:26:58,340] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 12:26:58,340] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 12:26:58,340] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 12:26:58,340] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 192, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [01:04,  1.62it/s]\titers: 100, epoch: 1 | loss: 0.4440314\n",
      "\tspeed: 0.6971s/iter; left time: 16067.8542s\n",
      "199it [02:10,  2.04it/s]\titers: 200, epoch: 1 | loss: 0.3840341\n",
      "\tspeed: 0.6522s/iter; left time: 14968.3582s\n",
      "299it [03:14,  1.48it/s]\titers: 300, epoch: 1 | loss: 0.3122567\n",
      "\tspeed: 0.6456s/iter; left time: 14751.8231s\n",
      "399it [04:18,  1.99it/s]\titers: 400, epoch: 1 | loss: 0.3672516\n",
      "\tspeed: 0.6370s/iter; left time: 14492.7941s\n",
      "463it [04:59,  1.54it/s]\n",
      "Epoch: 1 cost time: 299.9610357284546\n",
      "100it [00:50,  1.97it/s]\n",
      "99it [00:55,  1.78it/s]\n",
      "Epoch: 1 | Train Loss: 0.5001562 Vali Loss: 0.4802140 Test Loss: 0.5706647 MAE Loss: 0.4833559\n",
      "Validation loss decreased (inf --> 0.480214).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:56,  1.56it/s]\titers: 100, epoch: 2 | loss: 0.4306646\n",
      "\tspeed: 2.0525s/iter; left time: 46361.2723s\n",
      "199it [01:54,  1.82it/s]\titers: 200, epoch: 2 | loss: 0.3725622\n",
      "\tspeed: 0.5839s/iter; left time: 13131.3588s\n",
      "299it [02:50,  1.70it/s]\titers: 300, epoch: 2 | loss: 0.3696827\n",
      "\tspeed: 0.5622s/iter; left time: 12587.3500s\n",
      "399it [03:49,  1.99it/s]\titers: 400, epoch: 2 | loss: 0.4788693\n",
      "\tspeed: 0.5873s/iter; left time: 13089.7711s\n",
      "463it [04:25,  1.74it/s]\n",
      "Epoch: 2 cost time: 265.3764226436615\n",
      "100it [00:44,  2.27it/s]\n",
      "99it [00:44,  2.22it/s]\n",
      "Epoch: 2 | Train Loss: 0.3860932 Vali Loss: 0.4688845 Test Loss: 0.5610100 MAE Loss: 0.4719131\n",
      "Validation loss decreased (0.480214 --> 0.468884).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:58,  1.38it/s]\titers: 100, epoch: 3 | loss: 0.3348576\n",
      "\tspeed: 1.8506s/iter; left time: 40944.3637s\n",
      "199it [01:55,  1.56it/s]\titers: 200, epoch: 3 | loss: 0.4293299\n",
      "\tspeed: 0.5722s/iter; left time: 12602.0057s\n",
      "299it [02:53,  2.45it/s]\titers: 300, epoch: 3 | loss: 0.4408928\n",
      "\tspeed: 0.5729s/iter; left time: 12561.0842s\n",
      "399it [03:33,  2.58it/s]\titers: 400, epoch: 3 | loss: 0.3780863\n",
      "\tspeed: 0.3967s/iter; left time: 8657.5391s\n",
      "463it [03:58,  1.94it/s]\n",
      "Epoch: 3 cost time: 238.25966787338257\n",
      "100it [00:29,  3.38it/s]\n",
      "99it [00:28,  3.45it/s]\n",
      "Epoch: 3 | Train Loss: 0.3706617 Vali Loss: 0.4712121 Test Loss: 0.5703471 MAE Loss: 0.4849992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000400000\n",
      "99it [00:38,  2.69it/s]\titers: 100, epoch: 4 | loss: 0.3885621\n",
      "\tspeed: 1.2177s/iter; left time: 26378.4000s\n",
      "199it [01:16,  2.74it/s]\titers: 200, epoch: 4 | loss: 0.3977180\n",
      "\tspeed: 0.3816s/iter; left time: 8228.9696s\n",
      "299it [01:54,  2.66it/s]\titers: 300, epoch: 4 | loss: 0.3352035\n",
      "\tspeed: 0.3817s/iter; left time: 8192.7693s\n",
      "399it [02:32,  2.72it/s]\titers: 400, epoch: 4 | loss: 0.3588782\n",
      "\tspeed: 0.3801s/iter; left time: 8118.7040s\n",
      "463it [02:57,  2.61it/s]\n",
      "Epoch: 4 cost time: 177.5882110595703\n",
      "100it [00:29,  3.38it/s]\n",
      "99it [00:29,  3.38it/s]\n",
      "Epoch: 4 | Train Loss: 0.3591489 Vali Loss: 0.4528614 Test Loss: 0.5561225 MAE Loss: 0.4771294\n",
      "Validation loss decreased (0.468884 --> 0.452861).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "99it [00:38,  2.64it/s]\titers: 100, epoch: 5 | loss: 0.2806355\n",
      "\tspeed: 1.2377s/iter; left time: 26238.7315s\n",
      "199it [01:17,  2.66it/s]\titers: 200, epoch: 5 | loss: 0.3568400\n",
      "\tspeed: 0.3871s/iter; left time: 8167.8918s\n",
      "299it [01:55,  2.63it/s]\titers: 300, epoch: 5 | loss: 0.3864603\n",
      "\tspeed: 0.3845s/iter; left time: 8075.1377s\n",
      "399it [02:34,  2.30it/s]\titers: 400, epoch: 5 | loss: 0.3732320\n",
      "\tspeed: 0.3862s/iter; left time: 8072.0659s\n",
      "463it [02:58,  2.59it/s]\n",
      "Epoch: 5 cost time: 178.7939178943634\n",
      "100it [00:29,  3.35it/s]\n",
      "99it [00:28,  3.45it/s]\n",
      "Epoch: 5 | Train Loss: 0.3523730 Vali Loss: 0.4576467 Test Loss: 0.5631233 MAE Loss: 0.4722830\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000400000\n",
      "99it [00:38,  2.67it/s]\titers: 100, epoch: 6 | loss: 0.4059130\n",
      "\tspeed: 1.2108s/iter; left time: 25107.4665s\n",
      "199it [01:16,  2.74it/s]\titers: 200, epoch: 6 | loss: 0.4357373\n",
      "\tspeed: 0.3790s/iter; left time: 7821.7023s\n",
      "299it [01:54,  2.68it/s]\titers: 300, epoch: 6 | loss: 0.3469841\n",
      "\tspeed: 0.3859s/iter; left time: 7924.7352s\n",
      "399it [02:33,  2.41it/s]\titers: 400, epoch: 6 | loss: 0.3255226\n",
      "\tspeed: 0.3856s/iter; left time: 7880.5021s\n",
      "463it [02:57,  2.61it/s]\n",
      "Epoch: 6 cost time: 177.7055959701538\n",
      "100it [00:29,  3.38it/s]\n",
      "99it [00:29,  3.37it/s]\n",
      "Epoch: 6 | Train Loss: 0.3453731 Vali Loss: 0.4558216 Test Loss: 0.5734216 MAE Loss: 0.4782472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "lr = 0.0000400000\n",
      "99it [00:38,  2.75it/s]\titers: 100, epoch: 7 | loss: 0.2919878\n",
      "\tspeed: 1.2163s/iter; left time: 24658.0451s\n",
      "199it [01:16,  2.75it/s]\titers: 200, epoch: 7 | loss: 0.3213936\n",
      "\tspeed: 0.3800s/iter; left time: 7666.2901s\n",
      "299it [01:54,  2.69it/s]\titers: 300, epoch: 7 | loss: 0.3718455\n",
      "\tspeed: 0.3795s/iter; left time: 7618.1738s\n",
      "399it [02:32,  2.25it/s]\titers: 400, epoch: 7 | loss: 0.3662370\n",
      "\tspeed: 0.3840s/iter; left time: 7669.9587s\n",
      "463it [02:56,  2.62it/s]\n",
      "Epoch: 7 cost time: 176.9512119293213\n",
      "100it [00:30,  3.30it/s]\n",
      "99it [00:29,  3.38it/s]\n",
      "Epoch: 7 | Train Loss: 0.3401699 Vali Loss: 0.4561859 Test Loss: 0.5703517 MAE Loss: 0.4791602\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "loading model...\n",
      "99it [00:29,  3.32it/s]\n",
      "mse:0.5561225105716725, mae:0.47712935672865975\n",
      "train_losses [0.500156226348671, 0.38609323175885507, 0.3706616967208442, 0.3591488778719892, 0.3523729792745788, 0.34537312600834064]\n",
      "val_losses [0.4802140384912491, 0.46888448983430864, 0.4712121176719666, 0.4528613820672035, 0.45764674603939054, 0.4558216428756714]\n",
      "Total time: 34.377626446882886 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=50\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=192\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest GPT2, 50 epochs run_main_copy.py WITH gradient accumulation and scheduler step after epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 13:01:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 13:01:26,092] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 13:01:26,093] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 13:01:26,093] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 13:01:26,929] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 13:01:26,929] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 13:01:27,603] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 13:01:27,603] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 13:01:27,603] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 13:01:27,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 13:01:27,604] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 13:01:27,604] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 13:01:27,604] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 13:01:27,604] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 13:01:27,604] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 13:01:27,604] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 13:01:27,994] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 13:01:27,995] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 13:01:27,996] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.49 GB, percent = 20.3%\n",
      "[2024-05-20 13:01:28,158] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 13:01:28,159] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 13:01:28,160] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.51 GB, percent = 20.3%\n",
      "[2024-05-20 13:01:28,160] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 13:01:28,316] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 13:01:28,317] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 13:01:28,317] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 153.6 GB, percent = 20.4%\n",
      "[2024-05-20 13:01:28,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 13:01:28,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 13:01:28,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 13:01:28,319] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 13:01:28,319] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9e624a6590>\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 13:01:28,320] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 13:01:28,321] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 13:01:28,322] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 13:01:28,323] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "14816it [11:03, 22.32it/s]\n",
      "Epoch: 1 cost time: 663.8861508369446\n",
      "3204it [01:17, 41.61it/s]\n",
      "3192it [01:18, 40.43it/s]\n",
      "Epoch: 1 | Train Loss: 0.4955682 Vali Loss: 0.4804414 Test Loss: 0.6038412 MAE Loss: 0.4934117\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "14816it [10:25, 23.67it/s]\n",
      "Epoch: 2 cost time: 625.889443397522\n",
      "3204it [01:11, 45.05it/s]\n",
      "3192it [01:11, 44.35it/s]\n",
      "Epoch: 2 | Train Loss: 0.3856661 Vali Loss: 0.4719015 Test Loss: 0.5948117 MAE Loss: 0.4796047\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "14816it [10:22, 23.81it/s]\n",
      "Epoch: 3 cost time: 622.1944086551666\n",
      "3204it [01:10, 45.39it/s]\n",
      "3192it [01:11, 44.51it/s]\n",
      "Epoch: 3 | Train Loss: 0.3707675 Vali Loss: 0.4613397 Test Loss: 0.5923879 MAE Loss: 0.4833428\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "14816it [10:26, 23.63it/s]\n",
      "Epoch: 4 cost time: 626.8920955657959\n",
      "3204it [01:11, 44.75it/s]\n",
      "3192it [01:11, 44.48it/s]\n",
      "Epoch: 4 | Train Loss: 0.3632406 Vali Loss: 0.4604734 Test Loss: 0.5918105 MAE Loss: 0.4814437\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "14816it [10:25, 23.67it/s]\n",
      "Epoch: 5 cost time: 625.9252734184265\n",
      "3204it [01:11, 44.74it/s]\n",
      "3192it [01:11, 44.48it/s]\n",
      "Epoch: 5 | Train Loss: 0.3595551 Vali Loss: 0.4577387 Test Loss: 0.5920409 MAE Loss: 0.4924704\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "14816it [10:22, 23.81it/s]\n",
      "Epoch: 6 cost time: 622.2301471233368\n",
      "3204it [01:11, 45.00it/s]\n",
      "3192it [01:12, 43.97it/s]\n",
      "Epoch: 6 | Train Loss: 0.3571855 Vali Loss: 0.4553436 Test Loss: 0.5902988 MAE Loss: 0.4806915\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "14816it [10:21, 23.82it/s]\n",
      "Epoch: 7 cost time: 621.9704089164734\n",
      "3204it [01:10, 45.32it/s]\n",
      "3192it [01:11, 44.51it/s]\n",
      "Epoch: 7 | Train Loss: 0.3559692 Vali Loss: 0.4552110 Test Loss: 0.5903031 MAE Loss: 0.4818928\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "14816it [10:25, 23.68it/s]\n",
      "Epoch: 8 cost time: 625.7869663238525\n",
      "3204it [01:09, 45.84it/s]\n",
      "3192it [01:10, 45.55it/s]\n",
      "Epoch: 8 | Train Loss: 0.3554344 Vali Loss: 0.4546038 Test Loss: 0.5893548 MAE Loss: 0.4829518\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "14816it [10:24, 23.73it/s]\n",
      "Epoch: 9 cost time: 624.4014823436737\n",
      "3204it [01:09, 45.83it/s]\n",
      "3192it [01:12, 44.16it/s]\n",
      "Epoch: 9 | Train Loss: 0.3548991 Vali Loss: 0.4544607 Test Loss: 0.5890798 MAE Loss: 0.4837787\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "14816it [10:46, 22.93it/s]\n",
      "Epoch: 10 cost time: 646.234103679657\n",
      "3204it [01:06, 47.86it/s]\n",
      "3192it [01:11, 44.83it/s]\n",
      "Epoch: 10 | Train Loss: 0.3553254 Vali Loss: 0.4546227 Test Loss: 0.5894614 MAE Loss: 0.4845496\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "14816it [11:06, 22.22it/s]\n",
      "Epoch: 11 cost time: 666.7052974700928\n",
      "3204it [01:09, 46.28it/s]\n",
      "3192it [01:10, 45.37it/s]\n",
      "Epoch: 11 | Train Loss: 0.3550324 Vali Loss: 0.4545572 Test Loss: 0.5893093 MAE Loss: 0.4834146\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "14816it [10:48, 22.84it/s]\n",
      "Epoch: 12 cost time: 648.7252752780914\n",
      "3204it [01:08, 47.03it/s]\n",
      "3192it [01:08, 46.42it/s]\n",
      "Epoch: 12 | Train Loss: 0.3547451 Vali Loss: 0.4543858 Test Loss: 0.5892781 MAE Loss: 0.4830649\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "14816it [10:54, 22.65it/s]\n",
      "Epoch: 13 cost time: 654.2382707595825\n",
      "3204it [01:08, 46.56it/s]\n",
      "3192it [01:12, 44.33it/s]\n",
      "Epoch: 13 | Train Loss: 0.3550528 Vali Loss: 0.4544939 Test Loss: 0.5893451 MAE Loss: 0.4833660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "14816it [10:56, 22.55it/s]\n",
      "Epoch: 14 cost time: 656.9983882904053\n",
      "3204it [01:10, 45.63it/s]\n",
      "3192it [01:11, 44.50it/s]\n",
      "Epoch: 14 | Train Loss: 0.3546695 Vali Loss: 0.4545505 Test Loss: 0.5893885 MAE Loss: 0.4835591\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "14816it [10:46, 22.90it/s]\n",
      "Epoch: 15 cost time: 646.8503074645996\n",
      "3204it [01:10, 45.35it/s]\n",
      "3192it [01:12, 44.22it/s]\n",
      "Epoch: 15 | Train Loss: 0.3548157 Vali Loss: 0.4545213 Test Loss: 0.5893993 MAE Loss: 0.4835596\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 196.0561461687088 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=50\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 16:19:51,742] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 16:19:53,056] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 16:19:53,057] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 16:19:53,057] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 16:19:53,955] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 16:19:53,955] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 16:19:54,611] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 16:19:54,613] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 16:19:54,613] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 16:19:54,614] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 16:19:54,614] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 16:19:54,614] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 16:19:54,615] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500,000,000\n",
      "[2024-05-20 16:19:54,615] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500,000,000\n",
      "[2024-05-20 16:19:54,615] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 16:19:54,615] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 16:19:55,034] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 16:19:55,036] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-20 16:19:55,036] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 157.9 GB, percent = 20.9%\n",
      "[2024-05-20 16:19:55,195] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 16:19:55,197] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 16:19:55,197] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 157.98 GB, percent = 20.9%\n",
      "[2024-05-20 16:19:55,197] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 16:19:55,398] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 16:19:55,399] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-20 16:19:55,399] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 158.03 GB, percent = 20.9%\n",
      "[2024-05-20 16:19:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 16:19:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 16:19:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 16:19:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 16:19:55,401] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 16:19:55,401] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 16:19:55,401] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 16:19:55,401] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 16:19:55,401] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1145ae1310>\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 16:19:55,402] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 16:19:55,403] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 16:19:55,404] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"none\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"none\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:05, 23.03it/s]\titers: 100, epoch: 1 | loss: 1.2100023\n",
      "\tspeed: 0.0972s/iter; left time: 71967.5976s\n",
      "198it [00:09, 22.65it/s]\titers: 200, epoch: 1 | loss: 0.4719745\n",
      "\tspeed: 0.0446s/iter; left time: 33059.3656s\n",
      "297it [00:14, 22.83it/s]\titers: 300, epoch: 1 | loss: 0.8270715\n",
      "\tspeed: 0.0455s/iter; left time: 33664.5508s\n",
      "399it [00:19, 18.15it/s]\titers: 400, epoch: 1 | loss: 0.8933063\n",
      "\tspeed: 0.0457s/iter; left time: 33825.0488s\n",
      "498it [00:24, 17.52it/s]\titers: 500, epoch: 1 | loss: 1.1096756\n",
      "\tspeed: 0.0557s/iter; left time: 41263.7256s\n",
      "597it [00:29, 23.22it/s]\titers: 600, epoch: 1 | loss: 1.0732007\n",
      "\tspeed: 0.0531s/iter; left time: 39315.7096s\n",
      "699it [00:34, 22.74it/s]\titers: 700, epoch: 1 | loss: 0.6724876\n",
      "\tspeed: 0.0453s/iter; left time: 33494.2717s\n",
      "798it [00:38, 23.74it/s]\titers: 800, epoch: 1 | loss: 0.4488840\n",
      "\tspeed: 0.0432s/iter; left time: 31974.5283s\n",
      "897it [00:42, 23.48it/s]\titers: 900, epoch: 1 | loss: 0.4415597\n",
      "\tspeed: 0.0425s/iter; left time: 31412.6564s\n",
      "999it [00:47, 22.99it/s]\titers: 1000, epoch: 1 | loss: 0.5833146\n",
      "\tspeed: 0.0431s/iter; left time: 31851.3333s\n",
      "1098it [00:51, 20.79it/s]\titers: 1100, epoch: 1 | loss: 0.4452401\n",
      "\tspeed: 0.0447s/iter; left time: 33091.5102s\n",
      "1197it [00:56, 19.84it/s]\titers: 1200, epoch: 1 | loss: 0.4246193\n",
      "\tspeed: 0.0466s/iter; left time: 34466.9378s\n",
      "1297it [01:01, 21.20it/s]\titers: 1300, epoch: 1 | loss: 0.8128982\n",
      "\tspeed: 0.0477s/iter; left time: 35283.0008s\n",
      "1399it [01:05, 23.15it/s]\titers: 1400, epoch: 1 | loss: 0.5363386\n",
      "\tspeed: 0.0434s/iter; left time: 32103.4693s\n",
      "1498it [01:10, 21.25it/s]\titers: 1500, epoch: 1 | loss: 0.8632331\n",
      "\tspeed: 0.0455s/iter; left time: 33627.7181s\n",
      "1597it [01:14, 22.28it/s]\titers: 1600, epoch: 1 | loss: 0.4425161\n",
      "\tspeed: 0.0446s/iter; left time: 32938.4835s\n",
      "1699it [01:19, 21.35it/s]\titers: 1700, epoch: 1 | loss: 0.9049737\n",
      "\tspeed: 0.0449s/iter; left time: 33191.4483s\n",
      "1798it [01:23, 22.58it/s]\titers: 1800, epoch: 1 | loss: 0.6961403\n",
      "\tspeed: 0.0434s/iter; left time: 32093.3506s\n",
      "1898it [01:28, 19.18it/s]\titers: 1900, epoch: 1 | loss: 0.7065306\n",
      "\tspeed: 0.0468s/iter; left time: 34560.2094s\n",
      "1998it [01:32, 26.29it/s]\titers: 2000, epoch: 1 | loss: 0.2669930\n",
      "\tspeed: 0.0414s/iter; left time: 30591.0617s\n",
      "2097it [01:36, 19.54it/s]\titers: 2100, epoch: 1 | loss: 0.4881725\n",
      "\tspeed: 0.0412s/iter; left time: 30433.8851s\n",
      "2199it [01:40, 21.48it/s]\titers: 2200, epoch: 1 | loss: 0.8746573\n",
      "\tspeed: 0.0446s/iter; left time: 32963.4355s\n",
      "2298it [01:45, 23.96it/s]\titers: 2300, epoch: 1 | loss: 1.1616392\n",
      "\tspeed: 0.0433s/iter; left time: 31985.9826s\n",
      "2397it [01:49, 23.52it/s]\titers: 2400, epoch: 1 | loss: 0.2961538\n",
      "\tspeed: 0.0441s/iter; left time: 32573.0230s\n",
      "2499it [01:54, 23.02it/s]\titers: 2500, epoch: 1 | loss: 0.4981700\n",
      "\tspeed: 0.0444s/iter; left time: 32803.4973s\n",
      "2598it [01:58, 22.04it/s]\titers: 2600, epoch: 1 | loss: 1.0616041\n",
      "\tspeed: 0.0453s/iter; left time: 33463.2479s\n",
      "2699it [02:04, 16.63it/s]\titers: 2700, epoch: 1 | loss: 0.9184409\n",
      "\tspeed: 0.0544s/iter; left time: 40164.1404s\n",
      "2797it [02:09, 20.41it/s]\titers: 2800, epoch: 1 | loss: 0.7068489\n",
      "\tspeed: 0.0578s/iter; left time: 42650.3485s\n",
      "2899it [02:14, 23.33it/s]\titers: 2900, epoch: 1 | loss: 0.5155199\n",
      "\tspeed: 0.0447s/iter; left time: 32998.7876s\n",
      "2998it [02:18, 24.00it/s]\titers: 3000, epoch: 1 | loss: 0.3697930\n",
      "\tspeed: 0.0432s/iter; left time: 31856.2847s\n",
      "3097it [02:22, 21.96it/s]\titers: 3100, epoch: 1 | loss: 1.7031286\n",
      "\tspeed: 0.0425s/iter; left time: 31353.7893s\n",
      "3199it [02:27, 22.69it/s]\titers: 3200, epoch: 1 | loss: 0.3750121\n",
      "\tspeed: 0.0428s/iter; left time: 31592.8576s\n",
      "3298it [02:31, 23.17it/s]\titers: 3300, epoch: 1 | loss: 0.1839736\n",
      "\tspeed: 0.0423s/iter; left time: 31167.1110s\n",
      "3397it [02:36, 20.61it/s]\titers: 3400, epoch: 1 | loss: 1.0785438\n",
      "\tspeed: 0.0479s/iter; left time: 35301.4600s\n",
      "3499it [02:40, 20.24it/s]\titers: 3500, epoch: 1 | loss: 0.6788548\n",
      "\tspeed: 0.0474s/iter; left time: 34978.7000s\n",
      "3599it [02:45, 22.36it/s]\titers: 3600, epoch: 1 | loss: 0.8473063\n",
      "\tspeed: 0.0458s/iter; left time: 33794.6955s\n",
      "3698it [02:50, 22.07it/s]\titers: 3700, epoch: 1 | loss: 0.3364809\n",
      "\tspeed: 0.0467s/iter; left time: 34431.5659s\n",
      "3797it [02:54, 22.74it/s]\titers: 3800, epoch: 1 | loss: 0.4078275\n",
      "\tspeed: 0.0451s/iter; left time: 33248.1598s\n",
      "3899it [02:59, 23.75it/s]\titers: 3900, epoch: 1 | loss: 0.6516296\n",
      "\tspeed: 0.0444s/iter; left time: 32708.8543s\n",
      "3998it [03:03, 21.89it/s]\titers: 4000, epoch: 1 | loss: 0.6825324\n",
      "\tspeed: 0.0456s/iter; left time: 33619.6251s\n",
      "4099it [03:08, 17.26it/s]\titers: 4100, epoch: 1 | loss: 0.4433888\n",
      "\tspeed: 0.0485s/iter; left time: 35753.2863s\n",
      "4199it [03:13, 16.61it/s]\titers: 4200, epoch: 1 | loss: 0.9938721\n",
      "\tspeed: 0.0524s/iter; left time: 38626.7573s\n",
      "4298it [03:18, 21.63it/s]\titers: 4300, epoch: 1 | loss: 0.3262190\n",
      "\tspeed: 0.0523s/iter; left time: 38516.8777s\n",
      "4397it [03:23, 23.36it/s]\titers: 4400, epoch: 1 | loss: 0.4855730\n",
      "\tspeed: 0.0455s/iter; left time: 33507.5637s\n",
      "4499it [03:28, 21.44it/s]\titers: 4500, epoch: 1 | loss: 0.1956166\n",
      "\tspeed: 0.0452s/iter; left time: 33261.4650s\n",
      "4598it [03:32, 22.40it/s]\titers: 4600, epoch: 1 | loss: 0.2855468\n",
      "\tspeed: 0.0451s/iter; left time: 33200.5342s\n",
      "4697it [03:36, 22.43it/s]\titers: 4700, epoch: 1 | loss: 1.2788696\n",
      "\tspeed: 0.0453s/iter; left time: 33322.2424s\n",
      "4799it [03:41, 18.29it/s]\titers: 4800, epoch: 1 | loss: 0.3046062\n",
      "\tspeed: 0.0486s/iter; left time: 35795.2814s\n",
      "4899it [03:47, 16.68it/s]\titers: 4900, epoch: 1 | loss: 0.4774517\n",
      "\tspeed: 0.0598s/iter; left time: 43988.5539s\n",
      "4998it [03:52, 22.75it/s]\titers: 5000, epoch: 1 | loss: 0.5055078\n",
      "\tspeed: 0.0484s/iter; left time: 35638.6452s\n",
      "5097it [03:57, 23.02it/s]\titers: 5100, epoch: 1 | loss: 0.7752290\n",
      "\tspeed: 0.0441s/iter; left time: 32449.5576s\n",
      "5199it [04:01, 23.18it/s]\titers: 5200, epoch: 1 | loss: 0.3553796\n",
      "\tspeed: 0.0429s/iter; left time: 31554.8150s\n",
      "5298it [04:05, 22.38it/s]\titers: 5300, epoch: 1 | loss: 1.2170597\n",
      "\tspeed: 0.0434s/iter; left time: 31899.9033s\n",
      "5397it [04:10, 21.80it/s]\titers: 5400, epoch: 1 | loss: 0.3382396\n",
      "\tspeed: 0.0437s/iter; left time: 32112.6463s\n",
      "5499it [04:14, 21.45it/s]\titers: 5500, epoch: 1 | loss: 0.1891921\n",
      "\tspeed: 0.0454s/iter; left time: 33367.4693s\n",
      "5597it [04:19, 19.91it/s]\titers: 5600, epoch: 1 | loss: 0.2955888\n",
      "\tspeed: 0.0480s/iter; left time: 35300.3138s\n",
      "5699it [04:24, 17.67it/s]\titers: 5700, epoch: 1 | loss: 0.2907146\n",
      "\tspeed: 0.0496s/iter; left time: 36452.8024s\n",
      "5798it [04:29, 23.06it/s]\titers: 5800, epoch: 1 | loss: 0.4387524\n",
      "\tspeed: 0.0471s/iter; left time: 34599.4237s\n",
      "5897it [04:33, 23.43it/s]\titers: 5900, epoch: 1 | loss: 0.2277153\n",
      "\tspeed: 0.0445s/iter; left time: 32698.6059s\n",
      "5999it [04:38, 23.16it/s]\titers: 6000, epoch: 1 | loss: 0.1939872\n",
      "\tspeed: 0.0446s/iter; left time: 32745.8446s\n",
      "6098it [04:42, 21.92it/s]\titers: 6100, epoch: 1 | loss: 0.2317864\n",
      "\tspeed: 0.0452s/iter; left time: 33176.8465s\n",
      "6197it [04:46, 23.29it/s]\titers: 6200, epoch: 1 | loss: 0.5303420\n",
      "\tspeed: 0.0445s/iter; left time: 32717.1126s\n",
      "6299it [04:52, 16.52it/s]\titers: 6300, epoch: 1 | loss: 0.4089229\n",
      "\tspeed: 0.0501s/iter; left time: 36804.6012s\n",
      "6398it [04:57, 24.43it/s]\titers: 6400, epoch: 1 | loss: 0.1928583\n",
      "\tspeed: 0.0562s/iter; left time: 41300.3280s\n",
      "6497it [05:02, 21.91it/s]\titers: 6500, epoch: 1 | loss: 0.2946931\n",
      "\tspeed: 0.0460s/iter; left time: 33742.4127s\n",
      "6599it [05:06, 23.55it/s]\titers: 6600, epoch: 1 | loss: 0.6640747\n",
      "\tspeed: 0.0447s/iter; left time: 32846.0363s\n",
      "6698it [05:11, 20.88it/s]\titers: 6700, epoch: 1 | loss: 0.2682841\n",
      "\tspeed: 0.0449s/iter; left time: 32966.3909s\n",
      "6797it [05:15, 21.93it/s]\titers: 6800, epoch: 1 | loss: 0.2828879\n",
      "\tspeed: 0.0446s/iter; left time: 32720.3362s\n",
      "6899it [05:20, 22.98it/s]\titers: 6900, epoch: 1 | loss: 0.5458733\n",
      "\tspeed: 0.0440s/iter; left time: 32286.7506s\n",
      "6997it [05:25, 20.86it/s]\titers: 7000, epoch: 1 | loss: 0.2802522\n",
      "\tspeed: 0.0515s/iter; left time: 37778.8625s\n",
      "7099it [05:30, 17.55it/s]\titers: 7100, epoch: 1 | loss: 0.3009359\n",
      "\tspeed: 0.0542s/iter; left time: 39738.1707s\n",
      "7199it [05:35, 22.44it/s]\titers: 7200, epoch: 1 | loss: 0.2249059\n",
      "\tspeed: 0.0474s/iter; left time: 34785.4187s\n",
      "7298it [05:39, 23.74it/s]\titers: 7300, epoch: 1 | loss: 0.7087804\n",
      "\tspeed: 0.0424s/iter; left time: 31071.9282s\n",
      "7397it [05:43, 23.54it/s]\titers: 7400, epoch: 1 | loss: 0.4487431\n",
      "\tspeed: 0.0427s/iter; left time: 31316.8713s\n",
      "7499it [05:48, 23.50it/s]\titers: 7500, epoch: 1 | loss: 0.3811559\n",
      "\tspeed: 0.0434s/iter; left time: 31853.8969s\n",
      "7598it [05:52, 23.27it/s]\titers: 7600, epoch: 1 | loss: 0.4741640\n",
      "\tspeed: 0.0434s/iter; left time: 31845.3243s\n",
      "7699it [05:57, 20.91it/s]\titers: 7700, epoch: 1 | loss: 0.2948685\n",
      "\tspeed: 0.0465s/iter; left time: 34088.5837s\n",
      "7799it [06:02, 20.22it/s]\titers: 7800, epoch: 1 | loss: 0.1803007\n",
      "\tspeed: 0.0500s/iter; left time: 36633.4162s\n",
      "7898it [06:07, 22.21it/s]\titers: 7900, epoch: 1 | loss: 0.3735719\n",
      "\tspeed: 0.0523s/iter; left time: 38314.3845s\n",
      "7997it [06:11, 22.33it/s]\titers: 8000, epoch: 1 | loss: 0.1715254\n",
      "\tspeed: 0.0448s/iter; left time: 32819.8058s\n",
      "8099it [06:16, 21.64it/s]\titers: 8100, epoch: 1 | loss: 0.1723867\n",
      "\tspeed: 0.0441s/iter; left time: 32337.6963s\n",
      "8198it [06:20, 21.62it/s]\titers: 8200, epoch: 1 | loss: 0.8741489\n",
      "\tspeed: 0.0453s/iter; left time: 33184.2418s\n",
      "8297it [06:25, 21.68it/s]\titers: 8300, epoch: 1 | loss: 0.5079411\n",
      "\tspeed: 0.0451s/iter; left time: 33047.2061s\n",
      "8398it [06:30, 18.18it/s]\titers: 8400, epoch: 1 | loss: 0.4221446\n",
      "\tspeed: 0.0502s/iter; left time: 36767.4486s\n",
      "8499it [06:36, 16.54it/s]\titers: 8500, epoch: 1 | loss: 0.5190887\n",
      "\tspeed: 0.0593s/iter; left time: 43428.2031s\n",
      "8598it [06:41, 22.80it/s]\titers: 8600, epoch: 1 | loss: 0.5163773\n",
      "\tspeed: 0.0504s/iter; left time: 36874.0894s\n",
      "8697it [06:45, 23.35it/s]\titers: 8700, epoch: 1 | loss: 0.2107243\n",
      "\tspeed: 0.0442s/iter; left time: 32326.5370s\n",
      "8799it [06:50, 21.69it/s]\titers: 8800, epoch: 1 | loss: 1.8230904\n",
      "\tspeed: 0.0448s/iter; left time: 32791.8700s\n",
      "8898it [06:54, 21.41it/s]\titers: 8900, epoch: 1 | loss: 0.7863830\n",
      "\tspeed: 0.0461s/iter; left time: 33737.9655s\n",
      "8997it [06:59, 22.49it/s]\titers: 9000, epoch: 1 | loss: 0.1825612\n",
      "\tspeed: 0.0454s/iter; left time: 33219.9877s\n",
      "9098it [07:03, 18.44it/s]\titers: 9100, epoch: 1 | loss: 0.1264677\n",
      "\tspeed: 0.0457s/iter; left time: 33420.1457s\n",
      "9198it [07:09, 16.52it/s]\titers: 9200, epoch: 1 | loss: 0.5377688\n",
      "\tspeed: 0.0600s/iter; left time: 43918.2384s\n",
      "9297it [07:14, 22.40it/s]\titers: 9300, epoch: 1 | loss: 0.8846996\n",
      "\tspeed: 0.0507s/iter; left time: 37100.4421s\n",
      "9399it [07:19, 23.49it/s]\titers: 9400, epoch: 1 | loss: 0.7158275\n",
      "\tspeed: 0.0431s/iter; left time: 31529.1843s\n",
      "9498it [07:23, 22.47it/s]\titers: 9500, epoch: 1 | loss: 0.2976035\n",
      "\tspeed: 0.0423s/iter; left time: 30933.6698s\n",
      "9597it [07:27, 25.16it/s]\titers: 9600, epoch: 1 | loss: 0.3770229\n",
      "\tspeed: 0.0428s/iter; left time: 31319.3052s\n",
      "9699it [07:32, 22.45it/s]\titers: 9700, epoch: 1 | loss: 0.4641332\n",
      "\tspeed: 0.0426s/iter; left time: 31124.4545s\n",
      "9798it [07:36, 21.57it/s]\titers: 9800, epoch: 1 | loss: 0.3670942\n",
      "\tspeed: 0.0435s/iter; left time: 31772.3740s\n",
      "9899it [07:41, 18.79it/s]\titers: 9900, epoch: 1 | loss: 0.4804549\n",
      "\tspeed: 0.0509s/iter; left time: 37219.3174s\n",
      "9998it [07:45, 25.70it/s]\titers: 10000, epoch: 1 | loss: 0.4358552\n",
      "\tspeed: 0.0431s/iter; left time: 31473.9171s\n",
      "10098it [07:50, 21.28it/s]\titers: 10100, epoch: 1 | loss: 0.2683017\n",
      "\tspeed: 0.0500s/iter; left time: 36552.6734s\n",
      "10197it [07:55, 22.49it/s]\titers: 10200, epoch: 1 | loss: 0.2550182\n",
      "\tspeed: 0.0450s/iter; left time: 32860.6155s\n",
      "10299it [08:00, 22.36it/s]\titers: 10300, epoch: 1 | loss: 0.3009215\n",
      "\tspeed: 0.0462s/iter; left time: 33724.4853s\n",
      "10398it [08:04, 24.11it/s]\titers: 10400, epoch: 1 | loss: 0.2636962\n",
      "\tspeed: 0.0436s/iter; left time: 31869.7459s\n",
      "10497it [08:08, 21.06it/s]\titers: 10500, epoch: 1 | loss: 0.3230118\n",
      "\tspeed: 0.0452s/iter; left time: 33020.3481s\n",
      "10598it [08:14, 16.43it/s]\titers: 10600, epoch: 1 | loss: 0.1425342\n",
      "\tspeed: 0.0523s/iter; left time: 38154.7268s\n",
      "10697it [08:18, 25.92it/s]\titers: 10700, epoch: 1 | loss: 0.0943355\n",
      "\tspeed: 0.0496s/iter; left time: 36243.4564s\n",
      "10797it [08:23, 21.65it/s]\titers: 10800, epoch: 1 | loss: 0.1555537\n",
      "\tspeed: 0.0480s/iter; left time: 35020.2882s\n",
      "10899it [08:28, 23.46it/s]\titers: 10900, epoch: 1 | loss: 0.4060164\n",
      "\tspeed: 0.0443s/iter; left time: 32321.9965s\n",
      "10998it [08:32, 23.20it/s]\titers: 11000, epoch: 1 | loss: 0.1792986\n",
      "\tspeed: 0.0445s/iter; left time: 32445.8935s\n",
      "11097it [08:37, 21.99it/s]\titers: 11100, epoch: 1 | loss: 0.1975928\n",
      "\tspeed: 0.0436s/iter; left time: 31803.8615s\n",
      "11199it [08:41, 22.15it/s]\titers: 11200, epoch: 1 | loss: 1.1800880\n",
      "\tspeed: 0.0445s/iter; left time: 32491.1909s\n",
      "11298it [08:46, 16.68it/s]\titers: 11300, epoch: 1 | loss: 0.5712709\n",
      "\tspeed: 0.0521s/iter; left time: 38036.7890s\n",
      "11399it [08:52, 15.96it/s]\titers: 11400, epoch: 1 | loss: 0.1855741\n",
      "\tspeed: 0.0611s/iter; left time: 44576.4397s\n",
      "11499it [08:57, 24.11it/s]\titers: 11500, epoch: 1 | loss: 0.1726841\n",
      "\tspeed: 0.0426s/iter; left time: 31090.0826s\n",
      "11598it [09:01, 22.68it/s]\titers: 11600, epoch: 1 | loss: 0.1752069\n",
      "\tspeed: 0.0427s/iter; left time: 31130.7716s\n",
      "11697it [09:05, 23.26it/s]\titers: 11700, epoch: 1 | loss: 0.4001184\n",
      "\tspeed: 0.0434s/iter; left time: 31641.3540s\n",
      "11799it [09:10, 23.38it/s]\titers: 11800, epoch: 1 | loss: 0.2365575\n",
      "\tspeed: 0.0434s/iter; left time: 31605.1014s\n",
      "11898it [09:14, 23.77it/s]\titers: 11900, epoch: 1 | loss: 0.2805452\n",
      "\tspeed: 0.0424s/iter; left time: 30911.9732s\n",
      "11998it [09:19, 20.37it/s]\titers: 12000, epoch: 1 | loss: 0.6049389\n",
      "\tspeed: 0.0473s/iter; left time: 34479.0728s\n",
      "12098it [09:24, 16.09it/s]\titers: 12100, epoch: 1 | loss: 0.2734621\n",
      "\tspeed: 0.0529s/iter; left time: 38558.4010s\n",
      "12199it [09:29, 22.32it/s]\titers: 12200, epoch: 1 | loss: 0.1548900\n",
      "\tspeed: 0.0555s/iter; left time: 40461.2545s\n",
      "12298it [09:34, 21.25it/s]\titers: 12300, epoch: 1 | loss: 0.1988429\n",
      "\tspeed: 0.0457s/iter; left time: 33318.6995s\n",
      "12397it [09:38, 22.97it/s]\titers: 12400, epoch: 1 | loss: 0.5242033\n",
      "\tspeed: 0.0443s/iter; left time: 32303.5593s\n",
      "12499it [09:43, 21.71it/s]\titers: 12500, epoch: 1 | loss: 0.5833334\n",
      "\tspeed: 0.0451s/iter; left time: 32812.5568s\n",
      "12598it [09:47, 21.23it/s]\titers: 12600, epoch: 1 | loss: 0.5361513\n",
      "\tspeed: 0.0459s/iter; left time: 33425.8854s\n",
      "12697it [09:52, 22.05it/s]\titers: 12700, epoch: 1 | loss: 0.2606279\n",
      "\tspeed: 0.0467s/iter; left time: 33973.6849s\n",
      "12799it [09:58, 17.17it/s]\titers: 12800, epoch: 1 | loss: 0.2270386\n",
      "\tspeed: 0.0569s/iter; left time: 41429.6186s\n",
      "12897it [10:04, 19.98it/s]\titers: 12900, epoch: 1 | loss: 0.2341306\n",
      "\tspeed: 0.0573s/iter; left time: 41680.4153s\n",
      "12999it [10:08, 22.61it/s]\titers: 13000, epoch: 1 | loss: 0.2403391\n",
      "\tspeed: 0.0438s/iter; left time: 31880.7369s\n",
      "13098it [10:12, 22.19it/s]\titers: 13100, epoch: 1 | loss: 0.1335177\n",
      "\tspeed: 0.0439s/iter; left time: 31919.7291s\n",
      "13197it [10:17, 23.30it/s]\titers: 13200, epoch: 1 | loss: 0.4476753\n",
      "\tspeed: 0.0439s/iter; left time: 31922.4117s\n",
      "13299it [10:21, 22.34it/s]\titers: 13300, epoch: 1 | loss: 0.8063035\n",
      "\tspeed: 0.0431s/iter; left time: 31341.3837s\n",
      "13398it [10:26, 21.97it/s]\titers: 13400, epoch: 1 | loss: 0.4766203\n",
      "\tspeed: 0.0451s/iter; left time: 32808.3743s\n",
      "13499it [10:31, 16.52it/s]\titers: 13500, epoch: 1 | loss: 0.3440460\n",
      "\tspeed: 0.0572s/iter; left time: 41603.0549s\n",
      "13598it [10:36, 22.35it/s]\titers: 13600, epoch: 1 | loss: 0.1265269\n",
      "\tspeed: 0.0502s/iter; left time: 36493.3761s\n",
      "13697it [10:40, 23.71it/s]\titers: 13700, epoch: 1 | loss: 0.5715402\n",
      "\tspeed: 0.0418s/iter; left time: 30360.2837s\n",
      "13799it [10:45, 23.91it/s]\titers: 13800, epoch: 1 | loss: 0.3003829\n",
      "\tspeed: 0.0418s/iter; left time: 30413.5863s\n",
      "13898it [10:49, 24.38it/s]\titers: 13900, epoch: 1 | loss: 0.2409656\n",
      "\tspeed: 0.0419s/iter; left time: 30442.1700s\n",
      "13997it [10:53, 23.63it/s]\titers: 14000, epoch: 1 | loss: 0.2682968\n",
      "\tspeed: 0.0427s/iter; left time: 31044.4824s\n",
      "14099it [10:57, 23.10it/s]\titers: 14100, epoch: 1 | loss: 0.2582831\n",
      "\tspeed: 0.0423s/iter; left time: 30736.2419s\n",
      "14196it [11:01, 27.08it/s]\titers: 14200, epoch: 1 | loss: 0.2974715\n",
      "\tspeed: 0.0388s/iter; left time: 28224.7901s\n",
      "14297it [11:05, 19.04it/s]\titers: 14300, epoch: 1 | loss: 0.2119940\n",
      "\tspeed: 0.0409s/iter; left time: 29722.3984s\n",
      "14398it [11:11, 16.54it/s]\titers: 14400, epoch: 1 | loss: 0.1829525\n",
      "\tspeed: 0.0588s/iter; left time: 42702.4317s\n",
      "14497it [11:16, 22.89it/s]\titers: 14500, epoch: 1 | loss: 0.2604047\n",
      "\tspeed: 0.0504s/iter; left time: 36618.1280s\n",
      "14599it [11:21, 23.44it/s]\titers: 14600, epoch: 1 | loss: 0.5738366\n",
      "\tspeed: 0.0445s/iter; left time: 32310.6485s\n",
      "14698it [11:25, 23.37it/s]\titers: 14700, epoch: 1 | loss: 0.3689606\n",
      "\tspeed: 0.0433s/iter; left time: 31441.7550s\n",
      "14797it [11:30, 22.63it/s]\titers: 14800, epoch: 1 | loss: 0.3793266\n",
      "\tspeed: 0.0458s/iter; left time: 33219.3702s\n",
      "14816it [11:30, 21.44it/s]\n",
      "Epoch: 1 cost time: 690.9120903015137\n",
      "3204it [01:17, 41.38it/s]\n",
      "3192it [01:15, 42.08it/s]\n",
      "Epoch: 1 | Train Loss: 0.4955682 Vali Loss: 0.4804414 Test Loss: 0.6038412 MAE Loss: 0.4934117\n",
      "Validation loss decreased (inf --> 0.480441).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "97it [00:04, 24.44it/s]\titers: 100, epoch: 2 | loss: 0.4087486\n",
      "\tspeed: 1.5970s/iter; left time: 1159231.6720s\n",
      "199it [00:08, 24.75it/s]\titers: 200, epoch: 2 | loss: 0.2096149\n",
      "\tspeed: 0.0405s/iter; left time: 29423.9029s\n",
      "297it [00:12, 27.80it/s]\titers: 300, epoch: 2 | loss: 0.6823894\n",
      "\tspeed: 0.0375s/iter; left time: 27208.1233s\n",
      "399it [00:16, 18.65it/s]\titers: 400, epoch: 2 | loss: 0.4070836\n",
      "\tspeed: 0.0398s/iter; left time: 28901.2307s\n",
      "498it [00:21, 18.89it/s]\titers: 500, epoch: 2 | loss: 0.2560939\n",
      "\tspeed: 0.0539s/iter; left time: 39081.2895s\n",
      "599it [00:26, 22.22it/s]\titers: 600, epoch: 2 | loss: 0.2489785\n",
      "\tspeed: 0.0504s/iter; left time: 36537.0194s\n",
      "699it [00:30, 24.93it/s]\titers: 700, epoch: 2 | loss: 0.2296976\n",
      "\tspeed: 0.0422s/iter; left time: 30622.0057s\n",
      "798it [00:35, 23.45it/s]\titers: 800, epoch: 2 | loss: 0.3975549\n",
      "\tspeed: 0.0423s/iter; left time: 30710.4653s\n",
      "897it [00:39, 21.47it/s]\titers: 900, epoch: 2 | loss: 0.4848240\n",
      "\tspeed: 0.0452s/iter; left time: 32765.3399s\n",
      "999it [00:43, 22.64it/s]\titers: 1000, epoch: 2 | loss: 0.1795153\n",
      "\tspeed: 0.0433s/iter; left time: 31404.7031s\n",
      "1098it [00:48, 18.18it/s]\titers: 1100, epoch: 2 | loss: 0.1902396\n",
      "\tspeed: 0.0460s/iter; left time: 33345.1777s\n",
      "1198it [00:53, 17.83it/s]\titers: 1200, epoch: 2 | loss: 0.4005301\n",
      "\tspeed: 0.0545s/iter; left time: 39533.8762s\n",
      "1299it [00:58, 25.06it/s]\titers: 1300, epoch: 2 | loss: 0.4403698\n",
      "\tspeed: 0.0495s/iter; left time: 35895.0135s\n",
      "1399it [01:03, 23.85it/s]\titers: 1400, epoch: 2 | loss: 0.1817827\n",
      "\tspeed: 0.0416s/iter; left time: 30140.0883s\n",
      "1497it [01:07, 23.31it/s]\titers: 1500, epoch: 2 | loss: 0.2190758\n",
      "\tspeed: 0.0407s/iter; left time: 29496.1221s\n",
      "1599it [01:11, 23.30it/s]\titers: 1600, epoch: 2 | loss: 0.2425815\n",
      "\tspeed: 0.0429s/iter; left time: 31090.0174s\n",
      "1698it [01:15, 23.08it/s]\titers: 1700, epoch: 2 | loss: 0.2168809\n",
      "\tspeed: 0.0425s/iter; left time: 30809.9749s\n",
      "1797it [01:19, 23.49it/s]\titers: 1800, epoch: 2 | loss: 0.1285856\n",
      "\tspeed: 0.0423s/iter; left time: 30655.6820s\n",
      "1897it [01:24, 20.45it/s]\titers: 1900, epoch: 2 | loss: 0.7902218\n",
      "\tspeed: 0.0473s/iter; left time: 34237.5073s\n",
      "1999it [01:29, 22.71it/s]\titers: 2000, epoch: 2 | loss: 0.6439389\n",
      "\tspeed: 0.0461s/iter; left time: 33346.2896s\n",
      "2098it [01:33, 26.02it/s]\titers: 2100, epoch: 2 | loss: 0.4022671\n",
      "\tspeed: 0.0420s/iter; left time: 30396.3048s\n",
      "2197it [01:37, 24.60it/s]\titers: 2200, epoch: 2 | loss: 0.0857176\n",
      "\tspeed: 0.0397s/iter; left time: 28742.8860s\n",
      "2299it [01:41, 25.75it/s]\titers: 2300, epoch: 2 | loss: 0.4685104\n",
      "\tspeed: 0.0404s/iter; left time: 29216.2638s\n",
      "2399it [01:45, 24.61it/s]\titers: 2400, epoch: 2 | loss: 0.2601773\n",
      "\tspeed: 0.0406s/iter; left time: 29353.7537s\n",
      "2498it [01:49, 21.94it/s]\titers: 2500, epoch: 2 | loss: 0.4417733\n",
      "\tspeed: 0.0428s/iter; left time: 30964.3264s\n",
      "2597it [01:54, 21.72it/s]\titers: 2600, epoch: 2 | loss: 0.5574515\n",
      "\tspeed: 0.0437s/iter; left time: 31602.8277s\n",
      "2699it [01:59, 16.53it/s]\titers: 2700, epoch: 2 | loss: 0.4352033\n",
      "\tspeed: 0.0543s/iter; left time: 39280.4357s\n",
      "2799it [02:05, 18.36it/s]\titers: 2800, epoch: 2 | loss: 0.2201878\n",
      "\tspeed: 0.0570s/iter; left time: 41216.9003s\n",
      "2899it [02:09, 24.86it/s]\titers: 2900, epoch: 2 | loss: 0.2412534\n",
      "\tspeed: 0.0426s/iter; left time: 30803.8105s\n",
      "2998it [02:13, 23.33it/s]\titers: 3000, epoch: 2 | loss: 0.7555633\n",
      "\tspeed: 0.0425s/iter; left time: 30710.1733s\n",
      "3097it [02:17, 24.14it/s]\titers: 3100, epoch: 2 | loss: 0.4107915\n",
      "\tspeed: 0.0416s/iter; left time: 30079.3897s\n",
      "3199it [02:22, 21.73it/s]\titers: 3200, epoch: 2 | loss: 0.3677379\n",
      "\tspeed: 0.0432s/iter; left time: 31242.0455s\n",
      "3298it [02:26, 23.35it/s]\titers: 3300, epoch: 2 | loss: 0.8528661\n",
      "\tspeed: 0.0427s/iter; left time: 30854.1902s\n",
      "3398it [02:31, 17.94it/s]\titers: 3400, epoch: 2 | loss: 0.2455551\n",
      "\tspeed: 0.0489s/iter; left time: 35346.9232s\n",
      "3498it [02:37, 17.12it/s]\titers: 3500, epoch: 2 | loss: 0.2114689\n",
      "\tspeed: 0.0578s/iter; left time: 41783.9016s\n",
      "3597it [02:41, 24.13it/s]\titers: 3600, epoch: 2 | loss: 0.2566910\n",
      "\tspeed: 0.0460s/iter; left time: 33223.7140s\n",
      "3699it [02:46, 24.27it/s]\titers: 3700, epoch: 2 | loss: 0.6274682\n",
      "\tspeed: 0.0419s/iter; left time: 30258.0281s\n",
      "3798it [02:50, 22.36it/s]\titers: 3800, epoch: 2 | loss: 0.2936935\n",
      "\tspeed: 0.0418s/iter; left time: 30191.5674s\n",
      "3897it [02:54, 25.04it/s]\titers: 3900, epoch: 2 | loss: 0.1358667\n",
      "\tspeed: 0.0413s/iter; left time: 29855.5273s\n",
      "3999it [02:58, 24.62it/s]\titers: 4000, epoch: 2 | loss: 0.3150377\n",
      "\tspeed: 0.0418s/iter; left time: 30162.0578s\n",
      "4098it [03:03, 19.66it/s]\titers: 4100, epoch: 2 | loss: 0.3238904\n",
      "\tspeed: 0.0484s/iter; left time: 34934.9702s\n",
      "4199it [03:07, 21.98it/s]\titers: 4200, epoch: 2 | loss: 0.3327637\n",
      "\tspeed: 0.0456s/iter; left time: 32901.0931s\n",
      "4298it [03:12, 23.02it/s]\titers: 4300, epoch: 2 | loss: 0.3811989\n",
      "\tspeed: 0.0440s/iter; left time: 31728.9593s\n",
      "4397it [03:16, 24.01it/s]\titers: 4400, epoch: 2 | loss: 0.5556164\n",
      "\tspeed: 0.0409s/iter; left time: 29516.4903s\n",
      "4499it [03:20, 24.17it/s]\titers: 4500, epoch: 2 | loss: 0.7829426\n",
      "\tspeed: 0.0407s/iter; left time: 29337.2657s\n",
      "4598it [03:24, 26.01it/s]\titers: 4600, epoch: 2 | loss: 0.1537062\n",
      "\tspeed: 0.0403s/iter; left time: 29084.2176s\n",
      "4697it [03:28, 26.32it/s]\titers: 4700, epoch: 2 | loss: 0.5796785\n",
      "\tspeed: 0.0395s/iter; left time: 28458.0427s\n",
      "4799it [03:32, 19.69it/s]\titers: 4800, epoch: 2 | loss: 0.1229288\n",
      "\tspeed: 0.0439s/iter; left time: 31645.2385s\n",
      "4899it [03:37, 28.76it/s]\titers: 4900, epoch: 2 | loss: 0.2861868\n",
      "\tspeed: 0.0426s/iter; left time: 30704.0994s\n",
      "4998it [03:40, 25.62it/s]\titers: 5000, epoch: 2 | loss: 0.1743478\n",
      "\tspeed: 0.0382s/iter; left time: 27515.4725s\n",
      "5098it [03:45, 27.79it/s]\titers: 5100, epoch: 2 | loss: 0.8171138\n",
      "\tspeed: 0.0422s/iter; left time: 30425.7110s\n",
      "5198it [03:49, 22.93it/s]\titers: 5200, epoch: 2 | loss: 0.7649007\n",
      "\tspeed: 0.0402s/iter; left time: 28993.2968s\n",
      "5297it [03:53, 22.05it/s]\titers: 5300, epoch: 2 | loss: 0.7802441\n",
      "\tspeed: 0.0428s/iter; left time: 30826.8466s\n",
      "5399it [03:57, 24.80it/s]\titers: 5400, epoch: 2 | loss: 0.8983614\n",
      "\tspeed: 0.0429s/iter; left time: 30904.4873s\n",
      "5498it [04:02, 22.82it/s]\titers: 5500, epoch: 2 | loss: 0.5329815\n",
      "\tspeed: 0.0435s/iter; left time: 31349.4022s\n",
      "5597it [04:06, 25.03it/s]\titers: 5600, epoch: 2 | loss: 0.0842553\n",
      "\tspeed: 0.0419s/iter; left time: 30204.3009s\n",
      "5698it [04:11, 17.54it/s]\titers: 5700, epoch: 2 | loss: 0.3948147\n",
      "\tspeed: 0.0472s/iter; left time: 34025.2964s\n",
      "5798it [04:16, 16.56it/s]\titers: 5800, epoch: 2 | loss: 0.1870982\n",
      "\tspeed: 0.0581s/iter; left time: 41814.9284s\n",
      "5897it [04:21, 24.81it/s]\titers: 5900, epoch: 2 | loss: 0.5340365\n",
      "\tspeed: 0.0491s/iter; left time: 35369.6528s\n",
      "5997it [04:25, 23.99it/s]\titers: 6000, epoch: 2 | loss: 0.0910232\n",
      "\tspeed: 0.0416s/iter; left time: 29926.5000s\n",
      "6099it [04:30, 22.91it/s]\titers: 6100, epoch: 2 | loss: 0.6611117\n",
      "\tspeed: 0.0435s/iter; left time: 31300.2002s\n",
      "6199it [04:34, 24.35it/s]\titers: 6200, epoch: 2 | loss: 0.1685711\n",
      "\tspeed: 0.0415s/iter; left time: 29880.7107s\n",
      "6298it [04:38, 24.37it/s]\titers: 6300, epoch: 2 | loss: 0.3941843\n",
      "\tspeed: 0.0422s/iter; left time: 30335.9387s\n",
      "6397it [04:43, 22.42it/s]\titers: 6400, epoch: 2 | loss: 0.5534138\n",
      "\tspeed: 0.0442s/iter; left time: 31816.2670s\n",
      "6499it [04:47, 20.91it/s]\titers: 6500, epoch: 2 | loss: 1.2748663\n",
      "\tspeed: 0.0471s/iter; left time: 33858.1791s\n",
      "6598it [04:52, 21.05it/s]\titers: 6600, epoch: 2 | loss: 0.2111511\n",
      "\tspeed: 0.0467s/iter; left time: 33576.9949s\n",
      "6699it [04:56, 22.58it/s]\titers: 6700, epoch: 2 | loss: 0.2078537\n",
      "\tspeed: 0.0426s/iter; left time: 30642.9866s\n",
      "6798it [05:00, 25.86it/s]\titers: 6800, epoch: 2 | loss: 0.2163189\n",
      "\tspeed: 0.0395s/iter; left time: 28401.0229s\n",
      "6897it [05:04, 25.75it/s]\titers: 6900, epoch: 2 | loss: 0.1972964\n",
      "\tspeed: 0.0402s/iter; left time: 28918.2012s\n",
      "6999it [05:08, 24.88it/s]\titers: 7000, epoch: 2 | loss: 0.3914500\n",
      "\tspeed: 0.0409s/iter; left time: 29421.4954s\n",
      "7098it [05:13, 24.21it/s]\titers: 7100, epoch: 2 | loss: 0.4291026\n",
      "\tspeed: 0.0426s/iter; left time: 30651.7305s\n",
      "7197it [05:17, 21.74it/s]\titers: 7200, epoch: 2 | loss: 0.1522719\n",
      "\tspeed: 0.0452s/iter; left time: 32482.6520s\n",
      "7299it [05:22, 16.49it/s]\titers: 7300, epoch: 2 | loss: 0.1461294\n",
      "\tspeed: 0.0538s/iter; left time: 38653.1618s\n",
      "7397it [05:28, 20.31it/s]\titers: 7400, epoch: 2 | loss: 0.2227389\n",
      "\tspeed: 0.0563s/iter; left time: 40422.7088s\n",
      "7497it [05:32, 23.78it/s]\titers: 7500, epoch: 2 | loss: 0.2863886\n",
      "\tspeed: 0.0418s/iter; left time: 30013.4485s\n",
      "7599it [05:36, 25.00it/s]\titers: 7600, epoch: 2 | loss: 0.1712186\n",
      "\tspeed: 0.0413s/iter; left time: 29634.4466s\n",
      "7698it [05:41, 23.11it/s]\titers: 7700, epoch: 2 | loss: 0.2930794\n",
      "\tspeed: 0.0421s/iter; left time: 30247.1078s\n",
      "7798it [05:45, 19.31it/s]\titers: 7800, epoch: 2 | loss: 0.2070568\n",
      "\tspeed: 0.0447s/iter; left time: 32078.9730s\n",
      "7898it [05:49, 23.16it/s]\titers: 7900, epoch: 2 | loss: 0.1014684\n",
      "\tspeed: 0.0445s/iter; left time: 31922.9867s\n",
      "7998it [05:54, 17.85it/s]\titers: 8000, epoch: 2 | loss: 0.1183595\n",
      "\tspeed: 0.0500s/iter; left time: 35888.1301s\n",
      "8099it [06:00, 17.81it/s]\titers: 8100, epoch: 2 | loss: 0.3919929\n",
      "\tspeed: 0.0564s/iter; left time: 40459.0515s\n",
      "8198it [06:05, 24.05it/s]\titers: 8200, epoch: 2 | loss: 0.6860974\n",
      "\tspeed: 0.0447s/iter; left time: 32118.1468s\n",
      "8299it [06:09, 22.70it/s]\titers: 8300, epoch: 2 | loss: 0.1721449\n",
      "\tspeed: 0.0422s/iter; left time: 30293.2731s\n",
      "8398it [06:13, 23.76it/s]\titers: 8400, epoch: 2 | loss: 0.3088490\n",
      "\tspeed: 0.0424s/iter; left time: 30430.0472s\n",
      "8497it [06:17, 23.11it/s]\titers: 8500, epoch: 2 | loss: 0.3709345\n",
      "\tspeed: 0.0408s/iter; left time: 29278.6801s\n",
      "8599it [06:21, 23.35it/s]\titers: 8600, epoch: 2 | loss: 0.2256505\n",
      "\tspeed: 0.0425s/iter; left time: 30502.8825s\n",
      "8698it [06:26, 22.37it/s]\titers: 8700, epoch: 2 | loss: 0.6709492\n",
      "\tspeed: 0.0433s/iter; left time: 31080.0476s\n",
      "8797it [06:30, 22.16it/s]\titers: 8800, epoch: 2 | loss: 0.4607559\n",
      "\tspeed: 0.0449s/iter; left time: 32173.9831s\n",
      "8899it [06:35, 22.88it/s]\titers: 8900, epoch: 2 | loss: 0.2527392\n",
      "\tspeed: 0.0457s/iter; left time: 32771.8457s\n",
      "8998it [06:39, 24.04it/s]\titers: 9000, epoch: 2 | loss: 0.2914466\n",
      "\tspeed: 0.0415s/iter; left time: 29769.2356s\n",
      "9097it [06:43, 24.51it/s]\titers: 9100, epoch: 2 | loss: 0.3053622\n",
      "\tspeed: 0.0412s/iter; left time: 29533.2410s\n",
      "9199it [06:47, 24.24it/s]\titers: 9200, epoch: 2 | loss: 0.6432325\n",
      "\tspeed: 0.0418s/iter; left time: 29987.6356s\n",
      "9298it [06:52, 23.02it/s]\titers: 9300, epoch: 2 | loss: 0.2271413\n",
      "\tspeed: 0.0436s/iter; left time: 31280.2451s\n",
      "9397it [06:56, 23.16it/s]\titers: 9400, epoch: 2 | loss: 0.3936445\n",
      "\tspeed: 0.0428s/iter; left time: 30686.7824s\n",
      "9498it [07:00, 18.58it/s]\titers: 9500, epoch: 2 | loss: 0.1458180\n",
      "\tspeed: 0.0451s/iter; left time: 32277.7150s\n",
      "9598it [07:06, 17.15it/s]\titers: 9600, epoch: 2 | loss: 0.4312429\n",
      "\tspeed: 0.0560s/iter; left time: 40130.3044s\n",
      "9699it [07:11, 24.27it/s]\titers: 9700, epoch: 2 | loss: 0.1829334\n",
      "\tspeed: 0.0531s/iter; left time: 38011.7381s\n",
      "9798it [07:15, 24.90it/s]\titers: 9800, epoch: 2 | loss: 0.1492081\n",
      "\tspeed: 0.0404s/iter; left time: 28962.8640s\n",
      "9897it [07:19, 25.56it/s]\titers: 9900, epoch: 2 | loss: 0.3498560\n",
      "\tspeed: 0.0414s/iter; left time: 29672.9289s\n",
      "9999it [07:24, 24.01it/s]\titers: 10000, epoch: 2 | loss: 0.6769270\n",
      "\tspeed: 0.0419s/iter; left time: 30003.7186s\n",
      "10098it [07:28, 23.06it/s]\titers: 10100, epoch: 2 | loss: 0.2849993\n",
      "\tspeed: 0.0424s/iter; left time: 30381.8212s\n",
      "10197it [07:32, 23.11it/s]\titers: 10200, epoch: 2 | loss: 0.5098151\n",
      "\tspeed: 0.0427s/iter; left time: 30535.6170s\n",
      "10299it [07:38, 16.84it/s]\titers: 10300, epoch: 2 | loss: 0.3397285\n",
      "\tspeed: 0.0540s/iter; left time: 38653.8689s\n",
      "10399it [07:43, 21.22it/s]\titers: 10400, epoch: 2 | loss: 0.2402358\n",
      "\tspeed: 0.0552s/iter; left time: 39465.0253s\n",
      "10499it [07:47, 22.83it/s]\titers: 10500, epoch: 2 | loss: 0.1471602\n",
      "\tspeed: 0.0429s/iter; left time: 30717.4648s\n",
      "10598it [07:52, 24.11it/s]\titers: 10600, epoch: 2 | loss: 0.2194155\n",
      "\tspeed: 0.0428s/iter; left time: 30651.4012s\n",
      "10697it [07:56, 21.24it/s]\titers: 10700, epoch: 2 | loss: 0.2499068\n",
      "\tspeed: 0.0433s/iter; left time: 30942.5161s\n",
      "10799it [08:00, 23.54it/s]\titers: 10800, epoch: 2 | loss: 0.1901600\n",
      "\tspeed: 0.0430s/iter; left time: 30766.2752s\n",
      "10898it [08:04, 25.06it/s]\titers: 10900, epoch: 2 | loss: 0.4498950\n",
      "\tspeed: 0.0403s/iter; left time: 28826.8948s\n",
      "10997it [08:08, 23.64it/s]\titers: 11000, epoch: 2 | loss: 0.4764846\n",
      "\tspeed: 0.0421s/iter; left time: 30083.1114s\n",
      "11099it [08:13, 22.33it/s]\titers: 11100, epoch: 2 | loss: 0.7763655\n",
      "\tspeed: 0.0438s/iter; left time: 31333.9832s\n",
      "11198it [08:17, 23.28it/s]\titers: 11200, epoch: 2 | loss: 0.3156588\n",
      "\tspeed: 0.0460s/iter; left time: 32867.1388s\n",
      "11298it [08:22, 26.12it/s]\titers: 11300, epoch: 2 | loss: 0.3827136\n",
      "\tspeed: 0.0407s/iter; left time: 29066.3286s\n",
      "11397it [08:26, 25.22it/s]\titers: 11400, epoch: 2 | loss: 0.2400607\n",
      "\tspeed: 0.0410s/iter; left time: 29328.1041s\n",
      "11499it [08:30, 20.00it/s]\titers: 11500, epoch: 2 | loss: 0.1821827\n",
      "\tspeed: 0.0427s/iter; left time: 30539.1053s\n",
      "11598it [08:34, 23.64it/s]\titers: 11600, epoch: 2 | loss: 0.1977159\n",
      "\tspeed: 0.0433s/iter; left time: 30920.9371s\n",
      "11697it [08:39, 25.23it/s]\titers: 11700, epoch: 2 | loss: 0.3947483\n",
      "\tspeed: 0.0429s/iter; left time: 30671.8843s\n",
      "11799it [08:43, 22.00it/s]\titers: 11800, epoch: 2 | loss: 0.3039238\n",
      "\tspeed: 0.0432s/iter; left time: 30874.7212s\n",
      "11897it [08:48, 18.06it/s]\titers: 11900, epoch: 2 | loss: 0.2637303\n",
      "\tspeed: 0.0545s/iter; left time: 38894.4429s\n",
      "11998it [08:54, 20.23it/s]\titers: 12000, epoch: 2 | loss: 0.8668292\n",
      "\tspeed: 0.0553s/iter; left time: 39473.2179s\n",
      "12098it [08:58, 23.36it/s]\titers: 12100, epoch: 2 | loss: 1.1623813\n",
      "\tspeed: 0.0426s/iter; left time: 30442.2550s\n",
      "12197it [09:02, 24.45it/s]\titers: 12200, epoch: 2 | loss: 0.2492280\n",
      "\tspeed: 0.0409s/iter; left time: 29160.7672s\n",
      "12297it [09:06, 25.65it/s]\titers: 12300, epoch: 2 | loss: 0.4222909\n",
      "\tspeed: 0.0404s/iter; left time: 28846.7618s\n",
      "12397it [09:10, 24.92it/s]\titers: 12400, epoch: 2 | loss: 0.3873922\n",
      "\tspeed: 0.0412s/iter; left time: 29397.9777s\n",
      "12499it [09:15, 24.46it/s]\titers: 12500, epoch: 2 | loss: 0.4062331\n",
      "\tspeed: 0.0409s/iter; left time: 29205.3731s\n",
      "12597it [09:20, 17.57it/s]\titers: 12600, epoch: 2 | loss: 0.2179781\n",
      "\tspeed: 0.0519s/iter; left time: 36995.5431s\n",
      "12699it [09:24, 18.07it/s]\titers: 12700, epoch: 2 | loss: 0.2200585\n",
      "\tspeed: 0.0431s/iter; left time: 30757.1556s\n",
      "12798it [09:29, 23.64it/s]\titers: 12800, epoch: 2 | loss: 0.6219527\n",
      "\tspeed: 0.0502s/iter; left time: 35808.3585s\n",
      "12897it [09:33, 23.57it/s]\titers: 12900, epoch: 2 | loss: 0.6864708\n",
      "\tspeed: 0.0421s/iter; left time: 30023.5276s\n",
      "12999it [09:38, 23.07it/s]\titers: 13000, epoch: 2 | loss: 1.4778383\n",
      "\tspeed: 0.0428s/iter; left time: 30541.7525s\n",
      "13098it [09:42, 25.52it/s]\titers: 13100, epoch: 2 | loss: 0.6315655\n",
      "\tspeed: 0.0414s/iter; left time: 29523.0734s\n",
      "13197it [09:46, 24.54it/s]\titers: 13200, epoch: 2 | loss: 0.6674256\n",
      "\tspeed: 0.0407s/iter; left time: 29034.1170s\n",
      "13299it [09:50, 23.39it/s]\titers: 13300, epoch: 2 | loss: 0.5571383\n",
      "\tspeed: 0.0416s/iter; left time: 29613.3087s\n",
      "13398it [09:54, 21.25it/s]\titers: 13400, epoch: 2 | loss: 0.2359023\n",
      "\tspeed: 0.0440s/iter; left time: 31335.3548s\n",
      "13497it [09:59, 22.27it/s]\titers: 13500, epoch: 2 | loss: 0.1902592\n",
      "\tspeed: 0.0453s/iter; left time: 32249.6261s\n",
      "13597it [10:03, 24.25it/s]\titers: 13600, epoch: 2 | loss: 0.1783268\n",
      "\tspeed: 0.0430s/iter; left time: 30626.9277s\n",
      "13699it [10:07, 22.54it/s]\titers: 13700, epoch: 2 | loss: 0.6540186\n",
      "\tspeed: 0.0415s/iter; left time: 29525.1743s\n",
      "13798it [10:11, 22.45it/s]\titers: 13800, epoch: 2 | loss: 0.2894026\n",
      "\tspeed: 0.0421s/iter; left time: 29958.6771s\n",
      "13897it [10:16, 23.61it/s]\titers: 13900, epoch: 2 | loss: 0.2001352\n",
      "\tspeed: 0.0419s/iter; left time: 29867.8567s\n",
      "13999it [10:20, 23.23it/s]\titers: 14000, epoch: 2 | loss: 0.1808207\n",
      "\tspeed: 0.0427s/iter; left time: 30420.1501s\n",
      "14098it [10:24, 24.19it/s]\titers: 14100, epoch: 2 | loss: 0.3034558\n",
      "\tspeed: 0.0416s/iter; left time: 29579.8739s\n",
      "14198it [10:29, 18.06it/s]\titers: 14200, epoch: 2 | loss: 0.2607985\n",
      "\tspeed: 0.0470s/iter; left time: 33453.4287s\n",
      "14298it [10:34, 17.85it/s]\titers: 14300, epoch: 2 | loss: 0.3144494\n",
      "\tspeed: 0.0572s/iter; left time: 40738.2796s\n",
      "14397it [10:39, 24.90it/s]\titers: 14400, epoch: 2 | loss: 0.3484701\n",
      "\tspeed: 0.0428s/iter; left time: 30485.4698s\n",
      "14499it [10:43, 24.84it/s]\titers: 14500, epoch: 2 | loss: 0.6493134\n",
      "\tspeed: 0.0406s/iter; left time: 28883.8004s\n",
      "14598it [10:47, 24.00it/s]\titers: 14600, epoch: 2 | loss: 0.1240453\n",
      "\tspeed: 0.0418s/iter; left time: 29705.9900s\n",
      "14697it [10:51, 23.56it/s]\titers: 14700, epoch: 2 | loss: 0.2639467\n",
      "\tspeed: 0.0424s/iter; left time: 30156.0895s\n",
      "14799it [10:56, 23.82it/s]\titers: 14800, epoch: 2 | loss: 0.2713909\n",
      "\tspeed: 0.0441s/iter; left time: 31386.5702s\n",
      "14816it [10:56, 22.55it/s]\n",
      "Epoch: 2 cost time: 656.9654626846313\n",
      "3204it [01:09, 45.79it/s]\n",
      "3192it [01:08, 46.65it/s]\n",
      "Epoch: 2 | Train Loss: 0.3856661 Vali Loss: 0.4719015 Test Loss: 0.5948117 MAE Loss: 0.4796047\n",
      "Validation loss decreased (0.480441 --> 0.471902).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "98it [00:04, 24.34it/s]\titers: 100, epoch: 3 | loss: 0.5278946\n",
      "\tspeed: 1.4544s/iter; left time: 1034150.4337s\n",
      "197it [00:08, 21.23it/s]\titers: 200, epoch: 3 | loss: 0.8207273\n",
      "\tspeed: 0.0430s/iter; left time: 30546.8744s\n",
      "299it [00:13, 24.33it/s]\titers: 300, epoch: 3 | loss: 0.3020312\n",
      "\tspeed: 0.0412s/iter; left time: 29305.7453s\n",
      "398it [00:17, 24.20it/s]\titers: 400, epoch: 3 | loss: 0.1920633\n",
      "\tspeed: 0.0414s/iter; left time: 29424.6681s\n",
      "497it [00:21, 23.60it/s]\titers: 500, epoch: 3 | loss: 0.9825035\n",
      "\tspeed: 0.0412s/iter; left time: 29299.1540s\n",
      "599it [00:25, 23.85it/s]\titers: 600, epoch: 3 | loss: 0.1032447\n",
      "\tspeed: 0.0428s/iter; left time: 30377.4489s\n",
      "698it [00:29, 22.31it/s]\titers: 700, epoch: 3 | loss: 0.3477395\n",
      "\tspeed: 0.0439s/iter; left time: 31206.2950s\n",
      "797it [00:34, 23.39it/s]\titers: 800, epoch: 3 | loss: 0.2135506\n",
      "\tspeed: 0.0450s/iter; left time: 31944.3894s\n",
      "899it [00:38, 25.19it/s]\titers: 900, epoch: 3 | loss: 0.3669769\n",
      "\tspeed: 0.0435s/iter; left time: 30897.5949s\n",
      "998it [00:43, 23.82it/s]\titers: 1000, epoch: 3 | loss: 0.3838996\n",
      "\tspeed: 0.0433s/iter; left time: 30774.9071s\n",
      "1097it [00:47, 25.77it/s]\titers: 1100, epoch: 3 | loss: 0.5435354\n",
      "\tspeed: 0.0399s/iter; left time: 28314.2668s\n",
      "1199it [00:51, 25.27it/s]\titers: 1200, epoch: 3 | loss: 0.7445388\n",
      "\tspeed: 0.0396s/iter; left time: 28110.7237s\n",
      "1298it [00:55, 24.26it/s]\titers: 1300, epoch: 3 | loss: 0.1728254\n",
      "\tspeed: 0.0411s/iter; left time: 29148.0467s\n",
      "1397it [00:59, 24.85it/s]\titers: 1400, epoch: 3 | loss: 0.3940254\n",
      "\tspeed: 0.0411s/iter; left time: 29191.7509s\n",
      "1499it [01:04, 22.68it/s]\titers: 1500, epoch: 3 | loss: 0.2250404\n",
      "\tspeed: 0.0469s/iter; left time: 33257.9800s\n",
      "1598it [01:09, 19.29it/s]\titers: 1600, epoch: 3 | loss: 0.2748400\n",
      "\tspeed: 0.0509s/iter; left time: 36119.9290s\n",
      "1698it [01:13, 23.74it/s]\titers: 1700, epoch: 3 | loss: 0.2805447\n",
      "\tspeed: 0.0467s/iter; left time: 33143.1334s\n",
      "1797it [01:17, 24.05it/s]\titers: 1800, epoch: 3 | loss: 0.4070167\n",
      "\tspeed: 0.0420s/iter; left time: 29809.3607s\n",
      "1899it [01:22, 24.99it/s]\titers: 1900, epoch: 3 | loss: 1.0162226\n",
      "\tspeed: 0.0405s/iter; left time: 28706.7049s\n",
      "1998it [01:26, 23.62it/s]\titers: 2000, epoch: 3 | loss: 0.2068892\n",
      "\tspeed: 0.0413s/iter; left time: 29295.9441s\n",
      "2097it [01:30, 24.77it/s]\titers: 2100, epoch: 3 | loss: 0.7390379\n",
      "\tspeed: 0.0412s/iter; left time: 29221.4354s\n",
      "2199it [01:34, 23.96it/s]\titers: 2200, epoch: 3 | loss: 0.2942721\n",
      "\tspeed: 0.0405s/iter; left time: 28705.8152s\n",
      "2298it [01:38, 19.97it/s]\titers: 2300, epoch: 3 | loss: 0.6117713\n",
      "\tspeed: 0.0454s/iter; left time: 32186.8319s\n",
      "2399it [01:44, 19.77it/s]\titers: 2400, epoch: 3 | loss: 0.4906154\n",
      "\tspeed: 0.0534s/iter; left time: 37840.9909s\n",
      "2499it [01:48, 26.16it/s]\titers: 2500, epoch: 3 | loss: 0.2343832\n",
      "\tspeed: 0.0434s/iter; left time: 30756.6463s\n",
      "2598it [01:52, 26.01it/s]\titers: 2600, epoch: 3 | loss: 0.2465896\n",
      "\tspeed: 0.0392s/iter; left time: 27787.4133s\n",
      "2697it [01:56, 24.79it/s]\titers: 2700, epoch: 3 | loss: 0.2719182\n",
      "\tspeed: 0.0397s/iter; left time: 28156.6220s\n",
      "2799it [02:00, 24.48it/s]\titers: 2800, epoch: 3 | loss: 0.2718423\n",
      "\tspeed: 0.0395s/iter; left time: 27976.2911s\n",
      "2898it [02:04, 25.13it/s]\titers: 2900, epoch: 3 | loss: 0.2264480\n",
      "\tspeed: 0.0393s/iter; left time: 27817.4457s\n",
      "2997it [02:08, 24.43it/s]\titers: 3000, epoch: 3 | loss: 0.6651196\n",
      "\tspeed: 0.0399s/iter; left time: 28255.6865s\n",
      "3099it [02:12, 21.03it/s]\titers: 3100, epoch: 3 | loss: 0.4750513\n",
      "\tspeed: 0.0444s/iter; left time: 31428.4676s\n",
      "3199it [02:17, 18.03it/s]\titers: 3200, epoch: 3 | loss: 0.2118996\n",
      "\tspeed: 0.0519s/iter; left time: 36739.9506s\n",
      "3298it [02:23, 24.65it/s]\titers: 3300, epoch: 3 | loss: 0.2685755\n",
      "\tspeed: 0.0508s/iter; left time: 35969.4978s\n",
      "3398it [02:26, 26.12it/s]\titers: 3400, epoch: 3 | loss: 0.1952534\n",
      "\tspeed: 0.0391s/iter; left time: 27671.7858s\n",
      "3498it [02:30, 25.56it/s]\titers: 3500, epoch: 3 | loss: 0.1592045\n",
      "\tspeed: 0.0394s/iter; left time: 27849.4169s\n",
      "3597it [02:34, 26.05it/s]\titers: 3600, epoch: 3 | loss: 0.1376058\n",
      "\tspeed: 0.0402s/iter; left time: 28446.2710s\n",
      "3697it [02:38, 24.12it/s]\titers: 3700, epoch: 3 | loss: 0.3417158\n",
      "\tspeed: 0.0408s/iter; left time: 28858.0113s\n",
      "3799it [02:43, 24.06it/s]\titers: 3800, epoch: 3 | loss: 0.2010016\n",
      "\tspeed: 0.0420s/iter; left time: 29738.2734s\n",
      "3898it [02:47, 19.25it/s]\titers: 3900, epoch: 3 | loss: 0.2762576\n",
      "\tspeed: 0.0461s/iter; left time: 32592.9945s\n",
      "3999it [02:53, 17.23it/s]\titers: 4000, epoch: 3 | loss: 0.2668163\n",
      "\tspeed: 0.0533s/iter; left time: 37703.2956s\n",
      "4098it [02:57, 23.16it/s]\titers: 4100, epoch: 3 | loss: 0.4664470\n",
      "\tspeed: 0.0475s/iter; left time: 33612.9743s\n",
      "4197it [03:02, 24.52it/s]\titers: 4200, epoch: 3 | loss: 0.2821302\n",
      "\tspeed: 0.0425s/iter; left time: 30081.0547s\n",
      "4299it [03:06, 23.93it/s]\titers: 4300, epoch: 3 | loss: 0.2216893\n",
      "\tspeed: 0.0420s/iter; left time: 29655.3130s\n",
      "4398it [03:10, 23.78it/s]\titers: 4400, epoch: 3 | loss: 0.6813632\n",
      "\tspeed: 0.0435s/iter; left time: 30774.7315s\n",
      "4497it [03:14, 23.66it/s]\titers: 4500, epoch: 3 | loss: 0.4053993\n",
      "\tspeed: 0.0412s/iter; left time: 29080.2668s\n",
      "4599it [03:19, 22.58it/s]\titers: 4600, epoch: 3 | loss: 0.5449346\n",
      "\tspeed: 0.0435s/iter; left time: 30732.5804s\n",
      "4699it [03:24, 17.84it/s]\titers: 4700, epoch: 3 | loss: 0.1417733\n",
      "\tspeed: 0.0530s/iter; left time: 37417.9468s\n",
      "4798it [03:30, 17.61it/s]\titers: 4800, epoch: 3 | loss: 0.4134873\n",
      "\tspeed: 0.0568s/iter; left time: 40141.8983s\n",
      "4897it [03:34, 24.64it/s]\titers: 4900, epoch: 3 | loss: 0.1342873\n",
      "\tspeed: 0.0423s/iter; left time: 29902.5115s\n",
      "4999it [03:38, 24.99it/s]\titers: 5000, epoch: 3 | loss: 0.2668993\n",
      "\tspeed: 0.0428s/iter; left time: 30196.1418s\n",
      "5098it [03:42, 23.79it/s]\titers: 5100, epoch: 3 | loss: 0.2242403\n",
      "\tspeed: 0.0416s/iter; left time: 29389.2528s\n",
      "5197it [03:46, 22.25it/s]\titers: 5200, epoch: 3 | loss: 0.2863150\n",
      "\tspeed: 0.0424s/iter; left time: 29918.9942s\n",
      "5299it [03:51, 23.19it/s]\titers: 5300, epoch: 3 | loss: 0.3189879\n",
      "\tspeed: 0.0440s/iter; left time: 31074.4685s\n",
      "5399it [03:56, 26.50it/s]\titers: 5400, epoch: 3 | loss: 0.1649878\n",
      "\tspeed: 0.0453s/iter; left time: 31946.6118s\n",
      "5498it [03:59, 20.93it/s]\titers: 5500, epoch: 3 | loss: 0.1443393\n",
      "\tspeed: 0.0387s/iter; left time: 27288.4918s\n",
      "5597it [04:04, 22.79it/s]\titers: 5600, epoch: 3 | loss: 0.5971522\n",
      "\tspeed: 0.0458s/iter; left time: 32318.7757s\n",
      "5698it [04:08, 25.29it/s]\titers: 5700, epoch: 3 | loss: 0.1794433\n",
      "\tspeed: 0.0407s/iter; left time: 28728.1460s\n",
      "5797it [04:12, 22.71it/s]\titers: 5800, epoch: 3 | loss: 0.2927238\n",
      "\tspeed: 0.0414s/iter; left time: 29218.4707s\n",
      "5899it [04:16, 24.72it/s]\titers: 5900, epoch: 3 | loss: 0.2892492\n",
      "\tspeed: 0.0403s/iter; left time: 28436.5542s\n",
      "5998it [04:20, 23.36it/s]\titers: 6000, epoch: 3 | loss: 0.6258401\n",
      "\tspeed: 0.0415s/iter; left time: 29290.0760s\n",
      "6097it [04:24, 24.40it/s]\titers: 6100, epoch: 3 | loss: 0.1255925\n",
      "\tspeed: 0.0406s/iter; left time: 28645.0839s\n",
      "6199it [04:29, 22.59it/s]\titers: 6200, epoch: 3 | loss: 0.2011451\n",
      "\tspeed: 0.0428s/iter; left time: 30204.4515s\n",
      "6298it [04:34, 17.55it/s]\titers: 6300, epoch: 3 | loss: 0.1631622\n",
      "\tspeed: 0.0544s/iter; left time: 38342.3868s\n",
      "6397it [04:39, 25.00it/s]\titers: 6400, epoch: 3 | loss: 1.0322512\n",
      "\tspeed: 0.0523s/iter; left time: 36891.3328s\n",
      "6499it [04:44, 22.66it/s]\titers: 6500, epoch: 3 | loss: 0.1643804\n",
      "\tspeed: 0.0431s/iter; left time: 30347.6471s\n",
      "6598it [04:48, 24.14it/s]\titers: 6600, epoch: 3 | loss: 0.4169674\n",
      "\tspeed: 0.0412s/iter; left time: 29059.7992s\n",
      "6697it [04:52, 21.56it/s]\titers: 6700, epoch: 3 | loss: 0.7656648\n",
      "\tspeed: 0.0447s/iter; left time: 31487.0553s\n",
      "6799it [04:57, 21.82it/s]\titers: 6800, epoch: 3 | loss: 0.1958673\n",
      "\tspeed: 0.0437s/iter; left time: 30801.5586s\n",
      "6898it [05:01, 20.86it/s]\titers: 6900, epoch: 3 | loss: 0.2114542\n",
      "\tspeed: 0.0442s/iter; left time: 31136.4562s\n",
      "6999it [05:07, 16.51it/s]\titers: 7000, epoch: 3 | loss: 0.2414893\n",
      "\tspeed: 0.0571s/iter; left time: 40231.1850s\n",
      "7099it [05:12, 23.83it/s]\titers: 7100, epoch: 3 | loss: 0.3681656\n",
      "\tspeed: 0.0535s/iter; left time: 37700.2126s\n",
      "7197it [05:16, 23.72it/s]\titers: 7200, epoch: 3 | loss: 0.1848322\n",
      "\tspeed: 0.0413s/iter; left time: 29082.1748s\n",
      "7299it [05:20, 23.71it/s]\titers: 7300, epoch: 3 | loss: 0.1709398\n",
      "\tspeed: 0.0417s/iter; left time: 29367.0420s\n",
      "7398it [05:25, 23.35it/s]\titers: 7400, epoch: 3 | loss: 0.1456491\n",
      "\tspeed: 0.0424s/iter; left time: 29853.8481s\n",
      "7497it [05:29, 22.70it/s]\titers: 7500, epoch: 3 | loss: 0.5621200\n",
      "\tspeed: 0.0430s/iter; left time: 30256.2148s\n",
      "7599it [05:33, 19.84it/s]\titers: 7600, epoch: 3 | loss: 0.3474715\n",
      "\tspeed: 0.0434s/iter; left time: 30507.0116s\n",
      "7699it [05:38, 22.94it/s]\titers: 7700, epoch: 3 | loss: 0.1956635\n",
      "\tspeed: 0.0514s/iter; left time: 36169.9001s\n",
      "7799it [05:43, 24.23it/s]\titers: 7800, epoch: 3 | loss: 0.4275600\n",
      "\tspeed: 0.0459s/iter; left time: 32255.8045s\n",
      "7897it [05:47, 23.41it/s]\titers: 7900, epoch: 3 | loss: 0.2851394\n",
      "\tspeed: 0.0434s/iter; left time: 30523.5138s\n",
      "7999it [05:51, 25.14it/s]\titers: 8000, epoch: 3 | loss: 0.2245116\n",
      "\tspeed: 0.0403s/iter; left time: 28369.1966s\n",
      "8098it [05:55, 23.09it/s]\titers: 8100, epoch: 3 | loss: 0.1938531\n",
      "\tspeed: 0.0400s/iter; left time: 28118.6465s\n",
      "8197it [05:59, 24.33it/s]\titers: 8200, epoch: 3 | loss: 0.1447303\n",
      "\tspeed: 0.0406s/iter; left time: 28532.7375s\n",
      "8299it [06:04, 23.70it/s]\titers: 8300, epoch: 3 | loss: 0.1698615\n",
      "\tspeed: 0.0423s/iter; left time: 29761.7556s\n",
      "8398it [06:08, 22.89it/s]\titers: 8400, epoch: 3 | loss: 0.7653539\n",
      "\tspeed: 0.0442s/iter; left time: 31038.4771s\n",
      "8498it [06:13, 16.59it/s]\titers: 8500, epoch: 3 | loss: 0.2308053\n",
      "\tspeed: 0.0523s/iter; left time: 36748.5217s\n",
      "8599it [06:19, 16.40it/s]\titers: 8600, epoch: 3 | loss: 0.1168003\n",
      "\tspeed: 0.0599s/iter; left time: 42109.5986s\n",
      "8697it [06:24, 23.55it/s]\titers: 8700, epoch: 3 | loss: 0.3043092\n",
      "\tspeed: 0.0436s/iter; left time: 30624.2076s\n",
      "8799it [06:28, 22.71it/s]\titers: 8800, epoch: 3 | loss: 0.2185405\n",
      "\tspeed: 0.0435s/iter; left time: 30523.6084s\n",
      "8898it [06:32, 22.90it/s]\titers: 8900, epoch: 3 | loss: 0.3558585\n",
      "\tspeed: 0.0420s/iter; left time: 29495.8509s\n",
      "8998it [06:37, 19.38it/s]\titers: 9000, epoch: 3 | loss: 0.5111861\n",
      "\tspeed: 0.0484s/iter; left time: 33971.1760s\n",
      "9097it [06:42, 19.09it/s]\titers: 9100, epoch: 3 | loss: 0.2670048\n",
      "\tspeed: 0.0497s/iter; left time: 34921.7706s\n",
      "9199it [06:46, 20.21it/s]\titers: 9200, epoch: 3 | loss: 0.2093480\n",
      "\tspeed: 0.0414s/iter; left time: 29067.9206s\n",
      "9298it [06:52, 24.64it/s]\titers: 9300, epoch: 3 | loss: 0.1875816\n",
      "\tspeed: 0.0550s/iter; left time: 38597.7497s\n",
      "9398it [06:56, 24.21it/s]\titers: 9400, epoch: 3 | loss: 0.2303696\n",
      "\tspeed: 0.0401s/iter; left time: 28145.4008s\n",
      "9497it [07:00, 24.20it/s]\titers: 9500, epoch: 3 | loss: 0.3136583\n",
      "\tspeed: 0.0429s/iter; left time: 30133.7682s\n",
      "9599it [07:04, 24.48it/s]\titers: 9600, epoch: 3 | loss: 0.5310749\n",
      "\tspeed: 0.0412s/iter; left time: 28890.0379s\n",
      "9698it [07:08, 24.74it/s]\titers: 9700, epoch: 3 | loss: 0.3456270\n",
      "\tspeed: 0.0428s/iter; left time: 30033.6752s\n",
      "9797it [07:12, 24.48it/s]\titers: 9800, epoch: 3 | loss: 0.7199041\n",
      "\tspeed: 0.0417s/iter; left time: 29251.9405s\n",
      "9898it [07:17, 19.15it/s]\titers: 9900, epoch: 3 | loss: 0.2460739\n",
      "\tspeed: 0.0449s/iter; left time: 31498.8139s\n",
      "9997it [07:21, 20.50it/s]\titers: 10000, epoch: 3 | loss: 0.2356671\n",
      "\tspeed: 0.0452s/iter; left time: 31671.6329s\n",
      "10099it [07:26, 22.98it/s]\titers: 10100, epoch: 3 | loss: 0.7194166\n",
      "\tspeed: 0.0451s/iter; left time: 31642.1959s\n",
      "10198it [07:30, 24.28it/s]\titers: 10200, epoch: 3 | loss: 0.3378266\n",
      "\tspeed: 0.0414s/iter; left time: 29033.7162s\n",
      "10298it [07:34, 24.36it/s]\titers: 10300, epoch: 3 | loss: 0.2597840\n",
      "\tspeed: 0.0403s/iter; left time: 28256.5454s\n",
      "10397it [07:38, 25.74it/s]\titers: 10400, epoch: 3 | loss: 0.6424517\n",
      "\tspeed: 0.0405s/iter; left time: 28380.6814s\n",
      "10499it [07:42, 24.40it/s]\titers: 10500, epoch: 3 | loss: 0.4517760\n",
      "\tspeed: 0.0411s/iter; left time: 28826.0444s\n",
      "10598it [07:47, 21.89it/s]\titers: 10600, epoch: 3 | loss: 0.4337007\n",
      "\tspeed: 0.0430s/iter; left time: 30111.9829s\n",
      "10697it [07:51, 25.34it/s]\titers: 10700, epoch: 3 | loss: 0.5268267\n",
      "\tspeed: 0.0440s/iter; left time: 30794.5772s\n",
      "10798it [07:56, 17.73it/s]\titers: 10800, epoch: 3 | loss: 0.3841441\n",
      "\tspeed: 0.0510s/iter; left time: 35752.7055s\n",
      "10898it [08:02, 17.67it/s]\titers: 10900, epoch: 3 | loss: 0.6265694\n",
      "\tspeed: 0.0541s/iter; left time: 37884.8974s\n",
      "10998it [08:06, 23.98it/s]\titers: 11000, epoch: 3 | loss: 0.3437184\n",
      "\tspeed: 0.0443s/iter; left time: 31028.2861s\n",
      "11097it [08:10, 23.40it/s]\titers: 11100, epoch: 3 | loss: 0.2992541\n",
      "\tspeed: 0.0418s/iter; left time: 29295.5355s\n",
      "11199it [08:14, 23.53it/s]\titers: 11200, epoch: 3 | loss: 0.1864961\n",
      "\tspeed: 0.0412s/iter; left time: 28828.5487s\n",
      "11298it [08:19, 20.26it/s]\titers: 11300, epoch: 3 | loss: 0.1861633\n",
      "\tspeed: 0.0448s/iter; left time: 31378.7685s\n",
      "11397it [08:24, 22.54it/s]\titers: 11400, epoch: 3 | loss: 0.2976792\n",
      "\tspeed: 0.0496s/iter; left time: 34681.0945s\n",
      "11499it [08:28, 28.78it/s]\titers: 11500, epoch: 3 | loss: 0.8139990\n",
      "\tspeed: 0.0423s/iter; left time: 29591.5466s\n",
      "11599it [08:32, 27.60it/s]\titers: 11600, epoch: 3 | loss: 0.5404238\n",
      "\tspeed: 0.0362s/iter; left time: 25302.0254s\n",
      "11699it [08:36, 18.63it/s]\titers: 11700, epoch: 3 | loss: 0.2384695\n",
      "\tspeed: 0.0451s/iter; left time: 31554.5636s\n",
      "11798it [08:40, 25.76it/s]\titers: 11800, epoch: 3 | loss: 0.3080744\n",
      "\tspeed: 0.0412s/iter; left time: 28801.7864s\n",
      "11897it [08:45, 22.48it/s]\titers: 11900, epoch: 3 | loss: 0.0802430\n",
      "\tspeed: 0.0431s/iter; left time: 30113.9842s\n",
      "11997it [08:49, 23.49it/s]\titers: 12000, epoch: 3 | loss: 0.5011000\n",
      "\tspeed: 0.0423s/iter; left time: 29609.7014s\n",
      "12099it [08:53, 21.37it/s]\titers: 12100, epoch: 3 | loss: 0.1537029\n",
      "\tspeed: 0.0425s/iter; left time: 29744.2101s\n",
      "12198it [08:58, 23.49it/s]\titers: 12200, epoch: 3 | loss: 0.4255113\n",
      "\tspeed: 0.0448s/iter; left time: 31289.8758s\n",
      "12297it [09:02, 20.28it/s]\titers: 12300, epoch: 3 | loss: 0.9904142\n",
      "\tspeed: 0.0450s/iter; left time: 31462.3282s\n",
      "12398it [09:07, 21.25it/s]\titers: 12400, epoch: 3 | loss: 1.0774645\n",
      "\tspeed: 0.0456s/iter; left time: 31870.5650s\n",
      "12497it [09:11, 23.89it/s]\titers: 12500, epoch: 3 | loss: 0.5872955\n",
      "\tspeed: 0.0464s/iter; left time: 32437.1237s\n",
      "12597it [09:15, 24.21it/s]\titers: 12600, epoch: 3 | loss: 0.3935277\n",
      "\tspeed: 0.0411s/iter; left time: 28742.4969s\n",
      "12699it [09:19, 24.78it/s]\titers: 12700, epoch: 3 | loss: 0.0795868\n",
      "\tspeed: 0.0406s/iter; left time: 28387.4513s\n",
      "12798it [09:24, 23.99it/s]\titers: 12800, epoch: 3 | loss: 0.2197041\n",
      "\tspeed: 0.0409s/iter; left time: 28578.8596s\n",
      "12897it [09:28, 23.01it/s]\titers: 12900, epoch: 3 | loss: 0.1848470\n",
      "\tspeed: 0.0427s/iter; left time: 29846.2973s\n",
      "12999it [09:32, 25.25it/s]\titers: 13000, epoch: 3 | loss: 0.2561437\n",
      "\tspeed: 0.0417s/iter; left time: 29121.1467s\n",
      "13098it [09:37, 18.33it/s]\titers: 13100, epoch: 3 | loss: 0.1731838\n",
      "\tspeed: 0.0472s/iter; left time: 32956.5678s\n",
      "13199it [09:42, 26.51it/s]\titers: 13200, epoch: 3 | loss: 0.4000860\n",
      "\tspeed: 0.0528s/iter; left time: 36826.1992s\n",
      "13298it [09:46, 24.28it/s]\titers: 13300, epoch: 3 | loss: 0.3544185\n",
      "\tspeed: 0.0376s/iter; left time: 26273.5573s\n",
      "13398it [09:50, 22.97it/s]\titers: 13400, epoch: 3 | loss: 0.5769793\n",
      "\tspeed: 0.0429s/iter; left time: 29945.7937s\n",
      "13498it [09:54, 22.88it/s]\titers: 13500, epoch: 3 | loss: 0.7402129\n",
      "\tspeed: 0.0423s/iter; left time: 29492.2584s\n",
      "13597it [09:59, 23.13it/s]\titers: 13600, epoch: 3 | loss: 0.1976167\n",
      "\tspeed: 0.0448s/iter; left time: 31218.4806s\n",
      "13699it [10:03, 22.11it/s]\titers: 13700, epoch: 3 | loss: 0.1592570\n",
      "\tspeed: 0.0436s/iter; left time: 30401.3099s\n",
      "13798it [10:07, 23.31it/s]\titers: 13800, epoch: 3 | loss: 0.1752078\n",
      "\tspeed: 0.0425s/iter; left time: 29641.8620s\n",
      "13899it [10:13, 17.32it/s]\titers: 13900, epoch: 3 | loss: 0.3869770\n",
      "\tspeed: 0.0520s/iter; left time: 36243.0831s\n",
      "13999it [10:18, 22.99it/s]\titers: 14000, epoch: 3 | loss: 0.1496625\n",
      "\tspeed: 0.0556s/iter; left time: 38773.5548s\n",
      "14098it [10:22, 22.08it/s]\titers: 14100, epoch: 3 | loss: 0.1255860\n",
      "\tspeed: 0.0404s/iter; left time: 28168.6606s\n",
      "14197it [10:26, 24.89it/s]\titers: 14200, epoch: 3 | loss: 0.1351347\n",
      "\tspeed: 0.0414s/iter; left time: 28875.5827s\n",
      "14299it [10:31, 23.81it/s]\titers: 14300, epoch: 3 | loss: 0.2117765\n",
      "\tspeed: 0.0427s/iter; left time: 29760.1658s\n",
      "14398it [10:35, 25.55it/s]\titers: 14400, epoch: 3 | loss: 0.2427612\n",
      "\tspeed: 0.0439s/iter; left time: 30613.1663s\n",
      "14497it [10:39, 25.17it/s]\titers: 14500, epoch: 3 | loss: 0.8061271\n",
      "\tspeed: 0.0404s/iter; left time: 28117.5011s\n",
      "14599it [10:43, 24.84it/s]\titers: 14600, epoch: 3 | loss: 0.2729841\n",
      "\tspeed: 0.0397s/iter; left time: 27658.8897s\n",
      "14698it [10:47, 24.87it/s]\titers: 14700, epoch: 3 | loss: 0.2496898\n",
      "\tspeed: 0.0456s/iter; left time: 31730.1479s\n",
      "14797it [10:52, 19.25it/s]\titers: 14800, epoch: 3 | loss: 0.3250307\n",
      "\tspeed: 0.0479s/iter; left time: 33390.7911s\n",
      "14816it [10:53, 22.66it/s]\n",
      "Epoch: 3 cost time: 653.700320482254\n",
      "3204it [01:09, 46.08it/s]\n",
      "3192it [01:09, 45.60it/s]\n",
      "Epoch: 3 | Train Loss: 0.3709007 Vali Loss: 0.4646254 Test Loss: 0.5988673 MAE Loss: 0.4916651\n",
      "Validation loss decreased (0.471902 --> 0.464625).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "97it [00:05, 22.88it/s]\titers: 100, epoch: 4 | loss: 0.1626250\n",
      "\tspeed: 1.4723s/iter; left time: 1025070.9900s\n",
      "199it [00:09, 22.41it/s]\titers: 200, epoch: 4 | loss: 0.2022431\n",
      "\tspeed: 0.0444s/iter; left time: 30940.0302s\n",
      "298it [00:14, 20.20it/s]\titers: 300, epoch: 4 | loss: 0.4598480\n",
      "\tspeed: 0.0461s/iter; left time: 32057.5638s\n",
      "397it [00:19, 16.64it/s]\titers: 400, epoch: 4 | loss: 0.5798229\n",
      "\tspeed: 0.0547s/iter; left time: 38052.4364s\n",
      "499it [00:24, 22.22it/s]\titers: 500, epoch: 4 | loss: 0.1326764\n",
      "\tspeed: 0.0497s/iter; left time: 34557.6947s\n",
      "598it [00:28, 24.88it/s]\titers: 600, epoch: 4 | loss: 0.1967918\n",
      "\tspeed: 0.0414s/iter; left time: 28792.5102s\n",
      "697it [00:32, 22.83it/s]\titers: 700, epoch: 4 | loss: 0.3609470\n",
      "\tspeed: 0.0426s/iter; left time: 29636.8412s\n",
      "799it [00:37, 24.30it/s]\titers: 800, epoch: 4 | loss: 0.3166209\n",
      "\tspeed: 0.0423s/iter; left time: 29444.5216s\n",
      "898it [00:41, 22.73it/s]\titers: 900, epoch: 4 | loss: 0.5740969\n",
      "\tspeed: 0.0418s/iter; left time: 29056.6844s\n",
      "997it [00:45, 25.92it/s]\titers: 1000, epoch: 4 | loss: 0.1984566\n",
      "\tspeed: 0.0403s/iter; left time: 28004.5407s\n",
      "1099it [00:50, 20.74it/s]\titers: 1100, epoch: 4 | loss: 0.3934523\n",
      "\tspeed: 0.0453s/iter; left time: 31488.1114s\n",
      "1198it [00:54, 21.32it/s]\titers: 1200, epoch: 4 | loss: 0.4173949\n",
      "\tspeed: 0.0476s/iter; left time: 33081.1732s\n",
      "1299it [00:59, 24.62it/s]\titers: 1300, epoch: 4 | loss: 0.5176777\n",
      "\tspeed: 0.0438s/iter; left time: 30418.6922s\n",
      "1398it [01:03, 24.45it/s]\titers: 1400, epoch: 4 | loss: 0.2067561\n",
      "\tspeed: 0.0412s/iter; left time: 28652.5851s\n",
      "1497it [01:07, 24.19it/s]\titers: 1500, epoch: 4 | loss: 0.3225462\n",
      "\tspeed: 0.0421s/iter; left time: 29280.2240s\n",
      "1599it [01:11, 22.93it/s]\titers: 1600, epoch: 4 | loss: 0.3932137\n",
      "\tspeed: 0.0431s/iter; left time: 29975.7151s\n",
      "1698it [01:16, 23.58it/s]\titers: 1700, epoch: 4 | loss: 0.1678384\n",
      "\tspeed: 0.0442s/iter; left time: 30709.7513s\n",
      "1797it [01:20, 21.57it/s]\titers: 1800, epoch: 4 | loss: 0.2228955\n",
      "\tspeed: 0.0437s/iter; left time: 30353.8647s\n",
      "1898it [01:25, 17.18it/s]\titers: 1900, epoch: 4 | loss: 0.2714488\n",
      "\tspeed: 0.0533s/iter; left time: 37035.8007s\n",
      "1998it [01:30, 18.38it/s]\titers: 2000, epoch: 4 | loss: 0.3282716\n",
      "\tspeed: 0.0461s/iter; left time: 32029.5878s\n",
      "2097it [01:35, 23.93it/s]\titers: 2100, epoch: 4 | loss: 0.5041998\n",
      "\tspeed: 0.0456s/iter; left time: 31666.6462s\n",
      "2199it [01:39, 23.72it/s]\titers: 2200, epoch: 4 | loss: 0.2559320\n",
      "\tspeed: 0.0419s/iter; left time: 29097.0081s\n",
      "2298it [01:43, 24.08it/s]\titers: 2300, epoch: 4 | loss: 0.2062184\n",
      "\tspeed: 0.0435s/iter; left time: 30220.1951s\n",
      "2397it [01:47, 22.98it/s]\titers: 2400, epoch: 4 | loss: 0.5267666\n",
      "\tspeed: 0.0432s/iter; left time: 30004.3992s\n",
      "2499it [01:52, 22.95it/s]\titers: 2500, epoch: 4 | loss: 0.4842477\n",
      "\tspeed: 0.0427s/iter; left time: 29650.1915s\n",
      "2597it [01:56, 27.80it/s]\titers: 2600, epoch: 4 | loss: 0.7529700\n",
      "\tspeed: 0.0464s/iter; left time: 32168.4820s\n",
      "2698it [02:01, 20.26it/s]\titers: 2700, epoch: 4 | loss: 0.1168044\n",
      "\tspeed: 0.0488s/iter; left time: 33850.6294s\n",
      "2797it [02:06, 23.28it/s]\titers: 2800, epoch: 4 | loss: 0.1384799\n",
      "\tspeed: 0.0437s/iter; left time: 30314.8779s\n",
      "2899it [02:10, 23.65it/s]\titers: 2900, epoch: 4 | loss: 0.2483453\n",
      "\tspeed: 0.0428s/iter; left time: 29655.0562s\n",
      "2998it [02:14, 21.90it/s]\titers: 3000, epoch: 4 | loss: 0.3224004\n",
      "\tspeed: 0.0451s/iter; left time: 31284.3243s\n",
      "3097it [02:19, 23.89it/s]\titers: 3100, epoch: 4 | loss: 0.2620616\n",
      "\tspeed: 0.0432s/iter; left time: 29936.2270s\n",
      "3199it [02:23, 24.14it/s]\titers: 3200, epoch: 4 | loss: 0.4142838\n",
      "\tspeed: 0.0406s/iter; left time: 28140.4266s\n",
      "3298it [02:27, 22.78it/s]\titers: 3300, epoch: 4 | loss: 0.2170057\n",
      "\tspeed: 0.0415s/iter; left time: 28743.9521s\n",
      "3397it [02:32, 21.91it/s]\titers: 3400, epoch: 4 | loss: 0.1696144\n",
      "\tspeed: 0.0464s/iter; left time: 32130.1859s\n",
      "3499it [02:36, 19.21it/s]\titers: 3500, epoch: 4 | loss: 0.7560053\n",
      "\tspeed: 0.0469s/iter; left time: 32496.2994s\n",
      "3599it [02:41, 25.08it/s]\titers: 3600, epoch: 4 | loss: 0.4330556\n",
      "\tspeed: 0.0440s/iter; left time: 30498.9474s\n",
      "3698it [02:45, 21.60it/s]\titers: 3700, epoch: 4 | loss: 0.2990661\n",
      "\tspeed: 0.0428s/iter; left time: 29648.3275s\n",
      "3797it [02:49, 22.00it/s]\titers: 3800, epoch: 4 | loss: 0.4807670\n",
      "\tspeed: 0.0432s/iter; left time: 29919.2584s\n",
      "3899it [02:54, 23.21it/s]\titers: 3900, epoch: 4 | loss: 0.3955661\n",
      "\tspeed: 0.0436s/iter; left time: 30178.9478s\n",
      "3998it [02:58, 23.34it/s]\titers: 4000, epoch: 4 | loss: 0.2707709\n",
      "\tspeed: 0.0423s/iter; left time: 29255.2414s\n",
      "4098it [03:02, 22.55it/s]\titers: 4100, epoch: 4 | loss: 0.2177304\n",
      "\tspeed: 0.0462s/iter; left time: 32007.7937s\n",
      "4199it [03:08, 17.41it/s]\titers: 4200, epoch: 4 | loss: 0.4702105\n",
      "\tspeed: 0.0516s/iter; left time: 35683.0811s\n",
      "4298it [03:13, 17.67it/s]\titers: 4300, epoch: 4 | loss: 0.4923164\n",
      "\tspeed: 0.0532s/iter; left time: 36790.6379s\n",
      "4399it [03:17, 24.37it/s]\titers: 4400, epoch: 4 | loss: 0.2345471\n",
      "\tspeed: 0.0439s/iter; left time: 30345.7651s\n",
      "4499it [03:22, 24.68it/s]\titers: 4500, epoch: 4 | loss: 0.3321971\n",
      "\tspeed: 0.0429s/iter; left time: 29662.0816s\n",
      "4598it [03:26, 22.98it/s]\titers: 4600, epoch: 4 | loss: 0.3117181\n",
      "\tspeed: 0.0425s/iter; left time: 29420.1711s\n",
      "4697it [03:30, 20.27it/s]\titers: 4700, epoch: 4 | loss: 0.2367174\n",
      "\tspeed: 0.0446s/iter; left time: 30816.8757s\n",
      "4799it [03:35, 24.05it/s]\titers: 4800, epoch: 4 | loss: 0.1028031\n",
      "\tspeed: 0.0432s/iter; left time: 29893.9810s\n",
      "4898it [03:39, 18.71it/s]\titers: 4900, epoch: 4 | loss: 0.6673850\n",
      "\tspeed: 0.0461s/iter; left time: 31903.2529s\n",
      "4999it [03:45, 16.80it/s]\titers: 5000, epoch: 4 | loss: 0.2865047\n",
      "\tspeed: 0.0565s/iter; left time: 39036.1023s\n",
      "5098it [03:49, 24.79it/s]\titers: 5100, epoch: 4 | loss: 0.2150929\n",
      "\tspeed: 0.0410s/iter; left time: 28342.5243s\n",
      "5197it [03:53, 23.67it/s]\titers: 5200, epoch: 4 | loss: 0.1405899\n",
      "\tspeed: 0.0420s/iter; left time: 29058.2950s\n",
      "5299it [03:57, 23.90it/s]\titers: 5300, epoch: 4 | loss: 0.3389138\n",
      "\tspeed: 0.0414s/iter; left time: 28591.2028s\n",
      "5398it [04:01, 24.26it/s]\titers: 5400, epoch: 4 | loss: 0.1850120\n",
      "\tspeed: 0.0399s/iter; left time: 27559.9906s\n",
      "5497it [04:05, 23.74it/s]\titers: 5500, epoch: 4 | loss: 0.2476273\n",
      "\tspeed: 0.0415s/iter; left time: 28665.0585s\n",
      "5599it [04:10, 23.14it/s]\titers: 5600, epoch: 4 | loss: 0.1880543\n",
      "\tspeed: 0.0431s/iter; left time: 29747.1838s\n",
      "5698it [04:14, 20.66it/s]\titers: 5700, epoch: 4 | loss: 0.7938313\n",
      "\tspeed: 0.0452s/iter; left time: 31200.1516s\n",
      "5798it [04:19, 22.39it/s]\titers: 5800, epoch: 4 | loss: 0.2925030\n",
      "\tspeed: 0.0472s/iter; left time: 32611.8352s\n",
      "5899it [04:23, 21.60it/s]\titers: 5900, epoch: 4 | loss: 0.2032930\n",
      "\tspeed: 0.0440s/iter; left time: 30385.4325s\n",
      "5998it [04:28, 23.71it/s]\titers: 6000, epoch: 4 | loss: 0.2319914\n",
      "\tspeed: 0.0422s/iter; left time: 29110.8644s\n",
      "6097it [04:32, 24.53it/s]\titers: 6100, epoch: 4 | loss: 0.1932314\n",
      "\tspeed: 0.0418s/iter; left time: 28861.8000s\n",
      "6199it [04:36, 25.33it/s]\titers: 6200, epoch: 4 | loss: 0.1821531\n",
      "\tspeed: 0.0428s/iter; left time: 29517.5654s\n",
      "6299it [04:41, 23.25it/s]\titers: 6300, epoch: 4 | loss: 0.5295746\n",
      "\tspeed: 0.0438s/iter; left time: 30251.6360s\n",
      "6398it [04:45, 19.51it/s]\titers: 6400, epoch: 4 | loss: 0.1748666\n",
      "\tspeed: 0.0452s/iter; left time: 31203.4965s\n",
      "6499it [04:51, 17.25it/s]\titers: 6500, epoch: 4 | loss: 0.7527309\n",
      "\tspeed: 0.0577s/iter; left time: 39781.0706s\n",
      "6599it [04:56, 26.36it/s]\titers: 6600, epoch: 4 | loss: 0.5236177\n",
      "\tspeed: 0.0500s/iter; left time: 34499.8012s\n",
      "6698it [05:00, 24.70it/s]\titers: 6700, epoch: 4 | loss: 0.3865529\n",
      "\tspeed: 0.0420s/iter; left time: 28987.5351s\n",
      "6797it [05:04, 24.68it/s]\titers: 6800, epoch: 4 | loss: 0.3114258\n",
      "\tspeed: 0.0403s/iter; left time: 27804.5776s\n",
      "6899it [05:08, 23.76it/s]\titers: 6900, epoch: 4 | loss: 0.2576486\n",
      "\tspeed: 0.0430s/iter; left time: 29625.1621s\n",
      "6998it [05:13, 22.40it/s]\titers: 7000, epoch: 4 | loss: 0.3224902\n",
      "\tspeed: 0.0437s/iter; left time: 30105.7276s\n",
      "7098it [05:17, 19.11it/s]\titers: 7100, epoch: 4 | loss: 0.3550968\n",
      "\tspeed: 0.0444s/iter; left time: 30585.2601s\n",
      "7198it [05:23, 17.03it/s]\titers: 7200, epoch: 4 | loss: 0.1952577\n",
      "\tspeed: 0.0549s/iter; left time: 37848.1504s\n",
      "7299it [05:27, 19.50it/s]\titers: 7300, epoch: 4 | loss: 0.4378886\n",
      "\tspeed: 0.0477s/iter; left time: 32877.6915s\n",
      "7397it [05:31, 24.18it/s]\titers: 7400, epoch: 4 | loss: 0.1974247\n",
      "\tspeed: 0.0407s/iter; left time: 28036.5364s\n",
      "7499it [05:36, 24.98it/s]\titers: 7500, epoch: 4 | loss: 0.3388119\n",
      "\tspeed: 0.0411s/iter; left time: 28292.4959s\n",
      "7598it [05:40, 24.35it/s]\titers: 7600, epoch: 4 | loss: 0.1495921\n",
      "\tspeed: 0.0403s/iter; left time: 27765.8775s\n",
      "7697it [05:44, 26.55it/s]\titers: 7700, epoch: 4 | loss: 0.3614186\n",
      "\tspeed: 0.0401s/iter; left time: 27600.6796s\n",
      "7799it [05:48, 24.59it/s]\titers: 7800, epoch: 4 | loss: 0.3088455\n",
      "\tspeed: 0.0407s/iter; left time: 28028.0991s\n",
      "7898it [05:52, 21.74it/s]\titers: 7900, epoch: 4 | loss: 0.1491339\n",
      "\tspeed: 0.0437s/iter; left time: 30070.2452s\n",
      "7997it [05:57, 20.88it/s]\titers: 8000, epoch: 4 | loss: 0.5961709\n",
      "\tspeed: 0.0465s/iter; left time: 31995.7076s\n",
      "8098it [06:01, 18.92it/s]\titers: 8100, epoch: 4 | loss: 0.1923337\n",
      "\tspeed: 0.0481s/iter; left time: 33119.7224s\n",
      "8197it [06:06, 22.82it/s]\titers: 8200, epoch: 4 | loss: 0.1876185\n",
      "\tspeed: 0.0422s/iter; left time: 29016.3834s\n",
      "8299it [06:10, 23.96it/s]\titers: 8300, epoch: 4 | loss: 0.2311641\n",
      "\tspeed: 0.0425s/iter; left time: 29251.6211s\n",
      "8398it [06:14, 23.16it/s]\titers: 8400, epoch: 4 | loss: 0.1094585\n",
      "\tspeed: 0.0417s/iter; left time: 28676.6791s\n",
      "8497it [06:18, 22.71it/s]\titers: 8500, epoch: 4 | loss: 0.5112658\n",
      "\tspeed: 0.0422s/iter; left time: 29018.5131s\n",
      "8599it [06:23, 23.04it/s]\titers: 8600, epoch: 4 | loss: 0.8517913\n",
      "\tspeed: 0.0430s/iter; left time: 29561.2397s\n",
      "8698it [06:27, 29.77it/s]\titers: 8700, epoch: 4 | loss: 0.5551071\n",
      "\tspeed: 0.0398s/iter; left time: 27380.8857s\n",
      "8797it [06:31, 22.80it/s]\titers: 8800, epoch: 4 | loss: 0.7695784\n",
      "\tspeed: 0.0449s/iter; left time: 30903.6280s\n",
      "8898it [06:36, 23.69it/s]\titers: 8900, epoch: 4 | loss: 0.2341888\n",
      "\tspeed: 0.0502s/iter; left time: 34481.6954s\n",
      "8997it [06:40, 24.07it/s]\titers: 9000, epoch: 4 | loss: 0.1800662\n",
      "\tspeed: 0.0409s/iter; left time: 28110.0692s\n",
      "9099it [06:45, 23.88it/s]\titers: 9100, epoch: 4 | loss: 0.1074979\n",
      "\tspeed: 0.0427s/iter; left time: 29320.8939s\n",
      "9198it [06:49, 23.99it/s]\titers: 9200, epoch: 4 | loss: 0.3280586\n",
      "\tspeed: 0.0413s/iter; left time: 28380.3306s\n",
      "9297it [06:53, 24.73it/s]\titers: 9300, epoch: 4 | loss: 0.4468344\n",
      "\tspeed: 0.0429s/iter; left time: 29440.5607s\n",
      "9399it [06:57, 21.63it/s]\titers: 9400, epoch: 4 | loss: 0.3205627\n",
      "\tspeed: 0.0452s/iter; left time: 31034.1773s\n",
      "9499it [07:03, 17.71it/s]\titers: 9500, epoch: 4 | loss: 0.2715108\n",
      "\tspeed: 0.0512s/iter; left time: 35185.1057s\n",
      "9599it [07:08, 19.03it/s]\titers: 9600, epoch: 4 | loss: 0.7816707\n",
      "\tspeed: 0.0559s/iter; left time: 38364.0150s\n",
      "9699it [07:12, 25.21it/s]\titers: 9700, epoch: 4 | loss: 0.3189777\n",
      "\tspeed: 0.0400s/iter; left time: 27473.2987s\n",
      "9798it [07:16, 24.78it/s]\titers: 9800, epoch: 4 | loss: 0.3257591\n",
      "\tspeed: 0.0409s/iter; left time: 28071.2533s\n",
      "9897it [07:20, 24.79it/s]\titers: 9900, epoch: 4 | loss: 0.4948491\n",
      "\tspeed: 0.0416s/iter; left time: 28589.6788s\n",
      "9999it [07:24, 25.31it/s]\titers: 10000, epoch: 4 | loss: 0.5580814\n",
      "\tspeed: 0.0401s/iter; left time: 27526.5124s\n",
      "10098it [07:28, 23.29it/s]\titers: 10100, epoch: 4 | loss: 0.5118344\n",
      "\tspeed: 0.0408s/iter; left time: 27994.3165s\n",
      "10197it [07:33, 22.96it/s]\titers: 10200, epoch: 4 | loss: 0.1615215\n",
      "\tspeed: 0.0435s/iter; left time: 29868.2936s\n",
      "10299it [07:37, 21.65it/s]\titers: 10300, epoch: 4 | loss: 0.3331116\n",
      "\tspeed: 0.0440s/iter; left time: 30204.3725s\n",
      "10398it [07:42, 17.04it/s]\titers: 10400, epoch: 4 | loss: 0.2779110\n",
      "\tspeed: 0.0530s/iter; left time: 36330.1806s\n",
      "10499it [07:47, 23.91it/s]\titers: 10500, epoch: 4 | loss: 0.1683977\n",
      "\tspeed: 0.0447s/iter; left time: 30645.3342s\n",
      "10598it [07:51, 23.83it/s]\titers: 10600, epoch: 4 | loss: 0.8855260\n",
      "\tspeed: 0.0416s/iter; left time: 28544.0249s\n",
      "10697it [07:55, 21.97it/s]\titers: 10700, epoch: 4 | loss: 0.1622652\n",
      "\tspeed: 0.0429s/iter; left time: 29439.4315s\n",
      "10799it [08:00, 23.53it/s]\titers: 10800, epoch: 4 | loss: 0.2489486\n",
      "\tspeed: 0.0424s/iter; left time: 29049.6183s\n",
      "10898it [08:04, 22.41it/s]\titers: 10900, epoch: 4 | loss: 0.0938203\n",
      "\tspeed: 0.0435s/iter; left time: 29786.6036s\n",
      "10999it [08:09, 18.89it/s]\titers: 11000, epoch: 4 | loss: 0.2342716\n",
      "\tspeed: 0.0471s/iter; left time: 32255.9269s\n",
      "11098it [08:15, 17.29it/s]\titers: 11100, epoch: 4 | loss: 0.3211882\n",
      "\tspeed: 0.0584s/iter; left time: 40011.2887s\n",
      "11198it [08:19, 24.30it/s]\titers: 11200, epoch: 4 | loss: 0.2170032\n",
      "\tspeed: 0.0452s/iter; left time: 30990.7117s\n",
      "11297it [08:23, 23.12it/s]\titers: 11300, epoch: 4 | loss: 0.3801545\n",
      "\tspeed: 0.0420s/iter; left time: 28774.1030s\n",
      "11399it [08:28, 22.93it/s]\titers: 11400, epoch: 4 | loss: 0.2316433\n",
      "\tspeed: 0.0422s/iter; left time: 28874.8853s\n",
      "11498it [08:32, 24.29it/s]\titers: 11500, epoch: 4 | loss: 0.7608374\n",
      "\tspeed: 0.0404s/iter; left time: 27700.7369s\n",
      "11599it [08:36, 23.40it/s]\titers: 11600, epoch: 4 | loss: 0.4211630\n",
      "\tspeed: 0.0442s/iter; left time: 30266.3198s\n",
      "11699it [08:41, 19.58it/s]\titers: 11700, epoch: 4 | loss: 0.2846328\n",
      "\tspeed: 0.0451s/iter; left time: 30881.3532s\n",
      "11798it [08:46, 17.25it/s]\titers: 11800, epoch: 4 | loss: 0.6524413\n",
      "\tspeed: 0.0556s/iter; left time: 38041.7619s\n",
      "11897it [08:51, 23.96it/s]\titers: 11900, epoch: 4 | loss: 0.6007652\n",
      "\tspeed: 0.0501s/iter; left time: 34294.9889s\n",
      "11997it [08:55, 24.20it/s]\titers: 12000, epoch: 4 | loss: 0.9528483\n",
      "\tspeed: 0.0417s/iter; left time: 28544.8499s\n",
      "12099it [08:59, 25.33it/s]\titers: 12100, epoch: 4 | loss: 0.2187259\n",
      "\tspeed: 0.0407s/iter; left time: 27869.7565s\n",
      "12198it [09:03, 25.38it/s]\titers: 12200, epoch: 4 | loss: 0.3670602\n",
      "\tspeed: 0.0403s/iter; left time: 27557.9381s\n",
      "12297it [09:07, 24.10it/s]\titers: 12300, epoch: 4 | loss: 0.3197168\n",
      "\tspeed: 0.0406s/iter; left time: 27765.5238s\n",
      "12399it [09:11, 25.15it/s]\titers: 12400, epoch: 4 | loss: 0.3553059\n",
      "\tspeed: 0.0404s/iter; left time: 27621.8713s\n",
      "12498it [09:16, 21.36it/s]\titers: 12500, epoch: 4 | loss: 0.1944313\n",
      "\tspeed: 0.0450s/iter; left time: 30780.2165s\n",
      "12599it [09:21, 19.26it/s]\titers: 12600, epoch: 4 | loss: 0.2476454\n",
      "\tspeed: 0.0477s/iter; left time: 32620.4416s\n",
      "12697it [09:25, 24.32it/s]\titers: 12700, epoch: 4 | loss: 0.3414422\n",
      "\tspeed: 0.0482s/iter; left time: 32918.4025s\n",
      "12799it [09:30, 22.95it/s]\titers: 12800, epoch: 4 | loss: 0.1749693\n",
      "\tspeed: 0.0427s/iter; left time: 29170.8845s\n",
      "12898it [09:34, 22.23it/s]\titers: 12900, epoch: 4 | loss: 0.3390207\n",
      "\tspeed: 0.0428s/iter; left time: 29223.6455s\n",
      "12997it [09:38, 22.98it/s]\titers: 13000, epoch: 4 | loss: 0.5696311\n",
      "\tspeed: 0.0419s/iter; left time: 28615.9543s\n",
      "13099it [09:43, 22.88it/s]\titers: 13100, epoch: 4 | loss: 0.6844093\n",
      "\tspeed: 0.0428s/iter; left time: 29221.4094s\n",
      "13198it [09:47, 23.45it/s]\titers: 13200, epoch: 4 | loss: 0.1756243\n",
      "\tspeed: 0.0440s/iter; left time: 30046.3133s\n",
      "13298it [09:52, 16.70it/s]\titers: 13300, epoch: 4 | loss: 0.3554517\n",
      "\tspeed: 0.0555s/iter; left time: 37876.5482s\n",
      "13399it [09:58, 26.25it/s]\titers: 13400, epoch: 4 | loss: 0.3102037\n",
      "\tspeed: 0.0520s/iter; left time: 35534.9146s\n",
      "13498it [10:02, 23.46it/s]\titers: 13500, epoch: 4 | loss: 0.1527738\n",
      "\tspeed: 0.0418s/iter; left time: 28569.1874s\n",
      "13597it [10:06, 24.46it/s]\titers: 13600, epoch: 4 | loss: 0.1615803\n",
      "\tspeed: 0.0420s/iter; left time: 28650.5467s\n",
      "13699it [10:10, 24.15it/s]\titers: 13700, epoch: 4 | loss: 0.5721961\n",
      "\tspeed: 0.0436s/iter; left time: 29760.5598s\n",
      "13798it [10:15, 23.67it/s]\titers: 13800, epoch: 4 | loss: 0.2614636\n",
      "\tspeed: 0.0423s/iter; left time: 28879.2841s\n",
      "13897it [10:19, 22.74it/s]\titers: 13900, epoch: 4 | loss: 0.2688888\n",
      "\tspeed: 0.0432s/iter; left time: 29459.8586s\n",
      "13998it [10:24, 17.44it/s]\titers: 14000, epoch: 4 | loss: 0.2451988\n",
      "\tspeed: 0.0541s/iter; left time: 36929.6240s\n",
      "14099it [10:29, 20.14it/s]\titers: 14100, epoch: 4 | loss: 0.4797363\n",
      "\tspeed: 0.0455s/iter; left time: 31064.9504s\n",
      "14198it [10:33, 24.87it/s]\titers: 14200, epoch: 4 | loss: 0.4740672\n",
      "\tspeed: 0.0433s/iter; left time: 29514.7966s\n",
      "14297it [10:37, 25.18it/s]\titers: 14300, epoch: 4 | loss: 0.4097959\n",
      "\tspeed: 0.0406s/iter; left time: 27696.9226s\n",
      "14399it [10:41, 25.43it/s]\titers: 14400, epoch: 4 | loss: 0.3076765\n",
      "\tspeed: 0.0398s/iter; left time: 27151.0216s\n",
      "14498it [10:45, 22.65it/s]\titers: 14500, epoch: 4 | loss: 0.1715812\n",
      "\tspeed: 0.0408s/iter; left time: 27852.6240s\n",
      "14597it [10:49, 25.18it/s]\titers: 14600, epoch: 4 | loss: 0.2668757\n",
      "\tspeed: 0.0411s/iter; left time: 28041.9323s\n",
      "14699it [10:54, 24.22it/s]\titers: 14700, epoch: 4 | loss: 0.5848483\n",
      "\tspeed: 0.0411s/iter; left time: 28039.4866s\n",
      "14798it [10:58, 20.70it/s]\titers: 14800, epoch: 4 | loss: 0.4444878\n",
      "\tspeed: 0.0438s/iter; left time: 29862.9841s\n",
      "14816it [10:59, 22.47it/s]\n",
      "Epoch: 4 cost time: 659.4174058437347\n",
      "3204it [01:09, 45.78it/s]\n",
      "3192it [01:10, 45.19it/s]\n",
      "Epoch: 4 | Train Loss: 0.3587150 Vali Loss: 0.4554109 Test Loss: 0.5913868 MAE Loss: 0.4858288\n",
      "Validation loss decreased (0.464625 --> 0.455411).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "98it [00:04, 21.00it/s]\titers: 100, epoch: 5 | loss: 0.2305460\n",
      "\tspeed: 1.4785s/iter; left time: 1007506.4722s\n",
      "199it [00:09, 19.43it/s]\titers: 200, epoch: 5 | loss: 0.3015937\n",
      "\tspeed: 0.0464s/iter; left time: 31597.8435s\n",
      "298it [00:14, 23.31it/s]\titers: 300, epoch: 5 | loss: 0.2217310\n",
      "\tspeed: 0.0462s/iter; left time: 31477.4560s\n",
      "399it [00:19, 27.21it/s]\titers: 400, epoch: 5 | loss: 0.1750264\n",
      "\tspeed: 0.0489s/iter; left time: 33333.8448s\n",
      "499it [00:24, 22.08it/s]\titers: 500, epoch: 5 | loss: 0.1464007\n",
      "\tspeed: 0.0524s/iter; left time: 35697.1009s\n",
      "598it [00:28, 25.54it/s]\titers: 600, epoch: 5 | loss: 0.5857660\n",
      "\tspeed: 0.0417s/iter; left time: 28382.9558s\n",
      "698it [00:32, 23.42it/s]\titers: 700, epoch: 5 | loss: 0.2663194\n",
      "\tspeed: 0.0423s/iter; left time: 28769.8152s\n",
      "797it [00:36, 24.00it/s]\titers: 800, epoch: 5 | loss: 0.7587684\n",
      "\tspeed: 0.0396s/iter; left time: 26965.2063s\n",
      "899it [00:40, 24.68it/s]\titers: 900, epoch: 5 | loss: 0.8071168\n",
      "\tspeed: 0.0413s/iter; left time: 28131.8008s\n",
      "998it [00:44, 24.32it/s]\titers: 1000, epoch: 5 | loss: 0.1965312\n",
      "\tspeed: 0.0402s/iter; left time: 27323.9555s\n",
      "1097it [00:49, 21.25it/s]\titers: 1100, epoch: 5 | loss: 0.5681382\n",
      "\tspeed: 0.0443s/iter; left time: 30146.5863s\n",
      "1199it [00:53, 21.99it/s]\titers: 1200, epoch: 5 | loss: 0.4995774\n",
      "\tspeed: 0.0451s/iter; left time: 30698.1750s\n",
      "1297it [00:58, 16.33it/s]\titers: 1300, epoch: 5 | loss: 0.2595541\n",
      "\tspeed: 0.0503s/iter; left time: 34191.5954s\n",
      "1399it [01:02, 24.34it/s]\titers: 1400, epoch: 5 | loss: 0.6290879\n",
      "\tspeed: 0.0413s/iter; left time: 28095.0166s\n",
      "1498it [01:07, 23.92it/s]\titers: 1500, epoch: 5 | loss: 0.1669912\n",
      "\tspeed: 0.0437s/iter; left time: 29710.6930s\n",
      "1597it [01:11, 24.53it/s]\titers: 1600, epoch: 5 | loss: 0.3762224\n",
      "\tspeed: 0.0430s/iter; left time: 29232.3269s\n",
      "1699it [01:15, 23.17it/s]\titers: 1700, epoch: 5 | loss: 0.3205333\n",
      "\tspeed: 0.0419s/iter; left time: 28506.4817s\n",
      "1798it [01:19, 23.45it/s]\titers: 1800, epoch: 5 | loss: 0.3452498\n",
      "\tspeed: 0.0422s/iter; left time: 28682.7851s\n",
      "1898it [01:24, 18.49it/s]\titers: 1900, epoch: 5 | loss: 0.3985712\n",
      "\tspeed: 0.0500s/iter; left time: 33988.3980s\n",
      "1998it [01:30, 17.55it/s]\titers: 2000, epoch: 5 | loss: 0.2490063\n",
      "\tspeed: 0.0573s/iter; left time: 38922.5957s\n",
      "2097it [01:35, 25.19it/s]\titers: 2100, epoch: 5 | loss: 0.2194353\n",
      "\tspeed: 0.0446s/iter; left time: 30284.1692s\n",
      "2199it [01:39, 23.48it/s]\titers: 2200, epoch: 5 | loss: 0.1179004\n",
      "\tspeed: 0.0436s/iter; left time: 29636.9007s\n",
      "2298it [01:43, 24.45it/s]\titers: 2300, epoch: 5 | loss: 0.1489922\n",
      "\tspeed: 0.0431s/iter; left time: 29261.2293s\n",
      "2397it [01:48, 23.20it/s]\titers: 2400, epoch: 5 | loss: 0.4922327\n",
      "\tspeed: 0.0436s/iter; left time: 29590.9681s\n",
      "2499it [01:52, 23.82it/s]\titers: 2500, epoch: 5 | loss: 0.6501368\n",
      "\tspeed: 0.0427s/iter; left time: 29017.6325s\n",
      "2597it [01:56, 19.80it/s]\titers: 2600, epoch: 5 | loss: 0.6103395\n",
      "\tspeed: 0.0460s/iter; left time: 31212.2369s\n",
      "2699it [02:02, 17.49it/s]\titers: 2700, epoch: 5 | loss: 0.1558691\n",
      "\tspeed: 0.0555s/iter; left time: 37699.3936s\n",
      "2799it [02:07, 24.84it/s]\titers: 2800, epoch: 5 | loss: 0.1937745\n",
      "\tspeed: 0.0507s/iter; left time: 34433.7242s\n",
      "2899it [02:11, 25.01it/s]\titers: 2900, epoch: 5 | loss: 0.2215296\n",
      "\tspeed: 0.0405s/iter; left time: 27504.5005s\n",
      "2999it [02:15, 25.23it/s]\titers: 3000, epoch: 5 | loss: 0.3014736\n",
      "\tspeed: 0.0401s/iter; left time: 27190.5207s\n",
      "3098it [02:19, 24.92it/s]\titers: 3100, epoch: 5 | loss: 0.0991576\n",
      "\tspeed: 0.0401s/iter; left time: 27182.7528s\n",
      "3197it [02:23, 24.05it/s]\titers: 3200, epoch: 5 | loss: 0.2663908\n",
      "\tspeed: 0.0403s/iter; left time: 27321.1833s\n",
      "3297it [02:27, 25.65it/s]\titers: 3300, epoch: 5 | loss: 0.1465067\n",
      "\tspeed: 0.0399s/iter; left time: 27095.1453s\n",
      "3399it [02:31, 23.49it/s]\titers: 3400, epoch: 5 | loss: 0.5886030\n",
      "\tspeed: 0.0420s/iter; left time: 28504.8973s\n",
      "3499it [02:36, 21.27it/s]\titers: 3500, epoch: 5 | loss: 0.1948348\n",
      "\tspeed: 0.0456s/iter; left time: 30928.5305s\n",
      "3598it [02:42, 17.25it/s]\titers: 3600, epoch: 5 | loss: 0.2542295\n",
      "\tspeed: 0.0568s/iter; left time: 38517.0421s\n",
      "3697it [02:46, 23.15it/s]\titers: 3700, epoch: 5 | loss: 0.1513371\n",
      "\tspeed: 0.0443s/iter; left time: 30042.9021s\n",
      "3799it [02:50, 24.72it/s]\titers: 3800, epoch: 5 | loss: 0.1162978\n",
      "\tspeed: 0.0422s/iter; left time: 28595.6815s\n",
      "3898it [02:54, 23.45it/s]\titers: 3900, epoch: 5 | loss: 0.2993306\n",
      "\tspeed: 0.0416s/iter; left time: 28197.5597s\n",
      "3997it [02:59, 23.05it/s]\titers: 4000, epoch: 5 | loss: 0.2700831\n",
      "\tspeed: 0.0459s/iter; left time: 31093.4377s\n",
      "4098it [03:04, 22.13it/s]\titers: 4100, epoch: 5 | loss: 0.5472832\n",
      "\tspeed: 0.0467s/iter; left time: 31644.0126s\n",
      "4199it [03:08, 27.20it/s]\titers: 4200, epoch: 5 | loss: 0.1980574\n",
      "\tspeed: 0.0467s/iter; left time: 31652.6644s\n",
      "4299it [03:14, 18.52it/s]\titers: 4300, epoch: 5 | loss: 0.2478197\n",
      "\tspeed: 0.0525s/iter; left time: 35521.1671s\n",
      "4398it [03:18, 23.18it/s]\titers: 4400, epoch: 5 | loss: 0.2503526\n",
      "\tspeed: 0.0451s/iter; left time: 30550.6090s\n",
      "4497it [03:22, 22.88it/s]\titers: 4500, epoch: 5 | loss: 0.5079444\n",
      "\tspeed: 0.0438s/iter; left time: 29643.1820s\n",
      "4599it [03:27, 25.15it/s]\titers: 4600, epoch: 5 | loss: 0.3260390\n",
      "\tspeed: 0.0421s/iter; left time: 28511.2752s\n",
      "4698it [03:31, 24.23it/s]\titers: 4700, epoch: 5 | loss: 0.2476656\n",
      "\tspeed: 0.0434s/iter; left time: 29377.6089s\n",
      "4797it [03:35, 23.01it/s]\titers: 4800, epoch: 5 | loss: 0.6840523\n",
      "\tspeed: 0.0421s/iter; left time: 28504.1972s\n",
      "4897it [03:40, 22.66it/s]\titers: 4900, epoch: 5 | loss: 0.3117846\n",
      "\tspeed: 0.0456s/iter; left time: 30850.9283s\n",
      "4999it [03:44, 24.86it/s]\titers: 5000, epoch: 5 | loss: 0.4344593\n",
      "\tspeed: 0.0398s/iter; left time: 26953.1080s\n",
      "5097it [03:49, 21.32it/s]\titers: 5100, epoch: 5 | loss: 0.5087878\n",
      "\tspeed: 0.0503s/iter; left time: 33998.8946s\n",
      "5199it [03:53, 25.94it/s]\titers: 5200, epoch: 5 | loss: 0.4104542\n",
      "\tspeed: 0.0406s/iter; left time: 27426.1979s\n",
      "5298it [03:57, 23.62it/s]\titers: 5300, epoch: 5 | loss: 0.2145871\n",
      "\tspeed: 0.0410s/iter; left time: 27704.5730s\n",
      "5397it [04:01, 24.58it/s]\titers: 5400, epoch: 5 | loss: 0.1686769\n",
      "\tspeed: 0.0407s/iter; left time: 27497.8561s\n",
      "5499it [04:05, 24.77it/s]\titers: 5500, epoch: 5 | loss: 0.2485573\n",
      "\tspeed: 0.0403s/iter; left time: 27255.0545s\n",
      "5598it [04:09, 24.61it/s]\titers: 5600, epoch: 5 | loss: 0.3030496\n",
      "\tspeed: 0.0406s/iter; left time: 27444.7130s\n",
      "5698it [04:13, 28.64it/s]\titers: 5700, epoch: 5 | loss: 0.5883042\n",
      "\tspeed: 0.0396s/iter; left time: 26755.8736s\n",
      "5797it [04:17, 30.36it/s]\titers: 5800, epoch: 5 | loss: 0.3044241\n",
      "\tspeed: 0.0342s/iter; left time: 23113.6762s\n",
      "5897it [04:21, 17.82it/s]\titers: 5900, epoch: 5 | loss: 0.3543423\n",
      "\tspeed: 0.0487s/iter; left time: 32926.9058s\n",
      "5998it [04:27, 17.51it/s]\titers: 6000, epoch: 5 | loss: 0.1771447\n",
      "\tspeed: 0.0559s/iter; left time: 37733.5252s\n",
      "6097it [04:32, 23.00it/s]\titers: 6100, epoch: 5 | loss: 1.1993849\n",
      "\tspeed: 0.0473s/iter; left time: 31914.5087s\n",
      "6199it [04:36, 22.61it/s]\titers: 6200, epoch: 5 | loss: 0.3741126\n",
      "\tspeed: 0.0420s/iter; left time: 28372.3322s\n",
      "6298it [04:40, 23.27it/s]\titers: 6300, epoch: 5 | loss: 0.3426784\n",
      "\tspeed: 0.0428s/iter; left time: 28872.2311s\n",
      "6397it [04:44, 23.48it/s]\titers: 6400, epoch: 5 | loss: 0.3751390\n",
      "\tspeed: 0.0423s/iter; left time: 28583.0501s\n",
      "6499it [04:49, 21.65it/s]\titers: 6500, epoch: 5 | loss: 0.6135153\n",
      "\tspeed: 0.0491s/iter; left time: 33153.4475s\n",
      "6598it [04:54, 19.02it/s]\titers: 6600, epoch: 5 | loss: 0.7251038\n",
      "\tspeed: 0.0472s/iter; left time: 31855.5333s\n",
      "6697it [04:59, 24.18it/s]\titers: 6700, epoch: 5 | loss: 0.3376411\n",
      "\tspeed: 0.0543s/iter; left time: 36654.6869s\n",
      "6798it [05:04, 24.76it/s]\titers: 6800, epoch: 5 | loss: 0.6778505\n",
      "\tspeed: 0.0442s/iter; left time: 29843.4428s\n",
      "6898it [05:08, 22.98it/s]\titers: 6900, epoch: 5 | loss: 0.2367867\n",
      "\tspeed: 0.0423s/iter; left time: 28544.1887s\n",
      "6998it [05:13, 20.05it/s]\titers: 7000, epoch: 5 | loss: 0.2824425\n",
      "\tspeed: 0.0460s/iter; left time: 31008.3413s\n",
      "7097it [05:17, 24.75it/s]\titers: 7100, epoch: 5 | loss: 0.2987415\n",
      "\tspeed: 0.0452s/iter; left time: 30485.0138s\n",
      "7199it [05:22, 24.05it/s]\titers: 7200, epoch: 5 | loss: 0.2920209\n",
      "\tspeed: 0.0439s/iter; left time: 29632.9245s\n",
      "7298it [05:26, 21.46it/s]\titers: 7300, epoch: 5 | loss: 0.3355755\n",
      "\tspeed: 0.0439s/iter; left time: 29605.0975s\n",
      "7397it [05:30, 22.53it/s]\titers: 7400, epoch: 5 | loss: 0.1615517\n",
      "\tspeed: 0.0441s/iter; left time: 29728.3124s\n",
      "7499it [05:35, 21.64it/s]\titers: 7500, epoch: 5 | loss: 0.1993215\n",
      "\tspeed: 0.0458s/iter; left time: 30893.4648s\n",
      "7597it [05:39, 26.48it/s]\titers: 7600, epoch: 5 | loss: 0.1791057\n",
      "\tspeed: 0.0412s/iter; left time: 27778.0328s\n",
      "7699it [05:43, 24.73it/s]\titers: 7700, epoch: 5 | loss: 0.2397955\n",
      "\tspeed: 0.0407s/iter; left time: 27401.8496s\n",
      "7798it [05:47, 24.35it/s]\titers: 7800, epoch: 5 | loss: 0.3109130\n",
      "\tspeed: 0.0403s/iter; left time: 27177.7437s\n",
      "7897it [05:51, 24.36it/s]\titers: 7900, epoch: 5 | loss: 0.2148320\n",
      "\tspeed: 0.0410s/iter; left time: 27649.8004s\n",
      "7999it [05:56, 23.45it/s]\titers: 8000, epoch: 5 | loss: 0.4989042\n",
      "\tspeed: 0.0436s/iter; left time: 29358.1335s\n",
      "8098it [06:00, 17.28it/s]\titers: 8100, epoch: 5 | loss: 0.3480837\n",
      "\tspeed: 0.0455s/iter; left time: 30632.2618s\n",
      "8199it [06:05, 16.55it/s]\titers: 8200, epoch: 5 | loss: 0.4272659\n",
      "\tspeed: 0.0516s/iter; left time: 34750.1184s\n",
      "8298it [06:11, 17.75it/s]\titers: 8300, epoch: 5 | loss: 0.1894694\n",
      "\tspeed: 0.0557s/iter; left time: 37514.4239s\n",
      "8397it [06:15, 24.80it/s]\titers: 8400, epoch: 5 | loss: 0.2339215\n",
      "\tspeed: 0.0428s/iter; left time: 28837.2206s\n",
      "8498it [06:20, 23.25it/s]\titers: 8500, epoch: 5 | loss: 0.1826598\n",
      "\tspeed: 0.0447s/iter; left time: 30086.7759s\n",
      "8597it [06:24, 24.33it/s]\titers: 8600, epoch: 5 | loss: 0.3120426\n",
      "\tspeed: 0.0435s/iter; left time: 29253.6632s\n",
      "8699it [06:28, 24.32it/s]\titers: 8700, epoch: 5 | loss: 0.1870272\n",
      "\tspeed: 0.0419s/iter; left time: 28189.6730s\n",
      "8798it [06:33, 24.72it/s]\titers: 8800, epoch: 5 | loss: 0.4092231\n",
      "\tspeed: 0.0421s/iter; left time: 28296.4464s\n",
      "8897it [06:37, 20.11it/s]\titers: 8900, epoch: 5 | loss: 0.2540069\n",
      "\tspeed: 0.0498s/iter; left time: 33514.7324s\n",
      "8998it [06:43, 18.71it/s]\titers: 9000, epoch: 5 | loss: 0.2610779\n",
      "\tspeed: 0.0564s/iter; left time: 37957.9534s\n",
      "9098it [06:48, 24.22it/s]\titers: 9100, epoch: 5 | loss: 0.3918426\n",
      "\tspeed: 0.0457s/iter; left time: 30702.2260s\n",
      "9197it [06:52, 24.23it/s]\titers: 9200, epoch: 5 | loss: 0.1907782\n",
      "\tspeed: 0.0429s/iter; left time: 28817.2103s\n",
      "9297it [06:56, 24.32it/s]\titers: 9300, epoch: 5 | loss: 0.2491984\n",
      "\tspeed: 0.0413s/iter; left time: 27780.1711s\n",
      "9399it [07:00, 24.20it/s]\titers: 9400, epoch: 5 | loss: 0.3234518\n",
      "\tspeed: 0.0420s/iter; left time: 28251.8336s\n",
      "9498it [07:05, 22.66it/s]\titers: 9500, epoch: 5 | loss: 0.2897208\n",
      "\tspeed: 0.0426s/iter; left time: 28658.4772s\n",
      "9597it [07:09, 24.23it/s]\titers: 9600, epoch: 5 | loss: 0.5611585\n",
      "\tspeed: 0.0439s/iter; left time: 29528.4414s\n",
      "9699it [07:14, 20.49it/s]\titers: 9700, epoch: 5 | loss: 0.8563988\n",
      "\tspeed: 0.0474s/iter; left time: 31841.0470s\n",
      "9798it [07:18, 21.49it/s]\titers: 9800, epoch: 5 | loss: 0.2080276\n",
      "\tspeed: 0.0462s/iter; left time: 31056.2475s\n",
      "9898it [07:22, 24.37it/s]\titers: 9900, epoch: 5 | loss: 0.3435356\n",
      "\tspeed: 0.0412s/iter; left time: 27673.7511s\n",
      "9997it [07:26, 25.45it/s]\titers: 10000, epoch: 5 | loss: 0.2092636\n",
      "\tspeed: 0.0402s/iter; left time: 26999.1127s\n",
      "10099it [07:31, 26.47it/s]\titers: 10100, epoch: 5 | loss: 0.1853700\n",
      "\tspeed: 0.0397s/iter; left time: 26688.6996s\n",
      "10198it [07:34, 24.29it/s]\titers: 10200, epoch: 5 | loss: 0.1514463\n",
      "\tspeed: 0.0400s/iter; left time: 26880.5044s\n",
      "10297it [07:39, 21.88it/s]\titers: 10300, epoch: 5 | loss: 0.5476085\n",
      "\tspeed: 0.0435s/iter; left time: 29167.5203s\n",
      "10399it [07:43, 24.20it/s]\titers: 10400, epoch: 5 | loss: 0.3843063\n",
      "\tspeed: 0.0433s/iter; left time: 29069.1378s\n",
      "10497it [07:48, 19.12it/s]\titers: 10500, epoch: 5 | loss: 0.7951134\n",
      "\tspeed: 0.0524s/iter; left time: 35129.4422s\n",
      "10597it [07:54, 23.92it/s]\titers: 10600, epoch: 5 | loss: 0.3617176\n",
      "\tspeed: 0.0543s/iter; left time: 36441.0967s\n",
      "10697it [07:58, 26.17it/s]\titers: 10700, epoch: 5 | loss: 0.2927218\n",
      "\tspeed: 0.0412s/iter; left time: 27614.3951s\n",
      "10799it [08:02, 23.68it/s]\titers: 10800, epoch: 5 | loss: 0.1279743\n",
      "\tspeed: 0.0414s/iter; left time: 27786.8789s\n",
      "10899it [08:06, 24.96it/s]\titers: 10900, epoch: 5 | loss: 0.3055369\n",
      "\tspeed: 0.0410s/iter; left time: 27479.0670s\n",
      "10998it [08:10, 21.60it/s]\titers: 11000, epoch: 5 | loss: 0.7323479\n",
      "\tspeed: 0.0431s/iter; left time: 28896.5888s\n",
      "11097it [08:15, 24.70it/s]\titers: 11100, epoch: 5 | loss: 0.4227690\n",
      "\tspeed: 0.0420s/iter; left time: 28133.8342s\n",
      "11199it [08:19, 27.15it/s]\titers: 11200, epoch: 5 | loss: 0.2236375\n",
      "\tspeed: 0.0402s/iter; left time: 26955.0301s\n",
      "11297it [08:23, 23.89it/s]\titers: 11300, epoch: 5 | loss: 0.2621760\n",
      "\tspeed: 0.0411s/iter; left time: 27545.4009s\n",
      "11397it [08:27, 18.36it/s]\titers: 11400, epoch: 5 | loss: 0.1581541\n",
      "\tspeed: 0.0451s/iter; left time: 30241.7267s\n",
      "11497it [08:31, 21.56it/s]\titers: 11500, epoch: 5 | loss: 0.5420423\n",
      "\tspeed: 0.0422s/iter; left time: 28242.6453s\n",
      "11599it [08:36, 23.61it/s]\titers: 11600, epoch: 5 | loss: 0.1728089\n",
      "\tspeed: 0.0418s/iter; left time: 28010.6984s\n",
      "11698it [08:40, 22.85it/s]\titers: 11700, epoch: 5 | loss: 0.2506289\n",
      "\tspeed: 0.0435s/iter; left time: 29157.5937s\n",
      "11797it [08:44, 24.01it/s]\titers: 11800, epoch: 5 | loss: 0.5162008\n",
      "\tspeed: 0.0443s/iter; left time: 29636.7897s\n",
      "11899it [08:49, 25.64it/s]\titers: 11900, epoch: 5 | loss: 0.2943844\n",
      "\tspeed: 0.0408s/iter; left time: 27311.7839s\n",
      "11998it [08:53, 20.95it/s]\titers: 12000, epoch: 5 | loss: 0.2897620\n",
      "\tspeed: 0.0445s/iter; left time: 29812.8197s\n",
      "12097it [08:58, 21.45it/s]\titers: 12100, epoch: 5 | loss: 0.4426323\n",
      "\tspeed: 0.0459s/iter; left time: 30694.7768s\n",
      "12199it [09:02, 20.69it/s]\titers: 12200, epoch: 5 | loss: 0.5539030\n",
      "\tspeed: 0.0462s/iter; left time: 30896.4343s\n",
      "12297it [09:06, 26.05it/s]\titers: 12300, epoch: 5 | loss: 0.1596682\n",
      "\tspeed: 0.0391s/iter; left time: 26168.9001s\n",
      "12399it [09:10, 24.26it/s]\titers: 12400, epoch: 5 | loss: 0.1075682\n",
      "\tspeed: 0.0416s/iter; left time: 27836.2370s\n",
      "12498it [09:15, 23.64it/s]\titers: 12500, epoch: 5 | loss: 0.8833743\n",
      "\tspeed: 0.0443s/iter; left time: 29652.8662s\n",
      "12597it [09:19, 24.03it/s]\titers: 12600, epoch: 5 | loss: 0.1542282\n",
      "\tspeed: 0.0430s/iter; left time: 28747.8221s\n",
      "12699it [09:23, 23.03it/s]\titers: 12700, epoch: 5 | loss: 0.1995778\n",
      "\tspeed: 0.0426s/iter; left time: 28507.6211s\n",
      "12798it [09:28, 19.29it/s]\titers: 12800, epoch: 5 | loss: 0.9572430\n",
      "\tspeed: 0.0449s/iter; left time: 30024.6842s\n",
      "12899it [09:33, 17.31it/s]\titers: 12900, epoch: 5 | loss: 0.4034707\n",
      "\tspeed: 0.0562s/iter; left time: 37592.9512s\n",
      "12998it [09:38, 23.09it/s]\titers: 13000, epoch: 5 | loss: 0.6003628\n",
      "\tspeed: 0.0490s/iter; left time: 32753.2657s\n",
      "13098it [09:42, 25.66it/s]\titers: 13100, epoch: 5 | loss: 0.3156387\n",
      "\tspeed: 0.0417s/iter; left time: 27851.4450s\n",
      "13197it [09:47, 23.14it/s]\titers: 13200, epoch: 5 | loss: 0.3121930\n",
      "\tspeed: 0.0427s/iter; left time: 28534.3233s\n",
      "13299it [09:51, 22.61it/s]\titers: 13300, epoch: 5 | loss: 0.5606303\n",
      "\tspeed: 0.0423s/iter; left time: 28243.8145s\n",
      "13398it [09:55, 24.64it/s]\titers: 13400, epoch: 5 | loss: 0.9160708\n",
      "\tspeed: 0.0430s/iter; left time: 28748.6080s\n",
      "13497it [10:00, 22.55it/s]\titers: 13500, epoch: 5 | loss: 0.1423665\n",
      "\tspeed: 0.0443s/iter; left time: 29623.3680s\n",
      "13598it [10:05, 17.75it/s]\titers: 13600, epoch: 5 | loss: 0.4108829\n",
      "\tspeed: 0.0556s/iter; left time: 37107.1256s\n",
      "13699it [10:10, 24.90it/s]\titers: 13700, epoch: 5 | loss: 0.2306906\n",
      "\tspeed: 0.0518s/iter; left time: 34624.6874s\n",
      "13798it [10:15, 23.65it/s]\titers: 13800, epoch: 5 | loss: 0.3975872\n",
      "\tspeed: 0.0424s/iter; left time: 28344.6946s\n",
      "13897it [10:19, 25.03it/s]\titers: 13900, epoch: 5 | loss: 0.0969111\n",
      "\tspeed: 0.0416s/iter; left time: 27762.2342s\n",
      "13999it [10:23, 22.38it/s]\titers: 14000, epoch: 5 | loss: 0.4403995\n",
      "\tspeed: 0.0425s/iter; left time: 28346.7185s\n",
      "14098it [10:27, 25.18it/s]\titers: 14100, epoch: 5 | loss: 0.4403400\n",
      "\tspeed: 0.0408s/iter; left time: 27200.4116s\n",
      "14197it [10:31, 23.56it/s]\titers: 14200, epoch: 5 | loss: 0.6731554\n",
      "\tspeed: 0.0403s/iter; left time: 26915.9875s\n",
      "14299it [10:36, 21.70it/s]\titers: 14300, epoch: 5 | loss: 0.1631805\n",
      "\tspeed: 0.0438s/iter; left time: 29211.5803s\n",
      "14398it [10:40, 20.46it/s]\titers: 14400, epoch: 5 | loss: 0.3029134\n",
      "\tspeed: 0.0451s/iter; left time: 30087.0309s\n",
      "14497it [10:45, 21.27it/s]\titers: 14500, epoch: 5 | loss: 0.4262111\n",
      "\tspeed: 0.0461s/iter; left time: 30750.3811s\n",
      "14597it [10:49, 24.50it/s]\titers: 14600, epoch: 5 | loss: 0.9286230\n",
      "\tspeed: 0.0402s/iter; left time: 26832.9919s\n",
      "14697it [10:53, 23.79it/s]\titers: 14700, epoch: 5 | loss: 0.6335403\n",
      "\tspeed: 0.0421s/iter; left time: 28091.3646s\n",
      "14799it [10:57, 22.70it/s]\titers: 14800, epoch: 5 | loss: 0.2591784\n",
      "\tspeed: 0.0441s/iter; left time: 29398.0997s\n",
      "14816it [10:58, 22.49it/s]\n",
      "Epoch: 5 cost time: 658.6759600639343\n",
      "3204it [01:09, 46.22it/s]\n",
      "3192it [01:10, 45.30it/s]\n",
      "Epoch: 5 | Train Loss: 0.3519023 Vali Loss: 0.4574203 Test Loss: 0.5933794 MAE Loss: 0.4816362\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000400000\n",
      "98it [00:05, 17.40it/s]\titers: 100, epoch: 6 | loss: 0.2936621\n",
      "\tspeed: 1.4653s/iter; left time: 976826.6254s\n",
      "199it [00:10, 23.44it/s]\titers: 200, epoch: 6 | loss: 0.3793704\n",
      "\tspeed: 0.0502s/iter; left time: 33426.5262s\n",
      "297it [00:15, 23.14it/s]\titers: 300, epoch: 6 | loss: 0.1651248\n",
      "\tspeed: 0.0414s/iter; left time: 27573.9350s\n",
      "399it [00:19, 20.54it/s]\titers: 400, epoch: 6 | loss: 0.1877437\n",
      "\tspeed: 0.0439s/iter; left time: 29241.2094s\n",
      "498it [00:23, 26.08it/s]\titers: 500, epoch: 6 | loss: 0.1496411\n",
      "\tspeed: 0.0428s/iter; left time: 28492.8121s\n",
      "597it [00:27, 24.60it/s]\titers: 600, epoch: 6 | loss: 0.1438605\n",
      "\tspeed: 0.0403s/iter; left time: 26872.7182s\n",
      "699it [00:31, 25.56it/s]\titers: 700, epoch: 6 | loss: 0.1959265\n",
      "\tspeed: 0.0395s/iter; left time: 26329.0349s\n",
      "798it [00:36, 20.62it/s]\titers: 800, epoch: 6 | loss: 0.2477929\n",
      "\tspeed: 0.0452s/iter; left time: 30086.5133s\n",
      "897it [00:40, 21.83it/s]\titers: 900, epoch: 6 | loss: 0.1364804\n",
      "\tspeed: 0.0454s/iter; left time: 30235.8230s\n",
      "998it [00:45, 25.70it/s]\titers: 1000, epoch: 6 | loss: 0.4619678\n",
      "\tspeed: 0.0436s/iter; left time: 29033.8772s\n",
      "1097it [00:49, 23.89it/s]\titers: 1100, epoch: 6 | loss: 0.5164634\n",
      "\tspeed: 0.0408s/iter; left time: 27144.8993s\n",
      "1198it [00:53, 25.85it/s]\titers: 1200, epoch: 6 | loss: 0.5240765\n",
      "\tspeed: 0.0412s/iter; left time: 27413.5364s\n",
      "1297it [00:57, 25.12it/s]\titers: 1300, epoch: 6 | loss: 0.3654906\n",
      "\tspeed: 0.0416s/iter; left time: 27688.3535s\n",
      "1399it [01:01, 22.89it/s]\titers: 1400, epoch: 6 | loss: 0.2032688\n",
      "\tspeed: 0.0420s/iter; left time: 27947.9302s\n",
      "1498it [01:06, 21.65it/s]\titers: 1500, epoch: 6 | loss: 0.5962573\n",
      "\tspeed: 0.0448s/iter; left time: 29777.5239s\n",
      "1598it [01:11, 17.67it/s]\titers: 1600, epoch: 6 | loss: 0.3283030\n",
      "\tspeed: 0.0499s/iter; left time: 33192.9379s\n",
      "1698it [01:16, 17.82it/s]\titers: 1700, epoch: 6 | loss: 0.7703698\n",
      "\tspeed: 0.0553s/iter; left time: 36743.0594s\n",
      "1797it [01:21, 22.45it/s]\titers: 1800, epoch: 6 | loss: 0.1270316\n",
      "\tspeed: 0.0467s/iter; left time: 31068.0732s\n",
      "1899it [01:25, 24.83it/s]\titers: 1900, epoch: 6 | loss: 0.2055087\n",
      "\tspeed: 0.0408s/iter; left time: 27128.7160s\n",
      "1998it [01:29, 23.63it/s]\titers: 2000, epoch: 6 | loss: 0.3011176\n",
      "\tspeed: 0.0437s/iter; left time: 29047.7000s\n",
      "2097it [01:33, 24.35it/s]\titers: 2100, epoch: 6 | loss: 0.3628902\n",
      "\tspeed: 0.0416s/iter; left time: 27648.5717s\n",
      "2199it [01:38, 24.43it/s]\titers: 2200, epoch: 6 | loss: 0.1563153\n",
      "\tspeed: 0.0420s/iter; left time: 27891.0191s\n",
      "2299it [01:42, 17.62it/s]\titers: 2300, epoch: 6 | loss: 0.5818335\n",
      "\tspeed: 0.0468s/iter; left time: 31092.2324s\n",
      "2397it [01:48, 19.25it/s]\titers: 2400, epoch: 6 | loss: 0.1276182\n",
      "\tspeed: 0.0575s/iter; left time: 38181.6638s\n",
      "2499it [01:53, 22.11it/s]\titers: 2500, epoch: 6 | loss: 0.1287532\n",
      "\tspeed: 0.0489s/iter; left time: 32499.4824s\n",
      "2598it [01:57, 23.92it/s]\titers: 2600, epoch: 6 | loss: 0.3227880\n",
      "\tspeed: 0.0430s/iter; left time: 28542.9427s\n",
      "2699it [02:01, 23.51it/s]\titers: 2700, epoch: 6 | loss: 0.2729033\n",
      "\tspeed: 0.0416s/iter; left time: 27608.5635s\n",
      "2798it [02:05, 24.64it/s]\titers: 2800, epoch: 6 | loss: 0.1627519\n",
      "\tspeed: 0.0401s/iter; left time: 26626.0939s\n",
      "2897it [02:09, 25.19it/s]\titers: 2900, epoch: 6 | loss: 0.1535499\n",
      "\tspeed: 0.0397s/iter; left time: 26359.3883s\n",
      "2999it [02:14, 21.76it/s]\titers: 3000, epoch: 6 | loss: 0.2275990\n",
      "\tspeed: 0.0415s/iter; left time: 27547.0252s\n",
      "3098it [02:18, 21.30it/s]\titers: 3100, epoch: 6 | loss: 1.1220491\n",
      "\tspeed: 0.0448s/iter; left time: 29698.9868s\n",
      "3197it [02:23, 22.19it/s]\titers: 3200, epoch: 6 | loss: 0.2358331\n",
      "\tspeed: 0.0461s/iter; left time: 30596.9818s\n",
      "3297it [02:27, 24.58it/s]\titers: 3300, epoch: 6 | loss: 0.7284061\n",
      "\tspeed: 0.0438s/iter; left time: 29081.1741s\n",
      "3399it [02:31, 23.81it/s]\titers: 3400, epoch: 6 | loss: 0.2569742\n",
      "\tspeed: 0.0413s/iter; left time: 27400.1698s\n",
      "3498it [02:35, 24.10it/s]\titers: 3500, epoch: 6 | loss: 0.5395100\n",
      "\tspeed: 0.0419s/iter; left time: 27782.5199s\n",
      "3597it [02:40, 23.08it/s]\titers: 3600, epoch: 6 | loss: 1.0083261\n",
      "\tspeed: 0.0427s/iter; left time: 28312.4223s\n",
      "3697it [02:44, 22.22it/s]\titers: 3700, epoch: 6 | loss: 0.5627854\n",
      "\tspeed: 0.0426s/iter; left time: 28212.0739s\n",
      "3797it [02:48, 22.66it/s]\titers: 3800, epoch: 6 | loss: 0.1625243\n",
      "\tspeed: 0.0426s/iter; left time: 28227.8741s\n",
      "3898it [02:53, 17.64it/s]\titers: 3900, epoch: 6 | loss: 0.2268854\n",
      "\tspeed: 0.0505s/iter; left time: 33501.3289s\n",
      "3999it [02:58, 17.52it/s]\titers: 4000, epoch: 6 | loss: 0.2085600\n",
      "\tspeed: 0.0448s/iter; left time: 29713.6396s\n",
      "4097it [03:03, 20.33it/s]\titers: 4100, epoch: 6 | loss: 0.1260192\n",
      "\tspeed: 0.0506s/iter; left time: 33523.9175s\n",
      "4198it [03:07, 23.37it/s]\titers: 4200, epoch: 6 | loss: 0.4300714\n",
      "\tspeed: 0.0472s/iter; left time: 31270.6044s\n",
      "4297it [03:12, 24.76it/s]\titers: 4300, epoch: 6 | loss: 1.1589379\n",
      "\tspeed: 0.0441s/iter; left time: 29242.6303s\n",
      "4399it [03:16, 24.74it/s]\titers: 4400, epoch: 6 | loss: 0.1630382\n",
      "\tspeed: 0.0410s/iter; left time: 27179.5669s\n",
      "4498it [03:20, 24.09it/s]\titers: 4500, epoch: 6 | loss: 0.6785685\n",
      "\tspeed: 0.0421s/iter; left time: 27910.6315s\n",
      "4597it [03:25, 28.54it/s]\titers: 4600, epoch: 6 | loss: 0.4801625\n",
      "\tspeed: 0.0452s/iter; left time: 29899.0814s\n",
      "4698it [03:30, 19.24it/s]\titers: 4700, epoch: 6 | loss: 0.5838231\n",
      "\tspeed: 0.0490s/iter; left time: 32408.4706s\n",
      "4797it [03:34, 26.00it/s]\titers: 4800, epoch: 6 | loss: 0.1668066\n",
      "\tspeed: 0.0479s/iter; left time: 31673.5343s\n",
      "4897it [03:38, 23.89it/s]\titers: 4900, epoch: 6 | loss: 0.5862921\n",
      "\tspeed: 0.0413s/iter; left time: 27317.6136s\n",
      "4999it [03:43, 24.18it/s]\titers: 5000, epoch: 6 | loss: 0.0810052\n",
      "\tspeed: 0.0415s/iter; left time: 27442.8120s\n",
      "5098it [03:47, 24.14it/s]\titers: 5100, epoch: 6 | loss: 0.4239528\n",
      "\tspeed: 0.0410s/iter; left time: 27152.2292s\n",
      "5197it [03:51, 26.07it/s]\titers: 5200, epoch: 6 | loss: 0.4956626\n",
      "\tspeed: 0.0402s/iter; left time: 26619.8033s\n",
      "5299it [03:55, 25.65it/s]\titers: 5300, epoch: 6 | loss: 0.1790583\n",
      "\tspeed: 0.0404s/iter; left time: 26724.1426s\n",
      "5398it [03:59, 20.84it/s]\titers: 5400, epoch: 6 | loss: 0.4217979\n",
      "\tspeed: 0.0462s/iter; left time: 30578.9522s\n",
      "5497it [04:04, 19.72it/s]\titers: 5500, epoch: 6 | loss: 0.4433869\n",
      "\tspeed: 0.0476s/iter; left time: 31460.4547s\n",
      "5598it [04:09, 24.57it/s]\titers: 5600, epoch: 6 | loss: 0.3065561\n",
      "\tspeed: 0.0477s/iter; left time: 31537.1077s\n",
      "5697it [04:13, 24.75it/s]\titers: 5700, epoch: 6 | loss: 0.4730638\n",
      "\tspeed: 0.0421s/iter; left time: 27796.9632s\n",
      "5799it [04:17, 24.05it/s]\titers: 5800, epoch: 6 | loss: 0.1743535\n",
      "\tspeed: 0.0423s/iter; left time: 27927.2601s\n",
      "5898it [04:22, 24.67it/s]\titers: 5900, epoch: 6 | loss: 0.2382679\n",
      "\tspeed: 0.0423s/iter; left time: 27941.3658s\n",
      "5997it [04:26, 23.47it/s]\titers: 6000, epoch: 6 | loss: 0.1520603\n",
      "\tspeed: 0.0425s/iter; left time: 28056.7313s\n",
      "6099it [04:30, 22.78it/s]\titers: 6100, epoch: 6 | loss: 0.1954198\n",
      "\tspeed: 0.0426s/iter; left time: 28155.0817s\n",
      "6198it [04:35, 19.74it/s]\titers: 6200, epoch: 6 | loss: 0.3519773\n",
      "\tspeed: 0.0497s/iter; left time: 32832.1900s\n",
      "6298it [04:41, 17.35it/s]\titers: 6300, epoch: 6 | loss: 0.2497960\n",
      "\tspeed: 0.0556s/iter; left time: 36713.9025s\n",
      "6399it [04:45, 23.16it/s]\titers: 6400, epoch: 6 | loss: 0.1775334\n",
      "\tspeed: 0.0428s/iter; left time: 28234.7751s\n",
      "6498it [04:49, 24.06it/s]\titers: 6500, epoch: 6 | loss: 0.3431976\n",
      "\tspeed: 0.0439s/iter; left time: 28954.8039s\n",
      "6597it [04:53, 23.13it/s]\titers: 6600, epoch: 6 | loss: 0.2618109\n",
      "\tspeed: 0.0422s/iter; left time: 27857.0733s\n",
      "6699it [04:58, 23.21it/s]\titers: 6700, epoch: 6 | loss: 0.3587041\n",
      "\tspeed: 0.0422s/iter; left time: 27868.7815s\n",
      "6798it [05:02, 21.97it/s]\titers: 6800, epoch: 6 | loss: 0.2328700\n",
      "\tspeed: 0.0420s/iter; left time: 27747.4528s\n",
      "6898it [05:07, 17.49it/s]\titers: 6900, epoch: 6 | loss: 0.1720991\n",
      "\tspeed: 0.0517s/iter; left time: 34098.9498s\n",
      "6998it [05:12, 17.77it/s]\titers: 7000, epoch: 6 | loss: 0.5401449\n",
      "\tspeed: 0.0510s/iter; left time: 33622.7652s\n",
      "7098it [05:17, 22.37it/s]\titers: 7100, epoch: 6 | loss: 0.2133241\n",
      "\tspeed: 0.0444s/iter; left time: 29312.9722s\n",
      "7197it [05:21, 23.76it/s]\titers: 7200, epoch: 6 | loss: 0.4142926\n",
      "\tspeed: 0.0415s/iter; left time: 27395.4004s\n",
      "7299it [05:25, 24.64it/s]\titers: 7300, epoch: 6 | loss: 0.2929332\n",
      "\tspeed: 0.0400s/iter; left time: 26399.9684s\n",
      "7398it [05:29, 24.63it/s]\titers: 7400, epoch: 6 | loss: 0.3556245\n",
      "\tspeed: 0.0405s/iter; left time: 26714.2269s\n",
      "7497it [05:33, 22.24it/s]\titers: 7500, epoch: 6 | loss: 0.3289596\n",
      "\tspeed: 0.0413s/iter; left time: 27242.5321s\n",
      "7598it [05:38, 21.89it/s]\titers: 7600, epoch: 6 | loss: 0.3496481\n",
      "\tspeed: 0.0449s/iter; left time: 29584.1126s\n",
      "7698it [05:42, 19.43it/s]\titers: 7700, epoch: 6 | loss: 0.6006637\n",
      "\tspeed: 0.0469s/iter; left time: 30933.4056s\n",
      "7798it [05:47, 22.27it/s]\titers: 7800, epoch: 6 | loss: 0.1452258\n",
      "\tspeed: 0.0467s/iter; left time: 30766.2683s\n",
      "7898it [05:51, 22.01it/s]\titers: 7900, epoch: 6 | loss: 0.2795610\n",
      "\tspeed: 0.0443s/iter; left time: 29211.6489s\n",
      "7997it [05:56, 24.48it/s]\titers: 8000, epoch: 6 | loss: 0.2979641\n",
      "\tspeed: 0.0426s/iter; left time: 28067.4228s\n",
      "8099it [06:00, 23.36it/s]\titers: 8100, epoch: 6 | loss: 0.2077766\n",
      "\tspeed: 0.0418s/iter; left time: 27543.1293s\n",
      "8198it [06:04, 21.22it/s]\titers: 8200, epoch: 6 | loss: 0.8426862\n",
      "\tspeed: 0.0428s/iter; left time: 28183.0815s\n",
      "8297it [06:08, 23.01it/s]\titers: 8300, epoch: 6 | loss: 0.2698816\n",
      "\tspeed: 0.0427s/iter; left time: 28117.6031s\n",
      "8399it [06:13, 18.48it/s]\titers: 8400, epoch: 6 | loss: 0.1402520\n",
      "\tspeed: 0.0456s/iter; left time: 30014.0819s\n",
      "8499it [06:18, 17.49it/s]\titers: 8500, epoch: 6 | loss: 0.3197338\n",
      "\tspeed: 0.0539s/iter; left time: 35501.8800s\n",
      "8597it [06:23, 23.85it/s]\titers: 8600, epoch: 6 | loss: 0.1842752\n",
      "\tspeed: 0.0469s/iter; left time: 30860.6126s\n",
      "8697it [06:27, 24.03it/s]\titers: 8700, epoch: 6 | loss: 0.2353677\n",
      "\tspeed: 0.0405s/iter; left time: 26647.9974s\n",
      "8799it [06:31, 24.63it/s]\titers: 8800, epoch: 6 | loss: 0.1752538\n",
      "\tspeed: 0.0433s/iter; left time: 28502.8304s\n",
      "8898it [06:36, 23.74it/s]\titers: 8900, epoch: 6 | loss: 0.5719410\n",
      "\tspeed: 0.0424s/iter; left time: 27895.9235s\n",
      "8997it [06:40, 24.10it/s]\titers: 9000, epoch: 6 | loss: 0.3139502\n",
      "\tspeed: 0.0422s/iter; left time: 27725.7606s\n",
      "9099it [06:44, 21.36it/s]\titers: 9100, epoch: 6 | loss: 0.3432649\n",
      "\tspeed: 0.0435s/iter; left time: 28598.9196s\n",
      "9198it [06:49, 18.58it/s]\titers: 9200, epoch: 6 | loss: 0.3073975\n",
      "\tspeed: 0.0536s/iter; left time: 35226.3573s\n",
      "9299it [06:55, 17.49it/s]\titers: 9300, epoch: 6 | loss: 0.2497945\n",
      "\tspeed: 0.0548s/iter; left time: 36045.6915s\n",
      "9398it [06:59, 25.18it/s]\titers: 9400, epoch: 6 | loss: 0.9610624\n",
      "\tspeed: 0.0428s/iter; left time: 28151.3016s\n",
      "9497it [07:03, 23.75it/s]\titers: 9500, epoch: 6 | loss: 0.3059777\n",
      "\tspeed: 0.0415s/iter; left time: 27275.4869s\n",
      "9599it [07:08, 23.68it/s]\titers: 9600, epoch: 6 | loss: 0.3568260\n",
      "\tspeed: 0.0407s/iter; left time: 26747.3795s\n",
      "9698it [07:12, 24.16it/s]\titers: 9700, epoch: 6 | loss: 0.2868703\n",
      "\tspeed: 0.0411s/iter; left time: 26982.2100s\n",
      "9797it [07:16, 22.95it/s]\titers: 9800, epoch: 6 | loss: 0.5306049\n",
      "\tspeed: 0.0403s/iter; left time: 26501.6758s\n",
      "9899it [07:20, 24.17it/s]\titers: 9900, epoch: 6 | loss: 0.4852527\n",
      "\tspeed: 0.0431s/iter; left time: 28293.1104s\n",
      "9998it [07:25, 20.51it/s]\titers: 10000, epoch: 6 | loss: 0.8940011\n",
      "\tspeed: 0.0462s/iter; left time: 30365.2388s\n",
      "10098it [07:30, 17.47it/s]\titers: 10100, epoch: 6 | loss: 0.1049932\n",
      "\tspeed: 0.0545s/iter; left time: 35787.7359s\n",
      "10199it [07:35, 22.53it/s]\titers: 10200, epoch: 6 | loss: 0.1990149\n",
      "\tspeed: 0.0453s/iter; left time: 29748.7330s\n",
      "10298it [07:39, 22.97it/s]\titers: 10300, epoch: 6 | loss: 0.2065516\n",
      "\tspeed: 0.0432s/iter; left time: 28388.5371s\n",
      "10397it [07:43, 22.78it/s]\titers: 10400, epoch: 6 | loss: 0.5556059\n",
      "\tspeed: 0.0437s/iter; left time: 28656.5549s\n",
      "10499it [07:48, 22.84it/s]\titers: 10500, epoch: 6 | loss: 0.2600691\n",
      "\tspeed: 0.0439s/iter; left time: 28822.1225s\n",
      "10598it [07:52, 23.42it/s]\titers: 10600, epoch: 6 | loss: 0.5026081\n",
      "\tspeed: 0.0426s/iter; left time: 27935.6620s\n",
      "10698it [07:56, 29.41it/s]\titers: 10700, epoch: 6 | loss: 0.6008983\n",
      "\tspeed: 0.0401s/iter; left time: 26302.6319s\n",
      "10799it [07:59, 27.57it/s]\titers: 10800, epoch: 6 | loss: 0.3918109\n",
      "\tspeed: 0.0355s/iter; left time: 23266.5183s\n",
      "10898it [08:06, 16.34it/s]\titers: 10900, epoch: 6 | loss: 0.2753001\n",
      "\tspeed: 0.0631s/iter; left time: 41352.6292s\n",
      "10998it [08:11, 17.45it/s]\titers: 11000, epoch: 6 | loss: 0.2037680\n",
      "\tspeed: 0.0539s/iter; left time: 35360.2328s\n",
      "11098it [08:16, 24.04it/s]\titers: 11100, epoch: 6 | loss: 0.3278367\n",
      "\tspeed: 0.0463s/iter; left time: 30348.4066s\n",
      "11197it [08:20, 25.66it/s]\titers: 11200, epoch: 6 | loss: 0.5594113\n",
      "\tspeed: 0.0425s/iter; left time: 27869.9060s\n",
      "11299it [08:24, 22.74it/s]\titers: 11300, epoch: 6 | loss: 0.2514786\n",
      "\tspeed: 0.0431s/iter; left time: 28255.5047s\n",
      "11398it [08:29, 24.58it/s]\titers: 11400, epoch: 6 | loss: 0.4271148\n",
      "\tspeed: 0.0430s/iter; left time: 28147.9858s\n",
      "11497it [08:33, 23.63it/s]\titers: 11500, epoch: 6 | loss: 0.8611218\n",
      "\tspeed: 0.0428s/iter; left time: 28016.2847s\n",
      "11599it [08:37, 19.27it/s]\titers: 11600, epoch: 6 | loss: 0.1509242\n",
      "\tspeed: 0.0429s/iter; left time: 28077.1195s\n",
      "11697it [08:42, 20.68it/s]\titers: 11700, epoch: 6 | loss: 0.3071425\n",
      "\tspeed: 0.0471s/iter; left time: 30854.8829s\n",
      "11799it [08:47, 21.71it/s]\titers: 11800, epoch: 6 | loss: 0.2980071\n",
      "\tspeed: 0.0467s/iter; left time: 30590.8977s\n",
      "11898it [08:51, 24.76it/s]\titers: 11900, epoch: 6 | loss: 0.4376500\n",
      "\tspeed: 0.0411s/iter; left time: 26899.8112s\n",
      "11997it [08:55, 24.48it/s]\titers: 12000, epoch: 6 | loss: 0.1367847\n",
      "\tspeed: 0.0398s/iter; left time: 26083.8909s\n",
      "12099it [08:59, 24.44it/s]\titers: 12100, epoch: 6 | loss: 0.6643260\n",
      "\tspeed: 0.0407s/iter; left time: 26642.9775s\n",
      "12198it [09:03, 24.25it/s]\titers: 12200, epoch: 6 | loss: 0.2391578\n",
      "\tspeed: 0.0419s/iter; left time: 27431.8614s\n",
      "12297it [09:07, 20.78it/s]\titers: 12300, epoch: 6 | loss: 0.9236857\n",
      "\tspeed: 0.0442s/iter; left time: 28939.1047s\n",
      "12399it [09:12, 21.85it/s]\titers: 12400, epoch: 6 | loss: 0.2929742\n",
      "\tspeed: 0.0460s/iter; left time: 30085.9779s\n",
      "12498it [09:18, 17.21it/s]\titers: 12500, epoch: 6 | loss: 0.2784688\n",
      "\tspeed: 0.0564s/iter; left time: 36867.4340s\n",
      "12597it [09:23, 22.20it/s]\titers: 12600, epoch: 6 | loss: 0.8288008\n",
      "\tspeed: 0.0529s/iter; left time: 34608.8708s\n",
      "12696it [09:27, 23.05it/s]\titers: 12700, epoch: 6 | loss: 0.1513814\n",
      "\tspeed: 0.0450s/iter; left time: 29448.9987s\n",
      "12797it [09:32, 23.98it/s]\titers: 12800, epoch: 6 | loss: 0.1796747\n",
      "\tspeed: 0.0432s/iter; left time: 28256.7674s\n",
      "12899it [09:36, 24.33it/s]\titers: 12900, epoch: 6 | loss: 0.3083021\n",
      "\tspeed: 0.0448s/iter; left time: 29266.8569s\n",
      "12999it [09:40, 25.28it/s]\titers: 13000, epoch: 6 | loss: 1.0637782\n",
      "\tspeed: 0.0424s/iter; left time: 27702.4339s\n",
      "13098it [09:45, 22.59it/s]\titers: 13100, epoch: 6 | loss: 0.1053766\n",
      "\tspeed: 0.0423s/iter; left time: 27650.1865s\n",
      "13198it [09:49, 19.10it/s]\titers: 13200, epoch: 6 | loss: 0.2976939\n",
      "\tspeed: 0.0458s/iter; left time: 29915.8952s\n",
      "13297it [09:55, 16.85it/s]\titers: 13300, epoch: 6 | loss: 0.1187241\n",
      "\tspeed: 0.0576s/iter; left time: 37623.5007s\n",
      "13399it [10:00, 24.16it/s]\titers: 13400, epoch: 6 | loss: 0.3437259\n",
      "\tspeed: 0.0470s/iter; left time: 30677.9532s\n",
      "13498it [10:04, 25.60it/s]\titers: 13500, epoch: 6 | loss: 0.3218561\n",
      "\tspeed: 0.0424s/iter; left time: 27678.3785s\n",
      "13597it [10:08, 24.78it/s]\titers: 13600, epoch: 6 | loss: 0.1428437\n",
      "\tspeed: 0.0411s/iter; left time: 26825.3542s\n",
      "13699it [10:12, 24.13it/s]\titers: 13700, epoch: 6 | loss: 0.4624282\n",
      "\tspeed: 0.0412s/iter; left time: 26907.4148s\n",
      "13798it [10:16, 22.77it/s]\titers: 13800, epoch: 6 | loss: 0.5054744\n",
      "\tspeed: 0.0428s/iter; left time: 27964.7231s\n",
      "13897it [10:21, 22.60it/s]\titers: 13900, epoch: 6 | loss: 0.5861977\n",
      "\tspeed: 0.0419s/iter; left time: 27330.8528s\n",
      "13999it [10:25, 21.91it/s]\titers: 14000, epoch: 6 | loss: 0.1766035\n",
      "\tspeed: 0.0447s/iter; left time: 29197.8836s\n",
      "14098it [10:30, 21.00it/s]\titers: 14100, epoch: 6 | loss: 0.2653042\n",
      "\tspeed: 0.0471s/iter; left time: 30761.2505s\n",
      "14198it [10:34, 25.67it/s]\titers: 14200, epoch: 6 | loss: 0.3900846\n",
      "\tspeed: 0.0403s/iter; left time: 26302.5157s\n",
      "14297it [10:38, 24.08it/s]\titers: 14300, epoch: 6 | loss: 0.1860855\n",
      "\tspeed: 0.0406s/iter; left time: 26495.2795s\n",
      "14399it [10:42, 23.80it/s]\titers: 14400, epoch: 6 | loss: 0.4388477\n",
      "\tspeed: 0.0413s/iter; left time: 26919.7004s\n",
      "14498it [10:46, 21.36it/s]\titers: 14500, epoch: 6 | loss: 0.1878115\n",
      "\tspeed: 0.0427s/iter; left time: 27856.7346s\n",
      "14598it [10:51, 24.03it/s]\titers: 14600, epoch: 6 | loss: 0.5059304\n",
      "\tspeed: 0.0438s/iter; left time: 28570.1971s\n",
      "14697it [10:55, 20.37it/s]\titers: 14700, epoch: 6 | loss: 0.3248606\n",
      "\tspeed: 0.0458s/iter; left time: 29865.3020s\n",
      "14799it [11:01, 16.63it/s]\titers: 14800, epoch: 6 | loss: 0.4456968\n",
      "\tspeed: 0.0534s/iter; left time: 34812.0244s\n",
      "14816it [11:02, 22.38it/s]\n",
      "Epoch: 6 cost time: 662.0554347038269\n",
      "3204it [01:09, 46.06it/s]\n",
      "3192it [01:09, 45.95it/s]\n",
      "Epoch: 6 | Train Loss: 0.3437630 Vali Loss: 0.4572568 Test Loss: 0.6066124 MAE Loss: 0.4924767\n",
      "EarlyStopping counter: 2 out of 3\n",
      "lr = 0.0000400000\n",
      "99it [00:04, 24.16it/s]\titers: 100, epoch: 7 | loss: 0.2061352\n",
      "\tspeed: 1.4466s/iter; left time: 942908.7143s\n",
      "198it [00:08, 24.29it/s]\titers: 200, epoch: 7 | loss: 0.1492809\n",
      "\tspeed: 0.0414s/iter; left time: 26985.8939s\n",
      "297it [00:13, 22.32it/s]\titers: 300, epoch: 7 | loss: 0.1744678\n",
      "\tspeed: 0.0429s/iter; left time: 27975.2326s\n",
      "399it [00:17, 22.16it/s]\titers: 400, epoch: 7 | loss: 0.3547266\n",
      "\tspeed: 0.0448s/iter; left time: 29218.4623s\n",
      "499it [00:22, 19.52it/s]\titers: 500, epoch: 7 | loss: 0.3505725\n",
      "\tspeed: 0.0492s/iter; left time: 32075.8005s\n",
      "599it [00:27, 24.67it/s]\titers: 600, epoch: 7 | loss: 0.3296242\n",
      "\tspeed: 0.0463s/iter; left time: 30145.8056s\n",
      "698it [00:31, 24.86it/s]\titers: 700, epoch: 7 | loss: 0.2482217\n",
      "\tspeed: 0.0404s/iter; left time: 26325.2510s\n",
      "797it [00:35, 24.92it/s]\titers: 800, epoch: 7 | loss: 0.2576041\n",
      "\tspeed: 0.0405s/iter; left time: 26362.6859s\n",
      "899it [00:39, 23.95it/s]\titers: 900, epoch: 7 | loss: 0.5618296\n",
      "\tspeed: 0.0413s/iter; left time: 26917.6582s\n",
      "998it [00:43, 22.12it/s]\titers: 1000, epoch: 7 | loss: 0.1278328\n",
      "\tspeed: 0.0422s/iter; left time: 27497.1198s\n",
      "1097it [00:47, 23.63it/s]\titers: 1100, epoch: 7 | loss: 0.1957707\n",
      "\tspeed: 0.0427s/iter; left time: 27758.2801s\n",
      "1199it [00:52, 18.58it/s]\titers: 1200, epoch: 7 | loss: 0.2251699\n",
      "\tspeed: 0.0474s/iter; left time: 30875.1712s\n",
      "1298it [00:56, 27.19it/s]\titers: 1300, epoch: 7 | loss: 0.3276539\n",
      "\tspeed: 0.0418s/iter; left time: 27194.7465s\n",
      "1397it [01:00, 26.58it/s]\titers: 1400, epoch: 7 | loss: 0.5077925\n",
      "\tspeed: 0.0368s/iter; left time: 23970.5133s\n",
      "1497it [01:04, 22.90it/s]\titers: 1500, epoch: 7 | loss: 1.1199661\n",
      "\tspeed: 0.0414s/iter; left time: 26924.8433s\n",
      "1597it [01:08, 23.37it/s]\titers: 1600, epoch: 7 | loss: 0.6054173\n",
      "\tspeed: 0.0415s/iter; left time: 26971.6668s\n",
      "1699it [01:13, 24.13it/s]\titers: 1700, epoch: 7 | loss: 0.2082248\n",
      "\tspeed: 0.0432s/iter; left time: 28080.4937s\n",
      "1798it [01:17, 24.03it/s]\titers: 1800, epoch: 7 | loss: 0.2912822\n",
      "\tspeed: 0.0416s/iter; left time: 27063.6579s\n",
      "1897it [01:21, 22.83it/s]\titers: 1900, epoch: 7 | loss: 0.1564337\n",
      "\tspeed: 0.0430s/iter; left time: 27959.8199s\n",
      "1998it [01:26, 17.60it/s]\titers: 2000, epoch: 7 | loss: 0.6411785\n",
      "\tspeed: 0.0516s/iter; left time: 33507.3719s\n",
      "2099it [01:32, 17.61it/s]\titers: 2100, epoch: 7 | loss: 0.7515437\n",
      "\tspeed: 0.0562s/iter; left time: 36548.3258s\n",
      "2199it [01:36, 24.61it/s]\titers: 2200, epoch: 7 | loss: 0.2337615\n",
      "\tspeed: 0.0424s/iter; left time: 27557.3841s\n",
      "2299it [01:40, 24.79it/s]\titers: 2300, epoch: 7 | loss: 0.2829054\n",
      "\tspeed: 0.0419s/iter; left time: 27243.6795s\n",
      "2398it [01:44, 24.25it/s]\titers: 2400, epoch: 7 | loss: 0.4957013\n",
      "\tspeed: 0.0413s/iter; left time: 26793.5353s\n",
      "2497it [01:48, 23.99it/s]\titers: 2500, epoch: 7 | loss: 0.3569604\n",
      "\tspeed: 0.0415s/iter; left time: 26921.3719s\n",
      "2598it [01:53, 21.07it/s]\titers: 2600, epoch: 7 | loss: 0.2215834\n",
      "\tspeed: 0.0470s/iter; left time: 30538.8704s\n",
      "2697it [01:58, 22.35it/s]\titers: 2700, epoch: 7 | loss: 0.2588252\n",
      "\tspeed: 0.0451s/iter; left time: 29302.2560s\n",
      "2798it [02:02, 21.70it/s]\titers: 2800, epoch: 7 | loss: 0.6688654\n",
      "\tspeed: 0.0469s/iter; left time: 30432.4750s\n",
      "2897it [02:07, 25.28it/s]\titers: 2900, epoch: 7 | loss: 0.9793714\n",
      "\tspeed: 0.0446s/iter; left time: 28963.5276s\n",
      "2999it [02:11, 24.23it/s]\titers: 3000, epoch: 7 | loss: 0.6038197\n",
      "\tspeed: 0.0409s/iter; left time: 26554.4272s\n",
      "3098it [02:15, 25.34it/s]\titers: 3100, epoch: 7 | loss: 0.1702218\n",
      "\tspeed: 0.0404s/iter; left time: 26196.5856s\n",
      "3197it [02:19, 23.35it/s]\titers: 3200, epoch: 7 | loss: 0.1000403\n",
      "\tspeed: 0.0409s/iter; left time: 26503.1598s\n",
      "3299it [02:23, 22.03it/s]\titers: 3300, epoch: 7 | loss: 0.3862249\n",
      "\tspeed: 0.0436s/iter; left time: 28256.6386s\n",
      "3399it [02:28, 21.34it/s]\titers: 3400, epoch: 7 | loss: 0.3112553\n",
      "\tspeed: 0.0460s/iter; left time: 29841.5082s\n",
      "3498it [02:33, 24.94it/s]\titers: 3500, epoch: 7 | loss: 0.5032834\n",
      "\tspeed: 0.0459s/iter; left time: 29780.4420s\n",
      "3598it [02:37, 17.72it/s]\titers: 3600, epoch: 7 | loss: 0.1775182\n",
      "\tspeed: 0.0440s/iter; left time: 28523.9909s\n",
      "3697it [02:42, 22.77it/s]\titers: 3700, epoch: 7 | loss: 0.4232211\n",
      "\tspeed: 0.0495s/iter; left time: 32055.6037s\n",
      "3799it [02:46, 23.06it/s]\titers: 3800, epoch: 7 | loss: 0.3518757\n",
      "\tspeed: 0.0428s/iter; left time: 27727.9383s\n",
      "3899it [02:51, 24.22it/s]\titers: 3900, epoch: 7 | loss: 0.2076869\n",
      "\tspeed: 0.0425s/iter; left time: 27568.2026s\n",
      "3998it [02:55, 23.77it/s]\titers: 4000, epoch: 7 | loss: 0.1553333\n",
      "\tspeed: 0.0427s/iter; left time: 27667.3924s\n",
      "4097it [02:59, 23.39it/s]\titers: 4100, epoch: 7 | loss: 0.1716274\n",
      "\tspeed: 0.0424s/iter; left time: 27498.2157s\n",
      "4199it [03:04, 19.20it/s]\titers: 4200, epoch: 7 | loss: 0.9326766\n",
      "\tspeed: 0.0465s/iter; left time: 30096.6281s\n",
      "4299it [03:09, 17.54it/s]\titers: 4300, epoch: 7 | loss: 0.5520208\n",
      "\tspeed: 0.0557s/iter; left time: 36088.5528s\n",
      "4399it [03:14, 24.04it/s]\titers: 4400, epoch: 7 | loss: 0.2177991\n",
      "\tspeed: 0.0519s/iter; left time: 33591.7579s\n",
      "4498it [03:19, 24.13it/s]\titers: 4500, epoch: 7 | loss: 0.8518427\n",
      "\tspeed: 0.0412s/iter; left time: 26695.0930s\n",
      "4597it [03:23, 24.13it/s]\titers: 4600, epoch: 7 | loss: 0.2635543\n",
      "\tspeed: 0.0413s/iter; left time: 26719.8647s\n",
      "4699it [03:27, 24.20it/s]\titers: 4700, epoch: 7 | loss: 0.3085926\n",
      "\tspeed: 0.0421s/iter; left time: 27259.8002s\n",
      "4798it [03:31, 23.09it/s]\titers: 4800, epoch: 7 | loss: 0.3452523\n",
      "\tspeed: 0.0419s/iter; left time: 27118.2250s\n",
      "4898it [03:35, 22.96it/s]\titers: 4900, epoch: 7 | loss: 0.1251037\n",
      "\tspeed: 0.0423s/iter; left time: 27363.7317s\n",
      "4997it [03:40, 22.67it/s]\titers: 5000, epoch: 7 | loss: 0.2402746\n",
      "\tspeed: 0.0441s/iter; left time: 28520.7407s\n",
      "5098it [03:45, 20.36it/s]\titers: 5100, epoch: 7 | loss: 0.2091964\n",
      "\tspeed: 0.0484s/iter; left time: 31299.9425s\n",
      "5197it [03:49, 24.94it/s]\titers: 5200, epoch: 7 | loss: 0.1738313\n",
      "\tspeed: 0.0430s/iter; left time: 27811.2735s\n",
      "5299it [03:53, 23.30it/s]\titers: 5300, epoch: 7 | loss: 0.2107864\n",
      "\tspeed: 0.0413s/iter; left time: 26716.1089s\n",
      "5398it [03:57, 23.40it/s]\titers: 5400, epoch: 7 | loss: 0.1662270\n",
      "\tspeed: 0.0411s/iter; left time: 26571.0065s\n",
      "5497it [04:01, 23.71it/s]\titers: 5500, epoch: 7 | loss: 0.1820056\n",
      "\tspeed: 0.0429s/iter; left time: 27714.5737s\n",
      "5599it [04:06, 22.79it/s]\titers: 5600, epoch: 7 | loss: 0.3769056\n",
      "\tspeed: 0.0441s/iter; left time: 28483.4261s\n",
      "5698it [04:10, 18.83it/s]\titers: 5700, epoch: 7 | loss: 0.2021551\n",
      "\tspeed: 0.0449s/iter; left time: 28985.6815s\n",
      "5799it [04:16, 17.26it/s]\titers: 5800, epoch: 7 | loss: 0.2627917\n",
      "\tspeed: 0.0550s/iter; left time: 35551.0931s\n",
      "5897it [04:21, 21.17it/s]\titers: 5900, epoch: 7 | loss: 0.3476965\n",
      "\tspeed: 0.0555s/iter; left time: 35847.3798s\n",
      "5998it [04:25, 25.43it/s]\titers: 6000, epoch: 7 | loss: 0.0932383\n",
      "\tspeed: 0.0409s/iter; left time: 26420.8587s\n",
      "6097it [04:29, 25.25it/s]\titers: 6100, epoch: 7 | loss: 0.4212391\n",
      "\tspeed: 0.0407s/iter; left time: 26279.3452s\n",
      "6199it [04:34, 23.01it/s]\titers: 6200, epoch: 7 | loss: 0.4929882\n",
      "\tspeed: 0.0430s/iter; left time: 27771.0477s\n",
      "6298it [04:38, 25.46it/s]\titers: 6300, epoch: 7 | loss: 0.7664613\n",
      "\tspeed: 0.0421s/iter; left time: 27171.4726s\n",
      "6397it [04:42, 20.37it/s]\titers: 6400, epoch: 7 | loss: 0.4065951\n",
      "\tspeed: 0.0450s/iter; left time: 29026.9869s\n",
      "6497it [04:47, 27.63it/s]\titers: 6500, epoch: 7 | loss: 0.5762184\n",
      "\tspeed: 0.0453s/iter; left time: 29240.5009s\n",
      "6599it [04:51, 27.42it/s]\titers: 6600, epoch: 7 | loss: 0.4624008\n",
      "\tspeed: 0.0377s/iter; left time: 24311.1484s\n",
      "6699it [04:56, 17.32it/s]\titers: 6700, epoch: 7 | loss: 0.3262244\n",
      "\tspeed: 0.0475s/iter; left time: 30620.0052s\n",
      "6798it [05:00, 23.37it/s]\titers: 6800, epoch: 7 | loss: 0.0749407\n",
      "\tspeed: 0.0412s/iter; left time: 26601.9697s\n",
      "6897it [05:04, 25.08it/s]\titers: 6900, epoch: 7 | loss: 0.8002842\n",
      "\tspeed: 0.0424s/iter; left time: 27345.5240s\n",
      "6999it [05:08, 24.23it/s]\titers: 7000, epoch: 7 | loss: 0.0972029\n",
      "\tspeed: 0.0415s/iter; left time: 26753.3256s\n",
      "7098it [05:12, 25.15it/s]\titers: 7100, epoch: 7 | loss: 0.1567652\n",
      "\tspeed: 0.0423s/iter; left time: 27249.2476s\n",
      "7197it [05:16, 25.23it/s]\titers: 7200, epoch: 7 | loss: 1.1104420\n",
      "\tspeed: 0.0414s/iter; left time: 26660.0888s\n",
      "7299it [05:21, 21.67it/s]\titers: 7300, epoch: 7 | loss: 0.4224286\n",
      "\tspeed: 0.0424s/iter; left time: 27348.6078s\n",
      "7397it [05:25, 20.12it/s]\titers: 7400, epoch: 7 | loss: 0.2227494\n",
      "\tspeed: 0.0458s/iter; left time: 29540.7770s\n",
      "7497it [05:30, 24.52it/s]\titers: 7500, epoch: 7 | loss: 0.5746579\n",
      "\tspeed: 0.0466s/iter; left time: 30022.4966s\n",
      "7599it [05:34, 25.02it/s]\titers: 7600, epoch: 7 | loss: 0.0980566\n",
      "\tspeed: 0.0399s/iter; left time: 25692.5587s\n",
      "7698it [05:38, 24.24it/s]\titers: 7700, epoch: 7 | loss: 0.3678572\n",
      "\tspeed: 0.0410s/iter; left time: 26438.8066s\n",
      "7797it [05:42, 23.27it/s]\titers: 7800, epoch: 7 | loss: 0.1180477\n",
      "\tspeed: 0.0433s/iter; left time: 27890.2405s\n",
      "7899it [05:47, 21.29it/s]\titers: 7900, epoch: 7 | loss: 0.3764383\n",
      "\tspeed: 0.0434s/iter; left time: 27939.4385s\n",
      "7998it [05:51, 22.41it/s]\titers: 8000, epoch: 7 | loss: 0.2359436\n",
      "\tspeed: 0.0431s/iter; left time: 27732.9019s\n",
      "8099it [05:56, 16.75it/s]\titers: 8100, epoch: 7 | loss: 0.2247208\n",
      "\tspeed: 0.0530s/iter; left time: 34117.6324s\n",
      "8198it [06:02, 17.31it/s]\titers: 8200, epoch: 7 | loss: 0.1762336\n",
      "\tspeed: 0.0568s/iter; left time: 36554.0097s\n",
      "8299it [06:06, 21.82it/s]\titers: 8300, epoch: 7 | loss: 0.1332155\n",
      "\tspeed: 0.0444s/iter; left time: 28545.5586s\n",
      "8398it [06:11, 22.15it/s]\titers: 8400, epoch: 7 | loss: 0.2984656\n",
      "\tspeed: 0.0420s/iter; left time: 27049.3938s\n",
      "8497it [06:15, 24.22it/s]\titers: 8500, epoch: 7 | loss: 0.1494697\n",
      "\tspeed: 0.0413s/iter; left time: 26575.0341s\n",
      "8599it [06:19, 22.31it/s]\titers: 8600, epoch: 7 | loss: 0.1985261\n",
      "\tspeed: 0.0430s/iter; left time: 27686.5812s\n",
      "8698it [06:23, 24.46it/s]\titers: 8700, epoch: 7 | loss: 0.3714769\n",
      "\tspeed: 0.0434s/iter; left time: 27904.7513s\n",
      "8799it [06:28, 18.45it/s]\titers: 8800, epoch: 7 | loss: 0.3761960\n",
      "\tspeed: 0.0474s/iter; left time: 30481.4414s\n",
      "8897it [06:32, 26.48it/s]\titers: 8900, epoch: 7 | loss: 0.1884747\n",
      "\tspeed: 0.0372s/iter; left time: 23943.2586s\n",
      "8997it [06:37, 22.60it/s]\titers: 9000, epoch: 7 | loss: 0.3542597\n",
      "\tspeed: 0.0502s/iter; left time: 32263.1764s\n",
      "9099it [06:41, 22.33it/s]\titers: 9100, epoch: 7 | loss: 0.1789340\n",
      "\tspeed: 0.0433s/iter; left time: 27848.2238s\n",
      "9198it [06:45, 24.08it/s]\titers: 9200, epoch: 7 | loss: 0.1939666\n",
      "\tspeed: 0.0421s/iter; left time: 27073.9334s\n",
      "9297it [06:50, 24.38it/s]\titers: 9300, epoch: 7 | loss: 0.2708960\n",
      "\tspeed: 0.0429s/iter; left time: 27556.0169s\n",
      "9399it [06:54, 25.23it/s]\titers: 9400, epoch: 7 | loss: 0.1739665\n",
      "\tspeed: 0.0396s/iter; left time: 25456.2986s\n",
      "9498it [06:58, 24.32it/s]\titers: 9500, epoch: 7 | loss: 0.2477606\n",
      "\tspeed: 0.0395s/iter; left time: 25378.1284s\n",
      "9597it [07:02, 21.02it/s]\titers: 9600, epoch: 7 | loss: 0.5268415\n",
      "\tspeed: 0.0440s/iter; left time: 28274.2719s\n",
      "9699it [07:07, 21.39it/s]\titers: 9700, epoch: 7 | loss: 0.1729533\n",
      "\tspeed: 0.0464s/iter; left time: 29786.4755s\n",
      "9796it [07:11, 24.01it/s]\titers: 9800, epoch: 7 | loss: 0.5499197\n",
      "\tspeed: 0.0440s/iter; left time: 28262.1780s\n",
      "9897it [07:15, 24.60it/s]\titers: 9900, epoch: 7 | loss: 0.8000079\n",
      "\tspeed: 0.0401s/iter; left time: 25770.5548s\n",
      "9999it [07:19, 24.18it/s]\titers: 10000, epoch: 7 | loss: 0.2899543\n",
      "\tspeed: 0.0405s/iter; left time: 26020.9181s\n",
      "10098it [07:23, 23.58it/s]\titers: 10100, epoch: 7 | loss: 0.2432822\n",
      "\tspeed: 0.0438s/iter; left time: 28111.4545s\n",
      "10197it [07:28, 24.17it/s]\titers: 10200, epoch: 7 | loss: 0.3450607\n",
      "\tspeed: 0.0425s/iter; left time: 27241.4031s\n",
      "10299it [07:32, 22.99it/s]\titers: 10300, epoch: 7 | loss: 1.0253131\n",
      "\tspeed: 0.0432s/iter; left time: 27710.2423s\n",
      "10399it [07:37, 18.03it/s]\titers: 10400, epoch: 7 | loss: 0.2905190\n",
      "\tspeed: 0.0503s/iter; left time: 32275.6056s\n",
      "10499it [07:43, 17.20it/s]\titers: 10500, epoch: 7 | loss: 0.2694618\n",
      "\tspeed: 0.0574s/iter; left time: 36811.0990s\n",
      "10597it [07:47, 23.23it/s]\titers: 10600, epoch: 7 | loss: 0.2316165\n",
      "\tspeed: 0.0459s/iter; left time: 29406.2228s\n",
      "10699it [07:52, 23.34it/s]\titers: 10700, epoch: 7 | loss: 0.2141968\n",
      "\tspeed: 0.0420s/iter; left time: 26905.3324s\n",
      "10798it [07:56, 25.64it/s]\titers: 10800, epoch: 7 | loss: 0.3522015\n",
      "\tspeed: 0.0420s/iter; left time: 26956.6428s\n",
      "10898it [08:00, 25.37it/s]\titers: 10900, epoch: 7 | loss: 0.3374667\n",
      "\tspeed: 0.0420s/iter; left time: 26927.8267s\n",
      "10997it [08:04, 22.70it/s]\titers: 11000, epoch: 7 | loss: 0.1943067\n",
      "\tspeed: 0.0436s/iter; left time: 27974.1617s\n",
      "11096it [08:09, 25.96it/s]\titers: 11100, epoch: 7 | loss: 0.3565352\n",
      "\tspeed: 0.0421s/iter; left time: 26957.2257s\n",
      "11199it [08:14, 17.90it/s]\titers: 11200, epoch: 7 | loss: 0.4984118\n",
      "\tspeed: 0.0524s/iter; left time: 33584.7486s\n",
      "11297it [08:19, 24.20it/s]\titers: 11300, epoch: 7 | loss: 0.2385790\n",
      "\tspeed: 0.0521s/iter; left time: 33368.0888s\n",
      "11399it [08:23, 25.02it/s]\titers: 11400, epoch: 7 | loss: 0.4285795\n",
      "\tspeed: 0.0424s/iter; left time: 27127.6569s\n",
      "11498it [08:27, 24.75it/s]\titers: 11500, epoch: 7 | loss: 0.1883947\n",
      "\tspeed: 0.0418s/iter; left time: 26771.5861s\n",
      "11598it [08:32, 24.25it/s]\titers: 11600, epoch: 7 | loss: 0.1820312\n",
      "\tspeed: 0.0414s/iter; left time: 26495.5798s\n",
      "11697it [08:36, 25.02it/s]\titers: 11700, epoch: 7 | loss: 0.3442618\n",
      "\tspeed: 0.0404s/iter; left time: 25843.6224s\n",
      "11799it [08:40, 25.14it/s]\titers: 11800, epoch: 7 | loss: 0.1274621\n",
      "\tspeed: 0.0405s/iter; left time: 25912.2431s\n",
      "11898it [08:44, 23.73it/s]\titers: 11900, epoch: 7 | loss: 0.6483110\n",
      "\tspeed: 0.0426s/iter; left time: 27249.8162s\n",
      "11997it [08:48, 22.76it/s]\titers: 12000, epoch: 7 | loss: 0.3093668\n",
      "\tspeed: 0.0453s/iter; left time: 28965.7086s\n",
      "12098it [08:53, 21.11it/s]\titers: 12100, epoch: 7 | loss: 0.3244457\n",
      "\tspeed: 0.0480s/iter; left time: 30735.9067s\n",
      "12197it [08:58, 22.39it/s]\titers: 12200, epoch: 7 | loss: 0.1916038\n",
      "\tspeed: 0.0461s/iter; left time: 29503.5194s\n",
      "12298it [09:02, 19.44it/s]\titers: 12300, epoch: 7 | loss: 0.4360396\n",
      "\tspeed: 0.0451s/iter; left time: 28844.4867s\n",
      "12397it [09:07, 21.59it/s]\titers: 12400, epoch: 7 | loss: 0.3630174\n",
      "\tspeed: 0.0450s/iter; left time: 28783.1407s\n",
      "12499it [09:11, 25.35it/s]\titers: 12500, epoch: 7 | loss: 0.2466213\n",
      "\tspeed: 0.0418s/iter; left time: 26729.0213s\n",
      "12598it [09:15, 25.31it/s]\titers: 12600, epoch: 7 | loss: 0.6397215\n",
      "\tspeed: 0.0416s/iter; left time: 26613.2481s\n",
      "12699it [09:20, 17.33it/s]\titers: 12700, epoch: 7 | loss: 0.3691167\n",
      "\tspeed: 0.0482s/iter; left time: 30787.5889s\n",
      "12798it [09:26, 17.00it/s]\titers: 12800, epoch: 7 | loss: 0.5446955\n",
      "\tspeed: 0.0574s/iter; left time: 36700.8047s\n",
      "12897it [09:30, 24.68it/s]\titers: 12900, epoch: 7 | loss: 0.2748612\n",
      "\tspeed: 0.0472s/iter; left time: 30164.1152s\n",
      "12999it [09:35, 24.25it/s]\titers: 13000, epoch: 7 | loss: 0.3710177\n",
      "\tspeed: 0.0411s/iter; left time: 26274.4712s\n",
      "13098it [09:39, 23.78it/s]\titers: 13100, epoch: 7 | loss: 0.4076060\n",
      "\tspeed: 0.0417s/iter; left time: 26660.2164s\n",
      "13199it [09:43, 18.12it/s]\titers: 13200, epoch: 7 | loss: 0.1781192\n",
      "\tspeed: 0.0460s/iter; left time: 29404.0677s\n",
      "13299it [09:48, 23.67it/s]\titers: 13300, epoch: 7 | loss: 0.7656618\n",
      "\tspeed: 0.0463s/iter; left time: 29580.0738s\n",
      "13398it [09:53, 17.53it/s]\titers: 13400, epoch: 7 | loss: 0.3765477\n",
      "\tspeed: 0.0506s/iter; left time: 32315.3690s\n",
      "13498it [09:59, 17.45it/s]\titers: 13500, epoch: 7 | loss: 0.4614994\n",
      "\tspeed: 0.0577s/iter; left time: 36805.5756s\n",
      "13599it [10:03, 22.26it/s]\titers: 13600, epoch: 7 | loss: 0.8298718\n",
      "\tspeed: 0.0455s/iter; left time: 29030.0405s\n",
      "13698it [10:08, 23.23it/s]\titers: 13700, epoch: 7 | loss: 0.4083237\n",
      "\tspeed: 0.0417s/iter; left time: 26610.4679s\n",
      "13797it [10:12, 23.81it/s]\titers: 13800, epoch: 7 | loss: 0.4874321\n",
      "\tspeed: 0.0406s/iter; left time: 25893.4449s\n",
      "13899it [10:16, 23.64it/s]\titers: 13900, epoch: 7 | loss: 0.2220180\n",
      "\tspeed: 0.0405s/iter; left time: 25830.9836s\n",
      "13998it [10:20, 25.05it/s]\titers: 14000, epoch: 7 | loss: 0.1326617\n",
      "\tspeed: 0.0411s/iter; left time: 26201.9697s\n",
      "14097it [10:24, 21.81it/s]\titers: 14100, epoch: 7 | loss: 0.1337051\n",
      "\tspeed: 0.0441s/iter; left time: 28148.8125s\n",
      "14199it [10:29, 21.36it/s]\titers: 14200, epoch: 7 | loss: 0.2059281\n",
      "\tspeed: 0.0464s/iter; left time: 29598.6640s\n",
      "14297it [10:34, 20.51it/s]\titers: 14300, epoch: 7 | loss: 0.3434809\n",
      "\tspeed: 0.0490s/iter; left time: 31242.1181s\n",
      "14399it [10:38, 22.93it/s]\titers: 14400, epoch: 7 | loss: 0.1509789\n",
      "\tspeed: 0.0429s/iter; left time: 27355.6899s\n",
      "14498it [10:42, 23.85it/s]\titers: 14500, epoch: 7 | loss: 0.2624492\n",
      "\tspeed: 0.0417s/iter; left time: 26554.6229s\n",
      "14597it [10:46, 24.31it/s]\titers: 14600, epoch: 7 | loss: 0.2205295\n",
      "\tspeed: 0.0415s/iter; left time: 26441.0106s\n",
      "14699it [10:51, 22.57it/s]\titers: 14700, epoch: 7 | loss: 0.6361473\n",
      "\tspeed: 0.0435s/iter; left time: 27699.7214s\n",
      "14798it [10:55, 22.94it/s]\titers: 14800, epoch: 7 | loss: 0.2303627\n",
      "\tspeed: 0.0434s/iter; left time: 27670.3720s\n",
      "14816it [10:56, 22.57it/s]\n",
      "Epoch: 7 cost time: 656.3516170978546\n",
      "3204it [01:09, 46.30it/s]\n",
      "3192it [01:09, 45.65it/s]\n",
      "Epoch: 7 | Train Loss: 0.3381199 Vali Loss: 0.4597676 Test Loss: 0.6031608 MAE Loss: 0.4857795\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "loading model...\n",
      "3192it [01:17, 41.35it/s]\n",
      "mse:0.5913868171996192, mae:0.48582875262712477\n",
      "train_losses [0.49556824458726795, 0.38566614542791083, 0.37090074034034604, 0.3587150347806799, 0.3519022889117475, 0.34376297366466435]\n",
      "val_losses [0.48044138019451044, 0.47190154611613233, 0.4646253559352381, 0.4554108617624987, 0.457420284647062, 0.45725677044278523]\n",
      "Total time: 95.61382190783819 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=50\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main_no_distributed_data_parallel.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA with run_main_copy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 16323\n",
      "val 19227\n",
      "test 19155\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:07<00:00,  3.66s/it]\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 17:57:04,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 17:57:05,883] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 17:57:05,883] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 17:57:05,883] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 17:57:06,889] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 17:57:06,889] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 17:57:18,035] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 17:57:18,037] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 17:57:18,037] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 17:57:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 17:57:18,039] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 17:57:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 17:57:18,040] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 17:57:18,040] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 17:57:18,040] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 17:57:18,040] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 17:57:18,409] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 17:57:18,410] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.63 GB         CA 12.63 GB         Max_CA 13 GB \n",
      "[2024-05-20 17:57:18,410] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 160.72 GB, percent = 21.3%\n",
      "[2024-05-20 17:57:18,575] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 17:57:18,576] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.7 GB         CA 12.77 GB         Max_CA 13 GB \n",
      "[2024-05-20 17:57:18,577] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 160.72 GB, percent = 21.3%\n",
      "[2024-05-20 17:57:18,577] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 17:57:18,727] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 17:57:18,728] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.56 GB         CA 12.77 GB         Max_CA 13 GB \n",
      "[2024-05-20 17:57:18,728] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 160.86 GB, percent = 21.3%\n",
      "[2024-05-20 17:57:18,729] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 17:57:18,729] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 17:57:18,729] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 17:57:18,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 17:57:18,731] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faa555d44d0>\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32\n",
      "[2024-05-20 17:57:18,732] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 17:57:18,733] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 17:57:18,734] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 17:57:18,734] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 17:57:18,734] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 17:57:18,734] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 17:57:18,734] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 32, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "2720it [15:45,  2.88it/s]\n",
      "Epoch: 1 cost time: 945.9990694522858\n",
      "3204it [08:42,  6.14it/s]\n",
      "3192it [08:42,  6.11it/s]\n",
      "Epoch: 1 | Train Loss: 1.1551334 Vali Loss: 1.0831153 Test Loss: 1.3673669 MAE Loss: 0.8725104\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "2720it [15:45,  2.88it/s]\n",
      "Epoch: 2 cost time: 945.1545023918152\n",
      "3204it [08:43,  6.12it/s]\n",
      "3192it [08:42,  6.11it/s]\n",
      "Epoch: 2 | Train Loss: 0.9668123 Vali Loss: 0.6507602 Test Loss: 0.8232902 MAE Loss: 0.6437873\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "2720it [15:43,  2.88it/s]\n",
      "Epoch: 3 cost time: 943.7322571277618\n",
      "3204it [08:43,  6.12it/s]\n",
      "3192it [08:41,  6.12it/s]\n",
      "Epoch: 3 | Train Loss: 0.7244979 Vali Loss: 0.5962926 Test Loss: 0.7502857 MAE Loss: 0.5964253\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "2720it [15:46,  2.88it/s]\n",
      "Epoch: 4 cost time: 946.0879058837891\n",
      "3204it [08:43,  6.12it/s]\n",
      "3192it [08:41,  6.12it/s]\n",
      "Epoch: 4 | Train Loss: 0.6519467 Vali Loss: 0.5690889 Test Loss: 0.7233649 MAE Loss: 0.5895799\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "2720it [15:43,  2.88it/s]\n",
      "Epoch: 5 cost time: 943.5486145019531\n",
      "3204it [08:43,  6.13it/s]\n",
      "3192it [08:43,  6.10it/s]\n",
      "Epoch: 5 | Train Loss: 0.6130995 Vali Loss: 0.5707440 Test Loss: 0.7361292 MAE Loss: 0.5991345\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "2720it [15:42,  2.89it/s]\n",
      "Epoch: 6 cost time: 942.7225930690765\n",
      "3204it [08:43,  6.13it/s]\n",
      "3192it [08:43,  6.10it/s]\n",
      "Epoch: 6 | Train Loss: 0.5927010 Vali Loss: 0.5685683 Test Loss: 0.7342488 MAE Loss: 0.5922835\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "2720it [15:48,  2.87it/s]\n",
      "Epoch: 7 cost time: 948.8496642112732\n",
      "3204it [08:41,  6.14it/s]\n",
      "3192it [08:40,  6.14it/s]\n",
      "Epoch: 7 | Train Loss: 0.5799806 Vali Loss: 0.5689090 Test Loss: 0.7349485 MAE Loss: 0.5932347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "2720it [15:43,  2.88it/s]\n",
      "Epoch: 8 cost time: 943.150096654892\n",
      "3204it [08:42,  6.13it/s]\n",
      "3192it [08:39,  6.14it/s]\n",
      "Epoch: 8 | Train Loss: 0.5733680 Vali Loss: 0.5695885 Test Loss: 0.7356676 MAE Loss: 0.5918982\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "2720it [15:42,  2.89it/s]\n",
      "Epoch: 9 cost time: 942.0435664653778\n",
      "3204it [08:39,  6.17it/s]\n",
      "3192it [08:41,  6.12it/s]\n",
      "Epoch: 9 | Train Loss: 0.5703101 Vali Loss: 0.5697607 Test Loss: 0.7365103 MAE Loss: 0.5917455\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 308.7705995241801 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=16\n",
    "d_ff=64\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --percent 20 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:06<00:00,  3.42s/it]\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-20 23:05:41,962] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-20 23:05:42,921] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-20 23:05:42,921] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-20 23:05:42,921] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-20 23:05:43,879] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-05-20 23:05:43,880] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-20 23:05:57,203] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-20 23:05:57,205] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-20 23:05:57,205] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-20 23:05:57,207] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-20 23:05:57,208] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-20 23:05:57,208] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-20 23:05:57,208] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-20 23:05:57,208] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-20 23:05:57,208] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-20 23:05:57,208] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-20 23:05:57,579] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-20 23:05:57,580] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.63 GB         CA 12.63 GB         Max_CA 13 GB \n",
      "[2024-05-20 23:05:57,580] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 158.89 GB, percent = 21.1%\n",
      "[2024-05-20 23:05:57,748] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-20 23:05:57,749] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.7 GB         CA 12.77 GB         Max_CA 13 GB \n",
      "[2024-05-20 23:05:57,749] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.0 GB, percent = 21.1%\n",
      "[2024-05-20 23:05:57,749] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-20 23:05:57,903] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-20 23:05:57,904] [INFO] [utils.py:801:see_memory_usage] MA 12.56 GB         Max_MA 12.56 GB         CA 12.77 GB         Max_CA 13 GB \n",
      "[2024-05-20 23:05:57,904] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.0 GB, percent = 21.1%\n",
      "[2024-05-20 23:05:57,904] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-20 23:05:57,905] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-20 23:05:57,905] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-20 23:05:57,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-20 23:05:57,906] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbfbd454690>\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-20 23:05:57,907] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 8\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-20 23:05:57,908] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   train_batch_size ............. 48\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  6\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-20 23:05:57,909] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 8, \n",
      "    \"train_batch_size\": 48, \n",
      "    \"train_micro_batch_size_per_gpu\": 6, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=6\n",
    "d_model=16\n",
    "d_ff=64\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
