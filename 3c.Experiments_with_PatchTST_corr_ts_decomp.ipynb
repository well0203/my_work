{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No Patching](#3-no-patching)\n",
    "- [4. Time series decomposition](#4-ts-decomposition)\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_lens = [512, 512, 336, 168, 168]\n",
    "\n",
    "model = \"PatchTST\"\n",
    "loss = \"MSE\"\n",
    "itr=1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2566070\n",
      "\tspeed: 0.0697s/iter; left time: 1554.3492s\n",
      "\titers: 200, epoch: 1 | loss: 0.2419528\n",
      "\tspeed: 0.0297s/iter; left time: 660.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.2636380 Vali Loss: 0.2222575 Test Loss: 0.2204070\n",
      "Validation loss decreased (inf --> 0.222257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1490381\n",
      "\tspeed: 0.0510s/iter; left time: 1125.5861s\n",
      "\titers: 200, epoch: 2 | loss: 0.1197937\n",
      "\tspeed: 0.0264s/iter; left time: 580.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.1535841 Vali Loss: 0.1151092 Test Loss: 0.1171536\n",
      "Validation loss decreased (0.222257 --> 0.115109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1010839\n",
      "\tspeed: 0.0513s/iter; left time: 1121.7780s\n",
      "\titers: 200, epoch: 3 | loss: 0.0979355\n",
      "\tspeed: 0.0264s/iter; left time: 574.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.1034884 Vali Loss: 0.1062425 Test Loss: 0.1076204\n",
      "Validation loss decreased (0.115109 --> 0.106242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974420\n",
      "\tspeed: 0.0515s/iter; left time: 1113.9680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977694\n",
      "\tspeed: 0.0264s/iter; left time: 567.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0933482 Vali Loss: 0.0992072 Test Loss: 0.1010505\n",
      "Validation loss decreased (0.106242 --> 0.099207).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909457\n",
      "\tspeed: 0.0512s/iter; left time: 1095.1722s\n",
      "\titers: 200, epoch: 5 | loss: 0.0860357\n",
      "\tspeed: 0.0263s/iter; left time: 560.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0887532 Vali Loss: 0.0971549 Test Loss: 0.0991021\n",
      "Validation loss decreased (0.099207 --> 0.097155).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950104\n",
      "\tspeed: 0.0511s/iter; left time: 1082.2264s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841039\n",
      "\tspeed: 0.0263s/iter; left time: 553.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0859246 Vali Loss: 0.0970220 Test Loss: 0.0979300\n",
      "Validation loss decreased (0.097155 --> 0.097022).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830651\n",
      "\tspeed: 0.0514s/iter; left time: 1077.2520s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861730\n",
      "\tspeed: 0.0266s/iter; left time: 554.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0841975 Vali Loss: 0.0949431 Test Loss: 0.0963822\n",
      "Validation loss decreased (0.097022 --> 0.094943).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834699\n",
      "\tspeed: 0.0515s/iter; left time: 1067.3835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0826666\n",
      "\tspeed: 0.0262s/iter; left time: 541.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0832470 Vali Loss: 0.0940332 Test Loss: 0.0951022\n",
      "Validation loss decreased (0.094943 --> 0.094033).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867406\n",
      "\tspeed: 0.0513s/iter; left time: 1051.3144s\n",
      "\titers: 200, epoch: 9 | loss: 0.0859180\n",
      "\tspeed: 0.0265s/iter; left time: 541.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0822038 Vali Loss: 0.0939286 Test Loss: 0.0947163\n",
      "Validation loss decreased (0.094033 --> 0.093929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839390\n",
      "\tspeed: 0.0520s/iter; left time: 1055.6915s\n",
      "\titers: 200, epoch: 10 | loss: 0.0786523\n",
      "\tspeed: 0.0266s/iter; left time: 536.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0808735 Vali Loss: 0.0932474 Test Loss: 0.0947599\n",
      "Validation loss decreased (0.093929 --> 0.093247).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754465\n",
      "\tspeed: 0.0518s/iter; left time: 1038.5746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798902\n",
      "\tspeed: 0.0265s/iter; left time: 528.4970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0805028 Vali Loss: 0.0930160 Test Loss: 0.0942361\n",
      "Validation loss decreased (0.093247 --> 0.093016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777061\n",
      "\tspeed: 0.0517s/iter; left time: 1025.7292s\n",
      "\titers: 200, epoch: 12 | loss: 0.0808789\n",
      "\tspeed: 0.0264s/iter; left time: 520.3353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0801001 Vali Loss: 0.0921757 Test Loss: 0.0932652\n",
      "Validation loss decreased (0.093016 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751510\n",
      "\tspeed: 0.0514s/iter; left time: 1008.7788s\n",
      "\titers: 200, epoch: 13 | loss: 0.0770847\n",
      "\tspeed: 0.0264s/iter; left time: 514.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0791738 Vali Loss: 0.0924514 Test Loss: 0.0932204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0782727\n",
      "\tspeed: 0.0512s/iter; left time: 992.9978s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786983\n",
      "\tspeed: 0.0264s/iter; left time: 509.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0787759 Vali Loss: 0.0920219 Test Loss: 0.0935162\n",
      "Validation loss decreased (0.092176 --> 0.092022).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0777310\n",
      "\tspeed: 0.0522s/iter; left time: 999.8995s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735414\n",
      "\tspeed: 0.0266s/iter; left time: 506.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0786300 Vali Loss: 0.0917478 Test Loss: 0.0926336\n",
      "Validation loss decreased (0.092022 --> 0.091748).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785231\n",
      "\tspeed: 0.0512s/iter; left time: 970.0143s\n",
      "\titers: 200, epoch: 16 | loss: 0.0768834\n",
      "\tspeed: 0.0265s/iter; left time: 499.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0784725 Vali Loss: 0.0918264 Test Loss: 0.0926172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798664\n",
      "\tspeed: 0.0514s/iter; left time: 962.0186s\n",
      "\titers: 200, epoch: 17 | loss: 0.0797044\n",
      "\tspeed: 0.0264s/iter; left time: 491.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0783037 Vali Loss: 0.0910420 Test Loss: 0.0925358\n",
      "Validation loss decreased (0.091748 --> 0.091042).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781114\n",
      "\tspeed: 0.0513s/iter; left time: 948.8579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0855012\n",
      "\tspeed: 0.0266s/iter; left time: 489.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0779318 Vali Loss: 0.0907866 Test Loss: 0.0921505\n",
      "Validation loss decreased (0.091042 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0735422\n",
      "\tspeed: 0.0517s/iter; left time: 944.8442s\n",
      "\titers: 200, epoch: 19 | loss: 0.0740805\n",
      "\tspeed: 0.0264s/iter; left time: 479.6136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0774609 Vali Loss: 0.0919343 Test Loss: 0.0928579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746833\n",
      "\tspeed: 0.0504s/iter; left time: 908.8097s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807188\n",
      "\tspeed: 0.0267s/iter; left time: 478.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0773912 Vali Loss: 0.0916482 Test Loss: 0.0923388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0721470\n",
      "\tspeed: 0.0508s/iter; left time: 904.9998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779014\n",
      "\tspeed: 0.0264s/iter; left time: 466.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0773700 Vali Loss: 0.0906744 Test Loss: 0.0923040\n",
      "Validation loss decreased (0.090787 --> 0.090674).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0702513\n",
      "\tspeed: 0.0510s/iter; left time: 897.7170s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733673\n",
      "\tspeed: 0.0269s/iter; left time: 470.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0772820 Vali Loss: 0.0907303 Test Loss: 0.0918452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767162\n",
      "\tspeed: 0.0518s/iter; left time: 900.4560s\n",
      "\titers: 200, epoch: 23 | loss: 0.0720851\n",
      "\tspeed: 0.0265s/iter; left time: 458.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0770278 Vali Loss: 0.0907926 Test Loss: 0.0918527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754888\n",
      "\tspeed: 0.0509s/iter; left time: 873.5967s\n",
      "\titers: 200, epoch: 24 | loss: 0.0748333\n",
      "\tspeed: 0.0264s/iter; left time: 449.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0768529 Vali Loss: 0.0908272 Test Loss: 0.0918088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0754161\n",
      "\tspeed: 0.0504s/iter; left time: 853.8475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0849064\n",
      "\tspeed: 0.0267s/iter; left time: 449.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0768403 Vali Loss: 0.0907090 Test Loss: 0.0916022\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0744077\n",
      "\tspeed: 0.0511s/iter; left time: 854.0449s\n",
      "\titers: 200, epoch: 26 | loss: 0.0762815\n",
      "\tspeed: 0.0264s/iter; left time: 437.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0767571 Vali Loss: 0.0906516 Test Loss: 0.0917031\n",
      "Validation loss decreased (0.090674 --> 0.090652).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0812616\n",
      "\tspeed: 0.0513s/iter; left time: 845.1961s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799414\n",
      "\tspeed: 0.0263s/iter; left time: 430.9567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0765723 Vali Loss: 0.0903748 Test Loss: 0.0915898\n",
      "Validation loss decreased (0.090652 --> 0.090375).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0726214\n",
      "\tspeed: 0.0510s/iter; left time: 828.6620s\n",
      "\titers: 200, epoch: 28 | loss: 0.0789795\n",
      "\tspeed: 0.0264s/iter; left time: 426.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0765280 Vali Loss: 0.0905175 Test Loss: 0.0916367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0772127\n",
      "\tspeed: 0.0507s/iter; left time: 812.8412s\n",
      "\titers: 200, epoch: 29 | loss: 0.0697870\n",
      "\tspeed: 0.0263s/iter; left time: 419.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0765321 Vali Loss: 0.0904983 Test Loss: 0.0915829\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811062\n",
      "\tspeed: 0.0508s/iter; left time: 802.3043s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780678\n",
      "\tspeed: 0.0265s/iter; left time: 416.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0765154 Vali Loss: 0.0902160 Test Loss: 0.0915959\n",
      "Validation loss decreased (0.090375 --> 0.090216).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0766579\n",
      "\tspeed: 0.0522s/iter; left time: 812.7127s\n",
      "\titers: 200, epoch: 31 | loss: 0.0730054\n",
      "\tspeed: 0.0264s/iter; left time: 409.0530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0764262 Vali Loss: 0.0905278 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0711051\n",
      "\tspeed: 0.0509s/iter; left time: 782.1983s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803683\n",
      "\tspeed: 0.0263s/iter; left time: 401.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0763533 Vali Loss: 0.0901207 Test Loss: 0.0914401\n",
      "Validation loss decreased (0.090216 --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0823469\n",
      "\tspeed: 0.0515s/iter; left time: 779.3056s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713614\n",
      "\tspeed: 0.0264s/iter; left time: 396.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0763147 Vali Loss: 0.0905146 Test Loss: 0.0916492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0752804\n",
      "\tspeed: 0.0506s/iter; left time: 755.0867s\n",
      "\titers: 200, epoch: 34 | loss: 0.0791326\n",
      "\tspeed: 0.0265s/iter; left time: 392.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0762617 Vali Loss: 0.0903647 Test Loss: 0.0914449\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0792777\n",
      "\tspeed: 0.0513s/iter; left time: 753.7300s\n",
      "\titers: 200, epoch: 35 | loss: 0.0719633\n",
      "\tspeed: 0.0263s/iter; left time: 382.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0761660 Vali Loss: 0.0903345 Test Loss: 0.0914848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769392\n",
      "\tspeed: 0.0504s/iter; left time: 728.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0812033\n",
      "\tspeed: 0.0263s/iter; left time: 377.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0762252 Vali Loss: 0.0910000 Test Loss: 0.0918637\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0839674\n",
      "\tspeed: 0.0506s/iter; left time: 720.8292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782146\n",
      "\tspeed: 0.0265s/iter; left time: 374.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0761717 Vali Loss: 0.0904660 Test Loss: 0.0915176\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0749981\n",
      "\tspeed: 0.0510s/iter; left time: 714.8634s\n",
      "\titers: 200, epoch: 38 | loss: 0.0715419\n",
      "\tspeed: 0.0263s/iter; left time: 365.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761763 Vali Loss: 0.0906010 Test Loss: 0.0916540\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0792945\n",
      "\tspeed: 0.0514s/iter; left time: 708.8584s\n",
      "\titers: 200, epoch: 39 | loss: 0.0729343\n",
      "\tspeed: 0.0263s/iter; left time: 360.4861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0762594 Vali Loss: 0.0901306 Test Loss: 0.0913918\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0725834\n",
      "\tspeed: 0.0507s/iter; left time: 687.9009s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821638\n",
      "\tspeed: 0.0264s/iter; left time: 355.7920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761080 Vali Loss: 0.0901505 Test Loss: 0.0913605\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0714317\n",
      "\tspeed: 0.0503s/iter; left time: 671.1363s\n",
      "\titers: 200, epoch: 41 | loss: 0.0747623\n",
      "\tspeed: 0.0263s/iter; left time: 348.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0761157 Vali Loss: 0.0900619 Test Loss: 0.0915041\n",
      "Validation loss decreased (0.090121 --> 0.090062).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0739755\n",
      "\tspeed: 0.0511s/iter; left time: 669.7266s\n",
      "\titers: 200, epoch: 42 | loss: 0.0810414\n",
      "\tspeed: 0.0262s/iter; left time: 341.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0761380 Vali Loss: 0.0903147 Test Loss: 0.0914038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0811172\n",
      "\tspeed: 0.0505s/iter; left time: 651.0997s\n",
      "\titers: 200, epoch: 43 | loss: 0.0779029\n",
      "\tspeed: 0.0263s/iter; left time: 336.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0760796 Vali Loss: 0.0902422 Test Loss: 0.0914716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0723317\n",
      "\tspeed: 0.0510s/iter; left time: 645.5269s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762026\n",
      "\tspeed: 0.0263s/iter; left time: 330.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0759945 Vali Loss: 0.0902213 Test Loss: 0.0914703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0768227\n",
      "\tspeed: 0.0506s/iter; left time: 629.5039s\n",
      "\titers: 200, epoch: 45 | loss: 0.0778465\n",
      "\tspeed: 0.0263s/iter; left time: 324.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0760749 Vali Loss: 0.0902847 Test Loss: 0.0914034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757674\n",
      "\tspeed: 0.0508s/iter; left time: 620.4236s\n",
      "\titers: 200, epoch: 46 | loss: 0.0817664\n",
      "\tspeed: 0.0264s/iter; left time: 320.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0760586 Vali Loss: 0.0901711 Test Loss: 0.0912951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0757344\n",
      "\tspeed: 0.0512s/iter; left time: 614.4499s\n",
      "\titers: 200, epoch: 47 | loss: 0.0739751\n",
      "\tspeed: 0.0263s/iter; left time: 312.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0760620 Vali Loss: 0.0903189 Test Loss: 0.0914689\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769868\n",
      "\tspeed: 0.0510s/iter; left time: 600.1422s\n",
      "\titers: 200, epoch: 48 | loss: 0.0761500\n",
      "\tspeed: 0.0264s/iter; left time: 308.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0760214 Vali Loss: 0.0901692 Test Loss: 0.0913794\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0779364\n",
      "\tspeed: 0.0504s/iter; left time: 581.5220s\n",
      "\titers: 200, epoch: 49 | loss: 0.0800145\n",
      "\tspeed: 0.0263s/iter; left time: 301.3702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0760802 Vali Loss: 0.0900943 Test Loss: 0.0913661\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0724418\n",
      "\tspeed: 0.0503s/iter; left time: 570.1542s\n",
      "\titers: 200, epoch: 50 | loss: 0.0738002\n",
      "\tspeed: 0.0263s/iter; left time: 294.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0759310 Vali Loss: 0.0905732 Test Loss: 0.0915211\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0714924\n",
      "\tspeed: 0.0504s/iter; left time: 559.1858s\n",
      "\titers: 200, epoch: 51 | loss: 0.0791853\n",
      "\tspeed: 0.0265s/iter; left time: 291.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0759803 Vali Loss: 0.0902920 Test Loss: 0.0913586\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021748371422290802, rmse:0.1474732905626297, mae:0.0915040671825409, rse:0.5204536318778992\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2623934\n",
      "\tspeed: 0.0283s/iter; left time: 631.1664s\n",
      "\titers: 200, epoch: 1 | loss: 0.2396158\n",
      "\tspeed: 0.0264s/iter; left time: 585.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.2633231 Vali Loss: 0.2145368 Test Loss: 0.2137502\n",
      "Validation loss decreased (inf --> 0.214537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1374790\n",
      "\tspeed: 0.0518s/iter; left time: 1143.5152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093387\n",
      "\tspeed: 0.0264s/iter; left time: 580.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.1501679 Vali Loss: 0.1194519 Test Loss: 0.1199035\n",
      "Validation loss decreased (0.214537 --> 0.119452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0990194\n",
      "\tspeed: 0.0530s/iter; left time: 1157.8753s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039781\n",
      "\tspeed: 0.0264s/iter; left time: 573.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1039293 Vali Loss: 0.1051352 Test Loss: 0.1071176\n",
      "Validation loss decreased (0.119452 --> 0.105135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944413\n",
      "\tspeed: 0.0521s/iter; left time: 1127.6466s\n",
      "\titers: 200, epoch: 4 | loss: 0.0901303\n",
      "\tspeed: 0.0266s/iter; left time: 572.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0936006 Vali Loss: 0.0998318 Test Loss: 0.1013047\n",
      "Validation loss decreased (0.105135 --> 0.099832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0877668\n",
      "\tspeed: 0.0516s/iter; left time: 1103.8633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928216\n",
      "\tspeed: 0.0264s/iter; left time: 562.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0888237 Vali Loss: 0.0964812 Test Loss: 0.0980058\n",
      "Validation loss decreased (0.099832 --> 0.096481).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0847580\n",
      "\tspeed: 0.0515s/iter; left time: 1089.9201s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826628\n",
      "\tspeed: 0.0263s/iter; left time: 554.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0858948 Vali Loss: 0.0959795 Test Loss: 0.0970195\n",
      "Validation loss decreased (0.096481 --> 0.095980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0905109\n",
      "\tspeed: 0.0516s/iter; left time: 1080.8875s\n",
      "\titers: 200, epoch: 7 | loss: 0.0828156\n",
      "\tspeed: 0.0263s/iter; left time: 548.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0842266 Vali Loss: 0.0946363 Test Loss: 0.0962865\n",
      "Validation loss decreased (0.095980 --> 0.094636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775391\n",
      "\tspeed: 0.0517s/iter; left time: 1071.6379s\n",
      "\titers: 200, epoch: 8 | loss: 0.0855141\n",
      "\tspeed: 0.0268s/iter; left time: 552.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0828761 Vali Loss: 0.0938537 Test Loss: 0.0953314\n",
      "Validation loss decreased (0.094636 --> 0.093854).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816690\n",
      "\tspeed: 0.0520s/iter; left time: 1067.0735s\n",
      "\titers: 200, epoch: 9 | loss: 0.0851879\n",
      "\tspeed: 0.0264s/iter; left time: 539.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0829858 Vali Loss: 0.0947143 Test Loss: 0.0958647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0823175\n",
      "\tspeed: 0.0512s/iter; left time: 1039.1988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0796459\n",
      "\tspeed: 0.0263s/iter; left time: 531.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0809271 Vali Loss: 0.0935037 Test Loss: 0.0946443\n",
      "Validation loss decreased (0.093854 --> 0.093504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768127\n",
      "\tspeed: 0.0528s/iter; left time: 1058.8666s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761531\n",
      "\tspeed: 0.0265s/iter; left time: 528.0351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0801934 Vali Loss: 0.0916781 Test Loss: 0.0932157\n",
      "Validation loss decreased (0.093504 --> 0.091678).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837837\n",
      "\tspeed: 0.0515s/iter; left time: 1022.5853s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775089\n",
      "\tspeed: 0.0265s/iter; left time: 522.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0802700 Vali Loss: 0.0934207 Test Loss: 0.0943639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784073\n",
      "\tspeed: 0.0511s/iter; left time: 1003.1424s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782698\n",
      "\tspeed: 0.0264s/iter; left time: 515.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0792549 Vali Loss: 0.0911230 Test Loss: 0.0926930\n",
      "Validation loss decreased (0.091678 --> 0.091123).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0733982\n",
      "\tspeed: 0.0512s/iter; left time: 993.5707s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791362\n",
      "\tspeed: 0.0263s/iter; left time: 506.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0786626 Vali Loss: 0.0918051 Test Loss: 0.0929869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759531\n",
      "\tspeed: 0.0514s/iter; left time: 984.9887s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776807\n",
      "\tspeed: 0.0263s/iter; left time: 501.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0783810 Vali Loss: 0.0908538 Test Loss: 0.0923476\n",
      "Validation loss decreased (0.091123 --> 0.090854).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0793302\n",
      "\tspeed: 0.0515s/iter; left time: 975.4116s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803491\n",
      "\tspeed: 0.0265s/iter; left time: 498.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0782527 Vali Loss: 0.0906397 Test Loss: 0.0923295\n",
      "Validation loss decreased (0.090854 --> 0.090640).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744852\n",
      "\tspeed: 0.0522s/iter; left time: 976.6843s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786489\n",
      "\tspeed: 0.0265s/iter; left time: 492.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0779015 Vali Loss: 0.0903674 Test Loss: 0.0920459\n",
      "Validation loss decreased (0.090640 --> 0.090367).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812337\n",
      "\tspeed: 0.0523s/iter; left time: 966.3005s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783246\n",
      "\tspeed: 0.0267s/iter; left time: 490.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0775950 Vali Loss: 0.0926962 Test Loss: 0.0936254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784258\n",
      "\tspeed: 0.0514s/iter; left time: 938.3536s\n",
      "\titers: 200, epoch: 19 | loss: 0.0762034\n",
      "\tspeed: 0.0263s/iter; left time: 478.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0777468 Vali Loss: 0.0910056 Test Loss: 0.0922556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0757184\n",
      "\tspeed: 0.0521s/iter; left time: 939.6522s\n",
      "\titers: 200, epoch: 20 | loss: 0.0782048\n",
      "\tspeed: 0.0265s/iter; left time: 475.0869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0774940 Vali Loss: 0.0901802 Test Loss: 0.0919014\n",
      "Validation loss decreased (0.090367 --> 0.090180).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752977\n",
      "\tspeed: 0.0520s/iter; left time: 926.6258s\n",
      "\titers: 200, epoch: 21 | loss: 0.0739630\n",
      "\tspeed: 0.0264s/iter; left time: 468.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0772572 Vali Loss: 0.0915566 Test Loss: 0.0928652\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0792587\n",
      "\tspeed: 0.0516s/iter; left time: 907.9606s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784705\n",
      "\tspeed: 0.0264s/iter; left time: 461.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0769730 Vali Loss: 0.0908989 Test Loss: 0.0921991\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772055\n",
      "\tspeed: 0.0514s/iter; left time: 893.6607s\n",
      "\titers: 200, epoch: 23 | loss: 0.0812640\n",
      "\tspeed: 0.0263s/iter; left time: 454.8712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0770093 Vali Loss: 0.0900116 Test Loss: 0.0918345\n",
      "Validation loss decreased (0.090180 --> 0.090012).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0803091\n",
      "\tspeed: 0.0524s/iter; left time: 897.8110s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759364\n",
      "\tspeed: 0.0262s/iter; left time: 447.2752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0770596 Vali Loss: 0.0899609 Test Loss: 0.0916573\n",
      "Validation loss decreased (0.090012 --> 0.089961).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758617\n",
      "\tspeed: 0.0518s/iter; left time: 876.7166s\n",
      "\titers: 200, epoch: 25 | loss: 0.0737996\n",
      "\tspeed: 0.0264s/iter; left time: 443.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0769033 Vali Loss: 0.0899511 Test Loss: 0.0915681\n",
      "Validation loss decreased (0.089961 --> 0.089951).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0765661\n",
      "\tspeed: 0.0519s/iter; left time: 866.3557s\n",
      "\titers: 200, epoch: 26 | loss: 0.0763971\n",
      "\tspeed: 0.0263s/iter; left time: 437.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0765872 Vali Loss: 0.0900413 Test Loss: 0.0916204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0758144\n",
      "\tspeed: 0.0510s/iter; left time: 839.5982s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757976\n",
      "\tspeed: 0.0264s/iter; left time: 432.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0764685 Vali Loss: 0.0906311 Test Loss: 0.0921329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0758253\n",
      "\tspeed: 0.0519s/iter; left time: 843.7484s\n",
      "\titers: 200, epoch: 28 | loss: 0.0753282\n",
      "\tspeed: 0.0263s/iter; left time: 424.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0765909 Vali Loss: 0.0898152 Test Loss: 0.0914769\n",
      "Validation loss decreased (0.089951 --> 0.089815).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0749874\n",
      "\tspeed: 0.0517s/iter; left time: 829.3648s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735045\n",
      "\tspeed: 0.0265s/iter; left time: 422.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0764512 Vali Loss: 0.0897418 Test Loss: 0.0915002\n",
      "Validation loss decreased (0.089815 --> 0.089742).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0812473\n",
      "\tspeed: 0.0523s/iter; left time: 826.7454s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751119\n",
      "\tspeed: 0.0264s/iter; left time: 415.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0764347 Vali Loss: 0.0904919 Test Loss: 0.0919945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0783717\n",
      "\tspeed: 0.0513s/iter; left time: 798.7433s\n",
      "\titers: 200, epoch: 31 | loss: 0.0838023\n",
      "\tspeed: 0.0265s/iter; left time: 410.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0763518 Vali Loss: 0.0900647 Test Loss: 0.0916321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0714996\n",
      "\tspeed: 0.0524s/iter; left time: 805.4191s\n",
      "\titers: 200, epoch: 32 | loss: 0.0752642\n",
      "\tspeed: 0.0265s/iter; left time: 404.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0763182 Vali Loss: 0.0899387 Test Loss: 0.0916039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0770082\n",
      "\tspeed: 0.0509s/iter; left time: 770.3764s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753402\n",
      "\tspeed: 0.0266s/iter; left time: 400.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0896231 Test Loss: 0.0914508\n",
      "Validation loss decreased (0.089742 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0725115\n",
      "\tspeed: 0.0526s/iter; left time: 783.9538s\n",
      "\titers: 200, epoch: 34 | loss: 0.0776233\n",
      "\tspeed: 0.0263s/iter; left time: 389.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0762119 Vali Loss: 0.0895975 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.089623 --> 0.089597).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0771235\n",
      "\tspeed: 0.0517s/iter; left time: 759.8852s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781061\n",
      "\tspeed: 0.0263s/iter; left time: 383.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0761741 Vali Loss: 0.0895915 Test Loss: 0.0913442\n",
      "Validation loss decreased (0.089597 --> 0.089591).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0696032\n",
      "\tspeed: 0.0517s/iter; left time: 748.2079s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770035\n",
      "\tspeed: 0.0263s/iter; left time: 377.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0760867 Vali Loss: 0.0900567 Test Loss: 0.0917049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0778791\n",
      "\tspeed: 0.0509s/iter; left time: 724.6042s\n",
      "\titers: 200, epoch: 37 | loss: 0.0745140\n",
      "\tspeed: 0.0263s/iter; left time: 371.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0762562 Vali Loss: 0.0897121 Test Loss: 0.0913620\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0783371\n",
      "\tspeed: 0.0509s/iter; left time: 713.1096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0818648\n",
      "\tspeed: 0.0263s/iter; left time: 365.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761213 Vali Loss: 0.0900666 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803079\n",
      "\tspeed: 0.0513s/iter; left time: 706.7780s\n",
      "\titers: 200, epoch: 39 | loss: 0.0745575\n",
      "\tspeed: 0.0265s/iter; left time: 363.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0760805 Vali Loss: 0.0901203 Test Loss: 0.0916768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0744408\n",
      "\tspeed: 0.0508s/iter; left time: 689.1131s\n",
      "\titers: 200, epoch: 40 | loss: 0.0698902\n",
      "\tspeed: 0.0263s/iter; left time: 354.3091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0760944 Vali Loss: 0.0897818 Test Loss: 0.0915024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0756303\n",
      "\tspeed: 0.0513s/iter; left time: 683.9743s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757952\n",
      "\tspeed: 0.0263s/iter; left time: 348.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0760046 Vali Loss: 0.0898426 Test Loss: 0.0915377\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0779208\n",
      "\tspeed: 0.0514s/iter; left time: 674.5092s\n",
      "\titers: 200, epoch: 42 | loss: 0.0747404\n",
      "\tspeed: 0.0265s/iter; left time: 345.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0761344 Vali Loss: 0.0901287 Test Loss: 0.0917811\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0771934\n",
      "\tspeed: 0.0514s/iter; left time: 662.9252s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749607\n",
      "\tspeed: 0.0264s/iter; left time: 337.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759900 Vali Loss: 0.0897255 Test Loss: 0.0914727\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0743435\n",
      "\tspeed: 0.0513s/iter; left time: 649.7218s\n",
      "\titers: 200, epoch: 44 | loss: 0.0800619\n",
      "\tspeed: 0.0263s/iter; left time: 330.9807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0760069 Vali Loss: 0.0894995 Test Loss: 0.0912929\n",
      "Validation loss decreased (0.089591 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0732608\n",
      "\tspeed: 0.0516s/iter; left time: 641.8608s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766907\n",
      "\tspeed: 0.0265s/iter; left time: 327.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759964 Vali Loss: 0.0898933 Test Loss: 0.0914188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0741571\n",
      "\tspeed: 0.0509s/iter; left time: 622.2045s\n",
      "\titers: 200, epoch: 46 | loss: 0.0754467\n",
      "\tspeed: 0.0264s/iter; left time: 319.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0760600 Vali Loss: 0.0897355 Test Loss: 0.0913146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0713772\n",
      "\tspeed: 0.0510s/iter; left time: 612.1991s\n",
      "\titers: 200, epoch: 47 | loss: 0.0743333\n",
      "\tspeed: 0.0262s/iter; left time: 312.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758811 Vali Loss: 0.0899609 Test Loss: 0.0915293\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0764152\n",
      "\tspeed: 0.0509s/iter; left time: 599.2296s\n",
      "\titers: 200, epoch: 48 | loss: 0.0770819\n",
      "\tspeed: 0.0263s/iter; left time: 307.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0759072 Vali Loss: 0.0899988 Test Loss: 0.0916863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0743392\n",
      "\tspeed: 0.0508s/iter; left time: 586.3439s\n",
      "\titers: 200, epoch: 49 | loss: 0.0781718\n",
      "\tspeed: 0.0267s/iter; left time: 305.1282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0759080 Vali Loss: 0.0899594 Test Loss: 0.0915774\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756658\n",
      "\tspeed: 0.0511s/iter; left time: 578.9039s\n",
      "\titers: 200, epoch: 50 | loss: 0.0756160\n",
      "\tspeed: 0.0263s/iter; left time: 295.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0759219 Vali Loss: 0.0898047 Test Loss: 0.0914517\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815681\n",
      "\tspeed: 0.0512s/iter; left time: 568.4181s\n",
      "\titers: 200, epoch: 51 | loss: 0.0765514\n",
      "\tspeed: 0.0263s/iter; left time: 289.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0759615 Vali Loss: 0.0896021 Test Loss: 0.0913982\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0764843\n",
      "\tspeed: 0.0511s/iter; left time: 555.8316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0764052\n",
      "\tspeed: 0.0264s/iter; left time: 283.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758922 Vali Loss: 0.0901767 Test Loss: 0.0917404\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0747740\n",
      "\tspeed: 0.0513s/iter; left time: 546.0956s\n",
      "\titers: 200, epoch: 53 | loss: 0.0760180\n",
      "\tspeed: 0.0263s/iter; left time: 277.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758861 Vali Loss: 0.0898443 Test Loss: 0.0914755\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0749051\n",
      "\tspeed: 0.0510s/iter; left time: 532.3610s\n",
      "\titers: 200, epoch: 54 | loss: 0.0723748\n",
      "\tspeed: 0.0263s/iter; left time: 271.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0899249 Test Loss: 0.0915471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021651936694979668, rmse:0.14714597165584564, mae:0.09129294008016586, rse:0.5192984938621521\n",
      "Intermediate time for DE and pred_len 24: 00h:13m:50.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2567174\n",
      "\tspeed: 0.0628s/iter; left time: 1388.0100s\n",
      "\titers: 200, epoch: 1 | loss: 0.2369715\n",
      "\tspeed: 0.0412s/iter; left time: 906.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.2615639 Vali Loss: 0.2209979 Test Loss: 0.2222324\n",
      "Validation loss decreased (inf --> 0.220998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1564926\n",
      "\tspeed: 0.0754s/iter; left time: 1649.4417s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341260\n",
      "\tspeed: 0.0410s/iter; left time: 893.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1608338 Vali Loss: 0.1363482 Test Loss: 0.1418259\n",
      "Validation loss decreased (0.220998 --> 0.136348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1162611\n",
      "\tspeed: 0.0761s/iter; left time: 1649.0645s\n",
      "\titers: 200, epoch: 3 | loss: 0.1177480\n",
      "\tspeed: 0.0409s/iter; left time: 880.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1208445 Vali Loss: 0.1277944 Test Loss: 0.1374204\n",
      "Validation loss decreased (0.136348 --> 0.127794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1102845\n",
      "\tspeed: 0.0763s/iter; left time: 1636.2639s\n",
      "\titers: 200, epoch: 4 | loss: 0.1140750\n",
      "\tspeed: 0.0409s/iter; left time: 873.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1129174 Vali Loss: 0.1251605 Test Loss: 0.1341668\n",
      "Validation loss decreased (0.127794 --> 0.125161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166949\n",
      "\tspeed: 0.0760s/iter; left time: 1611.2576s\n",
      "\titers: 200, epoch: 5 | loss: 0.1081393\n",
      "\tspeed: 0.0407s/iter; left time: 859.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1103549 Vali Loss: 0.1227886 Test Loss: 0.1303220\n",
      "Validation loss decreased (0.125161 --> 0.122789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062442\n",
      "\tspeed: 0.0756s/iter; left time: 1586.8452s\n",
      "\titers: 200, epoch: 6 | loss: 0.1072186\n",
      "\tspeed: 0.0409s/iter; left time: 855.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1078670 Vali Loss: 0.1219471 Test Loss: 0.1291881\n",
      "Validation loss decreased (0.122789 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061169\n",
      "\tspeed: 0.0762s/iter; left time: 1583.3644s\n",
      "\titers: 200, epoch: 7 | loss: 0.1112051\n",
      "\tspeed: 0.0407s/iter; left time: 841.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1068713 Vali Loss: 0.1213121 Test Loss: 0.1290444\n",
      "Validation loss decreased (0.121947 --> 0.121312).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057692\n",
      "\tspeed: 0.0757s/iter; left time: 1555.9161s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068326\n",
      "\tspeed: 0.0408s/iter; left time: 833.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1059914 Vali Loss: 0.1224635 Test Loss: 0.1298995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1034219\n",
      "\tspeed: 0.0754s/iter; left time: 1532.3575s\n",
      "\titers: 200, epoch: 9 | loss: 0.0999100\n",
      "\tspeed: 0.0408s/iter; left time: 825.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1050044 Vali Loss: 0.1230605 Test Loss: 0.1317926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1093468\n",
      "\tspeed: 0.0748s/iter; left time: 1504.2936s\n",
      "\titers: 200, epoch: 10 | loss: 0.1081782\n",
      "\tspeed: 0.0411s/iter; left time: 821.1721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1045642 Vali Loss: 0.1219349 Test Loss: 0.1301681\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1027195\n",
      "\tspeed: 0.0743s/iter; left time: 1477.2936s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048118\n",
      "\tspeed: 0.0407s/iter; left time: 805.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1038951 Vali Loss: 0.1220826 Test Loss: 0.1309490\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1036500\n",
      "\tspeed: 0.0756s/iter; left time: 1486.8648s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967905\n",
      "\tspeed: 0.0407s/iter; left time: 795.0850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1036535 Vali Loss: 0.1236033 Test Loss: 0.1331385\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004048\n",
      "\tspeed: 0.0750s/iter; left time: 1457.8008s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993740\n",
      "\tspeed: 0.0409s/iter; left time: 790.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1033556 Vali Loss: 0.1226675 Test Loss: 0.1322711\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1005409\n",
      "\tspeed: 0.0760s/iter; left time: 1459.5280s\n",
      "\titers: 200, epoch: 14 | loss: 0.1024006\n",
      "\tspeed: 0.0409s/iter; left time: 780.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1029066 Vali Loss: 0.1230128 Test Loss: 0.1320505\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068955\n",
      "\tspeed: 0.0756s/iter; left time: 1435.2907s\n",
      "\titers: 200, epoch: 15 | loss: 0.1093898\n",
      "\tspeed: 0.0410s/iter; left time: 773.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1028959 Vali Loss: 0.1227752 Test Loss: 0.1326943\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076504\n",
      "\tspeed: 0.0754s/iter; left time: 1416.2298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0938831\n",
      "\tspeed: 0.0408s/iter; left time: 760.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1022091 Vali Loss: 0.1224919 Test Loss: 0.1329917\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013022\n",
      "\tspeed: 0.0748s/iter; left time: 1387.4968s\n",
      "\titers: 200, epoch: 17 | loss: 0.1030388\n",
      "\tspeed: 0.0409s/iter; left time: 754.5603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1022000 Vali Loss: 0.1220423 Test Loss: 0.1307992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03688869625329971, rmse:0.1920643001794815, mae:0.12904435396194458, rse:0.6801385283470154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2674383\n",
      "\tspeed: 0.0430s/iter; left time: 951.1925s\n",
      "\titers: 200, epoch: 1 | loss: 0.2461667\n",
      "\tspeed: 0.0409s/iter; left time: 899.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.2638501 Vali Loss: 0.2226131 Test Loss: 0.2216158\n",
      "Validation loss decreased (inf --> 0.222613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543895\n",
      "\tspeed: 0.0770s/iter; left time: 1684.2141s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398169\n",
      "\tspeed: 0.0410s/iter; left time: 892.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1605066 Vali Loss: 0.1367813 Test Loss: 0.1428790\n",
      "Validation loss decreased (0.222613 --> 0.136781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1166887\n",
      "\tspeed: 0.0773s/iter; left time: 1673.4618s\n",
      "\titers: 200, epoch: 3 | loss: 0.1116634\n",
      "\tspeed: 0.0410s/iter; left time: 884.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1194075 Vali Loss: 0.1278751 Test Loss: 0.1380406\n",
      "Validation loss decreased (0.136781 --> 0.127875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1114147\n",
      "\tspeed: 0.0766s/iter; left time: 1641.8385s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107357\n",
      "\tspeed: 0.0407s/iter; left time: 869.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1119658 Vali Loss: 0.1239229 Test Loss: 0.1325669\n",
      "Validation loss decreased (0.127875 --> 0.123923).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1104820\n",
      "\tspeed: 0.0773s/iter; left time: 1640.6833s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076826\n",
      "\tspeed: 0.0410s/iter; left time: 864.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1088037 Vali Loss: 0.1234485 Test Loss: 0.1317335\n",
      "Validation loss decreased (0.123923 --> 0.123449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1043967\n",
      "\tspeed: 0.0769s/iter; left time: 1613.9428s\n",
      "\titers: 200, epoch: 6 | loss: 0.1043626\n",
      "\tspeed: 0.0408s/iter; left time: 853.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1072132 Vali Loss: 0.1251106 Test Loss: 0.1335774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1115653\n",
      "\tspeed: 0.0757s/iter; left time: 1572.3607s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044515\n",
      "\tspeed: 0.0408s/iter; left time: 843.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1065478 Vali Loss: 0.1222214 Test Loss: 0.1305019\n",
      "Validation loss decreased (0.123449 --> 0.122221).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1077851\n",
      "\tspeed: 0.0769s/iter; left time: 1579.9063s\n",
      "\titers: 200, epoch: 8 | loss: 0.1084414\n",
      "\tspeed: 0.0410s/iter; left time: 837.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1052958 Vali Loss: 0.1238670 Test Loss: 0.1318427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1064024\n",
      "\tspeed: 0.0757s/iter; left time: 1538.7054s\n",
      "\titers: 200, epoch: 9 | loss: 0.1059458\n",
      "\tspeed: 0.0407s/iter; left time: 823.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1049578 Vali Loss: 0.1226378 Test Loss: 0.1321362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027817\n",
      "\tspeed: 0.0758s/iter; left time: 1523.4538s\n",
      "\titers: 200, epoch: 10 | loss: 0.1018352\n",
      "\tspeed: 0.0409s/iter; left time: 817.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1040832 Vali Loss: 0.1221598 Test Loss: 0.1312657\n",
      "Validation loss decreased (0.122221 --> 0.122160).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044997\n",
      "\tspeed: 0.0763s/iter; left time: 1516.9135s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089497\n",
      "\tspeed: 0.0407s/iter; left time: 804.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1037177 Vali Loss: 0.1224726 Test Loss: 0.1325074\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011573\n",
      "\tspeed: 0.0753s/iter; left time: 1480.9254s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064023\n",
      "\tspeed: 0.0408s/iter; left time: 798.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1033040 Vali Loss: 0.1231317 Test Loss: 0.1332391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020794\n",
      "\tspeed: 0.0763s/iter; left time: 1483.3208s\n",
      "\titers: 200, epoch: 13 | loss: 0.1041973\n",
      "\tspeed: 0.0408s/iter; left time: 788.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1027258 Vali Loss: 0.1206543 Test Loss: 0.1306935\n",
      "Validation loss decreased (0.122160 --> 0.120654).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1010036\n",
      "\tspeed: 0.0767s/iter; left time: 1473.0943s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005691\n",
      "\tspeed: 0.0407s/iter; left time: 777.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1023238 Vali Loss: 0.1209531 Test Loss: 0.1310647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021855\n",
      "\tspeed: 0.0757s/iter; left time: 1437.1194s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030579\n",
      "\tspeed: 0.0409s/iter; left time: 773.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1019652 Vali Loss: 0.1216964 Test Loss: 0.1336367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990499\n",
      "\tspeed: 0.0751s/iter; left time: 1409.2914s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013082\n",
      "\tspeed: 0.0409s/iter; left time: 762.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1017566 Vali Loss: 0.1207150 Test Loss: 0.1311256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0989789\n",
      "\tspeed: 0.0764s/iter; left time: 1417.7488s\n",
      "\titers: 200, epoch: 17 | loss: 0.1032420\n",
      "\tspeed: 0.0409s/iter; left time: 755.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1016855 Vali Loss: 0.1216641 Test Loss: 0.1335739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1009876\n",
      "\tspeed: 0.0755s/iter; left time: 1383.5795s\n",
      "\titers: 200, epoch: 18 | loss: 0.0992788\n",
      "\tspeed: 0.0407s/iter; left time: 741.6790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1016551 Vali Loss: 0.1225416 Test Loss: 0.1356461\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0994656\n",
      "\tspeed: 0.0761s/iter; left time: 1376.9440s\n",
      "\titers: 200, epoch: 19 | loss: 0.1023100\n",
      "\tspeed: 0.0406s/iter; left time: 731.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1011918 Vali Loss: 0.1226855 Test Loss: 0.1347964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1051435\n",
      "\tspeed: 0.0755s/iter; left time: 1350.2551s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025466\n",
      "\tspeed: 0.0409s/iter; left time: 727.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1011156 Vali Loss: 0.1218346 Test Loss: 0.1332678\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033999\n",
      "\tspeed: 0.0756s/iter; left time: 1336.0540s\n",
      "\titers: 200, epoch: 21 | loss: 0.1037384\n",
      "\tspeed: 0.0407s/iter; left time: 715.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1009183 Vali Loss: 0.1211568 Test Loss: 0.1323556\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1021763\n",
      "\tspeed: 0.0763s/iter; left time: 1331.2421s\n",
      "\titers: 200, epoch: 22 | loss: 0.0984414\n",
      "\tspeed: 0.0406s/iter; left time: 704.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1006230 Vali Loss: 0.1213428 Test Loss: 0.1328119\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0972030\n",
      "\tspeed: 0.0760s/iter; left time: 1308.8892s\n",
      "\titers: 200, epoch: 23 | loss: 0.0972501\n",
      "\tspeed: 0.0408s/iter; left time: 698.3746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1005551 Vali Loss: 0.1217129 Test Loss: 0.1332923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03879741579294205, rmse:0.196970596909523, mae:0.1306934952735901, rse:0.6975127458572388\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:59.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2547011\n",
      "\tspeed: 0.0659s/iter; left time: 1455.6398s\n",
      "\titers: 200, epoch: 1 | loss: 0.2446538\n",
      "\tspeed: 0.0413s/iter; left time: 908.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.2621706 Vali Loss: 0.2210747 Test Loss: 0.2229995\n",
      "Validation loss decreased (inf --> 0.221075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1477357\n",
      "\tspeed: 0.0766s/iter; left time: 1676.1026s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341442\n",
      "\tspeed: 0.0412s/iter; left time: 898.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1630918 Vali Loss: 0.1387679 Test Loss: 0.1472351\n",
      "Validation loss decreased (0.221075 --> 0.138768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1283511\n",
      "\tspeed: 0.0767s/iter; left time: 1660.0239s\n",
      "\titers: 200, epoch: 3 | loss: 0.1233076\n",
      "\tspeed: 0.0414s/iter; left time: 891.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1242776 Vali Loss: 0.1343270 Test Loss: 0.1477458\n",
      "Validation loss decreased (0.138768 --> 0.134327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1228040\n",
      "\tspeed: 0.0773s/iter; left time: 1656.7594s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145430\n",
      "\tspeed: 0.0412s/iter; left time: 879.8497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1177692 Vali Loss: 0.1332793 Test Loss: 0.1471356\n",
      "Validation loss decreased (0.134327 --> 0.133279).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1108847\n",
      "\tspeed: 0.0781s/iter; left time: 1656.7242s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184591\n",
      "\tspeed: 0.0411s/iter; left time: 868.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1150895 Vali Loss: 0.1292599 Test Loss: 0.1394582\n",
      "Validation loss decreased (0.133279 --> 0.129260).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1109404\n",
      "\tspeed: 0.0758s/iter; left time: 1590.2715s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151391\n",
      "\tspeed: 0.0412s/iter; left time: 860.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1130198 Vali Loss: 0.1282362 Test Loss: 0.1374332\n",
      "Validation loss decreased (0.129260 --> 0.128236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1107276\n",
      "\tspeed: 0.0768s/iter; left time: 1594.0727s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117783\n",
      "\tspeed: 0.0412s/iter; left time: 851.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1117408 Vali Loss: 0.1297795 Test Loss: 0.1401883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098032\n",
      "\tspeed: 0.0762s/iter; left time: 1566.2717s\n",
      "\titers: 200, epoch: 8 | loss: 0.1121785\n",
      "\tspeed: 0.0411s/iter; left time: 840.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1110236 Vali Loss: 0.1291916 Test Loss: 0.1372601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1095344\n",
      "\tspeed: 0.0760s/iter; left time: 1544.2785s\n",
      "\titers: 200, epoch: 9 | loss: 0.1124224\n",
      "\tspeed: 0.0411s/iter; left time: 831.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1099584 Vali Loss: 0.1276474 Test Loss: 0.1373459\n",
      "Validation loss decreased (0.128236 --> 0.127647).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1069649\n",
      "\tspeed: 0.0765s/iter; left time: 1538.7754s\n",
      "\titers: 200, epoch: 10 | loss: 0.1128789\n",
      "\tspeed: 0.0412s/iter; left time: 824.2495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1094869 Vali Loss: 0.1279376 Test Loss: 0.1391968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1130599\n",
      "\tspeed: 0.0768s/iter; left time: 1527.6429s\n",
      "\titers: 200, epoch: 11 | loss: 0.1103044\n",
      "\tspeed: 0.0411s/iter; left time: 813.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1087799 Vali Loss: 0.1274702 Test Loss: 0.1376306\n",
      "Validation loss decreased (0.127647 --> 0.127470).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1128469\n",
      "\tspeed: 0.0771s/iter; left time: 1514.9593s\n",
      "\titers: 200, epoch: 12 | loss: 0.1105351\n",
      "\tspeed: 0.0413s/iter; left time: 808.1190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1082214 Vali Loss: 0.1273075 Test Loss: 0.1389605\n",
      "Validation loss decreased (0.127470 --> 0.127308).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044768\n",
      "\tspeed: 0.0771s/iter; left time: 1499.1437s\n",
      "\titers: 200, epoch: 13 | loss: 0.1075517\n",
      "\tspeed: 0.0411s/iter; left time: 794.5731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1078091 Vali Loss: 0.1270512 Test Loss: 0.1373295\n",
      "Validation loss decreased (0.127308 --> 0.127051).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1049805\n",
      "\tspeed: 0.0777s/iter; left time: 1492.5376s\n",
      "\titers: 200, epoch: 14 | loss: 0.1062305\n",
      "\tspeed: 0.0411s/iter; left time: 786.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1075614 Vali Loss: 0.1272584 Test Loss: 0.1405276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024106\n",
      "\tspeed: 0.0761s/iter; left time: 1444.7472s\n",
      "\titers: 200, epoch: 15 | loss: 0.1068587\n",
      "\tspeed: 0.0412s/iter; left time: 778.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1072686 Vali Loss: 0.1271282 Test Loss: 0.1395907\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1049831\n",
      "\tspeed: 0.0761s/iter; left time: 1428.1250s\n",
      "\titers: 200, epoch: 16 | loss: 0.1086448\n",
      "\tspeed: 0.0411s/iter; left time: 766.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1069641 Vali Loss: 0.1280589 Test Loss: 0.1429418\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1084256\n",
      "\tspeed: 0.0753s/iter; left time: 1396.3966s\n",
      "\titers: 200, epoch: 17 | loss: 0.1095028\n",
      "\tspeed: 0.0411s/iter; left time: 757.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1066884 Vali Loss: 0.1263519 Test Loss: 0.1385314\n",
      "Validation loss decreased (0.127051 --> 0.126352).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1123055\n",
      "\tspeed: 0.0773s/iter; left time: 1416.9853s\n",
      "\titers: 200, epoch: 18 | loss: 0.1091762\n",
      "\tspeed: 0.0411s/iter; left time: 749.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1065208 Vali Loss: 0.1267130 Test Loss: 0.1371872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1051615\n",
      "\tspeed: 0.0758s/iter; left time: 1373.1484s\n",
      "\titers: 200, epoch: 19 | loss: 0.1084474\n",
      "\tspeed: 0.0411s/iter; left time: 739.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1062202 Vali Loss: 0.1266989 Test Loss: 0.1404610\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1065915\n",
      "\tspeed: 0.0763s/iter; left time: 1365.3596s\n",
      "\titers: 200, epoch: 20 | loss: 0.1041478\n",
      "\tspeed: 0.0411s/iter; left time: 730.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1061190 Vali Loss: 0.1269398 Test Loss: 0.1404824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061094\n",
      "\tspeed: 0.0755s/iter; left time: 1334.2136s\n",
      "\titers: 200, epoch: 21 | loss: 0.1058959\n",
      "\tspeed: 0.0415s/iter; left time: 728.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1059716 Vali Loss: 0.1267279 Test Loss: 0.1402840\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1044017\n",
      "\tspeed: 0.0755s/iter; left time: 1316.3296s\n",
      "\titers: 200, epoch: 22 | loss: 0.1075009\n",
      "\tspeed: 0.0414s/iter; left time: 718.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1057801 Vali Loss: 0.1281811 Test Loss: 0.1419328\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1047539\n",
      "\tspeed: 0.0758s/iter; left time: 1305.3737s\n",
      "\titers: 200, epoch: 23 | loss: 0.1052754\n",
      "\tspeed: 0.0410s/iter; left time: 701.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1056472 Vali Loss: 0.1271066 Test Loss: 0.1417327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1032366\n",
      "\tspeed: 0.0759s/iter; left time: 1289.4818s\n",
      "\titers: 200, epoch: 24 | loss: 0.1044951\n",
      "\tspeed: 0.0411s/iter; left time: 693.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1055431 Vali Loss: 0.1264203 Test Loss: 0.1404810\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1115490\n",
      "\tspeed: 0.0749s/iter; left time: 1256.6678s\n",
      "\titers: 200, epoch: 25 | loss: 0.1035964\n",
      "\tspeed: 0.0411s/iter; left time: 686.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1053842 Vali Loss: 0.1263358 Test Loss: 0.1400815\n",
      "Validation loss decreased (0.126352 --> 0.126336).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1036159\n",
      "\tspeed: 0.0761s/iter; left time: 1259.7895s\n",
      "\titers: 200, epoch: 26 | loss: 0.1037731\n",
      "\tspeed: 0.0411s/iter; left time: 675.4162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1051834 Vali Loss: 0.1265433 Test Loss: 0.1410923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1022529\n",
      "\tspeed: 0.0753s/iter; left time: 1229.3054s\n",
      "\titers: 200, epoch: 27 | loss: 0.1063197\n",
      "\tspeed: 0.0412s/iter; left time: 667.9426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1051369 Vali Loss: 0.1266984 Test Loss: 0.1409570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1050435\n",
      "\tspeed: 0.0764s/iter; left time: 1231.3200s\n",
      "\titers: 200, epoch: 28 | loss: 0.1088132\n",
      "\tspeed: 0.0411s/iter; left time: 658.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1050999 Vali Loss: 0.1260449 Test Loss: 0.1398182\n",
      "Validation loss decreased (0.126336 --> 0.126045).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1074791\n",
      "\tspeed: 0.0766s/iter; left time: 1216.7442s\n",
      "\titers: 200, epoch: 29 | loss: 0.1086402\n",
      "\tspeed: 0.0412s/iter; left time: 650.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1049540 Vali Loss: 0.1264877 Test Loss: 0.1398621\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1017556\n",
      "\tspeed: 0.0749s/iter; left time: 1173.1060s\n",
      "\titers: 200, epoch: 30 | loss: 0.1018851\n",
      "\tspeed: 0.0412s/iter; left time: 640.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1050275 Vali Loss: 0.1266508 Test Loss: 0.1413750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1069471\n",
      "\tspeed: 0.0754s/iter; left time: 1163.7781s\n",
      "\titers: 200, epoch: 31 | loss: 0.1028269\n",
      "\tspeed: 0.0411s/iter; left time: 630.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1049095 Vali Loss: 0.1261828 Test Loss: 0.1394460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1106816\n",
      "\tspeed: 0.0761s/iter; left time: 1157.5232s\n",
      "\titers: 200, epoch: 32 | loss: 0.1046448\n",
      "\tspeed: 0.0412s/iter; left time: 622.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1047826 Vali Loss: 0.1264209 Test Loss: 0.1406406\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1042348\n",
      "\tspeed: 0.0758s/iter; left time: 1136.8372s\n",
      "\titers: 200, epoch: 33 | loss: 0.1059592\n",
      "\tspeed: 0.0411s/iter; left time: 612.9490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1047775 Vali Loss: 0.1266658 Test Loss: 0.1412112\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1083043\n",
      "\tspeed: 0.0753s/iter; left time: 1113.1941s\n",
      "\titers: 200, epoch: 34 | loss: 0.1091277\n",
      "\tspeed: 0.0410s/iter; left time: 601.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1047314 Vali Loss: 0.1269310 Test Loss: 0.1415482\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1050427\n",
      "\tspeed: 0.0746s/iter; left time: 1085.8634s\n",
      "\titers: 200, epoch: 35 | loss: 0.1053451\n",
      "\tspeed: 0.0411s/iter; left time: 593.8324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1046090 Vali Loss: 0.1260353 Test Loss: 0.1401784\n",
      "Validation loss decreased (0.126045 --> 0.126035).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1072772\n",
      "\tspeed: 0.0758s/iter; left time: 1086.7973s\n",
      "\titers: 200, epoch: 36 | loss: 0.1069313\n",
      "\tspeed: 0.0410s/iter; left time: 584.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1046577 Vali Loss: 0.1265546 Test Loss: 0.1414028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1073018\n",
      "\tspeed: 0.0749s/iter; left time: 1056.0987s\n",
      "\titers: 200, epoch: 37 | loss: 0.1043714\n",
      "\tspeed: 0.0410s/iter; left time: 574.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1046224 Vali Loss: 0.1261640 Test Loss: 0.1402127\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1110265\n",
      "\tspeed: 0.0759s/iter; left time: 1053.3801s\n",
      "\titers: 200, epoch: 38 | loss: 0.1001320\n",
      "\tspeed: 0.0410s/iter; left time: 565.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1045099 Vali Loss: 0.1261084 Test Loss: 0.1405019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1004808\n",
      "\tspeed: 0.0753s/iter; left time: 1028.4516s\n",
      "\titers: 200, epoch: 39 | loss: 0.1060599\n",
      "\tspeed: 0.0411s/iter; left time: 558.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1045482 Vali Loss: 0.1261528 Test Loss: 0.1404652\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1076685\n",
      "\tspeed: 0.0749s/iter; left time: 1007.5148s\n",
      "\titers: 200, epoch: 40 | loss: 0.1019712\n",
      "\tspeed: 0.0411s/iter; left time: 548.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1044784 Vali Loss: 0.1262912 Test Loss: 0.1407943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1066837\n",
      "\tspeed: 0.0756s/iter; left time: 999.6501s\n",
      "\titers: 200, epoch: 41 | loss: 0.1006510\n",
      "\tspeed: 0.0413s/iter; left time: 541.9486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1045106 Vali Loss: 0.1259988 Test Loss: 0.1401316\n",
      "Validation loss decreased (0.126035 --> 0.125999).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1069852\n",
      "\tspeed: 0.0774s/iter; left time: 1006.1285s\n",
      "\titers: 200, epoch: 42 | loss: 0.1012278\n",
      "\tspeed: 0.0411s/iter; left time: 529.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1044709 Vali Loss: 0.1263843 Test Loss: 0.1406530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1050513\n",
      "\tspeed: 0.0751s/iter; left time: 958.9403s\n",
      "\titers: 200, epoch: 43 | loss: 0.1035220\n",
      "\tspeed: 0.0412s/iter; left time: 521.8023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1044019 Vali Loss: 0.1262721 Test Loss: 0.1411214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1099950\n",
      "\tspeed: 0.0762s/iter; left time: 956.2018s\n",
      "\titers: 200, epoch: 44 | loss: 0.1008029\n",
      "\tspeed: 0.0413s/iter; left time: 514.0173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1043530 Vali Loss: 0.1268223 Test Loss: 0.1418868\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1062310\n",
      "\tspeed: 0.0748s/iter; left time: 922.6622s\n",
      "\titers: 200, epoch: 45 | loss: 0.0978017\n",
      "\tspeed: 0.0411s/iter; left time: 502.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1043717 Vali Loss: 0.1263294 Test Loss: 0.1411482\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1073297\n",
      "\tspeed: 0.0739s/iter; left time: 895.3941s\n",
      "\titers: 200, epoch: 46 | loss: 0.1029892\n",
      "\tspeed: 0.0411s/iter; left time: 493.3324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1043665 Vali Loss: 0.1261325 Test Loss: 0.1409885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1039653\n",
      "\tspeed: 0.0761s/iter; left time: 905.1491s\n",
      "\titers: 200, epoch: 47 | loss: 0.1021439\n",
      "\tspeed: 0.0411s/iter; left time: 484.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1044277 Vali Loss: 0.1264205 Test Loss: 0.1413692\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1047657\n",
      "\tspeed: 0.0753s/iter; left time: 879.0226s\n",
      "\titers: 200, epoch: 48 | loss: 0.1039199\n",
      "\tspeed: 0.0410s/iter; left time: 474.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1043820 Vali Loss: 0.1264119 Test Loss: 0.1411667\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1022447\n",
      "\tspeed: 0.0757s/iter; left time: 866.2159s\n",
      "\titers: 200, epoch: 49 | loss: 0.1015952\n",
      "\tspeed: 0.0412s/iter; left time: 467.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1043758 Vali Loss: 0.1260933 Test Loss: 0.1404598\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1026140\n",
      "\tspeed: 0.0743s/iter; left time: 834.1814s\n",
      "\titers: 200, epoch: 50 | loss: 0.0980135\n",
      "\tspeed: 0.0412s/iter; left time: 457.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1043637 Vali Loss: 0.1261517 Test Loss: 0.1409613\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1067247\n",
      "\tspeed: 0.0754s/iter; left time: 829.5468s\n",
      "\titers: 200, epoch: 51 | loss: 0.1038287\n",
      "\tspeed: 0.0412s/iter; left time: 449.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1043192 Vali Loss: 0.1263004 Test Loss: 0.1410258\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04456966370344162, rmse:0.2111152857542038, mae:0.14013166725635529, rse:0.747787356376648\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2695983\n",
      "\tspeed: 0.0435s/iter; left time: 960.9874s\n",
      "\titers: 200, epoch: 1 | loss: 0.2458136\n",
      "\tspeed: 0.0412s/iter; left time: 905.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.2653355 Vali Loss: 0.2224486 Test Loss: 0.2230866\n",
      "Validation loss decreased (inf --> 0.222449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1459184\n",
      "\tspeed: 0.0775s/iter; left time: 1695.2316s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344317\n",
      "\tspeed: 0.0411s/iter; left time: 894.6112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1615751 Vali Loss: 0.1398708 Test Loss: 0.1480999\n",
      "Validation loss decreased (0.222449 --> 0.139871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1242755\n",
      "\tspeed: 0.0788s/iter; left time: 1705.8541s\n",
      "\titers: 200, epoch: 3 | loss: 0.1158472\n",
      "\tspeed: 0.0413s/iter; left time: 889.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1242331 Vali Loss: 0.1310286 Test Loss: 0.1426450\n",
      "Validation loss decreased (0.139871 --> 0.131029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153544\n",
      "\tspeed: 0.0851s/iter; left time: 1824.0587s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145391\n",
      "\tspeed: 0.0412s/iter; left time: 878.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1171351 Vali Loss: 0.1277771 Test Loss: 0.1371709\n",
      "Validation loss decreased (0.131029 --> 0.127777).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1219279\n",
      "\tspeed: 0.0780s/iter; left time: 1653.8863s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114400\n",
      "\tspeed: 0.0411s/iter; left time: 867.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1141187 Vali Loss: 0.1312206 Test Loss: 0.1432557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1113654\n",
      "\tspeed: 0.0761s/iter; left time: 1596.7595s\n",
      "\titers: 200, epoch: 6 | loss: 0.1110327\n",
      "\tspeed: 0.0410s/iter; left time: 857.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1122951 Vali Loss: 0.1279132 Test Loss: 0.1393908\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1125884\n",
      "\tspeed: 0.0772s/iter; left time: 1602.6943s\n",
      "\titers: 200, epoch: 7 | loss: 0.1114042\n",
      "\tspeed: 0.0410s/iter; left time: 848.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1113330 Vali Loss: 0.1264910 Test Loss: 0.1378686\n",
      "Validation loss decreased (0.127777 --> 0.126491).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1113305\n",
      "\tspeed: 0.0778s/iter; left time: 1598.4130s\n",
      "\titers: 200, epoch: 8 | loss: 0.1078927\n",
      "\tspeed: 0.0410s/iter; left time: 839.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1103155 Vali Loss: 0.1271214 Test Loss: 0.1400218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1121107\n",
      "\tspeed: 0.0766s/iter; left time: 1556.5739s\n",
      "\titers: 200, epoch: 9 | loss: 0.1082017\n",
      "\tspeed: 0.0413s/iter; left time: 836.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1099665 Vali Loss: 0.1268901 Test Loss: 0.1410304\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1071596\n",
      "\tspeed: 0.0771s/iter; left time: 1549.6833s\n",
      "\titers: 200, epoch: 10 | loss: 0.1088479\n",
      "\tspeed: 0.0411s/iter; left time: 822.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1091042 Vali Loss: 0.1271832 Test Loss: 0.1428634\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068706\n",
      "\tspeed: 0.0762s/iter; left time: 1515.5644s\n",
      "\titers: 200, epoch: 11 | loss: 0.1111364\n",
      "\tspeed: 0.0413s/iter; left time: 816.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1084925 Vali Loss: 0.1307015 Test Loss: 0.1492935\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1100810\n",
      "\tspeed: 0.0774s/iter; left time: 1520.8222s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114843\n",
      "\tspeed: 0.0412s/iter; left time: 805.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1080450 Vali Loss: 0.1283088 Test Loss: 0.1461065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1144699\n",
      "\tspeed: 0.0764s/iter; left time: 1484.2761s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059909\n",
      "\tspeed: 0.0411s/iter; left time: 794.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1073719 Vali Loss: 0.1269572 Test Loss: 0.1428572\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083283\n",
      "\tspeed: 0.0763s/iter; left time: 1466.8498s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086156\n",
      "\tspeed: 0.0411s/iter; left time: 786.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1069796 Vali Loss: 0.1259924 Test Loss: 0.1436143\n",
      "Validation loss decreased (0.126491 --> 0.125992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1066480\n",
      "\tspeed: 0.0780s/iter; left time: 1482.3102s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062846\n",
      "\tspeed: 0.0411s/iter; left time: 777.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1068378 Vali Loss: 0.1262309 Test Loss: 0.1440513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067633\n",
      "\tspeed: 0.0765s/iter; left time: 1435.6313s\n",
      "\titers: 200, epoch: 16 | loss: 0.1104817\n",
      "\tspeed: 0.0412s/iter; left time: 769.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1063836 Vali Loss: 0.1261759 Test Loss: 0.1427229\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1053825\n",
      "\tspeed: 0.0766s/iter; left time: 1420.5417s\n",
      "\titers: 200, epoch: 17 | loss: 0.1034071\n",
      "\tspeed: 0.0410s/iter; left time: 756.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1059606 Vali Loss: 0.1266880 Test Loss: 0.1433154\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1074457\n",
      "\tspeed: 0.0763s/iter; left time: 1398.0312s\n",
      "\titers: 200, epoch: 18 | loss: 0.1025829\n",
      "\tspeed: 0.0411s/iter; left time: 748.5073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1056170 Vali Loss: 0.1255190 Test Loss: 0.1441649\n",
      "Validation loss decreased (0.125992 --> 0.125519).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1041701\n",
      "\tspeed: 0.0774s/iter; left time: 1401.8615s\n",
      "\titers: 200, epoch: 19 | loss: 0.1018132\n",
      "\tspeed: 0.0412s/iter; left time: 740.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1052355 Vali Loss: 0.1258863 Test Loss: 0.1445787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1048761\n",
      "\tspeed: 0.0761s/iter; left time: 1360.8724s\n",
      "\titers: 200, epoch: 20 | loss: 0.1065127\n",
      "\tspeed: 0.0412s/iter; left time: 732.6337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1051658 Vali Loss: 0.1252106 Test Loss: 0.1429672\n",
      "Validation loss decreased (0.125519 --> 0.125211).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1035283\n",
      "\tspeed: 0.0769s/iter; left time: 1357.3456s\n",
      "\titers: 200, epoch: 21 | loss: 0.1084166\n",
      "\tspeed: 0.0411s/iter; left time: 721.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1050887 Vali Loss: 0.1262848 Test Loss: 0.1436059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1018366\n",
      "\tspeed: 0.0779s/iter; left time: 1359.2956s\n",
      "\titers: 200, epoch: 22 | loss: 0.1031664\n",
      "\tspeed: 0.0411s/iter; left time: 712.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1047694 Vali Loss: 0.1251836 Test Loss: 0.1430537\n",
      "Validation loss decreased (0.125211 --> 0.125184).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1010575\n",
      "\tspeed: 0.0776s/iter; left time: 1335.4983s\n",
      "\titers: 200, epoch: 23 | loss: 0.1016529\n",
      "\tspeed: 0.0410s/iter; left time: 701.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1047283 Vali Loss: 0.1250855 Test Loss: 0.1421348\n",
      "Validation loss decreased (0.125184 --> 0.125085).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1066785\n",
      "\tspeed: 0.0774s/iter; left time: 1316.1817s\n",
      "\titers: 200, epoch: 24 | loss: 0.1021970\n",
      "\tspeed: 0.0411s/iter; left time: 694.2526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1045605 Vali Loss: 0.1252609 Test Loss: 0.1430158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1062797\n",
      "\tspeed: 0.0768s/iter; left time: 1288.2655s\n",
      "\titers: 200, epoch: 25 | loss: 0.1052838\n",
      "\tspeed: 0.0412s/iter; left time: 687.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1042314 Vali Loss: 0.1257189 Test Loss: 0.1448543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1088224\n",
      "\tspeed: 0.0765s/iter; left time: 1266.0218s\n",
      "\titers: 200, epoch: 26 | loss: 0.1028319\n",
      "\tspeed: 0.0411s/iter; left time: 676.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1042463 Vali Loss: 0.1254094 Test Loss: 0.1445392\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1050898\n",
      "\tspeed: 0.0764s/iter; left time: 1248.0756s\n",
      "\titers: 200, epoch: 27 | loss: 0.1036657\n",
      "\tspeed: 0.0411s/iter; left time: 667.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1041168 Vali Loss: 0.1252972 Test Loss: 0.1431515\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1059706\n",
      "\tspeed: 0.0763s/iter; left time: 1229.3850s\n",
      "\titers: 200, epoch: 28 | loss: 0.1038235\n",
      "\tspeed: 0.0410s/iter; left time: 656.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1038388 Vali Loss: 0.1252899 Test Loss: 0.1423092\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1048199\n",
      "\tspeed: 0.0766s/iter; left time: 1217.3585s\n",
      "\titers: 200, epoch: 29 | loss: 0.1049025\n",
      "\tspeed: 0.0412s/iter; left time: 650.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1037922 Vali Loss: 0.1254297 Test Loss: 0.1428744\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1042742\n",
      "\tspeed: 0.0760s/iter; left time: 1190.2551s\n",
      "\titers: 200, epoch: 30 | loss: 0.1088455\n",
      "\tspeed: 0.0414s/iter; left time: 643.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1037990 Vali Loss: 0.1253161 Test Loss: 0.1436195\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1021391\n",
      "\tspeed: 0.0767s/iter; left time: 1184.9977s\n",
      "\titers: 200, epoch: 31 | loss: 0.1076526\n",
      "\tspeed: 0.0411s/iter; left time: 629.8870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1036785 Vali Loss: 0.1253694 Test Loss: 0.1436673\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0983822\n",
      "\tspeed: 0.0762s/iter; left time: 1159.9313s\n",
      "\titers: 200, epoch: 32 | loss: 0.1030093\n",
      "\tspeed: 0.0411s/iter; left time: 621.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1036134 Vali Loss: 0.1252570 Test Loss: 0.1444752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1020824\n",
      "\tspeed: 0.0768s/iter; left time: 1152.4882s\n",
      "\titers: 200, epoch: 33 | loss: 0.1070113\n",
      "\tspeed: 0.0412s/iter; left time: 614.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1035500 Vali Loss: 0.1254304 Test Loss: 0.1442089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04730448126792908, rmse:0.21749593317508698, mae:0.14213477075099945, rse:0.770388126373291\n",
      "Intermediate time for DE and pred_len 168: 00h:16m:40.88s\n",
      "Intermediate time for DE: 00h:38m:30.83s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2713369\n",
      "\tspeed: 0.0642s/iter; left time: 1426.1914s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666838\n",
      "\tspeed: 0.0406s/iter; left time: 896.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.2775031 Vali Loss: 0.2227723 Test Loss: 0.2392421\n",
      "Validation loss decreased (inf --> 0.222772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1425531\n",
      "\tspeed: 0.0736s/iter; left time: 1618.4386s\n",
      "\titers: 200, epoch: 2 | loss: 0.1142946\n",
      "\tspeed: 0.0404s/iter; left time: 883.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.1516249 Vali Loss: 0.1061840 Test Loss: 0.1243391\n",
      "Validation loss decreased (0.222772 --> 0.106184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1043676\n",
      "\tspeed: 0.0740s/iter; left time: 1608.9193s\n",
      "\titers: 200, epoch: 3 | loss: 0.0964127\n",
      "\tspeed: 0.0405s/iter; left time: 876.3062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.1000793 Vali Loss: 0.0966325 Test Loss: 0.1096701\n",
      "Validation loss decreased (0.106184 --> 0.096632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971016\n",
      "\tspeed: 0.0745s/iter; left time: 1604.4450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0946171\n",
      "\tspeed: 0.0404s/iter; left time: 866.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0896545 Vali Loss: 0.0937908 Test Loss: 0.1082869\n",
      "Validation loss decreased (0.096632 --> 0.093791).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815196\n",
      "\tspeed: 0.0736s/iter; left time: 1567.2898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0840815\n",
      "\tspeed: 0.0404s/iter; left time: 856.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0858922 Vali Loss: 0.0940853 Test Loss: 0.1072255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800261\n",
      "\tspeed: 0.0738s/iter; left time: 1556.8144s\n",
      "\titers: 200, epoch: 6 | loss: 0.0847688\n",
      "\tspeed: 0.0404s/iter; left time: 848.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0843575 Vali Loss: 0.0934700 Test Loss: 0.1070231\n",
      "Validation loss decreased (0.093791 --> 0.093470).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830629\n",
      "\tspeed: 0.0735s/iter; left time: 1532.6763s\n",
      "\titers: 200, epoch: 7 | loss: 0.0818849\n",
      "\tspeed: 0.0405s/iter; left time: 840.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0830517 Vali Loss: 0.0935562 Test Loss: 0.1062768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0861846\n",
      "\tspeed: 0.0726s/iter; left time: 1498.8984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820004\n",
      "\tspeed: 0.0405s/iter; left time: 831.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0825876 Vali Loss: 0.0935195 Test Loss: 0.1072546\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820624\n",
      "\tspeed: 0.0733s/iter; left time: 1496.6125s\n",
      "\titers: 200, epoch: 9 | loss: 0.0781329\n",
      "\tspeed: 0.0404s/iter; left time: 821.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0817799 Vali Loss: 0.0945552 Test Loss: 0.1062779\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0802087\n",
      "\tspeed: 0.0729s/iter; left time: 1472.0468s\n",
      "\titers: 200, epoch: 10 | loss: 0.0832409\n",
      "\tspeed: 0.0407s/iter; left time: 818.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0810398 Vali Loss: 0.0922729 Test Loss: 0.1053363\n",
      "Validation loss decreased (0.093470 --> 0.092273).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854504\n",
      "\tspeed: 0.0736s/iter; left time: 1470.1661s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827603\n",
      "\tspeed: 0.0405s/iter; left time: 804.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0806057 Vali Loss: 0.0923044 Test Loss: 0.1049127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715239\n",
      "\tspeed: 0.0728s/iter; left time: 1437.5269s\n",
      "\titers: 200, epoch: 12 | loss: 0.0846490\n",
      "\tspeed: 0.0406s/iter; left time: 798.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0804665 Vali Loss: 0.0916704 Test Loss: 0.1046567\n",
      "Validation loss decreased (0.092273 --> 0.091670).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789320\n",
      "\tspeed: 0.0735s/iter; left time: 1435.9416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0801651\n",
      "\tspeed: 0.0404s/iter; left time: 784.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0798680 Vali Loss: 0.0913420 Test Loss: 0.1045888\n",
      "Validation loss decreased (0.091670 --> 0.091342).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795190\n",
      "\tspeed: 0.0740s/iter; left time: 1427.8847s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791162\n",
      "\tspeed: 0.0405s/iter; left time: 777.1902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0797841 Vali Loss: 0.0914175 Test Loss: 0.1047300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0785403\n",
      "\tspeed: 0.0732s/iter; left time: 1396.1154s\n",
      "\titers: 200, epoch: 15 | loss: 0.0783143\n",
      "\tspeed: 0.0404s/iter; left time: 766.6822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0794608 Vali Loss: 0.0913306 Test Loss: 0.1041831\n",
      "Validation loss decreased (0.091342 --> 0.091331).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0761678\n",
      "\tspeed: 0.0737s/iter; left time: 1389.3648s\n",
      "\titers: 200, epoch: 16 | loss: 0.0737287\n",
      "\tspeed: 0.0404s/iter; left time: 758.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0792677 Vali Loss: 0.0918222 Test Loss: 0.1056311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0833909\n",
      "\tspeed: 0.0731s/iter; left time: 1361.4509s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813364\n",
      "\tspeed: 0.0406s/iter; left time: 751.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0788700 Vali Loss: 0.0909332 Test Loss: 0.1044233\n",
      "Validation loss decreased (0.091331 --> 0.090933).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786313\n",
      "\tspeed: 0.0738s/iter; left time: 1358.7282s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771805\n",
      "\tspeed: 0.0404s/iter; left time: 740.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0787176 Vali Loss: 0.0909456 Test Loss: 0.1046183\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0785226\n",
      "\tspeed: 0.0728s/iter; left time: 1323.6296s\n",
      "\titers: 200, epoch: 19 | loss: 0.0825728\n",
      "\tspeed: 0.0408s/iter; left time: 738.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0784871 Vali Loss: 0.0913229 Test Loss: 0.1046131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0773899\n",
      "\tspeed: 0.0730s/iter; left time: 1312.1622s\n",
      "\titers: 200, epoch: 20 | loss: 0.0719374\n",
      "\tspeed: 0.0406s/iter; left time: 724.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0783474 Vali Loss: 0.0913036 Test Loss: 0.1047586\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0767777\n",
      "\tspeed: 0.0737s/iter; left time: 1306.6265s\n",
      "\titers: 200, epoch: 21 | loss: 0.0832794\n",
      "\tspeed: 0.0405s/iter; left time: 713.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0781011 Vali Loss: 0.0910498 Test Loss: 0.1046779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779329\n",
      "\tspeed: 0.0732s/iter; left time: 1282.5354s\n",
      "\titers: 200, epoch: 22 | loss: 0.0787014\n",
      "\tspeed: 0.0404s/iter; left time: 704.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0782003 Vali Loss: 0.0910638 Test Loss: 0.1044707\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0808069\n",
      "\tspeed: 0.0743s/iter; left time: 1284.7940s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714334\n",
      "\tspeed: 0.0404s/iter; left time: 695.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0781985 Vali Loss: 0.0906492 Test Loss: 0.1044392\n",
      "Validation loss decreased (0.090933 --> 0.090649).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0796330\n",
      "\tspeed: 0.0730s/iter; left time: 1246.6551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0792855\n",
      "\tspeed: 0.0404s/iter; left time: 685.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0781420 Vali Loss: 0.0928221 Test Loss: 0.1059146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0789801\n",
      "\tspeed: 0.0738s/iter; left time: 1242.9445s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770648\n",
      "\tspeed: 0.0405s/iter; left time: 678.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0778025 Vali Loss: 0.0910814 Test Loss: 0.1047692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0750756\n",
      "\tspeed: 0.0735s/iter; left time: 1222.6360s\n",
      "\titers: 200, epoch: 26 | loss: 0.0734449\n",
      "\tspeed: 0.0405s/iter; left time: 668.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0906680 Test Loss: 0.1045140\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0786629\n",
      "\tspeed: 0.0731s/iter; left time: 1199.1492s\n",
      "\titers: 200, epoch: 27 | loss: 0.0804909\n",
      "\tspeed: 0.0404s/iter; left time: 659.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0775561 Vali Loss: 0.0909488 Test Loss: 0.1053258\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0729849\n",
      "\tspeed: 0.0735s/iter; left time: 1188.6991s\n",
      "\titers: 200, epoch: 28 | loss: 0.0823348\n",
      "\tspeed: 0.0406s/iter; left time: 652.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0775038 Vali Loss: 0.0906877 Test Loss: 0.1043712\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803065\n",
      "\tspeed: 0.0728s/iter; left time: 1161.3404s\n",
      "\titers: 200, epoch: 29 | loss: 0.0776471\n",
      "\tspeed: 0.0404s/iter; left time: 641.1638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0775364 Vali Loss: 0.0904995 Test Loss: 0.1043667\n",
      "Validation loss decreased (0.090649 --> 0.090499).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0795126\n",
      "\tspeed: 0.0740s/iter; left time: 1164.1134s\n",
      "\titers: 200, epoch: 30 | loss: 0.0834667\n",
      "\tspeed: 0.0405s/iter; left time: 632.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0774307 Vali Loss: 0.0906215 Test Loss: 0.1045543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0763445\n",
      "\tspeed: 0.0729s/iter; left time: 1131.1346s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814237\n",
      "\tspeed: 0.0404s/iter; left time: 622.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0773705 Vali Loss: 0.0906609 Test Loss: 0.1045952\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0799850\n",
      "\tspeed: 0.0731s/iter; left time: 1117.6484s\n",
      "\titers: 200, epoch: 32 | loss: 0.0796433\n",
      "\tspeed: 0.0405s/iter; left time: 614.7204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0773739 Vali Loss: 0.0906913 Test Loss: 0.1047461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764047\n",
      "\tspeed: 0.0733s/iter; left time: 1103.7078s\n",
      "\titers: 200, epoch: 33 | loss: 0.0748812\n",
      "\tspeed: 0.0404s/iter; left time: 605.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0772914 Vali Loss: 0.0904291 Test Loss: 0.1046706\n",
      "Validation loss decreased (0.090499 --> 0.090429).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757065\n",
      "\tspeed: 0.0744s/iter; left time: 1104.3862s\n",
      "\titers: 200, epoch: 34 | loss: 0.0784300\n",
      "\tspeed: 0.0404s/iter; left time: 595.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0774925 Vali Loss: 0.0904285 Test Loss: 0.1045240\n",
      "Validation loss decreased (0.090429 --> 0.090428).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0789417\n",
      "\tspeed: 0.0737s/iter; left time: 1077.2250s\n",
      "\titers: 200, epoch: 35 | loss: 0.0795636\n",
      "\tspeed: 0.0404s/iter; left time: 587.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0772180 Vali Loss: 0.0903595 Test Loss: 0.1044108\n",
      "Validation loss decreased (0.090428 --> 0.090360).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0779223\n",
      "\tspeed: 0.0741s/iter; left time: 1067.2375s\n",
      "\titers: 200, epoch: 36 | loss: 0.0729762\n",
      "\tspeed: 0.0405s/iter; left time: 578.6734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771922 Vali Loss: 0.0907313 Test Loss: 0.1047319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0809649\n",
      "\tspeed: 0.0729s/iter; left time: 1032.8605s\n",
      "\titers: 200, epoch: 37 | loss: 0.0781822\n",
      "\tspeed: 0.0404s/iter; left time: 568.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0771938 Vali Loss: 0.0908119 Test Loss: 0.1048842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0790581\n",
      "\tspeed: 0.0730s/iter; left time: 1018.4860s\n",
      "\titers: 200, epoch: 38 | loss: 0.0769915\n",
      "\tspeed: 0.0405s/iter; left time: 560.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771616 Vali Loss: 0.0907066 Test Loss: 0.1046624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0794891\n",
      "\tspeed: 0.0736s/iter; left time: 1010.2209s\n",
      "\titers: 200, epoch: 39 | loss: 0.0770491\n",
      "\tspeed: 0.0405s/iter; left time: 551.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0770720 Vali Loss: 0.0905792 Test Loss: 0.1047044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0841586\n",
      "\tspeed: 0.0729s/iter; left time: 984.7676s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748983\n",
      "\tspeed: 0.0409s/iter; left time: 547.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0771946 Vali Loss: 0.0904707 Test Loss: 0.1045962\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0774204\n",
      "\tspeed: 0.0731s/iter; left time: 970.2207s\n",
      "\titers: 200, epoch: 41 | loss: 0.0755066\n",
      "\tspeed: 0.0405s/iter; left time: 533.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0771183 Vali Loss: 0.0908790 Test Loss: 0.1048907\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0775084\n",
      "\tspeed: 0.0732s/iter; left time: 956.0669s\n",
      "\titers: 200, epoch: 42 | loss: 0.0691002\n",
      "\tspeed: 0.0404s/iter; left time: 524.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0771249 Vali Loss: 0.0906246 Test Loss: 0.1047030\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784101\n",
      "\tspeed: 0.0732s/iter; left time: 940.1250s\n",
      "\titers: 200, epoch: 43 | loss: 0.0804814\n",
      "\tspeed: 0.0404s/iter; left time: 514.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0770689 Vali Loss: 0.0905814 Test Loss: 0.1046426\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0731711\n",
      "\tspeed: 0.0733s/iter; left time: 924.2530s\n",
      "\titers: 200, epoch: 44 | loss: 0.0752849\n",
      "\tspeed: 0.0406s/iter; left time: 508.3404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0769947 Vali Loss: 0.0905712 Test Loss: 0.1047970\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0773128\n",
      "\tspeed: 0.0739s/iter; left time: 915.1414s\n",
      "\titers: 200, epoch: 45 | loss: 0.0740729\n",
      "\tspeed: 0.0407s/iter; left time: 500.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0770263 Vali Loss: 0.0906391 Test Loss: 0.1048571\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026252198964357376, rmse:0.1620253026485443, mae:0.10441073030233383, rse:0.5589413642883301\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2769710\n",
      "\tspeed: 0.0422s/iter; left time: 936.9427s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703775\n",
      "\tspeed: 0.0404s/iter; left time: 893.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.2823273 Vali Loss: 0.2324963 Test Loss: 0.2465261\n",
      "Validation loss decreased (inf --> 0.232496).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1442659\n",
      "\tspeed: 0.0752s/iter; left time: 1653.5216s\n",
      "\titers: 200, epoch: 2 | loss: 0.1169949\n",
      "\tspeed: 0.0405s/iter; left time: 887.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.1555963 Vali Loss: 0.1053269 Test Loss: 0.1230106\n",
      "Validation loss decreased (0.232496 --> 0.105327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0988071\n",
      "\tspeed: 0.0756s/iter; left time: 1644.9951s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924419\n",
      "\tspeed: 0.0405s/iter; left time: 877.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0987847 Vali Loss: 0.0956057 Test Loss: 0.1094963\n",
      "Validation loss decreased (0.105327 --> 0.095606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0906304\n",
      "\tspeed: 0.0741s/iter; left time: 1595.9171s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859146\n",
      "\tspeed: 0.0406s/iter; left time: 870.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0896020 Vali Loss: 0.0942191 Test Loss: 0.1084674\n",
      "Validation loss decreased (0.095606 --> 0.094219).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833325\n",
      "\tspeed: 0.0744s/iter; left time: 1586.0871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0874665\n",
      "\tspeed: 0.0404s/iter; left time: 857.5373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0865134 Vali Loss: 0.0941752 Test Loss: 0.1083765\n",
      "Validation loss decreased (0.094219 --> 0.094175).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809869\n",
      "\tspeed: 0.0748s/iter; left time: 1577.3494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877753\n",
      "\tspeed: 0.0404s/iter; left time: 848.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0840436 Vali Loss: 0.0927668 Test Loss: 0.1062152\n",
      "Validation loss decreased (0.094175 --> 0.092767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832490\n",
      "\tspeed: 0.0747s/iter; left time: 1558.7404s\n",
      "\titers: 200, epoch: 7 | loss: 0.0829870\n",
      "\tspeed: 0.0405s/iter; left time: 839.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0835418 Vali Loss: 0.0924259 Test Loss: 0.1067966\n",
      "Validation loss decreased (0.092767 --> 0.092426).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0888897\n",
      "\tspeed: 0.0747s/iter; left time: 1542.5103s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776150\n",
      "\tspeed: 0.0405s/iter; left time: 832.2374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0817162 Vali Loss: 0.0922475 Test Loss: 0.1054070\n",
      "Validation loss decreased (0.092426 --> 0.092248).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843962\n",
      "\tspeed: 0.0742s/iter; left time: 1514.0752s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838336\n",
      "\tspeed: 0.0405s/iter; left time: 821.9022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0816821 Vali Loss: 0.0933507 Test Loss: 0.1062168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0810641\n",
      "\tspeed: 0.0744s/iter; left time: 1502.5885s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758244\n",
      "\tspeed: 0.0405s/iter; left time: 813.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0805795 Vali Loss: 0.0916511 Test Loss: 0.1045354\n",
      "Validation loss decreased (0.092248 --> 0.091651).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785524\n",
      "\tspeed: 0.0747s/iter; left time: 1492.0473s\n",
      "\titers: 200, epoch: 11 | loss: 0.0734199\n",
      "\tspeed: 0.0404s/iter; left time: 802.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0804764 Vali Loss: 0.0922665 Test Loss: 0.1044703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815930\n",
      "\tspeed: 0.0741s/iter; left time: 1463.5480s\n",
      "\titers: 200, epoch: 12 | loss: 0.0852654\n",
      "\tspeed: 0.0405s/iter; left time: 796.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0801125 Vali Loss: 0.0941295 Test Loss: 0.1052972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784688\n",
      "\tspeed: 0.0745s/iter; left time: 1455.5487s\n",
      "\titers: 200, epoch: 13 | loss: 0.0802191\n",
      "\tspeed: 0.0405s/iter; left time: 786.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0796360 Vali Loss: 0.0911914 Test Loss: 0.1038486\n",
      "Validation loss decreased (0.091651 --> 0.091191).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795192\n",
      "\tspeed: 0.0744s/iter; left time: 1436.1961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0730847\n",
      "\tspeed: 0.0405s/iter; left time: 776.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0789982 Vali Loss: 0.0926355 Test Loss: 0.1048882\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0796765\n",
      "\tspeed: 0.0743s/iter; left time: 1417.1129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0771256\n",
      "\tspeed: 0.0404s/iter; left time: 767.4386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0790234 Vali Loss: 0.0907969 Test Loss: 0.1034538\n",
      "Validation loss decreased (0.091191 --> 0.090797).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0818546\n",
      "\tspeed: 0.0750s/iter; left time: 1413.9264s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809140\n",
      "\tspeed: 0.0405s/iter; left time: 760.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0784743 Vali Loss: 0.0916429 Test Loss: 0.1039903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794071\n",
      "\tspeed: 0.0747s/iter; left time: 1392.2929s\n",
      "\titers: 200, epoch: 17 | loss: 0.0774146\n",
      "\tspeed: 0.0405s/iter; left time: 750.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0785013 Vali Loss: 0.0909371 Test Loss: 0.1035683\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766296\n",
      "\tspeed: 0.0744s/iter; left time: 1369.0815s\n",
      "\titers: 200, epoch: 18 | loss: 0.0832104\n",
      "\tspeed: 0.0405s/iter; left time: 741.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0784101 Vali Loss: 0.0908933 Test Loss: 0.1042490\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0762396\n",
      "\tspeed: 0.0737s/iter; left time: 1341.2443s\n",
      "\titers: 200, epoch: 19 | loss: 0.0799202\n",
      "\tspeed: 0.0405s/iter; left time: 732.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0783316 Vali Loss: 0.0916444 Test Loss: 0.1038889\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802529\n",
      "\tspeed: 0.0745s/iter; left time: 1337.9869s\n",
      "\titers: 200, epoch: 20 | loss: 0.0766167\n",
      "\tspeed: 0.0404s/iter; left time: 722.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0781671 Vali Loss: 0.0909578 Test Loss: 0.1033743\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0780121\n",
      "\tspeed: 0.0742s/iter; left time: 1315.8856s\n",
      "\titers: 200, epoch: 21 | loss: 0.0757186\n",
      "\tspeed: 0.0411s/iter; left time: 725.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0778531 Vali Loss: 0.0906028 Test Loss: 0.1035582\n",
      "Validation loss decreased (0.090797 --> 0.090603).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0755088\n",
      "\tspeed: 0.0748s/iter; left time: 1310.5108s\n",
      "\titers: 200, epoch: 22 | loss: 0.0724161\n",
      "\tspeed: 0.0406s/iter; left time: 706.5124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0779181 Vali Loss: 0.0907662 Test Loss: 0.1033700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0793474\n",
      "\tspeed: 0.0742s/iter; left time: 1283.5519s\n",
      "\titers: 200, epoch: 23 | loss: 0.0752869\n",
      "\tspeed: 0.0405s/iter; left time: 696.5507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0778138 Vali Loss: 0.0906027 Test Loss: 0.1033847\n",
      "Validation loss decreased (0.090603 --> 0.090603).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0718337\n",
      "\tspeed: 0.0744s/iter; left time: 1270.7808s\n",
      "\titers: 200, epoch: 24 | loss: 0.0822986\n",
      "\tspeed: 0.0406s/iter; left time: 688.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0774387 Vali Loss: 0.0905964 Test Loss: 0.1033350\n",
      "Validation loss decreased (0.090603 --> 0.090596).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781854\n",
      "\tspeed: 0.0745s/iter; left time: 1254.6554s\n",
      "\titers: 200, epoch: 25 | loss: 0.0776588\n",
      "\tspeed: 0.0405s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0773905 Vali Loss: 0.0911812 Test Loss: 0.1039794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0843180\n",
      "\tspeed: 0.0743s/iter; left time: 1234.5543s\n",
      "\titers: 200, epoch: 26 | loss: 0.0786229\n",
      "\tspeed: 0.0405s/iter; left time: 669.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0774403 Vali Loss: 0.0905203 Test Loss: 0.1033267\n",
      "Validation loss decreased (0.090596 --> 0.090520).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0778569\n",
      "\tspeed: 0.0743s/iter; left time: 1219.0835s\n",
      "\titers: 200, epoch: 27 | loss: 0.0760914\n",
      "\tspeed: 0.0404s/iter; left time: 659.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0773498 Vali Loss: 0.0905446 Test Loss: 0.1034297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0765770\n",
      "\tspeed: 0.0744s/iter; left time: 1203.1410s\n",
      "\titers: 200, epoch: 28 | loss: 0.0764705\n",
      "\tspeed: 0.0406s/iter; left time: 652.0977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0774625 Vali Loss: 0.0907428 Test Loss: 0.1031926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0801089\n",
      "\tspeed: 0.0742s/iter; left time: 1184.2724s\n",
      "\titers: 200, epoch: 29 | loss: 0.0829091\n",
      "\tspeed: 0.0405s/iter; left time: 641.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771658 Vali Loss: 0.0908485 Test Loss: 0.1035190\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0761231\n",
      "\tspeed: 0.0744s/iter; left time: 1171.0462s\n",
      "\titers: 200, epoch: 30 | loss: 0.0838616\n",
      "\tspeed: 0.0405s/iter; left time: 632.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0771273 Vali Loss: 0.0904082 Test Loss: 0.1034668\n",
      "Validation loss decreased (0.090520 --> 0.090408).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0791246\n",
      "\tspeed: 0.0746s/iter; left time: 1156.6156s\n",
      "\titers: 200, epoch: 31 | loss: 0.0760335\n",
      "\tspeed: 0.0404s/iter; left time: 622.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0771556 Vali Loss: 0.0904834 Test Loss: 0.1033723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0727148\n",
      "\tspeed: 0.0739s/iter; left time: 1129.9757s\n",
      "\titers: 200, epoch: 32 | loss: 0.0771118\n",
      "\tspeed: 0.0405s/iter; left time: 615.4426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0770119 Vali Loss: 0.0905958 Test Loss: 0.1032845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780054\n",
      "\tspeed: 0.0745s/iter; left time: 1122.0629s\n",
      "\titers: 200, epoch: 33 | loss: 0.0763030\n",
      "\tspeed: 0.0404s/iter; left time: 604.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0770482 Vali Loss: 0.0905138 Test Loss: 0.1034147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0723855\n",
      "\tspeed: 0.0740s/iter; left time: 1098.3092s\n",
      "\titers: 200, epoch: 34 | loss: 0.0809077\n",
      "\tspeed: 0.0405s/iter; left time: 597.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0769784 Vali Loss: 0.0901652 Test Loss: 0.1032317\n",
      "Validation loss decreased (0.090408 --> 0.090165).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753601\n",
      "\tspeed: 0.0743s/iter; left time: 1085.6582s\n",
      "\titers: 200, epoch: 35 | loss: 0.0833676\n",
      "\tspeed: 0.0404s/iter; left time: 586.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0770012 Vali Loss: 0.0904131 Test Loss: 0.1032534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0741394\n",
      "\tspeed: 0.0736s/iter; left time: 1059.4413s\n",
      "\titers: 200, epoch: 36 | loss: 0.0772207\n",
      "\tspeed: 0.0404s/iter; left time: 578.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768503 Vali Loss: 0.0902097 Test Loss: 0.1032458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0748613\n",
      "\tspeed: 0.0738s/iter; left time: 1045.4778s\n",
      "\titers: 200, epoch: 37 | loss: 0.0764078\n",
      "\tspeed: 0.0404s/iter; left time: 569.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768296 Vali Loss: 0.0906790 Test Loss: 0.1035006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0836533\n",
      "\tspeed: 0.0739s/iter; left time: 1030.3494s\n",
      "\titers: 200, epoch: 38 | loss: 0.0738607\n",
      "\tspeed: 0.0405s/iter; left time: 561.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0768080 Vali Loss: 0.0905389 Test Loss: 0.1032715\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0852324\n",
      "\tspeed: 0.0734s/iter; left time: 1008.1749s\n",
      "\titers: 200, epoch: 39 | loss: 0.0836052\n",
      "\tspeed: 0.0404s/iter; left time: 551.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0769123 Vali Loss: 0.0903165 Test Loss: 0.1031685\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0723093\n",
      "\tspeed: 0.0737s/iter; left time: 995.6857s\n",
      "\titers: 200, epoch: 40 | loss: 0.0770771\n",
      "\tspeed: 0.0405s/iter; left time: 542.2184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0767563 Vali Loss: 0.0902461 Test Loss: 0.1032339\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0769785\n",
      "\tspeed: 0.0738s/iter; left time: 979.6360s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785568\n",
      "\tspeed: 0.0404s/iter; left time: 532.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768789 Vali Loss: 0.0903825 Test Loss: 0.1032286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765508\n",
      "\tspeed: 0.0740s/iter; left time: 966.8555s\n",
      "\titers: 200, epoch: 42 | loss: 0.0757153\n",
      "\tspeed: 0.0407s/iter; left time: 526.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0767883 Vali Loss: 0.0905485 Test Loss: 0.1033848\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0777456\n",
      "\tspeed: 0.0736s/iter; left time: 944.6847s\n",
      "\titers: 200, epoch: 43 | loss: 0.0803093\n",
      "\tspeed: 0.0404s/iter; left time: 514.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0768418 Vali Loss: 0.0903485 Test Loss: 0.1032215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0777099\n",
      "\tspeed: 0.0737s/iter; left time: 929.3859s\n",
      "\titers: 200, epoch: 44 | loss: 0.0776393\n",
      "\tspeed: 0.0404s/iter; left time: 505.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0767603 Vali Loss: 0.0905746 Test Loss: 0.1033903\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02546694502234459, rmse:0.1595836579799652, mae:0.10323171317577362, rse:0.5505183935165405\n",
      "Intermediate time for GB and pred_len 24: 00h:17m:10.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2754908\n",
      "\tspeed: 0.0654s/iter; left time: 1445.2351s\n",
      "\titers: 200, epoch: 1 | loss: 0.2565268\n",
      "\tspeed: 0.0408s/iter; left time: 896.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.2785139 Vali Loss: 0.2301577 Test Loss: 0.2489777\n",
      "Validation loss decreased (inf --> 0.230158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1454410\n",
      "\tspeed: 0.0743s/iter; left time: 1626.4319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1294792\n",
      "\tspeed: 0.0408s/iter; left time: 889.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1582182 Vali Loss: 0.1259280 Test Loss: 0.1505259\n",
      "Validation loss decreased (0.230158 --> 0.125928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139631\n",
      "\tspeed: 0.0758s/iter; left time: 1642.2493s\n",
      "\titers: 200, epoch: 3 | loss: 0.1146949\n",
      "\tspeed: 0.0407s/iter; left time: 876.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1160379 Vali Loss: 0.1217796 Test Loss: 0.1469357\n",
      "Validation loss decreased (0.125928 --> 0.121780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1060906\n",
      "\tspeed: 0.0755s/iter; left time: 1618.8844s\n",
      "\titers: 200, epoch: 4 | loss: 0.1110405\n",
      "\tspeed: 0.0407s/iter; left time: 869.0712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1105263 Vali Loss: 0.1205399 Test Loss: 0.1479875\n",
      "Validation loss decreased (0.121780 --> 0.120540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105473\n",
      "\tspeed: 0.0755s/iter; left time: 1600.8842s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073875\n",
      "\tspeed: 0.0408s/iter; left time: 860.5413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1084831 Vali Loss: 0.1211721 Test Loss: 0.1462333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060356\n",
      "\tspeed: 0.0748s/iter; left time: 1570.8243s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084735\n",
      "\tspeed: 0.0409s/iter; left time: 855.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1067980 Vali Loss: 0.1211017 Test Loss: 0.1448717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1049255\n",
      "\tspeed: 0.0742s/iter; left time: 1540.1646s\n",
      "\titers: 200, epoch: 7 | loss: 0.1024340\n",
      "\tspeed: 0.0408s/iter; left time: 843.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1059185 Vali Loss: 0.1197927 Test Loss: 0.1431326\n",
      "Validation loss decreased (0.120540 --> 0.119793).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1077000\n",
      "\tspeed: 0.0756s/iter; left time: 1552.6685s\n",
      "\titers: 200, epoch: 8 | loss: 0.1062740\n",
      "\tspeed: 0.0408s/iter; left time: 833.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1051765 Vali Loss: 0.1208388 Test Loss: 0.1449344\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044981\n",
      "\tspeed: 0.0745s/iter; left time: 1514.6372s\n",
      "\titers: 200, epoch: 9 | loss: 0.1011425\n",
      "\tspeed: 0.0409s/iter; left time: 827.9057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1047338 Vali Loss: 0.1204256 Test Loss: 0.1450119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024128\n",
      "\tspeed: 0.0751s/iter; left time: 1509.6850s\n",
      "\titers: 200, epoch: 10 | loss: 0.1052173\n",
      "\tspeed: 0.0407s/iter; left time: 813.6001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1041979 Vali Loss: 0.1203746 Test Loss: 0.1434776\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1026772\n",
      "\tspeed: 0.0750s/iter; left time: 1491.2236s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031066\n",
      "\tspeed: 0.0408s/iter; left time: 806.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1035710 Vali Loss: 0.1205041 Test Loss: 0.1424923\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012086\n",
      "\tspeed: 0.0746s/iter; left time: 1466.9986s\n",
      "\titers: 200, epoch: 12 | loss: 0.1012537\n",
      "\tspeed: 0.0407s/iter; left time: 796.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1031444 Vali Loss: 0.1206255 Test Loss: 0.1456862\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988313\n",
      "\tspeed: 0.0750s/iter; left time: 1458.6676s\n",
      "\titers: 200, epoch: 13 | loss: 0.1054351\n",
      "\tspeed: 0.0407s/iter; left time: 787.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1028723 Vali Loss: 0.1207204 Test Loss: 0.1443202\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1001708\n",
      "\tspeed: 0.0750s/iter; left time: 1440.9286s\n",
      "\titers: 200, epoch: 14 | loss: 0.1036020\n",
      "\tspeed: 0.0407s/iter; left time: 778.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1025796 Vali Loss: 0.1213824 Test Loss: 0.1413605\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1079437\n",
      "\tspeed: 0.0744s/iter; left time: 1412.1922s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065903\n",
      "\tspeed: 0.0407s/iter; left time: 768.8275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1024036 Vali Loss: 0.1207993 Test Loss: 0.1439709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1031587\n",
      "\tspeed: 0.0742s/iter; left time: 1393.1864s\n",
      "\titers: 200, epoch: 16 | loss: 0.0969950\n",
      "\tspeed: 0.0407s/iter; left time: 760.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1019742 Vali Loss: 0.1192834 Test Loss: 0.1435636\n",
      "Validation loss decreased (0.119793 --> 0.119283).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1015605\n",
      "\tspeed: 0.0743s/iter; left time: 1377.5497s\n",
      "\titers: 200, epoch: 17 | loss: 0.1000266\n",
      "\tspeed: 0.0407s/iter; left time: 751.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1017171 Vali Loss: 0.1209069 Test Loss: 0.1445591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034859\n",
      "\tspeed: 0.0737s/iter; left time: 1349.9659s\n",
      "\titers: 200, epoch: 18 | loss: 0.1006415\n",
      "\tspeed: 0.0408s/iter; left time: 743.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1016131 Vali Loss: 0.1202661 Test Loss: 0.1447202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0975137\n",
      "\tspeed: 0.0741s/iter; left time: 1341.5279s\n",
      "\titers: 200, epoch: 19 | loss: 0.1048678\n",
      "\tspeed: 0.0408s/iter; left time: 734.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1013461 Vali Loss: 0.1196784 Test Loss: 0.1444775\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0967539\n",
      "\tspeed: 0.0740s/iter; left time: 1323.4880s\n",
      "\titers: 200, epoch: 20 | loss: 0.1014193\n",
      "\tspeed: 0.0408s/iter; left time: 725.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1012372 Vali Loss: 0.1201976 Test Loss: 0.1447031\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1000276\n",
      "\tspeed: 0.0744s/iter; left time: 1314.8539s\n",
      "\titers: 200, epoch: 21 | loss: 0.1064060\n",
      "\tspeed: 0.0407s/iter; left time: 714.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1009980 Vali Loss: 0.1195866 Test Loss: 0.1452566\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0979460\n",
      "\tspeed: 0.0738s/iter; left time: 1286.8706s\n",
      "\titers: 200, epoch: 22 | loss: 0.0992387\n",
      "\tspeed: 0.0408s/iter; left time: 708.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1010185 Vali Loss: 0.1197461 Test Loss: 0.1442865\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0942505\n",
      "\tspeed: 0.0739s/iter; left time: 1271.8307s\n",
      "\titers: 200, epoch: 23 | loss: 0.0990180\n",
      "\tspeed: 0.0410s/iter; left time: 702.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1007635 Vali Loss: 0.1201730 Test Loss: 0.1457032\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0997986\n",
      "\tspeed: 0.0738s/iter; left time: 1254.8725s\n",
      "\titers: 200, epoch: 24 | loss: 0.1051661\n",
      "\tspeed: 0.0407s/iter; left time: 687.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1006523 Vali Loss: 0.1204499 Test Loss: 0.1449772\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0943325\n",
      "\tspeed: 0.0744s/iter; left time: 1248.4015s\n",
      "\titers: 200, epoch: 25 | loss: 0.1028278\n",
      "\tspeed: 0.0408s/iter; left time: 679.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1005114 Vali Loss: 0.1195987 Test Loss: 0.1457044\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0993995\n",
      "\tspeed: 0.0738s/iter; left time: 1221.8400s\n",
      "\titers: 200, epoch: 26 | loss: 0.1025434\n",
      "\tspeed: 0.0407s/iter; left time: 669.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1004969 Vali Loss: 0.1198426 Test Loss: 0.1459493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04348594695329666, rmse:0.20853284001350403, mae:0.14356358349323273, rse:0.7211356163024902\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2774166\n",
      "\tspeed: 0.0426s/iter; left time: 942.1830s\n",
      "\titers: 200, epoch: 1 | loss: 0.2675685\n",
      "\tspeed: 0.0408s/iter; left time: 898.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.2809886 Vali Loss: 0.2336099 Test Loss: 0.2500508\n",
      "Validation loss decreased (inf --> 0.233610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1459654\n",
      "\tspeed: 0.0762s/iter; left time: 1667.1326s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273764\n",
      "\tspeed: 0.0411s/iter; left time: 896.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1587790 Vali Loss: 0.1263587 Test Loss: 0.1510657\n",
      "Validation loss decreased (0.233610 --> 0.126359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1151451\n",
      "\tspeed: 0.0761s/iter; left time: 1648.5984s\n",
      "\titers: 200, epoch: 3 | loss: 0.1132580\n",
      "\tspeed: 0.0407s/iter; left time: 876.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1159257 Vali Loss: 0.1221918 Test Loss: 0.1485164\n",
      "Validation loss decreased (0.126359 --> 0.122192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162400\n",
      "\tspeed: 0.0761s/iter; left time: 1630.1607s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102432\n",
      "\tspeed: 0.0408s/iter; left time: 870.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1102180 Vali Loss: 0.1223790 Test Loss: 0.1495408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053681\n",
      "\tspeed: 0.0759s/iter; left time: 1610.8944s\n",
      "\titers: 200, epoch: 5 | loss: 0.1080542\n",
      "\tspeed: 0.0408s/iter; left time: 861.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1080120 Vali Loss: 0.1205955 Test Loss: 0.1468638\n",
      "Validation loss decreased (0.122192 --> 0.120595).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1048465\n",
      "\tspeed: 0.0758s/iter; left time: 1592.0341s\n",
      "\titers: 200, epoch: 6 | loss: 0.1037291\n",
      "\tspeed: 0.0408s/iter; left time: 852.3388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1066948 Vali Loss: 0.1201176 Test Loss: 0.1445497\n",
      "Validation loss decreased (0.120595 --> 0.120118).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026185\n",
      "\tspeed: 0.0759s/iter; left time: 1577.0352s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106706\n",
      "\tspeed: 0.0408s/iter; left time: 842.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1056956 Vali Loss: 0.1220439 Test Loss: 0.1470570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1022454\n",
      "\tspeed: 0.0753s/iter; left time: 1546.2830s\n",
      "\titers: 200, epoch: 8 | loss: 0.1057987\n",
      "\tspeed: 0.0408s/iter; left time: 833.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1047436 Vali Loss: 0.1197518 Test Loss: 0.1431227\n",
      "Validation loss decreased (0.120118 --> 0.119752).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0995139\n",
      "\tspeed: 0.0760s/iter; left time: 1543.9720s\n",
      "\titers: 200, epoch: 9 | loss: 0.1068991\n",
      "\tspeed: 0.0407s/iter; left time: 823.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1040069 Vali Loss: 0.1207591 Test Loss: 0.1448716\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0977267\n",
      "\tspeed: 0.0754s/iter; left time: 1515.2548s\n",
      "\titers: 200, epoch: 10 | loss: 0.1050342\n",
      "\tspeed: 0.0407s/iter; left time: 813.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1034888 Vali Loss: 0.1209808 Test Loss: 0.1457036\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1062801\n",
      "\tspeed: 0.0751s/iter; left time: 1492.5965s\n",
      "\titers: 200, epoch: 11 | loss: 0.1037657\n",
      "\tspeed: 0.0408s/iter; left time: 806.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1032361 Vali Loss: 0.1218010 Test Loss: 0.1467660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1031072\n",
      "\tspeed: 0.0764s/iter; left time: 1502.4624s\n",
      "\titers: 200, epoch: 12 | loss: 0.1042846\n",
      "\tspeed: 0.0408s/iter; left time: 797.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1025889 Vali Loss: 0.1222248 Test Loss: 0.1471041\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004958\n",
      "\tspeed: 0.0760s/iter; left time: 1478.1091s\n",
      "\titers: 200, epoch: 13 | loss: 0.1037003\n",
      "\tspeed: 0.0407s/iter; left time: 787.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1026253 Vali Loss: 0.1218507 Test Loss: 0.1469564\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0960027\n",
      "\tspeed: 0.0748s/iter; left time: 1437.5752s\n",
      "\titers: 200, epoch: 14 | loss: 0.1035357\n",
      "\tspeed: 0.0407s/iter; left time: 778.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1021841 Vali Loss: 0.1208755 Test Loss: 0.1459521\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1015870\n",
      "\tspeed: 0.0750s/iter; left time: 1424.3674s\n",
      "\titers: 200, epoch: 15 | loss: 0.1023352\n",
      "\tspeed: 0.0408s/iter; left time: 770.9132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1016365 Vali Loss: 0.1208185 Test Loss: 0.1465824\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990154\n",
      "\tspeed: 0.0753s/iter; left time: 1414.3787s\n",
      "\titers: 200, epoch: 16 | loss: 0.1074008\n",
      "\tspeed: 0.0407s/iter; left time: 760.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1014939 Vali Loss: 0.1214339 Test Loss: 0.1468978\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1053690\n",
      "\tspeed: 0.0750s/iter; left time: 1392.0747s\n",
      "\titers: 200, epoch: 17 | loss: 0.1010550\n",
      "\tspeed: 0.0408s/iter; left time: 752.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1012388 Vali Loss: 0.1209148 Test Loss: 0.1468553\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0994772\n",
      "\tspeed: 0.0755s/iter; left time: 1383.4358s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990921\n",
      "\tspeed: 0.0407s/iter; left time: 742.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1008607 Vali Loss: 0.1210824 Test Loss: 0.1476732\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042964570224285126, rmse:0.20727896690368652, mae:0.14312276244163513, rse:0.7167995572090149\n",
      "Intermediate time for GB and pred_len 96: 00h:08m:42.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2716153\n",
      "\tspeed: 0.0660s/iter; left time: 1459.4963s\n",
      "\titers: 200, epoch: 1 | loss: 0.2638517\n",
      "\tspeed: 0.0412s/iter; left time: 907.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.2787672 Vali Loss: 0.2309910 Test Loss: 0.2493199\n",
      "Validation loss decreased (inf --> 0.230991).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443525\n",
      "\tspeed: 0.0764s/iter; left time: 1672.1266s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273726\n",
      "\tspeed: 0.0413s/iter; left time: 898.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1594456 Vali Loss: 0.1297770 Test Loss: 0.1556951\n",
      "Validation loss decreased (0.230991 --> 0.129777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1201734\n",
      "\tspeed: 0.0771s/iter; left time: 1669.4693s\n",
      "\titers: 200, epoch: 3 | loss: 0.1219832\n",
      "\tspeed: 0.0413s/iter; left time: 890.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1194605 Vali Loss: 0.1255238 Test Loss: 0.1545679\n",
      "Validation loss decreased (0.129777 --> 0.125524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1181283\n",
      "\tspeed: 0.0761s/iter; left time: 1632.1475s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108795\n",
      "\tspeed: 0.0413s/iter; left time: 881.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1145101 Vali Loss: 0.1246590 Test Loss: 0.1540057\n",
      "Validation loss decreased (0.125524 --> 0.124659).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1092665\n",
      "\tspeed: 0.0760s/iter; left time: 1612.9568s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132531\n",
      "\tspeed: 0.0412s/iter; left time: 870.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1123378 Vali Loss: 0.1265095 Test Loss: 0.1549340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1059428\n",
      "\tspeed: 0.0755s/iter; left time: 1584.5224s\n",
      "\titers: 200, epoch: 6 | loss: 0.1128200\n",
      "\tspeed: 0.0412s/iter; left time: 859.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1113528 Vali Loss: 0.1253730 Test Loss: 0.1533087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1118887\n",
      "\tspeed: 0.0756s/iter; left time: 1569.2793s\n",
      "\titers: 200, epoch: 7 | loss: 0.1120432\n",
      "\tspeed: 0.0412s/iter; left time: 852.2228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1100923 Vali Loss: 0.1250416 Test Loss: 0.1485461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1090592\n",
      "\tspeed: 0.0747s/iter; left time: 1534.7930s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068995\n",
      "\tspeed: 0.0414s/iter; left time: 847.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1091959 Vali Loss: 0.1256379 Test Loss: 0.1487788\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1106925\n",
      "\tspeed: 0.0754s/iter; left time: 1531.5013s\n",
      "\titers: 200, epoch: 9 | loss: 0.1068321\n",
      "\tspeed: 0.0414s/iter; left time: 836.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1085150 Vali Loss: 0.1243162 Test Loss: 0.1471283\n",
      "Validation loss decreased (0.124659 --> 0.124316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067732\n",
      "\tspeed: 0.0772s/iter; left time: 1552.5604s\n",
      "\titers: 200, epoch: 10 | loss: 0.1087037\n",
      "\tspeed: 0.0412s/iter; left time: 824.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1080044 Vali Loss: 0.1248898 Test Loss: 0.1474849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1124478\n",
      "\tspeed: 0.0755s/iter; left time: 1501.3308s\n",
      "\titers: 200, epoch: 11 | loss: 0.1083871\n",
      "\tspeed: 0.0413s/iter; left time: 816.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1076199 Vali Loss: 0.1253187 Test Loss: 0.1480367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1098340\n",
      "\tspeed: 0.0750s/iter; left time: 1473.6767s\n",
      "\titers: 200, epoch: 12 | loss: 0.1065531\n",
      "\tspeed: 0.0413s/iter; left time: 807.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1070364 Vali Loss: 0.1242883 Test Loss: 0.1481413\n",
      "Validation loss decreased (0.124316 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1028681\n",
      "\tspeed: 0.0763s/iter; left time: 1482.8800s\n",
      "\titers: 200, epoch: 13 | loss: 0.1073965\n",
      "\tspeed: 0.0413s/iter; left time: 798.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1067161 Vali Loss: 0.1250881 Test Loss: 0.1485085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1018266\n",
      "\tspeed: 0.0753s/iter; left time: 1447.5265s\n",
      "\titers: 200, epoch: 14 | loss: 0.1055653\n",
      "\tspeed: 0.0416s/iter; left time: 796.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1065856 Vali Loss: 0.1251107 Test Loss: 0.1492371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1073245\n",
      "\tspeed: 0.0753s/iter; left time: 1430.5092s\n",
      "\titers: 200, epoch: 15 | loss: 0.1032797\n",
      "\tspeed: 0.0413s/iter; left time: 780.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1062499 Vali Loss: 0.1251109 Test Loss: 0.1481002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1035097\n",
      "\tspeed: 0.0758s/iter; left time: 1423.5704s\n",
      "\titers: 200, epoch: 16 | loss: 0.1055012\n",
      "\tspeed: 0.0413s/iter; left time: 771.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1059731 Vali Loss: 0.1256487 Test Loss: 0.1495054\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1115270\n",
      "\tspeed: 0.0757s/iter; left time: 1404.3685s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086517\n",
      "\tspeed: 0.0413s/iter; left time: 761.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1058377 Vali Loss: 0.1241639 Test Loss: 0.1486776\n",
      "Validation loss decreased (0.124288 --> 0.124164).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1087099\n",
      "\tspeed: 0.0764s/iter; left time: 1400.1928s\n",
      "\titers: 200, epoch: 18 | loss: 0.1050047\n",
      "\tspeed: 0.0412s/iter; left time: 751.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1054555 Vali Loss: 0.1247823 Test Loss: 0.1497302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1028927\n",
      "\tspeed: 0.0755s/iter; left time: 1366.3546s\n",
      "\titers: 200, epoch: 19 | loss: 0.1060708\n",
      "\tspeed: 0.0414s/iter; left time: 745.0348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1052858 Vali Loss: 0.1249171 Test Loss: 0.1500403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1049049\n",
      "\tspeed: 0.0759s/iter; left time: 1358.1418s\n",
      "\titers: 200, epoch: 20 | loss: 0.1012393\n",
      "\tspeed: 0.0412s/iter; left time: 733.2661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1053540 Vali Loss: 0.1261377 Test Loss: 0.1504158\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1063648\n",
      "\tspeed: 0.0754s/iter; left time: 1331.4070s\n",
      "\titers: 200, epoch: 21 | loss: 0.1047757\n",
      "\tspeed: 0.0413s/iter; left time: 725.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1052722 Vali Loss: 0.1249897 Test Loss: 0.1501012\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1041152\n",
      "\tspeed: 0.0755s/iter; left time: 1315.8241s\n",
      "\titers: 200, epoch: 22 | loss: 0.1084766\n",
      "\tspeed: 0.0413s/iter; left time: 716.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1049150 Vali Loss: 0.1259064 Test Loss: 0.1513341\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1038138\n",
      "\tspeed: 0.0753s/iter; left time: 1295.6782s\n",
      "\titers: 200, epoch: 23 | loss: 0.1041932\n",
      "\tspeed: 0.0412s/iter; left time: 706.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1048258 Vali Loss: 0.1255358 Test Loss: 0.1509897\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1022567\n",
      "\tspeed: 0.0755s/iter; left time: 1282.2932s\n",
      "\titers: 200, epoch: 24 | loss: 0.1052244\n",
      "\tspeed: 0.0412s/iter; left time: 696.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1046484 Vali Loss: 0.1249385 Test Loss: 0.1507090\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1076378\n",
      "\tspeed: 0.0756s/iter; left time: 1267.7721s\n",
      "\titers: 200, epoch: 25 | loss: 0.1043807\n",
      "\tspeed: 0.0411s/iter; left time: 684.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1046707 Vali Loss: 0.1248684 Test Loss: 0.1510690\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1014151\n",
      "\tspeed: 0.0754s/iter; left time: 1248.1725s\n",
      "\titers: 200, epoch: 26 | loss: 0.1049445\n",
      "\tspeed: 0.0410s/iter; left time: 675.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1045685 Vali Loss: 0.1245818 Test Loss: 0.1509740\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1041414\n",
      "\tspeed: 0.0753s/iter; left time: 1229.0372s\n",
      "\titers: 200, epoch: 27 | loss: 0.1036496\n",
      "\tspeed: 0.0412s/iter; left time: 668.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1043760 Vali Loss: 0.1253036 Test Loss: 0.1515556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04521861672401428, rmse:0.2126466929912567, mae:0.14867757260799408, rse:0.7372766137123108\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812609\n",
      "\tspeed: 0.0430s/iter; left time: 950.3421s\n",
      "\titers: 200, epoch: 1 | loss: 0.2743198\n",
      "\tspeed: 0.0411s/iter; left time: 903.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.2822524 Vali Loss: 0.2363064 Test Loss: 0.2515047\n",
      "Validation loss decreased (inf --> 0.236306).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1393131\n",
      "\tspeed: 0.0779s/iter; left time: 1704.9258s\n",
      "\titers: 200, epoch: 2 | loss: 0.1262606\n",
      "\tspeed: 0.0410s/iter; left time: 893.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1575504 Vali Loss: 0.1273091 Test Loss: 0.1528630\n",
      "Validation loss decreased (0.236306 --> 0.127309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138505\n",
      "\tspeed: 0.0777s/iter; left time: 1682.9884s\n",
      "\titers: 200, epoch: 3 | loss: 0.1161965\n",
      "\tspeed: 0.0412s/iter; left time: 887.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1181751 Vali Loss: 0.1289422 Test Loss: 0.1709879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1163539\n",
      "\tspeed: 0.0759s/iter; left time: 1626.9556s\n",
      "\titers: 200, epoch: 4 | loss: 0.1155107\n",
      "\tspeed: 0.0410s/iter; left time: 874.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1139019 Vali Loss: 0.1297381 Test Loss: 0.1703210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1137907\n",
      "\tspeed: 0.0755s/iter; left time: 1602.5071s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132444\n",
      "\tspeed: 0.0412s/iter; left time: 868.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1125670 Vali Loss: 0.1281471 Test Loss: 0.1688897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1104800\n",
      "\tspeed: 0.0765s/iter; left time: 1606.2500s\n",
      "\titers: 200, epoch: 6 | loss: 0.1097190\n",
      "\tspeed: 0.0410s/iter; left time: 857.2504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1108655 Vali Loss: 0.1258683 Test Loss: 0.1585473\n",
      "Validation loss decreased (0.127309 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1140727\n",
      "\tspeed: 0.0764s/iter; left time: 1587.1705s\n",
      "\titers: 200, epoch: 7 | loss: 0.1073268\n",
      "\tspeed: 0.0410s/iter; left time: 847.6236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1100208 Vali Loss: 0.1245751 Test Loss: 0.1522525\n",
      "Validation loss decreased (0.125868 --> 0.124575).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1089322\n",
      "\tspeed: 0.0769s/iter; left time: 1579.9834s\n",
      "\titers: 200, epoch: 8 | loss: 0.1053236\n",
      "\tspeed: 0.0411s/iter; left time: 841.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1093476 Vali Loss: 0.1262100 Test Loss: 0.1514145\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1051588\n",
      "\tspeed: 0.0755s/iter; left time: 1534.4033s\n",
      "\titers: 200, epoch: 9 | loss: 0.1080333\n",
      "\tspeed: 0.0410s/iter; left time: 828.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1085658 Vali Loss: 0.1274492 Test Loss: 0.1521188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1053995\n",
      "\tspeed: 0.0756s/iter; left time: 1519.5446s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076154\n",
      "\tspeed: 0.0412s/iter; left time: 823.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1079732 Vali Loss: 0.1264845 Test Loss: 0.1513946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071782\n",
      "\tspeed: 0.0760s/iter; left time: 1510.1994s\n",
      "\titers: 200, epoch: 11 | loss: 0.1097906\n",
      "\tspeed: 0.0410s/iter; left time: 810.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1073974 Vali Loss: 0.1266323 Test Loss: 0.1527154\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1083495\n",
      "\tspeed: 0.0760s/iter; left time: 1494.2791s\n",
      "\titers: 200, epoch: 12 | loss: 0.1082444\n",
      "\tspeed: 0.0410s/iter; left time: 802.4627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1070229 Vali Loss: 0.1274204 Test Loss: 0.1519750\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1112958\n",
      "\tspeed: 0.0756s/iter; left time: 1470.2463s\n",
      "\titers: 200, epoch: 13 | loss: 0.1051681\n",
      "\tspeed: 0.0411s/iter; left time: 794.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1067402 Vali Loss: 0.1246966 Test Loss: 0.1504878\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1047404\n",
      "\tspeed: 0.0759s/iter; left time: 1458.2581s\n",
      "\titers: 200, epoch: 14 | loss: 0.1110080\n",
      "\tspeed: 0.0411s/iter; left time: 785.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1063147 Vali Loss: 0.1260417 Test Loss: 0.1516709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1065945\n",
      "\tspeed: 0.0759s/iter; left time: 1441.5429s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034605\n",
      "\tspeed: 0.0410s/iter; left time: 775.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1061472 Vali Loss: 0.1259253 Test Loss: 0.1521753\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1045114\n",
      "\tspeed: 0.0758s/iter; left time: 1423.7237s\n",
      "\titers: 200, epoch: 16 | loss: 0.1061935\n",
      "\tspeed: 0.0410s/iter; left time: 766.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1057498 Vali Loss: 0.1266438 Test Loss: 0.1531464\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1039447\n",
      "\tspeed: 0.0756s/iter; left time: 1402.3167s\n",
      "\titers: 200, epoch: 17 | loss: 0.1046212\n",
      "\tspeed: 0.0410s/iter; left time: 756.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1054660 Vali Loss: 0.1257910 Test Loss: 0.1528551\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05040593817830086, rmse:0.22451266646385193, mae:0.1522524505853653, rse:0.7784176468849182\n",
      "Intermediate time for GB and pred_len 168: 00h:08m:49.69s\n",
      "Intermediate time for GB: 00h:34m:42.33s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2708257\n",
      "\tspeed: 0.0412s/iter; left time: 919.6909s\n",
      "\titers: 200, epoch: 1 | loss: 0.2622724\n",
      "\tspeed: 0.0173s/iter; left time: 382.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.2779982 Vali Loss: 0.2074505 Test Loss: 0.2332473\n",
      "Validation loss decreased (inf --> 0.207451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1510847\n",
      "\tspeed: 0.0382s/iter; left time: 843.2884s\n",
      "\titers: 200, epoch: 2 | loss: 0.1117425\n",
      "\tspeed: 0.0192s/iter; left time: 422.6661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1574519 Vali Loss: 0.0915035 Test Loss: 0.0991069\n",
      "Validation loss decreased (0.207451 --> 0.091504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1003834\n",
      "\tspeed: 0.0364s/iter; left time: 794.6604s\n",
      "\titers: 200, epoch: 3 | loss: 0.0931744\n",
      "\tspeed: 0.0172s/iter; left time: 374.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1002942 Vali Loss: 0.0830410 Test Loss: 0.0912976\n",
      "Validation loss decreased (0.091504 --> 0.083041).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863603\n",
      "\tspeed: 0.0357s/iter; left time: 771.4233s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836940\n",
      "\tspeed: 0.0176s/iter; left time: 378.6460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0864073 Vali Loss: 0.0718561 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.083041 --> 0.071856).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736417\n",
      "\tspeed: 0.0358s/iter; left time: 766.0545s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762774\n",
      "\tspeed: 0.0175s/iter; left time: 372.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0774616 Vali Loss: 0.0680598 Test Loss: 0.0780765\n",
      "Validation loss decreased (0.071856 --> 0.068060).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711824\n",
      "\tspeed: 0.0359s/iter; left time: 761.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742073\n",
      "\tspeed: 0.0172s/iter; left time: 363.5269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0727056 Vali Loss: 0.0657509 Test Loss: 0.0764956\n",
      "Validation loss decreased (0.068060 --> 0.065751).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758830\n",
      "\tspeed: 0.0357s/iter; left time: 748.3752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721870\n",
      "\tspeed: 0.0172s/iter; left time: 358.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0708751 Vali Loss: 0.0660416 Test Loss: 0.0778710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0714698\n",
      "\tspeed: 0.0356s/iter; left time: 737.0937s\n",
      "\titers: 200, epoch: 8 | loss: 0.0658485\n",
      "\tspeed: 0.0174s/iter; left time: 358.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0689583 Vali Loss: 0.0642446 Test Loss: 0.0767666\n",
      "Validation loss decreased (0.065751 --> 0.064245).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0694290\n",
      "\tspeed: 0.0362s/iter; left time: 743.3197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0644000\n",
      "\tspeed: 0.0175s/iter; left time: 356.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0676455 Vali Loss: 0.0636601 Test Loss: 0.0770834\n",
      "Validation loss decreased (0.064245 --> 0.063660).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700247\n",
      "\tspeed: 0.0376s/iter; left time: 761.9303s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655249\n",
      "\tspeed: 0.0174s/iter; left time: 351.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0667840 Vali Loss: 0.0626065 Test Loss: 0.0754004\n",
      "Validation loss decreased (0.063660 --> 0.062607).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672422\n",
      "\tspeed: 0.0377s/iter; left time: 756.5545s\n",
      "\titers: 200, epoch: 11 | loss: 0.0646161\n",
      "\tspeed: 0.0173s/iter; left time: 345.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0662278 Vali Loss: 0.0625945 Test Loss: 0.0761153\n",
      "Validation loss decreased (0.062607 --> 0.062595).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0648139\n",
      "\tspeed: 0.0356s/iter; left time: 707.1482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0664951\n",
      "\tspeed: 0.0172s/iter; left time: 339.6006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0654111 Vali Loss: 0.0617924 Test Loss: 0.0757005\n",
      "Validation loss decreased (0.062595 --> 0.061792).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0622444\n",
      "\tspeed: 0.0356s/iter; left time: 698.7937s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599254\n",
      "\tspeed: 0.0203s/iter; left time: 396.4701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0647105 Vali Loss: 0.0609597 Test Loss: 0.0746203\n",
      "Validation loss decreased (0.061792 --> 0.060960).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0647993\n",
      "\tspeed: 0.0372s/iter; left time: 721.4152s\n",
      "\titers: 200, epoch: 14 | loss: 0.0610652\n",
      "\tspeed: 0.0174s/iter; left time: 336.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0643186 Vali Loss: 0.0609952 Test Loss: 0.0744172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0624425\n",
      "\tspeed: 0.0353s/iter; left time: 676.6652s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644481\n",
      "\tspeed: 0.0172s/iter; left time: 328.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0640143 Vali Loss: 0.0605438 Test Loss: 0.0741187\n",
      "Validation loss decreased (0.060960 --> 0.060544).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0600056\n",
      "\tspeed: 0.0354s/iter; left time: 670.0495s\n",
      "\titers: 200, epoch: 16 | loss: 0.0635128\n",
      "\tspeed: 0.0191s/iter; left time: 359.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0634908 Vali Loss: 0.0608249 Test Loss: 0.0749933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0606074\n",
      "\tspeed: 0.0360s/iter; left time: 673.3462s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622914\n",
      "\tspeed: 0.0176s/iter; left time: 327.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0630818 Vali Loss: 0.0603432 Test Loss: 0.0748148\n",
      "Validation loss decreased (0.060544 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0615552\n",
      "\tspeed: 0.0364s/iter; left time: 673.3772s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634372\n",
      "\tspeed: 0.0175s/iter; left time: 321.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0628284 Vali Loss: 0.0602996 Test Loss: 0.0743554\n",
      "Validation loss decreased (0.060343 --> 0.060300).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0640946\n",
      "\tspeed: 0.0366s/iter; left time: 668.3454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0632057\n",
      "\tspeed: 0.0173s/iter; left time: 314.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628115 Vali Loss: 0.0604891 Test Loss: 0.0746229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0630374\n",
      "\tspeed: 0.0354s/iter; left time: 639.4019s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633529\n",
      "\tspeed: 0.0172s/iter; left time: 307.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0625326 Vali Loss: 0.0596575 Test Loss: 0.0737812\n",
      "Validation loss decreased (0.060300 --> 0.059657).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0616223\n",
      "\tspeed: 0.0395s/iter; left time: 703.1604s\n",
      "\titers: 200, epoch: 21 | loss: 0.0649464\n",
      "\tspeed: 0.0183s/iter; left time: 323.6225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0621714 Vali Loss: 0.0597556 Test Loss: 0.0742557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0627824\n",
      "\tspeed: 0.0371s/iter; left time: 652.2355s\n",
      "\titers: 200, epoch: 22 | loss: 0.0598262\n",
      "\tspeed: 0.0174s/iter; left time: 303.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0622700 Vali Loss: 0.0598124 Test Loss: 0.0740635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619051\n",
      "\tspeed: 0.0357s/iter; left time: 620.7394s\n",
      "\titers: 200, epoch: 23 | loss: 0.0605921\n",
      "\tspeed: 0.0179s/iter; left time: 308.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0617665 Vali Loss: 0.0594863 Test Loss: 0.0737347\n",
      "Validation loss decreased (0.059657 --> 0.059486).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0607017\n",
      "\tspeed: 0.0388s/iter; left time: 664.6397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0636367\n",
      "\tspeed: 0.0174s/iter; left time: 297.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0617854 Vali Loss: 0.0594426 Test Loss: 0.0740125\n",
      "Validation loss decreased (0.059486 --> 0.059443).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673195\n",
      "\tspeed: 0.0362s/iter; left time: 612.4036s\n",
      "\titers: 200, epoch: 25 | loss: 0.0601358\n",
      "\tspeed: 0.0177s/iter; left time: 298.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0616259 Vali Loss: 0.0594604 Test Loss: 0.0745333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0618991\n",
      "\tspeed: 0.0358s/iter; left time: 597.6044s\n",
      "\titers: 200, epoch: 26 | loss: 0.0608135\n",
      "\tspeed: 0.0174s/iter; left time: 289.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0614542 Vali Loss: 0.0593405 Test Loss: 0.0739550\n",
      "Validation loss decreased (0.059443 --> 0.059341).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0631193\n",
      "\tspeed: 0.0369s/iter; left time: 607.5670s\n",
      "\titers: 200, epoch: 27 | loss: 0.0657145\n",
      "\tspeed: 0.0176s/iter; left time: 287.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0616794 Vali Loss: 0.0594699 Test Loss: 0.0737223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0565359\n",
      "\tspeed: 0.0397s/iter; left time: 645.6885s\n",
      "\titers: 200, epoch: 28 | loss: 0.0595181\n",
      "\tspeed: 0.0173s/iter; left time: 279.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0612757 Vali Loss: 0.0591323 Test Loss: 0.0734891\n",
      "Validation loss decreased (0.059341 --> 0.059132).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0586638\n",
      "\tspeed: 0.0367s/iter; left time: 587.9162s\n",
      "\titers: 200, epoch: 29 | loss: 0.0608017\n",
      "\tspeed: 0.0192s/iter; left time: 306.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0612530 Vali Loss: 0.0590975 Test Loss: 0.0735919\n",
      "Validation loss decreased (0.059132 --> 0.059097).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0592039\n",
      "\tspeed: 0.0412s/iter; left time: 650.7961s\n",
      "\titers: 200, epoch: 30 | loss: 0.0614624\n",
      "\tspeed: 0.0184s/iter; left time: 288.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0612326 Vali Loss: 0.0595413 Test Loss: 0.0739768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0617800\n",
      "\tspeed: 0.0358s/iter; left time: 557.7919s\n",
      "\titers: 200, epoch: 31 | loss: 0.0633619\n",
      "\tspeed: 0.0172s/iter; left time: 266.4169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0611033 Vali Loss: 0.0588847 Test Loss: 0.0730694\n",
      "Validation loss decreased (0.059097 --> 0.058885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0632723\n",
      "\tspeed: 0.0374s/iter; left time: 574.4131s\n",
      "\titers: 200, epoch: 32 | loss: 0.0576704\n",
      "\tspeed: 0.0175s/iter; left time: 266.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0609722 Vali Loss: 0.0589661 Test Loss: 0.0733982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0627338\n",
      "\tspeed: 0.0354s/iter; left time: 535.9954s\n",
      "\titers: 200, epoch: 33 | loss: 0.0608308\n",
      "\tspeed: 0.0172s/iter; left time: 258.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0609542 Vali Loss: 0.0587706 Test Loss: 0.0731882\n",
      "Validation loss decreased (0.058885 --> 0.058771).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0627589\n",
      "\tspeed: 0.0394s/iter; left time: 587.7688s\n",
      "\titers: 200, epoch: 34 | loss: 0.0576832\n",
      "\tspeed: 0.0176s/iter; left time: 260.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0610260 Vali Loss: 0.0588217 Test Loss: 0.0729814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0592602\n",
      "\tspeed: 0.0362s/iter; left time: 531.4638s\n",
      "\titers: 200, epoch: 35 | loss: 0.0609397\n",
      "\tspeed: 0.0172s/iter; left time: 250.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0608695 Vali Loss: 0.0589980 Test Loss: 0.0734148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0628913\n",
      "\tspeed: 0.0357s/iter; left time: 516.5297s\n",
      "\titers: 200, epoch: 36 | loss: 0.0595104\n",
      "\tspeed: 0.0178s/iter; left time: 255.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0607886 Vali Loss: 0.0588238 Test Loss: 0.0731824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592520\n",
      "\tspeed: 0.0359s/iter; left time: 510.4757s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619801\n",
      "\tspeed: 0.0173s/iter; left time: 243.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0608522 Vali Loss: 0.0588781 Test Loss: 0.0733389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0571876\n",
      "\tspeed: 0.0355s/iter; left time: 496.8229s\n",
      "\titers: 200, epoch: 38 | loss: 0.0626874\n",
      "\tspeed: 0.0172s/iter; left time: 238.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0609661 Vali Loss: 0.0588733 Test Loss: 0.0733372\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0603451\n",
      "\tspeed: 0.0355s/iter; left time: 489.3631s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607890\n",
      "\tspeed: 0.0173s/iter; left time: 236.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0607698 Vali Loss: 0.0588193 Test Loss: 0.0732570\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0569031\n",
      "\tspeed: 0.0356s/iter; left time: 482.7168s\n",
      "\titers: 200, epoch: 40 | loss: 0.0604230\n",
      "\tspeed: 0.0172s/iter; left time: 231.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0607826 Vali Loss: 0.0588016 Test Loss: 0.0730469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0587654\n",
      "\tspeed: 0.0367s/iter; left time: 490.2749s\n",
      "\titers: 200, epoch: 41 | loss: 0.0610591\n",
      "\tspeed: 0.0172s/iter; left time: 228.1223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0606978 Vali Loss: 0.0587396 Test Loss: 0.0732739\n",
      "Validation loss decreased (0.058771 --> 0.058740).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0635448\n",
      "\tspeed: 0.0367s/iter; left time: 481.0085s\n",
      "\titers: 200, epoch: 42 | loss: 0.0613662\n",
      "\tspeed: 0.0184s/iter; left time: 239.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0607116 Vali Loss: 0.0586978 Test Loss: 0.0730936\n",
      "Validation loss decreased (0.058740 --> 0.058698).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0577063\n",
      "\tspeed: 0.0380s/iter; left time: 490.5650s\n",
      "\titers: 200, epoch: 43 | loss: 0.0591121\n",
      "\tspeed: 0.0179s/iter; left time: 228.5114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0606261 Vali Loss: 0.0589224 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0624545\n",
      "\tspeed: 0.0374s/iter; left time: 473.3641s\n",
      "\titers: 200, epoch: 44 | loss: 0.0616844\n",
      "\tspeed: 0.0187s/iter; left time: 235.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0611692 Vali Loss: 0.0586782 Test Loss: 0.0729012\n",
      "Validation loss decreased (0.058698 --> 0.058678).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0593653\n",
      "\tspeed: 0.0372s/iter; left time: 463.2030s\n",
      "\titers: 200, epoch: 45 | loss: 0.0636859\n",
      "\tspeed: 0.0177s/iter; left time: 218.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0605644 Vali Loss: 0.0586519 Test Loss: 0.0729312\n",
      "Validation loss decreased (0.058678 --> 0.058652).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0588403\n",
      "\tspeed: 0.0369s/iter; left time: 450.9684s\n",
      "\titers: 200, epoch: 46 | loss: 0.0612193\n",
      "\tspeed: 0.0174s/iter; left time: 210.6585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0606294 Vali Loss: 0.0587211 Test Loss: 0.0729838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612823\n",
      "\tspeed: 0.0361s/iter; left time: 433.0083s\n",
      "\titers: 200, epoch: 47 | loss: 0.0574999\n",
      "\tspeed: 0.0180s/iter; left time: 213.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0608826 Vali Loss: 0.0586566 Test Loss: 0.0730382\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0617604\n",
      "\tspeed: 0.0386s/iter; left time: 454.8398s\n",
      "\titers: 200, epoch: 48 | loss: 0.0574106\n",
      "\tspeed: 0.0190s/iter; left time: 221.8804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0606421 Vali Loss: 0.0585935 Test Loss: 0.0729641\n",
      "Validation loss decreased (0.058652 --> 0.058594).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0595661\n",
      "\tspeed: 0.0365s/iter; left time: 421.1314s\n",
      "\titers: 200, epoch: 49 | loss: 0.0651810\n",
      "\tspeed: 0.0174s/iter; left time: 198.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605826 Vali Loss: 0.0586438 Test Loss: 0.0729285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0635316\n",
      "\tspeed: 0.0359s/iter; left time: 406.5635s\n",
      "\titers: 200, epoch: 50 | loss: 0.0610907\n",
      "\tspeed: 0.0171s/iter; left time: 192.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0609660 Vali Loss: 0.0588212 Test Loss: 0.0732808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0592435\n",
      "\tspeed: 0.0365s/iter; left time: 404.7395s\n",
      "\titers: 200, epoch: 51 | loss: 0.0632765\n",
      "\tspeed: 0.0175s/iter; left time: 192.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0606898 Vali Loss: 0.0586598 Test Loss: 0.0730526\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0635184\n",
      "\tspeed: 0.0361s/iter; left time: 392.6319s\n",
      "\titers: 200, epoch: 52 | loss: 0.0610863\n",
      "\tspeed: 0.0218s/iter; left time: 234.8409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0605371 Vali Loss: 0.0588704 Test Loss: 0.0736128\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0603129\n",
      "\tspeed: 0.0369s/iter; left time: 392.8355s\n",
      "\titers: 200, epoch: 53 | loss: 0.0641348\n",
      "\tspeed: 0.0172s/iter; left time: 181.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0606629 Vali Loss: 0.0587345 Test Loss: 0.0732306\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0610451\n",
      "\tspeed: 0.0368s/iter; left time: 384.1182s\n",
      "\titers: 200, epoch: 54 | loss: 0.0583071\n",
      "\tspeed: 0.0192s/iter; left time: 197.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0608471 Vali Loss: 0.0588552 Test Loss: 0.0735912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600205\n",
      "\tspeed: 0.0374s/iter; left time: 381.5183s\n",
      "\titers: 200, epoch: 55 | loss: 0.0605740\n",
      "\tspeed: 0.0173s/iter; left time: 174.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0605078 Vali Loss: 0.0587326 Test Loss: 0.0732537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0583362\n",
      "\tspeed: 0.0361s/iter; left time: 360.7633s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632899\n",
      "\tspeed: 0.0174s/iter; left time: 171.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0586046 Test Loss: 0.0729888\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0592648\n",
      "\tspeed: 0.0367s/iter; left time: 357.6104s\n",
      "\titers: 200, epoch: 57 | loss: 0.0603010\n",
      "\tspeed: 0.0174s/iter; left time: 168.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0605897 Vali Loss: 0.0587299 Test Loss: 0.0734092\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0576204\n",
      "\tspeed: 0.0360s/iter; left time: 342.8372s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604421\n",
      "\tspeed: 0.0174s/iter; left time: 164.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0606295 Vali Loss: 0.0587746 Test Loss: 0.0731275\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012697300873696804, rmse:0.1126822978258133, mae:0.07296409457921982, rse:0.33161038160324097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2723186\n",
      "\tspeed: 0.0221s/iter; left time: 492.7511s\n",
      "\titers: 200, epoch: 1 | loss: 0.2594370\n",
      "\tspeed: 0.0174s/iter; left time: 387.3062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.2804108 Vali Loss: 0.2111473 Test Loss: 0.2331517\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487849\n",
      "\tspeed: 0.0372s/iter; left time: 821.7814s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122121\n",
      "\tspeed: 0.0175s/iter; left time: 385.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1569681 Vali Loss: 0.0871886 Test Loss: 0.0957581\n",
      "Validation loss decreased (0.211147 --> 0.087189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0998303\n",
      "\tspeed: 0.0360s/iter; left time: 787.4339s\n",
      "\titers: 200, epoch: 3 | loss: 0.0900539\n",
      "\tspeed: 0.0172s/iter; left time: 375.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0995899 Vali Loss: 0.0780850 Test Loss: 0.0863740\n",
      "Validation loss decreased (0.087189 --> 0.078085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0908242\n",
      "\tspeed: 0.0364s/iter; left time: 787.0179s\n",
      "\titers: 200, epoch: 4 | loss: 0.0860295\n",
      "\tspeed: 0.0176s/iter; left time: 379.2616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0868707 Vali Loss: 0.0739030 Test Loss: 0.0811787\n",
      "Validation loss decreased (0.078085 --> 0.073903).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0818111\n",
      "\tspeed: 0.0375s/iter; left time: 802.0927s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754183\n",
      "\tspeed: 0.0181s/iter; left time: 385.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0790223 Vali Loss: 0.0694488 Test Loss: 0.0807753\n",
      "Validation loss decreased (0.073903 --> 0.069449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741047\n",
      "\tspeed: 0.0391s/iter; left time: 828.0456s\n",
      "\titers: 200, epoch: 6 | loss: 0.0749590\n",
      "\tspeed: 0.0216s/iter; left time: 454.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0735093 Vali Loss: 0.0666800 Test Loss: 0.0808575\n",
      "Validation loss decreased (0.069449 --> 0.066680).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0736243\n",
      "\tspeed: 0.0380s/iter; left time: 795.4230s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661629\n",
      "\tspeed: 0.0177s/iter; left time: 368.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0714205 Vali Loss: 0.0655510 Test Loss: 0.0802032\n",
      "Validation loss decreased (0.066680 --> 0.065551).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729664\n",
      "\tspeed: 0.0407s/iter; left time: 843.2198s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714460\n",
      "\tspeed: 0.0209s/iter; left time: 431.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0694222 Vali Loss: 0.0644655 Test Loss: 0.0811112\n",
      "Validation loss decreased (0.065551 --> 0.064465).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0659208\n",
      "\tspeed: 0.0369s/iter; left time: 756.4808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711732\n",
      "\tspeed: 0.0173s/iter; left time: 352.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0683030 Vali Loss: 0.0633331 Test Loss: 0.0808911\n",
      "Validation loss decreased (0.064465 --> 0.063333).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658178\n",
      "\tspeed: 0.0385s/iter; left time: 780.8806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632657\n",
      "\tspeed: 0.0206s/iter; left time: 416.7494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0671876 Vali Loss: 0.0626942 Test Loss: 0.0810161\n",
      "Validation loss decreased (0.063333 --> 0.062694).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675375\n",
      "\tspeed: 0.0420s/iter; left time: 842.6574s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656089\n",
      "\tspeed: 0.0178s/iter; left time: 356.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0663821 Vali Loss: 0.0650089 Test Loss: 0.0835631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698378\n",
      "\tspeed: 0.0374s/iter; left time: 742.3642s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709315\n",
      "\tspeed: 0.0182s/iter; left time: 360.0192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0658216 Vali Loss: 0.0622524 Test Loss: 0.0804868\n",
      "Validation loss decreased (0.062694 --> 0.062252).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0702056\n",
      "\tspeed: 0.0372s/iter; left time: 730.0678s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646744\n",
      "\tspeed: 0.0179s/iter; left time: 348.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0651245 Vali Loss: 0.0614892 Test Loss: 0.0798468\n",
      "Validation loss decreased (0.062252 --> 0.061489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0666263\n",
      "\tspeed: 0.0383s/iter; left time: 742.3045s\n",
      "\titers: 200, epoch: 14 | loss: 0.0637792\n",
      "\tspeed: 0.0176s/iter; left time: 339.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0645446 Vali Loss: 0.0609676 Test Loss: 0.0781604\n",
      "Validation loss decreased (0.061489 --> 0.060968).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713808\n",
      "\tspeed: 0.0385s/iter; left time: 738.1148s\n",
      "\titers: 200, epoch: 15 | loss: 0.0672789\n",
      "\tspeed: 0.0220s/iter; left time: 420.2792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0644304 Vali Loss: 0.0603074 Test Loss: 0.0764001\n",
      "Validation loss decreased (0.060968 --> 0.060307).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0611395\n",
      "\tspeed: 0.0366s/iter; left time: 693.5715s\n",
      "\titers: 200, epoch: 16 | loss: 0.0639924\n",
      "\tspeed: 0.0171s/iter; left time: 323.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0638584 Vali Loss: 0.0604877 Test Loss: 0.0751136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645290\n",
      "\tspeed: 0.0381s/iter; left time: 713.7701s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622595\n",
      "\tspeed: 0.0171s/iter; left time: 319.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0634671 Vali Loss: 0.0599232 Test Loss: 0.0762809\n",
      "Validation loss decreased (0.060307 --> 0.059923).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624876\n",
      "\tspeed: 0.0366s/iter; left time: 676.2772s\n",
      "\titers: 200, epoch: 18 | loss: 0.0637171\n",
      "\tspeed: 0.0175s/iter; left time: 321.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0630357 Vali Loss: 0.0595618 Test Loss: 0.0750244\n",
      "Validation loss decreased (0.059923 --> 0.059562).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0617419\n",
      "\tspeed: 0.0385s/iter; left time: 704.1668s\n",
      "\titers: 200, epoch: 19 | loss: 0.0608804\n",
      "\tspeed: 0.0172s/iter; left time: 311.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0629090 Vali Loss: 0.0596770 Test Loss: 0.0742886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0633113\n",
      "\tspeed: 0.0363s/iter; left time: 654.8177s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655701\n",
      "\tspeed: 0.0173s/iter; left time: 310.7320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0625126 Vali Loss: 0.0595197 Test Loss: 0.0756664\n",
      "Validation loss decreased (0.059562 --> 0.059520).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0628558\n",
      "\tspeed: 0.0366s/iter; left time: 653.0582s\n",
      "\titers: 200, epoch: 21 | loss: 0.0602739\n",
      "\tspeed: 0.0173s/iter; left time: 306.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0623610 Vali Loss: 0.0591243 Test Loss: 0.0753350\n",
      "Validation loss decreased (0.059520 --> 0.059124).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0651103\n",
      "\tspeed: 0.0364s/iter; left time: 640.0614s\n",
      "\titers: 200, epoch: 22 | loss: 0.0575442\n",
      "\tspeed: 0.0174s/iter; left time: 304.0223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0621670 Vali Loss: 0.0592054 Test Loss: 0.0741855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0664264\n",
      "\tspeed: 0.0367s/iter; left time: 638.1007s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587535\n",
      "\tspeed: 0.0172s/iter; left time: 297.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0620225 Vali Loss: 0.0589292 Test Loss: 0.0742925\n",
      "Validation loss decreased (0.059124 --> 0.058929).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0641541\n",
      "\tspeed: 0.0368s/iter; left time: 630.3895s\n",
      "\titers: 200, epoch: 24 | loss: 0.0634813\n",
      "\tspeed: 0.0174s/iter; left time: 297.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0621247 Vali Loss: 0.0589253 Test Loss: 0.0734498\n",
      "Validation loss decreased (0.058929 --> 0.058925).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0564462\n",
      "\tspeed: 0.0369s/iter; left time: 624.3433s\n",
      "\titers: 200, epoch: 25 | loss: 0.0637565\n",
      "\tspeed: 0.0174s/iter; left time: 291.9264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0617372 Vali Loss: 0.0589466 Test Loss: 0.0749519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0636609\n",
      "\tspeed: 0.0359s/iter; left time: 600.0659s\n",
      "\titers: 200, epoch: 26 | loss: 0.0584842\n",
      "\tspeed: 0.0172s/iter; left time: 285.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0616560 Vali Loss: 0.0590757 Test Loss: 0.0742946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0581466\n",
      "\tspeed: 0.0357s/iter; left time: 588.6790s\n",
      "\titers: 200, epoch: 27 | loss: 0.0603953\n",
      "\tspeed: 0.0173s/iter; left time: 283.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0616052 Vali Loss: 0.0585262 Test Loss: 0.0741448\n",
      "Validation loss decreased (0.058925 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0577278\n",
      "\tspeed: 0.0392s/iter; left time: 637.3915s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644682\n",
      "\tspeed: 0.0181s/iter; left time: 291.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0618389 Vali Loss: 0.0587341 Test Loss: 0.0739767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625474\n",
      "\tspeed: 0.0360s/iter; left time: 576.4015s\n",
      "\titers: 200, epoch: 29 | loss: 0.0580867\n",
      "\tspeed: 0.0171s/iter; left time: 272.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0613939 Vali Loss: 0.0586087 Test Loss: 0.0742347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0590229\n",
      "\tspeed: 0.0355s/iter; left time: 561.1628s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606227\n",
      "\tspeed: 0.0173s/iter; left time: 272.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0611694 Vali Loss: 0.0584188 Test Loss: 0.0739610\n",
      "Validation loss decreased (0.058526 --> 0.058419).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0643775\n",
      "\tspeed: 0.0367s/iter; left time: 571.0828s\n",
      "\titers: 200, epoch: 31 | loss: 0.0578023\n",
      "\tspeed: 0.0173s/iter; left time: 268.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0611918 Vali Loss: 0.0583375 Test Loss: 0.0744160\n",
      "Validation loss decreased (0.058419 --> 0.058337).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0579711\n",
      "\tspeed: 0.0377s/iter; left time: 579.2495s\n",
      "\titers: 200, epoch: 32 | loss: 0.0620027\n",
      "\tspeed: 0.0179s/iter; left time: 273.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0612068 Vali Loss: 0.0583986 Test Loss: 0.0742417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0653523\n",
      "\tspeed: 0.0403s/iter; left time: 609.4985s\n",
      "\titers: 200, epoch: 33 | loss: 0.0614485\n",
      "\tspeed: 0.0206s/iter; left time: 309.8559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0611182 Vali Loss: 0.0582882 Test Loss: 0.0733675\n",
      "Validation loss decreased (0.058337 --> 0.058288).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647610\n",
      "\tspeed: 0.0366s/iter; left time: 545.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0633823\n",
      "\tspeed: 0.0175s/iter; left time: 259.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0610971 Vali Loss: 0.0584576 Test Loss: 0.0729061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0626284\n",
      "\tspeed: 0.0390s/iter; left time: 573.3413s\n",
      "\titers: 200, epoch: 35 | loss: 0.0601387\n",
      "\tspeed: 0.0173s/iter; left time: 251.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0610140 Vali Loss: 0.0582965 Test Loss: 0.0737146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639531\n",
      "\tspeed: 0.0359s/iter; left time: 518.8844s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608174\n",
      "\tspeed: 0.0178s/iter; left time: 256.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0611647 Vali Loss: 0.0582508 Test Loss: 0.0736249\n",
      "Validation loss decreased (0.058288 --> 0.058251).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0602419\n",
      "\tspeed: 0.0366s/iter; left time: 521.4744s\n",
      "\titers: 200, epoch: 37 | loss: 0.0581153\n",
      "\tspeed: 0.0173s/iter; left time: 245.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0610484 Vali Loss: 0.0583448 Test Loss: 0.0732000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0600050\n",
      "\tspeed: 0.0365s/iter; left time: 510.8782s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618239\n",
      "\tspeed: 0.0172s/iter; left time: 239.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0609829 Vali Loss: 0.0584209 Test Loss: 0.0728817\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601002\n",
      "\tspeed: 0.0355s/iter; left time: 488.8881s\n",
      "\titers: 200, epoch: 39 | loss: 0.0637596\n",
      "\tspeed: 0.0171s/iter; left time: 234.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0608545 Vali Loss: 0.0582400 Test Loss: 0.0727859\n",
      "Validation loss decreased (0.058251 --> 0.058240).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0579164\n",
      "\tspeed: 0.0380s/iter; left time: 515.7594s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646479\n",
      "\tspeed: 0.0177s/iter; left time: 238.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0608278 Vali Loss: 0.0582177 Test Loss: 0.0733635\n",
      "Validation loss decreased (0.058240 --> 0.058218).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0616952\n",
      "\tspeed: 0.0405s/iter; left time: 540.6834s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571715\n",
      "\tspeed: 0.0204s/iter; left time: 270.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0608960 Vali Loss: 0.0581996 Test Loss: 0.0732759\n",
      "Validation loss decreased (0.058218 --> 0.058200).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0631871\n",
      "\tspeed: 0.0375s/iter; left time: 491.4789s\n",
      "\titers: 200, epoch: 42 | loss: 0.0568571\n",
      "\tspeed: 0.0171s/iter; left time: 222.4476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0608211 Vali Loss: 0.0580944 Test Loss: 0.0728690\n",
      "Validation loss decreased (0.058200 --> 0.058094).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0618066\n",
      "\tspeed: 0.0370s/iter; left time: 476.8264s\n",
      "\titers: 200, epoch: 43 | loss: 0.0615122\n",
      "\tspeed: 0.0174s/iter; left time: 222.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0611374 Vali Loss: 0.0583234 Test Loss: 0.0724586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0589104\n",
      "\tspeed: 0.0392s/iter; left time: 497.1608s\n",
      "\titers: 200, epoch: 44 | loss: 0.0627911\n",
      "\tspeed: 0.0202s/iter; left time: 254.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0609306 Vali Loss: 0.0582577 Test Loss: 0.0726218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0628825\n",
      "\tspeed: 0.0368s/iter; left time: 458.3033s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587390\n",
      "\tspeed: 0.0174s/iter; left time: 214.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0613185 Vali Loss: 0.0582871 Test Loss: 0.0725785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0598876\n",
      "\tspeed: 0.0410s/iter; left time: 500.8020s\n",
      "\titers: 200, epoch: 46 | loss: 0.0615125\n",
      "\tspeed: 0.0216s/iter; left time: 261.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0608629 Vali Loss: 0.0581948 Test Loss: 0.0726809\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0631883\n",
      "\tspeed: 0.0369s/iter; left time: 442.5629s\n",
      "\titers: 200, epoch: 47 | loss: 0.0606678\n",
      "\tspeed: 0.0181s/iter; left time: 214.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0607024 Vali Loss: 0.0582297 Test Loss: 0.0723210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0599459\n",
      "\tspeed: 0.0377s/iter; left time: 443.6570s\n",
      "\titers: 200, epoch: 48 | loss: 0.0553894\n",
      "\tspeed: 0.0172s/iter; left time: 201.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0608386 Vali Loss: 0.0579962 Test Loss: 0.0727201\n",
      "Validation loss decreased (0.058094 --> 0.057996).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0578657\n",
      "\tspeed: 0.0380s/iter; left time: 439.3892s\n",
      "\titers: 200, epoch: 49 | loss: 0.0608033\n",
      "\tspeed: 0.0180s/iter; left time: 206.3923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0609807 Vali Loss: 0.0581391 Test Loss: 0.0725509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0621150\n",
      "\tspeed: 0.0358s/iter; left time: 405.6554s\n",
      "\titers: 200, epoch: 50 | loss: 0.0631911\n",
      "\tspeed: 0.0177s/iter; left time: 198.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0607364 Vali Loss: 0.0581990 Test Loss: 0.0728008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0609419\n",
      "\tspeed: 0.0358s/iter; left time: 397.3895s\n",
      "\titers: 200, epoch: 51 | loss: 0.0609045\n",
      "\tspeed: 0.0175s/iter; left time: 192.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605976 Vali Loss: 0.0580235 Test Loss: 0.0729227\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0613372\n",
      "\tspeed: 0.0376s/iter; left time: 409.0928s\n",
      "\titers: 200, epoch: 52 | loss: 0.0578110\n",
      "\tspeed: 0.0173s/iter; left time: 186.7250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0606016 Vali Loss: 0.0580805 Test Loss: 0.0728458\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597081\n",
      "\tspeed: 0.0362s/iter; left time: 385.8459s\n",
      "\titers: 200, epoch: 53 | loss: 0.0599167\n",
      "\tspeed: 0.0173s/iter; left time: 182.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0606716 Vali Loss: 0.0581069 Test Loss: 0.0723052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0602916\n",
      "\tspeed: 0.0362s/iter; left time: 377.1772s\n",
      "\titers: 200, epoch: 54 | loss: 0.0620375\n",
      "\tspeed: 0.0173s/iter; left time: 178.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0607120 Vali Loss: 0.0583016 Test Loss: 0.0727637\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623368\n",
      "\tspeed: 0.0360s/iter; left time: 367.1473s\n",
      "\titers: 200, epoch: 55 | loss: 0.0654304\n",
      "\tspeed: 0.0178s/iter; left time: 180.3104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0606441 Vali Loss: 0.0581952 Test Loss: 0.0731348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0625696\n",
      "\tspeed: 0.0356s/iter; left time: 355.0182s\n",
      "\titers: 200, epoch: 56 | loss: 0.0563569\n",
      "\tspeed: 0.0172s/iter; left time: 169.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0607840 Vali Loss: 0.0580681 Test Loss: 0.0729142\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0616411\n",
      "\tspeed: 0.0359s/iter; left time: 349.8216s\n",
      "\titers: 200, epoch: 57 | loss: 0.0601746\n",
      "\tspeed: 0.0174s/iter; left time: 167.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605397 Vali Loss: 0.0581108 Test Loss: 0.0730427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0618836\n",
      "\tspeed: 0.0369s/iter; left time: 351.6512s\n",
      "\titers: 200, epoch: 58 | loss: 0.0594452\n",
      "\tspeed: 0.0171s/iter; left time: 161.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0606900 Vali Loss: 0.0581163 Test Loss: 0.0726102\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01282523199915886, rmse:0.1132485419511795, mae:0.07272014766931534, rse:0.33327677845954895\n",
      "Intermediate time for ES and pred_len 24: 00h:10m:47.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2699923\n",
      "\tspeed: 0.0421s/iter; left time: 937.9746s\n",
      "\titers: 200, epoch: 1 | loss: 0.2550710\n",
      "\tspeed: 0.0180s/iter; left time: 398.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.2779176 Vali Loss: 0.2090562 Test Loss: 0.2344670\n",
      "Validation loss decreased (inf --> 0.209056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451056\n",
      "\tspeed: 0.0375s/iter; left time: 827.5422s\n",
      "\titers: 200, epoch: 2 | loss: 0.1162974\n",
      "\tspeed: 0.0176s/iter; left time: 387.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1551280 Vali Loss: 0.1042353 Test Loss: 0.1172750\n",
      "Validation loss decreased (0.209056 --> 0.104235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089795\n",
      "\tspeed: 0.0373s/iter; left time: 815.6770s\n",
      "\titers: 200, epoch: 3 | loss: 0.1037570\n",
      "\tspeed: 0.0174s/iter; left time: 378.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1090032 Vali Loss: 0.0926297 Test Loss: 0.1092328\n",
      "Validation loss decreased (0.104235 --> 0.092630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0931839\n",
      "\tspeed: 0.0362s/iter; left time: 783.5263s\n",
      "\titers: 200, epoch: 4 | loss: 0.0921412\n",
      "\tspeed: 0.0174s/iter; left time: 374.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0958092 Vali Loss: 0.0869654 Test Loss: 0.1052669\n",
      "Validation loss decreased (0.092630 --> 0.086965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0885624\n",
      "\tspeed: 0.0370s/iter; left time: 792.7775s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861385\n",
      "\tspeed: 0.0174s/iter; left time: 370.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0911318 Vali Loss: 0.0844819 Test Loss: 0.1059624\n",
      "Validation loss decreased (0.086965 --> 0.084482).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0869646\n",
      "\tspeed: 0.0375s/iter; left time: 793.3715s\n",
      "\titers: 200, epoch: 6 | loss: 0.0883404\n",
      "\tspeed: 0.0177s/iter; left time: 372.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0878641 Vali Loss: 0.0837793 Test Loss: 0.1088766\n",
      "Validation loss decreased (0.084482 --> 0.083779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0886907\n",
      "\tspeed: 0.0388s/iter; left time: 813.2618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817665\n",
      "\tspeed: 0.0182s/iter; left time: 380.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0862188 Vali Loss: 0.0827717 Test Loss: 0.1055454\n",
      "Validation loss decreased (0.083779 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847801\n",
      "\tspeed: 0.0373s/iter; left time: 773.0924s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820215\n",
      "\tspeed: 0.0175s/iter; left time: 361.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0846143 Vali Loss: 0.0810567 Test Loss: 0.1060755\n",
      "Validation loss decreased (0.082772 --> 0.081057).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844776\n",
      "\tspeed: 0.0386s/iter; left time: 792.4186s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794606\n",
      "\tspeed: 0.0195s/iter; left time: 397.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0838625 Vali Loss: 0.0811782 Test Loss: 0.1076061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0855363\n",
      "\tspeed: 0.0381s/iter; left time: 772.8100s\n",
      "\titers: 200, epoch: 10 | loss: 0.0853410\n",
      "\tspeed: 0.0223s/iter; left time: 449.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0832864 Vali Loss: 0.0808300 Test Loss: 0.1084978\n",
      "Validation loss decreased (0.081057 --> 0.080830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816533\n",
      "\tspeed: 0.0376s/iter; left time: 755.2453s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852584\n",
      "\tspeed: 0.0174s/iter; left time: 347.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0824372 Vali Loss: 0.0800179 Test Loss: 0.1059387\n",
      "Validation loss decreased (0.080830 --> 0.080018).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0845546\n",
      "\tspeed: 0.0394s/iter; left time: 781.4903s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818359\n",
      "\tspeed: 0.0176s/iter; left time: 346.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0820708 Vali Loss: 0.0797471 Test Loss: 0.1046065\n",
      "Validation loss decreased (0.080018 --> 0.079747).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0820495\n",
      "\tspeed: 0.0378s/iter; left time: 741.1513s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821259\n",
      "\tspeed: 0.0174s/iter; left time: 339.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0817390 Vali Loss: 0.0797309 Test Loss: 0.1047793\n",
      "Validation loss decreased (0.079747 --> 0.079731).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771034\n",
      "\tspeed: 0.0374s/iter; left time: 725.9512s\n",
      "\titers: 200, epoch: 14 | loss: 0.0803334\n",
      "\tspeed: 0.0177s/iter; left time: 341.0476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0816818 Vali Loss: 0.0795235 Test Loss: 0.1054109\n",
      "Validation loss decreased (0.079731 --> 0.079524).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790244\n",
      "\tspeed: 0.0374s/iter; left time: 716.8276s\n",
      "\titers: 200, epoch: 15 | loss: 0.0830677\n",
      "\tspeed: 0.0176s/iter; left time: 336.2045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0809772 Vali Loss: 0.0793998 Test Loss: 0.1049986\n",
      "Validation loss decreased (0.079524 --> 0.079400).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790241\n",
      "\tspeed: 0.0372s/iter; left time: 703.7488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845467\n",
      "\tspeed: 0.0177s/iter; left time: 333.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0810577 Vali Loss: 0.0812501 Test Loss: 0.1041506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794203\n",
      "\tspeed: 0.0369s/iter; left time: 689.9567s\n",
      "\titers: 200, epoch: 17 | loss: 0.0831470\n",
      "\tspeed: 0.0177s/iter; left time: 329.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0806764 Vali Loss: 0.0792494 Test Loss: 0.1062545\n",
      "Validation loss decreased (0.079400 --> 0.079249).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804426\n",
      "\tspeed: 0.0377s/iter; left time: 698.1049s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796953\n",
      "\tspeed: 0.0175s/iter; left time: 321.4670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0806038 Vali Loss: 0.0788590 Test Loss: 0.1040276\n",
      "Validation loss decreased (0.079249 --> 0.078859).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0802150\n",
      "\tspeed: 0.0374s/iter; left time: 682.7215s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840697\n",
      "\tspeed: 0.0176s/iter; left time: 319.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0800741 Vali Loss: 0.0789752 Test Loss: 0.1047164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0799749\n",
      "\tspeed: 0.0369s/iter; left time: 665.0032s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796723\n",
      "\tspeed: 0.0177s/iter; left time: 317.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0799620 Vali Loss: 0.0787971 Test Loss: 0.1043757\n",
      "Validation loss decreased (0.078859 --> 0.078797).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814895\n",
      "\tspeed: 0.0377s/iter; left time: 671.1743s\n",
      "\titers: 200, epoch: 21 | loss: 0.0775726\n",
      "\tspeed: 0.0176s/iter; left time: 311.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0799304 Vali Loss: 0.0786215 Test Loss: 0.1053541\n",
      "Validation loss decreased (0.078797 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0822030\n",
      "\tspeed: 0.0388s/iter; left time: 682.6459s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822271\n",
      "\tspeed: 0.0194s/iter; left time: 339.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0797733 Vali Loss: 0.0788172 Test Loss: 0.1050946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0782094\n",
      "\tspeed: 0.0368s/iter; left time: 639.5816s\n",
      "\titers: 200, epoch: 23 | loss: 0.0817364\n",
      "\tspeed: 0.0174s/iter; left time: 299.9704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0796080 Vali Loss: 0.0783708 Test Loss: 0.1048175\n",
      "Validation loss decreased (0.078622 --> 0.078371).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0782946\n",
      "\tspeed: 0.0389s/iter; left time: 667.6350s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759547\n",
      "\tspeed: 0.0193s/iter; left time: 329.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0795476 Vali Loss: 0.0784284 Test Loss: 0.1046700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781184\n",
      "\tspeed: 0.0385s/iter; left time: 651.9828s\n",
      "\titers: 200, epoch: 25 | loss: 0.0811927\n",
      "\tspeed: 0.0177s/iter; left time: 297.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0799517 Vali Loss: 0.0786431 Test Loss: 0.1045798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0762303\n",
      "\tspeed: 0.0370s/iter; left time: 618.4891s\n",
      "\titers: 200, epoch: 26 | loss: 0.0799544\n",
      "\tspeed: 0.0181s/iter; left time: 300.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0793796 Vali Loss: 0.0786190 Test Loss: 0.1051480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789374\n",
      "\tspeed: 0.0370s/iter; left time: 609.6431s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780281\n",
      "\tspeed: 0.0176s/iter; left time: 288.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0792773 Vali Loss: 0.0784299 Test Loss: 0.1052233\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0814020\n",
      "\tspeed: 0.0395s/iter; left time: 641.9937s\n",
      "\titers: 200, epoch: 28 | loss: 0.0798138\n",
      "\tspeed: 0.0186s/iter; left time: 299.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0791199 Vali Loss: 0.0783501 Test Loss: 0.1047811\n",
      "Validation loss decreased (0.078371 --> 0.078350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0820562\n",
      "\tspeed: 0.0370s/iter; left time: 593.4710s\n",
      "\titers: 200, epoch: 29 | loss: 0.0808358\n",
      "\tspeed: 0.0189s/iter; left time: 300.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0791596 Vali Loss: 0.0785035 Test Loss: 0.1055300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0763969\n",
      "\tspeed: 0.0379s/iter; left time: 599.3888s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771363\n",
      "\tspeed: 0.0176s/iter; left time: 276.2735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0791952 Vali Loss: 0.0784093 Test Loss: 0.1051583\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785842\n",
      "\tspeed: 0.0374s/iter; left time: 582.5881s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813041\n",
      "\tspeed: 0.0188s/iter; left time: 290.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0790166 Vali Loss: 0.0783721 Test Loss: 0.1051348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0805069\n",
      "\tspeed: 0.0370s/iter; left time: 568.1873s\n",
      "\titers: 200, epoch: 32 | loss: 0.0800453\n",
      "\tspeed: 0.0185s/iter; left time: 281.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0790431 Vali Loss: 0.0783341 Test Loss: 0.1047582\n",
      "Validation loss decreased (0.078350 --> 0.078334).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0781617\n",
      "\tspeed: 0.0379s/iter; left time: 572.8596s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795569\n",
      "\tspeed: 0.0176s/iter; left time: 265.0821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0790344 Vali Loss: 0.0783522 Test Loss: 0.1054242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754284\n",
      "\tspeed: 0.0397s/iter; left time: 592.1762s\n",
      "\titers: 200, epoch: 34 | loss: 0.0840273\n",
      "\tspeed: 0.0201s/iter; left time: 296.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0790746 Vali Loss: 0.0782857 Test Loss: 0.1051250\n",
      "Validation loss decreased (0.078334 --> 0.078286).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0800861\n",
      "\tspeed: 0.0390s/iter; left time: 573.1407s\n",
      "\titers: 200, epoch: 35 | loss: 0.0839135\n",
      "\tspeed: 0.0176s/iter; left time: 256.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0789047 Vali Loss: 0.0782892 Test Loss: 0.1051449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0803963\n",
      "\tspeed: 0.0379s/iter; left time: 548.4311s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774545\n",
      "\tspeed: 0.0175s/iter; left time: 251.6576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0788350 Vali Loss: 0.0783046 Test Loss: 0.1055788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0808286\n",
      "\tspeed: 0.0373s/iter; left time: 530.5222s\n",
      "\titers: 200, epoch: 37 | loss: 0.0770837\n",
      "\tspeed: 0.0211s/iter; left time: 298.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0788810 Vali Loss: 0.0783464 Test Loss: 0.1056055\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0771653\n",
      "\tspeed: 0.0376s/iter; left time: 527.5544s\n",
      "\titers: 200, epoch: 38 | loss: 0.0761486\n",
      "\tspeed: 0.0175s/iter; left time: 243.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0791125 Vali Loss: 0.0782723 Test Loss: 0.1056459\n",
      "Validation loss decreased (0.078286 --> 0.078272).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0771597\n",
      "\tspeed: 0.0392s/iter; left time: 540.5652s\n",
      "\titers: 200, epoch: 39 | loss: 0.0795766\n",
      "\tspeed: 0.0211s/iter; left time: 288.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0789243 Vali Loss: 0.0781249 Test Loss: 0.1045209\n",
      "Validation loss decreased (0.078272 --> 0.078125).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0800514\n",
      "\tspeed: 0.0379s/iter; left time: 513.7359s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769166\n",
      "\tspeed: 0.0174s/iter; left time: 233.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0787367 Vali Loss: 0.0781777 Test Loss: 0.1055735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0788939\n",
      "\tspeed: 0.0380s/iter; left time: 506.7403s\n",
      "\titers: 200, epoch: 41 | loss: 0.0796120\n",
      "\tspeed: 0.0194s/iter; left time: 256.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0787654 Vali Loss: 0.0783776 Test Loss: 0.1058984\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0801310\n",
      "\tspeed: 0.0377s/iter; left time: 494.3213s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760927\n",
      "\tspeed: 0.0175s/iter; left time: 228.4381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0787919 Vali Loss: 0.0782467 Test Loss: 0.1052588\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0780973\n",
      "\tspeed: 0.0375s/iter; left time: 483.0579s\n",
      "\titers: 200, epoch: 43 | loss: 0.0798386\n",
      "\tspeed: 0.0174s/iter; left time: 222.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0787492 Vali Loss: 0.0781928 Test Loss: 0.1050963\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0823438\n",
      "\tspeed: 0.0373s/iter; left time: 472.6711s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814990\n",
      "\tspeed: 0.0176s/iter; left time: 220.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0787495 Vali Loss: 0.0783943 Test Loss: 0.1058547\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0747283\n",
      "\tspeed: 0.0373s/iter; left time: 463.7394s\n",
      "\titers: 200, epoch: 45 | loss: 0.0808855\n",
      "\tspeed: 0.0189s/iter; left time: 233.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0786864 Vali Loss: 0.0781960 Test Loss: 0.1050198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0759459\n",
      "\tspeed: 0.0419s/iter; left time: 512.0966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0787885\n",
      "\tspeed: 0.0174s/iter; left time: 210.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0786618 Vali Loss: 0.0782442 Test Loss: 0.1055460\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0770903\n",
      "\tspeed: 0.0374s/iter; left time: 448.5779s\n",
      "\titers: 200, epoch: 47 | loss: 0.0741980\n",
      "\tspeed: 0.0176s/iter; left time: 209.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0786734 Vali Loss: 0.0782155 Test Loss: 0.1053684\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0808809\n",
      "\tspeed: 0.0399s/iter; left time: 470.2276s\n",
      "\titers: 200, epoch: 48 | loss: 0.0765063\n",
      "\tspeed: 0.0204s/iter; left time: 238.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0787458 Vali Loss: 0.0782955 Test Loss: 0.1055569\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0781761\n",
      "\tspeed: 0.0370s/iter; left time: 427.0267s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780755\n",
      "\tspeed: 0.0174s/iter; left time: 198.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0785175 Vali Loss: 0.0782023 Test Loss: 0.1054485\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02427673526108265, rmse:0.1558099389076233, mae:0.10452089458703995, rse:0.4577226936817169\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2807732\n",
      "\tspeed: 0.0241s/iter; left time: 538.3053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2653032\n",
      "\tspeed: 0.0210s/iter; left time: 466.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.2841145 Vali Loss: 0.2130373 Test Loss: 0.2379890\n",
      "Validation loss decreased (inf --> 0.213037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1392819\n",
      "\tspeed: 0.0391s/iter; left time: 862.9989s\n",
      "\titers: 200, epoch: 2 | loss: 0.1165387\n",
      "\tspeed: 0.0176s/iter; left time: 387.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1551139 Vali Loss: 0.1124424 Test Loss: 0.1264123\n",
      "Validation loss decreased (0.213037 --> 0.112442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1126997\n",
      "\tspeed: 0.0389s/iter; left time: 850.2621s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035556\n",
      "\tspeed: 0.0174s/iter; left time: 378.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1085227 Vali Loss: 0.0961990 Test Loss: 0.1101242\n",
      "Validation loss decreased (0.112442 --> 0.096199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962838\n",
      "\tspeed: 0.0387s/iter; left time: 837.5867s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969591\n",
      "\tspeed: 0.0175s/iter; left time: 377.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0975332 Vali Loss: 0.0874930 Test Loss: 0.1175036\n",
      "Validation loss decreased (0.096199 --> 0.087493).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0933458\n",
      "\tspeed: 0.0409s/iter; left time: 874.7736s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946651\n",
      "\tspeed: 0.0175s/iter; left time: 372.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0918568 Vali Loss: 0.0853591 Test Loss: 0.1164506\n",
      "Validation loss decreased (0.087493 --> 0.085359).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0905998\n",
      "\tspeed: 0.0410s/iter; left time: 868.6588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834064\n",
      "\tspeed: 0.0186s/iter; left time: 392.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0886637 Vali Loss: 0.0833173 Test Loss: 0.1190308\n",
      "Validation loss decreased (0.085359 --> 0.083317).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859550\n",
      "\tspeed: 0.0387s/iter; left time: 810.8632s\n",
      "\titers: 200, epoch: 7 | loss: 0.0857930\n",
      "\tspeed: 0.0174s/iter; left time: 361.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0870941 Vali Loss: 0.0824725 Test Loss: 0.1289645\n",
      "Validation loss decreased (0.083317 --> 0.082472).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0835487\n",
      "\tspeed: 0.0394s/iter; left time: 816.0628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800077\n",
      "\tspeed: 0.0202s/iter; left time: 417.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0859448 Vali Loss: 0.0809953 Test Loss: 0.1246080\n",
      "Validation loss decreased (0.082472 --> 0.080995).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829436\n",
      "\tspeed: 0.0376s/iter; left time: 771.6681s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795209\n",
      "\tspeed: 0.0174s/iter; left time: 354.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0850060 Vali Loss: 0.0815726 Test Loss: 0.1122439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0820003\n",
      "\tspeed: 0.0370s/iter; left time: 750.4537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848408\n",
      "\tspeed: 0.0174s/iter; left time: 350.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0839826 Vali Loss: 0.0810251 Test Loss: 0.1215878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819815\n",
      "\tspeed: 0.0400s/iter; left time: 802.8165s\n",
      "\titers: 200, epoch: 11 | loss: 0.0843423\n",
      "\tspeed: 0.0194s/iter; left time: 387.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0837573 Vali Loss: 0.0803522 Test Loss: 0.1226014\n",
      "Validation loss decreased (0.080995 --> 0.080352).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821579\n",
      "\tspeed: 0.0382s/iter; left time: 758.6621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0825495\n",
      "\tspeed: 0.0173s/iter; left time: 342.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0829496 Vali Loss: 0.0797525 Test Loss: 0.1239641\n",
      "Validation loss decreased (0.080352 --> 0.079753).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0780287\n",
      "\tspeed: 0.0373s/iter; left time: 731.3173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800011\n",
      "\tspeed: 0.0175s/iter; left time: 341.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0824018 Vali Loss: 0.0796889 Test Loss: 0.1207599\n",
      "Validation loss decreased (0.079753 --> 0.079689).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0824617\n",
      "\tspeed: 0.0383s/iter; left time: 743.4180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0812564\n",
      "\tspeed: 0.0174s/iter; left time: 334.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0819560 Vali Loss: 0.0796502 Test Loss: 0.1245411\n",
      "Validation loss decreased (0.079689 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0830183\n",
      "\tspeed: 0.0380s/iter; left time: 728.2025s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822272\n",
      "\tspeed: 0.0175s/iter; left time: 333.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0817088 Vali Loss: 0.0795031 Test Loss: 0.1285043\n",
      "Validation loss decreased (0.079650 --> 0.079503).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823791\n",
      "\tspeed: 0.0382s/iter; left time: 723.6515s\n",
      "\titers: 200, epoch: 16 | loss: 0.0843695\n",
      "\tspeed: 0.0176s/iter; left time: 330.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0813237 Vali Loss: 0.0790901 Test Loss: 0.1307180\n",
      "Validation loss decreased (0.079503 --> 0.079090).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792187\n",
      "\tspeed: 0.0383s/iter; left time: 716.8989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0829362\n",
      "\tspeed: 0.0174s/iter; left time: 323.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0812568 Vali Loss: 0.0794295 Test Loss: 0.1282273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0772294\n",
      "\tspeed: 0.0401s/iter; left time: 741.0517s\n",
      "\titers: 200, epoch: 18 | loss: 0.0806995\n",
      "\tspeed: 0.0202s/iter; left time: 371.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0811110 Vali Loss: 0.0793635 Test Loss: 0.1272759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784017\n",
      "\tspeed: 0.0379s/iter; left time: 692.2446s\n",
      "\titers: 200, epoch: 19 | loss: 0.0811006\n",
      "\tspeed: 0.0176s/iter; left time: 319.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0807204 Vali Loss: 0.0791787 Test Loss: 0.1262407\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806236\n",
      "\tspeed: 0.0376s/iter; left time: 678.5568s\n",
      "\titers: 200, epoch: 20 | loss: 0.0801287\n",
      "\tspeed: 0.0174s/iter; left time: 312.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0805928 Vali Loss: 0.0788154 Test Loss: 0.1241784\n",
      "Validation loss decreased (0.079090 --> 0.078815).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814793\n",
      "\tspeed: 0.0379s/iter; left time: 674.7187s\n",
      "\titers: 200, epoch: 21 | loss: 0.0794477\n",
      "\tspeed: 0.0174s/iter; left time: 308.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0805322 Vali Loss: 0.0791230 Test Loss: 0.1281666\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802228\n",
      "\tspeed: 0.0371s/iter; left time: 652.9956s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822596\n",
      "\tspeed: 0.0199s/iter; left time: 347.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0803095 Vali Loss: 0.0789785 Test Loss: 0.1211020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0813869\n",
      "\tspeed: 0.0410s/iter; left time: 712.1590s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802233\n",
      "\tspeed: 0.0176s/iter; left time: 304.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0803901 Vali Loss: 0.0790809 Test Loss: 0.1202924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0823530\n",
      "\tspeed: 0.0375s/iter; left time: 643.7499s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754244\n",
      "\tspeed: 0.0175s/iter; left time: 298.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0799929 Vali Loss: 0.0786709 Test Loss: 0.1282071\n",
      "Validation loss decreased (0.078815 --> 0.078671).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0769625\n",
      "\tspeed: 0.0384s/iter; left time: 649.5076s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787524\n",
      "\tspeed: 0.0177s/iter; left time: 297.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0799626 Vali Loss: 0.0787696 Test Loss: 0.1272044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821803\n",
      "\tspeed: 0.0377s/iter; left time: 629.2086s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780077\n",
      "\tspeed: 0.0181s/iter; left time: 300.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0799785 Vali Loss: 0.0786442 Test Loss: 0.1239915\n",
      "Validation loss decreased (0.078671 --> 0.078644).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0795876\n",
      "\tspeed: 0.0400s/iter; left time: 659.8528s\n",
      "\titers: 200, epoch: 27 | loss: 0.0790085\n",
      "\tspeed: 0.0204s/iter; left time: 334.6971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0797704 Vali Loss: 0.0786359 Test Loss: 0.1259093\n",
      "Validation loss decreased (0.078644 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0818633\n",
      "\tspeed: 0.0381s/iter; left time: 619.7570s\n",
      "\titers: 200, epoch: 28 | loss: 0.0793344\n",
      "\tspeed: 0.0174s/iter; left time: 280.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0797060 Vali Loss: 0.0784768 Test Loss: 0.1269663\n",
      "Validation loss decreased (0.078636 --> 0.078477).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0812629\n",
      "\tspeed: 0.0433s/iter; left time: 694.5047s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797160\n",
      "\tspeed: 0.0183s/iter; left time: 291.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0796613 Vali Loss: 0.0785777 Test Loss: 0.1275836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0785135\n",
      "\tspeed: 0.0379s/iter; left time: 599.4292s\n",
      "\titers: 200, epoch: 30 | loss: 0.0747149\n",
      "\tspeed: 0.0176s/iter; left time: 276.6621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0795775 Vali Loss: 0.0786406 Test Loss: 0.1256996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0790730\n",
      "\tspeed: 0.0373s/iter; left time: 581.5883s\n",
      "\titers: 200, epoch: 31 | loss: 0.0801010\n",
      "\tspeed: 0.0184s/iter; left time: 285.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0794757 Vali Loss: 0.0785512 Test Loss: 0.1254068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0801477\n",
      "\tspeed: 0.0377s/iter; left time: 578.5869s\n",
      "\titers: 200, epoch: 32 | loss: 0.0805202\n",
      "\tspeed: 0.0183s/iter; left time: 279.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0794999 Vali Loss: 0.0785085 Test Loss: 0.1251069\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760565\n",
      "\tspeed: 0.0374s/iter; left time: 566.3457s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793328\n",
      "\tspeed: 0.0176s/iter; left time: 264.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0795171 Vali Loss: 0.0785686 Test Loss: 0.1274197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0773843\n",
      "\tspeed: 0.0380s/iter; left time: 566.1015s\n",
      "\titers: 200, epoch: 34 | loss: 0.0792592\n",
      "\tspeed: 0.0175s/iter; left time: 259.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0794413 Vali Loss: 0.0782065 Test Loss: 0.1235717\n",
      "Validation loss decreased (0.078477 --> 0.078206).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0784409\n",
      "\tspeed: 0.0379s/iter; left time: 556.2497s\n",
      "\titers: 200, epoch: 35 | loss: 0.0783178\n",
      "\tspeed: 0.0173s/iter; left time: 252.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0795024 Vali Loss: 0.0784416 Test Loss: 0.1234996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0821839\n",
      "\tspeed: 0.0375s/iter; left time: 542.2428s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777974\n",
      "\tspeed: 0.0202s/iter; left time: 290.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0781588 Test Loss: 0.1211270\n",
      "Validation loss decreased (0.078206 --> 0.078159).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0747080\n",
      "\tspeed: 0.0436s/iter; left time: 621.1374s\n",
      "\titers: 200, epoch: 37 | loss: 0.0795331\n",
      "\tspeed: 0.0195s/iter; left time: 275.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0792608 Vali Loss: 0.0784312 Test Loss: 0.1257160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0776572\n",
      "\tspeed: 0.0381s/iter; left time: 534.0900s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762254\n",
      "\tspeed: 0.0176s/iter; left time: 244.4825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0794165 Vali Loss: 0.0782640 Test Loss: 0.1224292\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0813769\n",
      "\tspeed: 0.0422s/iter; left time: 581.9967s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792352\n",
      "\tspeed: 0.0209s/iter; left time: 285.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0793261 Vali Loss: 0.0783679 Test Loss: 0.1225942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799571\n",
      "\tspeed: 0.0374s/iter; left time: 507.9205s\n",
      "\titers: 200, epoch: 40 | loss: 0.0804243\n",
      "\tspeed: 0.0174s/iter; left time: 233.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0792455 Vali Loss: 0.0784150 Test Loss: 0.1252133\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0813761\n",
      "\tspeed: 0.0372s/iter; left time: 495.7526s\n",
      "\titers: 200, epoch: 41 | loss: 0.0816666\n",
      "\tspeed: 0.0174s/iter; left time: 230.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0792573 Vali Loss: 0.0782532 Test Loss: 0.1225800\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0778905\n",
      "\tspeed: 0.0373s/iter; left time: 489.1493s\n",
      "\titers: 200, epoch: 42 | loss: 0.0788236\n",
      "\tspeed: 0.0176s/iter; left time: 229.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0792435 Vali Loss: 0.0781906 Test Loss: 0.1238133\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0783627\n",
      "\tspeed: 0.0393s/iter; left time: 506.2812s\n",
      "\titers: 200, epoch: 43 | loss: 0.0787241\n",
      "\tspeed: 0.0207s/iter; left time: 264.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0793239 Vali Loss: 0.0781083 Test Loss: 0.1231488\n",
      "Validation loss decreased (0.078159 --> 0.078108).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0763025\n",
      "\tspeed: 0.0416s/iter; left time: 526.6662s\n",
      "\titers: 200, epoch: 44 | loss: 0.0738823\n",
      "\tspeed: 0.0199s/iter; left time: 249.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0792564 Vali Loss: 0.0784912 Test Loss: 0.1267495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0757882\n",
      "\tspeed: 0.0410s/iter; left time: 509.6752s\n",
      "\titers: 200, epoch: 45 | loss: 0.0789459\n",
      "\tspeed: 0.0174s/iter; left time: 214.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0793981 Vali Loss: 0.0783084 Test Loss: 0.1237282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0772759\n",
      "\tspeed: 0.0376s/iter; left time: 459.7951s\n",
      "\titers: 200, epoch: 46 | loss: 0.0767787\n",
      "\tspeed: 0.0177s/iter; left time: 214.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0790786 Vali Loss: 0.0783964 Test Loss: 0.1239477\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0750165\n",
      "\tspeed: 0.0380s/iter; left time: 456.1696s\n",
      "\titers: 200, epoch: 47 | loss: 0.0791191\n",
      "\tspeed: 0.0177s/iter; left time: 210.7319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0791732 Vali Loss: 0.0784350 Test Loss: 0.1260129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0822771\n",
      "\tspeed: 0.0387s/iter; left time: 455.5598s\n",
      "\titers: 200, epoch: 48 | loss: 0.0833114\n",
      "\tspeed: 0.0200s/iter; left time: 233.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0792517 Vali Loss: 0.0783070 Test Loss: 0.1245301\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0782012\n",
      "\tspeed: 0.0379s/iter; left time: 437.8831s\n",
      "\titers: 200, epoch: 49 | loss: 0.0790513\n",
      "\tspeed: 0.0182s/iter; left time: 208.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0790816 Vali Loss: 0.0784223 Test Loss: 0.1252991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0769528\n",
      "\tspeed: 0.0378s/iter; left time: 428.5405s\n",
      "\titers: 200, epoch: 50 | loss: 0.0796110\n",
      "\tspeed: 0.0183s/iter; left time: 205.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0792062 Vali Loss: 0.0781806 Test Loss: 0.1240269\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0821458\n",
      "\tspeed: 0.0405s/iter; left time: 449.8227s\n",
      "\titers: 200, epoch: 51 | loss: 0.0748606\n",
      "\tspeed: 0.0208s/iter; left time: 229.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0791860 Vali Loss: 0.0783969 Test Loss: 0.1252220\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0788861\n",
      "\tspeed: 0.0389s/iter; left time: 423.1191s\n",
      "\titers: 200, epoch: 52 | loss: 0.0744792\n",
      "\tspeed: 0.0175s/iter; left time: 188.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0791129 Vali Loss: 0.0783578 Test Loss: 0.1260209\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0779445\n",
      "\tspeed: 0.0373s/iter; left time: 397.8023s\n",
      "\titers: 200, epoch: 53 | loss: 0.0807185\n",
      "\tspeed: 0.0175s/iter; left time: 184.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0790737 Vali Loss: 0.0782593 Test Loss: 0.1245420\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04175650700926781, rmse:0.20434409379959106, mae:0.1231488287448883, rse:0.6003013849258423\n",
      "Intermediate time for ES and pred_len 96: 00h:09m:48.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2749318\n",
      "\tspeed: 0.0415s/iter; left time: 920.3683s\n",
      "\titers: 200, epoch: 1 | loss: 0.2637250\n",
      "\tspeed: 0.0177s/iter; left time: 390.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.2789764 Vali Loss: 0.2100756 Test Loss: 0.2343825\n",
      "Validation loss decreased (inf --> 0.210076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1421229\n",
      "\tspeed: 0.0373s/iter; left time: 819.5815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1207080\n",
      "\tspeed: 0.0177s/iter; left time: 388.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1543833 Vali Loss: 0.1086527 Test Loss: 0.1232387\n",
      "Validation loss decreased (0.210076 --> 0.108653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1143583\n",
      "\tspeed: 0.0381s/iter; left time: 829.6279s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035095\n",
      "\tspeed: 0.0180s/iter; left time: 390.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1096992 Vali Loss: 0.0961292 Test Loss: 0.1119838\n",
      "Validation loss decreased (0.108653 --> 0.096129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991537\n",
      "\tspeed: 0.0379s/iter; left time: 817.1208s\n",
      "\titers: 200, epoch: 4 | loss: 0.0941834\n",
      "\tspeed: 0.0179s/iter; left time: 383.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0979566 Vali Loss: 0.0913458 Test Loss: 0.1117256\n",
      "Validation loss decreased (0.096129 --> 0.091346).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948883\n",
      "\tspeed: 0.0376s/iter; left time: 801.8857s\n",
      "\titers: 200, epoch: 5 | loss: 0.0904951\n",
      "\tspeed: 0.0181s/iter; left time: 383.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0934428 Vali Loss: 0.0899405 Test Loss: 0.1138975\n",
      "Validation loss decreased (0.091346 --> 0.089940).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889967\n",
      "\tspeed: 0.0388s/iter; left time: 817.4538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896095\n",
      "\tspeed: 0.0178s/iter; left time: 373.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0908615 Vali Loss: 0.0874881 Test Loss: 0.1135529\n",
      "Validation loss decreased (0.089940 --> 0.087488).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891786\n",
      "\tspeed: 0.0377s/iter; left time: 786.8146s\n",
      "\titers: 200, epoch: 7 | loss: 0.0887473\n",
      "\tspeed: 0.0177s/iter; left time: 368.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0893473 Vali Loss: 0.0867286 Test Loss: 0.1134460\n",
      "Validation loss decreased (0.087488 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847037\n",
      "\tspeed: 0.0387s/iter; left time: 798.8800s\n",
      "\titers: 200, epoch: 8 | loss: 0.0879599\n",
      "\tspeed: 0.0177s/iter; left time: 363.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0882717 Vali Loss: 0.0867410 Test Loss: 0.1150925\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0870168\n",
      "\tspeed: 0.0381s/iter; left time: 777.2110s\n",
      "\titers: 200, epoch: 9 | loss: 0.0849715\n",
      "\tspeed: 0.0178s/iter; left time: 361.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0878216 Vali Loss: 0.0872022 Test Loss: 0.1176080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0875702\n",
      "\tspeed: 0.0378s/iter; left time: 762.7947s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899240\n",
      "\tspeed: 0.0181s/iter; left time: 364.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0869609 Vali Loss: 0.0860930 Test Loss: 0.1131297\n",
      "Validation loss decreased (0.086729 --> 0.086093).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0882442\n",
      "\tspeed: 0.0385s/iter; left time: 769.2968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0836711\n",
      "\tspeed: 0.0179s/iter; left time: 355.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0865654 Vali Loss: 0.0859699 Test Loss: 0.1132639\n",
      "Validation loss decreased (0.086093 --> 0.085970).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0827679\n",
      "\tspeed: 0.0383s/iter; left time: 755.5015s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866363\n",
      "\tspeed: 0.0177s/iter; left time: 347.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0860623 Vali Loss: 0.0858304 Test Loss: 0.1128382\n",
      "Validation loss decreased (0.085970 --> 0.085830).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0829732\n",
      "\tspeed: 0.0378s/iter; left time: 738.1925s\n",
      "\titers: 200, epoch: 13 | loss: 0.0850765\n",
      "\tspeed: 0.0177s/iter; left time: 343.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0856914 Vali Loss: 0.0856651 Test Loss: 0.1135978\n",
      "Validation loss decreased (0.085830 --> 0.085665).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841183\n",
      "\tspeed: 0.0396s/iter; left time: 763.7380s\n",
      "\titers: 200, epoch: 14 | loss: 0.0859597\n",
      "\tspeed: 0.0177s/iter; left time: 340.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0852342 Vali Loss: 0.0856685 Test Loss: 0.1136733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842968\n",
      "\tspeed: 0.0382s/iter; left time: 729.1758s\n",
      "\titers: 200, epoch: 15 | loss: 0.0909677\n",
      "\tspeed: 0.0178s/iter; left time: 337.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0852555 Vali Loss: 0.0855243 Test Loss: 0.1138341\n",
      "Validation loss decreased (0.085665 --> 0.085524).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0852345\n",
      "\tspeed: 0.0382s/iter; left time: 720.0223s\n",
      "\titers: 200, epoch: 16 | loss: 0.0851248\n",
      "\tspeed: 0.0203s/iter; left time: 380.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0847901 Vali Loss: 0.0851691 Test Loss: 0.1139723\n",
      "Validation loss decreased (0.085524 --> 0.085169).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0839362\n",
      "\tspeed: 0.0385s/iter; left time: 717.8357s\n",
      "\titers: 200, epoch: 17 | loss: 0.0833548\n",
      "\tspeed: 0.0177s/iter; left time: 328.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0845173 Vali Loss: 0.0850614 Test Loss: 0.1140275\n",
      "Validation loss decreased (0.085169 --> 0.085061).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0813416\n",
      "\tspeed: 0.0377s/iter; left time: 693.3347s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866940\n",
      "\tspeed: 0.0192s/iter; left time: 351.3236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0843307 Vali Loss: 0.0847981 Test Loss: 0.1144203\n",
      "Validation loss decreased (0.085061 --> 0.084798).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0843313\n",
      "\tspeed: 0.0381s/iter; left time: 693.2385s\n",
      "\titers: 200, epoch: 19 | loss: 0.0832647\n",
      "\tspeed: 0.0180s/iter; left time: 325.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0842799 Vali Loss: 0.0846771 Test Loss: 0.1141960\n",
      "Validation loss decreased (0.084798 --> 0.084677).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0862335\n",
      "\tspeed: 0.0379s/iter; left time: 681.4529s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817612\n",
      "\tspeed: 0.0178s/iter; left time: 318.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0838804 Vali Loss: 0.0843563 Test Loss: 0.1145415\n",
      "Validation loss decreased (0.084677 --> 0.084356).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0837195\n",
      "\tspeed: 0.0404s/iter; left time: 716.5821s\n",
      "\titers: 200, epoch: 21 | loss: 0.1031141\n",
      "\tspeed: 0.0202s/iter; left time: 356.7964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0839049 Vali Loss: 0.0849667 Test Loss: 0.1150237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0836587\n",
      "\tspeed: 0.0377s/iter; left time: 660.8575s\n",
      "\titers: 200, epoch: 22 | loss: 0.0852197\n",
      "\tspeed: 0.0179s/iter; left time: 311.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0837684 Vali Loss: 0.0846416 Test Loss: 0.1158141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0795333\n",
      "\tspeed: 0.0383s/iter; left time: 663.0939s\n",
      "\titers: 200, epoch: 23 | loss: 0.0865810\n",
      "\tspeed: 0.0178s/iter; left time: 306.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0835962 Vali Loss: 0.0847980 Test Loss: 0.1160617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0831024\n",
      "\tspeed: 0.0373s/iter; left time: 637.2761s\n",
      "\titers: 200, epoch: 24 | loss: 0.0805572\n",
      "\tspeed: 0.0177s/iter; left time: 299.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0839736 Vali Loss: 0.0847975 Test Loss: 0.1165650\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0849554\n",
      "\tspeed: 0.0380s/iter; left time: 639.8876s\n",
      "\titers: 200, epoch: 25 | loss: 0.0840587\n",
      "\tspeed: 0.0189s/iter; left time: 316.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0834544 Vali Loss: 0.0845328 Test Loss: 0.1162506\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0892217\n",
      "\tspeed: 0.0375s/iter; left time: 623.1592s\n",
      "\titers: 200, epoch: 26 | loss: 0.0807220\n",
      "\tspeed: 0.0183s/iter; left time: 302.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0833992 Vali Loss: 0.0846728 Test Loss: 0.1164240\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810502\n",
      "\tspeed: 0.0385s/iter; left time: 630.8216s\n",
      "\titers: 200, epoch: 27 | loss: 0.0854318\n",
      "\tspeed: 0.0178s/iter; left time: 291.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0833067 Vali Loss: 0.0845248 Test Loss: 0.1158283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0797867\n",
      "\tspeed: 0.0403s/iter; left time: 651.9570s\n",
      "\titers: 200, epoch: 28 | loss: 0.0819262\n",
      "\tspeed: 0.0194s/iter; left time: 312.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0833002 Vali Loss: 0.0843592 Test Loss: 0.1163825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0846014\n",
      "\tspeed: 0.0374s/iter; left time: 597.1936s\n",
      "\titers: 200, epoch: 29 | loss: 0.0876969\n",
      "\tspeed: 0.0177s/iter; left time: 280.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0833116 Vali Loss: 0.0845298 Test Loss: 0.1166252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0819796\n",
      "\tspeed: 0.0395s/iter; left time: 621.2215s\n",
      "\titers: 200, epoch: 30 | loss: 0.0857283\n",
      "\tspeed: 0.0219s/iter; left time: 342.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0831343 Vali Loss: 0.0845026 Test Loss: 0.1163839\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0290948748588562, rmse:0.1705721914768219, mae:0.11454156041145325, rse:0.5011257529258728\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2807395\n",
      "\tspeed: 0.0197s/iter; left time: 437.4888s\n",
      "\titers: 200, epoch: 1 | loss: 0.2651633\n",
      "\tspeed: 0.0177s/iter; left time: 391.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.2830992 Vali Loss: 0.2142654 Test Loss: 0.2370222\n",
      "Validation loss decreased (inf --> 0.214265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453094\n",
      "\tspeed: 0.0382s/iter; left time: 840.0588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242578\n",
      "\tspeed: 0.0180s/iter; left time: 393.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1572299 Vali Loss: 0.1083790 Test Loss: 0.1231012\n",
      "Validation loss decreased (0.214265 --> 0.108379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1133961\n",
      "\tspeed: 0.0428s/iter; left time: 932.0011s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982893\n",
      "\tspeed: 0.0208s/iter; left time: 451.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1100277 Vali Loss: 0.0972046 Test Loss: 0.1224924\n",
      "Validation loss decreased (0.108379 --> 0.097205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974868\n",
      "\tspeed: 0.0402s/iter; left time: 864.6889s\n",
      "\titers: 200, epoch: 4 | loss: 0.0972847\n",
      "\tspeed: 0.0178s/iter; left time: 382.2048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0984315 Vali Loss: 0.0914870 Test Loss: 0.1193569\n",
      "Validation loss decreased (0.097205 --> 0.091487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0947529\n",
      "\tspeed: 0.0390s/iter; left time: 831.2727s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937127\n",
      "\tspeed: 0.0188s/iter; left time: 399.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0946569 Vali Loss: 0.0894347 Test Loss: 0.1191490\n",
      "Validation loss decreased (0.091487 --> 0.089435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918505\n",
      "\tspeed: 0.0394s/iter; left time: 831.3602s\n",
      "\titers: 200, epoch: 6 | loss: 0.0901247\n",
      "\tspeed: 0.0179s/iter; left time: 375.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0917058 Vali Loss: 0.0881212 Test Loss: 0.1236080\n",
      "Validation loss decreased (0.089435 --> 0.088121).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917704\n",
      "\tspeed: 0.0382s/iter; left time: 797.0048s\n",
      "\titers: 200, epoch: 7 | loss: 0.0922219\n",
      "\tspeed: 0.0178s/iter; left time: 370.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0899804 Vali Loss: 0.0864551 Test Loss: 0.1166708\n",
      "Validation loss decreased (0.088121 --> 0.086455).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0917562\n",
      "\tspeed: 0.0390s/iter; left time: 805.6186s\n",
      "\titers: 200, epoch: 8 | loss: 0.0877953\n",
      "\tspeed: 0.0177s/iter; left time: 363.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0890128 Vali Loss: 0.0861659 Test Loss: 0.1123231\n",
      "Validation loss decreased (0.086455 --> 0.086166).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919937\n",
      "\tspeed: 0.0386s/iter; left time: 787.5926s\n",
      "\titers: 200, epoch: 9 | loss: 0.0899467\n",
      "\tspeed: 0.0178s/iter; left time: 362.6346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0910410 Vali Loss: 0.0899233 Test Loss: 0.1119124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0895764\n",
      "\tspeed: 0.0380s/iter; left time: 767.0532s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906453\n",
      "\tspeed: 0.0177s/iter; left time: 355.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0887168 Vali Loss: 0.0859634 Test Loss: 0.1185711\n",
      "Validation loss decreased (0.086166 --> 0.085963).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0892631\n",
      "\tspeed: 0.0378s/iter; left time: 754.8397s\n",
      "\titers: 200, epoch: 11 | loss: 0.0895315\n",
      "\tspeed: 0.0177s/iter; left time: 351.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0871117 Vali Loss: 0.0853329 Test Loss: 0.1164193\n",
      "Validation loss decreased (0.085963 --> 0.085333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0869905\n",
      "\tspeed: 0.0381s/iter; left time: 752.4551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0848289\n",
      "\tspeed: 0.0178s/iter; left time: 349.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0865530 Vali Loss: 0.0852942 Test Loss: 0.1179176\n",
      "Validation loss decreased (0.085333 --> 0.085294).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0864150\n",
      "\tspeed: 0.0386s/iter; left time: 752.7703s\n",
      "\titers: 200, epoch: 13 | loss: 0.0838847\n",
      "\tspeed: 0.0177s/iter; left time: 343.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0862789 Vali Loss: 0.0850571 Test Loss: 0.1164684\n",
      "Validation loss decreased (0.085294 --> 0.085057).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0867992\n",
      "\tspeed: 0.0388s/iter; left time: 748.5236s\n",
      "\titers: 200, epoch: 14 | loss: 0.0845527\n",
      "\tspeed: 0.0177s/iter; left time: 338.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0858124 Vali Loss: 0.0850595 Test Loss: 0.1153065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0845146\n",
      "\tspeed: 0.0378s/iter; left time: 721.2674s\n",
      "\titers: 200, epoch: 15 | loss: 0.0846549\n",
      "\tspeed: 0.0182s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0856219 Vali Loss: 0.0849426 Test Loss: 0.1166757\n",
      "Validation loss decreased (0.085057 --> 0.084943).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0845102\n",
      "\tspeed: 0.0407s/iter; left time: 766.9892s\n",
      "\titers: 200, epoch: 16 | loss: 0.0888782\n",
      "\tspeed: 0.0199s/iter; left time: 373.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0858942 Vali Loss: 0.0853336 Test Loss: 0.1119651\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0912922\n",
      "\tspeed: 0.0378s/iter; left time: 703.8816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0889382\n",
      "\tspeed: 0.0177s/iter; left time: 327.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0856840 Vali Loss: 0.0851839 Test Loss: 0.1192388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0845657\n",
      "\tspeed: 0.0402s/iter; left time: 739.8128s\n",
      "\titers: 200, epoch: 18 | loss: 0.0815924\n",
      "\tspeed: 0.0180s/iter; left time: 329.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0849107 Vali Loss: 0.0853217 Test Loss: 0.1206380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0849029\n",
      "\tspeed: 0.0380s/iter; left time: 690.7471s\n",
      "\titers: 200, epoch: 19 | loss: 0.0853960\n",
      "\tspeed: 0.0179s/iter; left time: 323.5752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0848261 Vali Loss: 0.0846747 Test Loss: 0.1192671\n",
      "Validation loss decreased (0.084943 --> 0.084675).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811674\n",
      "\tspeed: 0.0386s/iter; left time: 693.0126s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817534\n",
      "\tspeed: 0.0178s/iter; left time: 318.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0845942 Vali Loss: 0.0847365 Test Loss: 0.1183660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0826207\n",
      "\tspeed: 0.0375s/iter; left time: 665.2076s\n",
      "\titers: 200, epoch: 21 | loss: 0.0816803\n",
      "\tspeed: 0.0177s/iter; left time: 312.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0843873 Vali Loss: 0.0846548 Test Loss: 0.1183502\n",
      "Validation loss decreased (0.084675 --> 0.084655).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834691\n",
      "\tspeed: 0.0381s/iter; left time: 667.4153s\n",
      "\titers: 200, epoch: 22 | loss: 0.0883418\n",
      "\tspeed: 0.0185s/iter; left time: 322.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0843994 Vali Loss: 0.0845420 Test Loss: 0.1178532\n",
      "Validation loss decreased (0.084655 --> 0.084542).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0847441\n",
      "\tspeed: 0.0384s/iter; left time: 663.9202s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805724\n",
      "\tspeed: 0.0178s/iter; left time: 305.8888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0841674 Vali Loss: 0.0844933 Test Loss: 0.1170921\n",
      "Validation loss decreased (0.084542 --> 0.084493).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0839649\n",
      "\tspeed: 0.0392s/iter; left time: 668.4869s\n",
      "\titers: 200, epoch: 24 | loss: 0.0834868\n",
      "\tspeed: 0.0178s/iter; left time: 301.9828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0841976 Vali Loss: 0.0846161 Test Loss: 0.1172125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0881067\n",
      "\tspeed: 0.0398s/iter; left time: 670.4357s\n",
      "\titers: 200, epoch: 25 | loss: 0.0828818\n",
      "\tspeed: 0.0194s/iter; left time: 324.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0841515 Vali Loss: 0.0843772 Test Loss: 0.1175339\n",
      "Validation loss decreased (0.084493 --> 0.084377).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0825793\n",
      "\tspeed: 0.0410s/iter; left time: 682.0217s\n",
      "\titers: 200, epoch: 26 | loss: 0.0856509\n",
      "\tspeed: 0.0181s/iter; left time: 298.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0842238 Vali Loss: 0.0844084 Test Loss: 0.1173107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819396\n",
      "\tspeed: 0.0404s/iter; left time: 662.8102s\n",
      "\titers: 200, epoch: 27 | loss: 0.0869512\n",
      "\tspeed: 0.0195s/iter; left time: 317.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0840297 Vali Loss: 0.0846008 Test Loss: 0.1175796\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0859564\n",
      "\tspeed: 0.0386s/iter; left time: 624.9775s\n",
      "\titers: 200, epoch: 28 | loss: 0.0873584\n",
      "\tspeed: 0.0180s/iter; left time: 289.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0837992 Vali Loss: 0.0845674 Test Loss: 0.1199782\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0821546\n",
      "\tspeed: 0.0382s/iter; left time: 610.2197s\n",
      "\titers: 200, epoch: 29 | loss: 0.0846214\n",
      "\tspeed: 0.0178s/iter; left time: 282.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0837742 Vali Loss: 0.0844055 Test Loss: 0.1191112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0844201\n",
      "\tspeed: 0.0412s/iter; left time: 647.6364s\n",
      "\titers: 200, epoch: 30 | loss: 0.0841895\n",
      "\tspeed: 0.0222s/iter; left time: 346.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0837221 Vali Loss: 0.0842772 Test Loss: 0.1190496\n",
      "Validation loss decreased (0.084377 --> 0.084277).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0870948\n",
      "\tspeed: 0.0393s/iter; left time: 609.4403s\n",
      "\titers: 200, epoch: 31 | loss: 0.0821873\n",
      "\tspeed: 0.0177s/iter; left time: 273.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0836353 Vali Loss: 0.0842929 Test Loss: 0.1206920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0848337\n",
      "\tspeed: 0.0377s/iter; left time: 576.4363s\n",
      "\titers: 200, epoch: 32 | loss: 0.0830336\n",
      "\tspeed: 0.0177s/iter; left time: 268.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0837642 Vali Loss: 0.0842275 Test Loss: 0.1182323\n",
      "Validation loss decreased (0.084277 --> 0.084228).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0846711\n",
      "\tspeed: 0.0395s/iter; left time: 594.5822s\n",
      "\titers: 200, epoch: 33 | loss: 0.0801985\n",
      "\tspeed: 0.0180s/iter; left time: 269.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0836584 Vali Loss: 0.0844522 Test Loss: 0.1194240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836901\n",
      "\tspeed: 0.0381s/iter; left time: 565.8463s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838794\n",
      "\tspeed: 0.0177s/iter; left time: 260.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0836737 Vali Loss: 0.0843503 Test Loss: 0.1194371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0843293\n",
      "\tspeed: 0.0396s/iter; left time: 578.5798s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848211\n",
      "\tspeed: 0.0179s/iter; left time: 259.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0835618 Vali Loss: 0.0844821 Test Loss: 0.1200642\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0810826\n",
      "\tspeed: 0.0387s/iter; left time: 556.7249s\n",
      "\titers: 200, epoch: 36 | loss: 0.0852567\n",
      "\tspeed: 0.0177s/iter; left time: 253.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0838000 Vali Loss: 0.0845061 Test Loss: 0.1194763\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803306\n",
      "\tspeed: 0.0410s/iter; left time: 581.3790s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833322\n",
      "\tspeed: 0.0182s/iter; left time: 255.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0835411 Vali Loss: 0.0843955 Test Loss: 0.1186716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0823816\n",
      "\tspeed: 0.0381s/iter; left time: 531.2084s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843670\n",
      "\tspeed: 0.0181s/iter; left time: 250.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0834298 Vali Loss: 0.0843624 Test Loss: 0.1192587\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0864377\n",
      "\tspeed: 0.0393s/iter; left time: 539.8572s\n",
      "\titers: 200, epoch: 39 | loss: 0.0857570\n",
      "\tspeed: 0.0178s/iter; left time: 242.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0836104 Vali Loss: 0.0843764 Test Loss: 0.1198429\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0814850\n",
      "\tspeed: 0.0378s/iter; left time: 510.7382s\n",
      "\titers: 200, epoch: 40 | loss: 0.0841378\n",
      "\tspeed: 0.0178s/iter; left time: 238.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0839965 Vali Loss: 0.0844893 Test Loss: 0.1194120\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799215\n",
      "\tspeed: 0.0376s/iter; left time: 499.8096s\n",
      "\titers: 200, epoch: 41 | loss: 0.0783022\n",
      "\tspeed: 0.0179s/iter; left time: 235.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0834080 Vali Loss: 0.0841839 Test Loss: 0.1189149\n",
      "Validation loss decreased (0.084228 --> 0.084184).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0835249\n",
      "\tspeed: 0.0388s/iter; left time: 506.5320s\n",
      "\titers: 200, epoch: 42 | loss: 0.0811903\n",
      "\tspeed: 0.0178s/iter; left time: 230.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0834037 Vali Loss: 0.0844404 Test Loss: 0.1207593\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0831517\n",
      "\tspeed: 0.0379s/iter; left time: 486.5615s\n",
      "\titers: 200, epoch: 43 | loss: 0.0815078\n",
      "\tspeed: 0.0177s/iter; left time: 225.4865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0834141 Vali Loss: 0.0845041 Test Loss: 0.1203174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0865642\n",
      "\tspeed: 0.0378s/iter; left time: 477.0652s\n",
      "\titers: 200, epoch: 44 | loss: 0.0847886\n",
      "\tspeed: 0.0182s/iter; left time: 227.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0835477 Vali Loss: 0.0844085 Test Loss: 0.1198660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0788437\n",
      "\tspeed: 0.0417s/iter; left time: 516.0462s\n",
      "\titers: 200, epoch: 45 | loss: 0.0816742\n",
      "\tspeed: 0.0179s/iter; left time: 220.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0834426 Vali Loss: 0.0842027 Test Loss: 0.1195737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830794\n",
      "\tspeed: 0.0397s/iter; left time: 482.8533s\n",
      "\titers: 200, epoch: 46 | loss: 0.0839437\n",
      "\tspeed: 0.0186s/iter; left time: 224.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0833704 Vali Loss: 0.0842480 Test Loss: 0.1193747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0823590\n",
      "\tspeed: 0.0385s/iter; left time: 459.4566s\n",
      "\titers: 200, epoch: 47 | loss: 0.0856680\n",
      "\tspeed: 0.0177s/iter; left time: 209.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0832862 Vali Loss: 0.0841228 Test Loss: 0.1197550\n",
      "Validation loss decreased (0.084184 --> 0.084123).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0883429\n",
      "\tspeed: 0.0387s/iter; left time: 453.8099s\n",
      "\titers: 200, epoch: 48 | loss: 0.0826623\n",
      "\tspeed: 0.0177s/iter; left time: 205.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0833737 Vali Loss: 0.0842797 Test Loss: 0.1200274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0815217\n",
      "\tspeed: 0.0387s/iter; left time: 444.5435s\n",
      "\titers: 200, epoch: 49 | loss: 0.0848437\n",
      "\tspeed: 0.0184s/iter; left time: 209.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0833760 Vali Loss: 0.0841590 Test Loss: 0.1200445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0827644\n",
      "\tspeed: 0.0379s/iter; left time: 427.7059s\n",
      "\titers: 200, epoch: 50 | loss: 0.0767582\n",
      "\tspeed: 0.0177s/iter; left time: 197.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0832877 Vali Loss: 0.0839660 Test Loss: 0.1184397\n",
      "Validation loss decreased (0.084123 --> 0.083966).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0835075\n",
      "\tspeed: 0.0384s/iter; left time: 424.8004s\n",
      "\titers: 200, epoch: 51 | loss: 0.0817596\n",
      "\tspeed: 0.0177s/iter; left time: 193.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0832505 Vali Loss: 0.0842132 Test Loss: 0.1197245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0808008\n",
      "\tspeed: 0.0377s/iter; left time: 408.7473s\n",
      "\titers: 200, epoch: 52 | loss: 0.0849158\n",
      "\tspeed: 0.0181s/iter; left time: 194.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0834962 Vali Loss: 0.0841127 Test Loss: 0.1192776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800299\n",
      "\tspeed: 0.0407s/iter; left time: 431.5793s\n",
      "\titers: 200, epoch: 53 | loss: 0.0820698\n",
      "\tspeed: 0.0179s/iter; left time: 188.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0832694 Vali Loss: 0.0842121 Test Loss: 0.1194684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802618\n",
      "\tspeed: 0.0379s/iter; left time: 393.3319s\n",
      "\titers: 200, epoch: 54 | loss: 0.0827059\n",
      "\tspeed: 0.0178s/iter; left time: 183.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0833176 Vali Loss: 0.0842278 Test Loss: 0.1203044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0861164\n",
      "\tspeed: 0.0401s/iter; left time: 407.5977s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852268\n",
      "\tspeed: 0.0187s/iter; left time: 187.8602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0833072 Vali Loss: 0.0842820 Test Loss: 0.1206407\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0806998\n",
      "\tspeed: 0.0387s/iter; left time: 384.6696s\n",
      "\titers: 200, epoch: 56 | loss: 0.0823214\n",
      "\tspeed: 0.0178s/iter; left time: 174.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0834395 Vali Loss: 0.0842447 Test Loss: 0.1202066\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0837483\n",
      "\tspeed: 0.0387s/iter; left time: 376.3452s\n",
      "\titers: 200, epoch: 57 | loss: 0.0801571\n",
      "\tspeed: 0.0197s/iter; left time: 189.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0833268 Vali Loss: 0.0842674 Test Loss: 0.1203132\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0821808\n",
      "\tspeed: 0.0419s/iter; left time: 397.5706s\n",
      "\titers: 200, epoch: 58 | loss: 0.0829196\n",
      "\tspeed: 0.0200s/iter; left time: 187.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0832269 Vali Loss: 0.0843088 Test Loss: 0.1198582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0822175\n",
      "\tspeed: 0.0380s/iter; left time: 352.3228s\n",
      "\titers: 200, epoch: 59 | loss: 0.0831296\n",
      "\tspeed: 0.0177s/iter; left time: 162.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0833064 Vali Loss: 0.0840443 Test Loss: 0.1194816\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0843803\n",
      "\tspeed: 0.0383s/iter; left time: 346.6295s\n",
      "\titers: 200, epoch: 60 | loss: 0.0825238\n",
      "\tspeed: 0.0177s/iter; left time: 158.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0836524 Vali Loss: 0.0842534 Test Loss: 0.1202688\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03208500146865845, rmse:0.17912286520004272, mae:0.1184396892786026, rse:0.5262468457221985\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:43.78s\n",
      "Intermediate time for ES: 00h:29m:19.98s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2387870\n",
      "\tspeed: 0.0372s/iter; left time: 836.6014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2139293\n",
      "\tspeed: 0.0166s/iter; left time: 371.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.2391190 Vali Loss: 0.1718954 Test Loss: 0.1789114\n",
      "Validation loss decreased (inf --> 0.171895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1444989\n",
      "\tspeed: 0.0290s/iter; left time: 646.5466s\n",
      "\titers: 200, epoch: 2 | loss: 0.1030055\n",
      "\tspeed: 0.0164s/iter; left time: 364.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.1399414 Vali Loss: 0.0846169 Test Loss: 0.0930004\n",
      "Validation loss decreased (0.171895 --> 0.084617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0855119\n",
      "\tspeed: 0.0387s/iter; left time: 853.1069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0796396\n",
      "\tspeed: 0.0195s/iter; left time: 428.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 226 | Train Loss: 0.0862447 Vali Loss: 0.0776337 Test Loss: 0.0803794\n",
      "Validation loss decreased (0.084617 --> 0.077634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774116\n",
      "\tspeed: 0.0269s/iter; left time: 587.9104s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713846\n",
      "\tspeed: 0.0107s/iter; left time: 232.0666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.62s\n",
      "Steps: 226 | Train Loss: 0.0744315 Vali Loss: 0.0723683 Test Loss: 0.0729725\n",
      "Validation loss decreased (0.077634 --> 0.072368).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0675851\n",
      "\tspeed: 0.0273s/iter; left time: 589.1216s\n",
      "\titers: 200, epoch: 5 | loss: 0.0648144\n",
      "\tspeed: 0.0164s/iter; left time: 353.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0683895 Vali Loss: 0.0677736 Test Loss: 0.0678707\n",
      "Validation loss decreased (0.072368 --> 0.067774).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0625560\n",
      "\tspeed: 0.0329s/iter; left time: 702.1603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0605061\n",
      "\tspeed: 0.0172s/iter; left time: 365.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0641057 Vali Loss: 0.0669710 Test Loss: 0.0681956\n",
      "Validation loss decreased (0.067774 --> 0.066971).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0640559\n",
      "\tspeed: 0.0319s/iter; left time: 674.4038s\n",
      "\titers: 200, epoch: 7 | loss: 0.0622133\n",
      "\tspeed: 0.0175s/iter; left time: 368.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0617407 Vali Loss: 0.0671168 Test Loss: 0.0687033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596539\n",
      "\tspeed: 0.0319s/iter; left time: 667.6760s\n",
      "\titers: 200, epoch: 8 | loss: 0.0568511\n",
      "\tspeed: 0.0163s/iter; left time: 338.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0595213 Vali Loss: 0.0637386 Test Loss: 0.0658388\n",
      "Validation loss decreased (0.066971 --> 0.063739).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613193\n",
      "\tspeed: 0.0376s/iter; left time: 778.7144s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555061\n",
      "\tspeed: 0.0194s/iter; left time: 399.3243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0582117 Vali Loss: 0.0640913 Test Loss: 0.0660351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564618\n",
      "\tspeed: 0.0343s/iter; left time: 701.3254s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569139\n",
      "\tspeed: 0.0157s/iter; left time: 319.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0570274 Vali Loss: 0.0628751 Test Loss: 0.0648090\n",
      "Validation loss decreased (0.063739 --> 0.062875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0547675\n",
      "\tspeed: 0.0329s/iter; left time: 665.4400s\n",
      "\titers: 200, epoch: 11 | loss: 0.0522877\n",
      "\tspeed: 0.0181s/iter; left time: 364.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0563346 Vali Loss: 0.0616423 Test Loss: 0.0636703\n",
      "Validation loss decreased (0.062875 --> 0.061642).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0635433\n",
      "\tspeed: 0.0306s/iter; left time: 612.2893s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654986\n",
      "\tspeed: 0.0203s/iter; left time: 403.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0555374 Vali Loss: 0.0614510 Test Loss: 0.0635653\n",
      "Validation loss decreased (0.061642 --> 0.061451).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0531383\n",
      "\tspeed: 0.0375s/iter; left time: 742.8981s\n",
      "\titers: 200, epoch: 13 | loss: 0.0553830\n",
      "\tspeed: 0.0205s/iter; left time: 404.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 226 | Train Loss: 0.0548404 Vali Loss: 0.0604893 Test Loss: 0.0627076\n",
      "Validation loss decreased (0.061451 --> 0.060489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0534457\n",
      "\tspeed: 0.0387s/iter; left time: 757.3095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0527696\n",
      "\tspeed: 0.0148s/iter; left time: 288.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0542413 Vali Loss: 0.0604573 Test Loss: 0.0628189\n",
      "Validation loss decreased (0.060489 --> 0.060457).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518984\n",
      "\tspeed: 0.0321s/iter; left time: 621.0095s\n",
      "\titers: 200, epoch: 15 | loss: 0.0516676\n",
      "\tspeed: 0.0169s/iter; left time: 324.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0537804 Vali Loss: 0.0600585 Test Loss: 0.0623806\n",
      "Validation loss decreased (0.060457 --> 0.060059).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550333\n",
      "\tspeed: 0.0327s/iter; left time: 625.8643s\n",
      "\titers: 200, epoch: 16 | loss: 0.0510157\n",
      "\tspeed: 0.0168s/iter; left time: 318.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0535094 Vali Loss: 0.0602220 Test Loss: 0.0625936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0523797\n",
      "\tspeed: 0.0357s/iter; left time: 674.3092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0531689\n",
      "\tspeed: 0.0221s/iter; left time: 414.3207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 226 | Train Loss: 0.0532145 Vali Loss: 0.0605116 Test Loss: 0.0627661\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0516262\n",
      "\tspeed: 0.0306s/iter; left time: 570.1852s\n",
      "\titers: 200, epoch: 18 | loss: 0.0522057\n",
      "\tspeed: 0.0132s/iter; left time: 245.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0530755 Vali Loss: 0.0596637 Test Loss: 0.0620338\n",
      "Validation loss decreased (0.060059 --> 0.059664).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0540840\n",
      "\tspeed: 0.0358s/iter; left time: 660.1307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570081\n",
      "\tspeed: 0.0213s/iter; left time: 390.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0527678 Vali Loss: 0.0602670 Test Loss: 0.0627092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0530464\n",
      "\tspeed: 0.0343s/iter; left time: 625.0790s\n",
      "\titers: 200, epoch: 20 | loss: 0.0567837\n",
      "\tspeed: 0.0123s/iter; left time: 222.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0526713 Vali Loss: 0.0596454 Test Loss: 0.0620650\n",
      "Validation loss decreased (0.059664 --> 0.059645).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0499494\n",
      "\tspeed: 0.0331s/iter; left time: 595.3982s\n",
      "\titers: 200, epoch: 21 | loss: 0.0520596\n",
      "\tspeed: 0.0243s/iter; left time: 434.1204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 226 | Train Loss: 0.0523840 Vali Loss: 0.0598361 Test Loss: 0.0620769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0509677\n",
      "\tspeed: 0.0362s/iter; left time: 642.1720s\n",
      "\titers: 200, epoch: 22 | loss: 0.0528032\n",
      "\tspeed: 0.0182s/iter; left time: 321.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0524401 Vali Loss: 0.0595239 Test Loss: 0.0619001\n",
      "Validation loss decreased (0.059645 --> 0.059524).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0528261\n",
      "\tspeed: 0.0317s/iter; left time: 555.8472s\n",
      "\titers: 200, epoch: 23 | loss: 0.0492108\n",
      "\tspeed: 0.0165s/iter; left time: 288.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0522637 Vali Loss: 0.0590840 Test Loss: 0.0614077\n",
      "Validation loss decreased (0.059524 --> 0.059084).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0518252\n",
      "\tspeed: 0.0338s/iter; left time: 585.2626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523993\n",
      "\tspeed: 0.0167s/iter; left time: 286.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0520737 Vali Loss: 0.0589433 Test Loss: 0.0612480\n",
      "Validation loss decreased (0.059084 --> 0.058943).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0526683\n",
      "\tspeed: 0.0354s/iter; left time: 605.1103s\n",
      "\titers: 200, epoch: 25 | loss: 0.0541010\n",
      "\tspeed: 0.0204s/iter; left time: 347.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 226 | Train Loss: 0.0521598 Vali Loss: 0.0588813 Test Loss: 0.0613570\n",
      "Validation loss decreased (0.058943 --> 0.058881).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0520070\n",
      "\tspeed: 0.0275s/iter; left time: 463.4306s\n",
      "\titers: 200, epoch: 26 | loss: 0.0532121\n",
      "\tspeed: 0.0095s/iter; left time: 159.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.47s\n",
      "Steps: 226 | Train Loss: 0.0518301 Vali Loss: 0.0587287 Test Loss: 0.0611357\n",
      "Validation loss decreased (0.058881 --> 0.058729).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0526764\n",
      "\tspeed: 0.0315s/iter; left time: 523.8758s\n",
      "\titers: 200, epoch: 27 | loss: 0.0514687\n",
      "\tspeed: 0.0152s/iter; left time: 250.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0517552 Vali Loss: 0.0590239 Test Loss: 0.0614569\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513778\n",
      "\tspeed: 0.0345s/iter; left time: 566.2563s\n",
      "\titers: 200, epoch: 28 | loss: 0.0509993\n",
      "\tspeed: 0.0164s/iter; left time: 267.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0516570 Vali Loss: 0.0591060 Test Loss: 0.0615547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525079\n",
      "\tspeed: 0.0268s/iter; left time: 433.5700s\n",
      "\titers: 200, epoch: 29 | loss: 0.0533223\n",
      "\tspeed: 0.0183s/iter; left time: 294.8776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0516441 Vali Loss: 0.0588266 Test Loss: 0.0614746\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0481990\n",
      "\tspeed: 0.0345s/iter; left time: 549.9548s\n",
      "\titers: 200, epoch: 30 | loss: 0.0526182\n",
      "\tspeed: 0.0192s/iter; left time: 304.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0515156 Vali Loss: 0.0585467 Test Loss: 0.0610625\n",
      "Validation loss decreased (0.058729 --> 0.058547).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509937\n",
      "\tspeed: 0.0321s/iter; left time: 504.5547s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554018\n",
      "\tspeed: 0.0141s/iter; left time: 220.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0514165 Vali Loss: 0.0584982 Test Loss: 0.0609978\n",
      "Validation loss decreased (0.058547 --> 0.058498).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0521961\n",
      "\tspeed: 0.0336s/iter; left time: 520.0480s\n",
      "\titers: 200, epoch: 32 | loss: 0.0502925\n",
      "\tspeed: 0.0181s/iter; left time: 279.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0514829 Vali Loss: 0.0585121 Test Loss: 0.0609906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0542395\n",
      "\tspeed: 0.0322s/iter; left time: 491.2185s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552315\n",
      "\tspeed: 0.0162s/iter; left time: 246.0203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0513255 Vali Loss: 0.0585441 Test Loss: 0.0610287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0502087\n",
      "\tspeed: 0.0259s/iter; left time: 389.3056s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526543\n",
      "\tspeed: 0.0109s/iter; left time: 163.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.65s\n",
      "Steps: 226 | Train Loss: 0.0512074 Vali Loss: 0.0585198 Test Loss: 0.0610669\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515986\n",
      "\tspeed: 0.0253s/iter; left time: 374.6177s\n",
      "\titers: 200, epoch: 35 | loss: 0.0516961\n",
      "\tspeed: 0.0111s/iter; left time: 163.1161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 226 | Train Loss: 0.0512349 Vali Loss: 0.0588582 Test Loss: 0.0614055\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545352\n",
      "\tspeed: 0.0325s/iter; left time: 474.5437s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521886\n",
      "\tspeed: 0.0149s/iter; left time: 215.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0511284 Vali Loss: 0.0586213 Test Loss: 0.0610915\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0492245\n",
      "\tspeed: 0.0320s/iter; left time: 460.3118s\n",
      "\titers: 200, epoch: 37 | loss: 0.0546065\n",
      "\tspeed: 0.0187s/iter; left time: 266.2676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0512189 Vali Loss: 0.0586420 Test Loss: 0.0611143\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0489465\n",
      "\tspeed: 0.0339s/iter; left time: 479.8878s\n",
      "\titers: 200, epoch: 38 | loss: 0.0510282\n",
      "\tspeed: 0.0204s/iter; left time: 286.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0512186 Vali Loss: 0.0585996 Test Loss: 0.0611576\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0521461\n",
      "\tspeed: 0.0336s/iter; left time: 467.2052s\n",
      "\titers: 200, epoch: 39 | loss: 0.0486002\n",
      "\tspeed: 0.0170s/iter; left time: 234.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0512181 Vali Loss: 0.0583023 Test Loss: 0.0607115\n",
      "Validation loss decreased (0.058498 --> 0.058302).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0483637\n",
      "\tspeed: 0.0304s/iter; left time: 415.9153s\n",
      "\titers: 200, epoch: 40 | loss: 0.0534848\n",
      "\tspeed: 0.0139s/iter; left time: 189.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0511078 Vali Loss: 0.0584909 Test Loss: 0.0609967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0510957\n",
      "\tspeed: 0.0267s/iter; left time: 359.9818s\n",
      "\titers: 200, epoch: 41 | loss: 0.0504879\n",
      "\tspeed: 0.0123s/iter; left time: 164.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0512328 Vali Loss: 0.0588054 Test Loss: 0.0613718\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0496044\n",
      "\tspeed: 0.0273s/iter; left time: 360.8408s\n",
      "\titers: 200, epoch: 42 | loss: 0.0513230\n",
      "\tspeed: 0.0137s/iter; left time: 180.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0509708 Vali Loss: 0.0584022 Test Loss: 0.0609477\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0525000\n",
      "\tspeed: 0.0279s/iter; left time: 362.9609s\n",
      "\titers: 200, epoch: 43 | loss: 0.0508434\n",
      "\tspeed: 0.0125s/iter; left time: 161.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0512291 Vali Loss: 0.0583417 Test Loss: 0.0607665\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0548755\n",
      "\tspeed: 0.0337s/iter; left time: 430.8043s\n",
      "\titers: 200, epoch: 44 | loss: 0.0522109\n",
      "\tspeed: 0.0174s/iter; left time: 221.2122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0510478 Vali Loss: 0.0582927 Test Loss: 0.0607605\n",
      "Validation loss decreased (0.058302 --> 0.058293).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0506126\n",
      "\tspeed: 0.0325s/iter; left time: 407.9411s\n",
      "\titers: 200, epoch: 45 | loss: 0.0528465\n",
      "\tspeed: 0.0181s/iter; left time: 226.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 226 | Train Loss: 0.0512065 Vali Loss: 0.0584716 Test Loss: 0.0607955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0543340\n",
      "\tspeed: 0.0289s/iter; left time: 356.3160s\n",
      "\titers: 200, epoch: 46 | loss: 0.0472873\n",
      "\tspeed: 0.0111s/iter; left time: 135.3325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0511917 Vali Loss: 0.0584659 Test Loss: 0.0609901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0537727\n",
      "\tspeed: 0.0357s/iter; left time: 432.1095s\n",
      "\titers: 200, epoch: 47 | loss: 0.0553661\n",
      "\tspeed: 0.0211s/iter; left time: 252.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0511310 Vali Loss: 0.0588045 Test Loss: 0.0614261\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0514362\n",
      "\tspeed: 0.0390s/iter; left time: 463.5479s\n",
      "\titers: 200, epoch: 48 | loss: 0.0472045\n",
      "\tspeed: 0.0208s/iter; left time: 244.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 226 | Train Loss: 0.0510057 Vali Loss: 0.0584156 Test Loss: 0.0608528\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0496042\n",
      "\tspeed: 0.0378s/iter; left time: 440.3898s\n",
      "\titers: 200, epoch: 49 | loss: 0.0499088\n",
      "\tspeed: 0.0191s/iter; left time: 220.2751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 226 | Train Loss: 0.0511481 Vali Loss: 0.0587064 Test Loss: 0.0612833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0537619\n",
      "\tspeed: 0.0347s/iter; left time: 396.2178s\n",
      "\titers: 200, epoch: 50 | loss: 0.0525173\n",
      "\tspeed: 0.0178s/iter; left time: 202.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0510573 Vali Loss: 0.0584213 Test Loss: 0.0609016\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0498492\n",
      "\tspeed: 0.0336s/iter; left time: 375.9466s\n",
      "\titers: 200, epoch: 51 | loss: 0.0518584\n",
      "\tspeed: 0.0176s/iter; left time: 195.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0510924 Vali Loss: 0.0582117 Test Loss: 0.0606907\n",
      "Validation loss decreased (0.058293 --> 0.058212).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0508633\n",
      "\tspeed: 0.0335s/iter; left time: 367.6509s\n",
      "\titers: 200, epoch: 52 | loss: 0.0550103\n",
      "\tspeed: 0.0153s/iter; left time: 166.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0509129 Vali Loss: 0.0581993 Test Loss: 0.0607614\n",
      "Validation loss decreased (0.058212 --> 0.058199).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0480261\n",
      "\tspeed: 0.0354s/iter; left time: 380.1742s\n",
      "\titers: 200, epoch: 53 | loss: 0.0512180\n",
      "\tspeed: 0.0135s/iter; left time: 143.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0509997 Vali Loss: 0.0583812 Test Loss: 0.0609259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0531948\n",
      "\tspeed: 0.0275s/iter; left time: 289.6032s\n",
      "\titers: 200, epoch: 54 | loss: 0.0474615\n",
      "\tspeed: 0.0152s/iter; left time: 158.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0509769 Vali Loss: 0.0583499 Test Loss: 0.0608505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0507050\n",
      "\tspeed: 0.0330s/iter; left time: 339.8780s\n",
      "\titers: 200, epoch: 55 | loss: 0.0514766\n",
      "\tspeed: 0.0191s/iter; left time: 194.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0510671 Vali Loss: 0.0582356 Test Loss: 0.0607276\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0516714\n",
      "\tspeed: 0.0325s/iter; left time: 327.3084s\n",
      "\titers: 200, epoch: 56 | loss: 0.0518651\n",
      "\tspeed: 0.0148s/iter; left time: 147.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0510166 Vali Loss: 0.0582356 Test Loss: 0.0607591\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0489705\n",
      "\tspeed: 0.0337s/iter; left time: 331.6164s\n",
      "\titers: 200, epoch: 57 | loss: 0.0528853\n",
      "\tspeed: 0.0169s/iter; left time: 164.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0509707 Vali Loss: 0.0582195 Test Loss: 0.0607423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0502746\n",
      "\tspeed: 0.0344s/iter; left time: 330.6800s\n",
      "\titers: 200, epoch: 58 | loss: 0.0522595\n",
      "\tspeed: 0.0161s/iter; left time: 152.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0511142 Vali Loss: 0.0584232 Test Loss: 0.0608961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0509823\n",
      "\tspeed: 0.0321s/iter; left time: 301.4973s\n",
      "\titers: 200, epoch: 59 | loss: 0.0486975\n",
      "\tspeed: 0.0173s/iter; left time: 160.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0508444 Vali Loss: 0.0588405 Test Loss: 0.0614654\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0516023\n",
      "\tspeed: 0.0349s/iter; left time: 319.4895s\n",
      "\titers: 200, epoch: 60 | loss: 0.0504437\n",
      "\tspeed: 0.0185s/iter; left time: 167.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 226 | Train Loss: 0.0511295 Vali Loss: 0.0581398 Test Loss: 0.0605930\n",
      "Validation loss decreased (0.058199 --> 0.058140).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0520362\n",
      "\tspeed: 0.0321s/iter; left time: 287.2443s\n",
      "\titers: 200, epoch: 61 | loss: 0.0556048\n",
      "\tspeed: 0.0149s/iter; left time: 132.1537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0510963 Vali Loss: 0.0583216 Test Loss: 0.0608756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0489466\n",
      "\tspeed: 0.0308s/iter; left time: 268.6907s\n",
      "\titers: 200, epoch: 62 | loss: 0.0509101\n",
      "\tspeed: 0.0167s/iter; left time: 143.5892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0509727 Vali Loss: 0.0582650 Test Loss: 0.0607129\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0520241\n",
      "\tspeed: 0.0300s/iter; left time: 254.4145s\n",
      "\titers: 200, epoch: 63 | loss: 0.0503084\n",
      "\tspeed: 0.0165s/iter; left time: 138.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0510012 Vali Loss: 0.0585479 Test Loss: 0.0611012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0499376\n",
      "\tspeed: 0.0364s/iter; left time: 301.1208s\n",
      "\titers: 200, epoch: 64 | loss: 0.0512204\n",
      "\tspeed: 0.0198s/iter; left time: 161.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 226 | Train Loss: 0.0509128 Vali Loss: 0.0585969 Test Loss: 0.0610523\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0492525\n",
      "\tspeed: 0.0351s/iter; left time: 281.9243s\n",
      "\titers: 200, epoch: 65 | loss: 0.0499918\n",
      "\tspeed: 0.0154s/iter; left time: 122.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0509866 Vali Loss: 0.0582172 Test Loss: 0.0607015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0500380\n",
      "\tspeed: 0.0343s/iter; left time: 267.8132s\n",
      "\titers: 200, epoch: 66 | loss: 0.0492308\n",
      "\tspeed: 0.0129s/iter; left time: 99.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0509230 Vali Loss: 0.0582179 Test Loss: 0.0606962\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0567633\n",
      "\tspeed: 0.0309s/iter; left time: 234.0709s\n",
      "\titers: 200, epoch: 67 | loss: 0.0497529\n",
      "\tspeed: 0.0165s/iter; left time: 123.5086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0509263 Vali Loss: 0.0583092 Test Loss: 0.0607846\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0494144\n",
      "\tspeed: 0.0312s/iter; left time: 229.9635s\n",
      "\titers: 200, epoch: 68 | loss: 0.0522436\n",
      "\tspeed: 0.0165s/iter; left time: 119.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0509374 Vali Loss: 0.0584095 Test Loss: 0.0608217\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0530711\n",
      "\tspeed: 0.0322s/iter; left time: 229.7920s\n",
      "\titers: 200, epoch: 69 | loss: 0.0486707\n",
      "\tspeed: 0.0140s/iter; left time: 98.2286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0508935 Vali Loss: 0.0582418 Test Loss: 0.0607684\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0478494\n",
      "\tspeed: 0.0312s/iter; left time: 215.1662s\n",
      "\titers: 200, epoch: 70 | loss: 0.0519286\n",
      "\tspeed: 0.0173s/iter; left time: 117.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0509530 Vali Loss: 0.0583988 Test Loss: 0.0609481\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011059106327593327, rmse:0.10516228526830673, mae:0.06059299036860466, rse:0.40571320056915283\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2416628\n",
      "\tspeed: 0.0195s/iter; left time: 439.8132s\n",
      "\titers: 200, epoch: 1 | loss: 0.2118645\n",
      "\tspeed: 0.0191s/iter; left time: 426.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.2365767 Vali Loss: 0.1752155 Test Loss: 0.1818404\n",
      "Validation loss decreased (inf --> 0.175215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1395827\n",
      "\tspeed: 0.0319s/iter; left time: 710.5907s\n",
      "\titers: 200, epoch: 2 | loss: 0.1041168\n",
      "\tspeed: 0.0176s/iter; left time: 389.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.1377829 Vali Loss: 0.0912523 Test Loss: 0.0981285\n",
      "Validation loss decreased (0.175215 --> 0.091252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0868506\n",
      "\tspeed: 0.0353s/iter; left time: 777.5708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0817878\n",
      "\tspeed: 0.0188s/iter; left time: 411.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0857371 Vali Loss: 0.0796753 Test Loss: 0.0823581\n",
      "Validation loss decreased (0.091252 --> 0.079675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0767839\n",
      "\tspeed: 0.0342s/iter; left time: 747.3954s\n",
      "\titers: 200, epoch: 4 | loss: 0.0726637\n",
      "\tspeed: 0.0171s/iter; left time: 371.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0733852 Vali Loss: 0.0716293 Test Loss: 0.0714761\n",
      "Validation loss decreased (0.079675 --> 0.071629).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0654529\n",
      "\tspeed: 0.0325s/iter; left time: 701.3059s\n",
      "\titers: 200, epoch: 5 | loss: 0.0700655\n",
      "\tspeed: 0.0152s/iter; left time: 325.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0672182 Vali Loss: 0.0680346 Test Loss: 0.0680098\n",
      "Validation loss decreased (0.071629 --> 0.068035).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0712112\n",
      "\tspeed: 0.0335s/iter; left time: 716.6855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635504\n",
      "\tspeed: 0.0185s/iter; left time: 394.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0631633 Vali Loss: 0.0652654 Test Loss: 0.0669694\n",
      "Validation loss decreased (0.068035 --> 0.065265).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0623794\n",
      "\tspeed: 0.0332s/iter; left time: 702.2844s\n",
      "\titers: 200, epoch: 7 | loss: 0.0575420\n",
      "\tspeed: 0.0150s/iter; left time: 315.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0606888 Vali Loss: 0.0636692 Test Loss: 0.0657486\n",
      "Validation loss decreased (0.065265 --> 0.063669).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0561675\n",
      "\tspeed: 0.0312s/iter; left time: 652.1613s\n",
      "\titers: 200, epoch: 8 | loss: 0.0559797\n",
      "\tspeed: 0.0140s/iter; left time: 292.2053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0587371 Vali Loss: 0.0633773 Test Loss: 0.0654466\n",
      "Validation loss decreased (0.063669 --> 0.063377).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0564218\n",
      "\tspeed: 0.0360s/iter; left time: 745.4763s\n",
      "\titers: 200, epoch: 9 | loss: 0.0600520\n",
      "\tspeed: 0.0162s/iter; left time: 332.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0578731 Vali Loss: 0.0627705 Test Loss: 0.0648424\n",
      "Validation loss decreased (0.063377 --> 0.062771).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573411\n",
      "\tspeed: 0.0265s/iter; left time: 541.8748s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585905\n",
      "\tspeed: 0.0125s/iter; left time: 255.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0567742 Vali Loss: 0.0621514 Test Loss: 0.0644379\n",
      "Validation loss decreased (0.062771 --> 0.062151).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559383\n",
      "\tspeed: 0.0366s/iter; left time: 741.4936s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565468\n",
      "\tspeed: 0.0157s/iter; left time: 316.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0557982 Vali Loss: 0.0619139 Test Loss: 0.0639982\n",
      "Validation loss decreased (0.062151 --> 0.061914).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0525815\n",
      "\tspeed: 0.0317s/iter; left time: 635.3405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535919\n",
      "\tspeed: 0.0132s/iter; left time: 263.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0552507 Vali Loss: 0.0611877 Test Loss: 0.0635318\n",
      "Validation loss decreased (0.061914 --> 0.061188).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0581328\n",
      "\tspeed: 0.0310s/iter; left time: 613.7022s\n",
      "\titers: 200, epoch: 13 | loss: 0.0549002\n",
      "\tspeed: 0.0152s/iter; left time: 299.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0547234 Vali Loss: 0.0615271 Test Loss: 0.0636993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0568595\n",
      "\tspeed: 0.0320s/iter; left time: 625.4121s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548544\n",
      "\tspeed: 0.0149s/iter; left time: 289.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0543082 Vali Loss: 0.0612200 Test Loss: 0.0635789\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0548684\n",
      "\tspeed: 0.0330s/iter; left time: 637.8120s\n",
      "\titers: 200, epoch: 15 | loss: 0.0530043\n",
      "\tspeed: 0.0170s/iter; left time: 326.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0537783 Vali Loss: 0.0612516 Test Loss: 0.0636767\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0521529\n",
      "\tspeed: 0.0320s/iter; left time: 611.2286s\n",
      "\titers: 200, epoch: 16 | loss: 0.0506460\n",
      "\tspeed: 0.0168s/iter; left time: 320.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0537510 Vali Loss: 0.0605211 Test Loss: 0.0629692\n",
      "Validation loss decreased (0.061188 --> 0.060521).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0543273\n",
      "\tspeed: 0.0339s/iter; left time: 640.3099s\n",
      "\titers: 200, epoch: 17 | loss: 0.0502027\n",
      "\tspeed: 0.0179s/iter; left time: 335.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0531656 Vali Loss: 0.0603622 Test Loss: 0.0628506\n",
      "Validation loss decreased (0.060521 --> 0.060362).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0546218\n",
      "\tspeed: 0.0347s/iter; left time: 647.7130s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563045\n",
      "\tspeed: 0.0210s/iter; left time: 389.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 226 | Train Loss: 0.0531353 Vali Loss: 0.0597555 Test Loss: 0.0621679\n",
      "Validation loss decreased (0.060362 --> 0.059756).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578719\n",
      "\tspeed: 0.0311s/iter; left time: 573.5929s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559273\n",
      "\tspeed: 0.0153s/iter; left time: 279.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0529508 Vali Loss: 0.0597700 Test Loss: 0.0623024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0500620\n",
      "\tspeed: 0.0334s/iter; left time: 607.8282s\n",
      "\titers: 200, epoch: 20 | loss: 0.0510834\n",
      "\tspeed: 0.0164s/iter; left time: 297.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0527228 Vali Loss: 0.0598549 Test Loss: 0.0622901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0518224\n",
      "\tspeed: 0.0326s/iter; left time: 585.3250s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519954\n",
      "\tspeed: 0.0174s/iter; left time: 310.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0524627 Vali Loss: 0.0598198 Test Loss: 0.0622270\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0520502\n",
      "\tspeed: 0.0311s/iter; left time: 552.6466s\n",
      "\titers: 200, epoch: 22 | loss: 0.0541251\n",
      "\tspeed: 0.0203s/iter; left time: 357.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0524199 Vali Loss: 0.0601374 Test Loss: 0.0625613\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513092\n",
      "\tspeed: 0.0337s/iter; left time: 589.8545s\n",
      "\titers: 200, epoch: 23 | loss: 0.0516593\n",
      "\tspeed: 0.0156s/iter; left time: 271.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0523227 Vali Loss: 0.0598450 Test Loss: 0.0623014\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0510257\n",
      "\tspeed: 0.0322s/iter; left time: 557.2097s\n",
      "\titers: 200, epoch: 24 | loss: 0.0487331\n",
      "\tspeed: 0.0170s/iter; left time: 291.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0521394 Vali Loss: 0.0594246 Test Loss: 0.0619224\n",
      "Validation loss decreased (0.059756 --> 0.059425).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0467195\n",
      "\tspeed: 0.0362s/iter; left time: 617.9581s\n",
      "\titers: 200, epoch: 25 | loss: 0.0519570\n",
      "\tspeed: 0.0179s/iter; left time: 304.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0519435 Vali Loss: 0.0593750 Test Loss: 0.0619810\n",
      "Validation loss decreased (0.059425 --> 0.059375).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0524631\n",
      "\tspeed: 0.0318s/iter; left time: 535.6440s\n",
      "\titers: 200, epoch: 26 | loss: 0.0534046\n",
      "\tspeed: 0.0149s/iter; left time: 249.9460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0518191 Vali Loss: 0.0591756 Test Loss: 0.0617106\n",
      "Validation loss decreased (0.059375 --> 0.059176).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0542041\n",
      "\tspeed: 0.0343s/iter; left time: 569.7595s\n",
      "\titers: 200, epoch: 27 | loss: 0.0519935\n",
      "\tspeed: 0.0195s/iter; left time: 321.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0519694 Vali Loss: 0.0597937 Test Loss: 0.0622555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0515420\n",
      "\tspeed: 0.0366s/iter; left time: 600.8277s\n",
      "\titers: 200, epoch: 28 | loss: 0.0502045\n",
      "\tspeed: 0.0205s/iter; left time: 334.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0521151 Vali Loss: 0.0595430 Test Loss: 0.0620863\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0641427\n",
      "\tspeed: 0.0351s/iter; left time: 568.1361s\n",
      "\titers: 200, epoch: 29 | loss: 0.0514867\n",
      "\tspeed: 0.0184s/iter; left time: 296.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0518454 Vali Loss: 0.0592493 Test Loss: 0.0618645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0513309\n",
      "\tspeed: 0.0326s/iter; left time: 520.3928s\n",
      "\titers: 200, epoch: 30 | loss: 0.0528735\n",
      "\tspeed: 0.0147s/iter; left time: 232.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0516423 Vali Loss: 0.0591638 Test Loss: 0.0616811\n",
      "Validation loss decreased (0.059176 --> 0.059164).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0508543\n",
      "\tspeed: 0.0327s/iter; left time: 513.8776s\n",
      "\titers: 200, epoch: 31 | loss: 0.0532794\n",
      "\tspeed: 0.0143s/iter; left time: 224.1262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0515427 Vali Loss: 0.0593265 Test Loss: 0.0617769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0535211\n",
      "\tspeed: 0.0310s/iter; left time: 480.6860s\n",
      "\titers: 200, epoch: 32 | loss: 0.0515713\n",
      "\tspeed: 0.0134s/iter; left time: 206.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0515884 Vali Loss: 0.0592297 Test Loss: 0.0616450\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0506216\n",
      "\tspeed: 0.0376s/iter; left time: 574.4233s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552973\n",
      "\tspeed: 0.0179s/iter; left time: 270.9593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 226 | Train Loss: 0.0514787 Vali Loss: 0.0593651 Test Loss: 0.0618762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0500266\n",
      "\tspeed: 0.0367s/iter; left time: 551.4485s\n",
      "\titers: 200, epoch: 34 | loss: 0.0525294\n",
      "\tspeed: 0.0170s/iter; left time: 254.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0515054 Vali Loss: 0.0591138 Test Loss: 0.0617489\n",
      "Validation loss decreased (0.059164 --> 0.059114).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515080\n",
      "\tspeed: 0.0322s/iter; left time: 477.3783s\n",
      "\titers: 200, epoch: 35 | loss: 0.0520318\n",
      "\tspeed: 0.0152s/iter; left time: 223.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0514527 Vali Loss: 0.0590694 Test Loss: 0.0616565\n",
      "Validation loss decreased (0.059114 --> 0.059069).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0530447\n",
      "\tspeed: 0.0350s/iter; left time: 511.2124s\n",
      "\titers: 200, epoch: 36 | loss: 0.0504718\n",
      "\tspeed: 0.0111s/iter; left time: 161.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0514593 Vali Loss: 0.0591461 Test Loss: 0.0618174\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0502356\n",
      "\tspeed: 0.0359s/iter; left time: 516.0171s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500012\n",
      "\tspeed: 0.0125s/iter; left time: 177.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0514596 Vali Loss: 0.0598087 Test Loss: 0.0623762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0530377\n",
      "\tspeed: 0.0318s/iter; left time: 449.4951s\n",
      "\titers: 200, epoch: 38 | loss: 0.0490269\n",
      "\tspeed: 0.0173s/iter; left time: 242.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0513402 Vali Loss: 0.0593734 Test Loss: 0.0619947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0510635\n",
      "\tspeed: 0.0339s/iter; left time: 471.4628s\n",
      "\titers: 200, epoch: 39 | loss: 0.0519244\n",
      "\tspeed: 0.0181s/iter; left time: 249.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0514132 Vali Loss: 0.0592859 Test Loss: 0.0618880\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0479976\n",
      "\tspeed: 0.0329s/iter; left time: 449.6407s\n",
      "\titers: 200, epoch: 40 | loss: 0.0587389\n",
      "\tspeed: 0.0200s/iter; left time: 272.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0512591 Vali Loss: 0.0589257 Test Loss: 0.0614904\n",
      "Validation loss decreased (0.059069 --> 0.058926).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0499182\n",
      "\tspeed: 0.0371s/iter; left time: 499.5009s\n",
      "\titers: 200, epoch: 41 | loss: 0.0517714\n",
      "\tspeed: 0.0175s/iter; left time: 233.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0513970 Vali Loss: 0.0589165 Test Loss: 0.0615032\n",
      "Validation loss decreased (0.058926 --> 0.058916).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0555581\n",
      "\tspeed: 0.0379s/iter; left time: 501.0847s\n",
      "\titers: 200, epoch: 42 | loss: 0.0493980\n",
      "\tspeed: 0.0197s/iter; left time: 259.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0512042 Vali Loss: 0.0592286 Test Loss: 0.0617734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0499269\n",
      "\tspeed: 0.0348s/iter; left time: 453.0064s\n",
      "\titers: 200, epoch: 43 | loss: 0.0529789\n",
      "\tspeed: 0.0143s/iter; left time: 184.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0513263 Vali Loss: 0.0591241 Test Loss: 0.0616876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0506182\n",
      "\tspeed: 0.0327s/iter; left time: 417.5317s\n",
      "\titers: 200, epoch: 44 | loss: 0.0491669\n",
      "\tspeed: 0.0166s/iter; left time: 210.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0512939 Vali Loss: 0.0588932 Test Loss: 0.0614789\n",
      "Validation loss decreased (0.058916 --> 0.058893).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504569\n",
      "\tspeed: 0.0394s/iter; left time: 494.2587s\n",
      "\titers: 200, epoch: 45 | loss: 0.0495079\n",
      "\tspeed: 0.0163s/iter; left time: 202.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0511449 Vali Loss: 0.0590043 Test Loss: 0.0615300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0504148\n",
      "\tspeed: 0.0348s/iter; left time: 428.8185s\n",
      "\titers: 200, epoch: 46 | loss: 0.0546191\n",
      "\tspeed: 0.0190s/iter; left time: 232.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0512323 Vali Loss: 0.0593695 Test Loss: 0.0620349\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528963\n",
      "\tspeed: 0.0329s/iter; left time: 397.7923s\n",
      "\titers: 200, epoch: 47 | loss: 0.0509227\n",
      "\tspeed: 0.0156s/iter; left time: 186.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0512757 Vali Loss: 0.0589895 Test Loss: 0.0616225\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522054\n",
      "\tspeed: 0.0310s/iter; left time: 368.2862s\n",
      "\titers: 200, epoch: 48 | loss: 0.0484653\n",
      "\tspeed: 0.0159s/iter; left time: 187.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0512539 Vali Loss: 0.0591156 Test Loss: 0.0617639\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0526090\n",
      "\tspeed: 0.0317s/iter; left time: 369.9610s\n",
      "\titers: 200, epoch: 49 | loss: 0.0553374\n",
      "\tspeed: 0.0110s/iter; left time: 126.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0513467 Vali Loss: 0.0589459 Test Loss: 0.0614353\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0502638\n",
      "\tspeed: 0.0254s/iter; left time: 290.2524s\n",
      "\titers: 200, epoch: 50 | loss: 0.0521959\n",
      "\tspeed: 0.0111s/iter; left time: 125.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0512335 Vali Loss: 0.0592556 Test Loss: 0.0619066\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0534625\n",
      "\tspeed: 0.0319s/iter; left time: 356.9499s\n",
      "\titers: 200, epoch: 51 | loss: 0.0522593\n",
      "\tspeed: 0.0171s/iter; left time: 189.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0512247 Vali Loss: 0.0590859 Test Loss: 0.0617177\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0478016\n",
      "\tspeed: 0.0334s/iter; left time: 366.3536s\n",
      "\titers: 200, epoch: 52 | loss: 0.0518351\n",
      "\tspeed: 0.0172s/iter; left time: 186.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0513318 Vali Loss: 0.0587435 Test Loss: 0.0613683\n",
      "Validation loss decreased (0.058893 --> 0.058744).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0524634\n",
      "\tspeed: 0.0329s/iter; left time: 353.8793s\n",
      "\titers: 200, epoch: 53 | loss: 0.0528184\n",
      "\tspeed: 0.0142s/iter; left time: 151.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0511697 Vali Loss: 0.0595583 Test Loss: 0.0622298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0493532\n",
      "\tspeed: 0.0340s/iter; left time: 358.2648s\n",
      "\titers: 200, epoch: 54 | loss: 0.0491158\n",
      "\tspeed: 0.0198s/iter; left time: 206.5691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0512054 Vali Loss: 0.0594513 Test Loss: 0.0620704\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534966\n",
      "\tspeed: 0.0317s/iter; left time: 326.8456s\n",
      "\titers: 200, epoch: 55 | loss: 0.0487425\n",
      "\tspeed: 0.0178s/iter; left time: 181.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0513194 Vali Loss: 0.0591265 Test Loss: 0.0616807\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0520311\n",
      "\tspeed: 0.0340s/iter; left time: 342.6129s\n",
      "\titers: 200, epoch: 56 | loss: 0.0511009\n",
      "\tspeed: 0.0151s/iter; left time: 150.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0512252 Vali Loss: 0.0588257 Test Loss: 0.0613912\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0501452\n",
      "\tspeed: 0.0321s/iter; left time: 316.0024s\n",
      "\titers: 200, epoch: 57 | loss: 0.0561148\n",
      "\tspeed: 0.0171s/iter; left time: 166.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0511195 Vali Loss: 0.0592716 Test Loss: 0.0618494\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0495522\n",
      "\tspeed: 0.0329s/iter; left time: 316.4605s\n",
      "\titers: 200, epoch: 58 | loss: 0.0490600\n",
      "\tspeed: 0.0147s/iter; left time: 139.5894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0510768 Vali Loss: 0.0589688 Test Loss: 0.0614992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0488771\n",
      "\tspeed: 0.0363s/iter; left time: 341.0892s\n",
      "\titers: 200, epoch: 59 | loss: 0.0531398\n",
      "\tspeed: 0.0169s/iter; left time: 157.4804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0511723 Vali Loss: 0.0590542 Test Loss: 0.0616732\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0536283\n",
      "\tspeed: 0.0322s/iter; left time: 295.1166s\n",
      "\titers: 200, epoch: 60 | loss: 0.0513347\n",
      "\tspeed: 0.0142s/iter; left time: 128.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0510745 Vali Loss: 0.0591924 Test Loss: 0.0618312\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0511971\n",
      "\tspeed: 0.0244s/iter; left time: 218.4595s\n",
      "\titers: 200, epoch: 61 | loss: 0.0507888\n",
      "\tspeed: 0.0096s/iter; left time: 85.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:02.45s\n",
      "Steps: 226 | Train Loss: 0.0512314 Vali Loss: 0.0591397 Test Loss: 0.0617536\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0488633\n",
      "\tspeed: 0.0312s/iter; left time: 272.1085s\n",
      "\titers: 200, epoch: 62 | loss: 0.0498987\n",
      "\tspeed: 0.0168s/iter; left time: 144.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0511543 Vali Loss: 0.0593258 Test Loss: 0.0620149\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01122244168072939, rmse:0.10593602806329727, mae:0.061368297785520554, rse:0.40869826078414917\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:00.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2399536\n",
      "\tspeed: 0.0363s/iter; left time: 812.0937s\n",
      "\titers: 200, epoch: 1 | loss: 0.2218693\n",
      "\tspeed: 0.0145s/iter; left time: 323.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.2435918 Vali Loss: 0.1775215 Test Loss: 0.1869208\n",
      "Validation loss decreased (inf --> 0.177521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348915\n",
      "\tspeed: 0.0315s/iter; left time: 699.4382s\n",
      "\titers: 200, epoch: 2 | loss: 0.0999899\n",
      "\tspeed: 0.0145s/iter; left time: 320.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.1339489 Vali Loss: 0.0989685 Test Loss: 0.1108424\n",
      "Validation loss decreased (0.177521 --> 0.098968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0897997\n",
      "\tspeed: 0.0331s/iter; left time: 726.4421s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906458\n",
      "\tspeed: 0.0156s/iter; left time: 341.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0907362 Vali Loss: 0.0915546 Test Loss: 0.0976730\n",
      "Validation loss decreased (0.098968 --> 0.091555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0803316\n",
      "\tspeed: 0.0305s/iter; left time: 663.1096s\n",
      "\titers: 200, epoch: 4 | loss: 0.0824087\n",
      "\tspeed: 0.0145s/iter; left time: 313.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0827918 Vali Loss: 0.0843838 Test Loss: 0.0914720\n",
      "Validation loss decreased (0.091555 --> 0.084384).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784377\n",
      "\tspeed: 0.0277s/iter; left time: 596.2867s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759989\n",
      "\tspeed: 0.0113s/iter; left time: 242.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 225 | Train Loss: 0.0780586 Vali Loss: 0.0813468 Test Loss: 0.0897788\n",
      "Validation loss decreased (0.084384 --> 0.081347).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0739028\n",
      "\tspeed: 0.0331s/iter; left time: 703.1759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0733849\n",
      "\tspeed: 0.0156s/iter; left time: 330.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0752780 Vali Loss: 0.0799889 Test Loss: 0.0886891\n",
      "Validation loss decreased (0.081347 --> 0.079989).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700873\n",
      "\tspeed: 0.0344s/iter; left time: 723.1578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0707081\n",
      "\tspeed: 0.0152s/iter; left time: 319.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0736288 Vali Loss: 0.0790577 Test Loss: 0.0879290\n",
      "Validation loss decreased (0.079989 --> 0.079058).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0762281\n",
      "\tspeed: 0.0336s/iter; left time: 700.4877s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738689\n",
      "\tspeed: 0.0157s/iter; left time: 324.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0722952 Vali Loss: 0.0787441 Test Loss: 0.0879052\n",
      "Validation loss decreased (0.079058 --> 0.078744).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0683771\n",
      "\tspeed: 0.0326s/iter; left time: 671.2067s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747857\n",
      "\tspeed: 0.0157s/iter; left time: 322.4174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0715896 Vali Loss: 0.0774867 Test Loss: 0.0866617\n",
      "Validation loss decreased (0.078744 --> 0.077487).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698917\n",
      "\tspeed: 0.0368s/iter; left time: 750.1355s\n",
      "\titers: 200, epoch: 10 | loss: 0.0716846\n",
      "\tspeed: 0.0151s/iter; left time: 306.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0704057 Vali Loss: 0.0769684 Test Loss: 0.0858415\n",
      "Validation loss decreased (0.077487 --> 0.076968).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0699004\n",
      "\tspeed: 0.0326s/iter; left time: 655.9198s\n",
      "\titers: 200, epoch: 11 | loss: 0.0707201\n",
      "\tspeed: 0.0156s/iter; left time: 313.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0697867 Vali Loss: 0.0764495 Test Loss: 0.0853819\n",
      "Validation loss decreased (0.076968 --> 0.076450).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698846\n",
      "\tspeed: 0.0332s/iter; left time: 661.8796s\n",
      "\titers: 200, epoch: 12 | loss: 0.0716245\n",
      "\tspeed: 0.0157s/iter; left time: 311.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0691675 Vali Loss: 0.0769113 Test Loss: 0.0856977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0649242\n",
      "\tspeed: 0.0312s/iter; left time: 614.6777s\n",
      "\titers: 200, epoch: 13 | loss: 0.0703803\n",
      "\tspeed: 0.0150s/iter; left time: 293.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0685956 Vali Loss: 0.0758379 Test Loss: 0.0847957\n",
      "Validation loss decreased (0.076450 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0711271\n",
      "\tspeed: 0.0341s/iter; left time: 664.7411s\n",
      "\titers: 200, epoch: 14 | loss: 0.0694447\n",
      "\tspeed: 0.0170s/iter; left time: 330.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0680487 Vali Loss: 0.0758935 Test Loss: 0.0846345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0656746\n",
      "\tspeed: 0.0288s/iter; left time: 553.5301s\n",
      "\titers: 200, epoch: 15 | loss: 0.0668071\n",
      "\tspeed: 0.0112s/iter; left time: 214.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 225 | Train Loss: 0.0678959 Vali Loss: 0.0754225 Test Loss: 0.0840952\n",
      "Validation loss decreased (0.075838 --> 0.075422).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693426\n",
      "\tspeed: 0.0274s/iter; left time: 520.9245s\n",
      "\titers: 200, epoch: 16 | loss: 0.0683042\n",
      "\tspeed: 0.0113s/iter; left time: 213.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 225 | Train Loss: 0.0676131 Vali Loss: 0.0754790 Test Loss: 0.0842982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665731\n",
      "\tspeed: 0.0284s/iter; left time: 533.9705s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692905\n",
      "\tspeed: 0.0128s/iter; left time: 239.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0672391 Vali Loss: 0.0753235 Test Loss: 0.0840408\n",
      "Validation loss decreased (0.075422 --> 0.075323).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0675017\n",
      "\tspeed: 0.0319s/iter; left time: 593.3823s\n",
      "\titers: 200, epoch: 18 | loss: 0.0680042\n",
      "\tspeed: 0.0183s/iter; left time: 337.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0671991 Vali Loss: 0.0752749 Test Loss: 0.0838677\n",
      "Validation loss decreased (0.075323 --> 0.075275).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657052\n",
      "\tspeed: 0.0343s/iter; left time: 629.8836s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674223\n",
      "\tspeed: 0.0151s/iter; left time: 276.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0668679 Vali Loss: 0.0751044 Test Loss: 0.0839776\n",
      "Validation loss decreased (0.075275 --> 0.075104).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0669044\n",
      "\tspeed: 0.0360s/iter; left time: 653.0866s\n",
      "\titers: 200, epoch: 20 | loss: 0.0678561\n",
      "\tspeed: 0.0193s/iter; left time: 348.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0666958 Vali Loss: 0.0752382 Test Loss: 0.0841614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0627363\n",
      "\tspeed: 0.0349s/iter; left time: 625.5673s\n",
      "\titers: 200, epoch: 21 | loss: 0.0638758\n",
      "\tspeed: 0.0166s/iter; left time: 295.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0664966 Vali Loss: 0.0751106 Test Loss: 0.0842004\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0678066\n",
      "\tspeed: 0.0367s/iter; left time: 648.0246s\n",
      "\titers: 200, epoch: 22 | loss: 0.0707027\n",
      "\tspeed: 0.0195s/iter; left time: 342.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0663971 Vali Loss: 0.0750149 Test Loss: 0.0839074\n",
      "Validation loss decreased (0.075104 --> 0.075015).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725942\n",
      "\tspeed: 0.0332s/iter; left time: 578.7540s\n",
      "\titers: 200, epoch: 23 | loss: 0.0631115\n",
      "\tspeed: 0.0172s/iter; left time: 298.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0662704 Vali Loss: 0.0749497 Test Loss: 0.0838586\n",
      "Validation loss decreased (0.075015 --> 0.074950).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0666017\n",
      "\tspeed: 0.0345s/iter; left time: 593.5369s\n",
      "\titers: 200, epoch: 24 | loss: 0.0659782\n",
      "\tspeed: 0.0193s/iter; left time: 330.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0662504 Vali Loss: 0.0748828 Test Loss: 0.0839017\n",
      "Validation loss decreased (0.074950 --> 0.074883).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0667289\n",
      "\tspeed: 0.0323s/iter; left time: 549.5887s\n",
      "\titers: 200, epoch: 25 | loss: 0.0662316\n",
      "\tspeed: 0.0168s/iter; left time: 283.4324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0660893 Vali Loss: 0.0747243 Test Loss: 0.0837082\n",
      "Validation loss decreased (0.074883 --> 0.074724).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0672820\n",
      "\tspeed: 0.0301s/iter; left time: 505.6858s\n",
      "\titers: 200, epoch: 26 | loss: 0.0641873\n",
      "\tspeed: 0.0159s/iter; left time: 265.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0661890 Vali Loss: 0.0747570 Test Loss: 0.0837986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0659174\n",
      "\tspeed: 0.0306s/iter; left time: 505.9188s\n",
      "\titers: 200, epoch: 27 | loss: 0.0678228\n",
      "\tspeed: 0.0152s/iter; left time: 250.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0660290 Vali Loss: 0.0749338 Test Loss: 0.0840740\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0658934\n",
      "\tspeed: 0.0307s/iter; left time: 501.1573s\n",
      "\titers: 200, epoch: 28 | loss: 0.0669217\n",
      "\tspeed: 0.0159s/iter; left time: 257.6608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0660034 Vali Loss: 0.0746343 Test Loss: 0.0837211\n",
      "Validation loss decreased (0.074724 --> 0.074634).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645059\n",
      "\tspeed: 0.0373s/iter; left time: 601.0624s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661160\n",
      "\tspeed: 0.0174s/iter; left time: 278.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0660438 Vali Loss: 0.0746923 Test Loss: 0.0838302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0647524\n",
      "\tspeed: 0.0299s/iter; left time: 474.0192s\n",
      "\titers: 200, epoch: 30 | loss: 0.0642171\n",
      "\tspeed: 0.0097s/iter; left time: 153.5135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 225 | Train Loss: 0.0659379 Vali Loss: 0.0747332 Test Loss: 0.0839173\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0647936\n",
      "\tspeed: 0.0290s/iter; left time: 454.6078s\n",
      "\titers: 200, epoch: 31 | loss: 0.0682318\n",
      "\tspeed: 0.0148s/iter; left time: 229.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0657921 Vali Loss: 0.0746830 Test Loss: 0.0837747\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0651756\n",
      "\tspeed: 0.0287s/iter; left time: 442.2085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0618787\n",
      "\tspeed: 0.0108s/iter; left time: 165.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0658708 Vali Loss: 0.0746024 Test Loss: 0.0837288\n",
      "Validation loss decreased (0.074634 --> 0.074602).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0668168\n",
      "\tspeed: 0.0338s/iter; left time: 513.6581s\n",
      "\titers: 200, epoch: 33 | loss: 0.0633686\n",
      "\tspeed: 0.0165s/iter; left time: 249.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0658372 Vali Loss: 0.0745602 Test Loss: 0.0835967\n",
      "Validation loss decreased (0.074602 --> 0.074560).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647600\n",
      "\tspeed: 0.0316s/iter; left time: 473.0027s\n",
      "\titers: 200, epoch: 34 | loss: 0.0629268\n",
      "\tspeed: 0.0146s/iter; left time: 217.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0657470 Vali Loss: 0.0746374 Test Loss: 0.0837197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0641729\n",
      "\tspeed: 0.0345s/iter; left time: 508.2503s\n",
      "\titers: 200, epoch: 35 | loss: 0.0617976\n",
      "\tspeed: 0.0177s/iter; left time: 259.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0657178 Vali Loss: 0.0746599 Test Loss: 0.0838663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0682861\n",
      "\tspeed: 0.0345s/iter; left time: 501.5188s\n",
      "\titers: 200, epoch: 36 | loss: 0.0719490\n",
      "\tspeed: 0.0200s/iter; left time: 288.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0656840 Vali Loss: 0.0747683 Test Loss: 0.0839771\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0674170\n",
      "\tspeed: 0.0365s/iter; left time: 522.0842s\n",
      "\titers: 200, epoch: 37 | loss: 0.0645799\n",
      "\tspeed: 0.0177s/iter; left time: 251.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0657696 Vali Loss: 0.0745763 Test Loss: 0.0837600\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0679446\n",
      "\tspeed: 0.0361s/iter; left time: 507.7489s\n",
      "\titers: 200, epoch: 38 | loss: 0.0619880\n",
      "\tspeed: 0.0196s/iter; left time: 273.9043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0656903 Vali Loss: 0.0745828 Test Loss: 0.0835773\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0635080\n",
      "\tspeed: 0.0329s/iter; left time: 456.3189s\n",
      "\titers: 200, epoch: 39 | loss: 0.0654072\n",
      "\tspeed: 0.0167s/iter; left time: 229.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0656889 Vali Loss: 0.0746122 Test Loss: 0.0837281\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0648413\n",
      "\tspeed: 0.0350s/iter; left time: 476.7628s\n",
      "\titers: 200, epoch: 40 | loss: 0.0636021\n",
      "\tspeed: 0.0196s/iter; left time: 264.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0654821 Vali Loss: 0.0746146 Test Loss: 0.0837951\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0624976\n",
      "\tspeed: 0.0360s/iter; left time: 482.8451s\n",
      "\titers: 200, epoch: 41 | loss: 0.0613499\n",
      "\tspeed: 0.0168s/iter; left time: 224.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0655606 Vali Loss: 0.0745522 Test Loss: 0.0837003\n",
      "Validation loss decreased (0.074560 --> 0.074552).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0655213\n",
      "\tspeed: 0.0311s/iter; left time: 409.8903s\n",
      "\titers: 200, epoch: 42 | loss: 0.0619614\n",
      "\tspeed: 0.0156s/iter; left time: 204.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0655404 Vali Loss: 0.0746655 Test Loss: 0.0837635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0676364\n",
      "\tspeed: 0.0353s/iter; left time: 457.7237s\n",
      "\titers: 200, epoch: 43 | loss: 0.0665837\n",
      "\tspeed: 0.0173s/iter; left time: 222.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0656253 Vali Loss: 0.0745803 Test Loss: 0.0836900\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0677450\n",
      "\tspeed: 0.0371s/iter; left time: 472.1259s\n",
      "\titers: 200, epoch: 44 | loss: 0.0624176\n",
      "\tspeed: 0.0208s/iter; left time: 263.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 225 | Train Loss: 0.0656435 Vali Loss: 0.0746780 Test Loss: 0.0839206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0664974\n",
      "\tspeed: 0.0377s/iter; left time: 471.5338s\n",
      "\titers: 200, epoch: 45 | loss: 0.0629244\n",
      "\tspeed: 0.0173s/iter; left time: 214.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0655669 Vali Loss: 0.0746178 Test Loss: 0.0837615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0656827\n",
      "\tspeed: 0.0325s/iter; left time: 399.4772s\n",
      "\titers: 200, epoch: 46 | loss: 0.0656918\n",
      "\tspeed: 0.0151s/iter; left time: 184.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0656163 Vali Loss: 0.0747212 Test Loss: 0.0839002\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0688594\n",
      "\tspeed: 0.0355s/iter; left time: 427.6679s\n",
      "\titers: 200, epoch: 47 | loss: 0.0655751\n",
      "\tspeed: 0.0183s/iter; left time: 218.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0654692 Vali Loss: 0.0745072 Test Loss: 0.0836411\n",
      "Validation loss decreased (0.074552 --> 0.074507).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0682336\n",
      "\tspeed: 0.0370s/iter; left time: 437.2951s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633480\n",
      "\tspeed: 0.0195s/iter; left time: 228.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0656726 Vali Loss: 0.0745180 Test Loss: 0.0836578\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0704546\n",
      "\tspeed: 0.0334s/iter; left time: 387.4953s\n",
      "\titers: 200, epoch: 49 | loss: 0.0642681\n",
      "\tspeed: 0.0160s/iter; left time: 184.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0654801 Vali Loss: 0.0745601 Test Loss: 0.0837021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0658883\n",
      "\tspeed: 0.0335s/iter; left time: 381.5052s\n",
      "\titers: 200, epoch: 50 | loss: 0.0619239\n",
      "\tspeed: 0.0176s/iter; left time: 198.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0655309 Vali Loss: 0.0745200 Test Loss: 0.0836687\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0675842\n",
      "\tspeed: 0.0347s/iter; left time: 386.5840s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630216\n",
      "\tspeed: 0.0211s/iter; left time: 233.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0655235 Vali Loss: 0.0747122 Test Loss: 0.0838947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0621631\n",
      "\tspeed: 0.0323s/iter; left time: 352.7972s\n",
      "\titers: 200, epoch: 52 | loss: 0.0661019\n",
      "\tspeed: 0.0182s/iter; left time: 196.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0655488 Vali Loss: 0.0745604 Test Loss: 0.0837188\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0655467\n",
      "\tspeed: 0.0321s/iter; left time: 343.7845s\n",
      "\titers: 200, epoch: 53 | loss: 0.0644962\n",
      "\tspeed: 0.0178s/iter; left time: 188.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0655646 Vali Loss: 0.0746658 Test Loss: 0.0838256\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0677637\n",
      "\tspeed: 0.0368s/iter; left time: 385.3133s\n",
      "\titers: 200, epoch: 54 | loss: 0.0620990\n",
      "\tspeed: 0.0190s/iter; left time: 196.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0654664 Vali Loss: 0.0746213 Test Loss: 0.0837417\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688697\n",
      "\tspeed: 0.0337s/iter; left time: 345.6830s\n",
      "\titers: 200, epoch: 55 | loss: 0.0613465\n",
      "\tspeed: 0.0171s/iter; left time: 173.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0655057 Vali Loss: 0.0746580 Test Loss: 0.0838546\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0621942\n",
      "\tspeed: 0.0317s/iter; left time: 317.6353s\n",
      "\titers: 200, epoch: 56 | loss: 0.0620328\n",
      "\tspeed: 0.0152s/iter; left time: 150.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0658393 Vali Loss: 0.0746421 Test Loss: 0.0838695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0651978\n",
      "\tspeed: 0.0325s/iter; left time: 318.5446s\n",
      "\titers: 200, epoch: 57 | loss: 0.0681412\n",
      "\tspeed: 0.0153s/iter; left time: 148.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0654082 Vali Loss: 0.0745729 Test Loss: 0.0837556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020481519401073456, rmse:0.1431136578321457, mae:0.08364105224609375, rse:0.5536016821861267\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2388178\n",
      "\tspeed: 0.0246s/iter; left time: 552.0856s\n",
      "\titers: 200, epoch: 1 | loss: 0.2182519\n",
      "\tspeed: 0.0164s/iter; left time: 365.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.2399724 Vali Loss: 0.1777182 Test Loss: 0.1867836\n",
      "Validation loss decreased (inf --> 0.177718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1273558\n",
      "\tspeed: 0.0352s/iter; left time: 781.4662s\n",
      "\titers: 200, epoch: 2 | loss: 0.1026327\n",
      "\tspeed: 0.0152s/iter; left time: 336.6227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.1317914 Vali Loss: 0.0993074 Test Loss: 0.1113348\n",
      "Validation loss decreased (0.177718 --> 0.099307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890958\n",
      "\tspeed: 0.0372s/iter; left time: 817.6551s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865826\n",
      "\tspeed: 0.0198s/iter; left time: 432.9223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.0907453 Vali Loss: 0.0894003 Test Loss: 0.0954325\n",
      "Validation loss decreased (0.099307 --> 0.089400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838012\n",
      "\tspeed: 0.0337s/iter; left time: 732.2815s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784943\n",
      "\tspeed: 0.0180s/iter; left time: 390.0139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0831156 Vali Loss: 0.0839630 Test Loss: 0.0908817\n",
      "Validation loss decreased (0.089400 --> 0.083963).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758482\n",
      "\tspeed: 0.0332s/iter; left time: 713.0166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0736847\n",
      "\tspeed: 0.0169s/iter; left time: 361.0933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0785101 Vali Loss: 0.0816287 Test Loss: 0.0896576\n",
      "Validation loss decreased (0.083963 --> 0.081629).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728346\n",
      "\tspeed: 0.0359s/iter; left time: 763.0707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0717377\n",
      "\tspeed: 0.0176s/iter; left time: 373.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0757676 Vali Loss: 0.0806589 Test Loss: 0.0891806\n",
      "Validation loss decreased (0.081629 --> 0.080659).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0755224\n",
      "\tspeed: 0.0345s/iter; left time: 727.0654s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664887\n",
      "\tspeed: 0.0150s/iter; left time: 314.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0739093 Vali Loss: 0.0794674 Test Loss: 0.0877857\n",
      "Validation loss decreased (0.080659 --> 0.079467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753219\n",
      "\tspeed: 0.0318s/iter; left time: 662.5818s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710723\n",
      "\tspeed: 0.0151s/iter; left time: 312.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0723964 Vali Loss: 0.0791210 Test Loss: 0.0877187\n",
      "Validation loss decreased (0.079467 --> 0.079121).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728624\n",
      "\tspeed: 0.0377s/iter; left time: 777.1781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668347\n",
      "\tspeed: 0.0174s/iter; left time: 357.3355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0715036 Vali Loss: 0.0779304 Test Loss: 0.0869970\n",
      "Validation loss decreased (0.079121 --> 0.077930).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0699616\n",
      "\tspeed: 0.0313s/iter; left time: 637.4537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692299\n",
      "\tspeed: 0.0143s/iter; left time: 290.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0704371 Vali Loss: 0.0773976 Test Loss: 0.0863333\n",
      "Validation loss decreased (0.077930 --> 0.077398).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0701377\n",
      "\tspeed: 0.0336s/iter; left time: 676.2188s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711334\n",
      "\tspeed: 0.0182s/iter; left time: 364.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0697987 Vali Loss: 0.0768846 Test Loss: 0.0858211\n",
      "Validation loss decreased (0.077398 --> 0.076885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698014\n",
      "\tspeed: 0.0354s/iter; left time: 704.8776s\n",
      "\titers: 200, epoch: 12 | loss: 0.0695472\n",
      "\tspeed: 0.0178s/iter; left time: 352.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0694048 Vali Loss: 0.0766271 Test Loss: 0.0852364\n",
      "Validation loss decreased (0.076885 --> 0.076627).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0675972\n",
      "\tspeed: 0.0365s/iter; left time: 719.3901s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714289\n",
      "\tspeed: 0.0181s/iter; left time: 355.2345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0688381 Vali Loss: 0.0768167 Test Loss: 0.0856031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0700926\n",
      "\tspeed: 0.0359s/iter; left time: 698.5357s\n",
      "\titers: 200, epoch: 14 | loss: 0.0705423\n",
      "\tspeed: 0.0179s/iter; left time: 346.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0685697 Vali Loss: 0.0757709 Test Loss: 0.0846112\n",
      "Validation loss decreased (0.076627 --> 0.075771).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0666968\n",
      "\tspeed: 0.0378s/iter; left time: 728.3466s\n",
      "\titers: 200, epoch: 15 | loss: 0.0667904\n",
      "\tspeed: 0.0160s/iter; left time: 306.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0678830 Vali Loss: 0.0756376 Test Loss: 0.0844000\n",
      "Validation loss decreased (0.075771 --> 0.075638).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0671397\n",
      "\tspeed: 0.0373s/iter; left time: 710.1456s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691180\n",
      "\tspeed: 0.0186s/iter; left time: 351.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0677403 Vali Loss: 0.0755905 Test Loss: 0.0843625\n",
      "Validation loss decreased (0.075638 --> 0.075590).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0662527\n",
      "\tspeed: 0.0380s/iter; left time: 713.6629s\n",
      "\titers: 200, epoch: 17 | loss: 0.0610230\n",
      "\tspeed: 0.0201s/iter; left time: 375.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0675268 Vali Loss: 0.0756874 Test Loss: 0.0843866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0695783\n",
      "\tspeed: 0.0383s/iter; left time: 711.1710s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691342\n",
      "\tspeed: 0.0167s/iter; left time: 309.0759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0673784 Vali Loss: 0.0758241 Test Loss: 0.0845734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0719842\n",
      "\tspeed: 0.0371s/iter; left time: 681.1131s\n",
      "\titers: 200, epoch: 19 | loss: 0.0653379\n",
      "\tspeed: 0.0168s/iter; left time: 306.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0671919 Vali Loss: 0.0753380 Test Loss: 0.0841991\n",
      "Validation loss decreased (0.075590 --> 0.075338).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0687822\n",
      "\tspeed: 0.0333s/iter; left time: 604.0065s\n",
      "\titers: 200, epoch: 20 | loss: 0.0619461\n",
      "\tspeed: 0.0160s/iter; left time: 287.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0670129 Vali Loss: 0.0753580 Test Loss: 0.0842329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0677746\n",
      "\tspeed: 0.0330s/iter; left time: 591.4132s\n",
      "\titers: 200, epoch: 21 | loss: 0.0670879\n",
      "\tspeed: 0.0152s/iter; left time: 271.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0669365 Vali Loss: 0.0755064 Test Loss: 0.0842856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0670374\n",
      "\tspeed: 0.0318s/iter; left time: 562.2980s\n",
      "\titers: 200, epoch: 22 | loss: 0.0655113\n",
      "\tspeed: 0.0153s/iter; left time: 269.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0667176 Vali Loss: 0.0750331 Test Loss: 0.0839804\n",
      "Validation loss decreased (0.075338 --> 0.075033).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0668420\n",
      "\tspeed: 0.0343s/iter; left time: 597.7805s\n",
      "\titers: 200, epoch: 23 | loss: 0.0658703\n",
      "\tspeed: 0.0165s/iter; left time: 285.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0665682 Vali Loss: 0.0750212 Test Loss: 0.0839592\n",
      "Validation loss decreased (0.075033 --> 0.075021).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0648703\n",
      "\tspeed: 0.0328s/iter; left time: 564.8329s\n",
      "\titers: 200, epoch: 24 | loss: 0.0706152\n",
      "\tspeed: 0.0151s/iter; left time: 259.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0663835 Vali Loss: 0.0749902 Test Loss: 0.0838656\n",
      "Validation loss decreased (0.075021 --> 0.074990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0653138\n",
      "\tspeed: 0.0386s/iter; left time: 656.1101s\n",
      "\titers: 200, epoch: 25 | loss: 0.0695039\n",
      "\tspeed: 0.0175s/iter; left time: 296.0069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0663624 Vali Loss: 0.0749484 Test Loss: 0.0837926\n",
      "Validation loss decreased (0.074990 --> 0.074948).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0691248\n",
      "\tspeed: 0.0335s/iter; left time: 561.4209s\n",
      "\titers: 200, epoch: 26 | loss: 0.0618585\n",
      "\tspeed: 0.0147s/iter; left time: 245.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0662928 Vali Loss: 0.0749143 Test Loss: 0.0837867\n",
      "Validation loss decreased (0.074948 --> 0.074914).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0626284\n",
      "\tspeed: 0.0319s/iter; left time: 528.5842s\n",
      "\titers: 200, epoch: 27 | loss: 0.0687371\n",
      "\tspeed: 0.0149s/iter; left time: 244.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0661510 Vali Loss: 0.0748319 Test Loss: 0.0835857\n",
      "Validation loss decreased (0.074914 --> 0.074832).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0651349\n",
      "\tspeed: 0.0311s/iter; left time: 508.4941s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707700\n",
      "\tspeed: 0.0159s/iter; left time: 257.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0660908 Vali Loss: 0.0748184 Test Loss: 0.0835905\n",
      "Validation loss decreased (0.074832 --> 0.074818).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0658929\n",
      "\tspeed: 0.0322s/iter; left time: 517.8244s\n",
      "\titers: 200, epoch: 29 | loss: 0.0664856\n",
      "\tspeed: 0.0160s/iter; left time: 255.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0661918 Vali Loss: 0.0748716 Test Loss: 0.0837305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0693522\n",
      "\tspeed: 0.0319s/iter; left time: 506.3924s\n",
      "\titers: 200, epoch: 30 | loss: 0.0671649\n",
      "\tspeed: 0.0145s/iter; left time: 229.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0660417 Vali Loss: 0.0748484 Test Loss: 0.0838063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0664139\n",
      "\tspeed: 0.0318s/iter; left time: 498.3755s\n",
      "\titers: 200, epoch: 31 | loss: 0.0674991\n",
      "\tspeed: 0.0153s/iter; left time: 237.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0660052 Vali Loss: 0.0748098 Test Loss: 0.0836985\n",
      "Validation loss decreased (0.074818 --> 0.074810).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0629480\n",
      "\tspeed: 0.0354s/iter; left time: 546.7001s\n",
      "\titers: 200, epoch: 32 | loss: 0.0679041\n",
      "\tspeed: 0.0172s/iter; left time: 264.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0659681 Vali Loss: 0.0747911 Test Loss: 0.0836148\n",
      "Validation loss decreased (0.074810 --> 0.074791).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0672479\n",
      "\tspeed: 0.0295s/iter; left time: 448.1865s\n",
      "\titers: 200, epoch: 33 | loss: 0.0727934\n",
      "\tspeed: 0.0118s/iter; left time: 177.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0660251 Vali Loss: 0.0747474 Test Loss: 0.0836668\n",
      "Validation loss decreased (0.074791 --> 0.074747).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0706449\n",
      "\tspeed: 0.0341s/iter; left time: 511.2375s\n",
      "\titers: 200, epoch: 34 | loss: 0.0624950\n",
      "\tspeed: 0.0171s/iter; left time: 254.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0658645 Vali Loss: 0.0747966 Test Loss: 0.0837391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0653407\n",
      "\tspeed: 0.0336s/iter; left time: 495.1802s\n",
      "\titers: 200, epoch: 35 | loss: 0.0693895\n",
      "\tspeed: 0.0156s/iter; left time: 228.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0658733 Vali Loss: 0.0747852 Test Loss: 0.0836694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0682885\n",
      "\tspeed: 0.0341s/iter; left time: 495.5976s\n",
      "\titers: 200, epoch: 36 | loss: 0.0668036\n",
      "\tspeed: 0.0166s/iter; left time: 239.1863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0657792 Vali Loss: 0.0747351 Test Loss: 0.0836585\n",
      "Validation loss decreased (0.074747 --> 0.074735).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0690809\n",
      "\tspeed: 0.0356s/iter; left time: 509.2706s\n",
      "\titers: 200, epoch: 37 | loss: 0.0640136\n",
      "\tspeed: 0.0171s/iter; left time: 243.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0658756 Vali Loss: 0.0747907 Test Loss: 0.0836819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0670546\n",
      "\tspeed: 0.0327s/iter; left time: 460.9193s\n",
      "\titers: 200, epoch: 38 | loss: 0.0665384\n",
      "\tspeed: 0.0145s/iter; left time: 202.7471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0657899 Vali Loss: 0.0747696 Test Loss: 0.0836834\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0626673\n",
      "\tspeed: 0.0326s/iter; left time: 451.1311s\n",
      "\titers: 200, epoch: 39 | loss: 0.0650180\n",
      "\tspeed: 0.0169s/iter; left time: 231.9260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0656801 Vali Loss: 0.0748786 Test Loss: 0.0839305\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0671039\n",
      "\tspeed: 0.0330s/iter; left time: 449.0905s\n",
      "\titers: 200, epoch: 40 | loss: 0.0674989\n",
      "\tspeed: 0.0149s/iter; left time: 201.3616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0657427 Vali Loss: 0.0747225 Test Loss: 0.0836363\n",
      "Validation loss decreased (0.074735 --> 0.074723).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0650668\n",
      "\tspeed: 0.0314s/iter; left time: 420.7551s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672973\n",
      "\tspeed: 0.0152s/iter; left time: 202.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0656366 Vali Loss: 0.0747689 Test Loss: 0.0837518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0697005\n",
      "\tspeed: 0.0316s/iter; left time: 416.5228s\n",
      "\titers: 200, epoch: 42 | loss: 0.0656713\n",
      "\tspeed: 0.0152s/iter; left time: 199.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0657307 Vali Loss: 0.0747003 Test Loss: 0.0836473\n",
      "Validation loss decreased (0.074723 --> 0.074700).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646323\n",
      "\tspeed: 0.0336s/iter; left time: 435.3986s\n",
      "\titers: 200, epoch: 43 | loss: 0.0638158\n",
      "\tspeed: 0.0159s/iter; left time: 204.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0656570 Vali Loss: 0.0747236 Test Loss: 0.0836677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0654169\n",
      "\tspeed: 0.0317s/iter; left time: 403.1378s\n",
      "\titers: 200, epoch: 44 | loss: 0.0667009\n",
      "\tspeed: 0.0154s/iter; left time: 194.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0655989 Vali Loss: 0.0746637 Test Loss: 0.0835448\n",
      "Validation loss decreased (0.074700 --> 0.074664).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0653667\n",
      "\tspeed: 0.0354s/iter; left time: 442.5793s\n",
      "\titers: 200, epoch: 45 | loss: 0.0623195\n",
      "\tspeed: 0.0162s/iter; left time: 201.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0655927 Vali Loss: 0.0746361 Test Loss: 0.0835031\n",
      "Validation loss decreased (0.074664 --> 0.074636).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0648136\n",
      "\tspeed: 0.0325s/iter; left time: 398.9867s\n",
      "\titers: 200, epoch: 46 | loss: 0.0634316\n",
      "\tspeed: 0.0154s/iter; left time: 187.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0656873 Vali Loss: 0.0746974 Test Loss: 0.0835906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0644567\n",
      "\tspeed: 0.0322s/iter; left time: 387.8203s\n",
      "\titers: 200, epoch: 47 | loss: 0.0674649\n",
      "\tspeed: 0.0149s/iter; left time: 177.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0656318 Vali Loss: 0.0747004 Test Loss: 0.0835359\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0638885\n",
      "\tspeed: 0.0267s/iter; left time: 315.3132s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633170\n",
      "\tspeed: 0.0127s/iter; left time: 149.3234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 225 | Train Loss: 0.0656023 Vali Loss: 0.0748286 Test Loss: 0.0838135\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0663939\n",
      "\tspeed: 0.0377s/iter; left time: 437.6171s\n",
      "\titers: 200, epoch: 49 | loss: 0.0685082\n",
      "\tspeed: 0.0179s/iter; left time: 205.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0656506 Vali Loss: 0.0747889 Test Loss: 0.0837646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0632886\n",
      "\tspeed: 0.0352s/iter; left time: 400.1008s\n",
      "\titers: 200, epoch: 50 | loss: 0.0671445\n",
      "\tspeed: 0.0173s/iter; left time: 195.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0655780 Vali Loss: 0.0747806 Test Loss: 0.0835741\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0623374\n",
      "\tspeed: 0.0347s/iter; left time: 387.3919s\n",
      "\titers: 200, epoch: 51 | loss: 0.0643868\n",
      "\tspeed: 0.0178s/iter; left time: 197.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0655646 Vali Loss: 0.0747436 Test Loss: 0.0837317\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0636110\n",
      "\tspeed: 0.0348s/iter; left time: 380.2505s\n",
      "\titers: 200, epoch: 52 | loss: 0.0663075\n",
      "\tspeed: 0.0176s/iter; left time: 190.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0656421 Vali Loss: 0.0746701 Test Loss: 0.0835855\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0626311\n",
      "\tspeed: 0.0334s/iter; left time: 357.6473s\n",
      "\titers: 200, epoch: 53 | loss: 0.0688870\n",
      "\tspeed: 0.0157s/iter; left time: 166.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0655239 Vali Loss: 0.0746517 Test Loss: 0.0835584\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0718522\n",
      "\tspeed: 0.0316s/iter; left time: 330.8418s\n",
      "\titers: 200, epoch: 54 | loss: 0.0653040\n",
      "\tspeed: 0.0152s/iter; left time: 157.8334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0656512 Vali Loss: 0.0746795 Test Loss: 0.0836077\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0699099\n",
      "\tspeed: 0.0331s/iter; left time: 339.6789s\n",
      "\titers: 200, epoch: 55 | loss: 0.0656586\n",
      "\tspeed: 0.0128s/iter; left time: 129.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0656060 Vali Loss: 0.0746935 Test Loss: 0.0836827\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020380981266498566, rmse:0.1427619755268097, mae:0.0835031047463417, rse:0.5522412657737732\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:28.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2457695\n",
      "\tspeed: 0.0362s/iter; left time: 811.3178s\n",
      "\titers: 200, epoch: 1 | loss: 0.2214903\n",
      "\tspeed: 0.0132s/iter; left time: 294.9859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.2463344 Vali Loss: 0.1826521 Test Loss: 0.1912599\n",
      "Validation loss decreased (inf --> 0.182652).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1277386\n",
      "\tspeed: 0.0361s/iter; left time: 800.4511s\n",
      "\titers: 200, epoch: 2 | loss: 0.1018808\n",
      "\tspeed: 0.0181s/iter; left time: 400.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.1313877 Vali Loss: 0.1018746 Test Loss: 0.1139771\n",
      "Validation loss decreased (0.182652 --> 0.101875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0908557\n",
      "\tspeed: 0.0314s/iter; left time: 688.6626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855185\n",
      "\tspeed: 0.0100s/iter; left time: 217.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 225 | Train Loss: 0.0930013 Vali Loss: 0.0921000 Test Loss: 0.0991172\n",
      "Validation loss decreased (0.101875 --> 0.092100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891004\n",
      "\tspeed: 0.0319s/iter; left time: 693.6035s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825887\n",
      "\tspeed: 0.0181s/iter; left time: 390.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0853147 Vali Loss: 0.0864257 Test Loss: 0.0946696\n",
      "Validation loss decreased (0.092100 --> 0.086426).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0822017\n",
      "\tspeed: 0.0361s/iter; left time: 775.1247s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771825\n",
      "\tspeed: 0.0189s/iter; left time: 404.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0809365 Vali Loss: 0.0845859 Test Loss: 0.0936776\n",
      "Validation loss decreased (0.086426 --> 0.084586).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798835\n",
      "\tspeed: 0.0316s/iter; left time: 672.2007s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827646\n",
      "\tspeed: 0.0153s/iter; left time: 323.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0789175 Vali Loss: 0.0837064 Test Loss: 0.0930236\n",
      "Validation loss decreased (0.084586 --> 0.083706).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752266\n",
      "\tspeed: 0.0335s/iter; left time: 705.7749s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747587\n",
      "\tspeed: 0.0159s/iter; left time: 333.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0769645 Vali Loss: 0.0841499 Test Loss: 0.0934944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0705568\n",
      "\tspeed: 0.0361s/iter; left time: 752.7324s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763874\n",
      "\tspeed: 0.0183s/iter; left time: 378.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0758539 Vali Loss: 0.0830533 Test Loss: 0.0929134\n",
      "Validation loss decreased (0.083706 --> 0.083053).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0757157\n",
      "\tspeed: 0.0329s/iter; left time: 677.7953s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759397\n",
      "\tspeed: 0.0170s/iter; left time: 348.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0749634 Vali Loss: 0.0820992 Test Loss: 0.0920538\n",
      "Validation loss decreased (0.083053 --> 0.082099).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0745221\n",
      "\tspeed: 0.0341s/iter; left time: 693.9088s\n",
      "\titers: 200, epoch: 10 | loss: 0.0719350\n",
      "\tspeed: 0.0156s/iter; left time: 315.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0741297 Vali Loss: 0.0814455 Test Loss: 0.0910367\n",
      "Validation loss decreased (0.082099 --> 0.081445).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764837\n",
      "\tspeed: 0.0330s/iter; left time: 664.7576s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695029\n",
      "\tspeed: 0.0167s/iter; left time: 334.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0739676 Vali Loss: 0.0803295 Test Loss: 0.0898504\n",
      "Validation loss decreased (0.081445 --> 0.080330).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716958\n",
      "\tspeed: 0.0339s/iter; left time: 676.3389s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746069\n",
      "\tspeed: 0.0154s/iter; left time: 305.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0731553 Vali Loss: 0.0803021 Test Loss: 0.0901671\n",
      "Validation loss decreased (0.080330 --> 0.080302).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0708047\n",
      "\tspeed: 0.0332s/iter; left time: 654.9965s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687040\n",
      "\tspeed: 0.0154s/iter; left time: 301.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0726615 Vali Loss: 0.0803218 Test Loss: 0.0901097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758782\n",
      "\tspeed: 0.0353s/iter; left time: 688.2904s\n",
      "\titers: 200, epoch: 14 | loss: 0.0756663\n",
      "\tspeed: 0.0168s/iter; left time: 325.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0721283 Vali Loss: 0.0797881 Test Loss: 0.0894258\n",
      "Validation loss decreased (0.080302 --> 0.079788).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686727\n",
      "\tspeed: 0.0352s/iter; left time: 676.9565s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697988\n",
      "\tspeed: 0.0183s/iter; left time: 351.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0717592 Vali Loss: 0.0802344 Test Loss: 0.0899736\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0721867\n",
      "\tspeed: 0.0338s/iter; left time: 642.7947s\n",
      "\titers: 200, epoch: 16 | loss: 0.0747293\n",
      "\tspeed: 0.0156s/iter; left time: 295.3021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0713627 Vali Loss: 0.0796205 Test Loss: 0.0895057\n",
      "Validation loss decreased (0.079788 --> 0.079620).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0694145\n",
      "\tspeed: 0.0326s/iter; left time: 612.9694s\n",
      "\titers: 200, epoch: 17 | loss: 0.0718711\n",
      "\tspeed: 0.0153s/iter; left time: 286.9771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0710901 Vali Loss: 0.0796221 Test Loss: 0.0895598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0694964\n",
      "\tspeed: 0.0318s/iter; left time: 590.3239s\n",
      "\titers: 200, epoch: 18 | loss: 0.0708955\n",
      "\tspeed: 0.0156s/iter; left time: 287.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0709736 Vali Loss: 0.0796491 Test Loss: 0.0896595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0705740\n",
      "\tspeed: 0.0345s/iter; left time: 632.2647s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759989\n",
      "\tspeed: 0.0203s/iter; left time: 370.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0706302 Vali Loss: 0.0795927 Test Loss: 0.0897387\n",
      "Validation loss decreased (0.079620 --> 0.079593).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0687659\n",
      "\tspeed: 0.0360s/iter; left time: 652.8019s\n",
      "\titers: 200, epoch: 20 | loss: 0.0704639\n",
      "\tspeed: 0.0188s/iter; left time: 338.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0705626 Vali Loss: 0.0795450 Test Loss: 0.0897743\n",
      "Validation loss decreased (0.079593 --> 0.079545).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0697231\n",
      "\tspeed: 0.0375s/iter; left time: 671.0817s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732484\n",
      "\tspeed: 0.0179s/iter; left time: 319.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0702737 Vali Loss: 0.0794629 Test Loss: 0.0898503\n",
      "Validation loss decreased (0.079545 --> 0.079463).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0725980\n",
      "\tspeed: 0.0336s/iter; left time: 594.0949s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697240\n",
      "\tspeed: 0.0156s/iter; left time: 273.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0701744 Vali Loss: 0.0795757 Test Loss: 0.0897552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662951\n",
      "\tspeed: 0.0346s/iter; left time: 603.3260s\n",
      "\titers: 200, epoch: 23 | loss: 0.0705444\n",
      "\tspeed: 0.0172s/iter; left time: 298.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0700460 Vali Loss: 0.0793628 Test Loss: 0.0896879\n",
      "Validation loss decreased (0.079463 --> 0.079363).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0696745\n",
      "\tspeed: 0.0333s/iter; left time: 573.1230s\n",
      "\titers: 200, epoch: 24 | loss: 0.0661158\n",
      "\tspeed: 0.0164s/iter; left time: 280.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0700054 Vali Loss: 0.0795738 Test Loss: 0.0900811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0697619\n",
      "\tspeed: 0.0321s/iter; left time: 546.4155s\n",
      "\titers: 200, epoch: 25 | loss: 0.0687341\n",
      "\tspeed: 0.0151s/iter; left time: 255.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0697976 Vali Loss: 0.0793890 Test Loss: 0.0897973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0694301\n",
      "\tspeed: 0.0310s/iter; left time: 520.3398s\n",
      "\titers: 200, epoch: 26 | loss: 0.0664604\n",
      "\tspeed: 0.0178s/iter; left time: 296.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0697441 Vali Loss: 0.0797010 Test Loss: 0.0899496\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0656098\n",
      "\tspeed: 0.0327s/iter; left time: 541.5560s\n",
      "\titers: 200, epoch: 27 | loss: 0.0713333\n",
      "\tspeed: 0.0185s/iter; left time: 304.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0696657 Vali Loss: 0.0794763 Test Loss: 0.0897405\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0722426\n",
      "\tspeed: 0.0318s/iter; left time: 519.4311s\n",
      "\titers: 200, epoch: 28 | loss: 0.0686098\n",
      "\tspeed: 0.0154s/iter; left time: 250.1012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0695880 Vali Loss: 0.0795084 Test Loss: 0.0898208\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0712926\n",
      "\tspeed: 0.0325s/iter; left time: 522.9468s\n",
      "\titers: 200, epoch: 29 | loss: 0.0702594\n",
      "\tspeed: 0.0189s/iter; left time: 302.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0695667 Vali Loss: 0.0794929 Test Loss: 0.0898527\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701126\n",
      "\tspeed: 0.0347s/iter; left time: 550.8938s\n",
      "\titers: 200, epoch: 30 | loss: 0.0691674\n",
      "\tspeed: 0.0191s/iter; left time: 300.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0696097 Vali Loss: 0.0795344 Test Loss: 0.0901617\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0710925\n",
      "\tspeed: 0.0371s/iter; left time: 580.9741s\n",
      "\titers: 200, epoch: 31 | loss: 0.0686123\n",
      "\tspeed: 0.0172s/iter; left time: 267.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0694451 Vali Loss: 0.0796398 Test Loss: 0.0897871\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0677457\n",
      "\tspeed: 0.0316s/iter; left time: 486.7493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0712155\n",
      "\tspeed: 0.0198s/iter; left time: 303.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0694937 Vali Loss: 0.0794603 Test Loss: 0.0898027\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0665110\n",
      "\tspeed: 0.0325s/iter; left time: 494.0400s\n",
      "\titers: 200, epoch: 33 | loss: 0.0714712\n",
      "\tspeed: 0.0172s/iter; left time: 260.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0694073 Vali Loss: 0.0795294 Test Loss: 0.0898771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022908687591552734, rmse:0.15135616064071655, mae:0.08968787640333176, rse:0.5862167477607727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2475315\n",
      "\tspeed: 0.0211s/iter; left time: 472.8780s\n",
      "\titers: 200, epoch: 1 | loss: 0.2264819\n",
      "\tspeed: 0.0162s/iter; left time: 361.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.2456049 Vali Loss: 0.1833336 Test Loss: 0.1914726\n",
      "Validation loss decreased (inf --> 0.183334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1228585\n",
      "\tspeed: 0.0353s/iter; left time: 783.0027s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990242\n",
      "\tspeed: 0.0189s/iter; left time: 417.5302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.1301335 Vali Loss: 0.1014620 Test Loss: 0.1144908\n",
      "Validation loss decreased (0.183334 --> 0.101462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894346\n",
      "\tspeed: 0.0352s/iter; left time: 772.6325s\n",
      "\titers: 200, epoch: 3 | loss: 0.0878249\n",
      "\tspeed: 0.0197s/iter; left time: 429.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0933888 Vali Loss: 0.0927016 Test Loss: 0.0995768\n",
      "Validation loss decreased (0.101462 --> 0.092702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936179\n",
      "\tspeed: 0.0346s/iter; left time: 752.6978s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834910\n",
      "\tspeed: 0.0178s/iter; left time: 385.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0856615 Vali Loss: 0.0868466 Test Loss: 0.0954649\n",
      "Validation loss decreased (0.092702 --> 0.086847).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0841565\n",
      "\tspeed: 0.0376s/iter; left time: 809.3174s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807808\n",
      "\tspeed: 0.0184s/iter; left time: 393.9126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0812586 Vali Loss: 0.0858457 Test Loss: 0.0945108\n",
      "Validation loss decreased (0.086847 --> 0.085846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802644\n",
      "\tspeed: 0.0372s/iter; left time: 791.6161s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779895\n",
      "\tspeed: 0.0174s/iter; left time: 368.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0787631 Vali Loss: 0.0846770 Test Loss: 0.0937102\n",
      "Validation loss decreased (0.085846 --> 0.084677).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776361\n",
      "\tspeed: 0.0333s/iter; left time: 700.2247s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771536\n",
      "\tspeed: 0.0167s/iter; left time: 350.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0769995 Vali Loss: 0.0834739 Test Loss: 0.0923947\n",
      "Validation loss decreased (0.084677 --> 0.083474).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780043\n",
      "\tspeed: 0.0334s/iter; left time: 695.5313s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787861\n",
      "\tspeed: 0.0170s/iter; left time: 353.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0756832 Vali Loss: 0.0826148 Test Loss: 0.0918682\n",
      "Validation loss decreased (0.083474 --> 0.082615).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0705152\n",
      "\tspeed: 0.0353s/iter; left time: 727.6348s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718096\n",
      "\tspeed: 0.0205s/iter; left time: 420.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0750352 Vali Loss: 0.0820301 Test Loss: 0.0913356\n",
      "Validation loss decreased (0.082615 --> 0.082030).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738082\n",
      "\tspeed: 0.0365s/iter; left time: 743.6972s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705996\n",
      "\tspeed: 0.0186s/iter; left time: 376.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0740733 Vali Loss: 0.0816444 Test Loss: 0.0911710\n",
      "Validation loss decreased (0.082030 --> 0.081644).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694988\n",
      "\tspeed: 0.0346s/iter; left time: 696.7456s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711344\n",
      "\tspeed: 0.0170s/iter; left time: 341.0570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0734706 Vali Loss: 0.0814154 Test Loss: 0.0910744\n",
      "Validation loss decreased (0.081644 --> 0.081415).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716891\n",
      "\tspeed: 0.0351s/iter; left time: 698.6890s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729579\n",
      "\tspeed: 0.0163s/iter; left time: 323.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0728471 Vali Loss: 0.0812354 Test Loss: 0.0910280\n",
      "Validation loss decreased (0.081415 --> 0.081235).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727554\n",
      "\tspeed: 0.0331s/iter; left time: 652.7930s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719812\n",
      "\tspeed: 0.0114s/iter; left time: 223.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0725295 Vali Loss: 0.0807067 Test Loss: 0.0906308\n",
      "Validation loss decreased (0.081235 --> 0.080707).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0737901\n",
      "\tspeed: 0.0315s/iter; left time: 612.5244s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761006\n",
      "\tspeed: 0.0156s/iter; left time: 302.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0721327 Vali Loss: 0.0807022 Test Loss: 0.0907606\n",
      "Validation loss decreased (0.080707 --> 0.080702).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0736133\n",
      "\tspeed: 0.0322s/iter; left time: 620.4389s\n",
      "\titers: 200, epoch: 15 | loss: 0.0723154\n",
      "\tspeed: 0.0168s/iter; left time: 322.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0717245 Vali Loss: 0.0804117 Test Loss: 0.0902714\n",
      "Validation loss decreased (0.080702 --> 0.080412).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0687496\n",
      "\tspeed: 0.0375s/iter; left time: 714.1060s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708548\n",
      "\tspeed: 0.0199s/iter; left time: 377.5447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0714129 Vali Loss: 0.0799183 Test Loss: 0.0899097\n",
      "Validation loss decreased (0.080412 --> 0.079918).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0679504\n",
      "\tspeed: 0.0348s/iter; left time: 653.8244s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778753\n",
      "\tspeed: 0.0178s/iter; left time: 332.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0711230 Vali Loss: 0.0798044 Test Loss: 0.0900320\n",
      "Validation loss decreased (0.079918 --> 0.079804).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0694376\n",
      "\tspeed: 0.0442s/iter; left time: 821.7637s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710280\n",
      "\tspeed: 0.0174s/iter; left time: 321.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0709428 Vali Loss: 0.0797784 Test Loss: 0.0898284\n",
      "Validation loss decreased (0.079804 --> 0.079778).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0688043\n",
      "\tspeed: 0.0359s/iter; left time: 659.1749s\n",
      "\titers: 200, epoch: 19 | loss: 0.0711079\n",
      "\tspeed: 0.0189s/iter; left time: 344.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0708623 Vali Loss: 0.0799950 Test Loss: 0.0903919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0645109\n",
      "\tspeed: 0.0345s/iter; left time: 625.4423s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717572\n",
      "\tspeed: 0.0182s/iter; left time: 327.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0705810 Vali Loss: 0.0797130 Test Loss: 0.0902688\n",
      "Validation loss decreased (0.079778 --> 0.079713).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0678085\n",
      "\tspeed: 0.0359s/iter; left time: 642.0294s\n",
      "\titers: 200, epoch: 21 | loss: 0.0693727\n",
      "\tspeed: 0.0182s/iter; left time: 324.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0704802 Vali Loss: 0.0796383 Test Loss: 0.0902148\n",
      "Validation loss decreased (0.079713 --> 0.079638).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0698550\n",
      "\tspeed: 0.0306s/iter; left time: 541.3396s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697957\n",
      "\tspeed: 0.0222s/iter; left time: 391.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0704161 Vali Loss: 0.0797148 Test Loss: 0.0903682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724288\n",
      "\tspeed: 0.0367s/iter; left time: 641.2787s\n",
      "\titers: 200, epoch: 23 | loss: 0.0695834\n",
      "\tspeed: 0.0150s/iter; left time: 259.9841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0703086 Vali Loss: 0.0799217 Test Loss: 0.0903951\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0704532\n",
      "\tspeed: 0.0369s/iter; left time: 636.2909s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708161\n",
      "\tspeed: 0.0190s/iter; left time: 325.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.0701037 Vali Loss: 0.0799287 Test Loss: 0.0905475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0711049\n",
      "\tspeed: 0.0368s/iter; left time: 625.1959s\n",
      "\titers: 200, epoch: 25 | loss: 0.0708909\n",
      "\tspeed: 0.0184s/iter; left time: 310.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0701468 Vali Loss: 0.0800464 Test Loss: 0.0906366\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0692690\n",
      "\tspeed: 0.0340s/iter; left time: 570.0768s\n",
      "\titers: 200, epoch: 26 | loss: 0.0730075\n",
      "\tspeed: 0.0186s/iter; left time: 309.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0701595 Vali Loss: 0.0801362 Test Loss: 0.0907676\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722371\n",
      "\tspeed: 0.0326s/iter; left time: 539.2172s\n",
      "\titers: 200, epoch: 27 | loss: 0.0678109\n",
      "\tspeed: 0.0173s/iter; left time: 284.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0699988 Vali Loss: 0.0799063 Test Loss: 0.0905414\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0755869\n",
      "\tspeed: 0.0320s/iter; left time: 522.5504s\n",
      "\titers: 200, epoch: 28 | loss: 0.0650524\n",
      "\tspeed: 0.0176s/iter; left time: 284.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0699465 Vali Loss: 0.0796831 Test Loss: 0.0902116\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0678778\n",
      "\tspeed: 0.0347s/iter; left time: 558.5371s\n",
      "\titers: 200, epoch: 29 | loss: 0.0683460\n",
      "\tspeed: 0.0173s/iter; left time: 277.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0698914 Vali Loss: 0.0797773 Test Loss: 0.0904671\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0732322\n",
      "\tspeed: 0.0356s/iter; left time: 564.5030s\n",
      "\titers: 200, epoch: 30 | loss: 0.0698619\n",
      "\tspeed: 0.0184s/iter; left time: 290.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0697509 Vali Loss: 0.0798239 Test Loss: 0.0905032\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0718747\n",
      "\tspeed: 0.0356s/iter; left time: 556.8336s\n",
      "\titers: 200, epoch: 31 | loss: 0.0708746\n",
      "\tspeed: 0.0168s/iter; left time: 261.3923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0699904 Vali Loss: 0.0794514 Test Loss: 0.0901573\n",
      "Validation loss decreased (0.079638 --> 0.079451).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0675547\n",
      "\tspeed: 0.0356s/iter; left time: 549.8464s\n",
      "\titers: 200, epoch: 32 | loss: 0.0683894\n",
      "\tspeed: 0.0164s/iter; left time: 251.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0696626 Vali Loss: 0.0796696 Test Loss: 0.0903575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0685225\n",
      "\tspeed: 0.0323s/iter; left time: 490.9030s\n",
      "\titers: 200, epoch: 33 | loss: 0.0686906\n",
      "\tspeed: 0.0171s/iter; left time: 258.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0696908 Vali Loss: 0.0795452 Test Loss: 0.0901167\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0667701\n",
      "\tspeed: 0.0349s/iter; left time: 523.2245s\n",
      "\titers: 200, epoch: 34 | loss: 0.0682344\n",
      "\tspeed: 0.0177s/iter; left time: 263.3715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0698480 Vali Loss: 0.0795390 Test Loss: 0.0901924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0728837\n",
      "\tspeed: 0.0344s/iter; left time: 507.6933s\n",
      "\titers: 200, epoch: 35 | loss: 0.0682282\n",
      "\tspeed: 0.0192s/iter; left time: 281.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0697524 Vali Loss: 0.0795052 Test Loss: 0.0902432\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0698334\n",
      "\tspeed: 0.0327s/iter; left time: 474.3197s\n",
      "\titers: 200, epoch: 36 | loss: 0.0653570\n",
      "\tspeed: 0.0146s/iter; left time: 210.8943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0696060 Vali Loss: 0.0797219 Test Loss: 0.0904662\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0688643\n",
      "\tspeed: 0.0350s/iter; left time: 500.3553s\n",
      "\titers: 200, epoch: 37 | loss: 0.0726332\n",
      "\tspeed: 0.0161s/iter; left time: 229.1044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0695769 Vali Loss: 0.0801196 Test Loss: 0.0909049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0683476\n",
      "\tspeed: 0.0369s/iter; left time: 520.0695s\n",
      "\titers: 200, epoch: 38 | loss: 0.0744995\n",
      "\tspeed: 0.0161s/iter; left time: 224.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0696177 Vali Loss: 0.0794538 Test Loss: 0.0900954\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0695931\n",
      "\tspeed: 0.0325s/iter; left time: 450.4762s\n",
      "\titers: 200, epoch: 39 | loss: 0.0729357\n",
      "\tspeed: 0.0155s/iter; left time: 213.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0694720 Vali Loss: 0.0795424 Test Loss: 0.0902805\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0661439\n",
      "\tspeed: 0.0314s/iter; left time: 427.9428s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719939\n",
      "\tspeed: 0.0140s/iter; left time: 189.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0695547 Vali Loss: 0.0796985 Test Loss: 0.0904467\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0714126\n",
      "\tspeed: 0.0338s/iter; left time: 453.0411s\n",
      "\titers: 200, epoch: 41 | loss: 0.0713710\n",
      "\tspeed: 0.0164s/iter; left time: 218.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0694798 Vali Loss: 0.0796473 Test Loss: 0.0904636\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023290717974305153, rmse:0.15261296927928925, mae:0.09015733748674393, rse:0.5910844802856445\n",
      "Intermediate time for FR and pred_len 168: 00h:06m:33.01s\n",
      "Intermediate time for FR: 00h:27m:02.97s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2748396\n",
      "\tspeed: 0.0417s/iter; left time: 937.2237s\n",
      "\titers: 200, epoch: 1 | loss: 0.2437673\n",
      "\tspeed: 0.0146s/iter; left time: 326.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.2755289 Vali Loss: 0.1856256 Test Loss: 0.1920305\n",
      "Validation loss decreased (inf --> 0.185626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1493361\n",
      "\tspeed: 0.0294s/iter; left time: 655.6071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1137058\n",
      "\tspeed: 0.0130s/iter; left time: 288.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.1543205 Vali Loss: 0.0913810 Test Loss: 0.0918437\n",
      "Validation loss decreased (0.185626 --> 0.091381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1026489\n",
      "\tspeed: 0.0302s/iter; left time: 665.1519s\n",
      "\titers: 200, epoch: 3 | loss: 0.0962690\n",
      "\tspeed: 0.0150s/iter; left time: 329.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.1004594 Vali Loss: 0.0835395 Test Loss: 0.0854951\n",
      "Validation loss decreased (0.091381 --> 0.083539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915175\n",
      "\tspeed: 0.0310s/iter; left time: 677.2316s\n",
      "\titers: 200, epoch: 4 | loss: 0.0810010\n",
      "\tspeed: 0.0156s/iter; left time: 338.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0900728 Vali Loss: 0.0788191 Test Loss: 0.0802079\n",
      "Validation loss decreased (0.083539 --> 0.078819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0855739\n",
      "\tspeed: 0.0296s/iter; left time: 640.1663s\n",
      "\titers: 200, epoch: 5 | loss: 0.0812334\n",
      "\tspeed: 0.0155s/iter; left time: 333.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0840692 Vali Loss: 0.0760780 Test Loss: 0.0758319\n",
      "Validation loss decreased (0.078819 --> 0.076078).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776363\n",
      "\tspeed: 0.0298s/iter; left time: 637.7694s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761937\n",
      "\tspeed: 0.0147s/iter; left time: 312.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0797316 Vali Loss: 0.0726597 Test Loss: 0.0717476\n",
      "Validation loss decreased (0.076078 --> 0.072660).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815444\n",
      "\tspeed: 0.0330s/iter; left time: 697.0667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786124\n",
      "\tspeed: 0.0155s/iter; left time: 325.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0767705 Vali Loss: 0.0700167 Test Loss: 0.0696374\n",
      "Validation loss decreased (0.072660 --> 0.070017).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715965\n",
      "\tspeed: 0.0356s/iter; left time: 744.7882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738217\n",
      "\tspeed: 0.0206s/iter; left time: 427.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 226 | Train Loss: 0.0745824 Vali Loss: 0.0685167 Test Loss: 0.0687677\n",
      "Validation loss decreased (0.070017 --> 0.068517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0756384\n",
      "\tspeed: 0.0333s/iter; left time: 689.5123s\n",
      "\titers: 200, epoch: 9 | loss: 0.0742270\n",
      "\tspeed: 0.0147s/iter; left time: 302.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0727980 Vali Loss: 0.0671877 Test Loss: 0.0674993\n",
      "Validation loss decreased (0.068517 --> 0.067188).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0706152\n",
      "\tspeed: 0.0369s/iter; left time: 756.1406s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760004\n",
      "\tspeed: 0.0217s/iter; left time: 441.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0716838 Vali Loss: 0.0665030 Test Loss: 0.0669898\n",
      "Validation loss decreased (0.067188 --> 0.066503).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702347\n",
      "\tspeed: 0.0318s/iter; left time: 643.2816s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718995\n",
      "\tspeed: 0.0172s/iter; left time: 346.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0707948 Vali Loss: 0.0666187 Test Loss: 0.0674490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0734934\n",
      "\tspeed: 0.0328s/iter; left time: 655.5600s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709180\n",
      "\tspeed: 0.0171s/iter; left time: 341.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0698628 Vali Loss: 0.0650645 Test Loss: 0.0659001\n",
      "Validation loss decreased (0.066503 --> 0.065064).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0696956\n",
      "\tspeed: 0.0353s/iter; left time: 698.2108s\n",
      "\titers: 200, epoch: 13 | loss: 0.0614012\n",
      "\tspeed: 0.0181s/iter; left time: 356.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0692104 Vali Loss: 0.0647886 Test Loss: 0.0656072\n",
      "Validation loss decreased (0.065064 --> 0.064789).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0693385\n",
      "\tspeed: 0.0355s/iter; left time: 693.9144s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682732\n",
      "\tspeed: 0.0167s/iter; left time: 324.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0685786 Vali Loss: 0.0644128 Test Loss: 0.0652005\n",
      "Validation loss decreased (0.064789 --> 0.064413).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638366\n",
      "\tspeed: 0.0251s/iter; left time: 486.1250s\n",
      "\titers: 200, epoch: 15 | loss: 0.0725680\n",
      "\tspeed: 0.0097s/iter; left time: 185.7303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.36s\n",
      "Steps: 226 | Train Loss: 0.0681003 Vali Loss: 0.0639429 Test Loss: 0.0648437\n",
      "Validation loss decreased (0.064413 --> 0.063943).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0701464\n",
      "\tspeed: 0.0319s/iter; left time: 609.2977s\n",
      "\titers: 200, epoch: 16 | loss: 0.0647896\n",
      "\tspeed: 0.0155s/iter; left time: 294.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0675665 Vali Loss: 0.0636157 Test Loss: 0.0646268\n",
      "Validation loss decreased (0.063943 --> 0.063616).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0655411\n",
      "\tspeed: 0.0309s/iter; left time: 582.7417s\n",
      "\titers: 200, epoch: 17 | loss: 0.0670703\n",
      "\tspeed: 0.0163s/iter; left time: 305.4474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0669401 Vali Loss: 0.0634104 Test Loss: 0.0643599\n",
      "Validation loss decreased (0.063616 --> 0.063410).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0698583\n",
      "\tspeed: 0.0316s/iter; left time: 590.3265s\n",
      "\titers: 200, epoch: 18 | loss: 0.0653305\n",
      "\tspeed: 0.0101s/iter; left time: 187.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 226 | Train Loss: 0.0667295 Vali Loss: 0.0626011 Test Loss: 0.0639532\n",
      "Validation loss decreased (0.063410 --> 0.062601).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661613\n",
      "\tspeed: 0.0295s/iter; left time: 544.4511s\n",
      "\titers: 200, epoch: 19 | loss: 0.0649737\n",
      "\tspeed: 0.0164s/iter; left time: 300.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0663652 Vali Loss: 0.0619979 Test Loss: 0.0636087\n",
      "Validation loss decreased (0.062601 --> 0.061998).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0649312\n",
      "\tspeed: 0.0353s/iter; left time: 643.0561s\n",
      "\titers: 200, epoch: 20 | loss: 0.0673294\n",
      "\tspeed: 0.0185s/iter; left time: 334.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0662496 Vali Loss: 0.0621928 Test Loss: 0.0636217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0673968\n",
      "\tspeed: 0.0336s/iter; left time: 604.5872s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683301\n",
      "\tspeed: 0.0198s/iter; left time: 353.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0660445 Vali Loss: 0.0619915 Test Loss: 0.0636112\n",
      "Validation loss decreased (0.061998 --> 0.061992).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0616098\n",
      "\tspeed: 0.0332s/iter; left time: 588.6153s\n",
      "\titers: 200, epoch: 22 | loss: 0.0679803\n",
      "\tspeed: 0.0150s/iter; left time: 265.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0657187 Vali Loss: 0.0618104 Test Loss: 0.0633237\n",
      "Validation loss decreased (0.061992 --> 0.061810).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0601932\n",
      "\tspeed: 0.0353s/iter; left time: 619.6269s\n",
      "\titers: 200, epoch: 23 | loss: 0.0639134\n",
      "\tspeed: 0.0197s/iter; left time: 342.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0654844 Vali Loss: 0.0615780 Test Loss: 0.0632567\n",
      "Validation loss decreased (0.061810 --> 0.061578).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621948\n",
      "\tspeed: 0.0365s/iter; left time: 632.3301s\n",
      "\titers: 200, epoch: 24 | loss: 0.0668994\n",
      "\tspeed: 0.0198s/iter; left time: 341.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 226 | Train Loss: 0.0654431 Vali Loss: 0.0612439 Test Loss: 0.0631715\n",
      "Validation loss decreased (0.061578 --> 0.061244).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0627289\n",
      "\tspeed: 0.0318s/iter; left time: 542.2627s\n",
      "\titers: 200, epoch: 25 | loss: 0.0677464\n",
      "\tspeed: 0.0147s/iter; left time: 248.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0652054 Vali Loss: 0.0613669 Test Loss: 0.0629946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0604987\n",
      "\tspeed: 0.0315s/iter; left time: 530.1911s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686064\n",
      "\tspeed: 0.0169s/iter; left time: 283.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0650758 Vali Loss: 0.0612290 Test Loss: 0.0629992\n",
      "Validation loss decreased (0.061244 --> 0.061229).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0660665\n",
      "\tspeed: 0.0351s/iter; left time: 583.3352s\n",
      "\titers: 200, epoch: 27 | loss: 0.0662128\n",
      "\tspeed: 0.0195s/iter; left time: 322.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 226 | Train Loss: 0.0649722 Vali Loss: 0.0614886 Test Loss: 0.0630154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650454\n",
      "\tspeed: 0.0333s/iter; left time: 546.8758s\n",
      "\titers: 200, epoch: 28 | loss: 0.0631211\n",
      "\tspeed: 0.0158s/iter; left time: 257.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0649112 Vali Loss: 0.0611055 Test Loss: 0.0628059\n",
      "Validation loss decreased (0.061229 --> 0.061105).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0670574\n",
      "\tspeed: 0.0305s/iter; left time: 493.6834s\n",
      "\titers: 200, epoch: 29 | loss: 0.0646305\n",
      "\tspeed: 0.0146s/iter; left time: 235.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0650379 Vali Loss: 0.0611235 Test Loss: 0.0630979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0619116\n",
      "\tspeed: 0.0338s/iter; left time: 538.7668s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688088\n",
      "\tspeed: 0.0150s/iter; left time: 238.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0646989 Vali Loss: 0.0609421 Test Loss: 0.0627098\n",
      "Validation loss decreased (0.061105 --> 0.060942).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0645512\n",
      "\tspeed: 0.0343s/iter; left time: 538.8844s\n",
      "\titers: 200, epoch: 31 | loss: 0.0659291\n",
      "\tspeed: 0.0169s/iter; left time: 264.6613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0646035 Vali Loss: 0.0611472 Test Loss: 0.0629095\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0626861\n",
      "\tspeed: 0.0310s/iter; left time: 480.4085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652184\n",
      "\tspeed: 0.0148s/iter; left time: 228.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0646430 Vali Loss: 0.0610199 Test Loss: 0.0626497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0652788\n",
      "\tspeed: 0.0337s/iter; left time: 515.2608s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659325\n",
      "\tspeed: 0.0170s/iter; left time: 258.5736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0645845 Vali Loss: 0.0608501 Test Loss: 0.0625451\n",
      "Validation loss decreased (0.060942 --> 0.060850).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0590962\n",
      "\tspeed: 0.0343s/iter; left time: 516.5190s\n",
      "\titers: 200, epoch: 34 | loss: 0.0679324\n",
      "\tspeed: 0.0169s/iter; left time: 252.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0644537 Vali Loss: 0.0607062 Test Loss: 0.0626173\n",
      "Validation loss decreased (0.060850 --> 0.060706).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0630025\n",
      "\tspeed: 0.0310s/iter; left time: 459.5427s\n",
      "\titers: 200, epoch: 35 | loss: 0.0656969\n",
      "\tspeed: 0.0151s/iter; left time: 222.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0646521 Vali Loss: 0.0611565 Test Loss: 0.0627958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0650596\n",
      "\tspeed: 0.0318s/iter; left time: 464.0778s\n",
      "\titers: 200, epoch: 36 | loss: 0.0631918\n",
      "\tspeed: 0.0149s/iter; left time: 215.4710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0644221 Vali Loss: 0.0606643 Test Loss: 0.0624270\n",
      "Validation loss decreased (0.060706 --> 0.060664).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0654559\n",
      "\tspeed: 0.0299s/iter; left time: 428.9926s\n",
      "\titers: 200, epoch: 37 | loss: 0.0641655\n",
      "\tspeed: 0.0167s/iter; left time: 238.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0645150 Vali Loss: 0.0606552 Test Loss: 0.0625015\n",
      "Validation loss decreased (0.060664 --> 0.060655).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0633260\n",
      "\tspeed: 0.0335s/iter; left time: 474.2394s\n",
      "\titers: 200, epoch: 38 | loss: 0.0695505\n",
      "\tspeed: 0.0184s/iter; left time: 258.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0642804 Vali Loss: 0.0609270 Test Loss: 0.0626896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0642076\n",
      "\tspeed: 0.0321s/iter; left time: 446.0454s\n",
      "\titers: 200, epoch: 39 | loss: 0.0640506\n",
      "\tspeed: 0.0174s/iter; left time: 240.2730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0643265 Vali Loss: 0.0606977 Test Loss: 0.0624603\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0686188\n",
      "\tspeed: 0.0296s/iter; left time: 405.5487s\n",
      "\titers: 200, epoch: 40 | loss: 0.0625081\n",
      "\tspeed: 0.0149s/iter; left time: 202.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0643408 Vali Loss: 0.0604858 Test Loss: 0.0624120\n",
      "Validation loss decreased (0.060655 --> 0.060486).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0631014\n",
      "\tspeed: 0.0331s/iter; left time: 445.7334s\n",
      "\titers: 200, epoch: 41 | loss: 0.0699809\n",
      "\tspeed: 0.0178s/iter; left time: 238.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0642466 Vali Loss: 0.0605204 Test Loss: 0.0623931\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0619243\n",
      "\tspeed: 0.0333s/iter; left time: 440.4574s\n",
      "\titers: 200, epoch: 42 | loss: 0.0649035\n",
      "\tspeed: 0.0179s/iter; left time: 235.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0641566 Vali Loss: 0.0607848 Test Loss: 0.0625766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0657198\n",
      "\tspeed: 0.0302s/iter; left time: 392.5188s\n",
      "\titers: 200, epoch: 43 | loss: 0.0621232\n",
      "\tspeed: 0.0179s/iter; left time: 231.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0642341 Vali Loss: 0.0605430 Test Loss: 0.0624739\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0633814\n",
      "\tspeed: 0.0295s/iter; left time: 376.8730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0651713\n",
      "\tspeed: 0.0123s/iter; left time: 155.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0641601 Vali Loss: 0.0609071 Test Loss: 0.0626294\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0628465\n",
      "\tspeed: 0.0325s/iter; left time: 408.2180s\n",
      "\titers: 200, epoch: 45 | loss: 0.0660572\n",
      "\tspeed: 0.0155s/iter; left time: 193.5537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0642404 Vali Loss: 0.0605895 Test Loss: 0.0625237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0685697\n",
      "\tspeed: 0.0339s/iter; left time: 417.8552s\n",
      "\titers: 200, epoch: 46 | loss: 0.0621873\n",
      "\tspeed: 0.0200s/iter; left time: 244.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0642729 Vali Loss: 0.0607251 Test Loss: 0.0624833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0646147\n",
      "\tspeed: 0.0326s/iter; left time: 394.6524s\n",
      "\titers: 200, epoch: 47 | loss: 0.0673378\n",
      "\tspeed: 0.0150s/iter; left time: 180.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0641940 Vali Loss: 0.0605492 Test Loss: 0.0623635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0633266\n",
      "\tspeed: 0.0336s/iter; left time: 398.8785s\n",
      "\titers: 200, epoch: 48 | loss: 0.0628880\n",
      "\tspeed: 0.0198s/iter; left time: 233.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0640995 Vali Loss: 0.0604947 Test Loss: 0.0624149\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0641017\n",
      "\tspeed: 0.0326s/iter; left time: 380.2014s\n",
      "\titers: 200, epoch: 49 | loss: 0.0668483\n",
      "\tspeed: 0.0159s/iter; left time: 184.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0640413 Vali Loss: 0.0605283 Test Loss: 0.0623423\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0645802\n",
      "\tspeed: 0.0312s/iter; left time: 356.0131s\n",
      "\titers: 200, epoch: 50 | loss: 0.0681049\n",
      "\tspeed: 0.0168s/iter; left time: 190.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0640587 Vali Loss: 0.0605727 Test Loss: 0.0623666\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010827051475644112, rmse:0.10405311733484268, mae:0.06241200491786003, rse:0.3931654989719391\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2683806\n",
      "\tspeed: 0.0178s/iter; left time: 400.4553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2500031\n",
      "\tspeed: 0.0164s/iter; left time: 367.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.2719273 Vali Loss: 0.1840928 Test Loss: 0.1898444\n",
      "Validation loss decreased (inf --> 0.184093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1473255\n",
      "\tspeed: 0.0356s/iter; left time: 792.3217s\n",
      "\titers: 200, epoch: 2 | loss: 0.1141868\n",
      "\tspeed: 0.0174s/iter; left time: 384.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.1519194 Vali Loss: 0.0927569 Test Loss: 0.0932253\n",
      "Validation loss decreased (0.184093 --> 0.092757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1015654\n",
      "\tspeed: 0.0336s/iter; left time: 740.5653s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946531\n",
      "\tspeed: 0.0158s/iter; left time: 346.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.1000551 Vali Loss: 0.0842878 Test Loss: 0.0861395\n",
      "Validation loss decreased (0.092757 --> 0.084288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961696\n",
      "\tspeed: 0.0309s/iter; left time: 674.1843s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867536\n",
      "\tspeed: 0.0171s/iter; left time: 370.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0895216 Vali Loss: 0.0783139 Test Loss: 0.0783058\n",
      "Validation loss decreased (0.084288 --> 0.078314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827323\n",
      "\tspeed: 0.0310s/iter; left time: 668.8156s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823020\n",
      "\tspeed: 0.0154s/iter; left time: 331.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0828466 Vali Loss: 0.0737580 Test Loss: 0.0737559\n",
      "Validation loss decreased (0.078314 --> 0.073758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794151\n",
      "\tspeed: 0.0367s/iter; left time: 784.5256s\n",
      "\titers: 200, epoch: 6 | loss: 0.0737667\n",
      "\tspeed: 0.0182s/iter; left time: 387.3200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0783047 Vali Loss: 0.0704807 Test Loss: 0.0705242\n",
      "Validation loss decreased (0.073758 --> 0.070481).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0736217\n",
      "\tspeed: 0.0343s/iter; left time: 724.3221s\n",
      "\titers: 200, epoch: 7 | loss: 0.0697554\n",
      "\tspeed: 0.0153s/iter; left time: 322.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0753732 Vali Loss: 0.0690016 Test Loss: 0.0695043\n",
      "Validation loss decreased (0.070481 --> 0.069002).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740855\n",
      "\tspeed: 0.0339s/iter; left time: 709.4961s\n",
      "\titers: 200, epoch: 8 | loss: 0.0729932\n",
      "\tspeed: 0.0167s/iter; left time: 346.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0735638 Vali Loss: 0.0673765 Test Loss: 0.0681725\n",
      "Validation loss decreased (0.069002 --> 0.067376).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0741466\n",
      "\tspeed: 0.0252s/iter; left time: 521.6940s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699058\n",
      "\tspeed: 0.0153s/iter; left time: 315.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0719995 Vali Loss: 0.0672796 Test Loss: 0.0680970\n",
      "Validation loss decreased (0.067376 --> 0.067280).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0702154\n",
      "\tspeed: 0.0325s/iter; left time: 666.1266s\n",
      "\titers: 200, epoch: 10 | loss: 0.0715199\n",
      "\tspeed: 0.0154s/iter; left time: 313.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0706106 Vali Loss: 0.0660015 Test Loss: 0.0670486\n",
      "Validation loss decreased (0.067280 --> 0.066002).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0648683\n",
      "\tspeed: 0.0315s/iter; left time: 638.2128s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669258\n",
      "\tspeed: 0.0169s/iter; left time: 340.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0697243 Vali Loss: 0.0652760 Test Loss: 0.0661902\n",
      "Validation loss decreased (0.066002 --> 0.065276).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712571\n",
      "\tspeed: 0.0314s/iter; left time: 628.3819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0662717\n",
      "\tspeed: 0.0174s/iter; left time: 347.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0687956 Vali Loss: 0.0644891 Test Loss: 0.0659832\n",
      "Validation loss decreased (0.065276 --> 0.064489).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688350\n",
      "\tspeed: 0.0304s/iter; left time: 600.7452s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723955\n",
      "\tspeed: 0.0167s/iter; left time: 328.7659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0682971 Vali Loss: 0.0655814 Test Loss: 0.0672650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0626216\n",
      "\tspeed: 0.0333s/iter; left time: 652.0142s\n",
      "\titers: 200, epoch: 14 | loss: 0.0653330\n",
      "\tspeed: 0.0181s/iter; left time: 352.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0676314 Vali Loss: 0.0636220 Test Loss: 0.0650536\n",
      "Validation loss decreased (0.064489 --> 0.063622).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0657042\n",
      "\tspeed: 0.0338s/iter; left time: 653.5294s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669574\n",
      "\tspeed: 0.0179s/iter; left time: 344.2830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0668961 Vali Loss: 0.0634391 Test Loss: 0.0649784\n",
      "Validation loss decreased (0.063622 --> 0.063439).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0697312\n",
      "\tspeed: 0.0331s/iter; left time: 632.9849s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630022\n",
      "\tspeed: 0.0177s/iter; left time: 336.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0664600 Vali Loss: 0.0630070 Test Loss: 0.0646449\n",
      "Validation loss decreased (0.063439 --> 0.063007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0637233\n",
      "\tspeed: 0.0476s/iter; left time: 898.0290s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637252\n",
      "\tspeed: 0.0154s/iter; left time: 288.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0659325 Vali Loss: 0.0624811 Test Loss: 0.0643669\n",
      "Validation loss decreased (0.063007 --> 0.062481).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649766\n",
      "\tspeed: 0.0334s/iter; left time: 623.6352s\n",
      "\titers: 200, epoch: 18 | loss: 0.0627688\n",
      "\tspeed: 0.0136s/iter; left time: 252.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0658954 Vali Loss: 0.0630394 Test Loss: 0.0648154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0659889\n",
      "\tspeed: 0.0314s/iter; left time: 578.7307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0662282\n",
      "\tspeed: 0.0148s/iter; left time: 270.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.0656105 Vali Loss: 0.0625913 Test Loss: 0.0644748\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0655865\n",
      "\tspeed: 0.0341s/iter; left time: 620.8576s\n",
      "\titers: 200, epoch: 20 | loss: 0.0657419\n",
      "\tspeed: 0.0164s/iter; left time: 297.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 226 | Train Loss: 0.0654036 Vali Loss: 0.0621260 Test Loss: 0.0637845\n",
      "Validation loss decreased (0.062481 --> 0.062126).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0695874\n",
      "\tspeed: 0.0327s/iter; left time: 588.7165s\n",
      "\titers: 200, epoch: 21 | loss: 0.0634244\n",
      "\tspeed: 0.0166s/iter; left time: 297.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0651018 Vali Loss: 0.0619380 Test Loss: 0.0638644\n",
      "Validation loss decreased (0.062126 --> 0.061938).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0650325\n",
      "\tspeed: 0.0307s/iter; left time: 544.6062s\n",
      "\titers: 200, epoch: 22 | loss: 0.0630519\n",
      "\tspeed: 0.0155s/iter; left time: 273.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0649287 Vali Loss: 0.0616359 Test Loss: 0.0637903\n",
      "Validation loss decreased (0.061938 --> 0.061636).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0641462\n",
      "\tspeed: 0.0308s/iter; left time: 540.1850s\n",
      "\titers: 200, epoch: 23 | loss: 0.0719948\n",
      "\tspeed: 0.0153s/iter; left time: 267.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0647936 Vali Loss: 0.0615581 Test Loss: 0.0639146\n",
      "Validation loss decreased (0.061636 --> 0.061558).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0681741\n",
      "\tspeed: 0.0327s/iter; left time: 565.9736s\n",
      "\titers: 200, epoch: 24 | loss: 0.0643590\n",
      "\tspeed: 0.0150s/iter; left time: 258.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0646900 Vali Loss: 0.0612422 Test Loss: 0.0634298\n",
      "Validation loss decreased (0.061558 --> 0.061242).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0616931\n",
      "\tspeed: 0.0308s/iter; left time: 526.0258s\n",
      "\titers: 200, epoch: 25 | loss: 0.0661258\n",
      "\tspeed: 0.0150s/iter; left time: 254.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0644749 Vali Loss: 0.0617726 Test Loss: 0.0638768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671707\n",
      "\tspeed: 0.0298s/iter; left time: 502.4363s\n",
      "\titers: 200, epoch: 26 | loss: 0.0633176\n",
      "\tspeed: 0.0190s/iter; left time: 317.6319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0642615 Vali Loss: 0.0610944 Test Loss: 0.0634198\n",
      "Validation loss decreased (0.061242 --> 0.061094).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0674960\n",
      "\tspeed: 0.0355s/iter; left time: 589.5168s\n",
      "\titers: 200, epoch: 27 | loss: 0.0583401\n",
      "\tspeed: 0.0184s/iter; left time: 303.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0641232 Vali Loss: 0.0611686 Test Loss: 0.0632927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650903\n",
      "\tspeed: 0.0305s/iter; left time: 500.4951s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644257\n",
      "\tspeed: 0.0156s/iter; left time: 254.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0643254 Vali Loss: 0.0615976 Test Loss: 0.0636764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0650363\n",
      "\tspeed: 0.0327s/iter; left time: 528.5208s\n",
      "\titers: 200, epoch: 29 | loss: 0.0612404\n",
      "\tspeed: 0.0150s/iter; left time: 241.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0641005 Vali Loss: 0.0610079 Test Loss: 0.0633634\n",
      "Validation loss decreased (0.061094 --> 0.061008).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0642853\n",
      "\tspeed: 0.0309s/iter; left time: 492.7942s\n",
      "\titers: 200, epoch: 30 | loss: 0.0671432\n",
      "\tspeed: 0.0152s/iter; left time: 241.6337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0640129 Vali Loss: 0.0607666 Test Loss: 0.0629210\n",
      "Validation loss decreased (0.061008 --> 0.060767).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0637396\n",
      "\tspeed: 0.0329s/iter; left time: 516.9158s\n",
      "\titers: 200, epoch: 31 | loss: 0.0668434\n",
      "\tspeed: 0.0153s/iter; left time: 238.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0639195 Vali Loss: 0.0608141 Test Loss: 0.0631239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0630049\n",
      "\tspeed: 0.0327s/iter; left time: 507.3852s\n",
      "\titers: 200, epoch: 32 | loss: 0.0637505\n",
      "\tspeed: 0.0148s/iter; left time: 227.1868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0638752 Vali Loss: 0.0608141 Test Loss: 0.0631300\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0624260\n",
      "\tspeed: 0.0329s/iter; left time: 503.0974s\n",
      "\titers: 200, epoch: 33 | loss: 0.0629199\n",
      "\tspeed: 0.0171s/iter; left time: 259.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0637798 Vali Loss: 0.0608580 Test Loss: 0.0632233\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0678928\n",
      "\tspeed: 0.0304s/iter; left time: 457.5547s\n",
      "\titers: 200, epoch: 34 | loss: 0.0654967\n",
      "\tspeed: 0.0183s/iter; left time: 273.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0635867 Vali Loss: 0.0606437 Test Loss: 0.0629190\n",
      "Validation loss decreased (0.060767 --> 0.060644).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0626763\n",
      "\tspeed: 0.0327s/iter; left time: 484.0725s\n",
      "\titers: 200, epoch: 35 | loss: 0.0595072\n",
      "\tspeed: 0.0097s/iter; left time: 142.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0636496 Vali Loss: 0.0607713 Test Loss: 0.0630210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0632355\n",
      "\tspeed: 0.0310s/iter; left time: 452.4127s\n",
      "\titers: 200, epoch: 36 | loss: 0.0626784\n",
      "\tspeed: 0.0165s/iter; left time: 239.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0635934 Vali Loss: 0.0607727 Test Loss: 0.0631237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0646072\n",
      "\tspeed: 0.0299s/iter; left time: 429.9258s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619449\n",
      "\tspeed: 0.0146s/iter; left time: 208.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0637344 Vali Loss: 0.0604826 Test Loss: 0.0628754\n",
      "Validation loss decreased (0.060644 --> 0.060483).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0628808\n",
      "\tspeed: 0.0353s/iter; left time: 498.5920s\n",
      "\titers: 200, epoch: 38 | loss: 0.0625452\n",
      "\tspeed: 0.0173s/iter; left time: 243.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0635299 Vali Loss: 0.0607594 Test Loss: 0.0630251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0618605\n",
      "\tspeed: 0.0328s/iter; left time: 456.1279s\n",
      "\titers: 200, epoch: 39 | loss: 0.0630019\n",
      "\tspeed: 0.0151s/iter; left time: 209.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0635054 Vali Loss: 0.0604440 Test Loss: 0.0628059\n",
      "Validation loss decreased (0.060483 --> 0.060444).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0633831\n",
      "\tspeed: 0.0341s/iter; left time: 467.0752s\n",
      "\titers: 200, epoch: 40 | loss: 0.0619897\n",
      "\tspeed: 0.0166s/iter; left time: 226.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0633871 Vali Loss: 0.0604068 Test Loss: 0.0627636\n",
      "Validation loss decreased (0.060444 --> 0.060407).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0637393\n",
      "\tspeed: 0.0338s/iter; left time: 455.1581s\n",
      "\titers: 200, epoch: 41 | loss: 0.0667270\n",
      "\tspeed: 0.0151s/iter; left time: 202.2399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0634874 Vali Loss: 0.0605568 Test Loss: 0.0628070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0642112\n",
      "\tspeed: 0.0318s/iter; left time: 421.1110s\n",
      "\titers: 200, epoch: 42 | loss: 0.0642818\n",
      "\tspeed: 0.0169s/iter; left time: 221.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0634600 Vali Loss: 0.0604853 Test Loss: 0.0628637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0662356\n",
      "\tspeed: 0.0292s/iter; left time: 380.4633s\n",
      "\titers: 200, epoch: 43 | loss: 0.0618695\n",
      "\tspeed: 0.0121s/iter; left time: 155.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 226 | Train Loss: 0.0635914 Vali Loss: 0.0605979 Test Loss: 0.0628928\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0643022\n",
      "\tspeed: 0.0287s/iter; left time: 366.8359s\n",
      "\titers: 200, epoch: 44 | loss: 0.0604591\n",
      "\tspeed: 0.0145s/iter; left time: 183.5275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0634527 Vali Loss: 0.0604677 Test Loss: 0.0628158\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0598588\n",
      "\tspeed: 0.0316s/iter; left time: 397.3438s\n",
      "\titers: 200, epoch: 45 | loss: 0.0621295\n",
      "\tspeed: 0.0166s/iter; left time: 206.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0632411 Vali Loss: 0.0605021 Test Loss: 0.0628431\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609445\n",
      "\tspeed: 0.0321s/iter; left time: 395.3985s\n",
      "\titers: 200, epoch: 46 | loss: 0.0611818\n",
      "\tspeed: 0.0165s/iter; left time: 202.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0634811 Vali Loss: 0.0604158 Test Loss: 0.0629384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0620083\n",
      "\tspeed: 0.0314s/iter; left time: 380.1078s\n",
      "\titers: 200, epoch: 47 | loss: 0.0650088\n",
      "\tspeed: 0.0151s/iter; left time: 180.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0632877 Vali Loss: 0.0604093 Test Loss: 0.0628394\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0626589\n",
      "\tspeed: 0.0335s/iter; left time: 397.7635s\n",
      "\titers: 200, epoch: 48 | loss: 0.0617674\n",
      "\tspeed: 0.0155s/iter; left time: 182.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0634256 Vali Loss: 0.0605984 Test Loss: 0.0629385\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0801785\n",
      "\tspeed: 0.0339s/iter; left time: 395.3750s\n",
      "\titers: 200, epoch: 49 | loss: 0.0644043\n",
      "\tspeed: 0.0182s/iter; left time: 210.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0633992 Vali Loss: 0.0605179 Test Loss: 0.0629123\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0656605\n",
      "\tspeed: 0.0339s/iter; left time: 387.2193s\n",
      "\titers: 200, epoch: 50 | loss: 0.0648636\n",
      "\tspeed: 0.0154s/iter; left time: 174.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0633635 Vali Loss: 0.0603140 Test Loss: 0.0628248\n",
      "Validation loss decreased (0.060407 --> 0.060314).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0649489\n",
      "\tspeed: 0.0326s/iter; left time: 365.2338s\n",
      "\titers: 200, epoch: 51 | loss: 0.0648584\n",
      "\tspeed: 0.0186s/iter; left time: 206.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0633087 Vali Loss: 0.0604656 Test Loss: 0.0627679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0614670\n",
      "\tspeed: 0.0305s/iter; left time: 334.5138s\n",
      "\titers: 200, epoch: 52 | loss: 0.0604024\n",
      "\tspeed: 0.0191s/iter; left time: 208.1896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0634348 Vali Loss: 0.0603848 Test Loss: 0.0627892\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597789\n",
      "\tspeed: 0.0318s/iter; left time: 342.0200s\n",
      "\titers: 200, epoch: 53 | loss: 0.0624102\n",
      "\tspeed: 0.0164s/iter; left time: 175.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0632580 Vali Loss: 0.0603975 Test Loss: 0.0627268\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0661077\n",
      "\tspeed: 0.0301s/iter; left time: 316.5067s\n",
      "\titers: 200, epoch: 54 | loss: 0.0639733\n",
      "\tspeed: 0.0164s/iter; left time: 171.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0633711 Vali Loss: 0.0603307 Test Loss: 0.0627780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0634417\n",
      "\tspeed: 0.0326s/iter; left time: 335.6777s\n",
      "\titers: 200, epoch: 55 | loss: 0.0628030\n",
      "\tspeed: 0.0150s/iter; left time: 153.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0632948 Vali Loss: 0.0603213 Test Loss: 0.0627216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0656375\n",
      "\tspeed: 0.0335s/iter; left time: 337.8010s\n",
      "\titers: 200, epoch: 56 | loss: 0.0626009\n",
      "\tspeed: 0.0169s/iter; left time: 168.4996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0632629 Vali Loss: 0.0602907 Test Loss: 0.0627626\n",
      "Validation loss decreased (0.060314 --> 0.060291).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0606608\n",
      "\tspeed: 0.0341s/iter; left time: 335.6841s\n",
      "\titers: 200, epoch: 57 | loss: 0.0667918\n",
      "\tspeed: 0.0169s/iter; left time: 164.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0632846 Vali Loss: 0.0604346 Test Loss: 0.0628324\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0614186\n",
      "\tspeed: 0.0319s/iter; left time: 306.5196s\n",
      "\titers: 200, epoch: 58 | loss: 0.0616034\n",
      "\tspeed: 0.0177s/iter; left time: 168.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0632635 Vali Loss: 0.0603961 Test Loss: 0.0627379\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0648625\n",
      "\tspeed: 0.0300s/iter; left time: 281.9206s\n",
      "\titers: 200, epoch: 59 | loss: 0.0606599\n",
      "\tspeed: 0.0150s/iter; left time: 139.3519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0632889 Vali Loss: 0.0604271 Test Loss: 0.0627835\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0595693\n",
      "\tspeed: 0.0356s/iter; left time: 325.9394s\n",
      "\titers: 200, epoch: 60 | loss: 0.0608444\n",
      "\tspeed: 0.0207s/iter; left time: 187.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0632423 Vali Loss: 0.0604059 Test Loss: 0.0627771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0611959\n",
      "\tspeed: 0.0372s/iter; left time: 332.8292s\n",
      "\titers: 200, epoch: 61 | loss: 0.0614771\n",
      "\tspeed: 0.0206s/iter; left time: 182.0880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 226 | Train Loss: 0.0633894 Vali Loss: 0.0603203 Test Loss: 0.0627730\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0627258\n",
      "\tspeed: 0.0374s/iter; left time: 325.8472s\n",
      "\titers: 200, epoch: 62 | loss: 0.0658270\n",
      "\tspeed: 0.0177s/iter; left time: 152.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0631786 Vali Loss: 0.0603669 Test Loss: 0.0628356\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0643718\n",
      "\tspeed: 0.0334s/iter; left time: 283.9527s\n",
      "\titers: 200, epoch: 63 | loss: 0.0651433\n",
      "\tspeed: 0.0153s/iter; left time: 128.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0633000 Vali Loss: 0.0603122 Test Loss: 0.0626970\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0600079\n",
      "\tspeed: 0.0272s/iter; left time: 224.9807s\n",
      "\titers: 200, epoch: 64 | loss: 0.0663806\n",
      "\tspeed: 0.0208s/iter; left time: 169.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0631326 Vali Loss: 0.0603702 Test Loss: 0.0627292\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0659940\n",
      "\tspeed: 0.0382s/iter; left time: 306.6183s\n",
      "\titers: 200, epoch: 65 | loss: 0.0599802\n",
      "\tspeed: 0.0227s/iter; left time: 180.2711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 226 | Train Loss: 0.0632878 Vali Loss: 0.0603091 Test Loss: 0.0626982\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0627154\n",
      "\tspeed: 0.0364s/iter; left time: 284.1278s\n",
      "\titers: 200, epoch: 66 | loss: 0.0643168\n",
      "\tspeed: 0.0162s/iter; left time: 124.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0632404 Vali Loss: 0.0603718 Test Loss: 0.0627312\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010896671563386917, rmse:0.10438712686300278, mae:0.06276259571313858, rse:0.3944275379180908\n",
      "Intermediate time for IT and pred_len 24: 00h:09m:39.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2777186\n",
      "\tspeed: 0.0429s/iter; left time: 961.0489s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569139\n",
      "\tspeed: 0.0150s/iter; left time: 335.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.2819139 Vali Loss: 0.1959135 Test Loss: 0.2025781\n",
      "Validation loss decreased (inf --> 0.195914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503462\n",
      "\tspeed: 0.0330s/iter; left time: 731.6456s\n",
      "\titers: 200, epoch: 2 | loss: 0.1258866\n",
      "\tspeed: 0.0166s/iter; left time: 367.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.1587552 Vali Loss: 0.1118642 Test Loss: 0.1198275\n",
      "Validation loss decreased (0.195914 --> 0.111864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1137129\n",
      "\tspeed: 0.0332s/iter; left time: 729.7910s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097044\n",
      "\tspeed: 0.0152s/iter; left time: 331.1760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1154826 Vali Loss: 0.1006880 Test Loss: 0.1063467\n",
      "Validation loss decreased (0.111864 --> 0.100688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1010056\n",
      "\tspeed: 0.0342s/iter; left time: 742.1826s\n",
      "\titers: 200, epoch: 4 | loss: 0.1015733\n",
      "\tspeed: 0.0171s/iter; left time: 368.8469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1046104 Vali Loss: 0.0929637 Test Loss: 0.0947932\n",
      "Validation loss decreased (0.100688 --> 0.092964).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931383\n",
      "\tspeed: 0.0321s/iter; left time: 690.8377s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927026\n",
      "\tspeed: 0.0128s/iter; left time: 274.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0980567 Vali Loss: 0.0881273 Test Loss: 0.0907078\n",
      "Validation loss decreased (0.092964 --> 0.088127).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0922307\n",
      "\tspeed: 0.0324s/iter; left time: 688.9151s\n",
      "\titers: 200, epoch: 6 | loss: 0.0929584\n",
      "\tspeed: 0.0150s/iter; left time: 318.6271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0937415 Vali Loss: 0.0870895 Test Loss: 0.0893921\n",
      "Validation loss decreased (0.088127 --> 0.087090).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876376\n",
      "\tspeed: 0.0304s/iter; left time: 640.8364s\n",
      "\titers: 200, epoch: 7 | loss: 0.0913200\n",
      "\tspeed: 0.0152s/iter; left time: 319.4856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0917897 Vali Loss: 0.0873184 Test Loss: 0.0884443\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0914330\n",
      "\tspeed: 0.0311s/iter; left time: 647.4304s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905815\n",
      "\tspeed: 0.0135s/iter; left time: 280.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0901037 Vali Loss: 0.0847947 Test Loss: 0.0869199\n",
      "Validation loss decreased (0.087090 --> 0.084795).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0856609\n",
      "\tspeed: 0.0312s/iter; left time: 642.2962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0856232\n",
      "\tspeed: 0.0148s/iter; left time: 304.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0886598 Vali Loss: 0.0832606 Test Loss: 0.0864825\n",
      "Validation loss decreased (0.084795 --> 0.083261).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0846817\n",
      "\tspeed: 0.0336s/iter; left time: 684.0704s\n",
      "\titers: 200, epoch: 10 | loss: 0.0886836\n",
      "\tspeed: 0.0174s/iter; left time: 353.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0876424 Vali Loss: 0.0821826 Test Loss: 0.0856964\n",
      "Validation loss decreased (0.083261 --> 0.082183).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854393\n",
      "\tspeed: 0.0325s/iter; left time: 653.9121s\n",
      "\titers: 200, epoch: 11 | loss: 0.0864105\n",
      "\tspeed: 0.0167s/iter; left time: 333.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0867340 Vali Loss: 0.0822964 Test Loss: 0.0857694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0855199\n",
      "\tspeed: 0.0344s/iter; left time: 685.3361s\n",
      "\titers: 200, epoch: 12 | loss: 0.0839509\n",
      "\tspeed: 0.0159s/iter; left time: 314.3120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0861404 Vali Loss: 0.0814085 Test Loss: 0.0855265\n",
      "Validation loss decreased (0.082183 --> 0.081408).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0868975\n",
      "\tspeed: 0.0349s/iter; left time: 688.2557s\n",
      "\titers: 200, epoch: 13 | loss: 0.0869677\n",
      "\tspeed: 0.0173s/iter; left time: 338.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0854552 Vali Loss: 0.0811413 Test Loss: 0.0852011\n",
      "Validation loss decreased (0.081408 --> 0.081141).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0895584\n",
      "\tspeed: 0.0358s/iter; left time: 697.4273s\n",
      "\titers: 200, epoch: 14 | loss: 0.0863725\n",
      "\tspeed: 0.0185s/iter; left time: 358.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0850139 Vali Loss: 0.0810665 Test Loss: 0.0850852\n",
      "Validation loss decreased (0.081141 --> 0.081066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0829848\n",
      "\tspeed: 0.0370s/iter; left time: 711.9327s\n",
      "\titers: 200, epoch: 15 | loss: 0.0862410\n",
      "\tspeed: 0.0177s/iter; left time: 339.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0848629 Vali Loss: 0.0807258 Test Loss: 0.0846477\n",
      "Validation loss decreased (0.081066 --> 0.080726).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0863633\n",
      "\tspeed: 0.0348s/iter; left time: 661.3818s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844380\n",
      "\tspeed: 0.0158s/iter; left time: 299.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0842551 Vali Loss: 0.0807420 Test Loss: 0.0847929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0799475\n",
      "\tspeed: 0.0352s/iter; left time: 661.7758s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838205\n",
      "\tspeed: 0.0180s/iter; left time: 337.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0838634 Vali Loss: 0.0803780 Test Loss: 0.0846857\n",
      "Validation loss decreased (0.080726 --> 0.080378).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0869446\n",
      "\tspeed: 0.0341s/iter; left time: 633.0774s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812265\n",
      "\tspeed: 0.0150s/iter; left time: 276.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0837593 Vali Loss: 0.0805071 Test Loss: 0.0846009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0842634\n",
      "\tspeed: 0.0311s/iter; left time: 570.3352s\n",
      "\titers: 200, epoch: 19 | loss: 0.0814005\n",
      "\tspeed: 0.0149s/iter; left time: 272.7924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0835424 Vali Loss: 0.0801593 Test Loss: 0.0845342\n",
      "Validation loss decreased (0.080378 --> 0.080159).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0785947\n",
      "\tspeed: 0.0302s/iter; left time: 546.5463s\n",
      "\titers: 200, epoch: 20 | loss: 0.0831343\n",
      "\tspeed: 0.0098s/iter; left time: 176.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0830553 Vali Loss: 0.0797146 Test Loss: 0.0843138\n",
      "Validation loss decreased (0.080159 --> 0.079715).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0833767\n",
      "\tspeed: 0.0305s/iter; left time: 545.3059s\n",
      "\titers: 200, epoch: 21 | loss: 0.0770623\n",
      "\tspeed: 0.0164s/iter; left time: 291.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0830372 Vali Loss: 0.0799927 Test Loss: 0.0844230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0853504\n",
      "\tspeed: 0.0342s/iter; left time: 605.1978s\n",
      "\titers: 200, epoch: 22 | loss: 0.0816715\n",
      "\tspeed: 0.0197s/iter; left time: 345.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0829589 Vali Loss: 0.0797679 Test Loss: 0.0844153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0850140\n",
      "\tspeed: 0.0351s/iter; left time: 612.2322s\n",
      "\titers: 200, epoch: 23 | loss: 0.0841234\n",
      "\tspeed: 0.0171s/iter; left time: 296.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0828476 Vali Loss: 0.0798274 Test Loss: 0.0842461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0811909\n",
      "\tspeed: 0.0340s/iter; left time: 586.3451s\n",
      "\titers: 200, epoch: 24 | loss: 0.0802586\n",
      "\tspeed: 0.0180s/iter; left time: 307.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0826429 Vali Loss: 0.0795573 Test Loss: 0.0841798\n",
      "Validation loss decreased (0.079715 --> 0.079557).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0818036\n",
      "\tspeed: 0.0345s/iter; left time: 587.3012s\n",
      "\titers: 200, epoch: 25 | loss: 0.0837724\n",
      "\tspeed: 0.0170s/iter; left time: 286.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0825855 Vali Loss: 0.0795854 Test Loss: 0.0841127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0862241\n",
      "\tspeed: 0.0333s/iter; left time: 558.4197s\n",
      "\titers: 200, epoch: 26 | loss: 0.0794363\n",
      "\tspeed: 0.0175s/iter; left time: 291.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0824944 Vali Loss: 0.0795109 Test Loss: 0.0841575\n",
      "Validation loss decreased (0.079557 --> 0.079511).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0837308\n",
      "\tspeed: 0.0366s/iter; left time: 606.5219s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837827\n",
      "\tspeed: 0.0166s/iter; left time: 272.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0824191 Vali Loss: 0.0793480 Test Loss: 0.0840780\n",
      "Validation loss decreased (0.079511 --> 0.079348).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0826852\n",
      "\tspeed: 0.0324s/iter; left time: 529.1745s\n",
      "\titers: 200, epoch: 28 | loss: 0.0801488\n",
      "\tspeed: 0.0174s/iter; left time: 282.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0824533 Vali Loss: 0.0794025 Test Loss: 0.0841289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0853649\n",
      "\tspeed: 0.0334s/iter; left time: 538.3358s\n",
      "\titers: 200, epoch: 29 | loss: 0.0783699\n",
      "\tspeed: 0.0182s/iter; left time: 290.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0823509 Vali Loss: 0.0792908 Test Loss: 0.0840861\n",
      "Validation loss decreased (0.079348 --> 0.079291).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0823211\n",
      "\tspeed: 0.0327s/iter; left time: 519.9043s\n",
      "\titers: 200, epoch: 30 | loss: 0.0827666\n",
      "\tspeed: 0.0176s/iter; left time: 277.8531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0822907 Vali Loss: 0.0792715 Test Loss: 0.0839312\n",
      "Validation loss decreased (0.079291 --> 0.079272).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808998\n",
      "\tspeed: 0.0325s/iter; left time: 509.1454s\n",
      "\titers: 200, epoch: 31 | loss: 0.0807928\n",
      "\tspeed: 0.0192s/iter; left time: 298.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0821265 Vali Loss: 0.0792237 Test Loss: 0.0839969\n",
      "Validation loss decreased (0.079272 --> 0.079224).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0815765\n",
      "\tspeed: 0.0357s/iter; left time: 550.7602s\n",
      "\titers: 200, epoch: 32 | loss: 0.0843080\n",
      "\tspeed: 0.0174s/iter; left time: 266.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0820431 Vali Loss: 0.0791623 Test Loss: 0.0839657\n",
      "Validation loss decreased (0.079224 --> 0.079162).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0847938\n",
      "\tspeed: 0.0354s/iter; left time: 537.3809s\n",
      "\titers: 200, epoch: 33 | loss: 0.0855501\n",
      "\tspeed: 0.0203s/iter; left time: 307.0463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0820090 Vali Loss: 0.0793583 Test Loss: 0.0840243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0875249\n",
      "\tspeed: 0.0349s/iter; left time: 522.5661s\n",
      "\titers: 200, epoch: 34 | loss: 0.0807978\n",
      "\tspeed: 0.0174s/iter; left time: 258.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0820447 Vali Loss: 0.0791663 Test Loss: 0.0839047\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0820323\n",
      "\tspeed: 0.0336s/iter; left time: 496.1109s\n",
      "\titers: 200, epoch: 35 | loss: 0.0817046\n",
      "\tspeed: 0.0170s/iter; left time: 248.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0820172 Vali Loss: 0.0792771 Test Loss: 0.0839085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0853832\n",
      "\tspeed: 0.0383s/iter; left time: 555.7814s\n",
      "\titers: 200, epoch: 36 | loss: 0.0840510\n",
      "\tspeed: 0.0205s/iter; left time: 295.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0818907 Vali Loss: 0.0792983 Test Loss: 0.0839392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0841038\n",
      "\tspeed: 0.0337s/iter; left time: 481.5279s\n",
      "\titers: 200, epoch: 37 | loss: 0.0768642\n",
      "\tspeed: 0.0155s/iter; left time: 220.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0818594 Vali Loss: 0.0791648 Test Loss: 0.0838817\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0840093\n",
      "\tspeed: 0.0330s/iter; left time: 464.6572s\n",
      "\titers: 200, epoch: 38 | loss: 0.0796729\n",
      "\tspeed: 0.0155s/iter; left time: 217.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0819101 Vali Loss: 0.0791788 Test Loss: 0.0838323\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0785457\n",
      "\tspeed: 0.0331s/iter; left time: 458.1444s\n",
      "\titers: 200, epoch: 39 | loss: 0.0818148\n",
      "\tspeed: 0.0174s/iter; left time: 238.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0817813 Vali Loss: 0.0791711 Test Loss: 0.0839773\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0786763\n",
      "\tspeed: 0.0342s/iter; left time: 465.5255s\n",
      "\titers: 200, epoch: 40 | loss: 0.0864732\n",
      "\tspeed: 0.0170s/iter; left time: 229.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0818996 Vali Loss: 0.0791738 Test Loss: 0.0838895\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0772040\n",
      "\tspeed: 0.0364s/iter; left time: 487.5658s\n",
      "\titers: 200, epoch: 41 | loss: 0.0768942\n",
      "\tspeed: 0.0187s/iter; left time: 248.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0819151 Vali Loss: 0.0793107 Test Loss: 0.0837918\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0828241\n",
      "\tspeed: 0.0319s/iter; left time: 420.5608s\n",
      "\titers: 200, epoch: 42 | loss: 0.0808430\n",
      "\tspeed: 0.0152s/iter; left time: 199.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0817570 Vali Loss: 0.0792095 Test Loss: 0.0838636\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01884772628545761, rmse:0.13728702068328857, mae:0.08396567404270172, rse:0.5190970301628113\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2806228\n",
      "\tspeed: 0.0206s/iter; left time: 461.4312s\n",
      "\titers: 200, epoch: 1 | loss: 0.2607370\n",
      "\tspeed: 0.0164s/iter; left time: 364.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.2831202 Vali Loss: 0.1983966 Test Loss: 0.2050680\n",
      "Validation loss decreased (inf --> 0.198397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462103\n",
      "\tspeed: 0.0340s/iter; left time: 753.8183s\n",
      "\titers: 200, epoch: 2 | loss: 0.1279159\n",
      "\tspeed: 0.0181s/iter; left time: 398.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1583383 Vali Loss: 0.1096080 Test Loss: 0.1172922\n",
      "Validation loss decreased (0.198397 --> 0.109608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1173452\n",
      "\tspeed: 0.0341s/iter; left time: 749.0793s\n",
      "\titers: 200, epoch: 3 | loss: 0.1107076\n",
      "\tspeed: 0.0160s/iter; left time: 348.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.1156612 Vali Loss: 0.0991728 Test Loss: 0.1039855\n",
      "Validation loss decreased (0.109608 --> 0.099173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1042874\n",
      "\tspeed: 0.0383s/iter; left time: 831.3813s\n",
      "\titers: 200, epoch: 4 | loss: 0.1006773\n",
      "\tspeed: 0.0155s/iter; left time: 334.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1042152 Vali Loss: 0.0926457 Test Loss: 0.0946814\n",
      "Validation loss decreased (0.099173 --> 0.092646).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0966639\n",
      "\tspeed: 0.0351s/iter; left time: 755.6407s\n",
      "\titers: 200, epoch: 5 | loss: 0.0967009\n",
      "\tspeed: 0.0197s/iter; left time: 422.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0973508 Vali Loss: 0.0883805 Test Loss: 0.0907344\n",
      "Validation loss decreased (0.092646 --> 0.088380).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990865\n",
      "\tspeed: 0.0327s/iter; left time: 695.9985s\n",
      "\titers: 200, epoch: 6 | loss: 0.0904820\n",
      "\tspeed: 0.0158s/iter; left time: 333.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0936973 Vali Loss: 0.0869135 Test Loss: 0.0890371\n",
      "Validation loss decreased (0.088380 --> 0.086913).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0910847\n",
      "\tspeed: 0.0330s/iter; left time: 694.2954s\n",
      "\titers: 200, epoch: 7 | loss: 0.0939122\n",
      "\tspeed: 0.0163s/iter; left time: 341.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0915057 Vali Loss: 0.0855780 Test Loss: 0.0873110\n",
      "Validation loss decreased (0.086913 --> 0.085578).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0887241\n",
      "\tspeed: 0.0327s/iter; left time: 681.5565s\n",
      "\titers: 200, epoch: 8 | loss: 0.0864781\n",
      "\tspeed: 0.0175s/iter; left time: 362.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0897954 Vali Loss: 0.0844579 Test Loss: 0.0867044\n",
      "Validation loss decreased (0.085578 --> 0.084458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0920255\n",
      "\tspeed: 0.0335s/iter; left time: 691.0493s\n",
      "\titers: 200, epoch: 9 | loss: 0.0843511\n",
      "\tspeed: 0.0175s/iter; left time: 358.8526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0883764 Vali Loss: 0.0829569 Test Loss: 0.0858086\n",
      "Validation loss decreased (0.084458 --> 0.082957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0842601\n",
      "\tspeed: 0.0332s/iter; left time: 675.9181s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844496\n",
      "\tspeed: 0.0149s/iter; left time: 302.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0878313 Vali Loss: 0.0819504 Test Loss: 0.0851816\n",
      "Validation loss decreased (0.082957 --> 0.081950).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0903435\n",
      "\tspeed: 0.0331s/iter; left time: 667.1771s\n",
      "\titers: 200, epoch: 11 | loss: 0.0884159\n",
      "\tspeed: 0.0129s/iter; left time: 258.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0869585 Vali Loss: 0.0821840 Test Loss: 0.0849077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880806\n",
      "\tspeed: 0.0311s/iter; left time: 618.9819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0892761\n",
      "\tspeed: 0.0169s/iter; left time: 335.8036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0861288 Vali Loss: 0.0821766 Test Loss: 0.0846017\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847698\n",
      "\tspeed: 0.0335s/iter; left time: 659.6273s\n",
      "\titers: 200, epoch: 13 | loss: 0.0886499\n",
      "\tspeed: 0.0155s/iter; left time: 303.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0856551 Vali Loss: 0.0813699 Test Loss: 0.0850033\n",
      "Validation loss decreased (0.081950 --> 0.081370).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0837286\n",
      "\tspeed: 0.0344s/iter; left time: 669.7197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0861768\n",
      "\tspeed: 0.0163s/iter; left time: 315.9275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0849992 Vali Loss: 0.0807958 Test Loss: 0.0844888\n",
      "Validation loss decreased (0.081370 --> 0.080796).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842981\n",
      "\tspeed: 0.0323s/iter; left time: 620.8995s\n",
      "\titers: 200, epoch: 15 | loss: 0.0860519\n",
      "\tspeed: 0.0152s/iter; left time: 290.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0846049 Vali Loss: 0.0808427 Test Loss: 0.0845398\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0834388\n",
      "\tspeed: 0.0315s/iter; left time: 599.4554s\n",
      "\titers: 200, epoch: 16 | loss: 0.0891821\n",
      "\tspeed: 0.0158s/iter; left time: 299.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0842148 Vali Loss: 0.0807076 Test Loss: 0.0839392\n",
      "Validation loss decreased (0.080796 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0813520\n",
      "\tspeed: 0.0341s/iter; left time: 640.7734s\n",
      "\titers: 200, epoch: 17 | loss: 0.0820236\n",
      "\tspeed: 0.0158s/iter; left time: 295.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0841889 Vali Loss: 0.0807928 Test Loss: 0.0843021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0794783\n",
      "\tspeed: 0.0315s/iter; left time: 584.3165s\n",
      "\titers: 200, epoch: 18 | loss: 0.0819564\n",
      "\tspeed: 0.0150s/iter; left time: 277.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0837958 Vali Loss: 0.0800502 Test Loss: 0.0839954\n",
      "Validation loss decreased (0.080708 --> 0.080050).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0825035\n",
      "\tspeed: 0.0330s/iter; left time: 604.9470s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834793\n",
      "\tspeed: 0.0156s/iter; left time: 284.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0833411 Vali Loss: 0.0804612 Test Loss: 0.0840887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0849448\n",
      "\tspeed: 0.0320s/iter; left time: 580.4257s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859698\n",
      "\tspeed: 0.0160s/iter; left time: 289.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0833001 Vali Loss: 0.0801358 Test Loss: 0.0839652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0786478\n",
      "\tspeed: 0.0340s/iter; left time: 609.4255s\n",
      "\titers: 200, epoch: 21 | loss: 0.0870727\n",
      "\tspeed: 0.0189s/iter; left time: 336.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0831646 Vali Loss: 0.0799826 Test Loss: 0.0838264\n",
      "Validation loss decreased (0.080050 --> 0.079983).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0886545\n",
      "\tspeed: 0.0376s/iter; left time: 665.4101s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784292\n",
      "\tspeed: 0.0182s/iter; left time: 319.6706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0830313 Vali Loss: 0.0801070 Test Loss: 0.0838581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0820926\n",
      "\tspeed: 0.0332s/iter; left time: 578.8328s\n",
      "\titers: 200, epoch: 23 | loss: 0.0841963\n",
      "\tspeed: 0.0163s/iter; left time: 282.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0829299 Vali Loss: 0.0797106 Test Loss: 0.0837441\n",
      "Validation loss decreased (0.079983 --> 0.079711).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0813720\n",
      "\tspeed: 0.0337s/iter; left time: 580.5527s\n",
      "\titers: 200, epoch: 24 | loss: 0.0823814\n",
      "\tspeed: 0.0178s/iter; left time: 304.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0825387 Vali Loss: 0.0800385 Test Loss: 0.0841180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0840227\n",
      "\tspeed: 0.0329s/iter; left time: 559.7043s\n",
      "\titers: 200, epoch: 25 | loss: 0.0792319\n",
      "\tspeed: 0.0180s/iter; left time: 304.6460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0825908 Vali Loss: 0.0795311 Test Loss: 0.0836701\n",
      "Validation loss decreased (0.079711 --> 0.079531).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0843800\n",
      "\tspeed: 0.0321s/iter; left time: 538.7035s\n",
      "\titers: 200, epoch: 26 | loss: 0.0830451\n",
      "\tspeed: 0.0152s/iter; left time: 253.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0825504 Vali Loss: 0.0797684 Test Loss: 0.0835431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0853239\n",
      "\tspeed: 0.0337s/iter; left time: 557.7382s\n",
      "\titers: 200, epoch: 27 | loss: 0.0819135\n",
      "\tspeed: 0.0178s/iter; left time: 292.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0823064 Vali Loss: 0.0796968 Test Loss: 0.0834956\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0836991\n",
      "\tspeed: 0.0340s/iter; left time: 554.6246s\n",
      "\titers: 200, epoch: 28 | loss: 0.0823716\n",
      "\tspeed: 0.0173s/iter; left time: 281.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0823479 Vali Loss: 0.0795949 Test Loss: 0.0834777\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0901566\n",
      "\tspeed: 0.0337s/iter; left time: 542.6435s\n",
      "\titers: 200, epoch: 29 | loss: 0.0815871\n",
      "\tspeed: 0.0180s/iter; left time: 287.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0822618 Vali Loss: 0.0793890 Test Loss: 0.0835268\n",
      "Validation loss decreased (0.079531 --> 0.079389).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0797134\n",
      "\tspeed: 0.0345s/iter; left time: 548.2422s\n",
      "\titers: 200, epoch: 30 | loss: 0.0839581\n",
      "\tspeed: 0.0160s/iter; left time: 252.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0822651 Vali Loss: 0.0798529 Test Loss: 0.0836726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0784735\n",
      "\tspeed: 0.0332s/iter; left time: 520.2067s\n",
      "\titers: 200, epoch: 31 | loss: 0.0858933\n",
      "\tspeed: 0.0160s/iter; left time: 248.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0821580 Vali Loss: 0.0797668 Test Loss: 0.0835013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0843875\n",
      "\tspeed: 0.0352s/iter; left time: 543.4274s\n",
      "\titers: 200, epoch: 32 | loss: 0.0813760\n",
      "\tspeed: 0.0199s/iter; left time: 304.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0820451 Vali Loss: 0.0796548 Test Loss: 0.0835479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0811357\n",
      "\tspeed: 0.0326s/iter; left time: 495.2098s\n",
      "\titers: 200, epoch: 33 | loss: 0.0862090\n",
      "\tspeed: 0.0151s/iter; left time: 228.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0819303 Vali Loss: 0.0795747 Test Loss: 0.0835437\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0850448\n",
      "\tspeed: 0.0318s/iter; left time: 476.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0820336\n",
      "\tspeed: 0.0162s/iter; left time: 240.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0819054 Vali Loss: 0.0796066 Test Loss: 0.0836889\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0863909\n",
      "\tspeed: 0.0340s/iter; left time: 501.8651s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772811\n",
      "\tspeed: 0.0188s/iter; left time: 275.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0818685 Vali Loss: 0.0795604 Test Loss: 0.0834159\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0811598\n",
      "\tspeed: 0.0343s/iter; left time: 497.7105s\n",
      "\titers: 200, epoch: 36 | loss: 0.0852249\n",
      "\tspeed: 0.0159s/iter; left time: 229.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0818304 Vali Loss: 0.0795000 Test Loss: 0.0835749\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0823470\n",
      "\tspeed: 0.0330s/iter; left time: 471.3904s\n",
      "\titers: 200, epoch: 37 | loss: 0.0786397\n",
      "\tspeed: 0.0129s/iter; left time: 182.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0818090 Vali Loss: 0.0792918 Test Loss: 0.0834800\n",
      "Validation loss decreased (0.079389 --> 0.079292).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813787\n",
      "\tspeed: 0.0305s/iter; left time: 429.1995s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800484\n",
      "\tspeed: 0.0155s/iter; left time: 217.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0817770 Vali Loss: 0.0793174 Test Loss: 0.0834549\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0846778\n",
      "\tspeed: 0.0314s/iter; left time: 434.5278s\n",
      "\titers: 200, epoch: 39 | loss: 0.0876444\n",
      "\tspeed: 0.0143s/iter; left time: 197.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0818475 Vali Loss: 0.0794521 Test Loss: 0.0833526\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0840096\n",
      "\tspeed: 0.0312s/iter; left time: 425.0502s\n",
      "\titers: 200, epoch: 40 | loss: 0.0797139\n",
      "\tspeed: 0.0138s/iter; left time: 186.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0818729 Vali Loss: 0.0792610 Test Loss: 0.0834639\n",
      "Validation loss decreased (0.079292 --> 0.079261).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0809445\n",
      "\tspeed: 0.0320s/iter; left time: 429.4419s\n",
      "\titers: 200, epoch: 41 | loss: 0.0835953\n",
      "\tspeed: 0.0162s/iter; left time: 215.7696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0817603 Vali Loss: 0.0793753 Test Loss: 0.0834233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0818785\n",
      "\tspeed: 0.0299s/iter; left time: 394.2577s\n",
      "\titers: 200, epoch: 42 | loss: 0.0793468\n",
      "\tspeed: 0.0134s/iter; left time: 175.2373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0819900 Vali Loss: 0.0794616 Test Loss: 0.0834463\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1099899\n",
      "\tspeed: 0.0310s/iter; left time: 400.9493s\n",
      "\titers: 200, epoch: 43 | loss: 0.0863156\n",
      "\tspeed: 0.0151s/iter; left time: 193.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0818719 Vali Loss: 0.0794408 Test Loss: 0.0834186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0830130\n",
      "\tspeed: 0.0323s/iter; left time: 411.4115s\n",
      "\titers: 200, epoch: 44 | loss: 0.0839347\n",
      "\tspeed: 0.0165s/iter; left time: 208.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0817068 Vali Loss: 0.0794648 Test Loss: 0.0834181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0816569\n",
      "\tspeed: 0.0345s/iter; left time: 431.1847s\n",
      "\titers: 200, epoch: 45 | loss: 0.0795054\n",
      "\tspeed: 0.0202s/iter; left time: 250.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0817080 Vali Loss: 0.0793059 Test Loss: 0.0834380\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0873833\n",
      "\tspeed: 0.0390s/iter; left time: 479.1947s\n",
      "\titers: 200, epoch: 46 | loss: 0.0815155\n",
      "\tspeed: 0.0204s/iter; left time: 247.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0816783 Vali Loss: 0.0794770 Test Loss: 0.0834538\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0832890\n",
      "\tspeed: 0.0357s/iter; left time: 429.6640s\n",
      "\titers: 200, epoch: 47 | loss: 0.0856036\n",
      "\tspeed: 0.0253s/iter; left time: 302.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0817624 Vali Loss: 0.0793323 Test Loss: 0.0834635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0817167\n",
      "\tspeed: 0.0403s/iter; left time: 476.9329s\n",
      "\titers: 200, epoch: 48 | loss: 0.0815217\n",
      "\tspeed: 0.0191s/iter; left time: 223.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0818865 Vali Loss: 0.0792611 Test Loss: 0.0835811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0825997\n",
      "\tspeed: 0.0336s/iter; left time: 389.4293s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801011\n",
      "\tspeed: 0.0181s/iter; left time: 208.5030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0816532 Vali Loss: 0.0792115 Test Loss: 0.0833805\n",
      "Validation loss decreased (0.079261 --> 0.079212).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0815825\n",
      "\tspeed: 0.0373s/iter; left time: 424.2101s\n",
      "\titers: 200, epoch: 50 | loss: 0.0805301\n",
      "\tspeed: 0.0222s/iter; left time: 250.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0819056 Vali Loss: 0.0794098 Test Loss: 0.0833791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0823547\n",
      "\tspeed: 0.0388s/iter; left time: 432.2377s\n",
      "\titers: 200, epoch: 51 | loss: 0.0836692\n",
      "\tspeed: 0.0183s/iter; left time: 202.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0818337 Vali Loss: 0.0793652 Test Loss: 0.0833687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0836443\n",
      "\tspeed: 0.0391s/iter; left time: 426.8916s\n",
      "\titers: 200, epoch: 52 | loss: 0.0822562\n",
      "\tspeed: 0.0214s/iter; left time: 232.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0817083 Vali Loss: 0.0794672 Test Loss: 0.0835472\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0861320\n",
      "\tspeed: 0.0332s/iter; left time: 355.3428s\n",
      "\titers: 200, epoch: 53 | loss: 0.0794507\n",
      "\tspeed: 0.0209s/iter; left time: 221.4396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0817173 Vali Loss: 0.0793203 Test Loss: 0.0834329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0831790\n",
      "\tspeed: 0.0318s/iter; left time: 333.2922s\n",
      "\titers: 200, epoch: 54 | loss: 0.0841627\n",
      "\tspeed: 0.0167s/iter; left time: 173.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0816611 Vali Loss: 0.0792993 Test Loss: 0.0834191\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0849556\n",
      "\tspeed: 0.0365s/iter; left time: 373.7607s\n",
      "\titers: 200, epoch: 55 | loss: 0.0824604\n",
      "\tspeed: 0.0200s/iter; left time: 203.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 225 | Train Loss: 0.0817934 Vali Loss: 0.0794798 Test Loss: 0.0834827\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0812058\n",
      "\tspeed: 0.0373s/iter; left time: 373.7917s\n",
      "\titers: 200, epoch: 56 | loss: 0.0791957\n",
      "\tspeed: 0.0189s/iter; left time: 187.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0818979 Vali Loss: 0.0792933 Test Loss: 0.0833512\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0799724\n",
      "\tspeed: 0.0389s/iter; left time: 380.9441s\n",
      "\titers: 200, epoch: 57 | loss: 0.0825712\n",
      "\tspeed: 0.0207s/iter; left time: 200.6459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0815750 Vali Loss: 0.0792557 Test Loss: 0.0833730\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0836057\n",
      "\tspeed: 0.0392s/iter; left time: 375.7318s\n",
      "\titers: 200, epoch: 58 | loss: 0.0862104\n",
      "\tspeed: 0.0203s/iter; left time: 192.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 225 | Train Loss: 0.0816147 Vali Loss: 0.0792267 Test Loss: 0.0833841\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0843756\n",
      "\tspeed: 0.0412s/iter; left time: 384.9438s\n",
      "\titers: 200, epoch: 59 | loss: 0.0816607\n",
      "\tspeed: 0.0220s/iter; left time: 203.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0815761 Vali Loss: 0.0794703 Test Loss: 0.0834059\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01843404211103916, rmse:0.13577201962471008, mae:0.08338046818971634, rse:0.5133686661720276\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:46.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2871464\n",
      "\tspeed: 0.0350s/iter; left time: 784.8044s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552790\n",
      "\tspeed: 0.0118s/iter; left time: 262.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 225 | Train Loss: 0.2854011 Vali Loss: 0.1998132 Test Loss: 0.2056278\n",
      "Validation loss decreased (inf --> 0.199813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431440\n",
      "\tspeed: 0.0294s/iter; left time: 651.6778s\n",
      "\titers: 200, epoch: 2 | loss: 0.1307513\n",
      "\tspeed: 0.0150s/iter; left time: 330.5901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.1579776 Vali Loss: 0.1133125 Test Loss: 0.1184016\n",
      "Validation loss decreased (0.199813 --> 0.113313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1170752\n",
      "\tspeed: 0.0313s/iter; left time: 687.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.1130971\n",
      "\tspeed: 0.0157s/iter; left time: 343.8582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1175846 Vali Loss: 0.1013606 Test Loss: 0.1047844\n",
      "Validation loss decreased (0.113313 --> 0.101361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1119373\n",
      "\tspeed: 0.0353s/iter; left time: 767.0267s\n",
      "\titers: 200, epoch: 4 | loss: 0.1014683\n",
      "\tspeed: 0.0170s/iter; left time: 367.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1058096 Vali Loss: 0.0938735 Test Loss: 0.0943376\n",
      "Validation loss decreased (0.101361 --> 0.093873).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0974286\n",
      "\tspeed: 0.0337s/iter; left time: 724.7678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965309\n",
      "\tspeed: 0.0170s/iter; left time: 362.9570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.1000301 Vali Loss: 0.0928358 Test Loss: 0.0944088\n",
      "Validation loss decreased (0.093873 --> 0.092836).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0954938\n",
      "\tspeed: 0.0337s/iter; left time: 716.1494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0964621\n",
      "\tspeed: 0.0158s/iter; left time: 335.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0964602 Vali Loss: 0.0884258 Test Loss: 0.0906295\n",
      "Validation loss decreased (0.092836 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0978478\n",
      "\tspeed: 0.0326s/iter; left time: 686.2370s\n",
      "\titers: 200, epoch: 7 | loss: 0.0921040\n",
      "\tspeed: 0.0202s/iter; left time: 424.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0944398 Vali Loss: 0.0873658 Test Loss: 0.0898157\n",
      "Validation loss decreased (0.088426 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869991\n",
      "\tspeed: 0.0334s/iter; left time: 695.3612s\n",
      "\titers: 200, epoch: 8 | loss: 0.0936323\n",
      "\tspeed: 0.0181s/iter; left time: 375.0768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0931402 Vali Loss: 0.0878391 Test Loss: 0.0891272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0928500\n",
      "\tspeed: 0.0331s/iter; left time: 682.1536s\n",
      "\titers: 200, epoch: 9 | loss: 0.0924792\n",
      "\tspeed: 0.0163s/iter; left time: 334.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0919907 Vali Loss: 0.0864041 Test Loss: 0.0892081\n",
      "Validation loss decreased (0.087366 --> 0.086404).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0924637\n",
      "\tspeed: 0.0359s/iter; left time: 730.5564s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947547\n",
      "\tspeed: 0.0194s/iter; left time: 393.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0911751 Vali Loss: 0.0859731 Test Loss: 0.0885750\n",
      "Validation loss decreased (0.086404 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0918101\n",
      "\tspeed: 0.0373s/iter; left time: 752.2057s\n",
      "\titers: 200, epoch: 11 | loss: 0.0909410\n",
      "\tspeed: 0.0191s/iter; left time: 383.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0903794 Vali Loss: 0.0853820 Test Loss: 0.0884126\n",
      "Validation loss decreased (0.085973 --> 0.085382).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880149\n",
      "\tspeed: 0.0341s/iter; left time: 678.9690s\n",
      "\titers: 200, epoch: 12 | loss: 0.0892051\n",
      "\tspeed: 0.0177s/iter; left time: 351.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0897380 Vali Loss: 0.0853620 Test Loss: 0.0886176\n",
      "Validation loss decreased (0.085382 --> 0.085362).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0866742\n",
      "\tspeed: 0.0351s/iter; left time: 692.4664s\n",
      "\titers: 200, epoch: 13 | loss: 0.0866411\n",
      "\tspeed: 0.0166s/iter; left time: 326.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0890611 Vali Loss: 0.0852427 Test Loss: 0.0886245\n",
      "Validation loss decreased (0.085362 --> 0.085243).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0873050\n",
      "\tspeed: 0.0367s/iter; left time: 715.3164s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878594\n",
      "\tspeed: 0.0190s/iter; left time: 367.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0886383 Vali Loss: 0.0850008 Test Loss: 0.0882895\n",
      "Validation loss decreased (0.085243 --> 0.085001).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0871279\n",
      "\tspeed: 0.0381s/iter; left time: 733.5587s\n",
      "\titers: 200, epoch: 15 | loss: 0.0854510\n",
      "\tspeed: 0.0187s/iter; left time: 358.7479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0881073 Vali Loss: 0.0858327 Test Loss: 0.0889315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0884793\n",
      "\tspeed: 0.0378s/iter; left time: 719.8521s\n",
      "\titers: 200, epoch: 16 | loss: 0.0910140\n",
      "\tspeed: 0.0169s/iter; left time: 319.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0878829 Vali Loss: 0.0851838 Test Loss: 0.0881989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0851787\n",
      "\tspeed: 0.0331s/iter; left time: 622.0127s\n",
      "\titers: 200, epoch: 17 | loss: 0.0884906\n",
      "\tspeed: 0.0160s/iter; left time: 299.6306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0876183 Vali Loss: 0.0851970 Test Loss: 0.0888068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0861608\n",
      "\tspeed: 0.0361s/iter; left time: 669.8588s\n",
      "\titers: 200, epoch: 18 | loss: 0.0879488\n",
      "\tspeed: 0.0199s/iter; left time: 368.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 225 | Train Loss: 0.0872039 Vali Loss: 0.0847646 Test Loss: 0.0885455\n",
      "Validation loss decreased (0.085001 --> 0.084765).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841821\n",
      "\tspeed: 0.0339s/iter; left time: 622.7458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927313\n",
      "\tspeed: 0.0162s/iter; left time: 295.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0871038 Vali Loss: 0.0841301 Test Loss: 0.0879659\n",
      "Validation loss decreased (0.084765 --> 0.084130).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0864908\n",
      "\tspeed: 0.0349s/iter; left time: 632.3668s\n",
      "\titers: 200, epoch: 20 | loss: 0.0873407\n",
      "\tspeed: 0.0190s/iter; left time: 342.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0869607 Vali Loss: 0.0842529 Test Loss: 0.0880568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0866177\n",
      "\tspeed: 0.0381s/iter; left time: 682.5803s\n",
      "\titers: 200, epoch: 21 | loss: 0.0867517\n",
      "\tspeed: 0.0203s/iter; left time: 360.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 225 | Train Loss: 0.0868113 Vali Loss: 0.0843626 Test Loss: 0.0878616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0879350\n",
      "\tspeed: 0.0384s/iter; left time: 679.3041s\n",
      "\titers: 200, epoch: 22 | loss: 0.0870513\n",
      "\tspeed: 0.0211s/iter; left time: 369.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0864764 Vali Loss: 0.0842002 Test Loss: 0.0879332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0858359\n",
      "\tspeed: 0.0348s/iter; left time: 606.6333s\n",
      "\titers: 200, epoch: 23 | loss: 0.0851808\n",
      "\tspeed: 0.0181s/iter; left time: 314.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0864841 Vali Loss: 0.0842316 Test Loss: 0.0881075\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0861321\n",
      "\tspeed: 0.0339s/iter; left time: 583.2187s\n",
      "\titers: 200, epoch: 24 | loss: 0.0962015\n",
      "\tspeed: 0.0183s/iter; left time: 313.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0864967 Vali Loss: 0.0848464 Test Loss: 0.0883762\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0878875\n",
      "\tspeed: 0.0339s/iter; left time: 576.0413s\n",
      "\titers: 200, epoch: 25 | loss: 0.0865147\n",
      "\tspeed: 0.0215s/iter; left time: 362.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0863466 Vali Loss: 0.0841036 Test Loss: 0.0880151\n",
      "Validation loss decreased (0.084130 --> 0.084104).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0824846\n",
      "\tspeed: 0.0333s/iter; left time: 559.0410s\n",
      "\titers: 200, epoch: 26 | loss: 0.0877685\n",
      "\tspeed: 0.0165s/iter; left time: 274.5133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0861868 Vali Loss: 0.0843329 Test Loss: 0.0881836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0860167\n",
      "\tspeed: 0.0338s/iter; left time: 559.1916s\n",
      "\titers: 200, epoch: 27 | loss: 0.0872357\n",
      "\tspeed: 0.0185s/iter; left time: 304.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0861339 Vali Loss: 0.0842179 Test Loss: 0.0879376\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0890730\n",
      "\tspeed: 0.0349s/iter; left time: 569.0543s\n",
      "\titers: 200, epoch: 28 | loss: 0.0879922\n",
      "\tspeed: 0.0209s/iter; left time: 339.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0859794 Vali Loss: 0.0840635 Test Loss: 0.0877377\n",
      "Validation loss decreased (0.084104 --> 0.084064).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0911478\n",
      "\tspeed: 0.0341s/iter; left time: 548.3408s\n",
      "\titers: 200, epoch: 29 | loss: 0.0832314\n",
      "\tspeed: 0.0181s/iter; left time: 290.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0859579 Vali Loss: 0.0840073 Test Loss: 0.0878611\n",
      "Validation loss decreased (0.084064 --> 0.084007).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0865786\n",
      "\tspeed: 0.0390s/iter; left time: 619.8198s\n",
      "\titers: 200, epoch: 30 | loss: 0.0882897\n",
      "\tspeed: 0.0203s/iter; left time: 320.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0859757 Vali Loss: 0.0840215 Test Loss: 0.0875936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0837739\n",
      "\tspeed: 0.0378s/iter; left time: 591.3445s\n",
      "\titers: 200, epoch: 31 | loss: 0.0823950\n",
      "\tspeed: 0.0160s/iter; left time: 248.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0860808 Vali Loss: 0.0840814 Test Loss: 0.0878295\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0830447\n",
      "\tspeed: 0.0393s/iter; left time: 605.8139s\n",
      "\titers: 200, epoch: 32 | loss: 0.0859739\n",
      "\tspeed: 0.0205s/iter; left time: 314.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0863978 Vali Loss: 0.0840468 Test Loss: 0.0878614\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0895207\n",
      "\tspeed: 0.0366s/iter; left time: 556.4685s\n",
      "\titers: 200, epoch: 33 | loss: 0.0877355\n",
      "\tspeed: 0.0185s/iter; left time: 278.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0858421 Vali Loss: 0.0839666 Test Loss: 0.0877551\n",
      "Validation loss decreased (0.084007 --> 0.083967).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0866324\n",
      "\tspeed: 0.0325s/iter; left time: 486.0566s\n",
      "\titers: 200, epoch: 34 | loss: 0.0839846\n",
      "\tspeed: 0.0154s/iter; left time: 229.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0857940 Vali Loss: 0.0839135 Test Loss: 0.0877007\n",
      "Validation loss decreased (0.083967 --> 0.083914).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0840788\n",
      "\tspeed: 0.0379s/iter; left time: 559.0763s\n",
      "\titers: 200, epoch: 35 | loss: 0.0875866\n",
      "\tspeed: 0.0195s/iter; left time: 286.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0858123 Vali Loss: 0.0842424 Test Loss: 0.0877640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0867140\n",
      "\tspeed: 0.0369s/iter; left time: 536.6394s\n",
      "\titers: 200, epoch: 36 | loss: 0.0856331\n",
      "\tspeed: 0.0191s/iter; left time: 275.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.0859275 Vali Loss: 0.0840178 Test Loss: 0.0876656\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0900123\n",
      "\tspeed: 0.0394s/iter; left time: 563.3746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0830691\n",
      "\tspeed: 0.0182s/iter; left time: 258.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0857823 Vali Loss: 0.0838440 Test Loss: 0.0878202\n",
      "Validation loss decreased (0.083914 --> 0.083844).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0872962\n",
      "\tspeed: 0.0318s/iter; left time: 447.0716s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843079\n",
      "\tspeed: 0.0169s/iter; left time: 236.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0856478 Vali Loss: 0.0842055 Test Loss: 0.0877056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0836912\n",
      "\tspeed: 0.0380s/iter; left time: 526.5336s\n",
      "\titers: 200, epoch: 39 | loss: 0.0842630\n",
      "\tspeed: 0.0218s/iter; left time: 299.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0857615 Vali Loss: 0.0839735 Test Loss: 0.0878095\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0847262\n",
      "\tspeed: 0.0333s/iter; left time: 453.3733s\n",
      "\titers: 200, epoch: 40 | loss: 0.0846217\n",
      "\tspeed: 0.0164s/iter; left time: 221.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0855740 Vali Loss: 0.0839487 Test Loss: 0.0876373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0832063\n",
      "\tspeed: 0.0370s/iter; left time: 495.7891s\n",
      "\titers: 200, epoch: 41 | loss: 0.0881097\n",
      "\tspeed: 0.0198s/iter; left time: 263.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0855960 Vali Loss: 0.0839609 Test Loss: 0.0877863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0827914\n",
      "\tspeed: 0.0354s/iter; left time: 466.6708s\n",
      "\titers: 200, epoch: 42 | loss: 0.0866479\n",
      "\tspeed: 0.0176s/iter; left time: 230.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0856862 Vali Loss: 0.0838571 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0855684\n",
      "\tspeed: 0.0334s/iter; left time: 432.9205s\n",
      "\titers: 200, epoch: 43 | loss: 0.0898735\n",
      "\tspeed: 0.0217s/iter; left time: 278.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0857198 Vali Loss: 0.0840194 Test Loss: 0.0876936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0840490\n",
      "\tspeed: 0.0348s/iter; left time: 443.0039s\n",
      "\titers: 200, epoch: 44 | loss: 0.0835335\n",
      "\tspeed: 0.0163s/iter; left time: 205.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0856540 Vali Loss: 0.0838441 Test Loss: 0.0877947\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0838612\n",
      "\tspeed: 0.0331s/iter; left time: 413.8472s\n",
      "\titers: 200, epoch: 45 | loss: 0.0866728\n",
      "\tspeed: 0.0170s/iter; left time: 210.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0855881 Vali Loss: 0.0840154 Test Loss: 0.0877012\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0848497\n",
      "\tspeed: 0.0335s/iter; left time: 411.6408s\n",
      "\titers: 200, epoch: 46 | loss: 0.0840844\n",
      "\tspeed: 0.0165s/iter; left time: 200.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0857706 Vali Loss: 0.0837818 Test Loss: 0.0878212\n",
      "Validation loss decreased (0.083844 --> 0.083782).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0809108\n",
      "\tspeed: 0.0323s/iter; left time: 389.2313s\n",
      "\titers: 200, epoch: 47 | loss: 0.0876100\n",
      "\tspeed: 0.0213s/iter; left time: 254.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0855649 Vali Loss: 0.0838934 Test Loss: 0.0876507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0854100\n",
      "\tspeed: 0.0345s/iter; left time: 408.0850s\n",
      "\titers: 200, epoch: 48 | loss: 0.0830703\n",
      "\tspeed: 0.0165s/iter; left time: 193.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0854888 Vali Loss: 0.0837947 Test Loss: 0.0877474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0881180\n",
      "\tspeed: 0.0329s/iter; left time: 381.6648s\n",
      "\titers: 200, epoch: 49 | loss: 0.0825081\n",
      "\tspeed: 0.0162s/iter; left time: 186.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0855913 Vali Loss: 0.0839997 Test Loss: 0.0876720\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0842309\n",
      "\tspeed: 0.0336s/iter; left time: 382.2480s\n",
      "\titers: 200, epoch: 50 | loss: 0.0896637\n",
      "\tspeed: 0.0170s/iter; left time: 191.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0855575 Vali Loss: 0.0836746 Test Loss: 0.0876439\n",
      "Validation loss decreased (0.083782 --> 0.083675).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0803221\n",
      "\tspeed: 0.0328s/iter; left time: 365.8281s\n",
      "\titers: 200, epoch: 51 | loss: 0.0852165\n",
      "\tspeed: 0.0166s/iter; left time: 183.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0857192 Vali Loss: 0.0838952 Test Loss: 0.0876832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0891636\n",
      "\tspeed: 0.0323s/iter; left time: 352.7288s\n",
      "\titers: 200, epoch: 52 | loss: 0.0858402\n",
      "\tspeed: 0.0155s/iter; left time: 168.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0855586 Vali Loss: 0.0839647 Test Loss: 0.0877191\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0857720\n",
      "\tspeed: 0.0358s/iter; left time: 382.6640s\n",
      "\titers: 200, epoch: 53 | loss: 0.0827048\n",
      "\tspeed: 0.0196s/iter; left time: 207.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0854881 Vali Loss: 0.0838258 Test Loss: 0.0876724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0894596\n",
      "\tspeed: 0.0329s/iter; left time: 344.6078s\n",
      "\titers: 200, epoch: 54 | loss: 0.0887103\n",
      "\tspeed: 0.0158s/iter; left time: 163.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0856003 Vali Loss: 0.0839257 Test Loss: 0.0877173\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0881316\n",
      "\tspeed: 0.0338s/iter; left time: 346.4570s\n",
      "\titers: 200, epoch: 55 | loss: 0.0862180\n",
      "\tspeed: 0.0159s/iter; left time: 161.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0855120 Vali Loss: 0.0838650 Test Loss: 0.0877261\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0841388\n",
      "\tspeed: 0.0334s/iter; left time: 334.6769s\n",
      "\titers: 200, epoch: 56 | loss: 0.0869091\n",
      "\tspeed: 0.0181s/iter; left time: 179.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0856856 Vali Loss: 0.0836929 Test Loss: 0.0878890\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0832032\n",
      "\tspeed: 0.0355s/iter; left time: 348.0622s\n",
      "\titers: 200, epoch: 57 | loss: 0.0826762\n",
      "\tspeed: 0.0178s/iter; left time: 173.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0856178 Vali Loss: 0.0839305 Test Loss: 0.0877205\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0862195\n",
      "\tspeed: 0.0341s/iter; left time: 326.8623s\n",
      "\titers: 200, epoch: 58 | loss: 0.0849153\n",
      "\tspeed: 0.0173s/iter; left time: 163.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0855426 Vali Loss: 0.0836311 Test Loss: 0.0877388\n",
      "Validation loss decreased (0.083675 --> 0.083631).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0874458\n",
      "\tspeed: 0.0337s/iter; left time: 315.5775s\n",
      "\titers: 200, epoch: 59 | loss: 0.0856677\n",
      "\tspeed: 0.0152s/iter; left time: 140.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0854076 Vali Loss: 0.0837660 Test Loss: 0.0877864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0862853\n",
      "\tspeed: 0.0383s/iter; left time: 349.1669s\n",
      "\titers: 200, epoch: 60 | loss: 0.0846376\n",
      "\tspeed: 0.0202s/iter; left time: 182.4430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0855039 Vali Loss: 0.0839287 Test Loss: 0.0877160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0831357\n",
      "\tspeed: 0.0380s/iter; left time: 338.5553s\n",
      "\titers: 200, epoch: 61 | loss: 0.0843221\n",
      "\tspeed: 0.0216s/iter; left time: 189.9404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0854917 Vali Loss: 0.0837465 Test Loss: 0.0877291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0863590\n",
      "\tspeed: 0.0384s/iter; left time: 332.7523s\n",
      "\titers: 200, epoch: 62 | loss: 0.0844525\n",
      "\tspeed: 0.0200s/iter; left time: 171.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0855115 Vali Loss: 0.0839486 Test Loss: 0.0877433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0835522\n",
      "\tspeed: 0.0345s/iter; left time: 291.3142s\n",
      "\titers: 200, epoch: 63 | loss: 0.0858202\n",
      "\tspeed: 0.0175s/iter; left time: 146.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0854575 Vali Loss: 0.0838609 Test Loss: 0.0876994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0863423\n",
      "\tspeed: 0.0367s/iter; left time: 301.7965s\n",
      "\titers: 200, epoch: 64 | loss: 0.0882498\n",
      "\tspeed: 0.0192s/iter; left time: 155.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0853901 Vali Loss: 0.0837660 Test Loss: 0.0876815\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0795603\n",
      "\tspeed: 0.0342s/iter; left time: 273.4767s\n",
      "\titers: 200, epoch: 65 | loss: 0.0861610\n",
      "\tspeed: 0.0159s/iter; left time: 125.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0854072 Vali Loss: 0.0837482 Test Loss: 0.0877235\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0849181\n",
      "\tspeed: 0.0373s/iter; left time: 290.0356s\n",
      "\titers: 200, epoch: 66 | loss: 0.0865337\n",
      "\tspeed: 0.0176s/iter; left time: 135.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.0855410 Vali Loss: 0.0837984 Test Loss: 0.0877984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0806636\n",
      "\tspeed: 0.0382s/iter; left time: 288.8172s\n",
      "\titers: 200, epoch: 67 | loss: 0.0847101\n",
      "\tspeed: 0.0201s/iter; left time: 149.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0854205 Vali Loss: 0.0839564 Test Loss: 0.0877346\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0891916\n",
      "\tspeed: 0.0342s/iter; left time: 250.2153s\n",
      "\titers: 200, epoch: 68 | loss: 0.0856488\n",
      "\tspeed: 0.0191s/iter; left time: 138.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0855271 Vali Loss: 0.0839384 Test Loss: 0.0878300\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01985144428908825, rmse:0.14089515805244446, mae:0.08773878216743469, rse:0.5332347750663757\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2811901\n",
      "\tspeed: 0.0192s/iter; left time: 430.7573s\n",
      "\titers: 200, epoch: 1 | loss: 0.2555557\n",
      "\tspeed: 0.0160s/iter; left time: 355.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.2855597 Vali Loss: 0.2034866 Test Loss: 0.2095738\n",
      "Validation loss decreased (inf --> 0.203487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407049\n",
      "\tspeed: 0.0329s/iter; left time: 730.2627s\n",
      "\titers: 200, epoch: 2 | loss: 0.1255486\n",
      "\tspeed: 0.0098s/iter; left time: 217.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.1563358 Vali Loss: 0.1131076 Test Loss: 0.1202545\n",
      "Validation loss decreased (0.203487 --> 0.113108).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1179366\n",
      "\tspeed: 0.0346s/iter; left time: 759.7440s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155250\n",
      "\tspeed: 0.0149s/iter; left time: 325.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.1178324 Vali Loss: 0.1009700 Test Loss: 0.1035364\n",
      "Validation loss decreased (0.113108 --> 0.100970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1069622\n",
      "\tspeed: 0.0381s/iter; left time: 826.9655s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056391\n",
      "\tspeed: 0.0190s/iter; left time: 410.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.1062726 Vali Loss: 0.0952413 Test Loss: 0.0965261\n",
      "Validation loss decreased (0.100970 --> 0.095241).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0975991\n",
      "\tspeed: 0.0334s/iter; left time: 717.6973s\n",
      "\titers: 200, epoch: 5 | loss: 0.1003618\n",
      "\tspeed: 0.0152s/iter; left time: 324.4944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.1005352 Vali Loss: 0.0913371 Test Loss: 0.0940908\n",
      "Validation loss decreased (0.095241 --> 0.091337).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990696\n",
      "\tspeed: 0.0373s/iter; left time: 793.5207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1006796\n",
      "\tspeed: 0.0189s/iter; left time: 399.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0975591 Vali Loss: 0.0896493 Test Loss: 0.0929677\n",
      "Validation loss decreased (0.091337 --> 0.089649).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0946059\n",
      "\tspeed: 0.0359s/iter; left time: 756.2554s\n",
      "\titers: 200, epoch: 7 | loss: 0.0987749\n",
      "\tspeed: 0.0175s/iter; left time: 366.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0952434 Vali Loss: 0.0885789 Test Loss: 0.0906260\n",
      "Validation loss decreased (0.089649 --> 0.088579).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0912916\n",
      "\tspeed: 0.0315s/iter; left time: 654.9935s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941708\n",
      "\tspeed: 0.0135s/iter; left time: 279.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0937680 Vali Loss: 0.0880198 Test Loss: 0.0900427\n",
      "Validation loss decreased (0.088579 --> 0.088020).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0892983\n",
      "\tspeed: 0.0314s/iter; left time: 647.8609s\n",
      "\titers: 200, epoch: 9 | loss: 0.0933996\n",
      "\tspeed: 0.0128s/iter; left time: 262.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0926713 Vali Loss: 0.0868229 Test Loss: 0.0900808\n",
      "Validation loss decreased (0.088020 --> 0.086823).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0906593\n",
      "\tspeed: 0.0340s/iter; left time: 693.3928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0939311\n",
      "\tspeed: 0.0168s/iter; left time: 339.9877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0914059 Vali Loss: 0.0864519 Test Loss: 0.0892728\n",
      "Validation loss decreased (0.086823 --> 0.086452).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0897200\n",
      "\tspeed: 0.0346s/iter; left time: 696.5937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0882291\n",
      "\tspeed: 0.0163s/iter; left time: 326.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0904506 Vali Loss: 0.0862451 Test Loss: 0.0891356\n",
      "Validation loss decreased (0.086452 --> 0.086245).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0927711\n",
      "\tspeed: 0.0286s/iter; left time: 569.8227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0938112\n",
      "\tspeed: 0.0172s/iter; left time: 341.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0897738 Vali Loss: 0.0862953 Test Loss: 0.0888204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893305\n",
      "\tspeed: 0.0340s/iter; left time: 669.1768s\n",
      "\titers: 200, epoch: 13 | loss: 0.0923870\n",
      "\tspeed: 0.0182s/iter; left time: 357.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0891380 Vali Loss: 0.0859750 Test Loss: 0.0888117\n",
      "Validation loss decreased (0.086245 --> 0.085975).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0903896\n",
      "\tspeed: 0.0324s/iter; left time: 631.5628s\n",
      "\titers: 200, epoch: 14 | loss: 0.0873978\n",
      "\tspeed: 0.0175s/iter; left time: 338.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0887752 Vali Loss: 0.0853476 Test Loss: 0.0883505\n",
      "Validation loss decreased (0.085975 --> 0.085348).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0904353\n",
      "\tspeed: 0.0340s/iter; left time: 654.3193s\n",
      "\titers: 200, epoch: 15 | loss: 0.0884306\n",
      "\tspeed: 0.0133s/iter; left time: 254.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0883704 Vali Loss: 0.0849287 Test Loss: 0.0884772\n",
      "Validation loss decreased (0.085348 --> 0.084929).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865225\n",
      "\tspeed: 0.0329s/iter; left time: 626.6952s\n",
      "\titers: 200, epoch: 16 | loss: 0.0862006\n",
      "\tspeed: 0.0143s/iter; left time: 271.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0879999 Vali Loss: 0.0850746 Test Loss: 0.0880633\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0891528\n",
      "\tspeed: 0.0344s/iter; left time: 646.5989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0878572\n",
      "\tspeed: 0.0145s/iter; left time: 270.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0878672 Vali Loss: 0.0847102 Test Loss: 0.0881083\n",
      "Validation loss decreased (0.084929 --> 0.084710).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0881433\n",
      "\tspeed: 0.0347s/iter; left time: 643.9944s\n",
      "\titers: 200, epoch: 18 | loss: 0.0901565\n",
      "\tspeed: 0.0159s/iter; left time: 294.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0874882 Vali Loss: 0.0848959 Test Loss: 0.0880535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0862640\n",
      "\tspeed: 0.0297s/iter; left time: 545.4961s\n",
      "\titers: 200, epoch: 19 | loss: 0.0926718\n",
      "\tspeed: 0.0173s/iter; left time: 316.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0874914 Vali Loss: 0.0846168 Test Loss: 0.0882703\n",
      "Validation loss decreased (0.084710 --> 0.084617).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0858740\n",
      "\tspeed: 0.0378s/iter; left time: 685.6659s\n",
      "\titers: 200, epoch: 20 | loss: 0.0878472\n",
      "\tspeed: 0.0158s/iter; left time: 284.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0871674 Vali Loss: 0.0845910 Test Loss: 0.0877174\n",
      "Validation loss decreased (0.084617 --> 0.084591).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0822908\n",
      "\tspeed: 0.0355s/iter; left time: 634.8406s\n",
      "\titers: 200, epoch: 21 | loss: 0.0888437\n",
      "\tspeed: 0.0179s/iter; left time: 318.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0869461 Vali Loss: 0.0846306 Test Loss: 0.0877483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0889016\n",
      "\tspeed: 0.0346s/iter; left time: 611.6671s\n",
      "\titers: 200, epoch: 22 | loss: 0.0853360\n",
      "\tspeed: 0.0163s/iter; left time: 286.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0868771 Vali Loss: 0.0845347 Test Loss: 0.0878567\n",
      "Validation loss decreased (0.084591 --> 0.084535).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0878374\n",
      "\tspeed: 0.0355s/iter; left time: 620.3362s\n",
      "\titers: 200, epoch: 23 | loss: 0.0857313\n",
      "\tspeed: 0.0186s/iter; left time: 323.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0867781 Vali Loss: 0.0845471 Test Loss: 0.0879436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0893482\n",
      "\tspeed: 0.0302s/iter; left time: 519.4805s\n",
      "\titers: 200, epoch: 24 | loss: 0.0847237\n",
      "\tspeed: 0.0102s/iter; left time: 174.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0868089 Vali Loss: 0.0843728 Test Loss: 0.0877755\n",
      "Validation loss decreased (0.084535 --> 0.084373).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0856335\n",
      "\tspeed: 0.0328s/iter; left time: 558.1006s\n",
      "\titers: 200, epoch: 25 | loss: 0.0884197\n",
      "\tspeed: 0.0144s/iter; left time: 243.7999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0866318 Vali Loss: 0.0844467 Test Loss: 0.0877618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0915473\n",
      "\tspeed: 0.0340s/iter; left time: 570.9848s\n",
      "\titers: 200, epoch: 26 | loss: 0.0861925\n",
      "\tspeed: 0.0156s/iter; left time: 259.8701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0864816 Vali Loss: 0.0843100 Test Loss: 0.0880293\n",
      "Validation loss decreased (0.084373 --> 0.084310).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0888533\n",
      "\tspeed: 0.0332s/iter; left time: 548.8214s\n",
      "\titers: 200, epoch: 27 | loss: 0.0828652\n",
      "\tspeed: 0.0159s/iter; left time: 261.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0864010 Vali Loss: 0.0840675 Test Loss: 0.0878859\n",
      "Validation loss decreased (0.084310 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0866069\n",
      "\tspeed: 0.0335s/iter; left time: 546.6210s\n",
      "\titers: 200, epoch: 28 | loss: 0.0846799\n",
      "\tspeed: 0.0151s/iter; left time: 245.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0863566 Vali Loss: 0.0841139 Test Loss: 0.0878939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0864667\n",
      "\tspeed: 0.0320s/iter; left time: 515.8490s\n",
      "\titers: 200, epoch: 29 | loss: 0.0849992\n",
      "\tspeed: 0.0153s/iter; left time: 244.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0861578 Vali Loss: 0.0842914 Test Loss: 0.0877159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0887233\n",
      "\tspeed: 0.0317s/iter; left time: 502.5355s\n",
      "\titers: 200, epoch: 30 | loss: 0.0850501\n",
      "\tspeed: 0.0174s/iter; left time: 274.3911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0861103 Vali Loss: 0.0840877 Test Loss: 0.0877250\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850813\n",
      "\tspeed: 0.0367s/iter; left time: 574.6106s\n",
      "\titers: 200, epoch: 31 | loss: 0.0864127\n",
      "\tspeed: 0.0118s/iter; left time: 183.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0861136 Vali Loss: 0.0841656 Test Loss: 0.0876141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0869038\n",
      "\tspeed: 0.0286s/iter; left time: 440.7895s\n",
      "\titers: 200, epoch: 32 | loss: 0.0882633\n",
      "\tspeed: 0.0111s/iter; left time: 169.6003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0860620 Vali Loss: 0.0840440 Test Loss: 0.0875890\n",
      "Validation loss decreased (0.084068 --> 0.084044).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0830199\n",
      "\tspeed: 0.0288s/iter; left time: 437.8174s\n",
      "\titers: 200, epoch: 33 | loss: 0.0820900\n",
      "\tspeed: 0.0125s/iter; left time: 189.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0860683 Vali Loss: 0.0840771 Test Loss: 0.0877418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0851234\n",
      "\tspeed: 0.0361s/iter; left time: 540.5820s\n",
      "\titers: 200, epoch: 34 | loss: 0.0869063\n",
      "\tspeed: 0.0162s/iter; left time: 241.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0860582 Vali Loss: 0.0841589 Test Loss: 0.0876531\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0853247\n",
      "\tspeed: 0.0328s/iter; left time: 484.3153s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821250\n",
      "\tspeed: 0.0189s/iter; left time: 277.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0859170 Vali Loss: 0.0837935 Test Loss: 0.0877555\n",
      "Validation loss decreased (0.084044 --> 0.083794).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0848440\n",
      "\tspeed: 0.0339s/iter; left time: 492.5746s\n",
      "\titers: 200, epoch: 36 | loss: 0.0825796\n",
      "\tspeed: 0.0155s/iter; left time: 224.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0859620 Vali Loss: 0.0839452 Test Loss: 0.0875413\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0834437\n",
      "\tspeed: 0.0362s/iter; left time: 517.5947s\n",
      "\titers: 200, epoch: 37 | loss: 0.0914393\n",
      "\tspeed: 0.0175s/iter; left time: 249.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0858014 Vali Loss: 0.0838901 Test Loss: 0.0875761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0870592\n",
      "\tspeed: 0.0320s/iter; left time: 450.5334s\n",
      "\titers: 200, epoch: 38 | loss: 0.0849523\n",
      "\tspeed: 0.0171s/iter; left time: 238.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0857765 Vali Loss: 0.0838603 Test Loss: 0.0876727\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0813147\n",
      "\tspeed: 0.0289s/iter; left time: 400.1122s\n",
      "\titers: 200, epoch: 39 | loss: 0.0890005\n",
      "\tspeed: 0.0157s/iter; left time: 216.0689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0859399 Vali Loss: 0.0838971 Test Loss: 0.0876239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0830819\n",
      "\tspeed: 0.0314s/iter; left time: 427.4216s\n",
      "\titers: 200, epoch: 40 | loss: 0.0856972\n",
      "\tspeed: 0.0138s/iter; left time: 186.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0860559 Vali Loss: 0.0839531 Test Loss: 0.0874863\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0860740\n",
      "\tspeed: 0.0336s/iter; left time: 450.3678s\n",
      "\titers: 200, epoch: 41 | loss: 0.0863928\n",
      "\tspeed: 0.0162s/iter; left time: 215.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0858800 Vali Loss: 0.0839168 Test Loss: 0.0875721\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0892703\n",
      "\tspeed: 0.0320s/iter; left time: 422.1587s\n",
      "\titers: 200, epoch: 42 | loss: 0.0883598\n",
      "\tspeed: 0.0166s/iter; left time: 217.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0857964 Vali Loss: 0.0837697 Test Loss: 0.0875823\n",
      "Validation loss decreased (0.083794 --> 0.083770).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0879114\n",
      "\tspeed: 0.0348s/iter; left time: 450.2445s\n",
      "\titers: 200, epoch: 43 | loss: 0.0877481\n",
      "\tspeed: 0.0163s/iter; left time: 208.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0858649 Vali Loss: 0.0837876 Test Loss: 0.0874805\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0840065\n",
      "\tspeed: 0.0318s/iter; left time: 405.0638s\n",
      "\titers: 200, epoch: 44 | loss: 0.0844992\n",
      "\tspeed: 0.0149s/iter; left time: 187.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0858228 Vali Loss: 0.0838888 Test Loss: 0.0876042\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0876887\n",
      "\tspeed: 0.0343s/iter; left time: 428.3675s\n",
      "\titers: 200, epoch: 45 | loss: 0.0862209\n",
      "\tspeed: 0.0160s/iter; left time: 198.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0858926 Vali Loss: 0.0838959 Test Loss: 0.0875133\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0850273\n",
      "\tspeed: 0.0324s/iter; left time: 398.2815s\n",
      "\titers: 200, epoch: 46 | loss: 0.0850483\n",
      "\tspeed: 0.0154s/iter; left time: 186.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0857520 Vali Loss: 0.0840085 Test Loss: 0.0876112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0873501\n",
      "\tspeed: 0.0315s/iter; left time: 379.6881s\n",
      "\titers: 200, epoch: 47 | loss: 0.0857628\n",
      "\tspeed: 0.0156s/iter; left time: 186.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0856933 Vali Loss: 0.0840146 Test Loss: 0.0875916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0866789\n",
      "\tspeed: 0.0323s/iter; left time: 381.4637s\n",
      "\titers: 200, epoch: 48 | loss: 0.0857183\n",
      "\tspeed: 0.0136s/iter; left time: 159.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0858344 Vali Loss: 0.0838272 Test Loss: 0.0874924\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0856871\n",
      "\tspeed: 0.0306s/iter; left time: 355.1994s\n",
      "\titers: 200, epoch: 49 | loss: 0.0848251\n",
      "\tspeed: 0.0133s/iter; left time: 152.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0857752 Vali Loss: 0.0838986 Test Loss: 0.0874747\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0884241\n",
      "\tspeed: 0.0319s/iter; left time: 362.6406s\n",
      "\titers: 200, epoch: 50 | loss: 0.0847695\n",
      "\tspeed: 0.0155s/iter; left time: 174.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0856900 Vali Loss: 0.0837343 Test Loss: 0.0876015\n",
      "Validation loss decreased (0.083770 --> 0.083734).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0916913\n",
      "\tspeed: 0.0304s/iter; left time: 339.0639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0854367\n",
      "\tspeed: 0.0138s/iter; left time: 152.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0857145 Vali Loss: 0.0839531 Test Loss: 0.0874348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0813114\n",
      "\tspeed: 0.0313s/iter; left time: 341.4976s\n",
      "\titers: 200, epoch: 52 | loss: 0.0878581\n",
      "\tspeed: 0.0141s/iter; left time: 152.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0857817 Vali Loss: 0.0840421 Test Loss: 0.0875262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0855496\n",
      "\tspeed: 0.0313s/iter; left time: 335.2605s\n",
      "\titers: 200, epoch: 53 | loss: 0.0854577\n",
      "\tspeed: 0.0156s/iter; left time: 165.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0858797 Vali Loss: 0.0838894 Test Loss: 0.0875471\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0848776\n",
      "\tspeed: 0.0323s/iter; left time: 338.4287s\n",
      "\titers: 200, epoch: 54 | loss: 0.0854730\n",
      "\tspeed: 0.0152s/iter; left time: 158.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0855863 Vali Loss: 0.0837929 Test Loss: 0.0875680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0851004\n",
      "\tspeed: 0.0324s/iter; left time: 332.6410s\n",
      "\titers: 200, epoch: 55 | loss: 0.0866423\n",
      "\tspeed: 0.0160s/iter; left time: 162.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0856860 Vali Loss: 0.0839773 Test Loss: 0.0875212\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0851850\n",
      "\tspeed: 0.0322s/iter; left time: 322.8402s\n",
      "\titers: 200, epoch: 56 | loss: 0.0869962\n",
      "\tspeed: 0.0128s/iter; left time: 126.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0857411 Vali Loss: 0.0838174 Test Loss: 0.0875457\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0855275\n",
      "\tspeed: 0.0323s/iter; left time: 316.3555s\n",
      "\titers: 200, epoch: 57 | loss: 0.0821422\n",
      "\tspeed: 0.0155s/iter; left time: 150.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0857449 Vali Loss: 0.0836694 Test Loss: 0.0876946\n",
      "Validation loss decreased (0.083734 --> 0.083669).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0852302\n",
      "\tspeed: 0.0313s/iter; left time: 300.1953s\n",
      "\titers: 200, epoch: 58 | loss: 0.0813387\n",
      "\tspeed: 0.0141s/iter; left time: 133.5898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0856328 Vali Loss: 0.0838333 Test Loss: 0.0876395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0865474\n",
      "\tspeed: 0.0319s/iter; left time: 297.9664s\n",
      "\titers: 200, epoch: 59 | loss: 0.0864555\n",
      "\tspeed: 0.0181s/iter; left time: 167.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0857513 Vali Loss: 0.0838587 Test Loss: 0.0875407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0815425\n",
      "\tspeed: 0.0336s/iter; left time: 306.1960s\n",
      "\titers: 200, epoch: 60 | loss: 0.0846148\n",
      "\tspeed: 0.0132s/iter; left time: 119.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0856650 Vali Loss: 0.0838523 Test Loss: 0.0875463\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0817179\n",
      "\tspeed: 0.0349s/iter; left time: 310.3364s\n",
      "\titers: 200, epoch: 61 | loss: 0.0882797\n",
      "\tspeed: 0.0169s/iter; left time: 148.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0857247 Vali Loss: 0.0837791 Test Loss: 0.0875305\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0847188\n",
      "\tspeed: 0.0304s/iter; left time: 263.4557s\n",
      "\titers: 200, epoch: 62 | loss: 0.0864886\n",
      "\tspeed: 0.0172s/iter; left time: 147.6845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0856562 Vali Loss: 0.0837275 Test Loss: 0.0875718\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0876755\n",
      "\tspeed: 0.0329s/iter; left time: 277.9308s\n",
      "\titers: 200, epoch: 63 | loss: 0.0876397\n",
      "\tspeed: 0.0154s/iter; left time: 128.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0856394 Vali Loss: 0.0837758 Test Loss: 0.0876276\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0870029\n",
      "\tspeed: 0.0323s/iter; left time: 265.3085s\n",
      "\titers: 200, epoch: 64 | loss: 0.0860020\n",
      "\tspeed: 0.0155s/iter; left time: 126.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0856961 Vali Loss: 0.0837211 Test Loss: 0.0875373\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0852330\n",
      "\tspeed: 0.0336s/iter; left time: 269.0732s\n",
      "\titers: 200, epoch: 65 | loss: 0.0844138\n",
      "\tspeed: 0.0179s/iter; left time: 141.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0855918 Vali Loss: 0.0838730 Test Loss: 0.0874921\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0866955\n",
      "\tspeed: 0.0336s/iter; left time: 261.4932s\n",
      "\titers: 200, epoch: 66 | loss: 0.0854436\n",
      "\tspeed: 0.0164s/iter; left time: 125.8727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0858716 Vali Loss: 0.0839868 Test Loss: 0.0875049\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0849778\n",
      "\tspeed: 0.0344s/iter; left time: 259.7289s\n",
      "\titers: 200, epoch: 67 | loss: 0.0866626\n",
      "\tspeed: 0.0166s/iter; left time: 123.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0856807 Vali Loss: 0.0837630 Test Loss: 0.0875618\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019952882081270218, rmse:0.14125467836856842, mae:0.08769454061985016, rse:0.5345954895019531\n",
      "Intermediate time for IT and pred_len 168: 00h:11m:37.36s\n",
      "Intermediate time for IT: 00h:30m:03.60s\n",
      "Total time: 02h:39m:39.71s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"no_revin_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1473  0.0914\n",
       "        96        0.0378  0.1945  0.1299\n",
       "        168       0.0459  0.2143  0.1411\n",
       "ES      24        0.0128  0.1130  0.0728\n",
       "        96        0.0330  0.1801  0.1138\n",
       "        168       0.0306  0.1748  0.1165\n",
       "FR      24        0.0111  0.1055  0.0610\n",
       "        96        0.0204  0.1429  0.0836\n",
       "        168       0.0231  0.1520  0.0899\n",
       "GB      24        0.0259  0.1608  0.1038\n",
       "        96        0.0432  0.2079  0.1433\n",
       "        168       0.0478  0.2186  0.1505\n",
       "IT      24        0.0109  0.1042  0.0626\n",
       "        96        0.0186  0.1365  0.0837\n",
       "        168       0.0199  0.1411  0.0877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience.\n",
    "\n",
    "Complete results are in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1051457\n",
      "\tspeed: 0.1703s/iter; left time: 3781.7709s\n",
      "\titers: 200, epoch: 1 | loss: 0.0932204\n",
      "\tspeed: 0.1458s/iter; left time: 3221.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 223 | Train Loss: 0.1071621 Vali Loss: 0.1028725 Test Loss: 0.1150246\n",
      "Validation loss decreased (inf --> 0.102873).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0896473\n",
      "\tspeed: 0.2421s/iter; left time: 5320.6976s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852750\n",
      "\tspeed: 0.1465s/iter; left time: 3204.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0888812 Vali Loss: 0.1054194 Test Loss: 0.1180188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0801186\n",
      "\tspeed: 0.2385s/iter; left time: 5189.3113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0752198\n",
      "\tspeed: 0.1471s/iter; left time: 3185.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 223 | Train Loss: 0.0808936 Vali Loss: 0.1088918 Test Loss: 0.1218244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764754\n",
      "\tspeed: 0.2386s/iter; left time: 5136.7827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0668249\n",
      "\tspeed: 0.1475s/iter; left time: 3162.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 223 | Train Loss: 0.0712032 Vali Loss: 0.1164811 Test Loss: 0.1314963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0584339\n",
      "\tspeed: 0.2388s/iter; left time: 5087.6700s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.1467s/iter; left time: 3111.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 223 | Train Loss: 0.0614232 Vali Loss: 0.1146671 Test Loss: 0.1260481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0533759\n",
      "\tspeed: 0.2367s/iter; left time: 4990.1201s\n",
      "\titers: 200, epoch: 6 | loss: 0.0495681\n",
      "\tspeed: 0.1466s/iter; left time: 3077.0692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0537273 Vali Loss: 0.1115397 Test Loss: 0.1244299\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0473040\n",
      "\tspeed: 0.2379s/iter; left time: 4962.2669s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490480\n",
      "\tspeed: 0.1467s/iter; left time: 3046.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 223 | Train Loss: 0.0485017 Vali Loss: 0.1118774 Test Loss: 0.1266170\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0428582\n",
      "\tspeed: 0.2373s/iter; left time: 4897.0955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0423327\n",
      "\tspeed: 0.1464s/iter; left time: 3006.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 223 | Train Loss: 0.0436265 Vali Loss: 0.1113263 Test Loss: 0.1248961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409019\n",
      "\tspeed: 0.2371s/iter; left time: 4841.5272s\n",
      "\titers: 200, epoch: 9 | loss: 0.0388029\n",
      "\tspeed: 0.1463s/iter; left time: 2971.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.73s\n",
      "Steps: 223 | Train Loss: 0.0416113 Vali Loss: 0.1129987 Test Loss: 0.1294562\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0386123\n",
      "\tspeed: 0.2363s/iter; left time: 4771.1943s\n",
      "\titers: 200, epoch: 10 | loss: 0.0380670\n",
      "\tspeed: 0.1463s/iter; left time: 2940.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0399942 Vali Loss: 0.1123616 Test Loss: 0.1261321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0382017\n",
      "\tspeed: 0.2373s/iter; left time: 4739.1549s\n",
      "\titers: 200, epoch: 11 | loss: 0.0367740\n",
      "\tspeed: 0.1463s/iter; left time: 2906.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0381936 Vali Loss: 0.1106567 Test Loss: 0.1257289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028743868693709373, rmse:0.1695401668548584, mae:0.11502459645271301, rse:0.5848655104637146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1056844\n",
      "\tspeed: 0.1474s/iter; left time: 3273.2981s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887723\n",
      "\tspeed: 0.1462s/iter; left time: 3231.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 223 | Train Loss: 0.1076930 Vali Loss: 0.1034200 Test Loss: 0.1157358\n",
      "Validation loss decreased (inf --> 0.103420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871905\n",
      "\tspeed: 0.2427s/iter; left time: 5333.6320s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820583\n",
      "\tspeed: 0.1465s/iter; left time: 3205.9718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0888926 Vali Loss: 0.1046297 Test Loss: 0.1171767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0843876\n",
      "\tspeed: 0.2379s/iter; left time: 5175.5638s\n",
      "\titers: 200, epoch: 3 | loss: 0.0818222\n",
      "\tspeed: 0.1464s/iter; left time: 3169.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 223 | Train Loss: 0.0815588 Vali Loss: 0.1086011 Test Loss: 0.1196759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0724633\n",
      "\tspeed: 0.2380s/iter; left time: 5125.0562s\n",
      "\titers: 200, epoch: 4 | loss: 0.0665326\n",
      "\tspeed: 0.1466s/iter; left time: 3142.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0715411 Vali Loss: 0.1171121 Test Loss: 0.1247998\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588575\n",
      "\tspeed: 0.2378s/iter; left time: 5066.5772s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584292\n",
      "\tspeed: 0.1465s/iter; left time: 3107.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0616918 Vali Loss: 0.1111074 Test Loss: 0.1225118\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505120\n",
      "\tspeed: 0.2374s/iter; left time: 5005.2128s\n",
      "\titers: 200, epoch: 6 | loss: 0.0511305\n",
      "\tspeed: 0.1461s/iter; left time: 3066.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0532696 Vali Loss: 0.1103224 Test Loss: 0.1216622\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0483326\n",
      "\tspeed: 0.2370s/iter; left time: 4944.9578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0455461\n",
      "\tspeed: 0.1462s/iter; left time: 3035.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0479013 Vali Loss: 0.1107165 Test Loss: 0.1228329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0439964\n",
      "\tspeed: 0.2375s/iter; left time: 4902.2376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449820\n",
      "\tspeed: 0.1463s/iter; left time: 3004.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.75s\n",
      "Steps: 223 | Train Loss: 0.0444204 Vali Loss: 0.1109379 Test Loss: 0.1237228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418664\n",
      "\tspeed: 0.2376s/iter; left time: 4851.4845s\n",
      "\titers: 200, epoch: 9 | loss: 0.0413343\n",
      "\tspeed: 0.1464s/iter; left time: 2974.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0413205 Vali Loss: 0.1107434 Test Loss: 0.1236369\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0371369\n",
      "\tspeed: 0.2377s/iter; left time: 4800.6975s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389452\n",
      "\tspeed: 0.1463s/iter; left time: 2938.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0396608 Vali Loss: 0.1118143 Test Loss: 0.1250867\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0370215\n",
      "\tspeed: 0.2380s/iter; left time: 4752.2605s\n",
      "\titers: 200, epoch: 11 | loss: 0.0395964\n",
      "\tspeed: 0.1465s/iter; left time: 2910.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0381358 Vali Loss: 0.1105671 Test Loss: 0.1246427\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029005983844399452, rmse:0.17031143605709076, mae:0.11573578417301178, rse:0.5875261425971985\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:21.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1156728\n",
      "\tspeed: 0.1709s/iter; left time: 3777.5477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1047598\n",
      "\tspeed: 0.1498s/iter; left time: 3295.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.44s\n",
      "Steps: 222 | Train Loss: 0.1199832 Vali Loss: 0.1229378 Test Loss: 0.1452433\n",
      "Validation loss decreased (inf --> 0.122938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1146321\n",
      "\tspeed: 0.2501s/iter; left time: 5472.0933s\n",
      "\titers: 200, epoch: 2 | loss: 0.0956471\n",
      "\tspeed: 0.1487s/iter; left time: 3238.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.31s\n",
      "Steps: 222 | Train Loss: 0.1067851 Vali Loss: 0.1402225 Test Loss: 0.1606241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768545\n",
      "\tspeed: 0.2397s/iter; left time: 5190.7345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670673\n",
      "\tspeed: 0.1484s/iter; left time: 3198.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0784635 Vali Loss: 0.1549436 Test Loss: 0.1626762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615202\n",
      "\tspeed: 0.2398s/iter; left time: 5139.7258s\n",
      "\titers: 200, epoch: 4 | loss: 0.0553973\n",
      "\tspeed: 0.1484s/iter; left time: 3166.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0621905 Vali Loss: 0.1486871 Test Loss: 0.1585362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0881757\n",
      "\tspeed: 0.2398s/iter; left time: 5086.7055s\n",
      "\titers: 200, epoch: 5 | loss: 0.0501511\n",
      "\tspeed: 0.1487s/iter; left time: 3139.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.12s\n",
      "Steps: 222 | Train Loss: 0.0527247 Vali Loss: 0.1394723 Test Loss: 0.1576203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0477496\n",
      "\tspeed: 0.2399s/iter; left time: 5035.0269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474090\n",
      "\tspeed: 0.1484s/iter; left time: 3101.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0484712 Vali Loss: 0.1370355 Test Loss: 0.1556998\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412586\n",
      "\tspeed: 0.2400s/iter; left time: 4983.5867s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407524\n",
      "\tspeed: 0.1485s/iter; left time: 3069.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0431573 Vali Loss: 0.1348506 Test Loss: 0.1544424\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0423980\n",
      "\tspeed: 0.2402s/iter; left time: 4935.6244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422410\n",
      "\tspeed: 0.1487s/iter; left time: 3039.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0418209 Vali Loss: 0.1379111 Test Loss: 0.1536960\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0395810\n",
      "\tspeed: 0.2392s/iter; left time: 4861.3254s\n",
      "\titers: 200, epoch: 9 | loss: 0.0401174\n",
      "\tspeed: 0.1485s/iter; left time: 3003.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0393178 Vali Loss: 0.1330695 Test Loss: 0.1526520\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0376254\n",
      "\tspeed: 0.2403s/iter; left time: 4830.8311s\n",
      "\titers: 200, epoch: 10 | loss: 0.0342666\n",
      "\tspeed: 0.1487s/iter; left time: 2974.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0370651 Vali Loss: 0.1324363 Test Loss: 0.1522708\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0352456\n",
      "\tspeed: 0.2408s/iter; left time: 4787.1133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0371032\n",
      "\tspeed: 0.1487s/iter; left time: 2940.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.19s\n",
      "Steps: 222 | Train Loss: 0.0362890 Vali Loss: 0.1320634 Test Loss: 0.1527143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04341920092701912, rmse:0.20837274193763733, mae:0.1452433168888092, rse:0.7205820083618164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1165444\n",
      "\tspeed: 0.1494s/iter; left time: 3302.5688s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111383\n",
      "\tspeed: 0.1485s/iter; left time: 3267.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.1201055 Vali Loss: 0.1230098 Test Loss: 0.1451796\n",
      "Validation loss decreased (inf --> 0.123010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108082\n",
      "\tspeed: 0.2554s/iter; left time: 5588.7955s\n",
      "\titers: 200, epoch: 2 | loss: 0.0935105\n",
      "\tspeed: 0.1486s/iter; left time: 3235.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 222 | Train Loss: 0.1068995 Vali Loss: 0.1398159 Test Loss: 0.1669322\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0784802\n",
      "\tspeed: 0.2413s/iter; left time: 5226.1157s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735279\n",
      "\tspeed: 0.1487s/iter; left time: 3206.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0795587 Vali Loss: 0.1421815 Test Loss: 0.1656734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637211\n",
      "\tspeed: 0.2420s/iter; left time: 5186.7990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617426\n",
      "\tspeed: 0.1487s/iter; left time: 3171.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0648935 Vali Loss: 0.1376564 Test Loss: 0.1604086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552284\n",
      "\tspeed: 0.2417s/iter; left time: 5127.4756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0531027\n",
      "\tspeed: 0.1486s/iter; left time: 3137.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.17s\n",
      "Steps: 222 | Train Loss: 0.0553986 Vali Loss: 0.1340457 Test Loss: 0.1575819\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0478428\n",
      "\tspeed: 0.2412s/iter; left time: 5063.8890s\n",
      "\titers: 200, epoch: 6 | loss: 0.0523911\n",
      "\tspeed: 0.1486s/iter; left time: 3103.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0490555 Vali Loss: 0.1340929 Test Loss: 0.1550300\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459050\n",
      "\tspeed: 0.2413s/iter; left time: 5011.3346s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428679\n",
      "\tspeed: 0.1485s/iter; left time: 3069.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0447298 Vali Loss: 0.1341426 Test Loss: 0.1539580\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405288\n",
      "\tspeed: 0.2414s/iter; left time: 4960.5656s\n",
      "\titers: 200, epoch: 8 | loss: 0.0405174\n",
      "\tspeed: 0.1482s/iter; left time: 3030.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0419976 Vali Loss: 0.1378684 Test Loss: 0.1581065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0382658\n",
      "\tspeed: 0.2406s/iter; left time: 4891.0947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0395453\n",
      "\tspeed: 0.1486s/iter; left time: 3005.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0404064 Vali Loss: 0.1317059 Test Loss: 0.1522986\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378837\n",
      "\tspeed: 0.2412s/iter; left time: 4848.7059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0369272\n",
      "\tspeed: 0.1485s/iter; left time: 2970.4434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0381774 Vali Loss: 0.1314865 Test Loss: 0.1513584\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0358450\n",
      "\tspeed: 0.2409s/iter; left time: 4789.2445s\n",
      "\titers: 200, epoch: 11 | loss: 0.0374405\n",
      "\tspeed: 0.1488s/iter; left time: 2943.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0363881 Vali Loss: 0.1307979 Test Loss: 0.1516058\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04355882108211517, rmse:0.20870749652385712, mae:0.1451796293258667, rse:0.7217395901679993\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:36.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1177407\n",
      "\tspeed: 0.1745s/iter; left time: 3857.2506s\n",
      "\titers: 200, epoch: 1 | loss: 0.1147017\n",
      "\tspeed: 0.1503s/iter; left time: 3306.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.78s\n",
      "Steps: 222 | Train Loss: 0.1225829 Vali Loss: 0.1266081 Test Loss: 0.1497908\n",
      "Validation loss decreased (inf --> 0.126608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1123300\n",
      "\tspeed: 0.2887s/iter; left time: 6315.4126s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922024\n",
      "\tspeed: 0.1506s/iter; left time: 3280.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.1073465 Vali Loss: 0.1534391 Test Loss: 0.1633927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0715112\n",
      "\tspeed: 0.2422s/iter; left time: 5244.5989s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678034\n",
      "\tspeed: 0.1507s/iter; left time: 3249.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.0751841 Vali Loss: 0.1467895 Test Loss: 0.1613366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0583339\n",
      "\tspeed: 0.2417s/iter; left time: 5180.5349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547504\n",
      "\tspeed: 0.1506s/iter; left time: 3213.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0591856 Vali Loss: 0.1385507 Test Loss: 0.1562234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0566366\n",
      "\tspeed: 0.2418s/iter; left time: 5129.7138s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517352\n",
      "\tspeed: 0.1507s/iter; left time: 3182.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.61s\n",
      "Steps: 222 | Train Loss: 0.0521256 Vali Loss: 0.1398461 Test Loss: 0.1579931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0485455\n",
      "\tspeed: 0.2414s/iter; left time: 5066.7254s\n",
      "\titers: 200, epoch: 6 | loss: 0.0483025\n",
      "\tspeed: 0.1508s/iter; left time: 3149.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0479918 Vali Loss: 0.1388285 Test Loss: 0.1559225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412977\n",
      "\tspeed: 0.2417s/iter; left time: 5019.4109s\n",
      "\titers: 200, epoch: 7 | loss: 0.0430455\n",
      "\tspeed: 0.1509s/iter; left time: 3118.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0437611 Vali Loss: 0.1360448 Test Loss: 0.1562288\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0412615\n",
      "\tspeed: 0.2412s/iter; left time: 4956.3507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435497\n",
      "\tspeed: 0.1508s/iter; left time: 3084.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0422933 Vali Loss: 0.1364408 Test Loss: 0.1566917\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0399560\n",
      "\tspeed: 0.2421s/iter; left time: 4920.5603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0365216\n",
      "\tspeed: 0.1508s/iter; left time: 3049.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0392865 Vali Loss: 0.1353271 Test Loss: 0.1550491\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0372904\n",
      "\tspeed: 0.2423s/iter; left time: 4869.9806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402687\n",
      "\tspeed: 0.1511s/iter; left time: 3022.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.69s\n",
      "Steps: 222 | Train Loss: 0.0405217 Vali Loss: 0.1355167 Test Loss: 0.1553616\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355937\n",
      "\tspeed: 0.2413s/iter; left time: 4797.8155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0380037\n",
      "\tspeed: 0.1509s/iter; left time: 2984.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0374547 Vali Loss: 0.1346184 Test Loss: 0.1547808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045506544411182404, rmse:0.21332262456417084, mae:0.14979074895381927, rse:0.7396202087402344\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1164795\n",
      "\tspeed: 0.1520s/iter; left time: 3360.0338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1178308\n",
      "\tspeed: 0.1507s/iter; left time: 3315.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.1227937 Vali Loss: 0.1269568 Test Loss: 0.1500853\n",
      "Validation loss decreased (inf --> 0.126957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1080633\n",
      "\tspeed: 0.2832s/iter; left time: 6196.1052s\n",
      "\titers: 200, epoch: 2 | loss: 0.0911027\n",
      "\tspeed: 0.1506s/iter; left time: 3279.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.63s\n",
      "Steps: 222 | Train Loss: 0.1069387 Vali Loss: 0.1472872 Test Loss: 0.1704258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0766009\n",
      "\tspeed: 0.2439s/iter; left time: 5282.7984s\n",
      "\titers: 200, epoch: 3 | loss: 0.0693914\n",
      "\tspeed: 0.1509s/iter; left time: 3253.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.70s\n",
      "Steps: 222 | Train Loss: 0.0753113 Vali Loss: 0.1423926 Test Loss: 0.1651071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579466\n",
      "\tspeed: 0.2448s/iter; left time: 5246.9351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602810\n",
      "\tspeed: 0.1509s/iter; left time: 3220.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0602860 Vali Loss: 0.1388860 Test Loss: 0.1613450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0529091\n",
      "\tspeed: 0.2440s/iter; left time: 5175.5351s\n",
      "\titers: 200, epoch: 5 | loss: 0.0478933\n",
      "\tspeed: 0.1510s/iter; left time: 3188.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0532050 Vali Loss: 0.1397931 Test Loss: 0.1621394\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488900\n",
      "\tspeed: 0.2441s/iter; left time: 5124.3289s\n",
      "\titers: 200, epoch: 6 | loss: 0.0479902\n",
      "\tspeed: 0.1508s/iter; left time: 3151.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0490049 Vali Loss: 0.1387042 Test Loss: 0.1603853\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0458506\n",
      "\tspeed: 0.2432s/iter; left time: 5051.5493s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413319\n",
      "\tspeed: 0.1508s/iter; left time: 3117.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0447227 Vali Loss: 0.1376807 Test Loss: 0.1579818\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406756\n",
      "\tspeed: 0.2439s/iter; left time: 5010.5233s\n",
      "\titers: 200, epoch: 8 | loss: 0.0401300\n",
      "\tspeed: 0.1510s/iter; left time: 3086.5883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0428238 Vali Loss: 0.1362697 Test Loss: 0.1593084\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0425120\n",
      "\tspeed: 0.2438s/iter; left time: 4955.0447s\n",
      "\titers: 200, epoch: 9 | loss: 0.0428176\n",
      "\tspeed: 0.1510s/iter; left time: 3053.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0406100 Vali Loss: 0.1351584 Test Loss: 0.1575931\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0391058\n",
      "\tspeed: 0.2447s/iter; left time: 4919.7646s\n",
      "\titers: 200, epoch: 10 | loss: 0.0359502\n",
      "\tspeed: 0.1509s/iter; left time: 3018.1160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0388262 Vali Loss: 0.1357430 Test Loss: 0.1580252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0361103\n",
      "\tspeed: 0.2442s/iter; left time: 4854.2990s\n",
      "\titers: 200, epoch: 11 | loss: 0.0373988\n",
      "\tspeed: 0.1510s/iter; left time: 2987.8669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0368991 Vali Loss: 0.1348735 Test Loss: 0.1577474\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045674242079257965, rmse:0.2137153297662735, mae:0.15008527040481567, rse:0.7409817576408386\n",
      "Intermediate time for GB and pred_len 168: 00h:14m:55.51s\n",
      "Intermediate time for GB: 00h:43m:52.56s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1083394\n",
      "\tspeed: 0.0573s/iter; left time: 1277.9257s\n",
      "\titers: 200, epoch: 1 | loss: 0.0949330\n",
      "\tspeed: 0.0326s/iter; left time: 723.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.1146521 Vali Loss: 0.0854233 Test Loss: 0.0978887\n",
      "Validation loss decreased (inf --> 0.085423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694569\n",
      "\tspeed: 0.0622s/iter; left time: 1372.0866s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682702\n",
      "\tspeed: 0.0326s/iter; left time: 715.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0716935 Vali Loss: 0.0656114 Test Loss: 0.0731752\n",
      "Validation loss decreased (0.085423 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638887\n",
      "\tspeed: 0.0622s/iter; left time: 1358.9573s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625745\n",
      "\tspeed: 0.0326s/iter; left time: 709.3744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0642866 Vali Loss: 0.0630241 Test Loss: 0.0710565\n",
      "Validation loss decreased (0.065611 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611238\n",
      "\tspeed: 0.0620s/iter; left time: 1340.0211s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643910\n",
      "\tspeed: 0.0325s/iter; left time: 699.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0619596 Vali Loss: 0.0643963 Test Loss: 0.0716253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614629\n",
      "\tspeed: 0.0593s/iter; left time: 1268.8093s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591143\n",
      "\tspeed: 0.0325s/iter; left time: 692.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0598301 Vali Loss: 0.0612322 Test Loss: 0.0694189\n",
      "Validation loss decreased (0.063024 --> 0.061232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568408\n",
      "\tspeed: 0.0610s/iter; left time: 1292.2982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567278\n",
      "\tspeed: 0.0325s/iter; left time: 685.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0577446 Vali Loss: 0.0609693 Test Loss: 0.0682407\n",
      "Validation loss decreased (0.061232 --> 0.060969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562621\n",
      "\tspeed: 0.0612s/iter; left time: 1282.4153s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554868\n",
      "\tspeed: 0.0325s/iter; left time: 678.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0561681 Vali Loss: 0.0597783 Test Loss: 0.0675127\n",
      "Validation loss decreased (0.060969 --> 0.059778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569908\n",
      "\tspeed: 0.0611s/iter; left time: 1266.2956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577169\n",
      "\tspeed: 0.0325s/iter; left time: 671.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0544420 Vali Loss: 0.0602443 Test Loss: 0.0683316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521781\n",
      "\tspeed: 0.0602s/iter; left time: 1235.5452s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503141\n",
      "\tspeed: 0.0327s/iter; left time: 667.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0526811 Vali Loss: 0.0609316 Test Loss: 0.0681847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519583\n",
      "\tspeed: 0.0596s/iter; left time: 1208.3835s\n",
      "\titers: 200, epoch: 10 | loss: 0.0487051\n",
      "\tspeed: 0.0329s/iter; left time: 664.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0512578 Vali Loss: 0.0613501 Test Loss: 0.0695660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517822\n",
      "\tspeed: 0.0598s/iter; left time: 1200.4242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482223\n",
      "\tspeed: 0.0327s/iter; left time: 652.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0498223 Vali Loss: 0.0620379 Test Loss: 0.0702392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494305\n",
      "\tspeed: 0.0599s/iter; left time: 1188.9516s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481998\n",
      "\tspeed: 0.0327s/iter; left time: 645.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0483653 Vali Loss: 0.0612045 Test Loss: 0.0701841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0462038\n",
      "\tspeed: 0.0607s/iter; left time: 1190.1800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461890\n",
      "\tspeed: 0.0328s/iter; left time: 639.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0470476 Vali Loss: 0.0618377 Test Loss: 0.0701277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0474969\n",
      "\tspeed: 0.0600s/iter; left time: 1164.1216s\n",
      "\titers: 200, epoch: 14 | loss: 0.0462358\n",
      "\tspeed: 0.0327s/iter; left time: 631.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0460021 Vali Loss: 0.0619138 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441642\n",
      "\tspeed: 0.0601s/iter; left time: 1152.4789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437523\n",
      "\tspeed: 0.0327s/iter; left time: 623.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0449358 Vali Loss: 0.0615214 Test Loss: 0.0704811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440189\n",
      "\tspeed: 0.0606s/iter; left time: 1146.9950s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432764\n",
      "\tspeed: 0.0328s/iter; left time: 618.5290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0439870 Vali Loss: 0.0616211 Test Loss: 0.0707664\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423084\n",
      "\tspeed: 0.0598s/iter; left time: 1118.4282s\n",
      "\titers: 200, epoch: 17 | loss: 0.0415025\n",
      "\tspeed: 0.0328s/iter; left time: 610.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0431494 Vali Loss: 0.0620262 Test Loss: 0.0715410\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01133799646049738, rmse:0.10648002475500107, mae:0.06751272827386856, rse:0.3133578300476074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1059176\n",
      "\tspeed: 0.0346s/iter; left time: 772.7058s\n",
      "\titers: 200, epoch: 1 | loss: 0.0954594\n",
      "\tspeed: 0.0327s/iter; left time: 726.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.1132807 Vali Loss: 0.0858611 Test Loss: 0.0978220\n",
      "Validation loss decreased (inf --> 0.085861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672946\n",
      "\tspeed: 0.0635s/iter; left time: 1401.7909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0662497\n",
      "\tspeed: 0.0326s/iter; left time: 715.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0716624 Vali Loss: 0.0645302 Test Loss: 0.0728868\n",
      "Validation loss decreased (0.085861 --> 0.064530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636461\n",
      "\tspeed: 0.0619s/iter; left time: 1352.4904s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644167\n",
      "\tspeed: 0.0328s/iter; left time: 712.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0639991 Vali Loss: 0.0630432 Test Loss: 0.0709006\n",
      "Validation loss decreased (0.064530 --> 0.063043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621769\n",
      "\tspeed: 0.0621s/iter; left time: 1342.1702s\n",
      "\titers: 200, epoch: 4 | loss: 0.0600844\n",
      "\tspeed: 0.0326s/iter; left time: 701.0833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0615069 Vali Loss: 0.0610647 Test Loss: 0.0695123\n",
      "Validation loss decreased (0.063043 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0606961\n",
      "\tspeed: 0.0630s/iter; left time: 1348.5926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597096\n",
      "\tspeed: 0.0327s/iter; left time: 696.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0594661 Vali Loss: 0.0604619 Test Loss: 0.0694347\n",
      "Validation loss decreased (0.061065 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590119\n",
      "\tspeed: 0.0623s/iter; left time: 1319.7344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569254\n",
      "\tspeed: 0.0327s/iter; left time: 690.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0579130 Vali Loss: 0.0610369 Test Loss: 0.0684163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0548901\n",
      "\tspeed: 0.0603s/iter; left time: 1263.4103s\n",
      "\titers: 200, epoch: 7 | loss: 0.0539524\n",
      "\tspeed: 0.0327s/iter; left time: 680.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0559329 Vali Loss: 0.0594218 Test Loss: 0.0678336\n",
      "Validation loss decreased (0.060462 --> 0.059422).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0538018\n",
      "\tspeed: 0.0648s/iter; left time: 1344.4634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0530818\n",
      "\tspeed: 0.0325s/iter; left time: 671.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0542583 Vali Loss: 0.0599612 Test Loss: 0.0689581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552536\n",
      "\tspeed: 0.0601s/iter; left time: 1232.8386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516640\n",
      "\tspeed: 0.0325s/iter; left time: 663.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0527426 Vali Loss: 0.0591997 Test Loss: 0.0679362\n",
      "Validation loss decreased (0.059422 --> 0.059200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536080\n",
      "\tspeed: 0.0617s/iter; left time: 1251.9853s\n",
      "\titers: 200, epoch: 10 | loss: 0.0499571\n",
      "\tspeed: 0.0325s/iter; left time: 656.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0512842 Vali Loss: 0.0599653 Test Loss: 0.0687808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517187\n",
      "\tspeed: 0.0604s/iter; left time: 1210.6819s\n",
      "\titers: 200, epoch: 11 | loss: 0.0499973\n",
      "\tspeed: 0.0326s/iter; left time: 651.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0497935 Vali Loss: 0.0604572 Test Loss: 0.0696274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468627\n",
      "\tspeed: 0.0595s/iter; left time: 1181.2420s\n",
      "\titers: 200, epoch: 12 | loss: 0.0489540\n",
      "\tspeed: 0.0328s/iter; left time: 648.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0483913 Vali Loss: 0.0602030 Test Loss: 0.0697745\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496078\n",
      "\tspeed: 0.0598s/iter; left time: 1172.5827s\n",
      "\titers: 200, epoch: 13 | loss: 0.0476634\n",
      "\tspeed: 0.0323s/iter; left time: 630.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0473625 Vali Loss: 0.0604081 Test Loss: 0.0700828\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464205\n",
      "\tspeed: 0.0594s/iter; left time: 1152.2500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0435993\n",
      "\tspeed: 0.0323s/iter; left time: 623.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0461338 Vali Loss: 0.0605141 Test Loss: 0.0701649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0460268\n",
      "\tspeed: 0.0599s/iter; left time: 1147.0383s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453027\n",
      "\tspeed: 0.0323s/iter; left time: 616.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0451875 Vali Loss: 0.0609419 Test Loss: 0.0697475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0459039\n",
      "\tspeed: 0.0604s/iter; left time: 1143.9558s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434766\n",
      "\tspeed: 0.0326s/iter; left time: 614.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0443061 Vali Loss: 0.0615374 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0443573\n",
      "\tspeed: 0.0599s/iter; left time: 1122.0651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425250\n",
      "\tspeed: 0.0324s/iter; left time: 603.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0435606 Vali Loss: 0.0604851 Test Loss: 0.0707585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413324\n",
      "\tspeed: 0.0602s/iter; left time: 1113.7053s\n",
      "\titers: 200, epoch: 18 | loss: 0.0445203\n",
      "\tspeed: 0.0325s/iter; left time: 598.5775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0428060 Vali Loss: 0.0611732 Test Loss: 0.0707645\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0436631\n",
      "\tspeed: 0.0596s/iter; left time: 1088.8430s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429139\n",
      "\tspeed: 0.0325s/iter; left time: 591.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0421968 Vali Loss: 0.0612346 Test Loss: 0.0706914\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011598608456552029, rmse:0.10769683867692947, mae:0.06793618202209473, rse:0.31693875789642334\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:48.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1167209\n",
      "\tspeed: 0.0581s/iter; left time: 1296.1155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1056875\n",
      "\tspeed: 0.0331s/iter; left time: 735.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.1227398 Vali Loss: 0.0988195 Test Loss: 0.1124716\n",
      "Validation loss decreased (inf --> 0.098819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888136\n",
      "\tspeed: 0.0650s/iter; left time: 1434.6344s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841860\n",
      "\tspeed: 0.0332s/iter; left time: 730.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0888445 Vali Loss: 0.0866662 Test Loss: 0.0969930\n",
      "Validation loss decreased (0.098819 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807913\n",
      "\tspeed: 0.0628s/iter; left time: 1372.0226s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785247\n",
      "\tspeed: 0.0331s/iter; left time: 720.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0809936 Vali Loss: 0.0850435 Test Loss: 0.0962780\n",
      "Validation loss decreased (0.086666 --> 0.085044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0752124\n",
      "\tspeed: 0.0652s/iter; left time: 1409.4935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712232\n",
      "\tspeed: 0.0332s/iter; left time: 714.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0751077 Vali Loss: 0.0873182 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689497\n",
      "\tspeed: 0.0621s/iter; left time: 1328.1937s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683093\n",
      "\tspeed: 0.0332s/iter; left time: 707.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0684474 Vali Loss: 0.0864051 Test Loss: 0.1003118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626845\n",
      "\tspeed: 0.0614s/iter; left time: 1300.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603980\n",
      "\tspeed: 0.0331s/iter; left time: 698.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0631113 Vali Loss: 0.0877236 Test Loss: 0.1011920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590933\n",
      "\tspeed: 0.0609s/iter; left time: 1275.9670s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597084\n",
      "\tspeed: 0.0331s/iter; left time: 690.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0589081 Vali Loss: 0.0872310 Test Loss: 0.1004953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552450\n",
      "\tspeed: 0.0611s/iter; left time: 1265.8009s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551953\n",
      "\tspeed: 0.0331s/iter; left time: 683.5963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0555059 Vali Loss: 0.0881087 Test Loss: 0.1008888\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524991\n",
      "\tspeed: 0.0613s/iter; left time: 1257.9821s\n",
      "\titers: 200, epoch: 9 | loss: 0.0530768\n",
      "\tspeed: 0.0332s/iter; left time: 677.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0527471 Vali Loss: 0.0886423 Test Loss: 0.1020612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515361\n",
      "\tspeed: 0.0615s/iter; left time: 1248.0465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495522\n",
      "\tspeed: 0.0333s/iter; left time: 672.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0506641 Vali Loss: 0.0878667 Test Loss: 0.1018857\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0495449\n",
      "\tspeed: 0.0622s/iter; left time: 1247.0062s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484085\n",
      "\tspeed: 0.0335s/iter; left time: 668.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0487303 Vali Loss: 0.0874963 Test Loss: 0.1018826\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460823\n",
      "\tspeed: 0.0613s/iter; left time: 1215.3686s\n",
      "\titers: 200, epoch: 12 | loss: 0.0487627\n",
      "\tspeed: 0.0331s/iter; left time: 653.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0472277 Vali Loss: 0.0875905 Test Loss: 0.1023017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0471489\n",
      "\tspeed: 0.0612s/iter; left time: 1201.1524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0454935\n",
      "\tspeed: 0.0331s/iter; left time: 645.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0459133 Vali Loss: 0.0874007 Test Loss: 0.1019594\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021271303296089172, rmse:0.14584684371948242, mae:0.09627804905176163, rse:0.4284541606903076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204117\n",
      "\tspeed: 0.0347s/iter; left time: 773.2841s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046546\n",
      "\tspeed: 0.0330s/iter; left time: 733.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.1222082 Vali Loss: 0.0986339 Test Loss: 0.1127096\n",
      "Validation loss decreased (inf --> 0.098634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892475\n",
      "\tspeed: 0.0637s/iter; left time: 1405.5402s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875973\n",
      "\tspeed: 0.0331s/iter; left time: 727.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0889160 Vali Loss: 0.0860521 Test Loss: 0.0965959\n",
      "Validation loss decreased (0.098634 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820314\n",
      "\tspeed: 0.0746s/iter; left time: 1629.4846s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766245\n",
      "\tspeed: 0.0331s/iter; left time: 720.1125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0810734 Vali Loss: 0.0846253 Test Loss: 0.0976963\n",
      "Validation loss decreased (0.086052 --> 0.084625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731675\n",
      "\tspeed: 0.0660s/iter; left time: 1426.5197s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741658\n",
      "\tspeed: 0.0335s/iter; left time: 721.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0754243 Vali Loss: 0.0878123 Test Loss: 0.1005267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0716164\n",
      "\tspeed: 0.0616s/iter; left time: 1317.6022s\n",
      "\titers: 200, epoch: 5 | loss: 0.0671426\n",
      "\tspeed: 0.0331s/iter; left time: 705.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0690027 Vali Loss: 0.0878285 Test Loss: 0.1006422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641997\n",
      "\tspeed: 0.0612s/iter; left time: 1295.4053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0674796\n",
      "\tspeed: 0.0331s/iter; left time: 697.8527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0635019 Vali Loss: 0.0878592 Test Loss: 0.1024417\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591606\n",
      "\tspeed: 0.0615s/iter; left time: 1288.8847s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583029\n",
      "\tspeed: 0.0331s/iter; left time: 691.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0588996 Vali Loss: 0.0877868 Test Loss: 0.1020480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553827\n",
      "\tspeed: 0.0614s/iter; left time: 1272.8050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554482\n",
      "\tspeed: 0.0332s/iter; left time: 684.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0554791 Vali Loss: 0.0881074 Test Loss: 0.1035934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0541625\n",
      "\tspeed: 0.0616s/iter; left time: 1263.4282s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502246\n",
      "\tspeed: 0.0332s/iter; left time: 676.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0527017 Vali Loss: 0.0881722 Test Loss: 0.1024241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0498284\n",
      "\tspeed: 0.0612s/iter; left time: 1240.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489367\n",
      "\tspeed: 0.0331s/iter; left time: 668.2251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0506088 Vali Loss: 0.0888529 Test Loss: 0.1031139\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476753\n",
      "\tspeed: 0.0623s/iter; left time: 1249.1649s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481353\n",
      "\tspeed: 0.0331s/iter; left time: 660.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0486823 Vali Loss: 0.0881064 Test Loss: 0.1029631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0461587\n",
      "\tspeed: 0.0609s/iter; left time: 1208.6124s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474565\n",
      "\tspeed: 0.0330s/iter; left time: 650.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0471709 Vali Loss: 0.0887941 Test Loss: 0.1031620\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465209\n",
      "\tspeed: 0.0616s/iter; left time: 1207.6783s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457823\n",
      "\tspeed: 0.0332s/iter; left time: 647.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0457775 Vali Loss: 0.0880506 Test Loss: 0.1036356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021871840581297874, rmse:0.1478913128376007, mae:0.09769626706838608, rse:0.4344601631164551\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:21.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163252\n",
      "\tspeed: 0.0624s/iter; left time: 1385.7644s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111509\n",
      "\tspeed: 0.0337s/iter; left time: 745.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1248032 Vali Loss: 0.1023557 Test Loss: 0.1157608\n",
      "Validation loss decreased (inf --> 0.102356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920324\n",
      "\tspeed: 0.0733s/iter; left time: 1611.7066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905396\n",
      "\tspeed: 0.0337s/iter; left time: 738.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0927347 Vali Loss: 0.0911596 Test Loss: 0.1026373\n",
      "Validation loss decreased (0.102356 --> 0.091160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813993\n",
      "\tspeed: 0.0775s/iter; left time: 1685.0918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804934\n",
      "\tspeed: 0.0338s/iter; left time: 732.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0837477 Vali Loss: 0.0901361 Test Loss: 0.1034494\n",
      "Validation loss decreased (0.091160 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745005\n",
      "\tspeed: 0.0755s/iter; left time: 1625.6449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743757\n",
      "\tspeed: 0.0338s/iter; left time: 723.6099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0773343 Vali Loss: 0.0920163 Test Loss: 0.1045371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717543\n",
      "\tspeed: 0.0623s/iter; left time: 1327.8117s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683926\n",
      "\tspeed: 0.0339s/iter; left time: 717.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0706961 Vali Loss: 0.0927095 Test Loss: 0.1056051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635267\n",
      "\tspeed: 0.0626s/iter; left time: 1319.7380s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626201\n",
      "\tspeed: 0.0338s/iter; left time: 709.7059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0648583 Vali Loss: 0.0928507 Test Loss: 0.1066073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594731\n",
      "\tspeed: 0.0620s/iter; left time: 1292.7169s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574201\n",
      "\tspeed: 0.0340s/iter; left time: 705.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0604445 Vali Loss: 0.0937179 Test Loss: 0.1071184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578186\n",
      "\tspeed: 0.0640s/iter; left time: 1321.4657s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562383\n",
      "\tspeed: 0.0338s/iter; left time: 694.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0571987 Vali Loss: 0.0920181 Test Loss: 0.1071269\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552342\n",
      "\tspeed: 0.0626s/iter; left time: 1277.5305s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548123\n",
      "\tspeed: 0.0339s/iter; left time: 687.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0545950 Vali Loss: 0.0930666 Test Loss: 0.1075234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529762\n",
      "\tspeed: 0.0622s/iter; left time: 1255.6336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518859\n",
      "\tspeed: 0.0339s/iter; left time: 681.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0524777 Vali Loss: 0.0920488 Test Loss: 0.1072294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0511605\n",
      "\tspeed: 0.0620s/iter; left time: 1237.8479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0511627\n",
      "\tspeed: 0.0339s/iter; left time: 674.3273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0506818 Vali Loss: 0.0927317 Test Loss: 0.1083499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0496722\n",
      "\tspeed: 0.0624s/iter; left time: 1232.3483s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484021\n",
      "\tspeed: 0.0339s/iter; left time: 666.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0491604 Vali Loss: 0.0922555 Test Loss: 0.1075642\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480842\n",
      "\tspeed: 0.0623s/iter; left time: 1215.7753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0480131\n",
      "\tspeed: 0.0340s/iter; left time: 659.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0478748 Vali Loss: 0.0920726 Test Loss: 0.1082650\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0238569937646389, rmse:0.15445709228515625, mae:0.10344940423965454, rse:0.45378103852272034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175357\n",
      "\tspeed: 0.0360s/iter; left time: 799.3014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085309\n",
      "\tspeed: 0.0339s/iter; left time: 749.2484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.1244877 Vali Loss: 0.1024658 Test Loss: 0.1162681\n",
      "Validation loss decreased (inf --> 0.102466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892978\n",
      "\tspeed: 0.0724s/iter; left time: 1591.8888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0858404\n",
      "\tspeed: 0.0339s/iter; left time: 742.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0925368 Vali Loss: 0.0931649 Test Loss: 0.1041178\n",
      "Validation loss decreased (0.102466 --> 0.093165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0832203\n",
      "\tspeed: 0.0679s/iter; left time: 1477.8758s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824200\n",
      "\tspeed: 0.0339s/iter; left time: 733.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0840002 Vali Loss: 0.0918773 Test Loss: 0.1027539\n",
      "Validation loss decreased (0.093165 --> 0.091877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755718\n",
      "\tspeed: 0.0684s/iter; left time: 1473.3897s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789680\n",
      "\tspeed: 0.0340s/iter; left time: 728.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0778846 Vali Loss: 0.0915824 Test Loss: 0.1033742\n",
      "Validation loss decreased (0.091877 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740893\n",
      "\tspeed: 0.0689s/iter; left time: 1468.1146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0704942\n",
      "\tspeed: 0.0339s/iter; left time: 718.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0719597 Vali Loss: 0.0934459 Test Loss: 0.1050283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0674252\n",
      "\tspeed: 0.0634s/iter; left time: 1336.3706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634718\n",
      "\tspeed: 0.0340s/iter; left time: 713.3638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0659032 Vali Loss: 0.0927102 Test Loss: 0.1051720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629653\n",
      "\tspeed: 0.0642s/iter; left time: 1338.9348s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605651\n",
      "\tspeed: 0.0342s/iter; left time: 709.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0613759 Vali Loss: 0.0924244 Test Loss: 0.1051302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563948\n",
      "\tspeed: 0.0629s/iter; left time: 1297.6812s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562144\n",
      "\tspeed: 0.0339s/iter; left time: 696.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0577199 Vali Loss: 0.0931844 Test Loss: 0.1064090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559244\n",
      "\tspeed: 0.0636s/iter; left time: 1298.2004s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532067\n",
      "\tspeed: 0.0339s/iter; left time: 689.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0549016 Vali Loss: 0.0936035 Test Loss: 0.1066466\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514232\n",
      "\tspeed: 0.0628s/iter; left time: 1268.0533s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512180\n",
      "\tspeed: 0.0338s/iter; left time: 680.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0526190 Vali Loss: 0.0929514 Test Loss: 0.1060959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514014\n",
      "\tspeed: 0.0625s/iter; left time: 1248.3156s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494085\n",
      "\tspeed: 0.0340s/iter; left time: 675.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0508202 Vali Loss: 0.0938980 Test Loss: 0.1071277\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0495044\n",
      "\tspeed: 0.0643s/iter; left time: 1270.2817s\n",
      "\titers: 200, epoch: 12 | loss: 0.0483764\n",
      "\tspeed: 0.0339s/iter; left time: 666.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0491536 Vali Loss: 0.0933724 Test Loss: 0.1070942\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0487324\n",
      "\tspeed: 0.0627s/iter; left time: 1224.8408s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466656\n",
      "\tspeed: 0.0339s/iter; left time: 658.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0478594 Vali Loss: 0.0935658 Test Loss: 0.1077204\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470098\n",
      "\tspeed: 0.0633s/iter; left time: 1221.3799s\n",
      "\titers: 200, epoch: 14 | loss: 0.0454411\n",
      "\tspeed: 0.0340s/iter; left time: 652.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.0467149 Vali Loss: 0.0932253 Test Loss: 0.1074122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023433756083250046, rmse:0.15308088064193726, mae:0.10337422043085098, rse:0.44973787665367126\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:41.40s\n",
      "Intermediate time for ES: 00h:14m:52.14s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0825739\n",
      "\tspeed: 0.0440s/iter; left time: 989.1272s\n",
      "\titers: 200, epoch: 1 | loss: 0.0720544\n",
      "\tspeed: 0.0179s/iter; left time: 400.4240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 226 | Train Loss: 0.0892576 Vali Loss: 0.0763335 Test Loss: 0.0833760\n",
      "Validation loss decreased (inf --> 0.076333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0519041\n",
      "\tspeed: 0.0395s/iter; left time: 879.1817s\n",
      "\titers: 200, epoch: 2 | loss: 0.0478711\n",
      "\tspeed: 0.0180s/iter; left time: 399.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0525726 Vali Loss: 0.0569420 Test Loss: 0.0612847\n",
      "Validation loss decreased (0.076333 --> 0.056942).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0440858\n",
      "\tspeed: 0.0394s/iter; left time: 868.8589s\n",
      "\titers: 200, epoch: 3 | loss: 0.0461644\n",
      "\tspeed: 0.0181s/iter; left time: 397.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0464609 Vali Loss: 0.0550702 Test Loss: 0.0593229\n",
      "Validation loss decreased (0.056942 --> 0.055070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0446937\n",
      "\tspeed: 0.0383s/iter; left time: 834.9939s\n",
      "\titers: 200, epoch: 4 | loss: 0.0430271\n",
      "\tspeed: 0.0185s/iter; left time: 402.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0446763 Vali Loss: 0.0546017 Test Loss: 0.0593835\n",
      "Validation loss decreased (0.055070 --> 0.054602).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449143\n",
      "\tspeed: 0.0391s/iter; left time: 845.1750s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423666\n",
      "\tspeed: 0.0179s/iter; left time: 384.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0431179 Vali Loss: 0.0536028 Test Loss: 0.0577287\n",
      "Validation loss decreased (0.054602 --> 0.053603).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0447902\n",
      "\tspeed: 0.0414s/iter; left time: 884.3643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0402884\n",
      "\tspeed: 0.0179s/iter; left time: 380.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0419177 Vali Loss: 0.0532793 Test Loss: 0.0576561\n",
      "Validation loss decreased (0.053603 --> 0.053279).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0400641\n",
      "\tspeed: 0.0380s/iter; left time: 803.0530s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413724\n",
      "\tspeed: 0.0180s/iter; left time: 377.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0406169 Vali Loss: 0.0529187 Test Loss: 0.0586069\n",
      "Validation loss decreased (0.053279 --> 0.052919).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422125\n",
      "\tspeed: 0.0385s/iter; left time: 804.8030s\n",
      "\titers: 200, epoch: 8 | loss: 0.0390262\n",
      "\tspeed: 0.0177s/iter; left time: 368.7307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0396278 Vali Loss: 0.0532204 Test Loss: 0.0586753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396171\n",
      "\tspeed: 0.0362s/iter; left time: 749.2150s\n",
      "\titers: 200, epoch: 9 | loss: 0.0392884\n",
      "\tspeed: 0.0178s/iter; left time: 365.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0383368 Vali Loss: 0.0533056 Test Loss: 0.0592961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352243\n",
      "\tspeed: 0.0365s/iter; left time: 746.7584s\n",
      "\titers: 200, epoch: 10 | loss: 0.0382171\n",
      "\tspeed: 0.0178s/iter; left time: 361.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0371329 Vali Loss: 0.0542546 Test Loss: 0.0600371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0372575\n",
      "\tspeed: 0.0366s/iter; left time: 741.1142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0357848\n",
      "\tspeed: 0.0179s/iter; left time: 359.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0361327 Vali Loss: 0.0540272 Test Loss: 0.0606850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0339495\n",
      "\tspeed: 0.0370s/iter; left time: 740.6702s\n",
      "\titers: 200, epoch: 12 | loss: 0.0343725\n",
      "\tspeed: 0.0178s/iter; left time: 355.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0351717 Vali Loss: 0.0541665 Test Loss: 0.0607401\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0350991\n",
      "\tspeed: 0.0367s/iter; left time: 725.8432s\n",
      "\titers: 200, epoch: 13 | loss: 0.0356509\n",
      "\tspeed: 0.0182s/iter; left time: 358.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0342767 Vali Loss: 0.0543875 Test Loss: 0.0612607\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0323812\n",
      "\tspeed: 0.0368s/iter; left time: 719.6369s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324937\n",
      "\tspeed: 0.0178s/iter; left time: 347.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0336061 Vali Loss: 0.0549471 Test Loss: 0.0617569\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0328720\n",
      "\tspeed: 0.0369s/iter; left time: 712.8441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0327561\n",
      "\tspeed: 0.0177s/iter; left time: 341.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0329703 Vali Loss: 0.0550517 Test Loss: 0.0612711\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0303529\n",
      "\tspeed: 0.0369s/iter; left time: 705.4486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0308379\n",
      "\tspeed: 0.0179s/iter; left time: 340.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0323310 Vali Loss: 0.0550910 Test Loss: 0.0609389\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0322276\n",
      "\tspeed: 0.0368s/iter; left time: 694.5076s\n",
      "\titers: 200, epoch: 17 | loss: 0.0307707\n",
      "\tspeed: 0.0177s/iter; left time: 333.4214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0318553 Vali Loss: 0.0549174 Test Loss: 0.0618004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0108979232609272, rmse:0.1043931171298027, mae:0.05860685557126999, rse:0.4027457535266876\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0808246\n",
      "\tspeed: 0.0211s/iter; left time: 474.1064s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777871\n",
      "\tspeed: 0.0188s/iter; left time: 420.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0886302 Vali Loss: 0.0765412 Test Loss: 0.0835635\n",
      "Validation loss decreased (inf --> 0.076541).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0512616\n",
      "\tspeed: 0.0396s/iter; left time: 882.4648s\n",
      "\titers: 200, epoch: 2 | loss: 0.0489905\n",
      "\tspeed: 0.0178s/iter; left time: 394.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0525013 Vali Loss: 0.0562015 Test Loss: 0.0609805\n",
      "Validation loss decreased (0.076541 --> 0.056202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472980\n",
      "\tspeed: 0.0394s/iter; left time: 867.7970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0457077\n",
      "\tspeed: 0.0178s/iter; left time: 391.5989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0466549 Vali Loss: 0.0544775 Test Loss: 0.0589031\n",
      "Validation loss decreased (0.056202 --> 0.054478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0453555\n",
      "\tspeed: 0.0389s/iter; left time: 849.9809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0427258\n",
      "\tspeed: 0.0181s/iter; left time: 392.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0447521 Vali Loss: 0.0536225 Test Loss: 0.0581660\n",
      "Validation loss decreased (0.054478 --> 0.053622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0439419\n",
      "\tspeed: 0.0387s/iter; left time: 836.7352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437575\n",
      "\tspeed: 0.0177s/iter; left time: 381.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0432652 Vali Loss: 0.0528611 Test Loss: 0.0578288\n",
      "Validation loss decreased (0.053622 --> 0.052861).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0424836\n",
      "\tspeed: 0.0397s/iter; left time: 849.0424s\n",
      "\titers: 200, epoch: 6 | loss: 0.0434853\n",
      "\tspeed: 0.0178s/iter; left time: 378.7619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0422494 Vali Loss: 0.0533285 Test Loss: 0.0580732\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412046\n",
      "\tspeed: 0.0369s/iter; left time: 781.2850s\n",
      "\titers: 200, epoch: 7 | loss: 0.0417114\n",
      "\tspeed: 0.0178s/iter; left time: 373.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0411409 Vali Loss: 0.0528526 Test Loss: 0.0578768\n",
      "Validation loss decreased (0.052861 --> 0.052853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405956\n",
      "\tspeed: 0.0383s/iter; left time: 801.0011s\n",
      "\titers: 200, epoch: 8 | loss: 0.0414334\n",
      "\tspeed: 0.0178s/iter; left time: 370.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0399912 Vali Loss: 0.0526390 Test Loss: 0.0583228\n",
      "Validation loss decreased (0.052853 --> 0.052639).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0392249\n",
      "\tspeed: 0.0396s/iter; left time: 819.5750s\n",
      "\titers: 200, epoch: 9 | loss: 0.0397011\n",
      "\tspeed: 0.0177s/iter; left time: 364.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0390025 Vali Loss: 0.0525965 Test Loss: 0.0577715\n",
      "Validation loss decreased (0.052639 --> 0.052597).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352390\n",
      "\tspeed: 0.0403s/iter; left time: 825.6378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0390021\n",
      "\tspeed: 0.0204s/iter; left time: 414.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0378733 Vali Loss: 0.0526242 Test Loss: 0.0583718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355981\n",
      "\tspeed: 0.0372s/iter; left time: 752.0537s\n",
      "\titers: 200, epoch: 11 | loss: 0.0361680\n",
      "\tspeed: 0.0180s/iter; left time: 362.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0368099 Vali Loss: 0.0531015 Test Loss: 0.0590410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0343426\n",
      "\tspeed: 0.0373s/iter; left time: 745.7549s\n",
      "\titers: 200, epoch: 12 | loss: 0.0386787\n",
      "\tspeed: 0.0177s/iter; left time: 352.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0359604 Vali Loss: 0.0532657 Test Loss: 0.0590416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0358210\n",
      "\tspeed: 0.0370s/iter; left time: 732.6723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0385372\n",
      "\tspeed: 0.0185s/iter; left time: 364.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0351373 Vali Loss: 0.0539517 Test Loss: 0.0593859\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0342100\n",
      "\tspeed: 0.0372s/iter; left time: 728.1848s\n",
      "\titers: 200, epoch: 14 | loss: 0.0354560\n",
      "\tspeed: 0.0180s/iter; left time: 349.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0343315 Vali Loss: 0.0538370 Test Loss: 0.0604549\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0339227\n",
      "\tspeed: 0.0368s/iter; left time: 712.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0324195\n",
      "\tspeed: 0.0177s/iter; left time: 341.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0336581 Vali Loss: 0.0539099 Test Loss: 0.0599087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0363340\n",
      "\tspeed: 0.0375s/iter; left time: 716.4222s\n",
      "\titers: 200, epoch: 16 | loss: 0.0296580\n",
      "\tspeed: 0.0178s/iter; left time: 338.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0331135 Vali Loss: 0.0539095 Test Loss: 0.0599806\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0320749\n",
      "\tspeed: 0.0379s/iter; left time: 714.9103s\n",
      "\titers: 200, epoch: 17 | loss: 0.0329088\n",
      "\tspeed: 0.0178s/iter; left time: 334.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0326186 Vali Loss: 0.0540928 Test Loss: 0.0603553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0313287\n",
      "\tspeed: 0.0379s/iter; left time: 706.8323s\n",
      "\titers: 200, epoch: 18 | loss: 0.0325896\n",
      "\tspeed: 0.0179s/iter; left time: 331.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0321234 Vali Loss: 0.0542886 Test Loss: 0.0603496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0324607\n",
      "\tspeed: 0.0366s/iter; left time: 674.4744s\n",
      "\titers: 200, epoch: 19 | loss: 0.0300568\n",
      "\tspeed: 0.0179s/iter; left time: 327.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0317324 Vali Loss: 0.0542460 Test Loss: 0.0601043\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010704690590500832, rmse:0.10346347838640213, mae:0.0577714666724205, rse:0.39915919303894043\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:33.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0949994\n",
      "\tspeed: 0.0456s/iter; left time: 1022.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.0818396\n",
      "\tspeed: 0.0181s/iter; left time: 404.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0984444 Vali Loss: 0.0880076 Test Loss: 0.0994513\n",
      "Validation loss decreased (inf --> 0.088008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0642481\n",
      "\tspeed: 0.0411s/iter; left time: 910.9899s\n",
      "\titers: 200, epoch: 2 | loss: 0.0622116\n",
      "\tspeed: 0.0182s/iter; left time: 400.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0677669 Vali Loss: 0.0737542 Test Loss: 0.0843380\n",
      "Validation loss decreased (0.088008 --> 0.073754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635156\n",
      "\tspeed: 0.0402s/iter; left time: 883.3367s\n",
      "\titers: 200, epoch: 3 | loss: 0.0583343\n",
      "\tspeed: 0.0187s/iter; left time: 407.8178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0608415 Vali Loss: 0.0740786 Test Loss: 0.0821252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0573911\n",
      "\tspeed: 0.0384s/iter; left time: 834.2952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538883\n",
      "\tspeed: 0.0183s/iter; left time: 396.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0571251 Vali Loss: 0.0752631 Test Loss: 0.0843270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0542980\n",
      "\tspeed: 0.0377s/iter; left time: 811.0578s\n",
      "\titers: 200, epoch: 5 | loss: 0.0494459\n",
      "\tspeed: 0.0181s/iter; left time: 386.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0532236 Vali Loss: 0.0759761 Test Loss: 0.0854147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505165\n",
      "\tspeed: 0.0371s/iter; left time: 790.0507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0506002\n",
      "\tspeed: 0.0183s/iter; left time: 387.8944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0501787 Vali Loss: 0.0768308 Test Loss: 0.0852290\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0480088\n",
      "\tspeed: 0.0382s/iter; left time: 804.1262s\n",
      "\titers: 200, epoch: 7 | loss: 0.0443931\n",
      "\tspeed: 0.0185s/iter; left time: 387.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0476712 Vali Loss: 0.0764843 Test Loss: 0.0855211\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0477575\n",
      "\tspeed: 0.0380s/iter; left time: 790.6320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449111\n",
      "\tspeed: 0.0180s/iter; left time: 373.4726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0455909 Vali Loss: 0.0765070 Test Loss: 0.0847537\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444669\n",
      "\tspeed: 0.0380s/iter; left time: 782.3708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0466012\n",
      "\tspeed: 0.0186s/iter; left time: 381.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0438265 Vali Loss: 0.0768355 Test Loss: 0.0856286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0435193\n",
      "\tspeed: 0.0379s/iter; left time: 772.4439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0399701\n",
      "\tspeed: 0.0182s/iter; left time: 368.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0423801 Vali Loss: 0.0769819 Test Loss: 0.0855340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0414985\n",
      "\tspeed: 0.0377s/iter; left time: 759.6218s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408975\n",
      "\tspeed: 0.0181s/iter; left time: 363.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0411706 Vali Loss: 0.0774362 Test Loss: 0.0854421\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397998\n",
      "\tspeed: 0.0381s/iter; left time: 759.1696s\n",
      "\titers: 200, epoch: 12 | loss: 0.0391970\n",
      "\tspeed: 0.0181s/iter; left time: 358.7041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0401057 Vali Loss: 0.0769203 Test Loss: 0.0855711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020127102732658386, rmse:0.14187002182006836, mae:0.08433804661035538, rse:0.5487909913063049\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0942150\n",
      "\tspeed: 0.0202s/iter; left time: 453.1591s\n",
      "\titers: 200, epoch: 1 | loss: 0.0819090\n",
      "\tspeed: 0.0180s/iter; left time: 402.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0978670 Vali Loss: 0.0881797 Test Loss: 0.0994574\n",
      "Validation loss decreased (inf --> 0.088180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0664974\n",
      "\tspeed: 0.0413s/iter; left time: 916.2054s\n",
      "\titers: 200, epoch: 2 | loss: 0.0632625\n",
      "\tspeed: 0.0185s/iter; left time: 408.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0679474 Vali Loss: 0.0738612 Test Loss: 0.0836209\n",
      "Validation loss decreased (0.088180 --> 0.073861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0601718\n",
      "\tspeed: 0.0442s/iter; left time: 969.4626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622078\n",
      "\tspeed: 0.0184s/iter; left time: 401.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0612250 Vali Loss: 0.0731753 Test Loss: 0.0819078\n",
      "Validation loss decreased (0.073861 --> 0.073175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579952\n",
      "\tspeed: 0.0398s/iter; left time: 865.2752s\n",
      "\titers: 200, epoch: 4 | loss: 0.0564419\n",
      "\tspeed: 0.0181s/iter; left time: 392.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0574971 Vali Loss: 0.0752813 Test Loss: 0.0844468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0572532\n",
      "\tspeed: 0.0377s/iter; left time: 810.4702s\n",
      "\titers: 200, epoch: 5 | loss: 0.0534076\n",
      "\tspeed: 0.0181s/iter; left time: 387.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0539225 Vali Loss: 0.0754249 Test Loss: 0.0834574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0501882\n",
      "\tspeed: 0.0380s/iter; left time: 808.8260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0494513\n",
      "\tspeed: 0.0181s/iter; left time: 384.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0507724 Vali Loss: 0.0762898 Test Loss: 0.0839536\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0474354\n",
      "\tspeed: 0.0397s/iter; left time: 835.1748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0489970\n",
      "\tspeed: 0.0190s/iter; left time: 397.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0482603 Vali Loss: 0.0765327 Test Loss: 0.0842737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0459890\n",
      "\tspeed: 0.0381s/iter; left time: 793.1110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0453775\n",
      "\tspeed: 0.0185s/iter; left time: 382.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0462406 Vali Loss: 0.0767720 Test Loss: 0.0844933\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0424829\n",
      "\tspeed: 0.0380s/iter; left time: 782.5921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439030\n",
      "\tspeed: 0.0182s/iter; left time: 372.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0444618 Vali Loss: 0.0772027 Test Loss: 0.0855004\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0433870\n",
      "\tspeed: 0.0380s/iter; left time: 773.6652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0414537\n",
      "\tspeed: 0.0183s/iter; left time: 370.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0430081 Vali Loss: 0.0774466 Test Loss: 0.0858750\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424098\n",
      "\tspeed: 0.0394s/iter; left time: 794.0385s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408237\n",
      "\tspeed: 0.0181s/iter; left time: 362.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0417295 Vali Loss: 0.0773811 Test Loss: 0.0860263\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397430\n",
      "\tspeed: 0.0383s/iter; left time: 763.8141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0397619\n",
      "\tspeed: 0.0187s/iter; left time: 371.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0406975 Vali Loss: 0.0766426 Test Loss: 0.0861305\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0392018\n",
      "\tspeed: 0.0395s/iter; left time: 777.6916s\n",
      "\titers: 200, epoch: 13 | loss: 0.0406257\n",
      "\tspeed: 0.0182s/iter; left time: 356.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0398008 Vali Loss: 0.0765993 Test Loss: 0.0865211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018997935578227043, rmse:0.13783299922943115, mae:0.08190777897834778, rse:0.5331746935844421\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:35.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0908656\n",
      "\tspeed: 0.0445s/iter; left time: 996.9496s\n",
      "\titers: 200, epoch: 1 | loss: 0.0891940\n",
      "\tspeed: 0.0186s/iter; left time: 415.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1014871 Vali Loss: 0.0917853 Test Loss: 0.1026675\n",
      "Validation loss decreased (inf --> 0.091785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0684629\n",
      "\tspeed: 0.0409s/iter; left time: 906.4908s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672442\n",
      "\tspeed: 0.0185s/iter; left time: 407.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0723063 Vali Loss: 0.0782374 Test Loss: 0.0879902\n",
      "Validation loss decreased (0.091785 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619121\n",
      "\tspeed: 0.0438s/iter; left time: 961.5666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0598689\n",
      "\tspeed: 0.0185s/iter; left time: 404.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0647034 Vali Loss: 0.0780730 Test Loss: 0.0865445\n",
      "Validation loss decreased (0.078237 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0606524\n",
      "\tspeed: 0.0486s/iter; left time: 1056.8225s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594136\n",
      "\tspeed: 0.0188s/iter; left time: 407.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0603122 Vali Loss: 0.0804714 Test Loss: 0.0876513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0565531\n",
      "\tspeed: 0.0382s/iter; left time: 822.2550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0558551\n",
      "\tspeed: 0.0184s/iter; left time: 394.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0566340 Vali Loss: 0.0817166 Test Loss: 0.0889156\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0553974\n",
      "\tspeed: 0.0387s/iter; left time: 823.8927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0514911\n",
      "\tspeed: 0.0193s/iter; left time: 407.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0532845 Vali Loss: 0.0825787 Test Loss: 0.0885907\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0522775\n",
      "\tspeed: 0.0385s/iter; left time: 810.6988s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490751\n",
      "\tspeed: 0.0184s/iter; left time: 385.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0506605 Vali Loss: 0.0819513 Test Loss: 0.0896498\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0481883\n",
      "\tspeed: 0.0389s/iter; left time: 811.1528s\n",
      "\titers: 200, epoch: 8 | loss: 0.0474817\n",
      "\tspeed: 0.0192s/iter; left time: 397.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0484786 Vali Loss: 0.0840234 Test Loss: 0.0901825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0470933\n",
      "\tspeed: 0.0400s/iter; left time: 824.1000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0446422\n",
      "\tspeed: 0.0185s/iter; left time: 378.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0467293 Vali Loss: 0.0832497 Test Loss: 0.0904056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0455585\n",
      "\tspeed: 0.0399s/iter; left time: 811.9973s\n",
      "\titers: 200, epoch: 10 | loss: 0.0460681\n",
      "\tspeed: 0.0197s/iter; left time: 398.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0453248 Vali Loss: 0.0837281 Test Loss: 0.0903833\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434859\n",
      "\tspeed: 0.0419s/iter; left time: 845.1868s\n",
      "\titers: 200, epoch: 11 | loss: 0.0438852\n",
      "\tspeed: 0.0185s/iter; left time: 369.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0440360 Vali Loss: 0.0829143 Test Loss: 0.0909697\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0423885\n",
      "\tspeed: 0.0382s/iter; left time: 760.2230s\n",
      "\titers: 200, epoch: 12 | loss: 0.0401541\n",
      "\tspeed: 0.0184s/iter; left time: 365.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0429602 Vali Loss: 0.0840859 Test Loss: 0.0908408\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0415776\n",
      "\tspeed: 0.0390s/iter; left time: 768.8135s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405993\n",
      "\tspeed: 0.0192s/iter; left time: 377.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0420540 Vali Loss: 0.0836687 Test Loss: 0.0909934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020075254142284393, rmse:0.14168716967105865, mae:0.08654448390007019, rse:0.5487678050994873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0945257\n",
      "\tspeed: 0.0207s/iter; left time: 463.0542s\n",
      "\titers: 200, epoch: 1 | loss: 0.0830759\n",
      "\tspeed: 0.0186s/iter; left time: 414.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.1009076 Vali Loss: 0.0917944 Test Loss: 0.1025656\n",
      "Validation loss decreased (inf --> 0.091794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0700706\n",
      "\tspeed: 0.0414s/iter; left time: 918.4545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0660276\n",
      "\tspeed: 0.0185s/iter; left time: 408.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0723461 Vali Loss: 0.0790639 Test Loss: 0.0894321\n",
      "Validation loss decreased (0.091794 --> 0.079064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0639853\n",
      "\tspeed: 0.0431s/iter; left time: 945.4431s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622231\n",
      "\tspeed: 0.0191s/iter; left time: 416.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0647785 Vali Loss: 0.0787261 Test Loss: 0.0880830\n",
      "Validation loss decreased (0.079064 --> 0.078726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630164\n",
      "\tspeed: 0.0558s/iter; left time: 1212.8221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602266\n",
      "\tspeed: 0.0184s/iter; left time: 397.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0603927 Vali Loss: 0.0806556 Test Loss: 0.0891107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562662\n",
      "\tspeed: 0.0392s/iter; left time: 842.6537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541140\n",
      "\tspeed: 0.0185s/iter; left time: 395.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0563509 Vali Loss: 0.0811103 Test Loss: 0.0888919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0523157\n",
      "\tspeed: 0.0392s/iter; left time: 833.0026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0513288\n",
      "\tspeed: 0.0185s/iter; left time: 391.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0530924 Vali Loss: 0.0807032 Test Loss: 0.0897623\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0500884\n",
      "\tspeed: 0.0394s/iter; left time: 829.3137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0500115\n",
      "\tspeed: 0.0184s/iter; left time: 385.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0504590 Vali Loss: 0.0820986 Test Loss: 0.0894578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0479878\n",
      "\tspeed: 0.0385s/iter; left time: 801.4588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0484171\n",
      "\tspeed: 0.0185s/iter; left time: 383.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0482995 Vali Loss: 0.0821091 Test Loss: 0.0903916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458567\n",
      "\tspeed: 0.0394s/iter; left time: 810.6843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0477157\n",
      "\tspeed: 0.0187s/iter; left time: 382.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0466534 Vali Loss: 0.0833053 Test Loss: 0.0899950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0471632\n",
      "\tspeed: 0.0392s/iter; left time: 799.0429s\n",
      "\titers: 200, epoch: 10 | loss: 0.0469389\n",
      "\tspeed: 0.0185s/iter; left time: 374.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0452414 Vali Loss: 0.0830634 Test Loss: 0.0917294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441526\n",
      "\tspeed: 0.0392s/iter; left time: 789.5945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0439629\n",
      "\tspeed: 0.0190s/iter; left time: 380.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0440587 Vali Loss: 0.0837354 Test Loss: 0.0909154\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436273\n",
      "\tspeed: 0.0405s/iter; left time: 806.6968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0430317\n",
      "\tspeed: 0.0185s/iter; left time: 366.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0430000 Vali Loss: 0.0836592 Test Loss: 0.0912588\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0423120\n",
      "\tspeed: 0.0397s/iter; left time: 782.0449s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426837\n",
      "\tspeed: 0.0190s/iter; left time: 371.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0421225 Vali Loss: 0.0831803 Test Loss: 0.0908114\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020790696144104004, rmse:0.14418978989124298, mae:0.08808299899101257, rse:0.5584607124328613\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:47.11s\n",
      "Intermediate time for FR: 00h:08m:56.14s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1186669\n",
      "\tspeed: 0.0437s/iter; left time: 982.3349s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038871\n",
      "\tspeed: 0.0177s/iter; left time: 396.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.1271104 Vali Loss: 0.0885935 Test Loss: 0.0908134\n",
      "Validation loss decreased (inf --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0683111\n",
      "\tspeed: 0.0396s/iter; left time: 881.0199s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647918\n",
      "\tspeed: 0.0177s/iter; left time: 392.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0725847 Vali Loss: 0.0627410 Test Loss: 0.0653730\n",
      "Validation loss decreased (0.088594 --> 0.062741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0620086\n",
      "\tspeed: 0.0401s/iter; left time: 883.9944s\n",
      "\titers: 200, epoch: 3 | loss: 0.0679798\n",
      "\tspeed: 0.0178s/iter; left time: 391.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0636721 Vali Loss: 0.0587901 Test Loss: 0.0619358\n",
      "Validation loss decreased (0.062741 --> 0.058790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620091\n",
      "\tspeed: 0.0391s/iter; left time: 853.6076s\n",
      "\titers: 200, epoch: 4 | loss: 0.0562509\n",
      "\tspeed: 0.0180s/iter; left time: 390.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0611027 Vali Loss: 0.0581652 Test Loss: 0.0608983\n",
      "Validation loss decreased (0.058790 --> 0.058165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612355\n",
      "\tspeed: 0.0396s/iter; left time: 854.9812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0565420\n",
      "\tspeed: 0.0177s/iter; left time: 380.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0594019 Vali Loss: 0.0568237 Test Loss: 0.0601146\n",
      "Validation loss decreased (0.058165 --> 0.056824).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579325\n",
      "\tspeed: 0.0383s/iter; left time: 818.7290s\n",
      "\titers: 200, epoch: 6 | loss: 0.0553782\n",
      "\tspeed: 0.0180s/iter; left time: 382.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0578790 Vali Loss: 0.0563135 Test Loss: 0.0592824\n",
      "Validation loss decreased (0.056824 --> 0.056313).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590282\n",
      "\tspeed: 0.0389s/iter; left time: 823.2705s\n",
      "\titers: 200, epoch: 7 | loss: 0.0608191\n",
      "\tspeed: 0.0177s/iter; left time: 372.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0567683 Vali Loss: 0.0565626 Test Loss: 0.0589534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570408\n",
      "\tspeed: 0.0363s/iter; left time: 758.6925s\n",
      "\titers: 200, epoch: 8 | loss: 0.0567258\n",
      "\tspeed: 0.0178s/iter; left time: 369.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0555047 Vali Loss: 0.0565501 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539403\n",
      "\tspeed: 0.0378s/iter; left time: 783.1071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558067\n",
      "\tspeed: 0.0177s/iter; left time: 364.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0543611 Vali Loss: 0.0559711 Test Loss: 0.0584920\n",
      "Validation loss decreased (0.056313 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0480541\n",
      "\tspeed: 0.0391s/iter; left time: 799.4237s\n",
      "\titers: 200, epoch: 10 | loss: 0.0515454\n",
      "\tspeed: 0.0177s/iter; left time: 361.0255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0533515 Vali Loss: 0.0562107 Test Loss: 0.0589197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0505390\n",
      "\tspeed: 0.0366s/iter; left time: 740.7503s\n",
      "\titers: 200, epoch: 11 | loss: 0.0505183\n",
      "\tspeed: 0.0177s/iter; left time: 356.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0523736 Vali Loss: 0.0565854 Test Loss: 0.0583816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0493615\n",
      "\tspeed: 0.0362s/iter; left time: 725.0631s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513223\n",
      "\tspeed: 0.0176s/iter; left time: 351.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0513761 Vali Loss: 0.0566836 Test Loss: 0.0582515\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0495898\n",
      "\tspeed: 0.0363s/iter; left time: 717.7518s\n",
      "\titers: 200, epoch: 13 | loss: 0.0460916\n",
      "\tspeed: 0.0177s/iter; left time: 348.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0502435 Vali Loss: 0.0569636 Test Loss: 0.0586153\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0491502\n",
      "\tspeed: 0.0368s/iter; left time: 720.7901s\n",
      "\titers: 200, epoch: 14 | loss: 0.0497240\n",
      "\tspeed: 0.0177s/iter; left time: 343.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0493753 Vali Loss: 0.0566386 Test Loss: 0.0585247\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0487527\n",
      "\tspeed: 0.0360s/iter; left time: 695.8543s\n",
      "\titers: 200, epoch: 15 | loss: 0.0464090\n",
      "\tspeed: 0.0177s/iter; left time: 340.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0485031 Vali Loss: 0.0565502 Test Loss: 0.0588691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0486492\n",
      "\tspeed: 0.0370s/iter; left time: 706.4464s\n",
      "\titers: 200, epoch: 16 | loss: 0.0468850\n",
      "\tspeed: 0.0176s/iter; left time: 335.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0476619 Vali Loss: 0.0570641 Test Loss: 0.0588286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0484204\n",
      "\tspeed: 0.0361s/iter; left time: 681.3553s\n",
      "\titers: 200, epoch: 17 | loss: 0.0457373\n",
      "\tspeed: 0.0177s/iter; left time: 332.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0469115 Vali Loss: 0.0571258 Test Loss: 0.0593243\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0459390\n",
      "\tspeed: 0.0377s/iter; left time: 704.2634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0463988\n",
      "\tspeed: 0.0177s/iter; left time: 328.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0463835 Vali Loss: 0.0574036 Test Loss: 0.0591414\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0449952\n",
      "\tspeed: 0.0376s/iter; left time: 693.2720s\n",
      "\titers: 200, epoch: 19 | loss: 0.0478959\n",
      "\tspeed: 0.0178s/iter; left time: 326.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0457615 Vali Loss: 0.0572451 Test Loss: 0.0597154\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010480063036084175, rmse:0.1023721769452095, mae:0.058492016047239304, rse:0.38681402802467346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1183293\n",
      "\tspeed: 0.0199s/iter; left time: 446.9918s\n",
      "\titers: 200, epoch: 1 | loss: 0.1023478\n",
      "\tspeed: 0.0182s/iter; left time: 408.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.1252369 Vali Loss: 0.0887429 Test Loss: 0.0913487\n",
      "Validation loss decreased (inf --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721573\n",
      "\tspeed: 0.0391s/iter; left time: 870.0501s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695804\n",
      "\tspeed: 0.0188s/iter; left time: 417.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0725251 Vali Loss: 0.0620892 Test Loss: 0.0651353\n",
      "Validation loss decreased (0.088743 --> 0.062089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637120\n",
      "\tspeed: 0.0395s/iter; left time: 870.4122s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642457\n",
      "\tspeed: 0.0177s/iter; left time: 387.5393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0637578 Vali Loss: 0.0588995 Test Loss: 0.0622270\n",
      "Validation loss decreased (0.062089 --> 0.058899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0622228\n",
      "\tspeed: 0.0378s/iter; left time: 825.3745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0597051\n",
      "\tspeed: 0.0177s/iter; left time: 383.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0611976 Vali Loss: 0.0583031 Test Loss: 0.0612591\n",
      "Validation loss decreased (0.058899 --> 0.058303).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569705\n",
      "\tspeed: 0.0424s/iter; left time: 915.5773s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624648\n",
      "\tspeed: 0.0178s/iter; left time: 381.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0594146 Vali Loss: 0.0572613 Test Loss: 0.0605500\n",
      "Validation loss decreased (0.058303 --> 0.057261).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574250\n",
      "\tspeed: 0.0397s/iter; left time: 848.6427s\n",
      "\titers: 200, epoch: 6 | loss: 0.0574117\n",
      "\tspeed: 0.0176s/iter; left time: 374.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0580177 Vali Loss: 0.0570326 Test Loss: 0.0598851\n",
      "Validation loss decreased (0.057261 --> 0.057033).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562002\n",
      "\tspeed: 0.0383s/iter; left time: 809.9356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0591149\n",
      "\tspeed: 0.0184s/iter; left time: 387.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0568774 Vali Loss: 0.0560135 Test Loss: 0.0586588\n",
      "Validation loss decreased (0.057033 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573453\n",
      "\tspeed: 0.0382s/iter; left time: 798.0599s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589271\n",
      "\tspeed: 0.0178s/iter; left time: 371.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0557198 Vali Loss: 0.0562147 Test Loss: 0.0584597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0532231\n",
      "\tspeed: 0.0377s/iter; left time: 781.0276s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533374\n",
      "\tspeed: 0.0180s/iter; left time: 369.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0546067 Vali Loss: 0.0557521 Test Loss: 0.0584721\n",
      "Validation loss decreased (0.056013 --> 0.055752).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554328\n",
      "\tspeed: 0.0385s/iter; left time: 787.5572s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529305\n",
      "\tspeed: 0.0177s/iter; left time: 359.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0534864 Vali Loss: 0.0556840 Test Loss: 0.0580632\n",
      "Validation loss decreased (0.055752 --> 0.055684).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0490568\n",
      "\tspeed: 0.0381s/iter; left time: 772.0579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579109\n",
      "\tspeed: 0.0181s/iter; left time: 364.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0524901 Vali Loss: 0.0556808 Test Loss: 0.0582837\n",
      "Validation loss decreased (0.055684 --> 0.055681).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0545119\n",
      "\tspeed: 0.0384s/iter; left time: 769.3993s\n",
      "\titers: 200, epoch: 12 | loss: 0.0526492\n",
      "\tspeed: 0.0177s/iter; left time: 351.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0515282 Vali Loss: 0.0556845 Test Loss: 0.0587237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0512061\n",
      "\tspeed: 0.0370s/iter; left time: 731.6856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0485435\n",
      "\tspeed: 0.0177s/iter; left time: 348.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0505559 Vali Loss: 0.0561550 Test Loss: 0.0583473\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505487\n",
      "\tspeed: 0.0368s/iter; left time: 719.7775s\n",
      "\titers: 200, epoch: 14 | loss: 0.0488571\n",
      "\tspeed: 0.0179s/iter; left time: 349.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0496760 Vali Loss: 0.0567544 Test Loss: 0.0589902\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486834\n",
      "\tspeed: 0.0374s/iter; left time: 722.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485694\n",
      "\tspeed: 0.0177s/iter; left time: 340.2375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0489163 Vali Loss: 0.0564030 Test Loss: 0.0587402\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0472454\n",
      "\tspeed: 0.0367s/iter; left time: 700.4890s\n",
      "\titers: 200, epoch: 16 | loss: 0.0488778\n",
      "\tspeed: 0.0177s/iter; left time: 336.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0480489 Vali Loss: 0.0567949 Test Loss: 0.0590802\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0461510\n",
      "\tspeed: 0.0385s/iter; left time: 727.4193s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470704\n",
      "\tspeed: 0.0194s/iter; left time: 364.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0474308 Vali Loss: 0.0565297 Test Loss: 0.0589807\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0475236\n",
      "\tspeed: 0.0371s/iter; left time: 692.2523s\n",
      "\titers: 200, epoch: 18 | loss: 0.0432625\n",
      "\tspeed: 0.0176s/iter; left time: 327.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0467678 Vali Loss: 0.0568878 Test Loss: 0.0593559\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0432556\n",
      "\tspeed: 0.0365s/iter; left time: 673.2113s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448248\n",
      "\tspeed: 0.0179s/iter; left time: 328.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0461628 Vali Loss: 0.0567260 Test Loss: 0.0594797\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0493075\n",
      "\tspeed: 0.0376s/iter; left time: 684.2777s\n",
      "\titers: 200, epoch: 20 | loss: 0.0476661\n",
      "\tspeed: 0.0177s/iter; left time: 319.8866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0458511 Vali Loss: 0.0567330 Test Loss: 0.0594195\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0462077\n",
      "\tspeed: 0.0365s/iter; left time: 656.7331s\n",
      "\titers: 200, epoch: 21 | loss: 0.0431399\n",
      "\tspeed: 0.0177s/iter; left time: 316.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0453313 Vali Loss: 0.0569593 Test Loss: 0.0592954\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335121303796768, rmse:0.1016618013381958, mae:0.058283690363168716, rse:0.3841298818588257\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:54.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1310730\n",
      "\tspeed: 0.0441s/iter; left time: 988.4177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159046\n",
      "\tspeed: 0.0181s/iter; left time: 402.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1386889 Vali Loss: 0.1017228 Test Loss: 0.1046455\n",
      "Validation loss decreased (inf --> 0.101723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922018\n",
      "\tspeed: 0.0404s/iter; left time: 895.4513s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875287\n",
      "\tspeed: 0.0180s/iter; left time: 398.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0913242 Vali Loss: 0.0810804 Test Loss: 0.0859926\n",
      "Validation loss decreased (0.101723 --> 0.081080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851930\n",
      "\tspeed: 0.0403s/iter; left time: 884.8194s\n",
      "\titers: 200, epoch: 3 | loss: 0.0848009\n",
      "\tspeed: 0.0181s/iter; left time: 396.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0831508 Vali Loss: 0.0784393 Test Loss: 0.0841096\n",
      "Validation loss decreased (0.081080 --> 0.078439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810510\n",
      "\tspeed: 0.0400s/iter; left time: 868.2449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782053\n",
      "\tspeed: 0.0180s/iter; left time: 389.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0795676 Vali Loss: 0.0784156 Test Loss: 0.0839126\n",
      "Validation loss decreased (0.078439 --> 0.078416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0816101\n",
      "\tspeed: 0.0390s/iter; left time: 839.4009s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721341\n",
      "\tspeed: 0.0180s/iter; left time: 385.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0762387 Vali Loss: 0.0790260 Test Loss: 0.0830072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0740837\n",
      "\tspeed: 0.0371s/iter; left time: 789.8721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762524\n",
      "\tspeed: 0.0187s/iter; left time: 395.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0728276 Vali Loss: 0.0801343 Test Loss: 0.0841383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0702368\n",
      "\tspeed: 0.0367s/iter; left time: 773.1533s\n",
      "\titers: 200, epoch: 7 | loss: 0.0654386\n",
      "\tspeed: 0.0181s/iter; left time: 378.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0698180 Vali Loss: 0.0802404 Test Loss: 0.0828267\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711698\n",
      "\tspeed: 0.0373s/iter; left time: 776.2859s\n",
      "\titers: 200, epoch: 8 | loss: 0.0639507\n",
      "\tspeed: 0.0180s/iter; left time: 374.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0670037 Vali Loss: 0.0815448 Test Loss: 0.0840982\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627414\n",
      "\tspeed: 0.0377s/iter; left time: 776.9450s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609370\n",
      "\tspeed: 0.0181s/iter; left time: 370.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0644941 Vali Loss: 0.0811407 Test Loss: 0.0839700\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0619954\n",
      "\tspeed: 0.0373s/iter; left time: 760.0455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0627662\n",
      "\tspeed: 0.0182s/iter; left time: 369.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0622920 Vali Loss: 0.0826805 Test Loss: 0.0853803\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642111\n",
      "\tspeed: 0.0370s/iter; left time: 745.9526s\n",
      "\titers: 200, epoch: 11 | loss: 0.0608653\n",
      "\tspeed: 0.0181s/iter; left time: 363.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0603079 Vali Loss: 0.0826404 Test Loss: 0.0851099\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0570892\n",
      "\tspeed: 0.0370s/iter; left time: 737.3791s\n",
      "\titers: 200, epoch: 12 | loss: 0.0618150\n",
      "\tspeed: 0.0180s/iter; left time: 357.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0586184 Vali Loss: 0.0831143 Test Loss: 0.0854465\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575813\n",
      "\tspeed: 0.0384s/iter; left time: 756.6247s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571408\n",
      "\tspeed: 0.0191s/iter; left time: 374.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0572359 Vali Loss: 0.0832216 Test Loss: 0.0854676\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0556617\n",
      "\tspeed: 0.0372s/iter; left time: 723.8908s\n",
      "\titers: 200, epoch: 14 | loss: 0.0540459\n",
      "\tspeed: 0.0182s/iter; left time: 353.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0558948 Vali Loss: 0.0837388 Test Loss: 0.0862194\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954498514533043, rmse:0.13980337977409363, mae:0.08391264081001282, rse:0.5286116600036621\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1263471\n",
      "\tspeed: 0.0199s/iter; left time: 444.9298s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159365\n",
      "\tspeed: 0.0182s/iter; left time: 404.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1380923 Vali Loss: 0.1020415 Test Loss: 0.1047741\n",
      "Validation loss decreased (inf --> 0.102042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909317\n",
      "\tspeed: 0.0410s/iter; left time: 908.6552s\n",
      "\titers: 200, epoch: 2 | loss: 0.0883571\n",
      "\tspeed: 0.0184s/iter; left time: 407.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0914261 Vali Loss: 0.0803037 Test Loss: 0.0852146\n",
      "Validation loss decreased (0.102042 --> 0.080304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0859512\n",
      "\tspeed: 0.0417s/iter; left time: 914.5156s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811047\n",
      "\tspeed: 0.0181s/iter; left time: 395.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0831277 Vali Loss: 0.0784896 Test Loss: 0.0827625\n",
      "Validation loss decreased (0.080304 --> 0.078490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0767060\n",
      "\tspeed: 0.0399s/iter; left time: 867.1353s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806868\n",
      "\tspeed: 0.0180s/iter; left time: 389.6694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0796888 Vali Loss: 0.0783908 Test Loss: 0.0829460\n",
      "Validation loss decreased (0.078490 --> 0.078391).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777936\n",
      "\tspeed: 0.0400s/iter; left time: 859.3647s\n",
      "\titers: 200, epoch: 5 | loss: 0.0772324\n",
      "\tspeed: 0.0180s/iter; left time: 385.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0760393 Vali Loss: 0.0800801 Test Loss: 0.0835676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0714719\n",
      "\tspeed: 0.0381s/iter; left time: 809.8240s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720436\n",
      "\tspeed: 0.0184s/iter; left time: 390.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0725466 Vali Loss: 0.0804555 Test Loss: 0.0829974\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0696251\n",
      "\tspeed: 0.0378s/iter; left time: 794.7793s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676035\n",
      "\tspeed: 0.0182s/iter; left time: 381.2569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0692073 Vali Loss: 0.0817006 Test Loss: 0.0846338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0691494\n",
      "\tspeed: 0.0382s/iter; left time: 796.2091s\n",
      "\titers: 200, epoch: 8 | loss: 0.0647662\n",
      "\tspeed: 0.0180s/iter; left time: 373.8621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0662966 Vali Loss: 0.0818667 Test Loss: 0.0849675\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623415\n",
      "\tspeed: 0.0374s/iter; left time: 770.5469s\n",
      "\titers: 200, epoch: 9 | loss: 0.0608835\n",
      "\tspeed: 0.0181s/iter; left time: 372.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0637759 Vali Loss: 0.0822691 Test Loss: 0.0853241\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0635078\n",
      "\tspeed: 0.0382s/iter; left time: 778.6474s\n",
      "\titers: 200, epoch: 10 | loss: 0.0581507\n",
      "\tspeed: 0.0181s/iter; left time: 366.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0615833 Vali Loss: 0.0827696 Test Loss: 0.0859685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572104\n",
      "\tspeed: 0.0378s/iter; left time: 761.9479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578615\n",
      "\tspeed: 0.0183s/iter; left time: 367.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0598117 Vali Loss: 0.0834219 Test Loss: 0.0876955\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567229\n",
      "\tspeed: 0.0373s/iter; left time: 743.5879s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560101\n",
      "\tspeed: 0.0181s/iter; left time: 358.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0581680 Vali Loss: 0.0832148 Test Loss: 0.0870609\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569095\n",
      "\tspeed: 0.0401s/iter; left time: 790.2327s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528492\n",
      "\tspeed: 0.0182s/iter; left time: 356.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0568319 Vali Loss: 0.0832953 Test Loss: 0.0874218\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592510\n",
      "\tspeed: 0.0389s/iter; left time: 757.8687s\n",
      "\titers: 200, epoch: 14 | loss: 0.0547856\n",
      "\tspeed: 0.0185s/iter; left time: 358.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0558380 Vali Loss: 0.0831213 Test Loss: 0.0874076\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01917097717523575, rmse:0.13845929503440857, mae:0.08294600993394852, rse:0.5235295295715332\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:50.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1275234\n",
      "\tspeed: 0.0489s/iter; left time: 1095.7558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189954\n",
      "\tspeed: 0.0184s/iter; left time: 410.1009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.1412950 Vali Loss: 0.1040635 Test Loss: 0.1070162\n",
      "Validation loss decreased (inf --> 0.104064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964050\n",
      "\tspeed: 0.0446s/iter; left time: 988.6547s\n",
      "\titers: 200, epoch: 2 | loss: 0.0886111\n",
      "\tspeed: 0.0186s/iter; left time: 411.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0955518 Vali Loss: 0.0854652 Test Loss: 0.0895273\n",
      "Validation loss decreased (0.104064 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0866833\n",
      "\tspeed: 0.0403s/iter; left time: 884.2453s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814698\n",
      "\tspeed: 0.0184s/iter; left time: 401.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0871050 Vali Loss: 0.0848689 Test Loss: 0.0877781\n",
      "Validation loss decreased (0.085465 --> 0.084869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808554\n",
      "\tspeed: 0.0399s/iter; left time: 867.7698s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826341\n",
      "\tspeed: 0.0184s/iter; left time: 398.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0828756 Vali Loss: 0.0852374 Test Loss: 0.0874300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791364\n",
      "\tspeed: 0.0395s/iter; left time: 849.4162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785064\n",
      "\tspeed: 0.0188s/iter; left time: 402.0365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0790885 Vali Loss: 0.0861373 Test Loss: 0.0885819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774719\n",
      "\tspeed: 0.0388s/iter; left time: 826.0458s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751552\n",
      "\tspeed: 0.0185s/iter; left time: 391.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0760913 Vali Loss: 0.0866237 Test Loss: 0.0889733\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741134\n",
      "\tspeed: 0.0385s/iter; left time: 811.0575s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721804\n",
      "\tspeed: 0.0184s/iter; left time: 385.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0732284 Vali Loss: 0.0865928 Test Loss: 0.0902340\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724975\n",
      "\tspeed: 0.0382s/iter; left time: 795.6113s\n",
      "\titers: 200, epoch: 8 | loss: 0.0668545\n",
      "\tspeed: 0.0187s/iter; left time: 388.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0703631 Vali Loss: 0.0864248 Test Loss: 0.0899004\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685533\n",
      "\tspeed: 0.0388s/iter; left time: 799.9027s\n",
      "\titers: 200, epoch: 9 | loss: 0.0653959\n",
      "\tspeed: 0.0185s/iter; left time: 378.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0678736 Vali Loss: 0.0872525 Test Loss: 0.0919391\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666165\n",
      "\tspeed: 0.0386s/iter; left time: 787.0395s\n",
      "\titers: 200, epoch: 10 | loss: 0.0637973\n",
      "\tspeed: 0.0184s/iter; left time: 372.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0657089 Vali Loss: 0.0874528 Test Loss: 0.0922164\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0632579\n",
      "\tspeed: 0.0385s/iter; left time: 775.3910s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619213\n",
      "\tspeed: 0.0184s/iter; left time: 369.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0639057 Vali Loss: 0.0867941 Test Loss: 0.0914731\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624109\n",
      "\tspeed: 0.0389s/iter; left time: 774.8493s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628552\n",
      "\tspeed: 0.0188s/iter; left time: 372.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0624616 Vali Loss: 0.0871244 Test Loss: 0.0930709\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0590759\n",
      "\tspeed: 0.0386s/iter; left time: 760.5655s\n",
      "\titers: 200, epoch: 13 | loss: 0.0594228\n",
      "\tspeed: 0.0184s/iter; left time: 360.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0609735 Vali Loss: 0.0873015 Test Loss: 0.0925411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02027822844684124, rmse:0.14240165054798126, mae:0.0877780169248581, rse:0.5389363169670105\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1299536\n",
      "\tspeed: 0.0203s/iter; left time: 454.0323s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161951\n",
      "\tspeed: 0.0184s/iter; left time: 410.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.1414682 Vali Loss: 0.1044085 Test Loss: 0.1074294\n",
      "Validation loss decreased (inf --> 0.104409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0972994\n",
      "\tspeed: 0.0414s/iter; left time: 918.8161s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901106\n",
      "\tspeed: 0.0184s/iter; left time: 406.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0957896 Vali Loss: 0.0854568 Test Loss: 0.0893396\n",
      "Validation loss decreased (0.104409 --> 0.085457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0885999\n",
      "\tspeed: 0.0417s/iter; left time: 915.1863s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868260\n",
      "\tspeed: 0.0189s/iter; left time: 414.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0873431 Vali Loss: 0.0845915 Test Loss: 0.0883179\n",
      "Validation loss decreased (0.085457 --> 0.084591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0882138\n",
      "\tspeed: 0.0415s/iter; left time: 901.0840s\n",
      "\titers: 200, epoch: 4 | loss: 0.0833410\n",
      "\tspeed: 0.0188s/iter; left time: 406.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0834392 Vali Loss: 0.0851915 Test Loss: 0.0894194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0792511\n",
      "\tspeed: 0.0394s/iter; left time: 846.8447s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755284\n",
      "\tspeed: 0.0187s/iter; left time: 400.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0796267 Vali Loss: 0.0848287 Test Loss: 0.0895064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0772265\n",
      "\tspeed: 0.0386s/iter; left time: 820.3110s\n",
      "\titers: 200, epoch: 6 | loss: 0.0731446\n",
      "\tspeed: 0.0184s/iter; left time: 389.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0765081 Vali Loss: 0.0859261 Test Loss: 0.0894576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0733916\n",
      "\tspeed: 0.0391s/iter; left time: 822.9563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741833\n",
      "\tspeed: 0.0184s/iter; left time: 386.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0736420 Vali Loss: 0.0860845 Test Loss: 0.0922697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725332\n",
      "\tspeed: 0.0392s/iter; left time: 815.8906s\n",
      "\titers: 200, epoch: 8 | loss: 0.0704023\n",
      "\tspeed: 0.0184s/iter; left time: 380.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0709409 Vali Loss: 0.0858436 Test Loss: 0.0913357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673422\n",
      "\tspeed: 0.0397s/iter; left time: 817.1669s\n",
      "\titers: 200, epoch: 9 | loss: 0.0649461\n",
      "\tspeed: 0.0186s/iter; left time: 381.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0682619 Vali Loss: 0.0864067 Test Loss: 0.0929804\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666464\n",
      "\tspeed: 0.0399s/iter; left time: 812.7487s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675855\n",
      "\tspeed: 0.0185s/iter; left time: 374.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0661923 Vali Loss: 0.0862028 Test Loss: 0.0925525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0661159\n",
      "\tspeed: 0.0393s/iter; left time: 792.4639s\n",
      "\titers: 200, epoch: 11 | loss: 0.0636477\n",
      "\tspeed: 0.0185s/iter; left time: 371.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0644045 Vali Loss: 0.0867072 Test Loss: 0.0929461\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0620243\n",
      "\tspeed: 0.0391s/iter; left time: 779.0745s\n",
      "\titers: 200, epoch: 12 | loss: 0.0625289\n",
      "\tspeed: 0.0184s/iter; left time: 363.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0629564 Vali Loss: 0.0861273 Test Loss: 0.0923139\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0624796\n",
      "\tspeed: 0.0387s/iter; left time: 762.3120s\n",
      "\titers: 200, epoch: 13 | loss: 0.0605377\n",
      "\tspeed: 0.0184s/iter; left time: 360.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0615932 Vali Loss: 0.0867980 Test Loss: 0.0913889\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020756619051098824, rmse:0.1440715789794922, mae:0.08831792324781418, rse:0.5452563762664795\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:43.78s\n",
      "Intermediate time for IT: 00h:09m:29.43s\n",
      "Total time: 01h:17m:10.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            model_id = f\"channel_mixing_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0264  0.1626  0.1055\n",
       "        96        0.0448  0.2117  0.1447\n",
       "        168       0.0443  0.2104  0.1441\n",
       "ES      24        0.0115  0.1071  0.0677\n",
       "        96        0.0216  0.1469  0.0970\n",
       "        168       0.0236  0.1538  0.1034\n",
       "FR      24        0.0108  0.1039  0.0582\n",
       "        96        0.0196  0.1399  0.0831\n",
       "        168       0.0204  0.1429  0.0873\n",
       "GB      24        0.0289  0.1699  0.1154\n",
       "        96        0.0435  0.2085  0.1452\n",
       "        168       0.0456  0.2135  0.1499\n",
       "IT      24        0.0104  0.1020  0.0584\n",
       "        96        0.0194  0.1391  0.0834\n",
       "        168       0.0205  0.1432  0.0880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1107970\n",
      "\tspeed: 0.0794s/iter; left time: 1787.3521s\n",
      "\titers: 200, epoch: 1 | loss: 0.0986829\n",
      "\tspeed: 0.0535s/iter; left time: 1199.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 226 | Train Loss: 0.1157395 Vali Loss: 0.1076960 Test Loss: 0.1105589\n",
      "Validation loss decreased (inf --> 0.107696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0841662\n",
      "\tspeed: 0.0998s/iter; left time: 2223.5783s\n",
      "\titers: 200, epoch: 2 | loss: 0.0774007\n",
      "\tspeed: 0.0536s/iter; left time: 1189.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.34s\n",
      "Steps: 226 | Train Loss: 0.0834303 Vali Loss: 0.0951717 Test Loss: 0.0983893\n",
      "Validation loss decreased (0.107696 --> 0.095172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795393\n",
      "\tspeed: 0.0999s/iter; left time: 2202.1801s\n",
      "\titers: 200, epoch: 3 | loss: 0.0760526\n",
      "\tspeed: 0.0537s/iter; left time: 1178.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.32s\n",
      "Steps: 226 | Train Loss: 0.0750043 Vali Loss: 0.0966898 Test Loss: 0.1009059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0720751\n",
      "\tspeed: 0.0951s/iter; left time: 2075.5827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0661474\n",
      "\tspeed: 0.0536s/iter; left time: 1164.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.35s\n",
      "Steps: 226 | Train Loss: 0.0688003 Vali Loss: 0.0998325 Test Loss: 0.1049393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602776\n",
      "\tspeed: 0.0952s/iter; left time: 2055.1461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615162\n",
      "\tspeed: 0.0537s/iter; left time: 1153.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 226 | Train Loss: 0.0612638 Vali Loss: 0.1016257 Test Loss: 0.1059316\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569761\n",
      "\tspeed: 0.0955s/iter; left time: 2040.9632s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536489\n",
      "\tspeed: 0.0544s/iter; left time: 1157.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0556323 Vali Loss: 0.1015170 Test Loss: 0.1060266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0515332\n",
      "\tspeed: 0.0951s/iter; left time: 2010.9353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0494139\n",
      "\tspeed: 0.0541s/iter; left time: 1138.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0510429 Vali Loss: 0.1021425 Test Loss: 0.1076099\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0495531\n",
      "\tspeed: 0.0952s/iter; left time: 1992.1008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448377\n",
      "\tspeed: 0.0541s/iter; left time: 1127.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0476645 Vali Loss: 0.1027132 Test Loss: 0.1065381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0459595\n",
      "\tspeed: 0.0953s/iter; left time: 1972.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0421387\n",
      "\tspeed: 0.0542s/iter; left time: 1116.0509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0448068 Vali Loss: 0.1028465 Test Loss: 0.1067780\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0415524\n",
      "\tspeed: 0.0951s/iter; left time: 1946.3540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0411832\n",
      "\tspeed: 0.0541s/iter; left time: 1102.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0425342 Vali Loss: 0.1018840 Test Loss: 0.1059912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0416039\n",
      "\tspeed: 0.0952s/iter; left time: 1927.1704s\n",
      "\titers: 200, epoch: 11 | loss: 0.0400221\n",
      "\tspeed: 0.0541s/iter; left time: 1090.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0406519 Vali Loss: 0.1015919 Test Loss: 0.1061520\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0380639\n",
      "\tspeed: 0.0954s/iter; left time: 1909.5089s\n",
      "\titers: 200, epoch: 12 | loss: 0.0371491\n",
      "\tspeed: 0.0542s/iter; left time: 1079.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0392447 Vali Loss: 0.1015829 Test Loss: 0.1071503\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02388782985508442, rmse:0.15455688536167145, mae:0.09838932752609253, rse:0.5454525947570801\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1082842\n",
      "\tspeed: 0.0561s/iter; left time: 1263.0431s\n",
      "\titers: 200, epoch: 1 | loss: 0.0992054\n",
      "\tspeed: 0.0540s/iter; left time: 1210.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 226 | Train Loss: 0.1151996 Vali Loss: 0.1069883 Test Loss: 0.1096331\n",
      "Validation loss decreased (inf --> 0.106988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0803967\n",
      "\tspeed: 0.1008s/iter; left time: 2244.7057s\n",
      "\titers: 200, epoch: 2 | loss: 0.0791126\n",
      "\tspeed: 0.0540s/iter; left time: 1198.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0834008 Vali Loss: 0.0945991 Test Loss: 0.0977492\n",
      "Validation loss decreased (0.106988 --> 0.094599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714960\n",
      "\tspeed: 0.1030s/iter; left time: 2271.0061s\n",
      "\titers: 200, epoch: 3 | loss: 0.0756860\n",
      "\tspeed: 0.0540s/iter; left time: 1185.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0754395 Vali Loss: 0.0975378 Test Loss: 0.1006314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0673068\n",
      "\tspeed: 0.0954s/iter; left time: 2080.9198s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649566\n",
      "\tspeed: 0.0540s/iter; left time: 1174.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0687112 Vali Loss: 0.0975886 Test Loss: 0.1047010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601761\n",
      "\tspeed: 0.0953s/iter; left time: 2057.2955s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578993\n",
      "\tspeed: 0.0541s/iter; left time: 1163.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0612437 Vali Loss: 0.1002051 Test Loss: 0.1077436\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574794\n",
      "\tspeed: 0.0961s/iter; left time: 2053.4366s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536630\n",
      "\tspeed: 0.0539s/iter; left time: 1147.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0554973 Vali Loss: 0.1027811 Test Loss: 0.1079550\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504069\n",
      "\tspeed: 0.0958s/iter; left time: 2024.7226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0509556\n",
      "\tspeed: 0.0539s/iter; left time: 1134.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0511312 Vali Loss: 0.1025358 Test Loss: 0.1072150\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0472141\n",
      "\tspeed: 0.0962s/iter; left time: 2012.6802s\n",
      "\titers: 200, epoch: 8 | loss: 0.0481741\n",
      "\tspeed: 0.0540s/iter; left time: 1123.5094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0475666 Vali Loss: 0.1019304 Test Loss: 0.1083649\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0450273\n",
      "\tspeed: 0.0969s/iter; left time: 2004.3318s\n",
      "\titers: 200, epoch: 9 | loss: 0.0434829\n",
      "\tspeed: 0.0541s/iter; left time: 1113.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.49s\n",
      "Steps: 226 | Train Loss: 0.0448368 Vali Loss: 0.1018909 Test Loss: 0.1080132\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0430186\n",
      "\tspeed: 0.0957s/iter; left time: 1958.0993s\n",
      "\titers: 200, epoch: 10 | loss: 0.0416615\n",
      "\tspeed: 0.0539s/iter; left time: 1098.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0426283 Vali Loss: 0.1012360 Test Loss: 0.1075009\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417660\n",
      "\tspeed: 0.0956s/iter; left time: 1935.5663s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401521\n",
      "\tspeed: 0.0539s/iter; left time: 1085.3783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0407016 Vali Loss: 0.1029636 Test Loss: 0.1072257\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0372848\n",
      "\tspeed: 0.0954s/iter; left time: 1908.5510s\n",
      "\titers: 200, epoch: 12 | loss: 0.0385782\n",
      "\tspeed: 0.0541s/iter; left time: 1077.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0391586 Vali Loss: 0.1025802 Test Loss: 0.1081261\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023594284430146217, rmse:0.15360431373119354, mae:0.09774922579526901, rse:0.5420908331871033\n",
      "Intermediate time for DE and pred_len 24: 00h:06m:13.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1333143\n",
      "\tspeed: 0.0806s/iter; left time: 1805.6530s\n",
      "\titers: 200, epoch: 1 | loss: 0.1251937\n",
      "\tspeed: 0.0548s/iter; left time: 1222.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 225 | Train Loss: 0.1350754 Vali Loss: 0.1330616 Test Loss: 0.1428668\n",
      "Validation loss decreased (inf --> 0.133062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1077519\n",
      "\tspeed: 0.1036s/iter; left time: 2297.4763s\n",
      "\titers: 200, epoch: 2 | loss: 0.0975782\n",
      "\tspeed: 0.0544s/iter; left time: 1200.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 225 | Train Loss: 0.1053988 Vali Loss: 0.1278307 Test Loss: 0.1397810\n",
      "Validation loss decreased (0.133062 --> 0.127831).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860106\n",
      "\tspeed: 0.1036s/iter; left time: 2274.4440s\n",
      "\titers: 200, epoch: 3 | loss: 0.0802355\n",
      "\tspeed: 0.0545s/iter; left time: 1190.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0869836 Vali Loss: 0.1320381 Test Loss: 0.1464900\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0748803\n",
      "\tspeed: 0.0968s/iter; left time: 2104.0879s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696452\n",
      "\tspeed: 0.0545s/iter; left time: 1178.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.49s\n",
      "Steps: 225 | Train Loss: 0.0740799 Vali Loss: 0.1308142 Test Loss: 0.1466282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646656\n",
      "\tspeed: 0.0961s/iter; left time: 2066.0537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0625145\n",
      "\tspeed: 0.0546s/iter; left time: 1167.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0652217 Vali Loss: 0.1311752 Test Loss: 0.1460544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605387\n",
      "\tspeed: 0.0965s/iter; left time: 2053.7771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0579678\n",
      "\tspeed: 0.0544s/iter; left time: 1151.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0588902 Vali Loss: 0.1316790 Test Loss: 0.1448181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562061\n",
      "\tspeed: 0.0966s/iter; left time: 2034.3241s\n",
      "\titers: 200, epoch: 7 | loss: 0.0527901\n",
      "\tspeed: 0.0546s/iter; left time: 1144.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0545442 Vali Loss: 0.1316228 Test Loss: 0.1457958\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0522657\n",
      "\tspeed: 0.0965s/iter; left time: 2008.8307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0514421\n",
      "\tspeed: 0.0547s/iter; left time: 1134.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0511548 Vali Loss: 0.1304799 Test Loss: 0.1432248\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0498829\n",
      "\tspeed: 0.0962s/iter; left time: 1982.7809s\n",
      "\titers: 200, epoch: 9 | loss: 0.0493235\n",
      "\tspeed: 0.0547s/iter; left time: 1121.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0482738 Vali Loss: 0.1298701 Test Loss: 0.1443696\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0474373\n",
      "\tspeed: 0.0965s/iter; left time: 1966.1923s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442286\n",
      "\tspeed: 0.0548s/iter; left time: 1110.2221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0461018 Vali Loss: 0.1297597 Test Loss: 0.1427234\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0449542\n",
      "\tspeed: 0.0969s/iter; left time: 1952.0446s\n",
      "\titers: 200, epoch: 11 | loss: 0.0443833\n",
      "\tspeed: 0.0547s/iter; left time: 1096.9436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0443575 Vali Loss: 0.1303327 Test Loss: 0.1435535\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436924\n",
      "\tspeed: 0.0974s/iter; left time: 1941.4671s\n",
      "\titers: 200, epoch: 12 | loss: 0.0425764\n",
      "\tspeed: 0.0548s/iter; left time: 1086.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0428586 Vali Loss: 0.1291575 Test Loss: 0.1419588\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044566426426172256, rmse:0.21110761165618896, mae:0.1397809535264969, rse:0.7475747466087341\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1305004\n",
      "\tspeed: 0.0564s/iter; left time: 1263.9093s\n",
      "\titers: 200, epoch: 1 | loss: 0.1234168\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.1356182 Vali Loss: 0.1333102 Test Loss: 0.1427393\n",
      "Validation loss decreased (inf --> 0.133310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052246\n",
      "\tspeed: 0.1048s/iter; left time: 2325.0453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0998564\n",
      "\tspeed: 0.0545s/iter; left time: 1203.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 225 | Train Loss: 0.1051226 Vali Loss: 0.1262625 Test Loss: 0.1385605\n",
      "Validation loss decreased (0.133310 --> 0.126263).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0880758\n",
      "\tspeed: 0.1062s/iter; left time: 2331.4872s\n",
      "\titers: 200, epoch: 3 | loss: 0.0775143\n",
      "\tspeed: 0.0546s/iter; left time: 1194.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 225 | Train Loss: 0.0872053 Vali Loss: 0.1273492 Test Loss: 0.1457350\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774589\n",
      "\tspeed: 0.0975s/iter; left time: 2117.5109s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696527\n",
      "\tspeed: 0.0545s/iter; left time: 1178.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0750550 Vali Loss: 0.1297122 Test Loss: 0.1456257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0676311\n",
      "\tspeed: 0.0973s/iter; left time: 2091.6429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631000\n",
      "\tspeed: 0.0545s/iter; left time: 1167.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0665385 Vali Loss: 0.1299191 Test Loss: 0.1467704\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633564\n",
      "\tspeed: 0.0966s/iter; left time: 2056.2984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616689\n",
      "\tspeed: 0.0545s/iter; left time: 1153.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.48s\n",
      "Steps: 225 | Train Loss: 0.0604947 Vali Loss: 0.1298159 Test Loss: 0.1456453\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0547417\n",
      "\tspeed: 0.0975s/iter; left time: 2052.0712s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547419\n",
      "\tspeed: 0.0547s/iter; left time: 1145.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0559934 Vali Loss: 0.1316791 Test Loss: 0.1468673\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542285\n",
      "\tspeed: 0.0974s/iter; left time: 2028.6788s\n",
      "\titers: 200, epoch: 8 | loss: 0.0505886\n",
      "\tspeed: 0.0546s/iter; left time: 1132.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0523586 Vali Loss: 0.1305334 Test Loss: 0.1449758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0514340\n",
      "\tspeed: 0.0974s/iter; left time: 2007.4988s\n",
      "\titers: 200, epoch: 9 | loss: 0.0490581\n",
      "\tspeed: 0.0547s/iter; left time: 1120.5801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0495374 Vali Loss: 0.1299654 Test Loss: 0.1441714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0458724\n",
      "\tspeed: 0.0978s/iter; left time: 1992.7452s\n",
      "\titers: 200, epoch: 10 | loss: 0.0471989\n",
      "\tspeed: 0.0545s/iter; left time: 1104.7199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0471732 Vali Loss: 0.1310883 Test Loss: 0.1436499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0456801\n",
      "\tspeed: 0.0969s/iter; left time: 1952.2006s\n",
      "\titers: 200, epoch: 11 | loss: 0.0444907\n",
      "\tspeed: 0.0547s/iter; left time: 1096.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0452869 Vali Loss: 0.1306960 Test Loss: 0.1433874\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460896\n",
      "\tspeed: 0.0975s/iter; left time: 1942.0439s\n",
      "\titers: 200, epoch: 12 | loss: 0.0449634\n",
      "\tspeed: 0.0547s/iter; left time: 1083.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.50s\n",
      "Steps: 225 | Train Loss: 0.0437059 Vali Loss: 0.1303346 Test Loss: 0.1430011\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043655913323163986, rmse:0.20893996953964233, mae:0.13856051862239838, rse:0.739898681640625\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:20.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1406612\n",
      "\tspeed: 0.0813s/iter; left time: 1821.9597s\n",
      "\titers: 200, epoch: 1 | loss: 0.1266166\n",
      "\tspeed: 0.0553s/iter; left time: 1232.1315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.01s\n",
      "Steps: 225 | Train Loss: 0.1407489 Vali Loss: 0.1362887 Test Loss: 0.1475281\n",
      "Validation loss decreased (inf --> 0.136289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1123547\n",
      "\tspeed: 0.1060s/iter; left time: 2350.5852s\n",
      "\titers: 200, epoch: 2 | loss: 0.0998369\n",
      "\tspeed: 0.0553s/iter; left time: 1220.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 225 | Train Loss: 0.1102064 Vali Loss: 0.1288327 Test Loss: 0.1476617\n",
      "Validation loss decreased (0.136289 --> 0.128833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0934906\n",
      "\tspeed: 0.1184s/iter; left time: 2598.1191s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850151\n",
      "\tspeed: 0.0554s/iter; left time: 1210.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 225 | Train Loss: 0.0920240 Vali Loss: 0.1323475 Test Loss: 0.1512921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801055\n",
      "\tspeed: 0.0994s/iter; left time: 2160.4869s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753021\n",
      "\tspeed: 0.0555s/iter; left time: 1200.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0791172 Vali Loss: 0.1329665 Test Loss: 0.1495522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717403\n",
      "\tspeed: 0.0992s/iter; left time: 2132.2386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685390\n",
      "\tspeed: 0.0556s/iter; left time: 1189.6771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 225 | Train Loss: 0.0701019 Vali Loss: 0.1331651 Test Loss: 0.1500273\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647874\n",
      "\tspeed: 0.0989s/iter; left time: 2103.4644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620601\n",
      "\tspeed: 0.0556s/iter; left time: 1178.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0636788 Vali Loss: 0.1325531 Test Loss: 0.1488694\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585716\n",
      "\tspeed: 0.0991s/iter; left time: 2085.4736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574709\n",
      "\tspeed: 0.0557s/iter; left time: 1167.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0588663 Vali Loss: 0.1338743 Test Loss: 0.1497303\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0562231\n",
      "\tspeed: 0.0985s/iter; left time: 2050.5653s\n",
      "\titers: 200, epoch: 8 | loss: 0.0539397\n",
      "\tspeed: 0.0556s/iter; left time: 1151.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0549779 Vali Loss: 0.1326314 Test Loss: 0.1489142\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546246\n",
      "\tspeed: 0.0988s/iter; left time: 2035.7260s\n",
      "\titers: 200, epoch: 9 | loss: 0.0511219\n",
      "\tspeed: 0.0557s/iter; left time: 1141.8989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0518904 Vali Loss: 0.1327110 Test Loss: 0.1492718\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0489933\n",
      "\tspeed: 0.0993s/iter; left time: 2023.4093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495632\n",
      "\tspeed: 0.0563s/iter; left time: 1141.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.0496443 Vali Loss: 0.1329360 Test Loss: 0.1487178\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491020\n",
      "\tspeed: 0.0983s/iter; left time: 1981.3276s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463657\n",
      "\tspeed: 0.0554s/iter; left time: 1111.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 225 | Train Loss: 0.0475663 Vali Loss: 0.1323775 Test Loss: 0.1490079\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0458864\n",
      "\tspeed: 0.0993s/iter; left time: 1979.5693s\n",
      "\titers: 200, epoch: 12 | loss: 0.0459646\n",
      "\tspeed: 0.0557s/iter; left time: 1103.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0460691 Vali Loss: 0.1317336 Test Loss: 0.1486037\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04906906932592392, rmse:0.22151538729667664, mae:0.1476617008447647, rse:0.7846253514289856\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1341049\n",
      "\tspeed: 0.0573s/iter; left time: 1284.2875s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229856\n",
      "\tspeed: 0.0554s/iter; left time: 1235.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.1405741 Vali Loss: 0.1368361 Test Loss: 0.1474738\n",
      "Validation loss decreased (inf --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093229\n",
      "\tspeed: 0.1060s/iter; left time: 2349.5772s\n",
      "\titers: 200, epoch: 2 | loss: 0.1050066\n",
      "\tspeed: 0.0555s/iter; left time: 1225.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.1096052 Vali Loss: 0.1309860 Test Loss: 0.1463656\n",
      "Validation loss decreased (0.136836 --> 0.130986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0980805\n",
      "\tspeed: 0.1082s/iter; left time: 2375.5044s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870968\n",
      "\tspeed: 0.0556s/iter; left time: 1214.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0911647 Vali Loss: 0.1292951 Test Loss: 0.1477515\n",
      "Validation loss decreased (0.130986 --> 0.129295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790136\n",
      "\tspeed: 0.1057s/iter; left time: 2297.1184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0775671\n",
      "\tspeed: 0.0553s/iter; left time: 1195.1313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0795131 Vali Loss: 0.1314423 Test Loss: 0.1489823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0720552\n",
      "\tspeed: 0.0998s/iter; left time: 2145.9261s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685515\n",
      "\tspeed: 0.0556s/iter; left time: 1190.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0707013 Vali Loss: 0.1314861 Test Loss: 0.1465668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0642642\n",
      "\tspeed: 0.1004s/iter; left time: 2136.9772s\n",
      "\titers: 200, epoch: 6 | loss: 0.0629607\n",
      "\tspeed: 0.0557s/iter; left time: 1179.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.81s\n",
      "Steps: 225 | Train Loss: 0.0642900 Vali Loss: 0.1314789 Test Loss: 0.1468510\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0586436\n",
      "\tspeed: 0.0995s/iter; left time: 2094.8741s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583489\n",
      "\tspeed: 0.0557s/iter; left time: 1167.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 225 | Train Loss: 0.0594529 Vali Loss: 0.1322349 Test Loss: 0.1468181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0529839\n",
      "\tspeed: 0.1001s/iter; left time: 2084.4608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0555473\n",
      "\tspeed: 0.0558s/iter; left time: 1156.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0556102 Vali Loss: 0.1325815 Test Loss: 0.1473669\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0529180\n",
      "\tspeed: 0.1001s/iter; left time: 2062.4197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533149\n",
      "\tspeed: 0.0557s/iter; left time: 1141.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.0525686 Vali Loss: 0.1319998 Test Loss: 0.1462125\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0504318\n",
      "\tspeed: 0.1009s/iter; left time: 2055.8093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495035\n",
      "\tspeed: 0.0558s/iter; left time: 1131.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0500964 Vali Loss: 0.1321188 Test Loss: 0.1462528\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0475139\n",
      "\tspeed: 0.1005s/iter; left time: 2025.5498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0480725\n",
      "\tspeed: 0.0558s/iter; left time: 1119.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 225 | Train Loss: 0.0480424 Vali Loss: 0.1319406 Test Loss: 0.1465782\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0473353\n",
      "\tspeed: 0.0999s/iter; left time: 1991.1849s\n",
      "\titers: 200, epoch: 12 | loss: 0.0451364\n",
      "\tspeed: 0.0557s/iter; left time: 1104.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0465250 Vali Loss: 0.1323243 Test Loss: 0.1460133\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0460064\n",
      "\tspeed: 0.0999s/iter; left time: 1968.4834s\n",
      "\titers: 200, epoch: 13 | loss: 0.0453575\n",
      "\tspeed: 0.0558s/iter; left time: 1093.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0450981 Vali Loss: 0.1323807 Test Loss: 0.1469318\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048308685421943665, rmse:0.21979236602783203, mae:0.14775153994560242, rse:0.778522253036499\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:46.33s\n",
      "Intermediate time for DE: 00h:19m:20.46s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1072044\n",
      "\tspeed: 0.0786s/iter; left time: 1767.6743s\n",
      "\titers: 200, epoch: 1 | loss: 0.0951643\n",
      "\tspeed: 0.0540s/iter; left time: 1209.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 226 | Train Loss: 0.1079968 Vali Loss: 0.1030718 Test Loss: 0.1146087\n",
      "Validation loss decreased (inf --> 0.103072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0816555\n",
      "\tspeed: 0.0995s/iter; left time: 2217.3235s\n",
      "\titers: 200, epoch: 2 | loss: 0.0808995\n",
      "\tspeed: 0.0537s/iter; left time: 1190.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0827446 Vali Loss: 0.0940444 Test Loss: 0.1063824\n",
      "Validation loss decreased (0.103072 --> 0.094044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0760829\n",
      "\tspeed: 0.1000s/iter; left time: 2205.3408s\n",
      "\titers: 200, epoch: 3 | loss: 0.0732299\n",
      "\tspeed: 0.0539s/iter; left time: 1184.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.35s\n",
      "Steps: 226 | Train Loss: 0.0766084 Vali Loss: 0.0963815 Test Loss: 0.1070990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731442\n",
      "\tspeed: 0.0958s/iter; left time: 2090.6086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649460\n",
      "\tspeed: 0.0538s/iter; left time: 1169.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0708761 Vali Loss: 0.1001709 Test Loss: 0.1115133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635758\n",
      "\tspeed: 0.0943s/iter; left time: 2036.2944s\n",
      "\titers: 200, epoch: 5 | loss: 0.0592086\n",
      "\tspeed: 0.0538s/iter; left time: 1157.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0635158 Vali Loss: 0.1023092 Test Loss: 0.1153543\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608806\n",
      "\tspeed: 0.0952s/iter; left time: 2034.2306s\n",
      "\titers: 200, epoch: 6 | loss: 0.0543686\n",
      "\tspeed: 0.0538s/iter; left time: 1144.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 226 | Train Loss: 0.0576630 Vali Loss: 0.1039233 Test Loss: 0.1179941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0538294\n",
      "\tspeed: 0.0950s/iter; left time: 2009.7429s\n",
      "\titers: 200, epoch: 7 | loss: 0.0526221\n",
      "\tspeed: 0.0539s/iter; left time: 1134.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.41s\n",
      "Steps: 226 | Train Loss: 0.0529325 Vali Loss: 0.1035913 Test Loss: 0.1165399\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0469315\n",
      "\tspeed: 0.0957s/iter; left time: 2001.8665s\n",
      "\titers: 200, epoch: 8 | loss: 0.0458908\n",
      "\tspeed: 0.0539s/iter; left time: 1122.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.41s\n",
      "Steps: 226 | Train Loss: 0.0494196 Vali Loss: 0.1039378 Test Loss: 0.1181313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0466256\n",
      "\tspeed: 0.0954s/iter; left time: 1975.0582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0455476\n",
      "\tspeed: 0.0539s/iter; left time: 1110.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.39s\n",
      "Steps: 226 | Train Loss: 0.0467545 Vali Loss: 0.1043459 Test Loss: 0.1177842\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0431702\n",
      "\tspeed: 0.0952s/iter; left time: 1948.8309s\n",
      "\titers: 200, epoch: 10 | loss: 0.0449245\n",
      "\tspeed: 0.0539s/iter; left time: 1098.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0445734 Vali Loss: 0.1038292 Test Loss: 0.1176439\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0421189\n",
      "\tspeed: 0.0948s/iter; left time: 1919.5672s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424473\n",
      "\tspeed: 0.0538s/iter; left time: 1083.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.36s\n",
      "Steps: 226 | Train Loss: 0.0426050 Vali Loss: 0.1039291 Test Loss: 0.1180243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0409853\n",
      "\tspeed: 0.0952s/iter; left time: 1904.4688s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414068\n",
      "\tspeed: 0.0539s/iter; left time: 1073.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0411548 Vali Loss: 0.1045172 Test Loss: 0.1169467\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026635607704520226, rmse:0.16320419311523438, mae:0.10638243705034256, rse:0.563008189201355\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1042103\n",
      "\tspeed: 0.0561s/iter; left time: 1261.4758s\n",
      "\titers: 200, epoch: 1 | loss: 0.0932506\n",
      "\tspeed: 0.0539s/iter; left time: 1206.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.1075098 Vali Loss: 0.1026871 Test Loss: 0.1146050\n",
      "Validation loss decreased (inf --> 0.102687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0827916\n",
      "\tspeed: 0.1014s/iter; left time: 2257.7162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818547\n",
      "\tspeed: 0.0539s/iter; left time: 1194.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0825427 Vali Loss: 0.0944417 Test Loss: 0.1071549\n",
      "Validation loss decreased (0.102687 --> 0.094442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0784460\n",
      "\tspeed: 0.1054s/iter; left time: 2323.6474s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800908\n",
      "\tspeed: 0.0542s/iter; left time: 1188.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 226 | Train Loss: 0.0764160 Vali Loss: 0.0986362 Test Loss: 0.1106796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0702497\n",
      "\tspeed: 0.0965s/iter; left time: 2105.3325s\n",
      "\titers: 200, epoch: 4 | loss: 0.0669691\n",
      "\tspeed: 0.0545s/iter; left time: 1183.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 226 | Train Loss: 0.0708451 Vali Loss: 0.1004043 Test Loss: 0.1111616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0623640\n",
      "\tspeed: 0.0961s/iter; left time: 2075.6338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600077\n",
      "\tspeed: 0.0539s/iter; left time: 1158.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0637427 Vali Loss: 0.1038250 Test Loss: 0.1157895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0550858\n",
      "\tspeed: 0.0959s/iter; left time: 2050.1717s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539705\n",
      "\tspeed: 0.0539s/iter; left time: 1146.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0573438 Vali Loss: 0.1033683 Test Loss: 0.1150562\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0536134\n",
      "\tspeed: 0.0968s/iter; left time: 2047.0676s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535443\n",
      "\tspeed: 0.0541s/iter; left time: 1138.5853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 226 | Train Loss: 0.0528843 Vali Loss: 0.1041554 Test Loss: 0.1172957\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0484644\n",
      "\tspeed: 0.0965s/iter; left time: 2019.0239s\n",
      "\titers: 200, epoch: 8 | loss: 0.0483736\n",
      "\tspeed: 0.0540s/iter; left time: 1123.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0493472 Vali Loss: 0.1026578 Test Loss: 0.1171316\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0469961\n",
      "\tspeed: 0.0967s/iter; left time: 2000.5807s\n",
      "\titers: 200, epoch: 9 | loss: 0.0460768\n",
      "\tspeed: 0.0540s/iter; left time: 1112.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 226 | Train Loss: 0.0465694 Vali Loss: 0.1035185 Test Loss: 0.1190842\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0451379\n",
      "\tspeed: 0.0964s/iter; left time: 1972.4274s\n",
      "\titers: 200, epoch: 10 | loss: 0.0406100\n",
      "\tspeed: 0.0539s/iter; left time: 1096.7785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0443786 Vali Loss: 0.1039430 Test Loss: 0.1190374\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0438192\n",
      "\tspeed: 0.0959s/iter; left time: 1940.1868s\n",
      "\titers: 200, epoch: 11 | loss: 0.0421218\n",
      "\tspeed: 0.0555s/iter; left time: 1117.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 226 | Train Loss: 0.0426470 Vali Loss: 0.1028817 Test Loss: 0.1179599\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0415459\n",
      "\tspeed: 0.0964s/iter; left time: 1929.2857s\n",
      "\titers: 200, epoch: 12 | loss: 0.0380141\n",
      "\tspeed: 0.0539s/iter; left time: 1073.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0410800 Vali Loss: 0.1028472 Test Loss: 0.1175687\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02711082622408867, rmse:0.16465365886688232, mae:0.10715489089488983, rse:0.5680084228515625\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:14.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1224959\n",
      "\tspeed: 0.0794s/iter; left time: 1778.2693s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160363\n",
      "\tspeed: 0.0544s/iter; left time: 1212.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 225 | Train Loss: 0.1264180 Vali Loss: 0.1264964 Test Loss: 0.1495192\n",
      "Validation loss decreased (inf --> 0.126496).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1015343\n",
      "\tspeed: 0.1027s/iter; left time: 2276.9056s\n",
      "\titers: 200, epoch: 2 | loss: 0.0967856\n",
      "\tspeed: 0.0543s/iter; left time: 1198.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 225 | Train Loss: 0.1042453 Vali Loss: 0.1274836 Test Loss: 0.1481230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0864128\n",
      "\tspeed: 0.0965s/iter; left time: 2117.5043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0791574\n",
      "\tspeed: 0.0546s/iter; left time: 1192.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0861891 Vali Loss: 0.1317791 Test Loss: 0.1499434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0738536\n",
      "\tspeed: 0.0977s/iter; left time: 2123.5571s\n",
      "\titers: 200, epoch: 4 | loss: 0.0709162\n",
      "\tspeed: 0.0548s/iter; left time: 1184.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 225 | Train Loss: 0.0740018 Vali Loss: 0.1332169 Test Loss: 0.1512938\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0641737\n",
      "\tspeed: 0.0975s/iter; left time: 2096.8685s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619924\n",
      "\tspeed: 0.0556s/iter; left time: 1190.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 225 | Train Loss: 0.0658201 Vali Loss: 0.1321504 Test Loss: 0.1486785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0650147\n",
      "\tspeed: 0.0968s/iter; left time: 2059.4686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601501\n",
      "\tspeed: 0.0548s/iter; left time: 1159.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 225 | Train Loss: 0.0600249 Vali Loss: 0.1300616 Test Loss: 0.1472222\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0559322\n",
      "\tspeed: 0.0976s/iter; left time: 2055.4552s\n",
      "\titers: 200, epoch: 7 | loss: 0.0548691\n",
      "\tspeed: 0.0547s/iter; left time: 1146.2895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 225 | Train Loss: 0.0557527 Vali Loss: 0.1297588 Test Loss: 0.1476926\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0536059\n",
      "\tspeed: 0.0980s/iter; left time: 2040.6234s\n",
      "\titers: 200, epoch: 8 | loss: 0.0512451\n",
      "\tspeed: 0.0548s/iter; left time: 1136.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 225 | Train Loss: 0.0522174 Vali Loss: 0.1293977 Test Loss: 0.1473823\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0519575\n",
      "\tspeed: 0.0965s/iter; left time: 1988.2710s\n",
      "\titers: 200, epoch: 9 | loss: 0.0481727\n",
      "\tspeed: 0.0548s/iter; left time: 1122.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0496511 Vali Loss: 0.1290194 Test Loss: 0.1478664\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0496600\n",
      "\tspeed: 0.0967s/iter; left time: 1970.9368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0457158\n",
      "\tspeed: 0.0547s/iter; left time: 1108.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0476154 Vali Loss: 0.1298917 Test Loss: 0.1480776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0454857\n",
      "\tspeed: 0.0976s/iter; left time: 1966.1850s\n",
      "\titers: 200, epoch: 11 | loss: 0.0459605\n",
      "\tspeed: 0.0544s/iter; left time: 1090.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 225 | Train Loss: 0.0456645 Vali Loss: 0.1294558 Test Loss: 0.1472701\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04690314456820488, rmse:0.21657133102416992, mae:0.1495191603899002, rse:0.7489338517189026\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204169\n",
      "\tspeed: 0.0564s/iter; left time: 1263.7660s\n",
      "\titers: 200, epoch: 1 | loss: 0.1210315\n",
      "\tspeed: 0.0548s/iter; left time: 1221.2591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.1264303 Vali Loss: 0.1267682 Test Loss: 0.1500666\n",
      "Validation loss decreased (inf --> 0.126768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038851\n",
      "\tspeed: 0.1034s/iter; left time: 2292.6868s\n",
      "\titers: 200, epoch: 2 | loss: 0.0967694\n",
      "\tspeed: 0.0547s/iter; left time: 1206.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.1041979 Vali Loss: 0.1256004 Test Loss: 0.1480494\n",
      "Validation loss decreased (0.126768 --> 0.125600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878237\n",
      "\tspeed: 0.1064s/iter; left time: 2336.6296s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822762\n",
      "\tspeed: 0.0550s/iter; left time: 1200.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 225 | Train Loss: 0.0872704 Vali Loss: 0.1323572 Test Loss: 0.1491212\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0741254\n",
      "\tspeed: 0.0977s/iter; left time: 2122.8647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0698530\n",
      "\tspeed: 0.0547s/iter; left time: 1183.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 225 | Train Loss: 0.0750340 Vali Loss: 0.1311133 Test Loss: 0.1477416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693829\n",
      "\tspeed: 0.0972s/iter; left time: 2089.9905s\n",
      "\titers: 200, epoch: 5 | loss: 0.0645594\n",
      "\tspeed: 0.0548s/iter; left time: 1173.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.0664887 Vali Loss: 0.1336191 Test Loss: 0.1488445\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612510\n",
      "\tspeed: 0.0973s/iter; left time: 2069.5119s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586281\n",
      "\tspeed: 0.0548s/iter; left time: 1160.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0607296 Vali Loss: 0.1320561 Test Loss: 0.1481156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588017\n",
      "\tspeed: 0.0973s/iter; left time: 2049.2679s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571976\n",
      "\tspeed: 0.0550s/iter; left time: 1151.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 225 | Train Loss: 0.0563253 Vali Loss: 0.1312302 Test Loss: 0.1483136\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542190\n",
      "\tspeed: 0.0971s/iter; left time: 2022.5554s\n",
      "\titers: 200, epoch: 8 | loss: 0.0522542\n",
      "\tspeed: 0.0547s/iter; left time: 1134.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0530697 Vali Loss: 0.1308068 Test Loss: 0.1491268\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0506167\n",
      "\tspeed: 0.0973s/iter; left time: 2005.4254s\n",
      "\titers: 200, epoch: 9 | loss: 0.0504119\n",
      "\tspeed: 0.0548s/iter; left time: 1123.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.0503541 Vali Loss: 0.1314857 Test Loss: 0.1501446\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0487696\n",
      "\tspeed: 0.0991s/iter; left time: 2018.6253s\n",
      "\titers: 200, epoch: 10 | loss: 0.0470511\n",
      "\tspeed: 0.0547s/iter; left time: 1109.0798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 225 | Train Loss: 0.0481307 Vali Loss: 0.1304721 Test Loss: 0.1489927\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0467205\n",
      "\tspeed: 0.0985s/iter; left time: 1983.9773s\n",
      "\titers: 200, epoch: 11 | loss: 0.0455113\n",
      "\tspeed: 0.0554s/iter; left time: 1111.6115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 225 | Train Loss: 0.0463793 Vali Loss: 0.1308019 Test Loss: 0.1496024\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0444195\n",
      "\tspeed: 0.0970s/iter; left time: 1932.3585s\n",
      "\titers: 200, epoch: 12 | loss: 0.0439973\n",
      "\tspeed: 0.0546s/iter; left time: 1081.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0448083 Vali Loss: 0.1303113 Test Loss: 0.1486246\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.050691790878772736, rmse:0.22514837980270386, mae:0.14804944396018982, rse:0.778594434261322\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:04.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1288887\n",
      "\tspeed: 0.0696s/iter; left time: 1558.6362s\n",
      "\titers: 200, epoch: 1 | loss: 0.1188913\n",
      "\tspeed: 0.0553s/iter; left time: 1233.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.12s\n",
      "Steps: 225 | Train Loss: 0.1306679 Vali Loss: 0.1317371 Test Loss: 0.1554242\n",
      "Validation loss decreased (inf --> 0.131737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093038\n",
      "\tspeed: 0.1041s/iter; left time: 2309.5830s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008310\n",
      "\tspeed: 0.0554s/iter; left time: 1222.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.1087003 Vali Loss: 0.1309559 Test Loss: 0.1525646\n",
      "Validation loss decreased (0.131737 --> 0.130956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0931468\n",
      "\tspeed: 0.1082s/iter; left time: 2375.5824s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867372\n",
      "\tspeed: 0.0554s/iter; left time: 1210.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0920048 Vali Loss: 0.1374218 Test Loss: 0.1584887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0782648\n",
      "\tspeed: 0.0990s/iter; left time: 2150.6331s\n",
      "\titers: 200, epoch: 4 | loss: 0.0778771\n",
      "\tspeed: 0.0552s/iter; left time: 1194.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 225 | Train Loss: 0.0791273 Vali Loss: 0.1383448 Test Loss: 0.1598979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701911\n",
      "\tspeed: 0.0978s/iter; left time: 2102.4045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0679734\n",
      "\tspeed: 0.0553s/iter; left time: 1182.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 225 | Train Loss: 0.0701510 Vali Loss: 0.1353877 Test Loss: 0.1583329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641981\n",
      "\tspeed: 0.0986s/iter; left time: 2096.9245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613489\n",
      "\tspeed: 0.0558s/iter; left time: 1180.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0640993 Vali Loss: 0.1362790 Test Loss: 0.1578299\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588057\n",
      "\tspeed: 0.0995s/iter; left time: 2094.6130s\n",
      "\titers: 200, epoch: 7 | loss: 0.0576348\n",
      "\tspeed: 0.0557s/iter; left time: 1166.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0595149 Vali Loss: 0.1357229 Test Loss: 0.1558924\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553018\n",
      "\tspeed: 0.0984s/iter; left time: 2049.6087s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570081\n",
      "\tspeed: 0.0556s/iter; left time: 1153.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0560118 Vali Loss: 0.1362291 Test Loss: 0.1570979\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547959\n",
      "\tspeed: 0.0986s/iter; left time: 2030.8818s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533020\n",
      "\tspeed: 0.0556s/iter; left time: 1140.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0530366 Vali Loss: 0.1346605 Test Loss: 0.1572518\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0522824\n",
      "\tspeed: 0.0996s/iter; left time: 2030.3171s\n",
      "\titers: 200, epoch: 10 | loss: 0.0514619\n",
      "\tspeed: 0.0561s/iter; left time: 1137.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.81s\n",
      "Steps: 225 | Train Loss: 0.0510274 Vali Loss: 0.1349460 Test Loss: 0.1567449\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491573\n",
      "\tspeed: 0.0982s/iter; left time: 1978.8315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0496059\n",
      "\tspeed: 0.0556s/iter; left time: 1114.6446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0489246 Vali Loss: 0.1346077 Test Loss: 0.1561785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0472633\n",
      "\tspeed: 0.0989s/iter; left time: 1969.7791s\n",
      "\titers: 200, epoch: 12 | loss: 0.0458323\n",
      "\tspeed: 0.0556s/iter; left time: 1103.2142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 225 | Train Loss: 0.0473697 Vali Loss: 0.1348265 Test Loss: 0.1564500\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0517885722219944, rmse:0.2275710254907608, mae:0.15256451070308685, rse:0.7890214323997498\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1248131\n",
      "\tspeed: 0.0573s/iter; left time: 1283.9049s\n",
      "\titers: 200, epoch: 1 | loss: 0.1162502\n",
      "\tspeed: 0.0554s/iter; left time: 1236.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.1305182 Vali Loss: 0.1320111 Test Loss: 0.1555002\n",
      "Validation loss decreased (inf --> 0.132011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1084589\n",
      "\tspeed: 0.1100s/iter; left time: 2440.3032s\n",
      "\titers: 200, epoch: 2 | loss: 0.1009342\n",
      "\tspeed: 0.0555s/iter; left time: 1224.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.1087005 Vali Loss: 0.1299949 Test Loss: 0.1539840\n",
      "Validation loss decreased (0.132011 --> 0.129995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939816\n",
      "\tspeed: 0.1103s/iter; left time: 2420.6642s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884041\n",
      "\tspeed: 0.0556s/iter; left time: 1215.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0910439 Vali Loss: 0.1361523 Test Loss: 0.1550590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0779125\n",
      "\tspeed: 0.1028s/iter; left time: 2232.6311s\n",
      "\titers: 200, epoch: 4 | loss: 0.0742685\n",
      "\tspeed: 0.0557s/iter; left time: 1204.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0776980 Vali Loss: 0.1395256 Test Loss: 0.1581779\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0682881\n",
      "\tspeed: 0.0994s/iter; left time: 2136.5027s\n",
      "\titers: 200, epoch: 5 | loss: 0.0675382\n",
      "\tspeed: 0.0555s/iter; left time: 1188.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 225 | Train Loss: 0.0694059 Vali Loss: 0.1372489 Test Loss: 0.1539304\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626082\n",
      "\tspeed: 0.1008s/iter; left time: 2143.9269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620468\n",
      "\tspeed: 0.0560s/iter; left time: 1185.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0636043 Vali Loss: 0.1361786 Test Loss: 0.1553313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572737\n",
      "\tspeed: 0.1002s/iter; left time: 2109.1299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601258\n",
      "\tspeed: 0.0556s/iter; left time: 1164.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0594467 Vali Loss: 0.1364768 Test Loss: 0.1566423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0548176\n",
      "\tspeed: 0.1003s/iter; left time: 2088.0351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569865\n",
      "\tspeed: 0.0557s/iter; left time: 1154.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.99s\n",
      "Steps: 225 | Train Loss: 0.0559141 Vali Loss: 0.1353940 Test Loss: 0.1561464\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0526453\n",
      "\tspeed: 0.1018s/iter; left time: 2097.4749s\n",
      "\titers: 200, epoch: 9 | loss: 0.0528355\n",
      "\tspeed: 0.0557s/iter; left time: 1141.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0528804 Vali Loss: 0.1361213 Test Loss: 0.1554508\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0506995\n",
      "\tspeed: 0.1013s/iter; left time: 2064.8186s\n",
      "\titers: 200, epoch: 10 | loss: 0.0504092\n",
      "\tspeed: 0.0557s/iter; left time: 1130.2357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0507411 Vali Loss: 0.1342339 Test Loss: 0.1568171\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0480116\n",
      "\tspeed: 0.1010s/iter; left time: 2035.4964s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484144\n",
      "\tspeed: 0.0557s/iter; left time: 1117.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 225 | Train Loss: 0.0486653 Vali Loss: 0.1335320 Test Loss: 0.1558110\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0486329\n",
      "\tspeed: 0.1006s/iter; left time: 2004.8748s\n",
      "\titers: 200, epoch: 12 | loss: 0.0467156\n",
      "\tspeed: 0.0556s/iter; left time: 1103.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 225 | Train Loss: 0.0471598 Vali Loss: 0.1340976 Test Loss: 0.1550207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05241897702217102, rmse:0.22895191609859467, mae:0.15398409962654114, rse:0.793809175491333\n",
      "Intermediate time for GB and pred_len 168: 00h:06m:26.76s\n",
      "Intermediate time for GB: 00h:18m:45.32s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1124842\n",
      "\tspeed: 0.0435s/iter; left time: 977.6714s\n",
      "\titers: 200, epoch: 1 | loss: 0.1009502\n",
      "\tspeed: 0.0179s/iter; left time: 399.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.1213686 Vali Loss: 0.0879941 Test Loss: 0.0994127\n",
      "Validation loss decreased (inf --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707472\n",
      "\tspeed: 0.0431s/iter; left time: 959.2595s\n",
      "\titers: 200, epoch: 2 | loss: 0.0645977\n",
      "\tspeed: 0.0183s/iter; left time: 405.0563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0720836 Vali Loss: 0.0634934 Test Loss: 0.0713428\n",
      "Validation loss decreased (0.087994 --> 0.063493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0628835\n",
      "\tspeed: 0.0401s/iter; left time: 884.4265s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655793\n",
      "\tspeed: 0.0179s/iter; left time: 393.4010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0632510 Vali Loss: 0.0608880 Test Loss: 0.0694066\n",
      "Validation loss decreased (0.063493 --> 0.060888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623999\n",
      "\tspeed: 0.0389s/iter; left time: 848.0771s\n",
      "\titers: 200, epoch: 4 | loss: 0.0592492\n",
      "\tspeed: 0.0187s/iter; left time: 405.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 226 | Train Loss: 0.0605673 Vali Loss: 0.0586846 Test Loss: 0.0669195\n",
      "Validation loss decreased (0.060888 --> 0.058685).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610170\n",
      "\tspeed: 0.0385s/iter; left time: 831.3171s\n",
      "\titers: 200, epoch: 5 | loss: 0.0594257\n",
      "\tspeed: 0.0178s/iter; left time: 382.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0587278 Vali Loss: 0.0585923 Test Loss: 0.0662567\n",
      "Validation loss decreased (0.058685 --> 0.058592).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599013\n",
      "\tspeed: 0.0387s/iter; left time: 826.1073s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568876\n",
      "\tspeed: 0.0177s/iter; left time: 377.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0571984 Vali Loss: 0.0573838 Test Loss: 0.0652744\n",
      "Validation loss decreased (0.058592 --> 0.057384).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0586293\n",
      "\tspeed: 0.0387s/iter; left time: 818.6383s\n",
      "\titers: 200, epoch: 7 | loss: 0.0559175\n",
      "\tspeed: 0.0177s/iter; left time: 372.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0558528 Vali Loss: 0.0571522 Test Loss: 0.0649240\n",
      "Validation loss decreased (0.057384 --> 0.057152).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0558720\n",
      "\tspeed: 0.0383s/iter; left time: 802.0610s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558167\n",
      "\tspeed: 0.0177s/iter; left time: 368.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0545714 Vali Loss: 0.0568685 Test Loss: 0.0653187\n",
      "Validation loss decreased (0.057152 --> 0.056869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0553593\n",
      "\tspeed: 0.0401s/iter; left time: 829.8921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0535859\n",
      "\tspeed: 0.0177s/iter; left time: 364.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0533603 Vali Loss: 0.0568295 Test Loss: 0.0647412\n",
      "Validation loss decreased (0.056869 --> 0.056830).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0508198\n",
      "\tspeed: 0.0381s/iter; left time: 779.0923s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548194\n",
      "\tspeed: 0.0177s/iter; left time: 361.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0524042 Vali Loss: 0.0572606 Test Loss: 0.0660838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0531354\n",
      "\tspeed: 0.0367s/iter; left time: 742.2749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0466009\n",
      "\tspeed: 0.0185s/iter; left time: 373.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0513938 Vali Loss: 0.0570663 Test Loss: 0.0655558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0510062\n",
      "\tspeed: 0.0373s/iter; left time: 746.1600s\n",
      "\titers: 200, epoch: 12 | loss: 0.0492757\n",
      "\tspeed: 0.0177s/iter; left time: 353.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0503798 Vali Loss: 0.0571216 Test Loss: 0.0652722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0488996\n",
      "\tspeed: 0.0369s/iter; left time: 729.9008s\n",
      "\titers: 200, epoch: 13 | loss: 0.0487254\n",
      "\tspeed: 0.0178s/iter; left time: 351.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0494039 Vali Loss: 0.0569635 Test Loss: 0.0654164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505270\n",
      "\tspeed: 0.0371s/iter; left time: 725.8340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0481179\n",
      "\tspeed: 0.0178s/iter; left time: 345.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0486680 Vali Loss: 0.0574444 Test Loss: 0.0659121\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0461680\n",
      "\tspeed: 0.0373s/iter; left time: 720.8922s\n",
      "\titers: 200, epoch: 15 | loss: 0.0467860\n",
      "\tspeed: 0.0182s/iter; left time: 349.3139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0477979 Vali Loss: 0.0575305 Test Loss: 0.0660432\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0470566\n",
      "\tspeed: 0.0371s/iter; left time: 709.7160s\n",
      "\titers: 200, epoch: 16 | loss: 0.0462770\n",
      "\tspeed: 0.0177s/iter; left time: 336.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0470584 Vali Loss: 0.0576381 Test Loss: 0.0664225\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0478649\n",
      "\tspeed: 0.0371s/iter; left time: 701.2459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425138\n",
      "\tspeed: 0.0179s/iter; left time: 335.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0464450 Vali Loss: 0.0574624 Test Loss: 0.0663594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0444574\n",
      "\tspeed: 0.0374s/iter; left time: 698.2273s\n",
      "\titers: 200, epoch: 18 | loss: 0.0454440\n",
      "\tspeed: 0.0178s/iter; left time: 330.8416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0458276 Vali Loss: 0.0578417 Test Loss: 0.0663731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0459243\n",
      "\tspeed: 0.0370s/iter; left time: 682.8415s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441686\n",
      "\tspeed: 0.0177s/iter; left time: 324.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0454053 Vali Loss: 0.0574835 Test Loss: 0.0664394\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011007036082446575, rmse:0.10491441935300827, mae:0.06474124640226364, rse:0.3087504804134369\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1162311\n",
      "\tspeed: 0.0199s/iter; left time: 446.6532s\n",
      "\titers: 200, epoch: 1 | loss: 0.1004892\n",
      "\tspeed: 0.0177s/iter; left time: 396.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.1192099 Vali Loss: 0.0875229 Test Loss: 0.0998294\n",
      "Validation loss decreased (inf --> 0.087523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0695417\n",
      "\tspeed: 0.0394s/iter; left time: 877.8776s\n",
      "\titers: 200, epoch: 2 | loss: 0.0663097\n",
      "\tspeed: 0.0177s/iter; left time: 393.5928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0719416 Vali Loss: 0.0630254 Test Loss: 0.0715464\n",
      "Validation loss decreased (0.087523 --> 0.063025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0648911\n",
      "\tspeed: 0.0409s/iter; left time: 901.0587s\n",
      "\titers: 200, epoch: 3 | loss: 0.0603960\n",
      "\tspeed: 0.0179s/iter; left time: 393.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0634335 Vali Loss: 0.0601272 Test Loss: 0.0680579\n",
      "Validation loss decreased (0.063025 --> 0.060127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630488\n",
      "\tspeed: 0.0405s/iter; left time: 883.9154s\n",
      "\titers: 200, epoch: 4 | loss: 0.0593784\n",
      "\tspeed: 0.0178s/iter; left time: 387.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0606399 Vali Loss: 0.0588839 Test Loss: 0.0669874\n",
      "Validation loss decreased (0.060127 --> 0.058884).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0567448\n",
      "\tspeed: 0.0398s/iter; left time: 858.8286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588744\n",
      "\tspeed: 0.0177s/iter; left time: 380.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0587466 Vali Loss: 0.0579996 Test Loss: 0.0665329\n",
      "Validation loss decreased (0.058884 --> 0.058000).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0600855\n",
      "\tspeed: 0.0410s/iter; left time: 876.9776s\n",
      "\titers: 200, epoch: 6 | loss: 0.0577135\n",
      "\tspeed: 0.0183s/iter; left time: 389.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0572608 Vali Loss: 0.0569367 Test Loss: 0.0653062\n",
      "Validation loss decreased (0.058000 --> 0.056937).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542247\n",
      "\tspeed: 0.0402s/iter; left time: 850.3942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0564543\n",
      "\tspeed: 0.0187s/iter; left time: 393.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0559290 Vali Loss: 0.0568971 Test Loss: 0.0651867\n",
      "Validation loss decreased (0.056937 --> 0.056897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0523716\n",
      "\tspeed: 0.0396s/iter; left time: 828.9344s\n",
      "\titers: 200, epoch: 8 | loss: 0.0535895\n",
      "\tspeed: 0.0178s/iter; left time: 369.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0547411 Vali Loss: 0.0569282 Test Loss: 0.0659702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539846\n",
      "\tspeed: 0.0388s/iter; left time: 803.4854s\n",
      "\titers: 200, epoch: 9 | loss: 0.0507050\n",
      "\tspeed: 0.0177s/iter; left time: 365.3535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0535003 Vali Loss: 0.0565453 Test Loss: 0.0662685\n",
      "Validation loss decreased (0.056897 --> 0.056545).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0525033\n",
      "\tspeed: 0.0397s/iter; left time: 811.6616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0521336\n",
      "\tspeed: 0.0178s/iter; left time: 361.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0524343 Vali Loss: 0.0562809 Test Loss: 0.0650042\n",
      "Validation loss decreased (0.056545 --> 0.056281).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0512471\n",
      "\tspeed: 0.0393s/iter; left time: 796.4033s\n",
      "\titers: 200, epoch: 11 | loss: 0.0523231\n",
      "\tspeed: 0.0178s/iter; left time: 359.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0514645 Vali Loss: 0.0561214 Test Loss: 0.0655144\n",
      "Validation loss decreased (0.056281 --> 0.056121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0517867\n",
      "\tspeed: 0.0397s/iter; left time: 793.6812s\n",
      "\titers: 200, epoch: 12 | loss: 0.0496815\n",
      "\tspeed: 0.0178s/iter; left time: 353.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0505630 Vali Loss: 0.0565962 Test Loss: 0.0661952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0490189\n",
      "\tspeed: 0.0378s/iter; left time: 748.0168s\n",
      "\titers: 200, epoch: 13 | loss: 0.0488397\n",
      "\tspeed: 0.0180s/iter; left time: 354.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0496286 Vali Loss: 0.0564829 Test Loss: 0.0664086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0473826\n",
      "\tspeed: 0.0378s/iter; left time: 739.7137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0479432\n",
      "\tspeed: 0.0177s/iter; left time: 345.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0488122 Vali Loss: 0.0564987 Test Loss: 0.0658618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0467108\n",
      "\tspeed: 0.0380s/iter; left time: 733.8844s\n",
      "\titers: 200, epoch: 15 | loss: 0.0534318\n",
      "\tspeed: 0.0178s/iter; left time: 342.2381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0481202 Vali Loss: 0.0566211 Test Loss: 0.0662000\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0479798\n",
      "\tspeed: 0.0381s/iter; left time: 727.2640s\n",
      "\titers: 200, epoch: 16 | loss: 0.0490280\n",
      "\tspeed: 0.0179s/iter; left time: 339.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0474466 Vali Loss: 0.0568491 Test Loss: 0.0672643\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0487071\n",
      "\tspeed: 0.0384s/iter; left time: 724.7280s\n",
      "\titers: 200, epoch: 17 | loss: 0.0477347\n",
      "\tspeed: 0.0177s/iter; left time: 332.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0468248 Vali Loss: 0.0567821 Test Loss: 0.0669147\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0470071\n",
      "\tspeed: 0.0376s/iter; left time: 701.5360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0450384\n",
      "\tspeed: 0.0177s/iter; left time: 328.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0463054 Vali Loss: 0.0566044 Test Loss: 0.0665685\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0442794\n",
      "\tspeed: 0.0379s/iter; left time: 697.6948s\n",
      "\titers: 200, epoch: 19 | loss: 0.0452530\n",
      "\tspeed: 0.0177s/iter; left time: 325.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0456901 Vali Loss: 0.0570509 Test Loss: 0.0667313\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0469251\n",
      "\tspeed: 0.0378s/iter; left time: 688.1240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0443603\n",
      "\tspeed: 0.0178s/iter; left time: 321.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0453321 Vali Loss: 0.0570785 Test Loss: 0.0672699\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0464923\n",
      "\tspeed: 0.0395s/iter; left time: 710.5409s\n",
      "\titers: 200, epoch: 21 | loss: 0.0467124\n",
      "\tspeed: 0.0178s/iter; left time: 317.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0448378 Vali Loss: 0.0569400 Test Loss: 0.0673984\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01132641639560461, rmse:0.10642563551664352, mae:0.06551436334848404, rse:0.3131977915763855\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:57.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1237152\n",
      "\tspeed: 0.0436s/iter; left time: 976.1799s\n",
      "\titers: 200, epoch: 1 | loss: 0.1135411\n",
      "\tspeed: 0.0186s/iter; left time: 414.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1316227 Vali Loss: 0.1026748 Test Loss: 0.1170933\n",
      "Validation loss decreased (inf --> 0.102675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0875041\n",
      "\tspeed: 0.0407s/iter; left time: 901.4934s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861476\n",
      "\tspeed: 0.0181s/iter; left time: 399.4828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0908247 Vali Loss: 0.0837092 Test Loss: 0.0957223\n",
      "Validation loss decreased (0.102675 --> 0.083709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821024\n",
      "\tspeed: 0.0412s/iter; left time: 905.3291s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819545\n",
      "\tspeed: 0.0181s/iter; left time: 394.8010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0828895 Vali Loss: 0.0808105 Test Loss: 0.0938665\n",
      "Validation loss decreased (0.083709 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0780354\n",
      "\tspeed: 0.0406s/iter; left time: 881.6916s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805350\n",
      "\tspeed: 0.0181s/iter; left time: 391.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0786676 Vali Loss: 0.0803954 Test Loss: 0.0944282\n",
      "Validation loss decreased (0.080810 --> 0.080395).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0761563\n",
      "\tspeed: 0.0422s/iter; left time: 907.5458s\n",
      "\titers: 200, epoch: 5 | loss: 0.0708133\n",
      "\tspeed: 0.0182s/iter; left time: 389.9596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0744769 Vali Loss: 0.0815953 Test Loss: 0.0971340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0679881\n",
      "\tspeed: 0.0390s/iter; left time: 829.9477s\n",
      "\titers: 200, epoch: 6 | loss: 0.0705811\n",
      "\tspeed: 0.0182s/iter; left time: 384.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0704299 Vali Loss: 0.0820850 Test Loss: 0.0969924\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0701797\n",
      "\tspeed: 0.0390s/iter; left time: 822.0239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0629454\n",
      "\tspeed: 0.0182s/iter; left time: 381.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0666835 Vali Loss: 0.0815112 Test Loss: 0.0976271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0647407\n",
      "\tspeed: 0.0389s/iter; left time: 809.6054s\n",
      "\titers: 200, epoch: 8 | loss: 0.0622736\n",
      "\tspeed: 0.0181s/iter; left time: 375.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0637334 Vali Loss: 0.0830895 Test Loss: 0.0994646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0603530\n",
      "\tspeed: 0.0386s/iter; left time: 796.0952s\n",
      "\titers: 200, epoch: 9 | loss: 0.0603974\n",
      "\tspeed: 0.0184s/iter; left time: 376.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0611769 Vali Loss: 0.0817545 Test Loss: 0.0993861\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600764\n",
      "\tspeed: 0.0393s/iter; left time: 800.1095s\n",
      "\titers: 200, epoch: 10 | loss: 0.0582973\n",
      "\tspeed: 0.0181s/iter; left time: 367.6679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0590898 Vali Loss: 0.0832220 Test Loss: 0.0996093\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572594\n",
      "\tspeed: 0.0396s/iter; left time: 797.3015s\n",
      "\titers: 200, epoch: 11 | loss: 0.0569117\n",
      "\tspeed: 0.0182s/iter; left time: 365.0839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0574465 Vali Loss: 0.0824588 Test Loss: 0.0995272\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0568082\n",
      "\tspeed: 0.0390s/iter; left time: 778.0359s\n",
      "\titers: 200, epoch: 12 | loss: 0.0554572\n",
      "\tspeed: 0.0181s/iter; left time: 358.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0559205 Vali Loss: 0.0839447 Test Loss: 0.1002958\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0544536\n",
      "\tspeed: 0.0384s/iter; left time: 757.4816s\n",
      "\titers: 200, epoch: 13 | loss: 0.0557813\n",
      "\tspeed: 0.0181s/iter; left time: 354.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0547010 Vali Loss: 0.0828165 Test Loss: 0.1006012\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0549239\n",
      "\tspeed: 0.0381s/iter; left time: 741.0889s\n",
      "\titers: 200, epoch: 14 | loss: 0.0532466\n",
      "\tspeed: 0.0181s/iter; left time: 350.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0537058 Vali Loss: 0.0825675 Test Loss: 0.1002479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021064607426524162, rmse:0.1451365202665329, mae:0.09442825615406036, rse:0.4263674020767212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1220162\n",
      "\tspeed: 0.0208s/iter; left time: 465.4625s\n",
      "\titers: 200, epoch: 1 | loss: 0.1103479\n",
      "\tspeed: 0.0181s/iter; left time: 403.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1313584 Vali Loss: 0.1028219 Test Loss: 0.1171752\n",
      "Validation loss decreased (inf --> 0.102822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938511\n",
      "\tspeed: 0.0462s/iter; left time: 1025.0942s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861422\n",
      "\tspeed: 0.0181s/iter; left time: 399.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0909858 Vali Loss: 0.0838486 Test Loss: 0.0959260\n",
      "Validation loss decreased (0.102822 --> 0.083849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0862403\n",
      "\tspeed: 0.0410s/iter; left time: 899.4305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0830001\n",
      "\tspeed: 0.0181s/iter; left time: 394.8757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0832866 Vali Loss: 0.0825980 Test Loss: 0.0954908\n",
      "Validation loss decreased (0.083849 --> 0.082598).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0782939\n",
      "\tspeed: 0.0447s/iter; left time: 970.1137s\n",
      "\titers: 200, epoch: 4 | loss: 0.0814964\n",
      "\tspeed: 0.0183s/iter; left time: 396.6409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0790398 Vali Loss: 0.0809088 Test Loss: 0.0939019\n",
      "Validation loss decreased (0.082598 --> 0.080909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0739339\n",
      "\tspeed: 0.0410s/iter; left time: 881.4071s\n",
      "\titers: 200, epoch: 5 | loss: 0.0742741\n",
      "\tspeed: 0.0192s/iter; left time: 411.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0746791 Vali Loss: 0.0811581 Test Loss: 0.0951832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0697818\n",
      "\tspeed: 0.0400s/iter; left time: 851.9782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0695777\n",
      "\tspeed: 0.0181s/iter; left time: 383.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0705332 Vali Loss: 0.0822380 Test Loss: 0.0965868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0687213\n",
      "\tspeed: 0.0394s/iter; left time: 828.7732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0651451\n",
      "\tspeed: 0.0187s/iter; left time: 391.3867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0670268 Vali Loss: 0.0823335 Test Loss: 0.0984485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0624922\n",
      "\tspeed: 0.0392s/iter; left time: 816.0951s\n",
      "\titers: 200, epoch: 8 | loss: 0.0625210\n",
      "\tspeed: 0.0181s/iter; left time: 374.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0640895 Vali Loss: 0.0825310 Test Loss: 0.0988109\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0615293\n",
      "\tspeed: 0.0414s/iter; left time: 852.2990s\n",
      "\titers: 200, epoch: 9 | loss: 0.0610103\n",
      "\tspeed: 0.0186s/iter; left time: 381.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0614805 Vali Loss: 0.0837530 Test Loss: 0.1001917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0645037\n",
      "\tspeed: 0.0391s/iter; left time: 796.7527s\n",
      "\titers: 200, epoch: 10 | loss: 0.0587965\n",
      "\tspeed: 0.0181s/iter; left time: 367.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0593795 Vali Loss: 0.0845202 Test Loss: 0.1010247\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0599034\n",
      "\tspeed: 0.0404s/iter; left time: 814.9790s\n",
      "\titers: 200, epoch: 11 | loss: 0.0571154\n",
      "\tspeed: 0.0182s/iter; left time: 365.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0577073 Vali Loss: 0.0837538 Test Loss: 0.1006436\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0575076\n",
      "\tspeed: 0.0393s/iter; left time: 783.5601s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553799\n",
      "\tspeed: 0.0181s/iter; left time: 358.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0562136 Vali Loss: 0.0842879 Test Loss: 0.0998713\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0551629\n",
      "\tspeed: 0.0408s/iter; left time: 804.5305s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547108\n",
      "\tspeed: 0.0182s/iter; left time: 356.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0549982 Vali Loss: 0.0848953 Test Loss: 0.1000355\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0544534\n",
      "\tspeed: 0.0392s/iter; left time: 764.0534s\n",
      "\titers: 200, epoch: 14 | loss: 0.0545231\n",
      "\tspeed: 0.0185s/iter; left time: 357.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0539025 Vali Loss: 0.0854289 Test Loss: 0.1009187\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02059120684862137, rmse:0.14349636435508728, mae:0.09390184283256531, rse:0.42154911160469055\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:54.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1247540\n",
      "\tspeed: 0.0417s/iter; left time: 934.3843s\n",
      "\titers: 200, epoch: 1 | loss: 0.1150539\n",
      "\tspeed: 0.0185s/iter; left time: 411.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.1349855 Vali Loss: 0.1072181 Test Loss: 0.1212277\n",
      "Validation loss decreased (inf --> 0.107218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0952868\n",
      "\tspeed: 0.0420s/iter; left time: 931.5524s\n",
      "\titers: 200, epoch: 2 | loss: 0.0945520\n",
      "\tspeed: 0.0184s/iter; left time: 406.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0958055 Vali Loss: 0.0891325 Test Loss: 0.1016404\n",
      "Validation loss decreased (0.107218 --> 0.089133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0861062\n",
      "\tspeed: 0.0429s/iter; left time: 941.9152s\n",
      "\titers: 200, epoch: 3 | loss: 0.0842636\n",
      "\tspeed: 0.0185s/iter; left time: 404.4816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0874688 Vali Loss: 0.0875926 Test Loss: 0.1009574\n",
      "Validation loss decreased (0.089133 --> 0.087593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0803422\n",
      "\tspeed: 0.0418s/iter; left time: 908.7489s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789519\n",
      "\tspeed: 0.0186s/iter; left time: 402.9947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0826494 Vali Loss: 0.0869722 Test Loss: 0.0999192\n",
      "Validation loss decreased (0.087593 --> 0.086972).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803686\n",
      "\tspeed: 0.0433s/iter; left time: 930.7006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0769203\n",
      "\tspeed: 0.0186s/iter; left time: 397.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0780406 Vali Loss: 0.0878041 Test Loss: 0.1009314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0742448\n",
      "\tspeed: 0.0400s/iter; left time: 851.7574s\n",
      "\titers: 200, epoch: 6 | loss: 0.0705056\n",
      "\tspeed: 0.0186s/iter; left time: 394.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0740998 Vali Loss: 0.0874714 Test Loss: 0.1005987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713059\n",
      "\tspeed: 0.0399s/iter; left time: 840.1154s\n",
      "\titers: 200, epoch: 7 | loss: 0.0685161\n",
      "\tspeed: 0.0185s/iter; left time: 388.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0705341 Vali Loss: 0.0876008 Test Loss: 0.1009772\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0688173\n",
      "\tspeed: 0.0397s/iter; left time: 826.6628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0669033\n",
      "\tspeed: 0.0184s/iter; left time: 382.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0674322 Vali Loss: 0.0876953 Test Loss: 0.1018889\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0656546\n",
      "\tspeed: 0.0389s/iter; left time: 801.6893s\n",
      "\titers: 200, epoch: 9 | loss: 0.0625771\n",
      "\tspeed: 0.0184s/iter; left time: 377.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0648954 Vali Loss: 0.0878862 Test Loss: 0.1018234\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0636433\n",
      "\tspeed: 0.0392s/iter; left time: 798.7257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610861\n",
      "\tspeed: 0.0184s/iter; left time: 373.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0627834 Vali Loss: 0.0887654 Test Loss: 0.1025015\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0597898\n",
      "\tspeed: 0.0389s/iter; left time: 783.6606s\n",
      "\titers: 200, epoch: 11 | loss: 0.0603452\n",
      "\tspeed: 0.0184s/iter; left time: 369.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0609051 Vali Loss: 0.0891276 Test Loss: 0.1031746\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595660\n",
      "\tspeed: 0.0390s/iter; left time: 776.9338s\n",
      "\titers: 200, epoch: 12 | loss: 0.0583236\n",
      "\tspeed: 0.0198s/iter; left time: 393.0724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0593992 Vali Loss: 0.0889052 Test Loss: 0.1035037\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0561858\n",
      "\tspeed: 0.0401s/iter; left time: 790.2838s\n",
      "\titers: 200, epoch: 13 | loss: 0.0568517\n",
      "\tspeed: 0.0184s/iter; left time: 361.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0581817 Vali Loss: 0.0892176 Test Loss: 0.1029303\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560341\n",
      "\tspeed: 0.0390s/iter; left time: 758.7934s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573181\n",
      "\tspeed: 0.0185s/iter; left time: 358.3559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0570184 Vali Loss: 0.0896377 Test Loss: 0.1037195\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023037901148200035, rmse:0.15178240835666656, mae:0.09991918504238129, rse:0.4459230601787567\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1261791\n",
      "\tspeed: 0.0208s/iter; left time: 466.4094s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139913\n",
      "\tspeed: 0.0185s/iter; left time: 412.5177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.1350769 Vali Loss: 0.1071121 Test Loss: 0.1210380\n",
      "Validation loss decreased (inf --> 0.107112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0985186\n",
      "\tspeed: 0.0463s/iter; left time: 1027.7213s\n",
      "\titers: 200, epoch: 2 | loss: 0.0899919\n",
      "\tspeed: 0.0189s/iter; left time: 416.3461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0956979 Vali Loss: 0.0897057 Test Loss: 0.1010741\n",
      "Validation loss decreased (0.107112 --> 0.089706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888578\n",
      "\tspeed: 0.0429s/iter; left time: 940.8254s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896617\n",
      "\tspeed: 0.0184s/iter; left time: 402.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0872689 Vali Loss: 0.0875277 Test Loss: 0.0992018\n",
      "Validation loss decreased (0.089706 --> 0.087528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816071\n",
      "\tspeed: 0.0427s/iter; left time: 927.3661s\n",
      "\titers: 200, epoch: 4 | loss: 0.0820200\n",
      "\tspeed: 0.0185s/iter; left time: 400.2018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0821305 Vali Loss: 0.0869310 Test Loss: 0.0992053\n",
      "Validation loss decreased (0.087528 --> 0.086931).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769678\n",
      "\tspeed: 0.0441s/iter; left time: 947.7166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741023\n",
      "\tspeed: 0.0186s/iter; left time: 399.0523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0775248 Vali Loss: 0.0868163 Test Loss: 0.1004667\n",
      "Validation loss decreased (0.086931 --> 0.086816).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0732511\n",
      "\tspeed: 0.0428s/iter; left time: 909.7394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729547\n",
      "\tspeed: 0.0185s/iter; left time: 392.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0734757 Vali Loss: 0.0884040 Test Loss: 0.1026382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0714987\n",
      "\tspeed: 0.0422s/iter; left time: 887.5784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0705451\n",
      "\tspeed: 0.0187s/iter; left time: 391.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0700019 Vali Loss: 0.0890642 Test Loss: 0.1035616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0675946\n",
      "\tspeed: 0.0408s/iter; left time: 849.9255s\n",
      "\titers: 200, epoch: 8 | loss: 0.0666065\n",
      "\tspeed: 0.0185s/iter; left time: 382.7006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0670320 Vali Loss: 0.0886770 Test Loss: 0.1047017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663665\n",
      "\tspeed: 0.0404s/iter; left time: 831.4488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0656349\n",
      "\tspeed: 0.0188s/iter; left time: 384.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0646494 Vali Loss: 0.0893991 Test Loss: 0.1041597\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633635\n",
      "\tspeed: 0.0408s/iter; left time: 832.2636s\n",
      "\titers: 200, epoch: 10 | loss: 0.0617162\n",
      "\tspeed: 0.0185s/iter; left time: 374.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0626202 Vali Loss: 0.0899764 Test Loss: 0.1048512\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0605506\n",
      "\tspeed: 0.0432s/iter; left time: 870.9245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0613867\n",
      "\tspeed: 0.0190s/iter; left time: 381.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0609869 Vali Loss: 0.0901252 Test Loss: 0.1047130\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0587517\n",
      "\tspeed: 0.0401s/iter; left time: 798.9508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584610\n",
      "\tspeed: 0.0185s/iter; left time: 367.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0595634 Vali Loss: 0.0902548 Test Loss: 0.1046337\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595968\n",
      "\tspeed: 0.0406s/iter; left time: 800.3465s\n",
      "\titers: 200, epoch: 13 | loss: 0.0577132\n",
      "\tspeed: 0.0186s/iter; left time: 363.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0583364 Vali Loss: 0.0901216 Test Loss: 0.1052209\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0553474\n",
      "\tspeed: 0.0416s/iter; left time: 809.8766s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580140\n",
      "\tspeed: 0.0190s/iter; left time: 368.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0572883 Vali Loss: 0.0903224 Test Loss: 0.1053021\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0561897\n",
      "\tspeed: 0.0431s/iter; left time: 829.4671s\n",
      "\titers: 200, epoch: 15 | loss: 0.0561889\n",
      "\tspeed: 0.0185s/iter; left time: 355.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0563494 Vali Loss: 0.0904639 Test Loss: 0.1047017\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023621639236807823, rmse:0.1536933332681656, mae:0.10046669095754623, rse:0.45153719186782837\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:05.16s\n",
      "Intermediate time for ES: 00h:09m:57.10s\n",
      "Total time: 00h:48m:02.89s\n"
     ]
    }
   ],
   "source": [
    "countries = ['DE', 'GB', 'ES']\n",
    "num_cols = [5, 5, 3]\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_168.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            seq_len=168\n",
    "\n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.1541</td>\n",
       "      <td>0.0981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.1533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0237  0.1541  0.0981\n",
       "        96        0.0441  0.2100  0.1392\n",
       "        168       0.0487  0.2207  0.1477\n",
       "ES      24        0.0112  0.1057  0.0651\n",
       "        96        0.0208  0.1443  0.0942\n",
       "        168       0.0233  0.1527  0.1002\n",
       "GB      24        0.0269  0.1639  0.1068\n",
       "        96        0.0488  0.2209  0.1488\n",
       "        168       0.0521  0.2283  0.1533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_168.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1261505\n",
      "\tspeed: 0.0389s/iter; left time: 876.2598s\n",
      "\titers: 200, epoch: 1 | loss: 0.1045834\n",
      "\tspeed: 0.0158s/iter; left time: 354.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.1294775 Vali Loss: 0.0948400 Test Loss: 0.1050907\n",
      "Validation loss decreased (inf --> 0.094840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0767076\n",
      "\tspeed: 0.0357s/iter; left time: 794.5104s\n",
      "\titers: 200, epoch: 2 | loss: 0.0721143\n",
      "\tspeed: 0.0164s/iter; left time: 362.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0756046 Vali Loss: 0.0646964 Test Loss: 0.0728172\n",
      "Validation loss decreased (0.094840 --> 0.064696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656266\n",
      "\tspeed: 0.0360s/iter; left time: 794.7223s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644903\n",
      "\tspeed: 0.0142s/iter; left time: 310.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0656169 Vali Loss: 0.0608506 Test Loss: 0.0695716\n",
      "Validation loss decreased (0.064696 --> 0.060851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650443\n",
      "\tspeed: 0.0367s/iter; left time: 801.7225s\n",
      "\titers: 200, epoch: 4 | loss: 0.0637198\n",
      "\tspeed: 0.0167s/iter; left time: 361.8758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0626084 Vali Loss: 0.0608452 Test Loss: 0.0687740\n",
      "Validation loss decreased (0.060851 --> 0.060845).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0605330\n",
      "\tspeed: 0.0353s/iter; left time: 763.2295s\n",
      "\titers: 200, epoch: 5 | loss: 0.0562332\n",
      "\tspeed: 0.0169s/iter; left time: 363.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0605957 Vali Loss: 0.0582919 Test Loss: 0.0657650\n",
      "Validation loss decreased (0.060845 --> 0.058292).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0593838\n",
      "\tspeed: 0.0358s/iter; left time: 765.0646s\n",
      "\titers: 200, epoch: 6 | loss: 0.0554853\n",
      "\tspeed: 0.0164s/iter; left time: 348.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0590788 Vali Loss: 0.0575854 Test Loss: 0.0654073\n",
      "Validation loss decreased (0.058292 --> 0.057585).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577590\n",
      "\tspeed: 0.0321s/iter; left time: 678.2140s\n",
      "\titers: 200, epoch: 7 | loss: 0.0586321\n",
      "\tspeed: 0.0141s/iter; left time: 297.7379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0578153 Vali Loss: 0.0572474 Test Loss: 0.0652406\n",
      "Validation loss decreased (0.057585 --> 0.057247).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573788\n",
      "\tspeed: 0.0356s/iter; left time: 745.1546s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589646\n",
      "\tspeed: 0.0164s/iter; left time: 341.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0568043 Vali Loss: 0.0566638 Test Loss: 0.0647745\n",
      "Validation loss decreased (0.057247 --> 0.056664).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554692\n",
      "\tspeed: 0.0365s/iter; left time: 755.1849s\n",
      "\titers: 200, epoch: 9 | loss: 0.0569972\n",
      "\tspeed: 0.0172s/iter; left time: 354.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0557859 Vali Loss: 0.0563612 Test Loss: 0.0648253\n",
      "Validation loss decreased (0.056664 --> 0.056361).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549635\n",
      "\tspeed: 0.0345s/iter; left time: 706.5124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576599\n",
      "\tspeed: 0.0129s/iter; left time: 262.3400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0550394 Vali Loss: 0.0565279 Test Loss: 0.0645595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579597\n",
      "\tspeed: 0.0299s/iter; left time: 604.7598s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546923\n",
      "\tspeed: 0.0143s/iter; left time: 288.0998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0542206 Vali Loss: 0.0558687 Test Loss: 0.0643536\n",
      "Validation loss decreased (0.056361 --> 0.055869).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553063\n",
      "\tspeed: 0.0326s/iter; left time: 653.1234s\n",
      "\titers: 200, epoch: 12 | loss: 0.0562879\n",
      "\tspeed: 0.0149s/iter; left time: 296.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0535740 Vali Loss: 0.0560607 Test Loss: 0.0641855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0526274\n",
      "\tspeed: 0.0299s/iter; left time: 590.9643s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506134\n",
      "\tspeed: 0.0128s/iter; left time: 251.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0528816 Vali Loss: 0.0558748 Test Loss: 0.0646109\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523458\n",
      "\tspeed: 0.0321s/iter; left time: 627.7665s\n",
      "\titers: 200, epoch: 14 | loss: 0.0522553\n",
      "\tspeed: 0.0155s/iter; left time: 300.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0523581 Vali Loss: 0.0556833 Test Loss: 0.0639260\n",
      "Validation loss decreased (0.055869 --> 0.055683).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533797\n",
      "\tspeed: 0.0303s/iter; left time: 585.9764s\n",
      "\titers: 200, epoch: 15 | loss: 0.0527787\n",
      "\tspeed: 0.0120s/iter; left time: 231.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0518446 Vali Loss: 0.0558065 Test Loss: 0.0639597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0511821\n",
      "\tspeed: 0.0288s/iter; left time: 550.8147s\n",
      "\titers: 200, epoch: 16 | loss: 0.0503562\n",
      "\tspeed: 0.0133s/iter; left time: 253.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0513143 Vali Loss: 0.0557360 Test Loss: 0.0640105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0486537\n",
      "\tspeed: 0.0308s/iter; left time: 581.3351s\n",
      "\titers: 200, epoch: 17 | loss: 0.0476101\n",
      "\tspeed: 0.0140s/iter; left time: 263.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0508641 Vali Loss: 0.0559398 Test Loss: 0.0641717\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0485818\n",
      "\tspeed: 0.0283s/iter; left time: 527.6909s\n",
      "\titers: 200, epoch: 18 | loss: 0.0535065\n",
      "\tspeed: 0.0132s/iter; left time: 245.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 226 | Train Loss: 0.0504648 Vali Loss: 0.0556975 Test Loss: 0.0639090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0510360\n",
      "\tspeed: 0.0291s/iter; left time: 535.9671s\n",
      "\titers: 200, epoch: 19 | loss: 0.0510751\n",
      "\tspeed: 0.0132s/iter; left time: 241.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0500255 Vali Loss: 0.0555788 Test Loss: 0.0645798\n",
      "Validation loss decreased (0.055683 --> 0.055579).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0480228\n",
      "\tspeed: 0.0310s/iter; left time: 564.2647s\n",
      "\titers: 200, epoch: 20 | loss: 0.0486701\n",
      "\tspeed: 0.0118s/iter; left time: 213.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0497338 Vali Loss: 0.0556655 Test Loss: 0.0640523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0508732\n",
      "\tspeed: 0.0293s/iter; left time: 526.7977s\n",
      "\titers: 200, epoch: 21 | loss: 0.0497380\n",
      "\tspeed: 0.0135s/iter; left time: 241.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0494304 Vali Loss: 0.0556795 Test Loss: 0.0643621\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0473585\n",
      "\tspeed: 0.0334s/iter; left time: 592.9831s\n",
      "\titers: 200, epoch: 22 | loss: 0.0472204\n",
      "\tspeed: 0.0148s/iter; left time: 260.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0491408 Vali Loss: 0.0556646 Test Loss: 0.0639770\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0470456\n",
      "\tspeed: 0.0300s/iter; left time: 526.3448s\n",
      "\titers: 200, epoch: 23 | loss: 0.0475197\n",
      "\tspeed: 0.0148s/iter; left time: 258.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0488609 Vali Loss: 0.0553888 Test Loss: 0.0642007\n",
      "Validation loss decreased (0.055579 --> 0.055389).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0455110\n",
      "\tspeed: 0.0339s/iter; left time: 586.5159s\n",
      "\titers: 200, epoch: 24 | loss: 0.0500478\n",
      "\tspeed: 0.0153s/iter; left time: 262.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0485892 Vali Loss: 0.0554823 Test Loss: 0.0642269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0482877\n",
      "\tspeed: 0.0303s/iter; left time: 516.6942s\n",
      "\titers: 200, epoch: 25 | loss: 0.0474017\n",
      "\tspeed: 0.0148s/iter; left time: 251.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0484185 Vali Loss: 0.0555517 Test Loss: 0.0643024\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0463871\n",
      "\tspeed: 0.0333s/iter; left time: 561.9433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0504324\n",
      "\tspeed: 0.0159s/iter; left time: 266.0565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0482816 Vali Loss: 0.0555996 Test Loss: 0.0643811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0485109\n",
      "\tspeed: 0.0312s/iter; left time: 518.3908s\n",
      "\titers: 200, epoch: 27 | loss: 0.0479224\n",
      "\tspeed: 0.0161s/iter; left time: 265.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0481291 Vali Loss: 0.0556127 Test Loss: 0.0646453\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0471330\n",
      "\tspeed: 0.0312s/iter; left time: 511.5807s\n",
      "\titers: 200, epoch: 28 | loss: 0.0518033\n",
      "\tspeed: 0.0156s/iter; left time: 254.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0478540 Vali Loss: 0.0555018 Test Loss: 0.0644240\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0485359\n",
      "\tspeed: 0.0317s/iter; left time: 512.2523s\n",
      "\titers: 200, epoch: 29 | loss: 0.0488524\n",
      "\tspeed: 0.0142s/iter; left time: 228.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0477066 Vali Loss: 0.0556953 Test Loss: 0.0644282\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0472911\n",
      "\tspeed: 0.0326s/iter; left time: 519.5575s\n",
      "\titers: 200, epoch: 30 | loss: 0.0448027\n",
      "\tspeed: 0.0156s/iter; left time: 247.6315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0477078 Vali Loss: 0.0554871 Test Loss: 0.0643446\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0477228\n",
      "\tspeed: 0.0299s/iter; left time: 470.5082s\n",
      "\titers: 200, epoch: 31 | loss: 0.0498036\n",
      "\tspeed: 0.0130s/iter; left time: 202.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0475542 Vali Loss: 0.0556037 Test Loss: 0.0645968\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0483816\n",
      "\tspeed: 0.0294s/iter; left time: 455.6521s\n",
      "\titers: 200, epoch: 32 | loss: 0.0490651\n",
      "\tspeed: 0.0134s/iter; left time: 206.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0474598 Vali Loss: 0.0556020 Test Loss: 0.0645061\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0466786\n",
      "\tspeed: 0.0300s/iter; left time: 457.3069s\n",
      "\titers: 200, epoch: 33 | loss: 0.0476728\n",
      "\tspeed: 0.0124s/iter; left time: 187.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0473318 Vali Loss: 0.0555336 Test Loss: 0.0645604\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01109654363244772, rmse:0.1053401306271553, mae:0.06420067697763443, rse:0.31000328063964844\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1298355\n",
      "\tspeed: 0.0189s/iter; left time: 425.7097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1092459\n",
      "\tspeed: 0.0153s/iter; left time: 342.7972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.1324643 Vali Loss: 0.0952392 Test Loss: 0.1059600\n",
      "Validation loss decreased (inf --> 0.095239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745378\n",
      "\tspeed: 0.0320s/iter; left time: 712.1988s\n",
      "\titers: 200, epoch: 2 | loss: 0.0710034\n",
      "\tspeed: 0.0136s/iter; left time: 302.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0758506 Vali Loss: 0.0649607 Test Loss: 0.0730545\n",
      "Validation loss decreased (0.095239 --> 0.064961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0650133\n",
      "\tspeed: 0.0351s/iter; left time: 774.2808s\n",
      "\titers: 200, epoch: 3 | loss: 0.0632060\n",
      "\tspeed: 0.0136s/iter; left time: 298.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0659857 Vali Loss: 0.0615382 Test Loss: 0.0692593\n",
      "Validation loss decreased (0.064961 --> 0.061538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0613484\n",
      "\tspeed: 0.0309s/iter; left time: 673.9615s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615166\n",
      "\tspeed: 0.0142s/iter; left time: 308.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0627952 Vali Loss: 0.0601462 Test Loss: 0.0677789\n",
      "Validation loss decreased (0.061538 --> 0.060146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0595133\n",
      "\tspeed: 0.0305s/iter; left time: 657.7044s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604066\n",
      "\tspeed: 0.0118s/iter; left time: 254.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0607027 Vali Loss: 0.0585906 Test Loss: 0.0664334\n",
      "Validation loss decreased (0.060146 --> 0.058591).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588046\n",
      "\tspeed: 0.0304s/iter; left time: 650.1725s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616833\n",
      "\tspeed: 0.0139s/iter; left time: 295.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0592085 Vali Loss: 0.0581986 Test Loss: 0.0663687\n",
      "Validation loss decreased (0.058591 --> 0.058199).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566846\n",
      "\tspeed: 0.0319s/iter; left time: 674.6914s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594041\n",
      "\tspeed: 0.0122s/iter; left time: 256.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0580842 Vali Loss: 0.0571749 Test Loss: 0.0646432\n",
      "Validation loss decreased (0.058199 --> 0.057175).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596626\n",
      "\tspeed: 0.0308s/iter; left time: 643.8406s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549480\n",
      "\tspeed: 0.0120s/iter; left time: 250.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0569831 Vali Loss: 0.0570697 Test Loss: 0.0655890\n",
      "Validation loss decreased (0.057175 --> 0.057070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571199\n",
      "\tspeed: 0.0340s/iter; left time: 704.3797s\n",
      "\titers: 200, epoch: 9 | loss: 0.0551791\n",
      "\tspeed: 0.0145s/iter; left time: 298.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0560735 Vali Loss: 0.0568773 Test Loss: 0.0646910\n",
      "Validation loss decreased (0.057070 --> 0.056877).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0538923\n",
      "\tspeed: 0.0361s/iter; left time: 738.6884s\n",
      "\titers: 200, epoch: 10 | loss: 0.0502976\n",
      "\tspeed: 0.0173s/iter; left time: 353.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0553372 Vali Loss: 0.0559911 Test Loss: 0.0639011\n",
      "Validation loss decreased (0.056877 --> 0.055991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518299\n",
      "\tspeed: 0.0320s/iter; left time: 647.9743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0548057\n",
      "\tspeed: 0.0135s/iter; left time: 271.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0545444 Vali Loss: 0.0561786 Test Loss: 0.0642171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0532315\n",
      "\tspeed: 0.0327s/iter; left time: 653.5227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0545195\n",
      "\tspeed: 0.0154s/iter; left time: 305.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0539367 Vali Loss: 0.0557110 Test Loss: 0.0638198\n",
      "Validation loss decreased (0.055991 --> 0.055711).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0550689\n",
      "\tspeed: 0.0336s/iter; left time: 665.3167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506262\n",
      "\tspeed: 0.0156s/iter; left time: 308.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0532882 Vali Loss: 0.0560654 Test Loss: 0.0642667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530066\n",
      "\tspeed: 0.0319s/iter; left time: 624.1550s\n",
      "\titers: 200, epoch: 14 | loss: 0.0509835\n",
      "\tspeed: 0.0143s/iter; left time: 278.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0528216 Vali Loss: 0.0559201 Test Loss: 0.0640503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0481569\n",
      "\tspeed: 0.0304s/iter; left time: 588.7109s\n",
      "\titers: 200, epoch: 15 | loss: 0.0519428\n",
      "\tspeed: 0.0135s/iter; left time: 258.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0522880 Vali Loss: 0.0557858 Test Loss: 0.0635273\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0518527\n",
      "\tspeed: 0.0325s/iter; left time: 620.8857s\n",
      "\titers: 200, epoch: 16 | loss: 0.0541126\n",
      "\tspeed: 0.0142s/iter; left time: 270.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0517717 Vali Loss: 0.0556043 Test Loss: 0.0634354\n",
      "Validation loss decreased (0.055711 --> 0.055604).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0538259\n",
      "\tspeed: 0.0307s/iter; left time: 579.5287s\n",
      "\titers: 200, epoch: 17 | loss: 0.0533093\n",
      "\tspeed: 0.0138s/iter; left time: 259.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0513273 Vali Loss: 0.0558820 Test Loss: 0.0638887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0541670\n",
      "\tspeed: 0.0319s/iter; left time: 595.8923s\n",
      "\titers: 200, epoch: 18 | loss: 0.0492889\n",
      "\tspeed: 0.0124s/iter; left time: 229.5877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0509906 Vali Loss: 0.0556682 Test Loss: 0.0640585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0498789\n",
      "\tspeed: 0.0312s/iter; left time: 575.9430s\n",
      "\titers: 200, epoch: 19 | loss: 0.0512803\n",
      "\tspeed: 0.0144s/iter; left time: 264.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0505361 Vali Loss: 0.0561285 Test Loss: 0.0637186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0488083\n",
      "\tspeed: 0.0305s/iter; left time: 555.3996s\n",
      "\titers: 200, epoch: 20 | loss: 0.0509687\n",
      "\tspeed: 0.0133s/iter; left time: 241.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0502637 Vali Loss: 0.0555708 Test Loss: 0.0644000\n",
      "Validation loss decreased (0.055604 --> 0.055571).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0504927\n",
      "\tspeed: 0.0320s/iter; left time: 574.8542s\n",
      "\titers: 200, epoch: 21 | loss: 0.0481941\n",
      "\tspeed: 0.0137s/iter; left time: 245.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0500186 Vali Loss: 0.0558671 Test Loss: 0.0642352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0490446\n",
      "\tspeed: 0.0318s/iter; left time: 563.8117s\n",
      "\titers: 200, epoch: 22 | loss: 0.0513775\n",
      "\tspeed: 0.0134s/iter; left time: 237.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0496050 Vali Loss: 0.0556694 Test Loss: 0.0642141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0491438\n",
      "\tspeed: 0.0342s/iter; left time: 599.4655s\n",
      "\titers: 200, epoch: 23 | loss: 0.0535126\n",
      "\tspeed: 0.0130s/iter; left time: 226.0735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0493393 Vali Loss: 0.0558761 Test Loss: 0.0642837\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0496071\n",
      "\tspeed: 0.0326s/iter; left time: 564.8397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0509492\n",
      "\tspeed: 0.0143s/iter; left time: 246.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0491453 Vali Loss: 0.0557350 Test Loss: 0.0642155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0496965\n",
      "\tspeed: 0.0297s/iter; left time: 506.4310s\n",
      "\titers: 200, epoch: 25 | loss: 0.0495152\n",
      "\tspeed: 0.0124s/iter; left time: 209.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 226 | Train Loss: 0.0489119 Vali Loss: 0.0559967 Test Loss: 0.0642766\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0475527\n",
      "\tspeed: 0.0321s/iter; left time: 540.4320s\n",
      "\titers: 200, epoch: 26 | loss: 0.0487427\n",
      "\tspeed: 0.0136s/iter; left time: 226.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0487386 Vali Loss: 0.0557482 Test Loss: 0.0642316\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0473309\n",
      "\tspeed: 0.0309s/iter; left time: 514.3980s\n",
      "\titers: 200, epoch: 27 | loss: 0.0468213\n",
      "\tspeed: 0.0132s/iter; left time: 217.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0485303 Vali Loss: 0.0559879 Test Loss: 0.0644699\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0497085\n",
      "\tspeed: 0.0308s/iter; left time: 505.2457s\n",
      "\titers: 200, epoch: 28 | loss: 0.0488404\n",
      "\tspeed: 0.0148s/iter; left time: 241.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0484617 Vali Loss: 0.0557874 Test Loss: 0.0643525\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0455155\n",
      "\tspeed: 0.0312s/iter; left time: 505.2553s\n",
      "\titers: 200, epoch: 29 | loss: 0.0474569\n",
      "\tspeed: 0.0147s/iter; left time: 235.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0482477 Vali Loss: 0.0557425 Test Loss: 0.0644637\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0483084\n",
      "\tspeed: 0.0304s/iter; left time: 484.4458s\n",
      "\titers: 200, epoch: 30 | loss: 0.0468907\n",
      "\tspeed: 0.0156s/iter; left time: 246.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0481475 Vali Loss: 0.0558674 Test Loss: 0.0642240\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010962837375700474, rmse:0.10470356792211533, mae:0.06440004706382751, rse:0.3081299364566803\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:01.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1432228\n",
      "\tspeed: 0.0375s/iter; left time: 844.2336s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238714\n",
      "\tspeed: 0.0121s/iter; left time: 270.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.1447640 Vali Loss: 0.1137416 Test Loss: 0.1272953\n",
      "Validation loss decreased (inf --> 0.113742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0955269\n",
      "\tspeed: 0.0311s/iter; left time: 693.2394s\n",
      "\titers: 200, epoch: 2 | loss: 0.0884188\n",
      "\tspeed: 0.0121s/iter; left time: 267.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0972566 Vali Loss: 0.0874725 Test Loss: 0.0984257\n",
      "Validation loss decreased (0.113742 --> 0.087473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874788\n",
      "\tspeed: 0.0343s/iter; left time: 756.1255s\n",
      "\titers: 200, epoch: 3 | loss: 0.0853608\n",
      "\tspeed: 0.0121s/iter; left time: 264.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0877492 Vali Loss: 0.0840045 Test Loss: 0.0956733\n",
      "Validation loss decreased (0.087473 --> 0.084005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0824275\n",
      "\tspeed: 0.0313s/iter; left time: 683.2757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819495\n",
      "\tspeed: 0.0128s/iter; left time: 278.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0845370 Vali Loss: 0.0823604 Test Loss: 0.0942157\n",
      "Validation loss decreased (0.084005 --> 0.082360).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856093\n",
      "\tspeed: 0.0314s/iter; left time: 677.1721s\n",
      "\titers: 200, epoch: 5 | loss: 0.0815057\n",
      "\tspeed: 0.0120s/iter; left time: 258.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0815562 Vali Loss: 0.0824928 Test Loss: 0.0947016\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0787110\n",
      "\tspeed: 0.0292s/iter; left time: 624.6523s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779605\n",
      "\tspeed: 0.0148s/iter; left time: 313.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0789403 Vali Loss: 0.0824665 Test Loss: 0.0950766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0765377\n",
      "\tspeed: 0.0288s/iter; left time: 608.9540s\n",
      "\titers: 200, epoch: 7 | loss: 0.0757090\n",
      "\tspeed: 0.0120s/iter; left time: 253.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0764177 Vali Loss: 0.0838538 Test Loss: 0.0960459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758968\n",
      "\tspeed: 0.0298s/iter; left time: 622.6874s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748915\n",
      "\tspeed: 0.0123s/iter; left time: 255.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0743212 Vali Loss: 0.0835326 Test Loss: 0.0956333\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0723564\n",
      "\tspeed: 0.0323s/iter; left time: 668.2648s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717292\n",
      "\tspeed: 0.0130s/iter; left time: 268.1406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0723764 Vali Loss: 0.0837987 Test Loss: 0.0963536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0709493\n",
      "\tspeed: 0.0319s/iter; left time: 652.8430s\n",
      "\titers: 200, epoch: 10 | loss: 0.0682494\n",
      "\tspeed: 0.0149s/iter; left time: 304.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0706405 Vali Loss: 0.0848424 Test Loss: 0.0975980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0689652\n",
      "\tspeed: 0.0302s/iter; left time: 611.0070s\n",
      "\titers: 200, epoch: 11 | loss: 0.0698718\n",
      "\tspeed: 0.0139s/iter; left time: 280.4228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0692242 Vali Loss: 0.0848600 Test Loss: 0.0973191\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0669707\n",
      "\tspeed: 0.0334s/iter; left time: 668.7953s\n",
      "\titers: 200, epoch: 12 | loss: 0.0676858\n",
      "\tspeed: 0.0125s/iter; left time: 248.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0678661 Vali Loss: 0.0850040 Test Loss: 0.0981115\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0670570\n",
      "\tspeed: 0.0316s/iter; left time: 625.9350s\n",
      "\titers: 200, epoch: 13 | loss: 0.0671279\n",
      "\tspeed: 0.0162s/iter; left time: 318.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0667887 Vali Loss: 0.0848042 Test Loss: 0.0973745\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0669436\n",
      "\tspeed: 0.0334s/iter; left time: 653.2888s\n",
      "\titers: 200, epoch: 14 | loss: 0.0658115\n",
      "\tspeed: 0.0144s/iter; left time: 279.4000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 226 | Train Loss: 0.0658884 Vali Loss: 0.0851748 Test Loss: 0.0982291\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020591821521520615, rmse:0.1434985101222992, mae:0.0942157432436943, rse:0.42155542969703674\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1458973\n",
      "\tspeed: 0.0149s/iter; left time: 335.3484s\n",
      "\titers: 200, epoch: 1 | loss: 0.1209050\n",
      "\tspeed: 0.0142s/iter; left time: 318.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.1446354 Vali Loss: 0.1140107 Test Loss: 0.1272782\n",
      "Validation loss decreased (inf --> 0.114011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0968597\n",
      "\tspeed: 0.0334s/iter; left time: 744.4784s\n",
      "\titers: 200, epoch: 2 | loss: 0.0873625\n",
      "\tspeed: 0.0129s/iter; left time: 286.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0971026 Vali Loss: 0.0873974 Test Loss: 0.0980609\n",
      "Validation loss decreased (0.114011 --> 0.087397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0936810\n",
      "\tspeed: 0.0346s/iter; left time: 763.4749s\n",
      "\titers: 200, epoch: 3 | loss: 0.0887708\n",
      "\tspeed: 0.0121s/iter; left time: 265.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0877442 Vali Loss: 0.0846649 Test Loss: 0.0955773\n",
      "Validation loss decreased (0.087397 --> 0.084665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853073\n",
      "\tspeed: 0.0322s/iter; left time: 701.7743s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844880\n",
      "\tspeed: 0.0130s/iter; left time: 281.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0845925 Vali Loss: 0.0829113 Test Loss: 0.0943428\n",
      "Validation loss decreased (0.084665 --> 0.082911).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805078\n",
      "\tspeed: 0.0340s/iter; left time: 735.0449s\n",
      "\titers: 200, epoch: 5 | loss: 0.0772731\n",
      "\tspeed: 0.0121s/iter; left time: 259.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0814723 Vali Loss: 0.0831335 Test Loss: 0.0940529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0790438\n",
      "\tspeed: 0.0297s/iter; left time: 634.9107s\n",
      "\titers: 200, epoch: 6 | loss: 0.0774079\n",
      "\tspeed: 0.0133s/iter; left time: 282.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0787769 Vali Loss: 0.0828503 Test Loss: 0.0941699\n",
      "Validation loss decreased (0.082911 --> 0.082850).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0791036\n",
      "\tspeed: 0.0360s/iter; left time: 761.4989s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773327\n",
      "\tspeed: 0.0121s/iter; left time: 255.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0765849 Vali Loss: 0.0825221 Test Loss: 0.0944187\n",
      "Validation loss decreased (0.082850 --> 0.082522).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0779414\n",
      "\tspeed: 0.0327s/iter; left time: 683.6074s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706040\n",
      "\tspeed: 0.0122s/iter; left time: 253.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0744081 Vali Loss: 0.0831409 Test Loss: 0.0952084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0727267\n",
      "\tspeed: 0.0301s/iter; left time: 622.7415s\n",
      "\titers: 200, epoch: 9 | loss: 0.0713194\n",
      "\tspeed: 0.0122s/iter; left time: 251.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0726735 Vali Loss: 0.0840194 Test Loss: 0.0958889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725458\n",
      "\tspeed: 0.0300s/iter; left time: 614.5744s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699228\n",
      "\tspeed: 0.0125s/iter; left time: 255.5549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0708986 Vali Loss: 0.0840858 Test Loss: 0.0967213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0693088\n",
      "\tspeed: 0.0320s/iter; left time: 647.0917s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708501\n",
      "\tspeed: 0.0138s/iter; left time: 278.7495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0695247 Vali Loss: 0.0847357 Test Loss: 0.0971731\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692687\n",
      "\tspeed: 0.0311s/iter; left time: 623.4164s\n",
      "\titers: 200, epoch: 12 | loss: 0.0692844\n",
      "\tspeed: 0.0127s/iter; left time: 252.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0683685 Vali Loss: 0.0849097 Test Loss: 0.0971900\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0708801\n",
      "\tspeed: 0.0320s/iter; left time: 632.2764s\n",
      "\titers: 200, epoch: 13 | loss: 0.0673890\n",
      "\tspeed: 0.0139s/iter; left time: 272.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 226 | Train Loss: 0.0673383 Vali Loss: 0.0847755 Test Loss: 0.0972421\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652700\n",
      "\tspeed: 0.0307s/iter; left time: 601.1893s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669420\n",
      "\tspeed: 0.0121s/iter; left time: 235.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0663956 Vali Loss: 0.0847587 Test Loss: 0.0976123\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0656001\n",
      "\tspeed: 0.0311s/iter; left time: 601.3867s\n",
      "\titers: 200, epoch: 15 | loss: 0.0670249\n",
      "\tspeed: 0.0144s/iter; left time: 276.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 226 | Train Loss: 0.0655526 Vali Loss: 0.0848967 Test Loss: 0.0976898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0640606\n",
      "\tspeed: 0.0311s/iter; left time: 593.9456s\n",
      "\titers: 200, epoch: 16 | loss: 0.0629133\n",
      "\tspeed: 0.0140s/iter; left time: 265.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0648504 Vali Loss: 0.0846819 Test Loss: 0.0984848\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0639562\n",
      "\tspeed: 0.0316s/iter; left time: 596.9246s\n",
      "\titers: 200, epoch: 17 | loss: 0.0628385\n",
      "\tspeed: 0.0161s/iter; left time: 302.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0641896 Vali Loss: 0.0848450 Test Loss: 0.0986550\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021078813821077347, rmse:0.1451854407787323, mae:0.09441870450973511, rse:0.42651116847991943\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:30.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1440123\n",
      "\tspeed: 0.0397s/iter; left time: 890.1723s\n",
      "\titers: 200, epoch: 1 | loss: 0.1219980\n",
      "\tspeed: 0.0133s/iter; left time: 296.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.1466884 Vali Loss: 0.1161049 Test Loss: 0.1299156\n",
      "Validation loss decreased (inf --> 0.116105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1040402\n",
      "\tspeed: 0.0313s/iter; left time: 694.4444s\n",
      "\titers: 200, epoch: 2 | loss: 0.0966882\n",
      "\tspeed: 0.0123s/iter; left time: 271.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.1010600 Vali Loss: 0.0921646 Test Loss: 0.1041240\n",
      "Validation loss decreased (0.116105 --> 0.092165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899361\n",
      "\tspeed: 0.0352s/iter; left time: 772.0819s\n",
      "\titers: 200, epoch: 3 | loss: 0.0950214\n",
      "\tspeed: 0.0134s/iter; left time: 291.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0926913 Vali Loss: 0.0893897 Test Loss: 0.1015893\n",
      "Validation loss decreased (0.092165 --> 0.089390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892411\n",
      "\tspeed: 0.0339s/iter; left time: 736.4591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0930670\n",
      "\tspeed: 0.0168s/iter; left time: 362.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0895183 Vali Loss: 0.0888302 Test Loss: 0.1012411\n",
      "Validation loss decreased (0.089390 --> 0.088830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884369\n",
      "\tspeed: 0.0357s/iter; left time: 768.1049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0872802\n",
      "\tspeed: 0.0168s/iter; left time: 359.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0865985 Vali Loss: 0.0877893 Test Loss: 0.1004086\n",
      "Validation loss decreased (0.088830 --> 0.087789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0840330\n",
      "\tspeed: 0.0336s/iter; left time: 715.4638s\n",
      "\titers: 200, epoch: 6 | loss: 0.0823128\n",
      "\tspeed: 0.0128s/iter; left time: 270.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0838192 Vali Loss: 0.0887944 Test Loss: 0.1016514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832603\n",
      "\tspeed: 0.0337s/iter; left time: 708.5193s\n",
      "\titers: 200, epoch: 7 | loss: 0.0816261\n",
      "\tspeed: 0.0129s/iter; left time: 270.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0813194 Vali Loss: 0.0879882 Test Loss: 0.1014727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0812962\n",
      "\tspeed: 0.0341s/iter; left time: 710.9541s\n",
      "\titers: 200, epoch: 8 | loss: 0.0808096\n",
      "\tspeed: 0.0144s/iter; left time: 299.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0792205 Vali Loss: 0.0892362 Test Loss: 0.1027877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0788369\n",
      "\tspeed: 0.0346s/iter; left time: 712.5531s\n",
      "\titers: 200, epoch: 9 | loss: 0.0769801\n",
      "\tspeed: 0.0138s/iter; left time: 282.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0775114 Vali Loss: 0.0888906 Test Loss: 0.1026241\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758829\n",
      "\tspeed: 0.0308s/iter; left time: 628.2834s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748430\n",
      "\tspeed: 0.0126s/iter; left time: 255.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0759378 Vali Loss: 0.0889411 Test Loss: 0.1016021\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736376\n",
      "\tspeed: 0.0361s/iter; left time: 728.2056s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769293\n",
      "\tspeed: 0.0181s/iter; left time: 362.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0745113 Vali Loss: 0.0889894 Test Loss: 0.1026308\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0737329\n",
      "\tspeed: 0.0324s/iter; left time: 646.1770s\n",
      "\titers: 200, epoch: 12 | loss: 0.0753965\n",
      "\tspeed: 0.0147s/iter; left time: 292.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0733924 Vali Loss: 0.0899609 Test Loss: 0.1038212\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0697909\n",
      "\tspeed: 0.0341s/iter; left time: 672.1620s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727018\n",
      "\tspeed: 0.0164s/iter; left time: 321.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0723242 Vali Loss: 0.0899475 Test Loss: 0.1035086\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0750063\n",
      "\tspeed: 0.0315s/iter; left time: 613.9311s\n",
      "\titers: 200, epoch: 14 | loss: 0.0676442\n",
      "\tspeed: 0.0123s/iter; left time: 238.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0714187 Vali Loss: 0.0898940 Test Loss: 0.1037310\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717596\n",
      "\tspeed: 0.0300s/iter; left time: 577.3359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0693328\n",
      "\tspeed: 0.0126s/iter; left time: 240.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0705878 Vali Loss: 0.0899751 Test Loss: 0.1043542\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02318292111158371, rmse:0.15225939452648163, mae:0.10040855407714844, rse:0.44732439517974854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1436104\n",
      "\tspeed: 0.0164s/iter; left time: 368.1913s\n",
      "\titers: 200, epoch: 1 | loss: 0.1193593\n",
      "\tspeed: 0.0136s/iter; left time: 303.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.1461999 Vali Loss: 0.1158600 Test Loss: 0.1296075\n",
      "Validation loss decreased (inf --> 0.115860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1006850\n",
      "\tspeed: 0.0330s/iter; left time: 731.5806s\n",
      "\titers: 200, epoch: 2 | loss: 0.0938409\n",
      "\tspeed: 0.0140s/iter; left time: 309.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.1011552 Vali Loss: 0.0925210 Test Loss: 0.1042791\n",
      "Validation loss decreased (0.115860 --> 0.092521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930860\n",
      "\tspeed: 0.0365s/iter; left time: 800.1507s\n",
      "\titers: 200, epoch: 3 | loss: 0.0923619\n",
      "\tspeed: 0.0149s/iter; left time: 324.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0927644 Vali Loss: 0.0893844 Test Loss: 0.1019361\n",
      "Validation loss decreased (0.092521 --> 0.089384).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0871660\n",
      "\tspeed: 0.0340s/iter; left time: 737.7469s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888119\n",
      "\tspeed: 0.0135s/iter; left time: 292.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0894383 Vali Loss: 0.0884936 Test Loss: 0.1005468\n",
      "Validation loss decreased (0.089384 --> 0.088494).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867392\n",
      "\tspeed: 0.0351s/iter; left time: 754.3810s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861428\n",
      "\tspeed: 0.0127s/iter; left time: 272.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0864125 Vali Loss: 0.0877658 Test Loss: 0.1002546\n",
      "Validation loss decreased (0.088494 --> 0.087766).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862639\n",
      "\tspeed: 0.0359s/iter; left time: 763.1126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836816\n",
      "\tspeed: 0.0172s/iter; left time: 364.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0836745 Vali Loss: 0.0889044 Test Loss: 0.1009149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794809\n",
      "\tspeed: 0.0328s/iter; left time: 690.1293s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806813\n",
      "\tspeed: 0.0153s/iter; left time: 320.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0812870 Vali Loss: 0.0894548 Test Loss: 0.1015984\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774965\n",
      "\tspeed: 0.0304s/iter; left time: 632.9189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797873\n",
      "\tspeed: 0.0131s/iter; left time: 270.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0792019 Vali Loss: 0.0893858 Test Loss: 0.1016538\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0790205\n",
      "\tspeed: 0.0304s/iter; left time: 627.2970s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798370\n",
      "\tspeed: 0.0129s/iter; left time: 264.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 225 | Train Loss: 0.0773558 Vali Loss: 0.0895552 Test Loss: 0.1018691\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0766863\n",
      "\tspeed: 0.0304s/iter; left time: 619.8486s\n",
      "\titers: 200, epoch: 10 | loss: 0.0779208\n",
      "\tspeed: 0.0123s/iter; left time: 249.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 225 | Train Loss: 0.0758604 Vali Loss: 0.0904989 Test Loss: 0.1023914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0734509\n",
      "\tspeed: 0.0304s/iter; left time: 612.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0725524\n",
      "\tspeed: 0.0123s/iter; left time: 246.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0744450 Vali Loss: 0.0893395 Test Loss: 0.1021138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720939\n",
      "\tspeed: 0.0315s/iter; left time: 627.2959s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722905\n",
      "\tspeed: 0.0174s/iter; left time: 344.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0732077 Vali Loss: 0.0904308 Test Loss: 0.1031738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749435\n",
      "\tspeed: 0.0346s/iter; left time: 681.6041s\n",
      "\titers: 200, epoch: 13 | loss: 0.0711577\n",
      "\tspeed: 0.0164s/iter; left time: 321.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0722044 Vali Loss: 0.0908698 Test Loss: 0.1039440\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742032\n",
      "\tspeed: 0.0339s/iter; left time: 660.8271s\n",
      "\titers: 200, epoch: 14 | loss: 0.0721227\n",
      "\tspeed: 0.0135s/iter; left time: 261.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0711550 Vali Loss: 0.0902325 Test Loss: 0.1029459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0705779\n",
      "\tspeed: 0.0327s/iter; left time: 629.7867s\n",
      "\titers: 200, epoch: 15 | loss: 0.0729217\n",
      "\tspeed: 0.0127s/iter; left time: 242.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0703936 Vali Loss: 0.0904472 Test Loss: 0.1037747\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023172199726104736, rmse:0.15222418308258057, mae:0.10025465488433838, rse:0.44722095131874084\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:33.42s\n",
      "Intermediate time for ES: 00h:10m:05.58s\n",
      "Total time: 00h:10m:05.58s\n"
     ]
    }
   ],
   "source": [
    "countries = ['ES']\n",
    "num_cols = [3]\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_96.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            seq_len=96\n",
    "\n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "ES      24        0.0110  0.1050  0.0643\n",
       "        96        0.0208  0.1443  0.0943\n",
       "        168       0.0232  0.1522  0.1003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_96.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0766317\n",
      "\tspeed: 0.1594s/iter; left time: 704.8764s\n",
      "\titers: 200, epoch: 1 | loss: 0.0695265\n",
      "\tspeed: 0.1316s/iter; left time: 568.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.51s\n",
      "Steps: 226 | Train Loss: 0.0817155 Vali Loss: 0.0705644 Test Loss: 0.0732726\n",
      "Validation loss decreased (inf --> 0.070564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0562303\n",
      "\tspeed: 0.2236s/iter; left time: 938.0175s\n",
      "\titers: 200, epoch: 2 | loss: 0.0503308\n",
      "\tspeed: 0.1293s/iter; left time: 529.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 226 | Train Loss: 0.0548762 Vali Loss: 0.0606296 Test Loss: 0.0633584\n",
      "Validation loss decreased (0.070564 --> 0.060630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513493\n",
      "\tspeed: 0.2205s/iter; left time: 875.1299s\n",
      "\titers: 200, epoch: 3 | loss: 0.0548947\n",
      "\tspeed: 0.1285s/iter; left time: 497.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0505532 Vali Loss: 0.0587098 Test Loss: 0.0624320\n",
      "Validation loss decreased (0.060630 --> 0.058710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0527826\n",
      "\tspeed: 0.2214s/iter; left time: 828.5555s\n",
      "\titers: 200, epoch: 4 | loss: 0.0514440\n",
      "\tspeed: 0.1308s/iter; left time: 476.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 226 | Train Loss: 0.0490150 Vali Loss: 0.0584218 Test Loss: 0.0620288\n",
      "Validation loss decreased (0.058710 --> 0.058422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478798\n",
      "\tspeed: 0.2201s/iter; left time: 773.9429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0479713\n",
      "\tspeed: 0.1288s/iter; left time: 440.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 226 | Train Loss: 0.0479430 Vali Loss: 0.0563894 Test Loss: 0.0599632\n",
      "Validation loss decreased (0.058422 --> 0.056389).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0510816\n",
      "\tspeed: 0.2214s/iter; left time: 728.4802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0462048\n",
      "\tspeed: 0.1288s/iter; left time: 410.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0474372 Vali Loss: 0.0566435 Test Loss: 0.0606992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459774\n",
      "\tspeed: 0.2215s/iter; left time: 679.0356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0513296\n",
      "\tspeed: 0.1256s/iter; left time: 372.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.97s\n",
      "Steps: 226 | Train Loss: 0.0469073 Vali Loss: 0.0559441 Test Loss: 0.0600186\n",
      "Validation loss decreased (0.056389 --> 0.055944).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0457944\n",
      "\tspeed: 0.2160s/iter; left time: 613.3527s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448213\n",
      "\tspeed: 0.1306s/iter; left time: 357.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 226 | Train Loss: 0.0464634 Vali Loss: 0.0558273 Test Loss: 0.0593858\n",
      "Validation loss decreased (0.055944 --> 0.055827).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463735\n",
      "\tspeed: 0.2207s/iter; left time: 576.7132s\n",
      "\titers: 200, epoch: 9 | loss: 0.0489007\n",
      "\tspeed: 0.1280s/iter; left time: 321.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.29s\n",
      "Steps: 226 | Train Loss: 0.0461754 Vali Loss: 0.0556516 Test Loss: 0.0595443\n",
      "Validation loss decreased (0.055827 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0466776\n",
      "\tspeed: 0.2180s/iter; left time: 520.3154s\n",
      "\titers: 200, epoch: 10 | loss: 0.0459872\n",
      "\tspeed: 0.1278s/iter; left time: 292.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0457334 Vali Loss: 0.0548611 Test Loss: 0.0585909\n",
      "Validation loss decreased (0.055652 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0433881\n",
      "\tspeed: 0.2203s/iter; left time: 476.1144s\n",
      "\titers: 200, epoch: 11 | loss: 0.0430847\n",
      "\tspeed: 0.1303s/iter; left time: 268.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0453992 Vali Loss: 0.0553987 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0467320\n",
      "\tspeed: 0.2355s/iter; left time: 455.6640s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414491\n",
      "\tspeed: 0.1276s/iter; left time: 234.2293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.63s\n",
      "Steps: 226 | Train Loss: 0.0452521 Vali Loss: 0.0548284 Test Loss: 0.0586648\n",
      "Validation loss decreased (0.054861 --> 0.054828).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.2175s/iter; left time: 371.7388s\n",
      "\titers: 200, epoch: 13 | loss: 0.0478617\n",
      "\tspeed: 0.1292s/iter; left time: 207.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 226 | Train Loss: 0.0450395 Vali Loss: 0.0549135 Test Loss: 0.0585464\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0442970\n",
      "\tspeed: 0.2223s/iter; left time: 329.6137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0503605\n",
      "\tspeed: 0.1325s/iter; left time: 183.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 226 | Train Loss: 0.0447735 Vali Loss: 0.0546823 Test Loss: 0.0583076\n",
      "Validation loss decreased (0.054828 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0424463\n",
      "\tspeed: 0.2271s/iter; left time: 285.4459s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444540\n",
      "\tspeed: 0.1271s/iter; left time: 147.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0446773 Vali Loss: 0.0546821 Test Loss: 0.0582906\n",
      "Validation loss decreased (0.054682 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0437147\n",
      "\tspeed: 0.2197s/iter; left time: 226.5216s\n",
      "\titers: 200, epoch: 16 | loss: 0.0457383\n",
      "\tspeed: 0.1265s/iter; left time: 117.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.24s\n",
      "Steps: 226 | Train Loss: 0.0444284 Vali Loss: 0.0544112 Test Loss: 0.0578407\n",
      "Validation loss decreased (0.054682 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0409016\n",
      "\tspeed: 0.2172s/iter; left time: 174.8492s\n",
      "\titers: 200, epoch: 17 | loss: 0.0478386\n",
      "\tspeed: 0.1298s/iter; left time: 91.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 226 | Train Loss: 0.0443060 Vali Loss: 0.0542591 Test Loss: 0.0578918\n",
      "Validation loss decreased (0.054411 --> 0.054259).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443076\n",
      "\tspeed: 0.2171s/iter; left time: 125.7041s\n",
      "\titers: 200, epoch: 18 | loss: 0.0450188\n",
      "\tspeed: 0.1293s/iter; left time: 61.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0441691 Vali Loss: 0.0540334 Test Loss: 0.0580545\n",
      "Validation loss decreased (0.054259 --> 0.054033).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0454062\n",
      "\tspeed: 0.2185s/iter; left time: 77.1218s\n",
      "\titers: 200, epoch: 19 | loss: 0.0424051\n",
      "\tspeed: 0.1292s/iter; left time: 32.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0440228 Vali Loss: 0.0539079 Test Loss: 0.0574121\n",
      "Validation loss decreased (0.054033 --> 0.053908).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0425628\n",
      "\tspeed: 0.2249s/iter; left time: 28.5604s\n",
      "\titers: 200, epoch: 20 | loss: 0.0424072\n",
      "\tspeed: 0.1289s/iter; left time: 3.4791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 226 | Train Loss: 0.0439709 Vali Loss: 0.0540611 Test Loss: 0.0577443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010757667943835258, rmse:0.10371917486190796, mae:0.057412099093198776, rse:0.4001457095146179\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0778962\n",
      "\tspeed: 0.1302s/iter; left time: 575.4611s\n",
      "\titers: 200, epoch: 1 | loss: 0.0747243\n",
      "\tspeed: 0.1281s/iter; left time: 553.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 226 | Train Loss: 0.0831907 Vali Loss: 0.0704090 Test Loss: 0.0729090\n",
      "Validation loss decreased (inf --> 0.070409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0543477\n",
      "\tspeed: 0.2208s/iter; left time: 926.2374s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524221\n",
      "\tspeed: 0.1277s/iter; left time: 523.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 226 | Train Loss: 0.0553467 Vali Loss: 0.0607321 Test Loss: 0.0636736\n",
      "Validation loss decreased (0.070409 --> 0.060732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0470920\n",
      "\tspeed: 0.2191s/iter; left time: 869.6660s\n",
      "\titers: 200, epoch: 3 | loss: 0.0494604\n",
      "\tspeed: 0.1267s/iter; left time: 490.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.01s\n",
      "Steps: 226 | Train Loss: 0.0507888 Vali Loss: 0.0581976 Test Loss: 0.0614593\n",
      "Validation loss decreased (0.060732 --> 0.058198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472974\n",
      "\tspeed: 0.2199s/iter; left time: 823.1736s\n",
      "\titers: 200, epoch: 4 | loss: 0.0468269\n",
      "\tspeed: 0.1290s/iter; left time: 469.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.37s\n",
      "Steps: 226 | Train Loss: 0.0489967 Vali Loss: 0.0577703 Test Loss: 0.0621285\n",
      "Validation loss decreased (0.058198 --> 0.057770).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0490690\n",
      "\tspeed: 0.2222s/iter; left time: 781.3646s\n",
      "\titers: 200, epoch: 5 | loss: 0.0480625\n",
      "\tspeed: 0.1290s/iter; left time: 440.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 226 | Train Loss: 0.0481537 Vali Loss: 0.0568581 Test Loss: 0.0606220\n",
      "Validation loss decreased (0.057770 --> 0.056858).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454466\n",
      "\tspeed: 0.2245s/iter; left time: 738.7034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0472364\n",
      "\tspeed: 0.1300s/iter; left time: 414.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.66s\n",
      "Steps: 226 | Train Loss: 0.0473543 Vali Loss: 0.0561352 Test Loss: 0.0599884\n",
      "Validation loss decreased (0.056858 --> 0.056135).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0457151\n",
      "\tspeed: 0.2253s/iter; left time: 690.5855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0485219\n",
      "\tspeed: 0.1273s/iter; left time: 377.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.23s\n",
      "Steps: 226 | Train Loss: 0.0469531 Vali Loss: 0.0555767 Test Loss: 0.0595131\n",
      "Validation loss decreased (0.056135 --> 0.055577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0456666\n",
      "\tspeed: 0.2198s/iter; left time: 624.1087s\n",
      "\titers: 200, epoch: 8 | loss: 0.0436416\n",
      "\tspeed: 0.1267s/iter; left time: 347.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 226 | Train Loss: 0.0464396 Vali Loss: 0.0560706 Test Loss: 0.0598718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0451892\n",
      "\tspeed: 0.2140s/iter; left time: 559.1509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0475388\n",
      "\tspeed: 0.1279s/iter; left time: 321.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 226 | Train Loss: 0.0460145 Vali Loss: 0.0551534 Test Loss: 0.0584895\n",
      "Validation loss decreased (0.055577 --> 0.055153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0418452\n",
      "\tspeed: 0.2255s/iter; left time: 538.1840s\n",
      "\titers: 200, epoch: 10 | loss: 0.0461544\n",
      "\tspeed: 0.1294s/iter; left time: 295.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 226 | Train Loss: 0.0457849 Vali Loss: 0.0551798 Test Loss: 0.0594885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0420638\n",
      "\tspeed: 0.2259s/iter; left time: 488.2519s\n",
      "\titers: 200, epoch: 11 | loss: 0.0461470\n",
      "\tspeed: 0.1284s/iter; left time: 264.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.36s\n",
      "Steps: 226 | Train Loss: 0.0454104 Vali Loss: 0.0548973 Test Loss: 0.0588777\n",
      "Validation loss decreased (0.055153 --> 0.054897).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0470574\n",
      "\tspeed: 0.2291s/iter; left time: 443.3602s\n",
      "\titers: 200, epoch: 12 | loss: 0.0454375\n",
      "\tspeed: 0.1288s/iter; left time: 236.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 226 | Train Loss: 0.0451413 Vali Loss: 0.0549472 Test Loss: 0.0585421\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0454469\n",
      "\tspeed: 0.2142s/iter; left time: 366.1507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0446453\n",
      "\tspeed: 0.1260s/iter; left time: 202.6874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 226 | Train Loss: 0.0450150 Vali Loss: 0.0546606 Test Loss: 0.0587026\n",
      "Validation loss decreased (0.054897 --> 0.054661).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417745\n",
      "\tspeed: 0.2182s/iter; left time: 323.5572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0470195\n",
      "\tspeed: 0.1297s/iter; left time: 179.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 226 | Train Loss: 0.0447190 Vali Loss: 0.0546096 Test Loss: 0.0580985\n",
      "Validation loss decreased (0.054661 --> 0.054610).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0412011\n",
      "\tspeed: 0.2209s/iter; left time: 277.6884s\n",
      "\titers: 200, epoch: 15 | loss: 0.0458716\n",
      "\tspeed: 0.1267s/iter; left time: 146.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.73s\n",
      "Steps: 226 | Train Loss: 0.0445536 Vali Loss: 0.0544069 Test Loss: 0.0583128\n",
      "Validation loss decreased (0.054610 --> 0.054407).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0444622\n",
      "\tspeed: 0.2213s/iter; left time: 228.1786s\n",
      "\titers: 200, epoch: 16 | loss: 0.0436480\n",
      "\tspeed: 0.1282s/iter; left time: 119.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0444886 Vali Loss: 0.0541725 Test Loss: 0.0580277\n",
      "Validation loss decreased (0.054407 --> 0.054172).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0422892\n",
      "\tspeed: 0.2222s/iter; left time: 178.8709s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470878\n",
      "\tspeed: 0.1280s/iter; left time: 90.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 226 | Train Loss: 0.0442781 Vali Loss: 0.0540447 Test Loss: 0.0577816\n",
      "Validation loss decreased (0.054172 --> 0.054045).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0428621\n",
      "\tspeed: 0.2221s/iter; left time: 128.6126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420758\n",
      "\tspeed: 0.1283s/iter; left time: 61.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0441897 Vali Loss: 0.0538316 Test Loss: 0.0574501\n",
      "Validation loss decreased (0.054045 --> 0.053832).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0450100\n",
      "\tspeed: 0.2262s/iter; left time: 79.8356s\n",
      "\titers: 200, epoch: 19 | loss: 0.0438370\n",
      "\tspeed: 0.1301s/iter; left time: 32.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0440705 Vali Loss: 0.0542827 Test Loss: 0.0579725\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0456248\n",
      "\tspeed: 0.2326s/iter; left time: 29.5355s\n",
      "\titers: 200, epoch: 20 | loss: 0.0453012\n",
      "\tspeed: 0.1281s/iter; left time: 3.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.80s\n",
      "Steps: 226 | Train Loss: 0.0439894 Vali Loss: 0.0539670 Test Loss: 0.0578357\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010744874365627766, rmse:0.10365748405456543, mae:0.057450130581855774, rse:0.3999077081680298\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:39.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0821435\n",
      "\tspeed: 0.1545s/iter; left time: 679.7485s\n",
      "\titers: 200, epoch: 1 | loss: 0.0831200\n",
      "\tspeed: 0.1290s/iter; left time: 554.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.47s\n",
      "Steps: 225 | Train Loss: 0.0913107 Vali Loss: 0.0835734 Test Loss: 0.0922536\n",
      "Validation loss decreased (inf --> 0.083573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0678073\n",
      "\tspeed: 0.2200s/iter; left time: 918.6109s\n",
      "\titers: 200, epoch: 2 | loss: 0.0694359\n",
      "\tspeed: 0.1323s/iter; left time: 539.0511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 225 | Train Loss: 0.0713360 Vali Loss: 0.0779968 Test Loss: 0.0871771\n",
      "Validation loss decreased (0.083573 --> 0.077997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693156\n",
      "\tspeed: 0.2307s/iter; left time: 911.5833s\n",
      "\titers: 200, epoch: 3 | loss: 0.0701405\n",
      "\tspeed: 0.1332s/iter; left time: 512.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.04s\n",
      "Steps: 225 | Train Loss: 0.0673879 Vali Loss: 0.0758549 Test Loss: 0.0862915\n",
      "Validation loss decreased (0.077997 --> 0.075855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674907\n",
      "\tspeed: 0.2312s/iter; left time: 861.4394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651132\n",
      "\tspeed: 0.1320s/iter; left time: 478.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.88s\n",
      "Steps: 225 | Train Loss: 0.0659649 Vali Loss: 0.0749174 Test Loss: 0.0851213\n",
      "Validation loss decreased (0.075855 --> 0.074917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0647665\n",
      "\tspeed: 0.2353s/iter; left time: 823.8602s\n",
      "\titers: 200, epoch: 5 | loss: 0.0680801\n",
      "\tspeed: 0.1313s/iter; left time: 446.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0647660 Vali Loss: 0.0744220 Test Loss: 0.0845276\n",
      "Validation loss decreased (0.074917 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638947\n",
      "\tspeed: 0.2260s/iter; left time: 740.4066s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613103\n",
      "\tspeed: 0.1293s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.40s\n",
      "Steps: 225 | Train Loss: 0.0637174 Vali Loss: 0.0733305 Test Loss: 0.0838157\n",
      "Validation loss decreased (0.074422 --> 0.073331).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639387\n",
      "\tspeed: 0.2250s/iter; left time: 686.4712s\n",
      "\titers: 200, epoch: 7 | loss: 0.0675600\n",
      "\tspeed: 0.1322s/iter; left time: 390.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.76s\n",
      "Steps: 225 | Train Loss: 0.0629273 Vali Loss: 0.0727968 Test Loss: 0.0837717\n",
      "Validation loss decreased (0.073331 --> 0.072797).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0639801\n",
      "\tspeed: 0.2265s/iter; left time: 639.9718s\n",
      "\titers: 200, epoch: 8 | loss: 0.0635716\n",
      "\tspeed: 0.1335s/iter; left time: 363.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.93s\n",
      "Steps: 225 | Train Loss: 0.0625018 Vali Loss: 0.0732585 Test Loss: 0.0833542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613126\n",
      "\tspeed: 0.2306s/iter; left time: 599.6642s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657632\n",
      "\tspeed: 0.1333s/iter; left time: 333.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.36s\n",
      "Steps: 225 | Train Loss: 0.0620127 Vali Loss: 0.0723178 Test Loss: 0.0833246\n",
      "Validation loss decreased (0.072797 --> 0.072318).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602790\n",
      "\tspeed: 0.2521s/iter; left time: 599.0509s\n",
      "\titers: 200, epoch: 10 | loss: 0.0600664\n",
      "\tspeed: 0.1314s/iter; left time: 299.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:30.65s\n",
      "Steps: 225 | Train Loss: 0.0616372 Vali Loss: 0.0726278 Test Loss: 0.0831672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0597956\n",
      "\tspeed: 0.2272s/iter; left time: 488.7564s\n",
      "\titers: 200, epoch: 11 | loss: 0.0623358\n",
      "\tspeed: 0.1313s/iter; left time: 269.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.38s\n",
      "Steps: 225 | Train Loss: 0.0612253 Vali Loss: 0.0724789 Test Loss: 0.0828953\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646971\n",
      "\tspeed: 0.2234s/iter; left time: 430.1962s\n",
      "\titers: 200, epoch: 12 | loss: 0.0596059\n",
      "\tspeed: 0.1309s/iter; left time: 239.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 225 | Train Loss: 0.0609990 Vali Loss: 0.0719485 Test Loss: 0.0828231\n",
      "Validation loss decreased (0.072318 --> 0.071948).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582323\n",
      "\tspeed: 0.2297s/iter; left time: 390.7735s\n",
      "\titers: 200, epoch: 13 | loss: 0.0634934\n",
      "\tspeed: 0.1343s/iter; left time: 215.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.37s\n",
      "Steps: 225 | Train Loss: 0.0607619 Vali Loss: 0.0720306 Test Loss: 0.0829450\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0619525\n",
      "\tspeed: 0.2277s/iter; left time: 336.1307s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590660\n",
      "\tspeed: 0.1288s/iter; left time: 177.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.32s\n",
      "Steps: 225 | Train Loss: 0.0605827 Vali Loss: 0.0714336 Test Loss: 0.0823739\n",
      "Validation loss decreased (0.071948 --> 0.071434).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587442\n",
      "\tspeed: 0.2352s/iter; left time: 294.2492s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619651\n",
      "\tspeed: 0.1357s/iter; left time: 156.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.52s\n",
      "Steps: 225 | Train Loss: 0.0603027 Vali Loss: 0.0718620 Test Loss: 0.0827420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584721\n",
      "\tspeed: 0.2438s/iter; left time: 250.1415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555041\n",
      "\tspeed: 0.1298s/iter; left time: 120.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.02s\n",
      "Steps: 225 | Train Loss: 0.0602388 Vali Loss: 0.0716047 Test Loss: 0.0822622\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0603823\n",
      "\tspeed: 0.2270s/iter; left time: 181.8549s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582806\n",
      "\tspeed: 0.1320s/iter; left time: 92.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0599569 Vali Loss: 0.0717798 Test Loss: 0.0822858\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0589450\n",
      "\tspeed: 0.2184s/iter; left time: 125.7864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634137\n",
      "\tspeed: 0.1286s/iter; left time: 61.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 225 | Train Loss: 0.0598509 Vali Loss: 0.0716802 Test Loss: 0.0823941\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0584398\n",
      "\tspeed: 0.2293s/iter; left time: 80.4760s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588430\n",
      "\tspeed: 0.1327s/iter; left time: 33.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0596980 Vali Loss: 0.0715777 Test Loss: 0.0823717\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020205451175570488, rmse:0.14214588701725006, mae:0.08237384259700775, rse:0.549858033657074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0894169\n",
      "\tspeed: 0.1355s/iter; left time: 596.4210s\n",
      "\titers: 200, epoch: 1 | loss: 0.0878222\n",
      "\tspeed: 0.1323s/iter; left time: 568.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0921728 Vali Loss: 0.0833592 Test Loss: 0.0920192\n",
      "Validation loss decreased (inf --> 0.083359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0669506\n",
      "\tspeed: 0.2316s/iter; left time: 967.1961s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688249\n",
      "\tspeed: 0.1379s/iter; left time: 562.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.68s\n",
      "Steps: 225 | Train Loss: 0.0714438 Vali Loss: 0.0777502 Test Loss: 0.0868886\n",
      "Validation loss decreased (0.083359 --> 0.077750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638473\n",
      "\tspeed: 0.2275s/iter; left time: 898.6594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0689979\n",
      "\tspeed: 0.1291s/iter; left time: 497.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 225 | Train Loss: 0.0672572 Vali Loss: 0.0760684 Test Loss: 0.0863736\n",
      "Validation loss decreased (0.077750 --> 0.076068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672900\n",
      "\tspeed: 0.2176s/iter; left time: 810.6828s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639855\n",
      "\tspeed: 0.1278s/iter; left time: 463.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.98s\n",
      "Steps: 225 | Train Loss: 0.0658523 Vali Loss: 0.0749936 Test Loss: 0.0854241\n",
      "Validation loss decreased (0.076068 --> 0.074994).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0626215\n",
      "\tspeed: 0.2190s/iter; left time: 766.5479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626608\n",
      "\tspeed: 0.1280s/iter; left time: 435.2641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0646476 Vali Loss: 0.0739110 Test Loss: 0.0846380\n",
      "Validation loss decreased (0.074994 --> 0.073911).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641698\n",
      "\tspeed: 0.2408s/iter; left time: 788.9978s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627856\n",
      "\tspeed: 0.1388s/iter; left time: 440.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.55s\n",
      "Steps: 225 | Train Loss: 0.0639034 Vali Loss: 0.0747545 Test Loss: 0.0855872\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0652396\n",
      "\tspeed: 0.2333s/iter; left time: 711.9271s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667626\n",
      "\tspeed: 0.1315s/iter; left time: 387.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 225 | Train Loss: 0.0631427 Vali Loss: 0.0732717 Test Loss: 0.0834854\n",
      "Validation loss decreased (0.073911 --> 0.073272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0631166\n",
      "\tspeed: 0.2220s/iter; left time: 627.4747s\n",
      "\titers: 200, epoch: 8 | loss: 0.0626838\n",
      "\tspeed: 0.1296s/iter; left time: 353.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.34s\n",
      "Steps: 225 | Train Loss: 0.0625255 Vali Loss: 0.0733401 Test Loss: 0.0836931\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613080\n",
      "\tspeed: 0.2264s/iter; left time: 588.7666s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632498\n",
      "\tspeed: 0.1335s/iter; left time: 333.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0621014 Vali Loss: 0.0734221 Test Loss: 0.0835117\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0624017\n",
      "\tspeed: 0.2320s/iter; left time: 551.2138s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701763\n",
      "\tspeed: 0.1306s/iter; left time: 297.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 225 | Train Loss: 0.0616782 Vali Loss: 0.0723835 Test Loss: 0.0828523\n",
      "Validation loss decreased (0.073272 --> 0.072383).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0656709\n",
      "\tspeed: 0.2371s/iter; left time: 510.0696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0620192\n",
      "\tspeed: 0.1364s/iter; left time: 279.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0613649 Vali Loss: 0.0728863 Test Loss: 0.0833074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611714\n",
      "\tspeed: 0.2154s/iter; left time: 414.8459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589759\n",
      "\tspeed: 0.1288s/iter; left time: 235.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0611654 Vali Loss: 0.0720310 Test Loss: 0.0828215\n",
      "Validation loss decreased (0.072383 --> 0.072031).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0601530\n",
      "\tspeed: 0.2293s/iter; left time: 390.0917s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627939\n",
      "\tspeed: 0.1299s/iter; left time: 207.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0608504 Vali Loss: 0.0722075 Test Loss: 0.0826092\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0604201\n",
      "\tspeed: 0.2315s/iter; left time: 341.7533s\n",
      "\titers: 200, epoch: 14 | loss: 0.0634251\n",
      "\tspeed: 0.1313s/iter; left time: 180.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0606327 Vali Loss: 0.0726777 Test Loss: 0.0831189\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0640372\n",
      "\tspeed: 0.2379s/iter; left time: 297.5685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0630407\n",
      "\tspeed: 0.1352s/iter; left time: 155.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0604669 Vali Loss: 0.0721378 Test Loss: 0.0825559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0591577\n",
      "\tspeed: 0.2499s/iter; left time: 256.4079s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630949\n",
      "\tspeed: 0.1303s/iter; left time: 120.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 225 | Train Loss: 0.0602721 Vali Loss: 0.0723365 Test Loss: 0.0823819\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0585780\n",
      "\tspeed: 0.2232s/iter; left time: 178.7965s\n",
      "\titers: 200, epoch: 17 | loss: 0.0607349\n",
      "\tspeed: 0.1285s/iter; left time: 90.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 225 | Train Loss: 0.0601261 Vali Loss: 0.0719406 Test Loss: 0.0822569\n",
      "Validation loss decreased (0.072031 --> 0.071941).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573446\n",
      "\tspeed: 0.2356s/iter; left time: 135.7109s\n",
      "\titers: 200, epoch: 18 | loss: 0.0599148\n",
      "\tspeed: 0.1314s/iter; left time: 62.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.67s\n",
      "Steps: 225 | Train Loss: 0.0599890 Vali Loss: 0.0719018 Test Loss: 0.0822290\n",
      "Validation loss decreased (0.071941 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0560430\n",
      "\tspeed: 0.2310s/iter; left time: 81.0980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0599572\n",
      "\tspeed: 0.1354s/iter; left time: 33.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0598794 Vali Loss: 0.0721454 Test Loss: 0.0823054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0642339\n",
      "\tspeed: 0.2471s/iter; left time: 31.1371s\n",
      "\titers: 200, epoch: 20 | loss: 0.0639723\n",
      "\tspeed: 0.1287s/iter; left time: 3.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 225 | Train Loss: 0.0597939 Vali Loss: 0.0717466 Test Loss: 0.0819931\n",
      "Validation loss decreased (0.071902 --> 0.071747).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019991254433989525, rmse:0.14139042794704437, mae:0.08199303597211838, rse:0.5469357967376709\n",
      "Intermediate time for FR and pred_len 96: 00h:23m:48.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0916881\n",
      "\tspeed: 0.1560s/iter; left time: 686.5020s\n",
      "\titers: 200, epoch: 1 | loss: 0.0869237\n",
      "\tspeed: 0.1299s/iter; left time: 558.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0946456 Vali Loss: 0.0873302 Test Loss: 0.0960933\n",
      "Validation loss decreased (inf --> 0.087330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765944\n",
      "\tspeed: 0.2283s/iter; left time: 953.3026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703099\n",
      "\tspeed: 0.1304s/iter; left time: 531.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.74s\n",
      "Steps: 225 | Train Loss: 0.0755584 Vali Loss: 0.0817829 Test Loss: 0.0917741\n",
      "Validation loss decreased (0.087330 --> 0.081783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0746351\n",
      "\tspeed: 0.2314s/iter; left time: 914.1378s\n",
      "\titers: 200, epoch: 3 | loss: 0.0698561\n",
      "\tspeed: 0.1303s/iter; left time: 501.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.53s\n",
      "Steps: 225 | Train Loss: 0.0723485 Vali Loss: 0.0802219 Test Loss: 0.0911483\n",
      "Validation loss decreased (0.081783 --> 0.080222).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729910\n",
      "\tspeed: 0.2407s/iter; left time: 896.8529s\n",
      "\titers: 200, epoch: 4 | loss: 0.0687222\n",
      "\tspeed: 0.1320s/iter; left time: 478.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 225 | Train Loss: 0.0707458 Vali Loss: 0.0792043 Test Loss: 0.0905273\n",
      "Validation loss decreased (0.080222 --> 0.079204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0712522\n",
      "\tspeed: 0.2426s/iter; left time: 849.1715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685331\n",
      "\tspeed: 0.1376s/iter; left time: 468.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.85s\n",
      "Steps: 225 | Train Loss: 0.0694804 Vali Loss: 0.0787229 Test Loss: 0.0898371\n",
      "Validation loss decreased (0.079204 --> 0.078723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0689771\n",
      "\tspeed: 0.2448s/iter; left time: 802.0766s\n",
      "\titers: 200, epoch: 6 | loss: 0.0695027\n",
      "\tspeed: 0.1285s/iter; left time: 408.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 225 | Train Loss: 0.0686404 Vali Loss: 0.0781113 Test Loss: 0.0888023\n",
      "Validation loss decreased (0.078723 --> 0.078111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0682323\n",
      "\tspeed: 0.2350s/iter; left time: 717.0457s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699818\n",
      "\tspeed: 0.1299s/iter; left time: 383.3049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0679058 Vali Loss: 0.0782345 Test Loss: 0.0895413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0707153\n",
      "\tspeed: 0.2300s/iter; left time: 649.8795s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695843\n",
      "\tspeed: 0.1323s/iter; left time: 360.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 225 | Train Loss: 0.0674135 Vali Loss: 0.0771264 Test Loss: 0.0888884\n",
      "Validation loss decreased (0.078111 --> 0.077126).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0653303\n",
      "\tspeed: 0.2277s/iter; left time: 592.3061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724449\n",
      "\tspeed: 0.1330s/iter; left time: 332.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0669095 Vali Loss: 0.0773865 Test Loss: 0.0887160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0634143\n",
      "\tspeed: 0.2379s/iter; left time: 565.1939s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633310\n",
      "\tspeed: 0.1394s/iter; left time: 317.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 225 | Train Loss: 0.0665528 Vali Loss: 0.0775114 Test Loss: 0.0891376\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642596\n",
      "\tspeed: 0.2275s/iter; left time: 489.4264s\n",
      "\titers: 200, epoch: 11 | loss: 0.0683906\n",
      "\tspeed: 0.1276s/iter; left time: 261.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.03s\n",
      "Steps: 225 | Train Loss: 0.0662428 Vali Loss: 0.0768049 Test Loss: 0.0883481\n",
      "Validation loss decreased (0.077126 --> 0.076805).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624630\n",
      "\tspeed: 0.2224s/iter; left time: 428.3307s\n",
      "\titers: 200, epoch: 12 | loss: 0.0640266\n",
      "\tspeed: 0.1273s/iter; left time: 232.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 225 | Train Loss: 0.0660178 Vali Loss: 0.0770547 Test Loss: 0.0880818\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0683184\n",
      "\tspeed: 0.2192s/iter; left time: 372.8130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646703\n",
      "\tspeed: 0.1305s/iter; left time: 208.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.52s\n",
      "Steps: 225 | Train Loss: 0.0657393 Vali Loss: 0.0767636 Test Loss: 0.0878029\n",
      "Validation loss decreased (0.076805 --> 0.076764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0680823\n",
      "\tspeed: 0.2324s/iter; left time: 343.0095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666962\n",
      "\tspeed: 0.1327s/iter; left time: 182.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.85s\n",
      "Steps: 225 | Train Loss: 0.0655135 Vali Loss: 0.0769423 Test Loss: 0.0880894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665233\n",
      "\tspeed: 0.2246s/iter; left time: 281.0342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659037\n",
      "\tspeed: 0.1345s/iter; left time: 154.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.31s\n",
      "Steps: 225 | Train Loss: 0.0653375 Vali Loss: 0.0765706 Test Loss: 0.0880015\n",
      "Validation loss decreased (0.076764 --> 0.076571).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0669951\n",
      "\tspeed: 0.2355s/iter; left time: 241.6049s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666725\n",
      "\tspeed: 0.1388s/iter; left time: 128.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 225 | Train Loss: 0.0651356 Vali Loss: 0.0767214 Test Loss: 0.0881702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0642989\n",
      "\tspeed: 0.2467s/iter; left time: 197.5974s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637477\n",
      "\tspeed: 0.1343s/iter; left time: 94.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:30.53s\n",
      "Steps: 225 | Train Loss: 0.0649981 Vali Loss: 0.0762711 Test Loss: 0.0878609\n",
      "Validation loss decreased (0.076571 --> 0.076271).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0646516\n",
      "\tspeed: 0.2447s/iter; left time: 140.9559s\n",
      "\titers: 200, epoch: 18 | loss: 0.0679890\n",
      "\tspeed: 0.1346s/iter; left time: 64.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.47s\n",
      "Steps: 225 | Train Loss: 0.0648507 Vali Loss: 0.0767555 Test Loss: 0.0878701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0642924\n",
      "\tspeed: 0.2296s/iter; left time: 80.5763s\n",
      "\titers: 200, epoch: 19 | loss: 0.0647242\n",
      "\tspeed: 0.1311s/iter; left time: 32.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.71s\n",
      "Steps: 225 | Train Loss: 0.0647024 Vali Loss: 0.0764668 Test Loss: 0.0877801\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0624535\n",
      "\tspeed: 0.2363s/iter; left time: 29.7705s\n",
      "\titers: 200, epoch: 20 | loss: 0.0675110\n",
      "\tspeed: 0.1368s/iter; left time: 3.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0646263 Vali Loss: 0.0767285 Test Loss: 0.0880821\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02186432108283043, rmse:0.147865891456604, mae:0.08786085247993469, rse:0.5726985931396484\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0919613\n",
      "\tspeed: 0.1358s/iter; left time: 597.7374s\n",
      "\titers: 200, epoch: 1 | loss: 0.0867113\n",
      "\tspeed: 0.1342s/iter; left time: 577.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.35s\n",
      "Steps: 225 | Train Loss: 0.0940161 Vali Loss: 0.0871972 Test Loss: 0.0960238\n",
      "Validation loss decreased (inf --> 0.087197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0713059\n",
      "\tspeed: 0.2526s/iter; left time: 1054.7877s\n",
      "\titers: 200, epoch: 2 | loss: 0.0714525\n",
      "\tspeed: 0.1323s/iter; left time: 539.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0757864 Vali Loss: 0.0823225 Test Loss: 0.0925486\n",
      "Validation loss decreased (0.087197 --> 0.082323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0671578\n",
      "\tspeed: 0.2375s/iter; left time: 938.2541s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709672\n",
      "\tspeed: 0.1327s/iter; left time: 511.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 225 | Train Loss: 0.0723406 Vali Loss: 0.0810314 Test Loss: 0.0920664\n",
      "Validation loss decreased (0.082323 --> 0.081031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0700649\n",
      "\tspeed: 0.2308s/iter; left time: 859.8207s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703632\n",
      "\tspeed: 0.1333s/iter; left time: 483.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.08s\n",
      "Steps: 225 | Train Loss: 0.0707206 Vali Loss: 0.0790750 Test Loss: 0.0903970\n",
      "Validation loss decreased (0.081031 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656126\n",
      "\tspeed: 0.2482s/iter; left time: 869.1222s\n",
      "\titers: 200, epoch: 5 | loss: 0.0692182\n",
      "\tspeed: 0.1333s/iter; left time: 453.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 225 | Train Loss: 0.0694477 Vali Loss: 0.0789509 Test Loss: 0.0901828\n",
      "Validation loss decreased (0.079075 --> 0.078951).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0686687\n",
      "\tspeed: 0.2328s/iter; left time: 762.7674s\n",
      "\titers: 200, epoch: 6 | loss: 0.0678676\n",
      "\tspeed: 0.1305s/iter; left time: 414.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.92s\n",
      "Steps: 225 | Train Loss: 0.0686255 Vali Loss: 0.0783217 Test Loss: 0.0896430\n",
      "Validation loss decreased (0.078951 --> 0.078322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0661045\n",
      "\tspeed: 0.2638s/iter; left time: 804.9863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0682785\n",
      "\tspeed: 0.1376s/iter; left time: 406.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.81s\n",
      "Steps: 225 | Train Loss: 0.0678917 Vali Loss: 0.0783234 Test Loss: 0.0887447\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0683451\n",
      "\tspeed: 0.2095s/iter; left time: 591.9777s\n",
      "\titers: 200, epoch: 8 | loss: 0.0687753\n",
      "\tspeed: 0.1242s/iter; left time: 338.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0673855 Vali Loss: 0.0778848 Test Loss: 0.0888012\n",
      "Validation loss decreased (0.078322 --> 0.077885).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657038\n",
      "\tspeed: 0.2074s/iter; left time: 539.5108s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665707\n",
      "\tspeed: 0.1242s/iter; left time: 310.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0668863 Vali Loss: 0.0776036 Test Loss: 0.0886073\n",
      "Validation loss decreased (0.077885 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667441\n",
      "\tspeed: 0.2228s/iter; left time: 529.2991s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633583\n",
      "\tspeed: 0.1245s/iter; left time: 283.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0664838 Vali Loss: 0.0774441 Test Loss: 0.0883286\n",
      "Validation loss decreased (0.077604 --> 0.077444).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0627698\n",
      "\tspeed: 0.2068s/iter; left time: 444.8338s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660751\n",
      "\tspeed: 0.1249s/iter; left time: 256.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0662418 Vali Loss: 0.0770156 Test Loss: 0.0887772\n",
      "Validation loss decreased (0.077444 --> 0.077016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683075\n",
      "\tspeed: 0.2137s/iter; left time: 411.6625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0689828\n",
      "\tspeed: 0.1246s/iter; left time: 227.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0658903 Vali Loss: 0.0768637 Test Loss: 0.0878356\n",
      "Validation loss decreased (0.077016 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688406\n",
      "\tspeed: 0.2060s/iter; left time: 350.4884s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636687\n",
      "\tspeed: 0.1243s/iter; left time: 199.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0656338 Vali Loss: 0.0767962 Test Loss: 0.0876834\n",
      "Validation loss decreased (0.076864 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652549\n",
      "\tspeed: 0.2430s/iter; left time: 358.6146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669380\n",
      "\tspeed: 0.1244s/iter; left time: 171.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0654096 Vali Loss: 0.0768992 Test Loss: 0.0880054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605805\n",
      "\tspeed: 0.2051s/iter; left time: 256.5708s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669335\n",
      "\tspeed: 0.1242s/iter; left time: 142.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0652253 Vali Loss: 0.0767318 Test Loss: 0.0878261\n",
      "Validation loss decreased (0.076796 --> 0.076732).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0649559\n",
      "\tspeed: 0.2810s/iter; left time: 288.3519s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645573\n",
      "\tspeed: 0.1239s/iter; left time: 114.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 225 | Train Loss: 0.0650691 Vali Loss: 0.0766515 Test Loss: 0.0880999\n",
      "Validation loss decreased (0.076732 --> 0.076652).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705975\n",
      "\tspeed: 0.2069s/iter; left time: 165.6977s\n",
      "\titers: 200, epoch: 17 | loss: 0.0659833\n",
      "\tspeed: 0.1246s/iter; left time: 87.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0648604 Vali Loss: 0.0765938 Test Loss: 0.0877360\n",
      "Validation loss decreased (0.076652 --> 0.076594).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670262\n",
      "\tspeed: 0.2088s/iter; left time: 120.2704s\n",
      "\titers: 200, epoch: 18 | loss: 0.0629649\n",
      "\tspeed: 0.1242s/iter; left time: 59.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0647039 Vali Loss: 0.0767391 Test Loss: 0.0876653\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0651461\n",
      "\tspeed: 0.2065s/iter; left time: 72.4737s\n",
      "\titers: 200, epoch: 19 | loss: 0.0666738\n",
      "\tspeed: 0.1247s/iter; left time: 31.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0646175 Vali Loss: 0.0765972 Test Loss: 0.0876592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639071\n",
      "\tspeed: 0.2063s/iter; left time: 25.9905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0667633\n",
      "\tspeed: 0.1248s/iter; left time: 3.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0645528 Vali Loss: 0.0764963 Test Loss: 0.0876327\n",
      "Validation loss decreased (0.076594 --> 0.076496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021848367527127266, rmse:0.14781193435192108, mae:0.08763277530670166, rse:0.5724896192550659\n",
      "Intermediate time for FR and pred_len 168: 00h:24m:15.00s\n",
      "Intermediate time for FR: 01h:11m:43.09s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1121790\n",
      "\tspeed: 0.1485s/iter; left time: 656.3155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1071127\n",
      "\tspeed: 0.1232s/iter; left time: 532.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.1183522 Vali Loss: 0.0811168 Test Loss: 0.0823932\n",
      "Validation loss decreased (inf --> 0.081117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740139\n",
      "\tspeed: 0.2044s/iter; left time: 857.5001s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693383\n",
      "\tspeed: 0.1233s/iter; left time: 504.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0758895 Vali Loss: 0.0661073 Test Loss: 0.0684309\n",
      "Validation loss decreased (0.081117 --> 0.066107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0692373\n",
      "\tspeed: 0.2102s/iter; left time: 834.3075s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680119\n",
      "\tspeed: 0.1235s/iter; left time: 477.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 226 | Train Loss: 0.0688669 Vali Loss: 0.0632555 Test Loss: 0.0659584\n",
      "Validation loss decreased (0.066107 --> 0.063256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691024\n",
      "\tspeed: 0.2072s/iter; left time: 775.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713159\n",
      "\tspeed: 0.1235s/iter; left time: 449.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0659160 Vali Loss: 0.0616597 Test Loss: 0.0638568\n",
      "Validation loss decreased (0.063256 --> 0.061660).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0636145\n",
      "\tspeed: 0.2046s/iter; left time: 719.5598s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682091\n",
      "\tspeed: 0.1239s/iter; left time: 423.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 226 | Train Loss: 0.0640215 Vali Loss: 0.0601045 Test Loss: 0.0630680\n",
      "Validation loss decreased (0.061660 --> 0.060105).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645924\n",
      "\tspeed: 0.2080s/iter; left time: 684.6706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0623100\n",
      "\tspeed: 0.1244s/iter; left time: 396.8996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0623804 Vali Loss: 0.0589569 Test Loss: 0.0620875\n",
      "Validation loss decreased (0.060105 --> 0.058957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597447\n",
      "\tspeed: 0.2059s/iter; left time: 631.1167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645506\n",
      "\tspeed: 0.1241s/iter; left time: 368.0582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 226 | Train Loss: 0.0614329 Vali Loss: 0.0588587 Test Loss: 0.0619362\n",
      "Validation loss decreased (0.058957 --> 0.058859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0571509\n",
      "\tspeed: 0.2078s/iter; left time: 589.9646s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552820\n",
      "\tspeed: 0.1242s/iter; left time: 340.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 226 | Train Loss: 0.0606643 Vali Loss: 0.0580877 Test Loss: 0.0607174\n",
      "Validation loss decreased (0.058859 --> 0.058088).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0629100\n",
      "\tspeed: 0.2072s/iter; left time: 541.3866s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620225\n",
      "\tspeed: 0.1241s/iter; left time: 311.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0599683 Vali Loss: 0.0578587 Test Loss: 0.0605800\n",
      "Validation loss decreased (0.058088 --> 0.057859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0574319\n",
      "\tspeed: 0.2074s/iter; left time: 495.0400s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602710\n",
      "\tspeed: 0.1243s/iter; left time: 284.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 226 | Train Loss: 0.0595075 Vali Loss: 0.0576037 Test Loss: 0.0601031\n",
      "Validation loss decreased (0.057859 --> 0.057604).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0606948\n",
      "\tspeed: 0.2064s/iter; left time: 446.0991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578572\n",
      "\tspeed: 0.1242s/iter; left time: 255.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 226 | Train Loss: 0.0590668 Vali Loss: 0.0575622 Test Loss: 0.0603818\n",
      "Validation loss decreased (0.057604 --> 0.057562).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0614702\n",
      "\tspeed: 0.2109s/iter; left time: 408.0815s\n",
      "\titers: 200, epoch: 12 | loss: 0.0576249\n",
      "\tspeed: 0.1240s/iter; left time: 227.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 226 | Train Loss: 0.0588322 Vali Loss: 0.0570690 Test Loss: 0.0595613\n",
      "Validation loss decreased (0.057562 --> 0.057069).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536879\n",
      "\tspeed: 0.2054s/iter; left time: 350.9909s\n",
      "\titers: 200, epoch: 13 | loss: 0.0548065\n",
      "\tspeed: 0.1238s/iter; left time: 199.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0584687 Vali Loss: 0.0568619 Test Loss: 0.0593011\n",
      "Validation loss decreased (0.057069 --> 0.056862).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0570590\n",
      "\tspeed: 0.2051s/iter; left time: 304.2340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0629808\n",
      "\tspeed: 0.1233s/iter; left time: 170.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0580641 Vali Loss: 0.0568366 Test Loss: 0.0590742\n",
      "Validation loss decreased (0.056862 --> 0.056837).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571397\n",
      "\tspeed: 0.2038s/iter; left time: 256.1308s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618289\n",
      "\tspeed: 0.1230s/iter; left time: 142.3411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0577726 Vali Loss: 0.0567835 Test Loss: 0.0589230\n",
      "Validation loss decreased (0.056837 --> 0.056783).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0589630\n",
      "\tspeed: 0.2039s/iter; left time: 210.1841s\n",
      "\titers: 200, epoch: 16 | loss: 0.0573150\n",
      "\tspeed: 0.1231s/iter; left time: 114.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0576216 Vali Loss: 0.0564624 Test Loss: 0.0587323\n",
      "Validation loss decreased (0.056783 --> 0.056462).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0625905\n",
      "\tspeed: 0.2044s/iter; left time: 164.5188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577565\n",
      "\tspeed: 0.1232s/iter; left time: 86.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0573842 Vali Loss: 0.0568271 Test Loss: 0.0590868\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0595494\n",
      "\tspeed: 0.2032s/iter; left time: 117.6542s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563744\n",
      "\tspeed: 0.1231s/iter; left time: 58.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0572813 Vali Loss: 0.0563119 Test Loss: 0.0589350\n",
      "Validation loss decreased (0.056462 --> 0.056312).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0563603\n",
      "\tspeed: 0.2111s/iter; left time: 74.5156s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545016\n",
      "\tspeed: 0.1231s/iter; left time: 31.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0570930 Vali Loss: 0.0561932 Test Loss: 0.0585328\n",
      "Validation loss decreased (0.056312 --> 0.056193).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0566096\n",
      "\tspeed: 0.2045s/iter; left time: 25.9745s\n",
      "\titers: 200, epoch: 20 | loss: 0.0562457\n",
      "\tspeed: 0.1232s/iter; left time: 3.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0569631 Vali Loss: 0.0565658 Test Loss: 0.0586333\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010333484970033169, rmse:0.10165374726057053, mae:0.05853284150362015, rse:0.38409945368766785\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1148740\n",
      "\tspeed: 0.1241s/iter; left time: 548.5404s\n",
      "\titers: 200, epoch: 1 | loss: 0.1035100\n",
      "\tspeed: 0.1231s/iter; left time: 531.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.1211798 Vali Loss: 0.0813818 Test Loss: 0.0824983\n",
      "Validation loss decreased (inf --> 0.081382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743233\n",
      "\tspeed: 0.2036s/iter; left time: 854.1455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723142\n",
      "\tspeed: 0.1233s/iter; left time: 504.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0766999 Vali Loss: 0.0664761 Test Loss: 0.0689256\n",
      "Validation loss decreased (0.081382 --> 0.066476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662167\n",
      "\tspeed: 0.2042s/iter; left time: 810.5253s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662025\n",
      "\tspeed: 0.1231s/iter; left time: 476.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0688360 Vali Loss: 0.0637087 Test Loss: 0.0665311\n",
      "Validation loss decreased (0.066476 --> 0.063709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0641758\n",
      "\tspeed: 0.2029s/iter; left time: 759.5616s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634328\n",
      "\tspeed: 0.1232s/iter; left time: 448.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.95s\n",
      "Steps: 226 | Train Loss: 0.0661288 Vali Loss: 0.0619317 Test Loss: 0.0649719\n",
      "Validation loss decreased (0.063709 --> 0.061932).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0694065\n",
      "\tspeed: 0.2036s/iter; left time: 716.1528s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643803\n",
      "\tspeed: 0.1230s/iter; left time: 420.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.89s\n",
      "Steps: 226 | Train Loss: 0.0639748 Vali Loss: 0.0606104 Test Loss: 0.0633659\n",
      "Validation loss decreased (0.061932 --> 0.060610).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637849\n",
      "\tspeed: 0.2024s/iter; left time: 666.0609s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608316\n",
      "\tspeed: 0.1231s/iter; left time: 392.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.91s\n",
      "Steps: 226 | Train Loss: 0.0624958 Vali Loss: 0.0588577 Test Loss: 0.0615097\n",
      "Validation loss decreased (0.060610 --> 0.058858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591928\n",
      "\tspeed: 0.2033s/iter; left time: 623.0883s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583320\n",
      "\tspeed: 0.1233s/iter; left time: 365.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 226 | Train Loss: 0.0614027 Vali Loss: 0.0586346 Test Loss: 0.0618780\n",
      "Validation loss decreased (0.058858 --> 0.058635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0588122\n",
      "\tspeed: 0.2059s/iter; left time: 584.6852s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603447\n",
      "\tspeed: 0.1233s/iter; left time: 337.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0605622 Vali Loss: 0.0581572 Test Loss: 0.0613240\n",
      "Validation loss decreased (0.058635 --> 0.058157).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627868\n",
      "\tspeed: 0.2067s/iter; left time: 540.1944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602490\n",
      "\tspeed: 0.1235s/iter; left time: 310.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.09s\n",
      "Steps: 226 | Train Loss: 0.0599007 Vali Loss: 0.0575575 Test Loss: 0.0602312\n",
      "Validation loss decreased (0.058157 --> 0.057558).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0568765\n",
      "\tspeed: 0.2092s/iter; left time: 499.3861s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624954\n",
      "\tspeed: 0.1240s/iter; left time: 283.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.0593471 Vali Loss: 0.0574005 Test Loss: 0.0601187\n",
      "Validation loss decreased (0.057558 --> 0.057400).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596192\n",
      "\tspeed: 0.2111s/iter; left time: 456.0823s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592127\n",
      "\tspeed: 0.1240s/iter; left time: 255.4822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 226 | Train Loss: 0.0590144 Vali Loss: 0.0572044 Test Loss: 0.0598468\n",
      "Validation loss decreased (0.057400 --> 0.057204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0615893\n",
      "\tspeed: 0.2488s/iter; left time: 481.3734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559695\n",
      "\tspeed: 0.1233s/iter; left time: 226.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 226 | Train Loss: 0.0584624 Vali Loss: 0.0569848 Test Loss: 0.0595079\n",
      "Validation loss decreased (0.057204 --> 0.056985).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0584085\n",
      "\tspeed: 0.2060s/iter; left time: 352.1014s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579237\n",
      "\tspeed: 0.1232s/iter; left time: 198.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 226 | Train Loss: 0.0582000 Vali Loss: 0.0570694 Test Loss: 0.0599025\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592260\n",
      "\tspeed: 0.2046s/iter; left time: 303.4499s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572892\n",
      "\tspeed: 0.1232s/iter; left time: 170.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0580283 Vali Loss: 0.0570102 Test Loss: 0.0598739\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0573419\n",
      "\tspeed: 0.2042s/iter; left time: 256.6187s\n",
      "\titers: 200, epoch: 15 | loss: 0.0580359\n",
      "\tspeed: 0.1232s/iter; left time: 142.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0577937 Vali Loss: 0.0566747 Test Loss: 0.0594992\n",
      "Validation loss decreased (0.056985 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0595963\n",
      "\tspeed: 0.2052s/iter; left time: 211.5397s\n",
      "\titers: 200, epoch: 16 | loss: 0.0581507\n",
      "\tspeed: 0.1232s/iter; left time: 114.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0575645 Vali Loss: 0.0563853 Test Loss: 0.0590242\n",
      "Validation loss decreased (0.056675 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537569\n",
      "\tspeed: 0.2030s/iter; left time: 163.3863s\n",
      "\titers: 200, epoch: 17 | loss: 0.0591558\n",
      "\tspeed: 0.1232s/iter; left time: 86.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0572866 Vali Loss: 0.0562514 Test Loss: 0.0589677\n",
      "Validation loss decreased (0.056385 --> 0.056251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0616697\n",
      "\tspeed: 0.2047s/iter; left time: 118.5172s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598275\n",
      "\tspeed: 0.1234s/iter; left time: 59.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0571565 Vali Loss: 0.0560796 Test Loss: 0.0589612\n",
      "Validation loss decreased (0.056251 --> 0.056080).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564034\n",
      "\tspeed: 0.2039s/iter; left time: 71.9723s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553540\n",
      "\tspeed: 0.1234s/iter; left time: 31.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0570096 Vali Loss: 0.0560311 Test Loss: 0.0588667\n",
      "Validation loss decreased (0.056080 --> 0.056031).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543480\n",
      "\tspeed: 0.2057s/iter; left time: 26.1271s\n",
      "\titers: 200, epoch: 20 | loss: 0.0582589\n",
      "\tspeed: 0.1231s/iter; left time: 3.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0568625 Vali Loss: 0.0558932 Test Loss: 0.0588943\n",
      "Validation loss decreased (0.056031 --> 0.055893).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010509154759347439, rmse:0.10251417011022568, mae:0.058894332498311996, rse:0.38735058903694153\n",
      "Intermediate time for IT and pred_len 24: 00h:22m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1246291\n",
      "\tspeed: 0.1502s/iter; left time: 661.2296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1170714\n",
      "\tspeed: 0.1238s/iter; left time: 532.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1307737 Vali Loss: 0.0961518 Test Loss: 0.0997427\n",
      "Validation loss decreased (inf --> 0.096152).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0948495\n",
      "\tspeed: 0.2148s/iter; left time: 896.9106s\n",
      "\titers: 200, epoch: 2 | loss: 0.0954342\n",
      "\tspeed: 0.1237s/iter; left time: 504.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0978327 Vali Loss: 0.0849951 Test Loss: 0.0893700\n",
      "Validation loss decreased (0.096152 --> 0.084995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0911742\n",
      "\tspeed: 0.2054s/iter; left time: 811.6634s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884128\n",
      "\tspeed: 0.1237s/iter; left time: 476.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0892406 Vali Loss: 0.0825536 Test Loss: 0.0875067\n",
      "Validation loss decreased (0.084995 --> 0.082554).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0867200\n",
      "\tspeed: 0.2058s/iter; left time: 766.8796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0846905\n",
      "\tspeed: 0.1239s/iter; left time: 449.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0855845 Vali Loss: 0.0808799 Test Loss: 0.0862431\n",
      "Validation loss decreased (0.082554 --> 0.080880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797206\n",
      "\tspeed: 0.2094s/iter; left time: 733.1353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888789\n",
      "\tspeed: 0.1238s/iter; left time: 421.2037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0834375 Vali Loss: 0.0790271 Test Loss: 0.0843552\n",
      "Validation loss decreased (0.080880 --> 0.079027).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0826562\n",
      "\tspeed: 0.2102s/iter; left time: 688.7716s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778374\n",
      "\tspeed: 0.1240s/iter; left time: 393.7166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0821521 Vali Loss: 0.0782054 Test Loss: 0.0836802\n",
      "Validation loss decreased (0.079027 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0799794\n",
      "\tspeed: 0.2217s/iter; left time: 676.3642s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788258\n",
      "\tspeed: 0.1239s/iter; left time: 365.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0813023 Vali Loss: 0.0782941 Test Loss: 0.0837826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789111\n",
      "\tspeed: 0.2070s/iter; left time: 585.0643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0816973\n",
      "\tspeed: 0.1240s/iter; left time: 338.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0806553 Vali Loss: 0.0778118 Test Loss: 0.0829287\n",
      "Validation loss decreased (0.078205 --> 0.077812).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0801560\n",
      "\tspeed: 0.2108s/iter; left time: 548.3920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835952\n",
      "\tspeed: 0.1246s/iter; left time: 311.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0801367 Vali Loss: 0.0776850 Test Loss: 0.0827472\n",
      "Validation loss decreased (0.077812 --> 0.077685).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809377\n",
      "\tspeed: 0.2122s/iter; left time: 504.1102s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785008\n",
      "\tspeed: 0.1244s/iter; left time: 283.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0797318 Vali Loss: 0.0775685 Test Loss: 0.0825838\n",
      "Validation loss decreased (0.077685 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773143\n",
      "\tspeed: 0.2090s/iter; left time: 449.5153s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786918\n",
      "\tspeed: 0.1238s/iter; left time: 253.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0793911 Vali Loss: 0.0773214 Test Loss: 0.0821988\n",
      "Validation loss decreased (0.077569 --> 0.077321).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0843383\n",
      "\tspeed: 0.2057s/iter; left time: 396.2053s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793643\n",
      "\tspeed: 0.1236s/iter; left time: 225.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0790657 Vali Loss: 0.0772528 Test Loss: 0.0820618\n",
      "Validation loss decreased (0.077321 --> 0.077253).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776302\n",
      "\tspeed: 0.2073s/iter; left time: 352.5856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800399\n",
      "\tspeed: 0.1238s/iter; left time: 198.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0787998 Vali Loss: 0.0769798 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.077253 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797844\n",
      "\tspeed: 0.2163s/iter; left time: 319.2716s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793766\n",
      "\tspeed: 0.1239s/iter; left time: 170.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0785462 Vali Loss: 0.0769688 Test Loss: 0.0817476\n",
      "Validation loss decreased (0.076980 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755080\n",
      "\tspeed: 0.2114s/iter; left time: 264.5179s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763225\n",
      "\tspeed: 0.1237s/iter; left time: 142.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0783976 Vali Loss: 0.0769022 Test Loss: 0.0815266\n",
      "Validation loss decreased (0.076969 --> 0.076902).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0759583\n",
      "\tspeed: 0.2252s/iter; left time: 231.1064s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809015\n",
      "\tspeed: 0.1237s/iter; left time: 114.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0782896 Vali Loss: 0.0767670 Test Loss: 0.0815434\n",
      "Validation loss decreased (0.076902 --> 0.076767).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807900\n",
      "\tspeed: 0.2069s/iter; left time: 165.7560s\n",
      "\titers: 200, epoch: 17 | loss: 0.0796471\n",
      "\tspeed: 0.1236s/iter; left time: 86.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0780911 Vali Loss: 0.0765583 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.076767 --> 0.076558).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750794\n",
      "\tspeed: 0.2082s/iter; left time: 119.9227s\n",
      "\titers: 200, epoch: 18 | loss: 0.0804618\n",
      "\tspeed: 0.1238s/iter; left time: 58.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0778818 Vali Loss: 0.0766912 Test Loss: 0.0816509\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737888\n",
      "\tspeed: 0.2070s/iter; left time: 72.6420s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769352\n",
      "\tspeed: 0.1236s/iter; left time: 31.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0777152 Vali Loss: 0.0764046 Test Loss: 0.0812570\n",
      "Validation loss decreased (0.076558 --> 0.076405).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0773344\n",
      "\tspeed: 0.2066s/iter; left time: 26.0332s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809498\n",
      "\tspeed: 0.1237s/iter; left time: 3.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0776153 Vali Loss: 0.0764732 Test Loss: 0.0810120\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018536528572440147, rmse:0.13614891469478607, mae:0.08125697821378708, rse:0.5147936940193176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1274510\n",
      "\tspeed: 0.1244s/iter; left time: 547.5407s\n",
      "\titers: 200, epoch: 1 | loss: 0.1164847\n",
      "\tspeed: 0.1235s/iter; left time: 531.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.1317651 Vali Loss: 0.0965845 Test Loss: 0.1001872\n",
      "Validation loss decreased (inf --> 0.096585).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0931384\n",
      "\tspeed: 0.2059s/iter; left time: 859.8003s\n",
      "\titers: 200, epoch: 2 | loss: 0.0937748\n",
      "\tspeed: 0.1237s/iter; left time: 504.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0983610 Vali Loss: 0.0854578 Test Loss: 0.0899371\n",
      "Validation loss decreased (0.096585 --> 0.085458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0879004\n",
      "\tspeed: 0.2064s/iter; left time: 815.6114s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821228\n",
      "\tspeed: 0.1238s/iter; left time: 476.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0891939 Vali Loss: 0.0823376 Test Loss: 0.0874421\n",
      "Validation loss decreased (0.085458 --> 0.082338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863800\n",
      "\tspeed: 0.2064s/iter; left time: 769.2313s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839542\n",
      "\tspeed: 0.1237s/iter; left time: 448.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0857099 Vali Loss: 0.0812594 Test Loss: 0.0861944\n",
      "Validation loss decreased (0.082338 --> 0.081259).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0866721\n",
      "\tspeed: 0.2086s/iter; left time: 730.2604s\n",
      "\titers: 200, epoch: 5 | loss: 0.0816669\n",
      "\tspeed: 0.1237s/iter; left time: 420.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0838621 Vali Loss: 0.0807487 Test Loss: 0.0857736\n",
      "Validation loss decreased (0.081259 --> 0.080749).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839811\n",
      "\tspeed: 0.2056s/iter; left time: 673.5906s\n",
      "\titers: 200, epoch: 6 | loss: 0.0856897\n",
      "\tspeed: 0.1236s/iter; left time: 392.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 225 | Train Loss: 0.0824806 Vali Loss: 0.0787402 Test Loss: 0.0840767\n",
      "Validation loss decreased (0.080749 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0824418\n",
      "\tspeed: 0.2073s/iter; left time: 632.4306s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837693\n",
      "\tspeed: 0.1236s/iter; left time: 364.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0817001 Vali Loss: 0.0782434 Test Loss: 0.0841690\n",
      "Validation loss decreased (0.078740 --> 0.078243).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798583\n",
      "\tspeed: 0.2053s/iter; left time: 580.1476s\n",
      "\titers: 200, epoch: 8 | loss: 0.0807079\n",
      "\tspeed: 0.1237s/iter; left time: 337.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0809182 Vali Loss: 0.0780490 Test Loss: 0.0831145\n",
      "Validation loss decreased (0.078243 --> 0.078049).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792143\n",
      "\tspeed: 0.2077s/iter; left time: 540.2567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885995\n",
      "\tspeed: 0.1240s/iter; left time: 310.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0805063 Vali Loss: 0.0778816 Test Loss: 0.0831148\n",
      "Validation loss decreased (0.078049 --> 0.077882).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0826082\n",
      "\tspeed: 0.2055s/iter; left time: 488.1716s\n",
      "\titers: 200, epoch: 10 | loss: 0.0805768\n",
      "\tspeed: 0.1239s/iter; left time: 282.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0798953 Vali Loss: 0.0776451 Test Loss: 0.0828241\n",
      "Validation loss decreased (0.077882 --> 0.077645).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783376\n",
      "\tspeed: 0.2062s/iter; left time: 443.5818s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749998\n",
      "\tspeed: 0.1243s/iter; left time: 254.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0794778 Vali Loss: 0.0775692 Test Loss: 0.0823288\n",
      "Validation loss decreased (0.077645 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794503\n",
      "\tspeed: 0.2062s/iter; left time: 397.2318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762411\n",
      "\tspeed: 0.1248s/iter; left time: 227.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0791353 Vali Loss: 0.0772091 Test Loss: 0.0826240\n",
      "Validation loss decreased (0.077569 --> 0.077209).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0795701\n",
      "\tspeed: 0.2074s/iter; left time: 352.7250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782318\n",
      "\tspeed: 0.1243s/iter; left time: 198.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0788803 Vali Loss: 0.0770195 Test Loss: 0.0825596\n",
      "Validation loss decreased (0.077209 --> 0.077020).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0823900\n",
      "\tspeed: 0.2073s/iter; left time: 305.9652s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794970\n",
      "\tspeed: 0.1244s/iter; left time: 171.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0786027 Vali Loss: 0.0769410 Test Loss: 0.0823892\n",
      "Validation loss decreased (0.077020 --> 0.076941).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766661\n",
      "\tspeed: 0.2087s/iter; left time: 261.0253s\n",
      "\titers: 200, epoch: 15 | loss: 0.0806809\n",
      "\tspeed: 0.1242s/iter; left time: 142.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.13s\n",
      "Steps: 225 | Train Loss: 0.0783255 Vali Loss: 0.0767500 Test Loss: 0.0819774\n",
      "Validation loss decreased (0.076941 --> 0.076750).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0756244\n",
      "\tspeed: 0.2075s/iter; left time: 212.9265s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810186\n",
      "\tspeed: 0.1237s/iter; left time: 114.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0781282 Vali Loss: 0.0768651 Test Loss: 0.0821056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807884\n",
      "\tspeed: 0.2031s/iter; left time: 162.7110s\n",
      "\titers: 200, epoch: 17 | loss: 0.0767048\n",
      "\tspeed: 0.1235s/iter; left time: 86.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.0778863 Vali Loss: 0.0768578 Test Loss: 0.0821329\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0774752\n",
      "\tspeed: 0.2075s/iter; left time: 119.5412s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812058\n",
      "\tspeed: 0.1238s/iter; left time: 58.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0777132 Vali Loss: 0.0766468 Test Loss: 0.0820385\n",
      "Validation loss decreased (0.076750 --> 0.076647).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0832625\n",
      "\tspeed: 0.2046s/iter; left time: 71.8297s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773597\n",
      "\tspeed: 0.1242s/iter; left time: 31.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0775751 Vali Loss: 0.0764721 Test Loss: 0.0817944\n",
      "Validation loss decreased (0.076647 --> 0.076472).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0786291\n",
      "\tspeed: 0.2056s/iter; left time: 25.9106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785749\n",
      "\tspeed: 0.1248s/iter; left time: 3.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0774495 Vali Loss: 0.0764009 Test Loss: 0.0816955\n",
      "Validation loss decreased (0.076472 --> 0.076401).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018820010125637054, rmse:0.13718603551387787, mae:0.08169551938772202, rse:0.5187152028083801\n",
      "Intermediate time for IT and pred_len 96: 00h:22m:26.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1274062\n",
      "\tspeed: 0.1487s/iter; left time: 654.5295s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201956\n",
      "\tspeed: 0.1255s/iter; left time: 539.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.1337667 Vali Loss: 0.0992412 Test Loss: 0.1025607\n",
      "Validation loss decreased (inf --> 0.099241).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0999286\n",
      "\tspeed: 0.2093s/iter; left time: 874.2423s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971880\n",
      "\tspeed: 0.1240s/iter; left time: 505.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.1026157 Vali Loss: 0.0904709 Test Loss: 0.0948137\n",
      "Validation loss decreased (0.099241 --> 0.090471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945068\n",
      "\tspeed: 0.2068s/iter; left time: 817.0345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920321\n",
      "\tspeed: 0.1240s/iter; left time: 477.4222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0944772 Vali Loss: 0.0859233 Test Loss: 0.0916047\n",
      "Validation loss decreased (0.090471 --> 0.085923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0924504\n",
      "\tspeed: 0.2065s/iter; left time: 769.5238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887412\n",
      "\tspeed: 0.1243s/iter; left time: 450.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.12s\n",
      "Steps: 225 | Train Loss: 0.0908827 Vali Loss: 0.0868275 Test Loss: 0.0906128\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887746\n",
      "\tspeed: 0.2071s/iter; left time: 724.9291s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888827\n",
      "\tspeed: 0.1252s/iter; left time: 425.7346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0887758 Vali Loss: 0.0842572 Test Loss: 0.0898299\n",
      "Validation loss decreased (0.085923 --> 0.084257).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897459\n",
      "\tspeed: 0.2071s/iter; left time: 678.5198s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841771\n",
      "\tspeed: 0.1247s/iter; left time: 396.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.21s\n",
      "Steps: 225 | Train Loss: 0.0874938 Vali Loss: 0.0833510 Test Loss: 0.0876509\n",
      "Validation loss decreased (0.084257 --> 0.083351).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0841005\n",
      "\tspeed: 0.2065s/iter; left time: 629.8886s\n",
      "\titers: 200, epoch: 7 | loss: 0.0883561\n",
      "\tspeed: 0.1246s/iter; left time: 367.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0864298 Vali Loss: 0.0829024 Test Loss: 0.0872512\n",
      "Validation loss decreased (0.083351 --> 0.082902).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0864878\n",
      "\tspeed: 0.2065s/iter; left time: 583.5700s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836292\n",
      "\tspeed: 0.1244s/iter; left time: 339.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0858088 Vali Loss: 0.0824455 Test Loss: 0.0869225\n",
      "Validation loss decreased (0.082902 --> 0.082446).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0883054\n",
      "\tspeed: 0.2067s/iter; left time: 537.6703s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835050\n",
      "\tspeed: 0.1243s/iter; left time: 310.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0852685 Vali Loss: 0.0827654 Test Loss: 0.0869103\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833669\n",
      "\tspeed: 0.2058s/iter; left time: 489.0270s\n",
      "\titers: 200, epoch: 10 | loss: 0.0865522\n",
      "\tspeed: 0.1248s/iter; left time: 283.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0848592 Vali Loss: 0.0819396 Test Loss: 0.0861626\n",
      "Validation loss decreased (0.082446 --> 0.081940).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0845838\n",
      "\tspeed: 0.2060s/iter; left time: 443.1676s\n",
      "\titers: 200, epoch: 11 | loss: 0.0861566\n",
      "\tspeed: 0.1244s/iter; left time: 255.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0845001 Vali Loss: 0.0820744 Test Loss: 0.0859507\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0851333\n",
      "\tspeed: 0.2081s/iter; left time: 400.7558s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838776\n",
      "\tspeed: 0.1247s/iter; left time: 227.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0842150 Vali Loss: 0.0822200 Test Loss: 0.0856628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0833532\n",
      "\tspeed: 0.2085s/iter; left time: 354.6808s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793798\n",
      "\tspeed: 0.1250s/iter; left time: 200.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0838517 Vali Loss: 0.0816093 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.081940 --> 0.081609).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0838834\n",
      "\tspeed: 0.2074s/iter; left time: 306.1636s\n",
      "\titers: 200, epoch: 14 | loss: 0.0833073\n",
      "\tspeed: 0.1246s/iter; left time: 171.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0836320 Vali Loss: 0.0817205 Test Loss: 0.0854512\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0802528\n",
      "\tspeed: 0.2063s/iter; left time: 258.0424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804740\n",
      "\tspeed: 0.1245s/iter; left time: 143.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0834320 Vali Loss: 0.0816327 Test Loss: 0.0855313\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829816\n",
      "\tspeed: 0.2053s/iter; left time: 210.6108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0838366\n",
      "\tspeed: 0.1250s/iter; left time: 115.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0831726 Vali Loss: 0.0816667 Test Loss: 0.0854638\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814890\n",
      "\tspeed: 0.2073s/iter; left time: 166.0414s\n",
      "\titers: 200, epoch: 17 | loss: 0.0822350\n",
      "\tspeed: 0.1256s/iter; left time: 88.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 225 | Train Loss: 0.0829919 Vali Loss: 0.0820202 Test Loss: 0.0856585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839811\n",
      "\tspeed: 0.2077s/iter; left time: 119.6551s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843205\n",
      "\tspeed: 0.1256s/iter; left time: 59.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0828663 Vali Loss: 0.0817814 Test Loss: 0.0856330\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0196785070002079, rmse:0.1402800977230072, mae:0.08546759188175201, rse:0.5309070944786072\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1252874\n",
      "\tspeed: 0.1258s/iter; left time: 553.5807s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240589\n",
      "\tspeed: 0.1251s/iter; left time: 537.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.1343383 Vali Loss: 0.0994309 Test Loss: 0.1027002\n",
      "Validation loss decreased (inf --> 0.099431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1012369\n",
      "\tspeed: 0.2111s/iter; left time: 881.4227s\n",
      "\titers: 200, epoch: 2 | loss: 0.0978683\n",
      "\tspeed: 0.1247s/iter; left time: 508.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1025567 Vali Loss: 0.0899358 Test Loss: 0.0946148\n",
      "Validation loss decreased (0.099431 --> 0.089936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0953144\n",
      "\tspeed: 0.2091s/iter; left time: 825.9906s\n",
      "\titers: 200, epoch: 3 | loss: 0.0942210\n",
      "\tspeed: 0.1250s/iter; left time: 481.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0939962 Vali Loss: 0.0862187 Test Loss: 0.0924182\n",
      "Validation loss decreased (0.089936 --> 0.086219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886576\n",
      "\tspeed: 0.2070s/iter; left time: 771.3484s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866066\n",
      "\tspeed: 0.1250s/iter; left time: 453.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0907466 Vali Loss: 0.0852378 Test Loss: 0.0902182\n",
      "Validation loss decreased (0.086219 --> 0.085238).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0886593\n",
      "\tspeed: 0.2072s/iter; left time: 725.5006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915526\n",
      "\tspeed: 0.1247s/iter; left time: 424.1730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0887809 Vali Loss: 0.0845530 Test Loss: 0.0897828\n",
      "Validation loss decreased (0.085238 --> 0.084553).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0855750\n",
      "\tspeed: 0.2105s/iter; left time: 689.7385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0881630\n",
      "\tspeed: 0.1254s/iter; left time: 398.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.0876069 Vali Loss: 0.0839415 Test Loss: 0.0886852\n",
      "Validation loss decreased (0.084553 --> 0.083941).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855649\n",
      "\tspeed: 0.2094s/iter; left time: 638.9149s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861583\n",
      "\tspeed: 0.1251s/iter; left time: 369.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0867376 Vali Loss: 0.0830761 Test Loss: 0.0885835\n",
      "Validation loss decreased (0.083941 --> 0.083076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0900731\n",
      "\tspeed: 0.2115s/iter; left time: 597.7728s\n",
      "\titers: 200, epoch: 8 | loss: 0.0837901\n",
      "\tspeed: 0.1249s/iter; left time: 340.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0862249 Vali Loss: 0.0828923 Test Loss: 0.0886307\n",
      "Validation loss decreased (0.083076 --> 0.082892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0850363\n",
      "\tspeed: 0.2107s/iter; left time: 548.1492s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847476\n",
      "\tspeed: 0.1255s/iter; left time: 313.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0856819 Vali Loss: 0.0822114 Test Loss: 0.0875634\n",
      "Validation loss decreased (0.082892 --> 0.082211).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865811\n",
      "\tspeed: 0.2078s/iter; left time: 493.7087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0885911\n",
      "\tspeed: 0.1250s/iter; left time: 284.5643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0852687 Vali Loss: 0.0822291 Test Loss: 0.0871013\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0820281\n",
      "\tspeed: 0.2088s/iter; left time: 449.0294s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828203\n",
      "\tspeed: 0.1248s/iter; left time: 255.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0847809 Vali Loss: 0.0817572 Test Loss: 0.0870292\n",
      "Validation loss decreased (0.082211 --> 0.081757).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821820\n",
      "\tspeed: 0.2064s/iter; left time: 397.4723s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837839\n",
      "\tspeed: 0.1249s/iter; left time: 228.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0845500 Vali Loss: 0.0819127 Test Loss: 0.0866175\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802262\n",
      "\tspeed: 0.2076s/iter; left time: 353.1202s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826065\n",
      "\tspeed: 0.1251s/iter; left time: 200.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 225 | Train Loss: 0.0842274 Vali Loss: 0.0817468 Test Loss: 0.0864959\n",
      "Validation loss decreased (0.081757 --> 0.081747).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841475\n",
      "\tspeed: 0.2083s/iter; left time: 307.4843s\n",
      "\titers: 200, epoch: 14 | loss: 0.0823566\n",
      "\tspeed: 0.1249s/iter; left time: 171.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0840051 Vali Loss: 0.0814703 Test Loss: 0.0864162\n",
      "Validation loss decreased (0.081747 --> 0.081470).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0832792\n",
      "\tspeed: 0.2078s/iter; left time: 259.9452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0832064\n",
      "\tspeed: 0.1246s/iter; left time: 143.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0837586 Vali Loss: 0.0815400 Test Loss: 0.0859518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0816924\n",
      "\tspeed: 0.2051s/iter; left time: 210.4502s\n",
      "\titers: 200, epoch: 16 | loss: 0.0879495\n",
      "\tspeed: 0.1248s/iter; left time: 115.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 225 | Train Loss: 0.0834792 Vali Loss: 0.0814463 Test Loss: 0.0862716\n",
      "Validation loss decreased (0.081470 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814074\n",
      "\tspeed: 0.2072s/iter; left time: 165.9816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830946\n",
      "\tspeed: 0.1248s/iter; left time: 87.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.27s\n",
      "Steps: 225 | Train Loss: 0.0833982 Vali Loss: 0.0813847 Test Loss: 0.0859058\n",
      "Validation loss decreased (0.081446 --> 0.081385).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0828545\n",
      "\tspeed: 0.2064s/iter; left time: 118.8758s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824811\n",
      "\tspeed: 0.1247s/iter; left time: 59.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0832192 Vali Loss: 0.0813554 Test Loss: 0.0859548\n",
      "Validation loss decreased (0.081385 --> 0.081355).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0864082\n",
      "\tspeed: 0.2073s/iter; left time: 72.7458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0809942\n",
      "\tspeed: 0.1252s/iter; left time: 31.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.0830247 Vali Loss: 0.0809955 Test Loss: 0.0858491\n",
      "Validation loss decreased (0.081355 --> 0.080996).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0841437\n",
      "\tspeed: 0.2081s/iter; left time: 26.2232s\n",
      "\titers: 200, epoch: 20 | loss: 0.0797103\n",
      "\tspeed: 0.1254s/iter; left time: 3.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 225 | Train Loss: 0.0828929 Vali Loss: 0.0811498 Test Loss: 0.0856923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020069275051355362, rmse:0.14166606962680817, mae:0.08584906160831451, rse:0.5361524224281311\n",
      "Intermediate time for IT and pred_len 168: 00h:21m:19.68s\n",
      "Intermediate time for IT: 01h:06m:01.95s\n",
      "Total time: 02h:17m:45.04s\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            if seq_len == 512:\n",
    "                batch_size = 64\n",
    "            else:\n",
    "                batch_size = 128\n",
    "                \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"no_patching_{country}_data.csv\"\n",
    "\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0365  0.1910  0.1267\n",
       "        168       0.0384  0.1959  0.1325\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1037  0.0574\n",
       "        96        0.0201  0.1418  0.0822\n",
       "        168       0.0219  0.1478  0.0877\n",
       "GB      24        0.0263  0.1621  0.1036\n",
       "        96        0.0425  0.2061  0.1391\n",
       "        168       0.0442  0.2102  0.1445\n",
       "IT      24        0.0104  0.1021  0.0587\n",
       "        96        0.0187  0.1367  0.0815\n",
       "        168       0.0199  0.1410  0.0857"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0342353\n",
      "\tspeed: 0.0875s/iter; left time: 1951.0187s\n",
      "\titers: 200, epoch: 1 | loss: 0.0304398\n",
      "\tspeed: 0.0618s/iter; left time: 1372.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0356280 Vali Loss: 0.0356127 Test Loss: 0.0406857\n",
      "Validation loss decreased (inf --> 0.035613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0179059\n",
      "\tspeed: 0.1114s/iter; left time: 2459.5113s\n",
      "\titers: 200, epoch: 2 | loss: 0.0135274\n",
      "\tspeed: 0.0630s/iter; left time: 1383.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.37s\n",
      "Steps: 224 | Train Loss: 0.0187015 Vali Loss: 0.0215971 Test Loss: 0.0227938\n",
      "Validation loss decreased (0.035613 --> 0.021597).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0148644\n",
      "\tspeed: 0.1129s/iter; left time: 2466.2664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0162312\n",
      "\tspeed: 0.0628s/iter; left time: 1366.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0148318 Vali Loss: 0.0204003 Test Loss: 0.0219423\n",
      "Validation loss decreased (0.021597 --> 0.020400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121506\n",
      "\tspeed: 0.1104s/iter; left time: 2388.4875s\n",
      "\titers: 200, epoch: 4 | loss: 0.0147986\n",
      "\tspeed: 0.0632s/iter; left time: 1359.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.44s\n",
      "Steps: 224 | Train Loss: 0.0139572 Vali Loss: 0.0199230 Test Loss: 0.0216934\n",
      "Validation loss decreased (0.020400 --> 0.019923).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0116898\n",
      "\tspeed: 0.1120s/iter; left time: 2397.2212s\n",
      "\titers: 200, epoch: 5 | loss: 0.0124843\n",
      "\tspeed: 0.0630s/iter; left time: 1342.0438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.36s\n",
      "Steps: 224 | Train Loss: 0.0134950 Vali Loss: 0.0196710 Test Loss: 0.0212247\n",
      "Validation loss decreased (0.019923 --> 0.019671).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0135639\n",
      "\tspeed: 0.1095s/iter; left time: 2319.4150s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130063\n",
      "\tspeed: 0.0628s/iter; left time: 1324.2545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.36s\n",
      "Steps: 224 | Train Loss: 0.0132071 Vali Loss: 0.0192792 Test Loss: 0.0209840\n",
      "Validation loss decreased (0.019671 --> 0.019279).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0141211\n",
      "\tspeed: 0.1085s/iter; left time: 2273.2786s\n",
      "\titers: 200, epoch: 7 | loss: 0.0116548\n",
      "\tspeed: 0.0627s/iter; left time: 1308.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.29s\n",
      "Steps: 224 | Train Loss: 0.0129709 Vali Loss: 0.0193609 Test Loss: 0.0209007\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0129743\n",
      "\tspeed: 0.1084s/iter; left time: 2247.8515s\n",
      "\titers: 200, epoch: 8 | loss: 0.0115174\n",
      "\tspeed: 0.0633s/iter; left time: 1305.8803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.43s\n",
      "Steps: 224 | Train Loss: 0.0128204 Vali Loss: 0.0192315 Test Loss: 0.0208219\n",
      "Validation loss decreased (0.019279 --> 0.019232).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0134222\n",
      "\tspeed: 0.1124s/iter; left time: 2305.9778s\n",
      "\titers: 200, epoch: 9 | loss: 0.0132380\n",
      "\tspeed: 0.0634s/iter; left time: 1294.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.53s\n",
      "Steps: 224 | Train Loss: 0.0126810 Vali Loss: 0.0192015 Test Loss: 0.0211539\n",
      "Validation loss decreased (0.019232 --> 0.019202).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0108680\n",
      "\tspeed: 0.1102s/iter; left time: 2236.0371s\n",
      "\titers: 200, epoch: 10 | loss: 0.0109287\n",
      "\tspeed: 0.0635s/iter; left time: 1282.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0125709 Vali Loss: 0.0191250 Test Loss: 0.0208791\n",
      "Validation loss decreased (0.019202 --> 0.019125).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0126151\n",
      "\tspeed: 0.1120s/iter; left time: 2246.5155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0139635\n",
      "\tspeed: 0.0638s/iter; left time: 1273.2486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.43s\n",
      "Steps: 224 | Train Loss: 0.0124538 Vali Loss: 0.0192444 Test Loss: 0.0211788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0123928\n",
      "\tspeed: 0.1112s/iter; left time: 2205.8436s\n",
      "\titers: 200, epoch: 12 | loss: 0.0122462\n",
      "\tspeed: 0.0638s/iter; left time: 1258.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.56s\n",
      "Steps: 224 | Train Loss: 0.0123468 Vali Loss: 0.0192646 Test Loss: 0.0211260\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0111625\n",
      "\tspeed: 0.1107s/iter; left time: 2171.8415s\n",
      "\titers: 200, epoch: 13 | loss: 0.0118241\n",
      "\tspeed: 0.0641s/iter; left time: 1250.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.56s\n",
      "Steps: 224 | Train Loss: 0.0122662 Vali Loss: 0.0191742 Test Loss: 0.0211097\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0132771\n",
      "\tspeed: 0.1109s/iter; left time: 2151.1249s\n",
      "\titers: 200, epoch: 14 | loss: 0.0119486\n",
      "\tspeed: 0.0637s/iter; left time: 1229.0054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0121801 Vali Loss: 0.0190875 Test Loss: 0.0211803\n",
      "Validation loss decreased (0.019125 --> 0.019087).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0123984\n",
      "\tspeed: 0.1157s/iter; left time: 2217.3631s\n",
      "\titers: 200, epoch: 15 | loss: 0.0115990\n",
      "\tspeed: 0.0638s/iter; left time: 1215.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.57s\n",
      "Steps: 224 | Train Loss: 0.0121082 Vali Loss: 0.0191473 Test Loss: 0.0212391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0115731\n",
      "\tspeed: 0.1112s/iter; left time: 2106.0669s\n",
      "\titers: 200, epoch: 16 | loss: 0.0125065\n",
      "\tspeed: 0.0652s/iter; left time: 1227.7069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.70s\n",
      "Steps: 224 | Train Loss: 0.0120519 Vali Loss: 0.0192114 Test Loss: 0.0213595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0110334\n",
      "\tspeed: 0.1106s/iter; left time: 2069.9099s\n",
      "\titers: 200, epoch: 17 | loss: 0.0110572\n",
      "\tspeed: 0.0635s/iter; left time: 1182.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.49s\n",
      "Steps: 224 | Train Loss: 0.0119854 Vali Loss: 0.0193127 Test Loss: 0.0214091\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0123837\n",
      "\tspeed: 0.1117s/iter; left time: 2066.0553s\n",
      "\titers: 200, epoch: 18 | loss: 0.0115255\n",
      "\tspeed: 0.0644s/iter; left time: 1184.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:14.61s\n",
      "Steps: 224 | Train Loss: 0.0119524 Vali Loss: 0.0191424 Test Loss: 0.0212978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0113844\n",
      "\tspeed: 0.1099s/iter; left time: 2008.6306s\n",
      "\titers: 200, epoch: 19 | loss: 0.0117555\n",
      "\tspeed: 0.0638s/iter; left time: 1159.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.63s\n",
      "Steps: 224 | Train Loss: 0.0118991 Vali Loss: 0.0192516 Test Loss: 0.0213730\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0127686\n",
      "\tspeed: 0.1115s/iter; left time: 2012.8534s\n",
      "\titers: 200, epoch: 20 | loss: 0.0118836\n",
      "\tspeed: 0.0639s/iter; left time: 1147.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.58s\n",
      "Steps: 224 | Train Loss: 0.0118611 Vali Loss: 0.0191543 Test Loss: 0.0214134\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0097760\n",
      "\tspeed: 0.1114s/iter; left time: 1985.9934s\n",
      "\titers: 200, epoch: 21 | loss: 0.0125828\n",
      "\tspeed: 0.0641s/iter; left time: 1135.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:14.61s\n",
      "Steps: 224 | Train Loss: 0.0118073 Vali Loss: 0.0191751 Test Loss: 0.0214195\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0113530\n",
      "\tspeed: 0.1122s/iter; left time: 1973.5368s\n",
      "\titers: 200, epoch: 22 | loss: 0.0117535\n",
      "\tspeed: 0.0636s/iter; left time: 1113.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.56s\n",
      "Steps: 224 | Train Loss: 0.0117912 Vali Loss: 0.0192292 Test Loss: 0.0214898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0110555\n",
      "\tspeed: 0.1091s/iter; left time: 1895.0070s\n",
      "\titers: 200, epoch: 23 | loss: 0.0123274\n",
      "\tspeed: 0.0634s/iter; left time: 1094.9417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0117476 Vali Loss: 0.0191604 Test Loss: 0.0214992\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0120264\n",
      "\tspeed: 0.1116s/iter; left time: 1914.6195s\n",
      "\titers: 200, epoch: 24 | loss: 0.0109771\n",
      "\tspeed: 0.0640s/iter; left time: 1090.7186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:14.54s\n",
      "Steps: 224 | Train Loss: 0.0117202 Vali Loss: 0.0192950 Test Loss: 0.0215327\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021180348470807076, rmse:0.1455346941947937, mae:0.09210523962974548, rse:0.5136120915412903\n",
      "Intermediate time for DE and pred_len 24: 00h:07m:08.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0329614\n",
      "\tspeed: 0.1213s/iter; left time: 2680.9766s\n",
      "\titers: 200, epoch: 1 | loss: 0.0342793\n",
      "\tspeed: 0.0949s/iter; left time: 2086.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.45s\n",
      "Steps: 222 | Train Loss: 0.0381722 Vali Loss: 0.0400321 Test Loss: 0.0464097\n",
      "Validation loss decreased (inf --> 0.040032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0249408\n",
      "\tspeed: 0.1614s/iter; left time: 3531.9715s\n",
      "\titers: 200, epoch: 2 | loss: 0.0245128\n",
      "\tspeed: 0.0944s/iter; left time: 2056.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.23s\n",
      "Steps: 222 | Train Loss: 0.0261842 Vali Loss: 0.0313152 Test Loss: 0.0355902\n",
      "Validation loss decreased (0.040032 --> 0.031315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0225981\n",
      "\tspeed: 0.1578s/iter; left time: 3417.5223s\n",
      "\titers: 200, epoch: 3 | loss: 0.0215500\n",
      "\tspeed: 0.0940s/iter; left time: 2025.6781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.10s\n",
      "Steps: 222 | Train Loss: 0.0230212 Vali Loss: 0.0305828 Test Loss: 0.0352640\n",
      "Validation loss decreased (0.031315 --> 0.030583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0212214\n",
      "\tspeed: 0.1620s/iter; left time: 3471.6207s\n",
      "\titers: 200, epoch: 4 | loss: 0.0241675\n",
      "\tspeed: 0.0944s/iter; left time: 2014.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 222 | Train Loss: 0.0220573 Vali Loss: 0.0304505 Test Loss: 0.0349720\n",
      "Validation loss decreased (0.030583 --> 0.030451).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0187968\n",
      "\tspeed: 0.1613s/iter; left time: 3422.6666s\n",
      "\titers: 200, epoch: 5 | loss: 0.0215125\n",
      "\tspeed: 0.0942s/iter; left time: 1987.9876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.20s\n",
      "Steps: 222 | Train Loss: 0.0213611 Vali Loss: 0.0311286 Test Loss: 0.0353292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0202346\n",
      "\tspeed: 0.1588s/iter; left time: 3332.3294s\n",
      "\titers: 200, epoch: 6 | loss: 0.0217038\n",
      "\tspeed: 0.0944s/iter; left time: 1972.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.24s\n",
      "Steps: 222 | Train Loss: 0.0207145 Vali Loss: 0.0309714 Test Loss: 0.0360050\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0223751\n",
      "\tspeed: 0.1604s/iter; left time: 3330.5451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0199960\n",
      "\tspeed: 0.0948s/iter; left time: 1959.6509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.25s\n",
      "Steps: 222 | Train Loss: 0.0200865 Vali Loss: 0.0310773 Test Loss: 0.0356274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0195899\n",
      "\tspeed: 0.1595s/iter; left time: 3276.6289s\n",
      "\titers: 200, epoch: 8 | loss: 0.0178804\n",
      "\tspeed: 0.0943s/iter; left time: 1927.8601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.25s\n",
      "Steps: 222 | Train Loss: 0.0194329 Vali Loss: 0.0313896 Test Loss: 0.0364243\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0182610\n",
      "\tspeed: 0.1606s/iter; left time: 3263.5594s\n",
      "\titers: 200, epoch: 9 | loss: 0.0171852\n",
      "\tspeed: 0.0946s/iter; left time: 1914.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.26s\n",
      "Steps: 222 | Train Loss: 0.0188398 Vali Loss: 0.0320143 Test Loss: 0.0369441\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0178833\n",
      "\tspeed: 0.1603s/iter; left time: 3221.5580s\n",
      "\titers: 200, epoch: 10 | loss: 0.0183828\n",
      "\tspeed: 0.0950s/iter; left time: 1900.2688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:21.33s\n",
      "Steps: 222 | Train Loss: 0.0182868 Vali Loss: 0.0323330 Test Loss: 0.0375362\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0170726\n",
      "\tspeed: 0.1632s/iter; left time: 3243.9193s\n",
      "\titers: 200, epoch: 11 | loss: 0.0171561\n",
      "\tspeed: 0.0953s/iter; left time: 1884.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.46s\n",
      "Steps: 222 | Train Loss: 0.0178131 Vali Loss: 0.0325162 Test Loss: 0.0381181\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0156059\n",
      "\tspeed: 0.1617s/iter; left time: 3179.5853s\n",
      "\titers: 200, epoch: 12 | loss: 0.0171956\n",
      "\tspeed: 0.0953s/iter; left time: 1863.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:21.40s\n",
      "Steps: 222 | Train Loss: 0.0173819 Vali Loss: 0.0327625 Test Loss: 0.0383074\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0168562\n",
      "\tspeed: 0.1614s/iter; left time: 3137.0094s\n",
      "\titers: 200, epoch: 13 | loss: 0.0168701\n",
      "\tspeed: 0.0947s/iter; left time: 1831.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.31s\n",
      "Steps: 222 | Train Loss: 0.0170281 Vali Loss: 0.0330074 Test Loss: 0.0384945\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0171931\n",
      "\tspeed: 0.1631s/iter; left time: 3134.3682s\n",
      "\titers: 200, epoch: 14 | loss: 0.0163787\n",
      "\tspeed: 0.0953s/iter; left time: 1820.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:21.39s\n",
      "Steps: 222 | Train Loss: 0.0167069 Vali Loss: 0.0334165 Test Loss: 0.0390635\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.034971993416547775, rmse:0.18700800836086273, mae:0.12845256924629211, rse:0.6622331142425537\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:10.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0387041\n",
      "\tspeed: 0.1213s/iter; left time: 2679.9432s\n",
      "\titers: 200, epoch: 1 | loss: 0.0367387\n",
      "\tspeed: 0.0964s/iter; left time: 2120.7095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.66s\n",
      "Steps: 222 | Train Loss: 0.0390411 Vali Loss: 0.0407392 Test Loss: 0.0477720\n",
      "Validation loss decreased (inf --> 0.040739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0273303\n",
      "\tspeed: 0.1638s/iter; left time: 3583.8035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0257967\n",
      "\tspeed: 0.0945s/iter; left time: 2058.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.38s\n",
      "Steps: 222 | Train Loss: 0.0279824 Vali Loss: 0.0323106 Test Loss: 0.0378376\n",
      "Validation loss decreased (0.040739 --> 0.032311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0235256\n",
      "\tspeed: 0.1632s/iter; left time: 3535.3571s\n",
      "\titers: 200, epoch: 3 | loss: 0.0260652\n",
      "\tspeed: 0.0941s/iter; left time: 2029.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.27s\n",
      "Steps: 222 | Train Loss: 0.0248956 Vali Loss: 0.0316980 Test Loss: 0.0376379\n",
      "Validation loss decreased (0.032311 --> 0.031698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0228928\n",
      "\tspeed: 0.1589s/iter; left time: 3406.7093s\n",
      "\titers: 200, epoch: 4 | loss: 0.0260297\n",
      "\tspeed: 0.0950s/iter; left time: 2027.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.28s\n",
      "Steps: 222 | Train Loss: 0.0238866 Vali Loss: 0.0318940 Test Loss: 0.0372975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0237687\n",
      "\tspeed: 0.1578s/iter; left time: 3348.4405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0254924\n",
      "\tspeed: 0.0949s/iter; left time: 2003.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.30s\n",
      "Steps: 222 | Train Loss: 0.0230829 Vali Loss: 0.0317468 Test Loss: 0.0378864\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0225530\n",
      "\tspeed: 0.1620s/iter; left time: 3401.5602s\n",
      "\titers: 200, epoch: 6 | loss: 0.0233173\n",
      "\tspeed: 0.0952s/iter; left time: 1987.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.30s\n",
      "Steps: 222 | Train Loss: 0.0221907 Vali Loss: 0.0318182 Test Loss: 0.0383376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0209551\n",
      "\tspeed: 0.1603s/iter; left time: 3329.7252s\n",
      "\titers: 200, epoch: 7 | loss: 0.0204426\n",
      "\tspeed: 0.0950s/iter; left time: 1963.5442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.24s\n",
      "Steps: 222 | Train Loss: 0.0211809 Vali Loss: 0.0325979 Test Loss: 0.0391831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0211203\n",
      "\tspeed: 0.1613s/iter; left time: 3314.2004s\n",
      "\titers: 200, epoch: 8 | loss: 0.0213128\n",
      "\tspeed: 0.0948s/iter; left time: 1937.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.41s\n",
      "Steps: 222 | Train Loss: 0.0202974 Vali Loss: 0.0333517 Test Loss: 0.0402545\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0202783\n",
      "\tspeed: 0.1631s/iter; left time: 3315.4430s\n",
      "\titers: 200, epoch: 9 | loss: 0.0192422\n",
      "\tspeed: 0.0945s/iter; left time: 1911.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.30s\n",
      "Steps: 222 | Train Loss: 0.0195137 Vali Loss: 0.0340254 Test Loss: 0.0407766\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0180906\n",
      "\tspeed: 0.1604s/iter; left time: 3224.9205s\n",
      "\titers: 200, epoch: 10 | loss: 0.0189156\n",
      "\tspeed: 0.0942s/iter; left time: 1883.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:21.09s\n",
      "Steps: 222 | Train Loss: 0.0189293 Vali Loss: 0.0339762 Test Loss: 0.0416852\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0176849\n",
      "\tspeed: 0.1581s/iter; left time: 3142.5310s\n",
      "\titers: 200, epoch: 11 | loss: 0.0179650\n",
      "\tspeed: 0.0945s/iter; left time: 1869.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.17s\n",
      "Steps: 222 | Train Loss: 0.0184033 Vali Loss: 0.0344821 Test Loss: 0.0417360\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0175864\n",
      "\tspeed: 0.1630s/iter; left time: 3203.7566s\n",
      "\titers: 200, epoch: 12 | loss: 0.0180063\n",
      "\tspeed: 0.0946s/iter; left time: 1850.4636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:21.37s\n",
      "Steps: 222 | Train Loss: 0.0179364 Vali Loss: 0.0349451 Test Loss: 0.0421477\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0161562\n",
      "\tspeed: 0.1632s/iter; left time: 3171.1706s\n",
      "\titers: 200, epoch: 13 | loss: 0.0181546\n",
      "\tspeed: 0.0940s/iter; left time: 1818.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.24s\n",
      "Steps: 222 | Train Loss: 0.0175793 Vali Loss: 0.0348888 Test Loss: 0.0427010\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0376378670334816, rmse:0.1940048187971115, mae:0.1373552680015564, rse:0.6871806383132935\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:44.64s\n",
      "Intermediate time for DE: 00h:19m:03.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0285861\n",
      "\tspeed: 0.1186s/iter; left time: 2632.2587s\n",
      "\titers: 200, epoch: 1 | loss: 0.0235957\n",
      "\tspeed: 0.0931s/iter; left time: 2057.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.13s\n",
      "Steps: 223 | Train Loss: 0.0289108 Vali Loss: 0.0299576 Test Loss: 0.0402119\n",
      "Validation loss decreased (inf --> 0.029958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0168490\n",
      "\tspeed: 0.1604s/iter; left time: 3525.4887s\n",
      "\titers: 200, epoch: 2 | loss: 0.0150211\n",
      "\tspeed: 0.0940s/iter; left time: 2056.8890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.25s\n",
      "Steps: 223 | Train Loss: 0.0165758 Vali Loss: 0.0201012 Test Loss: 0.0257371\n",
      "Validation loss decreased (0.029958 --> 0.020101).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0147975\n",
      "\tspeed: 0.1611s/iter; left time: 3505.2665s\n",
      "\titers: 200, epoch: 3 | loss: 0.0114877\n",
      "\tspeed: 0.0931s/iter; left time: 2015.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.13s\n",
      "Steps: 223 | Train Loss: 0.0138311 Vali Loss: 0.0197572 Test Loss: 0.0254458\n",
      "Validation loss decreased (0.020101 --> 0.019757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0134558\n",
      "\tspeed: 0.1611s/iter; left time: 3469.0041s\n",
      "\titers: 200, epoch: 4 | loss: 0.0130610\n",
      "\tspeed: 0.0934s/iter; left time: 2001.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 223 | Train Loss: 0.0133422 Vali Loss: 0.0194035 Test Loss: 0.0254630\n",
      "Validation loss decreased (0.019757 --> 0.019404).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0139561\n",
      "\tspeed: 0.1598s/iter; left time: 3406.2267s\n",
      "\titers: 200, epoch: 5 | loss: 0.0122184\n",
      "\tspeed: 0.0938s/iter; left time: 1989.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 223 | Train Loss: 0.0130661 Vali Loss: 0.0194117 Test Loss: 0.0254777\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0131640\n",
      "\tspeed: 0.1569s/iter; left time: 3308.6907s\n",
      "\titers: 200, epoch: 6 | loss: 0.0126009\n",
      "\tspeed: 0.0938s/iter; left time: 1967.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 223 | Train Loss: 0.0128580 Vali Loss: 0.0194458 Test Loss: 0.0255027\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0120277\n",
      "\tspeed: 0.1564s/iter; left time: 3263.0627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0128480\n",
      "\tspeed: 0.0935s/iter; left time: 1940.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.00s\n",
      "Steps: 223 | Train Loss: 0.0127017 Vali Loss: 0.0192531 Test Loss: 0.0253398\n",
      "Validation loss decreased (0.019404 --> 0.019253).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132955\n",
      "\tspeed: 0.1594s/iter; left time: 3289.2630s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110742\n",
      "\tspeed: 0.0939s/iter; left time: 1929.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.25s\n",
      "Steps: 223 | Train Loss: 0.0125261 Vali Loss: 0.0192209 Test Loss: 0.0253723\n",
      "Validation loss decreased (0.019253 --> 0.019221).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0118963\n",
      "\tspeed: 0.1573s/iter; left time: 3211.4671s\n",
      "\titers: 200, epoch: 9 | loss: 0.0144243\n",
      "\tspeed: 0.0933s/iter; left time: 1896.4642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.08s\n",
      "Steps: 223 | Train Loss: 0.0123968 Vali Loss: 0.0192176 Test Loss: 0.0256189\n",
      "Validation loss decreased (0.019221 --> 0.019218).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0122397\n",
      "\tspeed: 0.1597s/iter; left time: 3224.4697s\n",
      "\titers: 200, epoch: 10 | loss: 0.0133132\n",
      "\tspeed: 0.0933s/iter; left time: 1875.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:21.15s\n",
      "Steps: 223 | Train Loss: 0.0122787 Vali Loss: 0.0193194 Test Loss: 0.0254228\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0129103\n",
      "\tspeed: 0.1554s/iter; left time: 3103.0742s\n",
      "\titers: 200, epoch: 11 | loss: 0.0124456\n",
      "\tspeed: 0.0934s/iter; left time: 1855.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.01s\n",
      "Steps: 223 | Train Loss: 0.0121720 Vali Loss: 0.0192457 Test Loss: 0.0254233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0107149\n",
      "\tspeed: 0.1553s/iter; left time: 3066.8324s\n",
      "\titers: 200, epoch: 12 | loss: 0.0122780\n",
      "\tspeed: 0.0935s/iter; left time: 1836.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:21.05s\n",
      "Steps: 223 | Train Loss: 0.0120658 Vali Loss: 0.0192520 Test Loss: 0.0256999\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0136001\n",
      "\tspeed: 0.1546s/iter; left time: 3019.2703s\n",
      "\titers: 200, epoch: 13 | loss: 0.0121955\n",
      "\tspeed: 0.0935s/iter; left time: 1815.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.02s\n",
      "Steps: 223 | Train Loss: 0.0119548 Vali Loss: 0.0194143 Test Loss: 0.0255138\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0118067\n",
      "\tspeed: 0.1554s/iter; left time: 3000.3371s\n",
      "\titers: 200, epoch: 14 | loss: 0.0113263\n",
      "\tspeed: 0.0941s/iter; left time: 1807.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 223 | Train Loss: 0.0118590 Vali Loss: 0.0192243 Test Loss: 0.0257150\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0123613\n",
      "\tspeed: 0.1583s/iter; left time: 3020.4093s\n",
      "\titers: 200, epoch: 15 | loss: 0.0114182\n",
      "\tspeed: 0.0940s/iter; left time: 1783.7810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.17s\n",
      "Steps: 223 | Train Loss: 0.0118130 Vali Loss: 0.0192974 Test Loss: 0.0256904\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0123047\n",
      "\tspeed: 0.1595s/iter; left time: 3007.8112s\n",
      "\titers: 200, epoch: 16 | loss: 0.0116101\n",
      "\tspeed: 0.0949s/iter; left time: 1779.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:21.35s\n",
      "Steps: 223 | Train Loss: 0.0117060 Vali Loss: 0.0193427 Test Loss: 0.0257772\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0115515\n",
      "\tspeed: 0.1591s/iter; left time: 2963.8612s\n",
      "\titers: 200, epoch: 17 | loss: 0.0126495\n",
      "\tspeed: 0.0945s/iter; left time: 1751.0267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:21.35s\n",
      "Steps: 223 | Train Loss: 0.0116239 Vali Loss: 0.0191912 Test Loss: 0.0256985\n",
      "Validation loss decreased (0.019218 --> 0.019191).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0114054\n",
      "\tspeed: 0.1602s/iter; left time: 2948.6454s\n",
      "\titers: 200, epoch: 18 | loss: 0.0150055\n",
      "\tspeed: 0.0939s/iter; left time: 1718.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:21.19s\n",
      "Steps: 223 | Train Loss: 0.0115610 Vali Loss: 0.0191888 Test Loss: 0.0256056\n",
      "Validation loss decreased (0.019191 --> 0.019189).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0125917\n",
      "\tspeed: 0.1561s/iter; left time: 2839.2842s\n",
      "\titers: 200, epoch: 19 | loss: 0.0120124\n",
      "\tspeed: 0.0942s/iter; left time: 1703.4208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 223 | Train Loss: 0.0114969 Vali Loss: 0.0190892 Test Loss: 0.0257412\n",
      "Validation loss decreased (0.019189 --> 0.019089).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0122237\n",
      "\tspeed: 0.1612s/iter; left time: 2895.6115s\n",
      "\titers: 200, epoch: 20 | loss: 0.0114678\n",
      "\tspeed: 0.0938s/iter; left time: 1676.5284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:21.22s\n",
      "Steps: 223 | Train Loss: 0.0114345 Vali Loss: 0.0192416 Test Loss: 0.0257330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0117269\n",
      "\tspeed: 0.1589s/iter; left time: 2819.1354s\n",
      "\titers: 200, epoch: 21 | loss: 0.0105044\n",
      "\tspeed: 0.0938s/iter; left time: 1654.6842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 223 | Train Loss: 0.0113826 Vali Loss: 0.0192071 Test Loss: 0.0257706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0102358\n",
      "\tspeed: 0.1552s/iter; left time: 2718.5290s\n",
      "\titers: 200, epoch: 22 | loss: 0.0108546\n",
      "\tspeed: 0.0938s/iter; left time: 1634.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:21.10s\n",
      "Steps: 223 | Train Loss: 0.0113194 Vali Loss: 0.0192080 Test Loss: 0.0258715\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0129011\n",
      "\tspeed: 0.1598s/iter; left time: 2763.1368s\n",
      "\titers: 200, epoch: 23 | loss: 0.0118957\n",
      "\tspeed: 0.0940s/iter; left time: 1615.6943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:21.24s\n",
      "Steps: 223 | Train Loss: 0.0112978 Vali Loss: 0.0191752 Test Loss: 0.0257918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0123660\n",
      "\tspeed: 0.1594s/iter; left time: 2721.5243s\n",
      "\titers: 200, epoch: 24 | loss: 0.0121564\n",
      "\tspeed: 0.0934s/iter; left time: 1584.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:21.12s\n",
      "Steps: 223 | Train Loss: 0.0112600 Vali Loss: 0.0191136 Test Loss: 0.0258611\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0114829\n",
      "\tspeed: 0.1581s/iter; left time: 2664.5791s\n",
      "\titers: 200, epoch: 25 | loss: 0.0114014\n",
      "\tspeed: 0.0943s/iter; left time: 1579.3643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:21.23s\n",
      "Steps: 223 | Train Loss: 0.0112204 Vali Loss: 0.0191932 Test Loss: 0.0258743\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0102350\n",
      "\tspeed: 0.1567s/iter; left time: 2605.2285s\n",
      "\titers: 200, epoch: 26 | loss: 0.0102867\n",
      "\tspeed: 0.0946s/iter; left time: 1563.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:21.27s\n",
      "Steps: 223 | Train Loss: 0.0111773 Vali Loss: 0.0191997 Test Loss: 0.0258097\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0112516\n",
      "\tspeed: 0.1567s/iter; left time: 2570.4500s\n",
      "\titers: 200, epoch: 27 | loss: 0.0099050\n",
      "\tspeed: 0.0941s/iter; left time: 1533.4953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:21.23s\n",
      "Steps: 223 | Train Loss: 0.0111468 Vali Loss: 0.0191967 Test Loss: 0.0259208\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0109515\n",
      "\tspeed: 0.1565s/iter; left time: 2532.5326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0110301\n",
      "\tspeed: 0.0935s/iter; left time: 1502.9385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:21.12s\n",
      "Steps: 223 | Train Loss: 0.0111133 Vali Loss: 0.0191783 Test Loss: 0.0259661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0124601\n",
      "\tspeed: 0.1597s/iter; left time: 2547.7118s\n",
      "\titers: 200, epoch: 29 | loss: 0.0120364\n",
      "\tspeed: 0.0943s/iter; left time: 1494.8954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:21.24s\n",
      "Steps: 223 | Train Loss: 0.0111053 Vali Loss: 0.0191795 Test Loss: 0.0259658\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025741200894117355, rmse:0.16044063866138458, mae:0.10560756176710129, rse:0.5534747242927551\n",
      "Intermediate time for GB and pred_len 24: 00h:12m:23.89s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0286385\n",
      "\tspeed: 0.1197s/iter; left time: 2645.9603s\n",
      "\titers: 200, epoch: 1 | loss: 0.0295933\n",
      "\tspeed: 0.0948s/iter; left time: 2086.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.38s\n",
      "Steps: 222 | Train Loss: 0.0317820 Vali Loss: 0.0346977 Test Loss: 0.0488847\n",
      "Validation loss decreased (inf --> 0.034698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0235543\n",
      "\tspeed: 0.1604s/iter; left time: 3508.6137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0227046\n",
      "\tspeed: 0.0956s/iter; left time: 2082.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.44s\n",
      "Steps: 222 | Train Loss: 0.0234395 Vali Loss: 0.0287206 Test Loss: 0.0406741\n",
      "Validation loss decreased (0.034698 --> 0.028721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0200146\n",
      "\tspeed: 0.1594s/iter; left time: 3452.8169s\n",
      "\titers: 200, epoch: 3 | loss: 0.0218524\n",
      "\tspeed: 0.0947s/iter; left time: 2040.9621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 222 | Train Loss: 0.0209781 Vali Loss: 0.0287287 Test Loss: 0.0410445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0211668\n",
      "\tspeed: 0.1620s/iter; left time: 3472.4997s\n",
      "\titers: 200, epoch: 4 | loss: 0.0203843\n",
      "\tspeed: 0.0938s/iter; left time: 2000.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 222 | Train Loss: 0.0203292 Vali Loss: 0.0285516 Test Loss: 0.0411656\n",
      "Validation loss decreased (0.028721 --> 0.028552).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0194393\n",
      "\tspeed: 0.1620s/iter; left time: 3437.5117s\n",
      "\titers: 200, epoch: 5 | loss: 0.0191649\n",
      "\tspeed: 0.0941s/iter; left time: 1987.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 222 | Train Loss: 0.0198284 Vali Loss: 0.0289271 Test Loss: 0.0424755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0196316\n",
      "\tspeed: 0.1567s/iter; left time: 3289.8664s\n",
      "\titers: 200, epoch: 6 | loss: 0.0199478\n",
      "\tspeed: 0.0949s/iter; left time: 1981.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.17s\n",
      "Steps: 222 | Train Loss: 0.0193910 Vali Loss: 0.0286927 Test Loss: 0.0425020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0190443\n",
      "\tspeed: 0.1624s/iter; left time: 3373.2784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0182975\n",
      "\tspeed: 0.0946s/iter; left time: 1956.2522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.28s\n",
      "Steps: 222 | Train Loss: 0.0188919 Vali Loss: 0.0286100 Test Loss: 0.0432125\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0195447\n",
      "\tspeed: 0.1627s/iter; left time: 3343.0615s\n",
      "\titers: 200, epoch: 8 | loss: 0.0165387\n",
      "\tspeed: 0.0944s/iter; left time: 1930.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.23s\n",
      "Steps: 222 | Train Loss: 0.0183238 Vali Loss: 0.0285322 Test Loss: 0.0441726\n",
      "Validation loss decreased (0.028552 --> 0.028532).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0172791\n",
      "\tspeed: 0.1585s/iter; left time: 3222.4603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0161693\n",
      "\tspeed: 0.0943s/iter; left time: 1908.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 222 | Train Loss: 0.0177548 Vali Loss: 0.0286932 Test Loss: 0.0450680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0165963\n",
      "\tspeed: 0.1581s/iter; left time: 3178.7282s\n",
      "\titers: 200, epoch: 10 | loss: 0.0155259\n",
      "\tspeed: 0.0943s/iter; left time: 1885.9714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:21.16s\n",
      "Steps: 222 | Train Loss: 0.0172159 Vali Loss: 0.0287755 Test Loss: 0.0460033\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0166531\n",
      "\tspeed: 0.1581s/iter; left time: 3142.3369s\n",
      "\titers: 200, epoch: 11 | loss: 0.0162404\n",
      "\tspeed: 0.0946s/iter; left time: 1870.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.22s\n",
      "Steps: 222 | Train Loss: 0.0167270 Vali Loss: 0.0292023 Test Loss: 0.0470175\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0154610\n",
      "\tspeed: 0.1634s/iter; left time: 3211.6980s\n",
      "\titers: 200, epoch: 12 | loss: 0.0157134\n",
      "\tspeed: 0.0946s/iter; left time: 1849.7598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:21.29s\n",
      "Steps: 222 | Train Loss: 0.0162688 Vali Loss: 0.0295332 Test Loss: 0.0480100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0161103\n",
      "\tspeed: 0.1627s/iter; left time: 3162.5079s\n",
      "\titers: 200, epoch: 13 | loss: 0.0151919\n",
      "\tspeed: 0.0948s/iter; left time: 1832.6486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.34s\n",
      "Steps: 222 | Train Loss: 0.0158783 Vali Loss: 0.0295055 Test Loss: 0.0479155\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0162746\n",
      "\tspeed: 0.1637s/iter; left time: 3145.3599s\n",
      "\titers: 200, epoch: 14 | loss: 0.0148365\n",
      "\tspeed: 0.0949s/iter; left time: 1814.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:21.43s\n",
      "Steps: 222 | Train Loss: 0.0155280 Vali Loss: 0.0300045 Test Loss: 0.0487217\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0161436\n",
      "\tspeed: 0.1586s/iter; left time: 3011.3826s\n",
      "\titers: 200, epoch: 15 | loss: 0.0160928\n",
      "\tspeed: 0.0966s/iter; left time: 1824.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.49s\n",
      "Steps: 222 | Train Loss: 0.0152617 Vali Loss: 0.0305100 Test Loss: 0.0493942\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0150417\n",
      "\tspeed: 0.1653s/iter; left time: 3103.0782s\n",
      "\titers: 200, epoch: 16 | loss: 0.0152812\n",
      "\tspeed: 0.0956s/iter; left time: 1785.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:21.60s\n",
      "Steps: 222 | Train Loss: 0.0149918 Vali Loss: 0.0303583 Test Loss: 0.0494975\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0145758\n",
      "\tspeed: 0.1635s/iter; left time: 3032.4198s\n",
      "\titers: 200, epoch: 17 | loss: 0.0148976\n",
      "\tspeed: 0.0944s/iter; left time: 1740.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:21.38s\n",
      "Steps: 222 | Train Loss: 0.0147757 Vali Loss: 0.0305942 Test Loss: 0.0500297\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0154183\n",
      "\tspeed: 0.1621s/iter; left time: 2971.2406s\n",
      "\titers: 200, epoch: 18 | loss: 0.0149352\n",
      "\tspeed: 0.0943s/iter; left time: 1719.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:21.27s\n",
      "Steps: 222 | Train Loss: 0.0145689 Vali Loss: 0.0308802 Test Loss: 0.0503970\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04417259246110916, rmse:0.21017277240753174, mae:0.1458372175693512, rse:0.7268067598342896\n",
      "Intermediate time for GB and pred_len 96: 00h:07m:53.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0309067\n",
      "\tspeed: 0.1203s/iter; left time: 2658.8454s\n",
      "\titers: 200, epoch: 1 | loss: 0.0305578\n",
      "\tspeed: 0.0949s/iter; left time: 2087.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.43s\n",
      "Steps: 222 | Train Loss: 0.0324825 Vali Loss: 0.0357595 Test Loss: 0.0506153\n",
      "Validation loss decreased (inf --> 0.035760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0234579\n",
      "\tspeed: 0.1623s/iter; left time: 3551.9261s\n",
      "\titers: 200, epoch: 2 | loss: 0.0235328\n",
      "\tspeed: 0.0949s/iter; left time: 2066.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.37s\n",
      "Steps: 222 | Train Loss: 0.0247941 Vali Loss: 0.0302881 Test Loss: 0.0431045\n",
      "Validation loss decreased (0.035760 --> 0.030288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0216421\n",
      "\tspeed: 0.1625s/iter; left time: 3518.7134s\n",
      "\titers: 200, epoch: 3 | loss: 0.0229728\n",
      "\tspeed: 0.0949s/iter; left time: 2046.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.29s\n",
      "Steps: 222 | Train Loss: 0.0223902 Vali Loss: 0.0300547 Test Loss: 0.0433430\n",
      "Validation loss decreased (0.030288 --> 0.030055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0217222\n",
      "\tspeed: 0.1593s/iter; left time: 3414.1708s\n",
      "\titers: 200, epoch: 4 | loss: 0.0213812\n",
      "\tspeed: 0.0952s/iter; left time: 2030.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.43s\n",
      "Steps: 222 | Train Loss: 0.0216150 Vali Loss: 0.0304544 Test Loss: 0.0442020\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0210088\n",
      "\tspeed: 0.1621s/iter; left time: 3439.1086s\n",
      "\titers: 200, epoch: 5 | loss: 0.0202953\n",
      "\tspeed: 0.0962s/iter; left time: 2031.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.58s\n",
      "Steps: 222 | Train Loss: 0.0208999 Vali Loss: 0.0302984 Test Loss: 0.0450833\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0189380\n",
      "\tspeed: 0.1636s/iter; left time: 3433.4803s\n",
      "\titers: 200, epoch: 6 | loss: 0.0206162\n",
      "\tspeed: 0.0944s/iter; left time: 1971.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.37s\n",
      "Steps: 222 | Train Loss: 0.0201319 Vali Loss: 0.0305536 Test Loss: 0.0449197\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0190060\n",
      "\tspeed: 0.1604s/iter; left time: 3330.3638s\n",
      "\titers: 200, epoch: 7 | loss: 0.0185485\n",
      "\tspeed: 0.0952s/iter; left time: 1968.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.40s\n",
      "Steps: 222 | Train Loss: 0.0193228 Vali Loss: 0.0308159 Test Loss: 0.0471335\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0188569\n",
      "\tspeed: 0.1618s/iter; left time: 3324.2852s\n",
      "\titers: 200, epoch: 8 | loss: 0.0182244\n",
      "\tspeed: 0.0955s/iter; left time: 1952.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.52s\n",
      "Steps: 222 | Train Loss: 0.0185810 Vali Loss: 0.0311854 Test Loss: 0.0479620\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0182293\n",
      "\tspeed: 0.1634s/iter; left time: 3321.0028s\n",
      "\titers: 200, epoch: 9 | loss: 0.0180830\n",
      "\tspeed: 0.0950s/iter; left time: 1920.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.45s\n",
      "Steps: 222 | Train Loss: 0.0178595 Vali Loss: 0.0313361 Test Loss: 0.0480685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0174545\n",
      "\tspeed: 0.1620s/iter; left time: 3255.9678s\n",
      "\titers: 200, epoch: 10 | loss: 0.0173179\n",
      "\tspeed: 0.0951s/iter; left time: 1901.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:21.37s\n",
      "Steps: 222 | Train Loss: 0.0172888 Vali Loss: 0.0318637 Test Loss: 0.0497189\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0172413\n",
      "\tspeed: 0.1571s/iter; left time: 3123.8067s\n",
      "\titers: 200, epoch: 11 | loss: 0.0158245\n",
      "\tspeed: 0.0956s/iter; left time: 1891.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.35s\n",
      "Steps: 222 | Train Loss: 0.0167556 Vali Loss: 0.0324732 Test Loss: 0.0513317\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0162971\n",
      "\tspeed: 0.1591s/iter; left time: 3127.7779s\n",
      "\titers: 200, epoch: 12 | loss: 0.0155065\n",
      "\tspeed: 0.0952s/iter; left time: 1861.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:21.42s\n",
      "Steps: 222 | Train Loss: 0.0163283 Vali Loss: 0.0330424 Test Loss: 0.0516216\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0157031\n",
      "\tspeed: 0.1595s/iter; left time: 3100.2365s\n",
      "\titers: 200, epoch: 13 | loss: 0.0157518\n",
      "\tspeed: 0.0952s/iter; left time: 1841.3508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.47s\n",
      "Steps: 222 | Train Loss: 0.0160152 Vali Loss: 0.0329372 Test Loss: 0.0514252\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043342988938093185, rmse:0.20818978548049927, mae:0.14809077978134155, rse:0.7218239307403564\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:44.74s\n",
      "Intermediate time for GB: 00h:26m:02.57s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0348135\n",
      "\tspeed: 0.0701s/iter; left time: 1564.3174s\n",
      "\titers: 200, epoch: 1 | loss: 0.0279558\n",
      "\tspeed: 0.0398s/iter; left time: 883.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0360427 Vali Loss: 0.0299661 Test Loss: 0.0475522\n",
      "Validation loss decreased (inf --> 0.029966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0117279\n",
      "\tspeed: 0.0770s/iter; left time: 1699.0435s\n",
      "\titers: 200, epoch: 2 | loss: 0.0114513\n",
      "\tspeed: 0.0406s/iter; left time: 891.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0132698 Vali Loss: 0.0097065 Test Loss: 0.0121705\n",
      "Validation loss decreased (0.029966 --> 0.009706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0105819\n",
      "\tspeed: 0.0758s/iter; left time: 1657.4884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0094481\n",
      "\tspeed: 0.0395s/iter; left time: 858.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 224 | Train Loss: 0.0094588 Vali Loss: 0.0091290 Test Loss: 0.0116908\n",
      "Validation loss decreased (0.009706 --> 0.009129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0088838\n",
      "\tspeed: 0.0710s/iter; left time: 1534.9348s\n",
      "\titers: 200, epoch: 4 | loss: 0.0090307\n",
      "\tspeed: 0.0401s/iter; left time: 863.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 224 | Train Loss: 0.0088182 Vali Loss: 0.0086805 Test Loss: 0.0109470\n",
      "Validation loss decreased (0.009129 --> 0.008680).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0084279\n",
      "\tspeed: 0.0753s/iter; left time: 1612.8127s\n",
      "\titers: 200, epoch: 5 | loss: 0.0071033\n",
      "\tspeed: 0.0400s/iter; left time: 853.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 224 | Train Loss: 0.0083898 Vali Loss: 0.0085340 Test Loss: 0.0107725\n",
      "Validation loss decreased (0.008680 --> 0.008534).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0080680\n",
      "\tspeed: 0.0761s/iter; left time: 1612.2777s\n",
      "\titers: 200, epoch: 6 | loss: 0.0075223\n",
      "\tspeed: 0.0401s/iter; left time: 845.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0080808 Vali Loss: 0.0083547 Test Loss: 0.0106105\n",
      "Validation loss decreased (0.008534 --> 0.008355).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0085003\n",
      "\tspeed: 0.0754s/iter; left time: 1579.6532s\n",
      "\titers: 200, epoch: 7 | loss: 0.0066878\n",
      "\tspeed: 0.0402s/iter; left time: 837.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 224 | Train Loss: 0.0078812 Vali Loss: 0.0082689 Test Loss: 0.0105079\n",
      "Validation loss decreased (0.008355 --> 0.008269).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0074902\n",
      "\tspeed: 0.0753s/iter; left time: 1560.2706s\n",
      "\titers: 200, epoch: 8 | loss: 0.0089986\n",
      "\tspeed: 0.0405s/iter; left time: 835.0026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 224 | Train Loss: 0.0077448 Vali Loss: 0.0082498 Test Loss: 0.0104880\n",
      "Validation loss decreased (0.008269 --> 0.008250).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0068881\n",
      "\tspeed: 0.0763s/iter; left time: 1564.7331s\n",
      "\titers: 200, epoch: 9 | loss: 0.0084584\n",
      "\tspeed: 0.0402s/iter; left time: 821.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 224 | Train Loss: 0.0076187 Vali Loss: 0.0081377 Test Loss: 0.0103038\n",
      "Validation loss decreased (0.008250 --> 0.008138).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0073678\n",
      "\tspeed: 0.0755s/iter; left time: 1532.4107s\n",
      "\titers: 200, epoch: 10 | loss: 0.0064469\n",
      "\tspeed: 0.0406s/iter; left time: 820.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 224 | Train Loss: 0.0075159 Vali Loss: 0.0081130 Test Loss: 0.0102854\n",
      "Validation loss decreased (0.008138 --> 0.008113).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0078629\n",
      "\tspeed: 0.0726s/iter; left time: 1455.7491s\n",
      "\titers: 200, epoch: 11 | loss: 0.0078060\n",
      "\tspeed: 0.0418s/iter; left time: 833.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0074433 Vali Loss: 0.0080540 Test Loss: 0.0102174\n",
      "Validation loss decreased (0.008113 --> 0.008054).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0070436\n",
      "\tspeed: 0.0758s/iter; left time: 1504.4145s\n",
      "\titers: 200, epoch: 12 | loss: 0.0074274\n",
      "\tspeed: 0.0404s/iter; left time: 797.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0073742 Vali Loss: 0.0080284 Test Loss: 0.0101991\n",
      "Validation loss decreased (0.008054 --> 0.008028).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0078824\n",
      "\tspeed: 0.0724s/iter; left time: 1420.2406s\n",
      "\titers: 200, epoch: 13 | loss: 0.0072415\n",
      "\tspeed: 0.0404s/iter; left time: 787.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 224 | Train Loss: 0.0073082 Vali Loss: 0.0080012 Test Loss: 0.0101375\n",
      "Validation loss decreased (0.008028 --> 0.008001).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0072908\n",
      "\tspeed: 0.0748s/iter; left time: 1449.5397s\n",
      "\titers: 200, epoch: 14 | loss: 0.0075571\n",
      "\tspeed: 0.0400s/iter; left time: 771.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 224 | Train Loss: 0.0072672 Vali Loss: 0.0079979 Test Loss: 0.0101258\n",
      "Validation loss decreased (0.008001 --> 0.007998).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0068022\n",
      "\tspeed: 0.0753s/iter; left time: 1442.5566s\n",
      "\titers: 200, epoch: 15 | loss: 0.0068772\n",
      "\tspeed: 0.0397s/iter; left time: 756.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 224 | Train Loss: 0.0071882 Vali Loss: 0.0079546 Test Loss: 0.0100737\n",
      "Validation loss decreased (0.007998 --> 0.007955).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0067951\n",
      "\tspeed: 0.0755s/iter; left time: 1429.4621s\n",
      "\titers: 200, epoch: 16 | loss: 0.0064120\n",
      "\tspeed: 0.0407s/iter; left time: 766.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 224 | Train Loss: 0.0071591 Vali Loss: 0.0079258 Test Loss: 0.0100779\n",
      "Validation loss decreased (0.007955 --> 0.007926).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0063230\n",
      "\tspeed: 0.0756s/iter; left time: 1415.2166s\n",
      "\titers: 200, epoch: 17 | loss: 0.0065741\n",
      "\tspeed: 0.0404s/iter; left time: 752.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0071193 Vali Loss: 0.0079394 Test Loss: 0.0100596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0065070\n",
      "\tspeed: 0.0751s/iter; left time: 1388.8717s\n",
      "\titers: 200, epoch: 18 | loss: 0.0055144\n",
      "\tspeed: 0.0405s/iter; left time: 744.6359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 224 | Train Loss: 0.0070758 Vali Loss: 0.0079622 Test Loss: 0.0100524\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0074361\n",
      "\tspeed: 0.0738s/iter; left time: 1348.4589s\n",
      "\titers: 200, epoch: 19 | loss: 0.0072957\n",
      "\tspeed: 0.0401s/iter; left time: 728.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 224 | Train Loss: 0.0070561 Vali Loss: 0.0079346 Test Loss: 0.0100271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0066086\n",
      "\tspeed: 0.0746s/iter; left time: 1345.7633s\n",
      "\titers: 200, epoch: 20 | loss: 0.0063746\n",
      "\tspeed: 0.0401s/iter; left time: 720.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0070262 Vali Loss: 0.0079240 Test Loss: 0.0100455\n",
      "Validation loss decreased (0.007926 --> 0.007924).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0070996\n",
      "\tspeed: 0.0738s/iter; left time: 1315.9988s\n",
      "\titers: 200, epoch: 21 | loss: 0.0068137\n",
      "\tspeed: 0.0401s/iter; left time: 711.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 224 | Train Loss: 0.0070012 Vali Loss: 0.0079252 Test Loss: 0.0100144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0057434\n",
      "\tspeed: 0.0751s/iter; left time: 1322.1515s\n",
      "\titers: 200, epoch: 22 | loss: 0.0069716\n",
      "\tspeed: 0.0400s/iter; left time: 700.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 224 | Train Loss: 0.0069806 Vali Loss: 0.0078971 Test Loss: 0.0099880\n",
      "Validation loss decreased (0.007924 --> 0.007897).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0063108\n",
      "\tspeed: 0.0744s/iter; left time: 1292.7863s\n",
      "\titers: 200, epoch: 23 | loss: 0.0077751\n",
      "\tspeed: 0.0400s/iter; left time: 690.6428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 224 | Train Loss: 0.0069536 Vali Loss: 0.0078935 Test Loss: 0.0100049\n",
      "Validation loss decreased (0.007897 --> 0.007894).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0076234\n",
      "\tspeed: 0.0706s/iter; left time: 1211.0314s\n",
      "\titers: 200, epoch: 24 | loss: 0.0067014\n",
      "\tspeed: 0.0398s/iter; left time: 678.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 224 | Train Loss: 0.0069433 Vali Loss: 0.0079255 Test Loss: 0.0100165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0067662\n",
      "\tspeed: 0.0702s/iter; left time: 1188.0141s\n",
      "\titers: 200, epoch: 25 | loss: 0.0072623\n",
      "\tspeed: 0.0395s/iter; left time: 664.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 224 | Train Loss: 0.0069202 Vali Loss: 0.0079031 Test Loss: 0.0099712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0058483\n",
      "\tspeed: 0.0757s/iter; left time: 1264.9997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0076322\n",
      "\tspeed: 0.0402s/iter; left time: 666.6635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0069081 Vali Loss: 0.0078902 Test Loss: 0.0099910\n",
      "Validation loss decreased (0.007894 --> 0.007890).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0070932\n",
      "\tspeed: 0.0776s/iter; left time: 1278.1568s\n",
      "\titers: 200, epoch: 27 | loss: 0.0070114\n",
      "\tspeed: 0.0413s/iter; left time: 676.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0069008 Vali Loss: 0.0078853 Test Loss: 0.0099927\n",
      "Validation loss decreased (0.007890 --> 0.007885).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0074644\n",
      "\tspeed: 0.0762s/iter; left time: 1238.8882s\n",
      "\titers: 200, epoch: 28 | loss: 0.0068178\n",
      "\tspeed: 0.0403s/iter; left time: 650.3326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 224 | Train Loss: 0.0068944 Vali Loss: 0.0078766 Test Loss: 0.0099825\n",
      "Validation loss decreased (0.007885 --> 0.007877).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0061516\n",
      "\tspeed: 0.0795s/iter; left time: 1273.8987s\n",
      "\titers: 200, epoch: 29 | loss: 0.0078615\n",
      "\tspeed: 0.0412s/iter; left time: 655.6767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0068611 Vali Loss: 0.0079156 Test Loss: 0.0099854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0070892\n",
      "\tspeed: 0.0757s/iter; left time: 1196.6453s\n",
      "\titers: 200, epoch: 30 | loss: 0.0075102\n",
      "\tspeed: 0.0404s/iter; left time: 635.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 224 | Train Loss: 0.0068717 Vali Loss: 0.0078952 Test Loss: 0.0099688\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0069819\n",
      "\tspeed: 0.0765s/iter; left time: 1192.2164s\n",
      "\titers: 200, epoch: 31 | loss: 0.0064553\n",
      "\tspeed: 0.0401s/iter; left time: 621.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 224 | Train Loss: 0.0068614 Vali Loss: 0.0079188 Test Loss: 0.0099761\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0064362\n",
      "\tspeed: 0.0740s/iter; left time: 1135.9289s\n",
      "\titers: 200, epoch: 32 | loss: 0.0070097\n",
      "\tspeed: 0.0396s/iter; left time: 603.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 224 | Train Loss: 0.0068627 Vali Loss: 0.0078979 Test Loss: 0.0099627\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0063498\n",
      "\tspeed: 0.0719s/iter; left time: 1087.3703s\n",
      "\titers: 200, epoch: 33 | loss: 0.0071306\n",
      "\tspeed: 0.0402s/iter; left time: 603.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 224 | Train Loss: 0.0068653 Vali Loss: 0.0078961 Test Loss: 0.0099741\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0072508\n",
      "\tspeed: 0.0754s/iter; left time: 1123.6086s\n",
      "\titers: 200, epoch: 34 | loss: 0.0069682\n",
      "\tspeed: 0.0400s/iter; left time: 592.7130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 224 | Train Loss: 0.0068500 Vali Loss: 0.0079201 Test Loss: 0.0099757\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0070428\n",
      "\tspeed: 0.0741s/iter; left time: 1087.4698s\n",
      "\titers: 200, epoch: 35 | loss: 0.0067961\n",
      "\tspeed: 0.0400s/iter; left time: 583.0122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0068337 Vali Loss: 0.0078607 Test Loss: 0.0099667\n",
      "Validation loss decreased (0.007877 --> 0.007861).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0067678\n",
      "\tspeed: 0.0758s/iter; left time: 1096.7335s\n",
      "\titers: 200, epoch: 36 | loss: 0.0068788\n",
      "\tspeed: 0.0406s/iter; left time: 582.6142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0068368 Vali Loss: 0.0078932 Test Loss: 0.0099688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0069024\n",
      "\tspeed: 0.0753s/iter; left time: 1071.4126s\n",
      "\titers: 200, epoch: 37 | loss: 0.0059279\n",
      "\tspeed: 0.0405s/iter; left time: 572.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 224 | Train Loss: 0.0068240 Vali Loss: 0.0078948 Test Loss: 0.0099717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0066940\n",
      "\tspeed: 0.0739s/iter; left time: 1035.0636s\n",
      "\titers: 200, epoch: 38 | loss: 0.0083425\n",
      "\tspeed: 0.0406s/iter; left time: 565.1197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0068233 Vali Loss: 0.0078799 Test Loss: 0.0099534\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0065581\n",
      "\tspeed: 0.0739s/iter; left time: 1018.8277s\n",
      "\titers: 200, epoch: 39 | loss: 0.0076693\n",
      "\tspeed: 0.0402s/iter; left time: 550.6285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0068080 Vali Loss: 0.0079031 Test Loss: 0.0099550\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0067119\n",
      "\tspeed: 0.0701s/iter; left time: 950.7442s\n",
      "\titers: 200, epoch: 40 | loss: 0.0072247\n",
      "\tspeed: 0.0397s/iter; left time: 533.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 224 | Train Loss: 0.0068220 Vali Loss: 0.0078942 Test Loss: 0.0099630\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0067039\n",
      "\tspeed: 0.0736s/iter; left time: 982.1935s\n",
      "\titers: 200, epoch: 41 | loss: 0.0058107\n",
      "\tspeed: 0.0398s/iter; left time: 527.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0068048 Vali Loss: 0.0078693 Test Loss: 0.0099544\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0064208\n",
      "\tspeed: 0.0702s/iter; left time: 920.4348s\n",
      "\titers: 200, epoch: 42 | loss: 0.0073063\n",
      "\tspeed: 0.0395s/iter; left time: 513.9775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 224 | Train Loss: 0.0067944 Vali Loss: 0.0078995 Test Loss: 0.0099657\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0070989\n",
      "\tspeed: 0.0716s/iter; left time: 922.5956s\n",
      "\titers: 200, epoch: 43 | loss: 0.0056477\n",
      "\tspeed: 0.0397s/iter; left time: 507.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 224 | Train Loss: 0.0068141 Vali Loss: 0.0078980 Test Loss: 0.0099552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0068735\n",
      "\tspeed: 0.0699s/iter; left time: 885.7117s\n",
      "\titers: 200, epoch: 44 | loss: 0.0065986\n",
      "\tspeed: 0.0400s/iter; left time: 502.8531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 224 | Train Loss: 0.0068138 Vali Loss: 0.0078920 Test Loss: 0.0099558\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0074571\n",
      "\tspeed: 0.0734s/iter; left time: 912.8450s\n",
      "\titers: 200, epoch: 45 | loss: 0.0062618\n",
      "\tspeed: 0.0404s/iter; left time: 499.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 224 | Train Loss: 0.0067898 Vali Loss: 0.0078955 Test Loss: 0.0099486\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009966684505343437, rmse:0.09983327984809875, mae:0.06222286447882652, rse:0.2937972843647003\n",
      "Intermediate time for ES and pred_len 24: 00h:08m:46.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0365303\n",
      "\tspeed: 0.0678s/iter; left time: 1512.7986s\n",
      "\titers: 200, epoch: 1 | loss: 0.0316518\n",
      "\tspeed: 0.0402s/iter; left time: 891.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0397728 Vali Loss: 0.0346919 Test Loss: 0.0530728\n",
      "Validation loss decreased (inf --> 0.034692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0173501\n",
      "\tspeed: 0.0740s/iter; left time: 1632.6967s\n",
      "\titers: 200, epoch: 2 | loss: 0.0140366\n",
      "\tspeed: 0.0396s/iter; left time: 869.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 224 | Train Loss: 0.0189057 Vali Loss: 0.0166225 Test Loss: 0.0204552\n",
      "Validation loss decreased (0.034692 --> 0.016622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0153811\n",
      "\tspeed: 0.0718s/iter; left time: 1567.9641s\n",
      "\titers: 200, epoch: 3 | loss: 0.0159975\n",
      "\tspeed: 0.0399s/iter; left time: 866.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 224 | Train Loss: 0.0154017 Vali Loss: 0.0157788 Test Loss: 0.0195935\n",
      "Validation loss decreased (0.016622 --> 0.015779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0145856\n",
      "\tspeed: 0.0723s/iter; left time: 1563.8034s\n",
      "\titers: 200, epoch: 4 | loss: 0.0135051\n",
      "\tspeed: 0.0426s/iter; left time: 917.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0146852 Vali Loss: 0.0155951 Test Loss: 0.0194327\n",
      "Validation loss decreased (0.015779 --> 0.015595).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0149921\n",
      "\tspeed: 0.0772s/iter; left time: 1652.0223s\n",
      "\titers: 200, epoch: 5 | loss: 0.0147848\n",
      "\tspeed: 0.0413s/iter; left time: 879.2462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 224 | Train Loss: 0.0142006 Vali Loss: 0.0153731 Test Loss: 0.0189737\n",
      "Validation loss decreased (0.015595 --> 0.015373).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0133416\n",
      "\tspeed: 0.0734s/iter; left time: 1554.8881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0153772\n",
      "\tspeed: 0.0410s/iter; left time: 864.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 224 | Train Loss: 0.0138783 Vali Loss: 0.0152602 Test Loss: 0.0188935\n",
      "Validation loss decreased (0.015373 --> 0.015260).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0130052\n",
      "\tspeed: 0.0772s/iter; left time: 1616.9919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0134969\n",
      "\tspeed: 0.0404s/iter; left time: 843.4249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 224 | Train Loss: 0.0136186 Vali Loss: 0.0152438 Test Loss: 0.0187640\n",
      "Validation loss decreased (0.015260 --> 0.015244).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132074\n",
      "\tspeed: 0.0752s/iter; left time: 1559.4652s\n",
      "\titers: 200, epoch: 8 | loss: 0.0129395\n",
      "\tspeed: 0.0401s/iter; left time: 827.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 224 | Train Loss: 0.0134132 Vali Loss: 0.0152602 Test Loss: 0.0186714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0121628\n",
      "\tspeed: 0.0738s/iter; left time: 1513.5165s\n",
      "\titers: 200, epoch: 9 | loss: 0.0122543\n",
      "\tspeed: 0.0432s/iter; left time: 882.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0132404 Vali Loss: 0.0152817 Test Loss: 0.0185974\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0128089\n",
      "\tspeed: 0.0770s/iter; left time: 1561.1093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139891\n",
      "\tspeed: 0.0408s/iter; left time: 822.9370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0130784 Vali Loss: 0.0151202 Test Loss: 0.0185711\n",
      "Validation loss decreased (0.015244 --> 0.015120).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0129790\n",
      "\tspeed: 0.0758s/iter; left time: 1519.6606s\n",
      "\titers: 200, epoch: 11 | loss: 0.0137075\n",
      "\tspeed: 0.0406s/iter; left time: 809.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 224 | Train Loss: 0.0129201 Vali Loss: 0.0150357 Test Loss: 0.0185410\n",
      "Validation loss decreased (0.015120 --> 0.015036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0124464\n",
      "\tspeed: 0.0752s/iter; left time: 1491.1937s\n",
      "\titers: 200, epoch: 12 | loss: 0.0120629\n",
      "\tspeed: 0.0416s/iter; left time: 820.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0127908 Vali Loss: 0.0152019 Test Loss: 0.0185965\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0120554\n",
      "\tspeed: 0.0751s/iter; left time: 1473.0010s\n",
      "\titers: 200, epoch: 13 | loss: 0.0123066\n",
      "\tspeed: 0.0414s/iter; left time: 807.5020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0126819 Vali Loss: 0.0151402 Test Loss: 0.0185929\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0113010\n",
      "\tspeed: 0.0776s/iter; left time: 1504.5548s\n",
      "\titers: 200, epoch: 14 | loss: 0.0128509\n",
      "\tspeed: 0.0401s/iter; left time: 773.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 224 | Train Loss: 0.0125700 Vali Loss: 0.0151274 Test Loss: 0.0186363\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0132990\n",
      "\tspeed: 0.0779s/iter; left time: 1493.5382s\n",
      "\titers: 200, epoch: 15 | loss: 0.0128301\n",
      "\tspeed: 0.0397s/iter; left time: 756.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0124754 Vali Loss: 0.0151696 Test Loss: 0.0187334\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0116920\n",
      "\tspeed: 0.0727s/iter; left time: 1377.7333s\n",
      "\titers: 200, epoch: 16 | loss: 0.0123879\n",
      "\tspeed: 0.0401s/iter; left time: 756.0079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 224 | Train Loss: 0.0123675 Vali Loss: 0.0151592 Test Loss: 0.0187494\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0119778\n",
      "\tspeed: 0.0777s/iter; left time: 1454.3987s\n",
      "\titers: 200, epoch: 17 | loss: 0.0120996\n",
      "\tspeed: 0.0406s/iter; left time: 756.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0122890 Vali Loss: 0.0152063 Test Loss: 0.0188288\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0120779\n",
      "\tspeed: 0.0750s/iter; left time: 1386.5607s\n",
      "\titers: 200, epoch: 18 | loss: 0.0117243\n",
      "\tspeed: 0.0406s/iter; left time: 746.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0122143 Vali Loss: 0.0152627 Test Loss: 0.0187947\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0120077\n",
      "\tspeed: 0.0758s/iter; left time: 1385.1187s\n",
      "\titers: 200, epoch: 19 | loss: 0.0116859\n",
      "\tspeed: 0.0412s/iter; left time: 748.5651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 224 | Train Loss: 0.0121321 Vali Loss: 0.0151597 Test Loss: 0.0187552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0124996\n",
      "\tspeed: 0.0763s/iter; left time: 1377.3381s\n",
      "\titers: 200, epoch: 20 | loss: 0.0117229\n",
      "\tspeed: 0.0404s/iter; left time: 725.3253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0120703 Vali Loss: 0.0152232 Test Loss: 0.0188663\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0121779\n",
      "\tspeed: 0.0779s/iter; left time: 1387.8963s\n",
      "\titers: 200, epoch: 21 | loss: 0.0116021\n",
      "\tspeed: 0.0414s/iter; left time: 733.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0120200 Vali Loss: 0.0152345 Test Loss: 0.0188971\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01854102313518524, rmse:0.13616542518138885, mae:0.09016308933496475, rse:0.4000130295753479\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:14.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0366378\n",
      "\tspeed: 0.0605s/iter; left time: 1342.3695s\n",
      "\titers: 200, epoch: 1 | loss: 0.0341413\n",
      "\tspeed: 0.0409s/iter; left time: 903.7922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0401920 Vali Loss: 0.0359451 Test Loss: 0.0540369\n",
      "Validation loss decreased (inf --> 0.035945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0199764\n",
      "\tspeed: 0.0761s/iter; left time: 1672.0534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0182494\n",
      "\tspeed: 0.0410s/iter; left time: 897.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0203326 Vali Loss: 0.0187530 Test Loss: 0.0227277\n",
      "Validation loss decreased (0.035945 --> 0.018753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185840\n",
      "\tspeed: 0.0732s/iter; left time: 1592.3707s\n",
      "\titers: 200, epoch: 3 | loss: 0.0158198\n",
      "\tspeed: 0.0401s/iter; left time: 868.3948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 223 | Train Loss: 0.0169954 Vali Loss: 0.0178719 Test Loss: 0.0217632\n",
      "Validation loss decreased (0.018753 --> 0.017872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0163149\n",
      "\tspeed: 0.0716s/iter; left time: 1541.8025s\n",
      "\titers: 200, epoch: 4 | loss: 0.0157575\n",
      "\tspeed: 0.0398s/iter; left time: 852.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 223 | Train Loss: 0.0163095 Vali Loss: 0.0177754 Test Loss: 0.0214484\n",
      "Validation loss decreased (0.017872 --> 0.017775).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0151731\n",
      "\tspeed: 0.0754s/iter; left time: 1605.6377s\n",
      "\titers: 200, epoch: 5 | loss: 0.0152159\n",
      "\tspeed: 0.0413s/iter; left time: 874.8968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0158534 Vali Loss: 0.0177297 Test Loss: 0.0211255\n",
      "Validation loss decreased (0.017775 --> 0.017730).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0162751\n",
      "\tspeed: 0.0743s/iter; left time: 1566.0506s\n",
      "\titers: 200, epoch: 6 | loss: 0.0149664\n",
      "\tspeed: 0.0412s/iter; left time: 863.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0154951 Vali Loss: 0.0176965 Test Loss: 0.0208516\n",
      "Validation loss decreased (0.017730 --> 0.017697).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0160296\n",
      "\tspeed: 0.0755s/iter; left time: 1574.9138s\n",
      "\titers: 200, epoch: 7 | loss: 0.0145932\n",
      "\tspeed: 0.0407s/iter; left time: 844.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0152308 Vali Loss: 0.0175979 Test Loss: 0.0208182\n",
      "Validation loss decreased (0.017697 --> 0.017598).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0153580\n",
      "\tspeed: 0.0762s/iter; left time: 1572.2958s\n",
      "\titers: 200, epoch: 8 | loss: 0.0153125\n",
      "\tspeed: 0.0404s/iter; left time: 829.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0150244 Vali Loss: 0.0175929 Test Loss: 0.0207815\n",
      "Validation loss decreased (0.017598 --> 0.017593).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0143828\n",
      "\tspeed: 0.0732s/iter; left time: 1495.2791s\n",
      "\titers: 200, epoch: 9 | loss: 0.0148236\n",
      "\tspeed: 0.0403s/iter; left time: 819.5928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0148137 Vali Loss: 0.0176052 Test Loss: 0.0207298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0138089\n",
      "\tspeed: 0.0750s/iter; left time: 1515.4339s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139034\n",
      "\tspeed: 0.0407s/iter; left time: 817.7249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0146265 Vali Loss: 0.0176391 Test Loss: 0.0207503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0150639\n",
      "\tspeed: 0.0747s/iter; left time: 1491.1220s\n",
      "\titers: 200, epoch: 11 | loss: 0.0139771\n",
      "\tspeed: 0.0407s/iter; left time: 808.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0144807 Vali Loss: 0.0176500 Test Loss: 0.0208407\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0141757\n",
      "\tspeed: 0.0770s/iter; left time: 1520.2194s\n",
      "\titers: 200, epoch: 12 | loss: 0.0143612\n",
      "\tspeed: 0.0409s/iter; left time: 803.8103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0143287 Vali Loss: 0.0177083 Test Loss: 0.0208639\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0147004\n",
      "\tspeed: 0.0721s/iter; left time: 1407.0782s\n",
      "\titers: 200, epoch: 13 | loss: 0.0133520\n",
      "\tspeed: 0.0408s/iter; left time: 792.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0141830 Vali Loss: 0.0175835 Test Loss: 0.0209193\n",
      "Validation loss decreased (0.017593 --> 0.017583).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0148835\n",
      "\tspeed: 0.0766s/iter; left time: 1478.3674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0135342\n",
      "\tspeed: 0.0404s/iter; left time: 776.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0140493 Vali Loss: 0.0176878 Test Loss: 0.0209121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0140480\n",
      "\tspeed: 0.0750s/iter; left time: 1430.5186s\n",
      "\titers: 200, epoch: 15 | loss: 0.0134882\n",
      "\tspeed: 0.0407s/iter; left time: 771.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0139412 Vali Loss: 0.0177276 Test Loss: 0.0210297\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0139034\n",
      "\tspeed: 0.0720s/iter; left time: 1358.2955s\n",
      "\titers: 200, epoch: 16 | loss: 0.0141805\n",
      "\tspeed: 0.0406s/iter; left time: 761.1610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0138520 Vali Loss: 0.0176976 Test Loss: 0.0212079\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0134496\n",
      "\tspeed: 0.0749s/iter; left time: 1396.3544s\n",
      "\titers: 200, epoch: 17 | loss: 0.0133921\n",
      "\tspeed: 0.0405s/iter; left time: 751.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0137343 Vali Loss: 0.0178277 Test Loss: 0.0213090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0142436\n",
      "\tspeed: 0.0747s/iter; left time: 1375.0628s\n",
      "\titers: 200, epoch: 18 | loss: 0.0131880\n",
      "\tspeed: 0.0404s/iter; left time: 739.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0136488 Vali Loss: 0.0178217 Test Loss: 0.0213838\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0145515\n",
      "\tspeed: 0.0748s/iter; left time: 1360.4498s\n",
      "\titers: 200, epoch: 19 | loss: 0.0130700\n",
      "\tspeed: 0.0405s/iter; left time: 731.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0135481 Vali Loss: 0.0179305 Test Loss: 0.0215576\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0126202\n",
      "\tspeed: 0.0755s/iter; left time: 1355.7551s\n",
      "\titers: 200, epoch: 20 | loss: 0.0135858\n",
      "\tspeed: 0.0400s/iter; left time: 714.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0134826 Vali Loss: 0.0178760 Test Loss: 0.0215306\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0134767\n",
      "\tspeed: 0.0716s/iter; left time: 1270.4905s\n",
      "\titers: 200, epoch: 21 | loss: 0.0138388\n",
      "\tspeed: 0.0411s/iter; left time: 724.2109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0134253 Vali Loss: 0.0179189 Test Loss: 0.0215415\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0131685\n",
      "\tspeed: 0.0769s/iter; left time: 1348.0082s\n",
      "\titers: 200, epoch: 22 | loss: 0.0131194\n",
      "\tspeed: 0.0417s/iter; left time: 726.6280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0133679 Vali Loss: 0.0178993 Test Loss: 0.0217009\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0127806\n",
      "\tspeed: 0.0759s/iter; left time: 1312.4114s\n",
      "\titers: 200, epoch: 23 | loss: 0.0133260\n",
      "\tspeed: 0.0405s/iter; left time: 696.8979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0133041 Vali Loss: 0.0179363 Test Loss: 0.0217140\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020919350907206535, rmse:0.14463523030281067, mae:0.09668708592653275, rse:0.424925297498703\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:34.89s\n",
      "Intermediate time for ES: 00h:17m:36.16s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0237356\n",
      "\tspeed: 0.0643s/iter; left time: 1446.4788s\n",
      "\titers: 200, epoch: 1 | loss: 0.0166661\n",
      "\tspeed: 0.0358s/iter; left time: 802.4598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.0230923 Vali Loss: 0.0238321 Test Loss: 0.0298794\n",
      "Validation loss decreased (inf --> 0.023832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0093542\n",
      "\tspeed: 0.0658s/iter; left time: 1466.1629s\n",
      "\titers: 200, epoch: 2 | loss: 0.0079462\n",
      "\tspeed: 0.0339s/iter; left time: 750.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 226 | Train Loss: 0.0099565 Vali Loss: 0.0107128 Test Loss: 0.0120591\n",
      "Validation loss decreased (0.023832 --> 0.010713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0080557\n",
      "\tspeed: 0.0530s/iter; left time: 1168.5306s\n",
      "\titers: 200, epoch: 3 | loss: 0.0073414\n",
      "\tspeed: 0.0281s/iter; left time: 617.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 226 | Train Loss: 0.0072211 Vali Loss: 0.0097881 Test Loss: 0.0109410\n",
      "Validation loss decreased (0.010713 --> 0.009788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0072077\n",
      "\tspeed: 0.0646s/iter; left time: 1410.6301s\n",
      "\titers: 200, epoch: 4 | loss: 0.0052147\n",
      "\tspeed: 0.0369s/iter; left time: 801.8392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 226 | Train Loss: 0.0066755 Vali Loss: 0.0095442 Test Loss: 0.0107035\n",
      "Validation loss decreased (0.009788 --> 0.009544).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0054814\n",
      "\tspeed: 0.0513s/iter; left time: 1107.1538s\n",
      "\titers: 200, epoch: 5 | loss: 0.0061579\n",
      "\tspeed: 0.0367s/iter; left time: 789.1115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.0063989 Vali Loss: 0.0092577 Test Loss: 0.0103496\n",
      "Validation loss decreased (0.009544 --> 0.009258).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0062205\n",
      "\tspeed: 0.0579s/iter; left time: 1237.9817s\n",
      "\titers: 200, epoch: 6 | loss: 0.0067256\n",
      "\tspeed: 0.0365s/iter; left time: 776.5598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 226 | Train Loss: 0.0062187 Vali Loss: 0.0091027 Test Loss: 0.0102357\n",
      "Validation loss decreased (0.009258 --> 0.009103).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0060843\n",
      "\tspeed: 0.0585s/iter; left time: 1236.9068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0056078\n",
      "\tspeed: 0.0275s/iter; left time: 577.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 226 | Train Loss: 0.0060805 Vali Loss: 0.0089617 Test Loss: 0.0101414\n",
      "Validation loss decreased (0.009103 --> 0.008962).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0050162\n",
      "\tspeed: 0.0627s/iter; left time: 1311.5486s\n",
      "\titers: 200, epoch: 8 | loss: 0.0051762\n",
      "\tspeed: 0.0305s/iter; left time: 634.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 226 | Train Loss: 0.0059466 Vali Loss: 0.0089266 Test Loss: 0.0100621\n",
      "Validation loss decreased (0.008962 --> 0.008927).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0043858\n",
      "\tspeed: 0.0588s/iter; left time: 1216.9558s\n",
      "\titers: 200, epoch: 9 | loss: 0.0063614\n",
      "\tspeed: 0.0294s/iter; left time: 605.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.0058522 Vali Loss: 0.0088418 Test Loss: 0.0099862\n",
      "Validation loss decreased (0.008927 --> 0.008842).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0063100\n",
      "\tspeed: 0.0629s/iter; left time: 1288.0611s\n",
      "\titers: 200, epoch: 10 | loss: 0.0061891\n",
      "\tspeed: 0.0343s/iter; left time: 698.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 226 | Train Loss: 0.0057647 Vali Loss: 0.0088251 Test Loss: 0.0100708\n",
      "Validation loss decreased (0.008842 --> 0.008825).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0067617\n",
      "\tspeed: 0.0644s/iter; left time: 1303.7207s\n",
      "\titers: 200, epoch: 11 | loss: 0.0066305\n",
      "\tspeed: 0.0295s/iter; left time: 593.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0056819 Vali Loss: 0.0087484 Test Loss: 0.0100197\n",
      "Validation loss decreased (0.008825 --> 0.008748).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0060824\n",
      "\tspeed: 0.0624s/iter; left time: 1248.8350s\n",
      "\titers: 200, epoch: 12 | loss: 0.0058182\n",
      "\tspeed: 0.0310s/iter; left time: 617.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 226 | Train Loss: 0.0055992 Vali Loss: 0.0087655 Test Loss: 0.0100026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0064740\n",
      "\tspeed: 0.0550s/iter; left time: 1088.0837s\n",
      "\titers: 200, epoch: 13 | loss: 0.0052136\n",
      "\tspeed: 0.0235s/iter; left time: 463.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0055461 Vali Loss: 0.0087297 Test Loss: 0.0100234\n",
      "Validation loss decreased (0.008748 --> 0.008730).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0054593\n",
      "\tspeed: 0.0615s/iter; left time: 1202.7324s\n",
      "\titers: 200, epoch: 14 | loss: 0.0066011\n",
      "\tspeed: 0.0233s/iter; left time: 452.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 226 | Train Loss: 0.0055118 Vali Loss: 0.0087377 Test Loss: 0.0100422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0048896\n",
      "\tspeed: 0.0522s/iter; left time: 1009.7790s\n",
      "\titers: 200, epoch: 15 | loss: 0.0061342\n",
      "\tspeed: 0.0349s/iter; left time: 671.0195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 226 | Train Loss: 0.0054799 Vali Loss: 0.0087377 Test Loss: 0.0099943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0055380\n",
      "\tspeed: 0.0555s/iter; left time: 1059.7947s\n",
      "\titers: 200, epoch: 16 | loss: 0.0058325\n",
      "\tspeed: 0.0302s/iter; left time: 574.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0054355 Vali Loss: 0.0086340 Test Loss: 0.0099511\n",
      "Validation loss decreased (0.008730 --> 0.008634).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0056160\n",
      "\tspeed: 0.0518s/iter; left time: 977.4937s\n",
      "\titers: 200, epoch: 17 | loss: 0.0052510\n",
      "\tspeed: 0.0343s/iter; left time: 643.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0054082 Vali Loss: 0.0086247 Test Loss: 0.0099653\n",
      "Validation loss decreased (0.008634 --> 0.008625).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0053355\n",
      "\tspeed: 0.0525s/iter; left time: 980.4072s\n",
      "\titers: 200, epoch: 18 | loss: 0.0048924\n",
      "\tspeed: 0.0307s/iter; left time: 569.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 226 | Train Loss: 0.0053938 Vali Loss: 0.0086484 Test Loss: 0.0099769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0055976\n",
      "\tspeed: 0.0611s/iter; left time: 1127.1524s\n",
      "\titers: 200, epoch: 19 | loss: 0.0050728\n",
      "\tspeed: 0.0292s/iter; left time: 535.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 226 | Train Loss: 0.0053646 Vali Loss: 0.0086138 Test Loss: 0.0099554\n",
      "Validation loss decreased (0.008625 --> 0.008614).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0056121\n",
      "\tspeed: 0.0589s/iter; left time: 1072.7417s\n",
      "\titers: 200, epoch: 20 | loss: 0.0047978\n",
      "\tspeed: 0.0332s/iter; left time: 601.1052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0053453 Vali Loss: 0.0086795 Test Loss: 0.0099502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0052046\n",
      "\tspeed: 0.0555s/iter; left time: 998.4303s\n",
      "\titers: 200, epoch: 21 | loss: 0.0055206\n",
      "\tspeed: 0.0284s/iter; left time: 507.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.0053154 Vali Loss: 0.0086463 Test Loss: 0.0099572\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0047986\n",
      "\tspeed: 0.0556s/iter; left time: 986.5428s\n",
      "\titers: 200, epoch: 22 | loss: 0.0047735\n",
      "\tspeed: 0.0262s/iter; left time: 463.1183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 226 | Train Loss: 0.0052983 Vali Loss: 0.0086482 Test Loss: 0.0099361\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0054964\n",
      "\tspeed: 0.0513s/iter; left time: 900.0557s\n",
      "\titers: 200, epoch: 23 | loss: 0.0057613\n",
      "\tspeed: 0.0317s/iter; left time: 552.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 226 | Train Loss: 0.0052910 Vali Loss: 0.0086885 Test Loss: 0.0099816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0051943\n",
      "\tspeed: 0.0607s/iter; left time: 1051.0514s\n",
      "\titers: 200, epoch: 24 | loss: 0.0046766\n",
      "\tspeed: 0.0294s/iter; left time: 505.4437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0052728 Vali Loss: 0.0086597 Test Loss: 0.0099599\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0048268\n",
      "\tspeed: 0.0534s/iter; left time: 912.6870s\n",
      "\titers: 200, epoch: 25 | loss: 0.0055762\n",
      "\tspeed: 0.0344s/iter; left time: 583.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 226 | Train Loss: 0.0052606 Vali Loss: 0.0086038 Test Loss: 0.0099352\n",
      "Validation loss decreased (0.008614 --> 0.008604).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0054199\n",
      "\tspeed: 0.0652s/iter; left time: 1098.7889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0047658\n",
      "\tspeed: 0.0309s/iter; left time: 517.5832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 226 | Train Loss: 0.0052556 Vali Loss: 0.0086673 Test Loss: 0.0099702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0054049\n",
      "\tspeed: 0.0530s/iter; left time: 880.9221s\n",
      "\titers: 200, epoch: 27 | loss: 0.0052203\n",
      "\tspeed: 0.0359s/iter; left time: 593.5437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 226 | Train Loss: 0.0052431 Vali Loss: 0.0086526 Test Loss: 0.0099488\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0051072\n",
      "\tspeed: 0.0537s/iter; left time: 881.0987s\n",
      "\titers: 200, epoch: 28 | loss: 0.0047350\n",
      "\tspeed: 0.0237s/iter; left time: 386.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0052365 Vali Loss: 0.0086557 Test Loss: 0.0099640\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0052623\n",
      "\tspeed: 0.0526s/iter; left time: 849.8916s\n",
      "\titers: 200, epoch: 29 | loss: 0.0066183\n",
      "\tspeed: 0.0313s/iter; left time: 502.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0052327 Vali Loss: 0.0086441 Test Loss: 0.0099638\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0041976\n",
      "\tspeed: 0.0599s/iter; left time: 955.3407s\n",
      "\titers: 200, epoch: 30 | loss: 0.0064455\n",
      "\tspeed: 0.0269s/iter; left time: 426.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.0052169 Vali Loss: 0.0086797 Test Loss: 0.0099548\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0047889\n",
      "\tspeed: 0.0554s/iter; left time: 870.9370s\n",
      "\titers: 200, epoch: 31 | loss: 0.0054666\n",
      "\tspeed: 0.0227s/iter; left time: 354.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 226 | Train Loss: 0.0052050 Vali Loss: 0.0086171 Test Loss: 0.0099502\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0052385\n",
      "\tspeed: 0.0601s/iter; left time: 930.4847s\n",
      "\titers: 200, epoch: 32 | loss: 0.0052754\n",
      "\tspeed: 0.0274s/iter; left time: 421.7482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0052094 Vali Loss: 0.0086470 Test Loss: 0.0099568\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0048150\n",
      "\tspeed: 0.0488s/iter; left time: 745.2558s\n",
      "\titers: 200, epoch: 33 | loss: 0.0051399\n",
      "\tspeed: 0.0235s/iter; left time: 356.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 226 | Train Loss: 0.0052055 Vali Loss: 0.0086455 Test Loss: 0.0099734\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0053405\n",
      "\tspeed: 0.0447s/iter; left time: 671.9277s\n",
      "\titers: 200, epoch: 34 | loss: 0.0056786\n",
      "\tspeed: 0.0317s/iter; left time: 473.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0052045 Vali Loss: 0.0086125 Test Loss: 0.0099662\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0055080\n",
      "\tspeed: 0.0540s/iter; left time: 800.5996s\n",
      "\titers: 200, epoch: 35 | loss: 0.0048850\n",
      "\tspeed: 0.0235s/iter; left time: 346.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 226 | Train Loss: 0.0051874 Vali Loss: 0.0086392 Test Loss: 0.0099633\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009935157373547554, rmse:0.0996752604842186, mae:0.056855376809835434, rse:0.38454437255859375\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:16.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0254300\n",
      "\tspeed: 0.0648s/iter; left time: 1452.0780s\n",
      "\titers: 200, epoch: 1 | loss: 0.0226345\n",
      "\tspeed: 0.0380s/iter; left time: 847.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 225 | Train Loss: 0.0254588 Vali Loss: 0.0273043 Test Loss: 0.0352626\n",
      "Validation loss decreased (inf --> 0.027304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0142459\n",
      "\tspeed: 0.0585s/iter; left time: 1296.5962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0128824\n",
      "\tspeed: 0.0328s/iter; left time: 724.2941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 225 | Train Loss: 0.0145184 Vali Loss: 0.0163889 Test Loss: 0.0206476\n",
      "Validation loss decreased (0.027304 --> 0.016389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0115962\n",
      "\tspeed: 0.0660s/iter; left time: 1447.8311s\n",
      "\titers: 200, epoch: 3 | loss: 0.0122913\n",
      "\tspeed: 0.0280s/iter; left time: 611.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 225 | Train Loss: 0.0118228 Vali Loss: 0.0154873 Test Loss: 0.0198312\n",
      "Validation loss decreased (0.016389 --> 0.015487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120922\n",
      "\tspeed: 0.0542s/iter; left time: 1177.0468s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113413\n",
      "\tspeed: 0.0251s/iter; left time: 543.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0112676 Vali Loss: 0.0152080 Test Loss: 0.0196720\n",
      "Validation loss decreased (0.015487 --> 0.015208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0102608\n",
      "\tspeed: 0.0578s/iter; left time: 1243.5615s\n",
      "\titers: 200, epoch: 5 | loss: 0.0104193\n",
      "\tspeed: 0.0321s/iter; left time: 686.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 225 | Train Loss: 0.0109707 Vali Loss: 0.0150341 Test Loss: 0.0193699\n",
      "Validation loss decreased (0.015208 --> 0.015034).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0108786\n",
      "\tspeed: 0.0667s/iter; left time: 1418.7312s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == \"DE\" and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "                \n",
    "            model_id = f\"ts_decomp_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.0967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.0583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0212  0.1455  0.0921\n",
       "        96              0.0350  0.1870  0.1285\n",
       "        168             0.0376  0.1940  0.1374\n",
       "ES      24              0.0100  0.0998  0.0622\n",
       "        96              0.0185  0.1362  0.0902\n",
       "        168             0.0209  0.1446  0.0967\n",
       "FR      24              0.0099  0.0997  0.0569\n",
       "        96              0.0192  0.1385  0.0838\n",
       "        168             0.0208  0.1442  0.0896\n",
       "GB      24              0.0257  0.1604  0.1056\n",
       "        96              0.0442  0.2102  0.1458\n",
       "        168             0.0433  0.2082  0.1481\n",
       "IT      24              0.0099  0.0996  0.0583\n",
       "        96              0.0178  0.1334  0.0818\n",
       "        168             0.0190  0.1380  0.0874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0237356\n",
      "\tspeed: 0.0630s/iter; left time: 1416.7940s\n",
      "\titers: 200, epoch: 1 | loss: 0.0166661\n",
      "\tspeed: 0.0352s/iter; left time: 787.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 226 | Train Loss: 0.0230923 Vali Loss: 0.0238321 Test Loss: 0.0298794\n",
      "Validation loss decreased (inf --> 0.023832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0093542\n",
      "\tspeed: 0.0549s/iter; left time: 1222.3188s\n",
      "\titers: 200, epoch: 2 | loss: 0.0079462\n",
      "\tspeed: 0.0307s/iter; left time: 681.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 226 | Train Loss: 0.0099565 Vali Loss: 0.0107128 Test Loss: 0.0120591\n",
      "Validation loss decreased (0.023832 --> 0.010713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0080557\n",
      "\tspeed: 0.0575s/iter; left time: 1267.1122s\n",
      "\titers: 200, epoch: 3 | loss: 0.0073414\n",
      "\tspeed: 0.0325s/iter; left time: 714.3936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0072211 Vali Loss: 0.0097881 Test Loss: 0.0109410\n",
      "Validation loss decreased (0.010713 --> 0.009788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0072077\n",
      "\tspeed: 0.0547s/iter; left time: 1193.3030s\n",
      "\titers: 200, epoch: 4 | loss: 0.0052147\n",
      "\tspeed: 0.0241s/iter; left time: 523.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 226 | Train Loss: 0.0066755 Vali Loss: 0.0095442 Test Loss: 0.0107035\n",
      "Validation loss decreased (0.009788 --> 0.009544).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0054814\n",
      "\tspeed: 0.0541s/iter; left time: 1167.6294s\n",
      "\titers: 200, epoch: 5 | loss: 0.0061579\n",
      "\tspeed: 0.0251s/iter; left time: 539.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0063989 Vali Loss: 0.0092577 Test Loss: 0.0103496\n",
      "Validation loss decreased (0.009544 --> 0.009258).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0062205\n",
      "\tspeed: 0.0579s/iter; left time: 1237.9695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0067256\n",
      "\tspeed: 0.0344s/iter; left time: 730.9275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 226 | Train Loss: 0.0062187 Vali Loss: 0.0091027 Test Loss: 0.0102357\n",
      "Validation loss decreased (0.009258 --> 0.009103).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0060843\n",
      "\tspeed: 0.0654s/iter; left time: 1382.3597s\n",
      "\titers: 200, epoch: 7 | loss: 0.0056078\n",
      "\tspeed: 0.0286s/iter; left time: 602.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 226 | Train Loss: 0.0060805 Vali Loss: 0.0089617 Test Loss: 0.0101414\n",
      "Validation loss decreased (0.009103 --> 0.008962).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0050162\n",
      "\tspeed: 0.0539s/iter; left time: 1127.4219s\n",
      "\titers: 200, epoch: 8 | loss: 0.0051762\n",
      "\tspeed: 0.0289s/iter; left time: 601.8684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 226 | Train Loss: 0.0059466 Vali Loss: 0.0089266 Test Loss: 0.0100621\n",
      "Validation loss decreased (0.008962 --> 0.008927).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0043858\n",
      "\tspeed: 0.0627s/iter; left time: 1297.6389s\n",
      "\titers: 200, epoch: 9 | loss: 0.0063614\n",
      "\tspeed: 0.0331s/iter; left time: 681.7924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 226 | Train Loss: 0.0058522 Vali Loss: 0.0088418 Test Loss: 0.0099862\n",
      "Validation loss decreased (0.008927 --> 0.008842).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0063100\n",
      "\tspeed: 0.0556s/iter; left time: 1137.8350s\n",
      "\titers: 200, epoch: 10 | loss: 0.0061891\n",
      "\tspeed: 0.0296s/iter; left time: 602.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 226 | Train Loss: 0.0057647 Vali Loss: 0.0088251 Test Loss: 0.0100708\n",
      "Validation loss decreased (0.008842 --> 0.008825).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0067617\n",
      "\tspeed: 0.0538s/iter; left time: 1089.2481s\n",
      "\titers: 200, epoch: 11 | loss: 0.0066305\n",
      "\tspeed: 0.0268s/iter; left time: 540.6986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 226 | Train Loss: 0.0056819 Vali Loss: 0.0087484 Test Loss: 0.0100197\n",
      "Validation loss decreased (0.008825 --> 0.008748).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0060824\n",
      "\tspeed: 0.0518s/iter; left time: 1036.1625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0058182\n",
      "\tspeed: 0.0270s/iter; left time: 538.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 226 | Train Loss: 0.0055992 Vali Loss: 0.0087655 Test Loss: 0.0100026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0064740\n",
      "\tspeed: 0.0519s/iter; left time: 1027.6831s\n",
      "\titers: 200, epoch: 13 | loss: 0.0052136\n",
      "\tspeed: 0.0275s/iter; left time: 541.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0055461 Vali Loss: 0.0087297 Test Loss: 0.0100234\n",
      "Validation loss decreased (0.008748 --> 0.008730).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0054593\n",
      "\tspeed: 0.0544s/iter; left time: 1063.8500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0066011\n",
      "\tspeed: 0.0277s/iter; left time: 538.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 226 | Train Loss: 0.0055118 Vali Loss: 0.0087377 Test Loss: 0.0100422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0048896\n",
      "\tspeed: 0.0587s/iter; left time: 1134.3386s\n",
      "\titers: 200, epoch: 15 | loss: 0.0061342\n",
      "\tspeed: 0.0299s/iter; left time: 575.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.0054799 Vali Loss: 0.0087377 Test Loss: 0.0099943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0055380\n",
      "\tspeed: 0.0584s/iter; left time: 1115.4190s\n",
      "\titers: 200, epoch: 16 | loss: 0.0058325\n",
      "\tspeed: 0.0248s/iter; left time: 471.3572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0054355 Vali Loss: 0.0086340 Test Loss: 0.0099511\n",
      "Validation loss decreased (0.008730 --> 0.008634).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0056160\n",
      "\tspeed: 0.0604s/iter; left time: 1141.4406s\n",
      "\titers: 200, epoch: 17 | loss: 0.0052510\n",
      "\tspeed: 0.0298s/iter; left time: 559.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0054082 Vali Loss: 0.0086247 Test Loss: 0.0099653\n",
      "Validation loss decreased (0.008634 --> 0.008625).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0053355\n",
      "\tspeed: 0.0577s/iter; left time: 1075.9685s\n",
      "\titers: 200, epoch: 18 | loss: 0.0048924\n",
      "\tspeed: 0.0280s/iter; left time: 519.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 226 | Train Loss: 0.0053938 Vali Loss: 0.0086484 Test Loss: 0.0099769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0055976\n",
      "\tspeed: 0.0601s/iter; left time: 1108.6693s\n",
      "\titers: 200, epoch: 19 | loss: 0.0050728\n",
      "\tspeed: 0.0374s/iter; left time: 684.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.0053646 Vali Loss: 0.0086138 Test Loss: 0.0099554\n",
      "Validation loss decreased (0.008625 --> 0.008614).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0056121\n",
      "\tspeed: 0.0606s/iter; left time: 1102.4992s\n",
      "\titers: 200, epoch: 20 | loss: 0.0047978\n",
      "\tspeed: 0.0271s/iter; left time: 491.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 226 | Train Loss: 0.0053453 Vali Loss: 0.0086795 Test Loss: 0.0099502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0052046\n",
      "\tspeed: 0.0548s/iter; left time: 985.3313s\n",
      "\titers: 200, epoch: 21 | loss: 0.0055206\n",
      "\tspeed: 0.0274s/iter; left time: 489.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0053154 Vali Loss: 0.0086463 Test Loss: 0.0099572\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0047986\n",
      "\tspeed: 0.0528s/iter; left time: 938.0809s\n",
      "\titers: 200, epoch: 22 | loss: 0.0047735\n",
      "\tspeed: 0.0283s/iter; left time: 500.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 226 | Train Loss: 0.0052983 Vali Loss: 0.0086482 Test Loss: 0.0099361\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0054964\n",
      "\tspeed: 0.0587s/iter; left time: 1029.2893s\n",
      "\titers: 200, epoch: 23 | loss: 0.0057613\n",
      "\tspeed: 0.0235s/iter; left time: 410.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 226 | Train Loss: 0.0052910 Vali Loss: 0.0086885 Test Loss: 0.0099816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0051943\n",
      "\tspeed: 0.0497s/iter; left time: 860.1582s\n",
      "\titers: 200, epoch: 24 | loss: 0.0046766\n",
      "\tspeed: 0.0264s/iter; left time: 453.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0052728 Vali Loss: 0.0086597 Test Loss: 0.0099599\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0048268\n",
      "\tspeed: 0.0502s/iter; left time: 857.0807s\n",
      "\titers: 200, epoch: 25 | loss: 0.0055762\n",
      "\tspeed: 0.0287s/iter; left time: 487.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 226 | Train Loss: 0.0052606 Vali Loss: 0.0086038 Test Loss: 0.0099352\n",
      "Validation loss decreased (0.008614 --> 0.008604).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0054199\n",
      "\tspeed: 0.0624s/iter; left time: 1051.8108s\n",
      "\titers: 200, epoch: 26 | loss: 0.0047658\n",
      "\tspeed: 0.0317s/iter; left time: 530.4635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.0052556 Vali Loss: 0.0086673 Test Loss: 0.0099702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0054049\n",
      "\tspeed: 0.0532s/iter; left time: 883.9730s\n",
      "\titers: 200, epoch: 27 | loss: 0.0052203\n",
      "\tspeed: 0.0294s/iter; left time: 485.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 226 | Train Loss: 0.0052431 Vali Loss: 0.0086526 Test Loss: 0.0099488\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0051072\n",
      "\tspeed: 0.0580s/iter; left time: 950.9519s\n",
      "\titers: 200, epoch: 28 | loss: 0.0047350\n",
      "\tspeed: 0.0249s/iter; left time: 405.5559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0052365 Vali Loss: 0.0086557 Test Loss: 0.0099640\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0052623\n",
      "\tspeed: 0.0535s/iter; left time: 865.1883s\n",
      "\titers: 200, epoch: 29 | loss: 0.0066183\n",
      "\tspeed: 0.0315s/iter; left time: 506.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0052327 Vali Loss: 0.0086441 Test Loss: 0.0099638\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0041976\n",
      "\tspeed: 0.0562s/iter; left time: 895.9772s\n",
      "\titers: 200, epoch: 30 | loss: 0.0064455\n",
      "\tspeed: 0.0327s/iter; left time: 517.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0052169 Vali Loss: 0.0086797 Test Loss: 0.0099548\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0047889\n",
      "\tspeed: 0.0549s/iter; left time: 863.2743s\n",
      "\titers: 200, epoch: 31 | loss: 0.0054666\n",
      "\tspeed: 0.0303s/iter; left time: 472.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0052050 Vali Loss: 0.0086171 Test Loss: 0.0099502\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0052385\n",
      "\tspeed: 0.0594s/iter; left time: 920.9677s\n",
      "\titers: 200, epoch: 32 | loss: 0.0052754\n",
      "\tspeed: 0.0264s/iter; left time: 405.8018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 226 | Train Loss: 0.0052094 Vali Loss: 0.0086470 Test Loss: 0.0099568\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0048150\n",
      "\tspeed: 0.0542s/iter; left time: 827.8754s\n",
      "\titers: 200, epoch: 33 | loss: 0.0051399\n",
      "\tspeed: 0.0270s/iter; left time: 409.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 226 | Train Loss: 0.0052055 Vali Loss: 0.0086455 Test Loss: 0.0099734\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0053405\n",
      "\tspeed: 0.0544s/iter; left time: 818.6350s\n",
      "\titers: 200, epoch: 34 | loss: 0.0056786\n",
      "\tspeed: 0.0247s/iter; left time: 369.4467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0052045 Vali Loss: 0.0086125 Test Loss: 0.0099662\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0055080\n",
      "\tspeed: 0.0579s/iter; left time: 858.3640s\n",
      "\titers: 200, epoch: 35 | loss: 0.0048850\n",
      "\tspeed: 0.0247s/iter; left time: 363.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 226 | Train Loss: 0.0051874 Vali Loss: 0.0086392 Test Loss: 0.0099633\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009935157373547554, rmse:0.0996752604842186, mae:0.056855376809835434, rse:0.38454437255859375\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:09.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0254300\n",
      "\tspeed: 0.0466s/iter; left time: 1044.5209s\n",
      "\titers: 200, epoch: 1 | loss: 0.0226345\n",
      "\tspeed: 0.0276s/iter; left time: 616.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0254588 Vali Loss: 0.0273043 Test Loss: 0.0352626\n",
      "Validation loss decreased (inf --> 0.027304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0142459\n",
      "\tspeed: 0.0601s/iter; left time: 1333.5906s\n",
      "\titers: 200, epoch: 2 | loss: 0.0128824\n",
      "\tspeed: 0.0366s/iter; left time: 807.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 225 | Train Loss: 0.0145184 Vali Loss: 0.0163889 Test Loss: 0.0206476\n",
      "Validation loss decreased (0.027304 --> 0.016389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0115962\n",
      "\tspeed: 0.0549s/iter; left time: 1205.2686s\n",
      "\titers: 200, epoch: 3 | loss: 0.0122913\n",
      "\tspeed: 0.0310s/iter; left time: 677.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 225 | Train Loss: 0.0118228 Vali Loss: 0.0154873 Test Loss: 0.0198312\n",
      "Validation loss decreased (0.016389 --> 0.015487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120922\n",
      "\tspeed: 0.0623s/iter; left time: 1353.8541s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113413\n",
      "\tspeed: 0.0300s/iter; left time: 647.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 225 | Train Loss: 0.0112676 Vali Loss: 0.0152080 Test Loss: 0.0196720\n",
      "Validation loss decreased (0.015487 --> 0.015208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0102608\n",
      "\tspeed: 0.0648s/iter; left time: 1393.2321s\n",
      "\titers: 200, epoch: 5 | loss: 0.0104193\n",
      "\tspeed: 0.0377s/iter; left time: 806.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 225 | Train Loss: 0.0109707 Vali Loss: 0.0150341 Test Loss: 0.0193699\n",
      "Validation loss decreased (0.015208 --> 0.015034).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0108786\n",
      "\tspeed: 0.0612s/iter; left time: 1303.0145s\n",
      "\titers: 200, epoch: 6 | loss: 0.0100191\n",
      "\tspeed: 0.0305s/iter; left time: 645.2362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 225 | Train Loss: 0.0106828 Vali Loss: 0.0148039 Test Loss: 0.0193114\n",
      "Validation loss decreased (0.015034 --> 0.014804).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0110777\n",
      "\tspeed: 0.0646s/iter; left time: 1359.5216s\n",
      "\titers: 200, epoch: 7 | loss: 0.0127516\n",
      "\tspeed: 0.0340s/iter; left time: 712.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 225 | Train Loss: 0.0104120 Vali Loss: 0.0146961 Test Loss: 0.0191919\n",
      "Validation loss decreased (0.014804 --> 0.014696).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0092179\n",
      "\tspeed: 0.0595s/iter; left time: 1240.1219s\n",
      "\titers: 200, epoch: 8 | loss: 0.0089943\n",
      "\tspeed: 0.0282s/iter; left time: 584.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 225 | Train Loss: 0.0101818 Vali Loss: 0.0145038 Test Loss: 0.0191868\n",
      "Validation loss decreased (0.014696 --> 0.014504).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0098994\n",
      "\tspeed: 0.0581s/iter; left time: 1196.0263s\n",
      "\titers: 200, epoch: 9 | loss: 0.0097919\n",
      "\tspeed: 0.0307s/iter; left time: 629.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 225 | Train Loss: 0.0100057 Vali Loss: 0.0145380 Test Loss: 0.0191176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0096034\n",
      "\tspeed: 0.0547s/iter; left time: 1114.2371s\n",
      "\titers: 200, epoch: 10 | loss: 0.0100670\n",
      "\tspeed: 0.0273s/iter; left time: 552.5516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 225 | Train Loss: 0.0098874 Vali Loss: 0.0145757 Test Loss: 0.0192410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0098913\n",
      "\tspeed: 0.0588s/iter; left time: 1185.8312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0097004\n",
      "\tspeed: 0.0306s/iter; left time: 614.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 225 | Train Loss: 0.0097905 Vali Loss: 0.0145232 Test Loss: 0.0191619\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0081249\n",
      "\tspeed: 0.0618s/iter; left time: 1231.0164s\n",
      "\titers: 200, epoch: 12 | loss: 0.0093403\n",
      "\tspeed: 0.0350s/iter; left time: 694.0710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 225 | Train Loss: 0.0096884 Vali Loss: 0.0146157 Test Loss: 0.0192267\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0094197\n",
      "\tspeed: 0.0696s/iter; left time: 1370.3090s\n",
      "\titers: 200, epoch: 13 | loss: 0.0094363\n",
      "\tspeed: 0.0310s/iter; left time: 607.9622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 225 | Train Loss: 0.0095827 Vali Loss: 0.0145366 Test Loss: 0.0191297\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0100738\n",
      "\tspeed: 0.0626s/iter; left time: 1218.8052s\n",
      "\titers: 200, epoch: 14 | loss: 0.0103495\n",
      "\tspeed: 0.0325s/iter; left time: 630.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 225 | Train Loss: 0.0094880 Vali Loss: 0.0146680 Test Loss: 0.0193109\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0093224\n",
      "\tspeed: 0.0582s/iter; left time: 1119.8090s\n",
      "\titers: 200, epoch: 15 | loss: 0.0091487\n",
      "\tspeed: 0.0327s/iter; left time: 626.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 225 | Train Loss: 0.0093999 Vali Loss: 0.0145867 Test Loss: 0.0193278\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0093353\n",
      "\tspeed: 0.0560s/iter; left time: 1065.4500s\n",
      "\titers: 200, epoch: 16 | loss: 0.0092124\n",
      "\tspeed: 0.0249s/iter; left time: 471.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 225 | Train Loss: 0.0093282 Vali Loss: 0.0145779 Test Loss: 0.0191555\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0087824\n",
      "\tspeed: 0.0517s/iter; left time: 972.2200s\n",
      "\titers: 200, epoch: 17 | loss: 0.0086737\n",
      "\tspeed: 0.0283s/iter; left time: 529.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0092395 Vali Loss: 0.0146747 Test Loss: 0.0192166\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0088149\n",
      "\tspeed: 0.0655s/iter; left time: 1216.3936s\n",
      "\titers: 200, epoch: 18 | loss: 0.0099954\n",
      "\tspeed: 0.0264s/iter; left time: 487.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 225 | Train Loss: 0.0091820 Vali Loss: 0.0147064 Test Loss: 0.0192700\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019186770543456078, rmse:0.13851632177829742, mae:0.08384789526462555, rse:0.5358179211616516\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:53.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0269169\n",
      "\tspeed: 0.0525s/iter; left time: 1177.1305s\n",
      "\titers: 200, epoch: 1 | loss: 0.0220217\n",
      "\tspeed: 0.0244s/iter; left time: 543.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0276227 Vali Loss: 0.0292230 Test Loss: 0.0370285\n",
      "Validation loss decreased (inf --> 0.029223).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0149196\n",
      "\tspeed: 0.0560s/iter; left time: 1241.4105s\n",
      "\titers: 200, epoch: 2 | loss: 0.0117432\n",
      "\tspeed: 0.0302s/iter; left time: 666.2404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 225 | Train Loss: 0.0159841 Vali Loss: 0.0176442 Test Loss: 0.0221663\n",
      "Validation loss decreased (0.029223 --> 0.017644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0130947\n",
      "\tspeed: 0.0558s/iter; left time: 1225.4648s\n",
      "\titers: 200, epoch: 3 | loss: 0.0118973\n",
      "\tspeed: 0.0245s/iter; left time: 534.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 225 | Train Loss: 0.0131677 Vali Loss: 0.0168402 Test Loss: 0.0214203\n",
      "Validation loss decreased (0.017644 --> 0.016840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120702\n",
      "\tspeed: 0.0516s/iter; left time: 1120.5532s\n",
      "\titers: 200, epoch: 4 | loss: 0.0153237\n",
      "\tspeed: 0.0275s/iter; left time: 595.6620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.0126011 Vali Loss: 0.0166417 Test Loss: 0.0214589\n",
      "Validation loss decreased (0.016840 --> 0.016642).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0122577\n",
      "\tspeed: 0.0591s/iter; left time: 1271.3524s\n",
      "\titers: 200, epoch: 5 | loss: 0.0114579\n",
      "\tspeed: 0.0310s/iter; left time: 663.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0122536 Vali Loss: 0.0165372 Test Loss: 0.0212060\n",
      "Validation loss decreased (0.016642 --> 0.016537).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0122982\n",
      "\tspeed: 0.0553s/iter; left time: 1177.0684s\n",
      "\titers: 200, epoch: 6 | loss: 0.0108476\n",
      "\tspeed: 0.0239s/iter; left time: 505.1855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0119525 Vali Loss: 0.0163623 Test Loss: 0.0210994\n",
      "Validation loss decreased (0.016537 --> 0.016362).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0103870\n",
      "\tspeed: 0.0535s/iter; left time: 1125.2335s\n",
      "\titers: 200, epoch: 7 | loss: 0.0120801\n",
      "\tspeed: 0.0255s/iter; left time: 534.3685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0116693 Vali Loss: 0.0163048 Test Loss: 0.0210180\n",
      "Validation loss decreased (0.016362 --> 0.016305).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0126737\n",
      "\tspeed: 0.0701s/iter; left time: 1458.8931s\n",
      "\titers: 200, epoch: 8 | loss: 0.0116746\n",
      "\tspeed: 0.0261s/iter; left time: 540.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 225 | Train Loss: 0.0114354 Vali Loss: 0.0161684 Test Loss: 0.0209229\n",
      "Validation loss decreased (0.016305 --> 0.016168).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0114568\n",
      "\tspeed: 0.0590s/iter; left time: 1215.5890s\n",
      "\titers: 200, epoch: 9 | loss: 0.0103613\n",
      "\tspeed: 0.0258s/iter; left time: 528.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0112451 Vali Loss: 0.0162233 Test Loss: 0.0209913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0106115\n",
      "\tspeed: 0.0555s/iter; left time: 1131.7468s\n",
      "\titers: 200, epoch: 10 | loss: 0.0107473\n",
      "\tspeed: 0.0241s/iter; left time: 489.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 225 | Train Loss: 0.0110886 Vali Loss: 0.0161682 Test Loss: 0.0208051\n",
      "Validation loss decreased (0.016168 --> 0.016168).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0095515\n",
      "\tspeed: 0.0610s/iter; left time: 1228.3944s\n",
      "\titers: 200, epoch: 11 | loss: 0.0108994\n",
      "\tspeed: 0.0301s/iter; left time: 604.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 225 | Train Loss: 0.0109432 Vali Loss: 0.0162758 Test Loss: 0.0210103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0102318\n",
      "\tspeed: 0.0624s/iter; left time: 1243.9470s\n",
      "\titers: 200, epoch: 12 | loss: 0.0117106\n",
      "\tspeed: 0.0308s/iter; left time: 611.2043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 225 | Train Loss: 0.0108397 Vali Loss: 0.0163587 Test Loss: 0.0211157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0103174\n",
      "\tspeed: 0.0552s/iter; left time: 1087.1800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0115475\n",
      "\tspeed: 0.0374s/iter; left time: 732.2872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 225 | Train Loss: 0.0107320 Vali Loss: 0.0163240 Test Loss: 0.0209834\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0106057\n",
      "\tspeed: 0.0588s/iter; left time: 1145.3310s\n",
      "\titers: 200, epoch: 14 | loss: 0.0110867\n",
      "\tspeed: 0.0269s/iter; left time: 520.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0106457 Vali Loss: 0.0163372 Test Loss: 0.0208973\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0099765\n",
      "\tspeed: 0.0594s/iter; left time: 1143.2446s\n",
      "\titers: 200, epoch: 15 | loss: 0.0116516\n",
      "\tspeed: 0.0275s/iter; left time: 526.7832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 225 | Train Loss: 0.0105807 Vali Loss: 0.0163443 Test Loss: 0.0209021\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0096081\n",
      "\tspeed: 0.0465s/iter; left time: 885.4802s\n",
      "\titers: 200, epoch: 16 | loss: 0.0116073\n",
      "\tspeed: 0.0250s/iter; left time: 472.4955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0105108 Vali Loss: 0.0164842 Test Loss: 0.0211343\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0115879\n",
      "\tspeed: 0.0568s/iter; left time: 1067.3560s\n",
      "\titers: 200, epoch: 17 | loss: 0.0106102\n",
      "\tspeed: 0.0367s/iter; left time: 685.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 225 | Train Loss: 0.0104455 Vali Loss: 0.0163789 Test Loss: 0.0211149\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0106645\n",
      "\tspeed: 0.0610s/iter; left time: 1133.4480s\n",
      "\titers: 200, epoch: 18 | loss: 0.0108051\n",
      "\tspeed: 0.0297s/iter; left time: 548.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 225 | Train Loss: 0.0103969 Vali Loss: 0.0164130 Test Loss: 0.0211276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0107501\n",
      "\tspeed: 0.0599s/iter; left time: 1098.6225s\n",
      "\titers: 200, epoch: 19 | loss: 0.0097857\n",
      "\tspeed: 0.0263s/iter; left time: 479.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 225 | Train Loss: 0.0103496 Vali Loss: 0.0164557 Test Loss: 0.0210654\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0101434\n",
      "\tspeed: 0.0603s/iter; left time: 1093.2678s\n",
      "\titers: 200, epoch: 20 | loss: 0.0112589\n",
      "\tspeed: 0.0242s/iter; left time: 435.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 225 | Train Loss: 0.0103155 Vali Loss: 0.0165480 Test Loss: 0.0210437\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020805105566978455, rmse:0.14423975348472595, mae:0.08963675051927567, rse:0.5586541891098022\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:00.74s\n",
      "Intermediate time for FR: 00h:11m:02.82s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0430156\n",
      "\tspeed: 0.0542s/iter; left time: 1219.3584s\n",
      "\titers: 200, epoch: 1 | loss: 0.0372121\n",
      "\tspeed: 0.0293s/iter; left time: 655.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0441541 Vali Loss: 0.0310717 Test Loss: 0.0345077\n",
      "Validation loss decreased (inf --> 0.031072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0152964\n",
      "\tspeed: 0.0515s/iter; left time: 1146.2866s\n",
      "\titers: 200, epoch: 2 | loss: 0.0113698\n",
      "\tspeed: 0.0255s/iter; left time: 565.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 226 | Train Loss: 0.0179926 Vali Loss: 0.0115744 Test Loss: 0.0126363\n",
      "Validation loss decreased (0.031072 --> 0.011574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0125631\n",
      "\tspeed: 0.0575s/iter; left time: 1268.2801s\n",
      "\titers: 200, epoch: 3 | loss: 0.0114366\n",
      "\tspeed: 0.0266s/iter; left time: 583.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 226 | Train Loss: 0.0120551 Vali Loss: 0.0104010 Test Loss: 0.0114574\n",
      "Validation loss decreased (0.011574 --> 0.010401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0110885\n",
      "\tspeed: 0.0596s/iter; left time: 1300.6696s\n",
      "\titers: 200, epoch: 4 | loss: 0.0099184\n",
      "\tspeed: 0.0321s/iter; left time: 696.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 226 | Train Loss: 0.0110524 Vali Loss: 0.0100088 Test Loss: 0.0111228\n",
      "Validation loss decreased (0.010401 --> 0.010009).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0098978\n",
      "\tspeed: 0.0611s/iter; left time: 1318.8958s\n",
      "\titers: 200, epoch: 5 | loss: 0.0116828\n",
      "\tspeed: 0.0310s/iter; left time: 666.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0105525 Vali Loss: 0.0096835 Test Loss: 0.0107585\n",
      "Validation loss decreased (0.010009 --> 0.009683).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0114763\n",
      "\tspeed: 0.0553s/iter; left time: 1182.6344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0109357\n",
      "\tspeed: 0.0339s/iter; left time: 721.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.0102527 Vali Loss: 0.0095776 Test Loss: 0.0106026\n",
      "Validation loss decreased (0.009683 --> 0.009578).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0090321\n",
      "\tspeed: 0.0540s/iter; left time: 1142.2472s\n",
      "\titers: 200, epoch: 7 | loss: 0.0095975\n",
      "\tspeed: 0.0292s/iter; left time: 614.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0099702 Vali Loss: 0.0094630 Test Loss: 0.0105136\n",
      "Validation loss decreased (0.009578 --> 0.009463).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0093714\n",
      "\tspeed: 0.0597s/iter; left time: 1247.9077s\n",
      "\titers: 200, epoch: 8 | loss: 0.0081001\n",
      "\tspeed: 0.0391s/iter; left time: 814.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 226 | Train Loss: 0.0097985 Vali Loss: 0.0093102 Test Loss: 0.0103237\n",
      "Validation loss decreased (0.009463 --> 0.009310).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0094263\n",
      "\tspeed: 0.0521s/iter; left time: 1077.9675s\n",
      "\titers: 200, epoch: 9 | loss: 0.0099736\n",
      "\tspeed: 0.0325s/iter; left time: 669.7630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 226 | Train Loss: 0.0096688 Vali Loss: 0.0092797 Test Loss: 0.0102676\n",
      "Validation loss decreased (0.009310 --> 0.009280).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0085524\n",
      "\tspeed: 0.0598s/iter; left time: 1223.3745s\n",
      "\titers: 200, epoch: 10 | loss: 0.0101026\n",
      "\tspeed: 0.0242s/iter; left time: 492.8865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 226 | Train Loss: 0.0095466 Vali Loss: 0.0093089 Test Loss: 0.0102406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0096203\n",
      "\tspeed: 0.0528s/iter; left time: 1068.9342s\n",
      "\titers: 200, epoch: 11 | loss: 0.0088058\n",
      "\tspeed: 0.0258s/iter; left time: 519.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0094569 Vali Loss: 0.0092299 Test Loss: 0.0102465\n",
      "Validation loss decreased (0.009280 --> 0.009230).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0088285\n",
      "\tspeed: 0.0531s/iter; left time: 1062.7348s\n",
      "\titers: 200, epoch: 12 | loss: 0.0094550\n",
      "\tspeed: 0.0307s/iter; left time: 611.8542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0093679 Vali Loss: 0.0092287 Test Loss: 0.0101918\n",
      "Validation loss decreased (0.009230 --> 0.009229).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0094994\n",
      "\tspeed: 0.0581s/iter; left time: 1149.4300s\n",
      "\titers: 200, epoch: 13 | loss: 0.0095642\n",
      "\tspeed: 0.0254s/iter; left time: 499.4905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 226 | Train Loss: 0.0093120 Vali Loss: 0.0091062 Test Loss: 0.0100900\n",
      "Validation loss decreased (0.009229 --> 0.009106).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0090722\n",
      "\tspeed: 0.0507s/iter; left time: 992.2097s\n",
      "\titers: 200, epoch: 14 | loss: 0.0097731\n",
      "\tspeed: 0.0283s/iter; left time: 550.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0092447 Vali Loss: 0.0091206 Test Loss: 0.0100921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0097098\n",
      "\tspeed: 0.0505s/iter; left time: 976.0067s\n",
      "\titers: 200, epoch: 15 | loss: 0.0098209\n",
      "\tspeed: 0.0253s/iter; left time: 487.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 226 | Train Loss: 0.0091855 Vali Loss: 0.0090958 Test Loss: 0.0100805\n",
      "Validation loss decreased (0.009106 --> 0.009096).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0091442\n",
      "\tspeed: 0.0566s/iter; left time: 1081.6922s\n",
      "\titers: 200, epoch: 16 | loss: 0.0073901\n",
      "\tspeed: 0.0308s/iter; left time: 585.8950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0091526 Vali Loss: 0.0091489 Test Loss: 0.0100649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0086832\n",
      "\tspeed: 0.0500s/iter; left time: 943.4212s\n",
      "\titers: 200, epoch: 17 | loss: 0.0081065\n",
      "\tspeed: 0.0297s/iter; left time: 557.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 226 | Train Loss: 0.0091120 Vali Loss: 0.0090676 Test Loss: 0.0100418\n",
      "Validation loss decreased (0.009096 --> 0.009068).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0089915\n",
      "\tspeed: 0.0553s/iter; left time: 1031.9393s\n",
      "\titers: 200, epoch: 18 | loss: 0.0104773\n",
      "\tspeed: 0.0270s/iter; left time: 500.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 226 | Train Loss: 0.0090761 Vali Loss: 0.0090888 Test Loss: 0.0100091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0087572\n",
      "\tspeed: 0.0504s/iter; left time: 929.6214s\n",
      "\titers: 200, epoch: 19 | loss: 0.0087940\n",
      "\tspeed: 0.0245s/iter; left time: 448.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 226 | Train Loss: 0.0090523 Vali Loss: 0.0090600 Test Loss: 0.0100221\n",
      "Validation loss decreased (0.009068 --> 0.009060).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0086708\n",
      "\tspeed: 0.0492s/iter; left time: 896.2677s\n",
      "\titers: 200, epoch: 20 | loss: 0.0089390\n",
      "\tspeed: 0.0255s/iter; left time: 462.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 226 | Train Loss: 0.0090191 Vali Loss: 0.0090712 Test Loss: 0.0099884\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0102910\n",
      "\tspeed: 0.0480s/iter; left time: 863.6423s\n",
      "\titers: 200, epoch: 21 | loss: 0.0078968\n",
      "\tspeed: 0.0260s/iter; left time: 465.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.0089772 Vali Loss: 0.0090484 Test Loss: 0.0099763\n",
      "Validation loss decreased (0.009060 --> 0.009048).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0083771\n",
      "\tspeed: 0.0547s/iter; left time: 971.6334s\n",
      "\titers: 200, epoch: 22 | loss: 0.0077762\n",
      "\tspeed: 0.0240s/iter; left time: 423.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0089653 Vali Loss: 0.0090280 Test Loss: 0.0099728\n",
      "Validation loss decreased (0.009048 --> 0.009028).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0089312\n",
      "\tspeed: 0.0583s/iter; left time: 1022.5282s\n",
      "\titers: 200, epoch: 23 | loss: 0.0089807\n",
      "\tspeed: 0.0264s/iter; left time: 459.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 226 | Train Loss: 0.0089423 Vali Loss: 0.0090344 Test Loss: 0.0099611\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0078890\n",
      "\tspeed: 0.0566s/iter; left time: 978.6115s\n",
      "\titers: 200, epoch: 24 | loss: 0.0085228\n",
      "\tspeed: 0.0320s/iter; left time: 550.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0089327 Vali Loss: 0.0090320 Test Loss: 0.0099370\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0097201\n",
      "\tspeed: 0.0547s/iter; left time: 934.0444s\n",
      "\titers: 200, epoch: 25 | loss: 0.0089450\n",
      "\tspeed: 0.0244s/iter; left time: 414.1116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0089084 Vali Loss: 0.0090175 Test Loss: 0.0099251\n",
      "Validation loss decreased (0.009028 --> 0.009017).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0097886\n",
      "\tspeed: 0.0583s/iter; left time: 982.0724s\n",
      "\titers: 200, epoch: 26 | loss: 0.0076452\n",
      "\tspeed: 0.0284s/iter; left time: 476.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 226 | Train Loss: 0.0089052 Vali Loss: 0.0090332 Test Loss: 0.0099195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0091809\n",
      "\tspeed: 0.0491s/iter; left time: 817.0285s\n",
      "\titers: 200, epoch: 27 | loss: 0.0093014\n",
      "\tspeed: 0.0246s/iter; left time: 405.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0088916 Vali Loss: 0.0090062 Test Loss: 0.0099227\n",
      "Validation loss decreased (0.009017 --> 0.009006).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0083350\n",
      "\tspeed: 0.0564s/iter; left time: 925.2712s\n",
      "\titers: 200, epoch: 28 | loss: 0.0081989\n",
      "\tspeed: 0.0256s/iter; left time: 418.0152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0088817 Vali Loss: 0.0090501 Test Loss: 0.0099505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0090654\n",
      "\tspeed: 0.0501s/iter; left time: 810.3152s\n",
      "\titers: 200, epoch: 29 | loss: 0.0101934\n",
      "\tspeed: 0.0266s/iter; left time: 427.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 226 | Train Loss: 0.0088651 Vali Loss: 0.0090426 Test Loss: 0.0099366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0100033\n",
      "\tspeed: 0.0529s/iter; left time: 843.7943s\n",
      "\titers: 200, epoch: 30 | loss: 0.0091661\n",
      "\tspeed: 0.0236s/iter; left time: 374.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 226 | Train Loss: 0.0088670 Vali Loss: 0.0090467 Test Loss: 0.0099255\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0078916\n",
      "\tspeed: 0.0529s/iter; left time: 832.2571s\n",
      "\titers: 200, epoch: 31 | loss: 0.0098773\n",
      "\tspeed: 0.0276s/iter; left time: 430.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0088527 Vali Loss: 0.0090145 Test Loss: 0.0099058\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0085965\n",
      "\tspeed: 0.0513s/iter; left time: 794.7831s\n",
      "\titers: 200, epoch: 32 | loss: 0.0095884\n",
      "\tspeed: 0.0244s/iter; left time: 375.5542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0088357 Vali Loss: 0.0090503 Test Loss: 0.0099251\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0078262\n",
      "\tspeed: 0.0540s/iter; left time: 824.3251s\n",
      "\titers: 200, epoch: 33 | loss: 0.0090609\n",
      "\tspeed: 0.0273s/iter; left time: 414.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0088254 Vali Loss: 0.0090212 Test Loss: 0.0099334\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0095772\n",
      "\tspeed: 0.0596s/iter; left time: 896.4411s\n",
      "\titers: 200, epoch: 34 | loss: 0.0093180\n",
      "\tspeed: 0.0309s/iter; left time: 461.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 226 | Train Loss: 0.0088139 Vali Loss: 0.0090119 Test Loss: 0.0099190\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0089763\n",
      "\tspeed: 0.0459s/iter; left time: 680.6396s\n",
      "\titers: 200, epoch: 35 | loss: 0.0093619\n",
      "\tspeed: 0.0242s/iter; left time: 355.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0088183 Vali Loss: 0.0090063 Test Loss: 0.0099132\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0080900\n",
      "\tspeed: 0.0515s/iter; left time: 750.9620s\n",
      "\titers: 200, epoch: 36 | loss: 0.0077684\n",
      "\tspeed: 0.0273s/iter; left time: 396.2352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0088260 Vali Loss: 0.0090389 Test Loss: 0.0099133\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0091542\n",
      "\tspeed: 0.0482s/iter; left time: 692.9952s\n",
      "\titers: 200, epoch: 37 | loss: 0.0082184\n",
      "\tspeed: 0.0232s/iter; left time: 330.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 226 | Train Loss: 0.0088172 Vali Loss: 0.0090156 Test Loss: 0.0099207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009922743774950504, rmse:0.09961297363042831, mae:0.05834198370575905, rse:0.3763883709907532\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:12.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0478222\n",
      "\tspeed: 0.0504s/iter; left time: 1128.4772s\n",
      "\titers: 200, epoch: 1 | loss: 0.0381344\n",
      "\tspeed: 0.0344s/iter; left time: 766.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 225 | Train Loss: 0.0474403 Vali Loss: 0.0352382 Test Loss: 0.0391712\n",
      "Validation loss decreased (inf --> 0.035238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0253392\n",
      "\tspeed: 0.0644s/iter; left time: 1427.8207s\n",
      "\titers: 200, epoch: 2 | loss: 0.0213449\n",
      "\tspeed: 0.0344s/iter; left time: 759.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 225 | Train Loss: 0.0254757 Vali Loss: 0.0179431 Test Loss: 0.0199769\n",
      "Validation loss decreased (0.035238 --> 0.017943).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0204113\n",
      "\tspeed: 0.0595s/iter; left time: 1305.1059s\n",
      "\titers: 200, epoch: 3 | loss: 0.0188128\n",
      "\tspeed: 0.0384s/iter; left time: 838.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 225 | Train Loss: 0.0195972 Vali Loss: 0.0166414 Test Loss: 0.0186526\n",
      "Validation loss decreased (0.017943 --> 0.016641).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0188461\n",
      "\tspeed: 0.0688s/iter; left time: 1494.3791s\n",
      "\titers: 200, epoch: 4 | loss: 0.0188044\n",
      "\tspeed: 0.0381s/iter; left time: 823.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 225 | Train Loss: 0.0185892 Vali Loss: 0.0163968 Test Loss: 0.0184007\n",
      "Validation loss decreased (0.016641 --> 0.016397).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0179484\n",
      "\tspeed: 0.0653s/iter; left time: 1402.9415s\n",
      "\titers: 200, epoch: 5 | loss: 0.0178978\n",
      "\tspeed: 0.0309s/iter; left time: 661.3506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 225 | Train Loss: 0.0180306 Vali Loss: 0.0161476 Test Loss: 0.0181733\n",
      "Validation loss decreased (0.016397 --> 0.016148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0198851\n",
      "\tspeed: 0.0607s/iter; left time: 1290.9299s\n",
      "\titers: 200, epoch: 6 | loss: 0.0186755\n",
      "\tspeed: 0.0389s/iter; left time: 823.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 225 | Train Loss: 0.0176643 Vali Loss: 0.0160395 Test Loss: 0.0180845\n",
      "Validation loss decreased (0.016148 --> 0.016040).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0174389\n",
      "\tspeed: 0.0582s/iter; left time: 1224.4866s\n",
      "\titers: 200, epoch: 7 | loss: 0.0180951\n",
      "\tspeed: 0.0243s/iter; left time: 509.7486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0173723 Vali Loss: 0.0158992 Test Loss: 0.0178840\n",
      "Validation loss decreased (0.016040 --> 0.015899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0174347\n",
      "\tspeed: 0.0541s/iter; left time: 1126.1975s\n",
      "\titers: 200, epoch: 8 | loss: 0.0167886\n",
      "\tspeed: 0.0322s/iter; left time: 666.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 225 | Train Loss: 0.0171305 Vali Loss: 0.0158986 Test Loss: 0.0178638\n",
      "Validation loss decreased (0.015899 --> 0.015899).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0182739\n",
      "\tspeed: 0.0615s/iter; left time: 1266.8376s\n",
      "\titers: 200, epoch: 9 | loss: 0.0169673\n",
      "\tspeed: 0.0300s/iter; left time: 615.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 225 | Train Loss: 0.0169175 Vali Loss: 0.0158338 Test Loss: 0.0178399\n",
      "Validation loss decreased (0.015899 --> 0.015834).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0168277\n",
      "\tspeed: 0.0633s/iter; left time: 1289.8898s\n",
      "\titers: 200, epoch: 10 | loss: 0.0179330\n",
      "\tspeed: 0.0273s/iter; left time: 553.6355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 225 | Train Loss: 0.0167715 Vali Loss: 0.0157845 Test Loss: 0.0177933\n",
      "Validation loss decreased (0.015834 --> 0.015784).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0163170\n",
      "\tspeed: 0.0645s/iter; left time: 1299.0787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0163759\n",
      "\tspeed: 0.0258s/iter; left time: 516.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 225 | Train Loss: 0.0166167 Vali Loss: 0.0157842 Test Loss: 0.0178167\n",
      "Validation loss decreased (0.015784 --> 0.015784).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0151263\n",
      "\tspeed: 0.0646s/iter; left time: 1286.8668s\n",
      "\titers: 200, epoch: 12 | loss: 0.0166397\n",
      "\tspeed: 0.0265s/iter; left time: 524.7317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 225 | Train Loss: 0.0165070 Vali Loss: 0.0157736 Test Loss: 0.0178441\n",
      "Validation loss decreased (0.015784 --> 0.015774).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0164019\n",
      "\tspeed: 0.0620s/iter; left time: 1221.5179s\n",
      "\titers: 200, epoch: 13 | loss: 0.0159479\n",
      "\tspeed: 0.0319s/iter; left time: 625.8896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 225 | Train Loss: 0.0163756 Vali Loss: 0.0157088 Test Loss: 0.0178032\n",
      "Validation loss decreased (0.015774 --> 0.015709).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0154372\n",
      "\tspeed: 0.0603s/iter; left time: 1173.8247s\n",
      "\titers: 200, epoch: 14 | loss: 0.0160886\n",
      "\tspeed: 0.0308s/iter; left time: 596.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 225 | Train Loss: 0.0162828 Vali Loss: 0.0158301 Test Loss: 0.0179277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0154287\n",
      "\tspeed: 0.0599s/iter; left time: 1154.0704s\n",
      "\titers: 200, epoch: 15 | loss: 0.0153177\n",
      "\tspeed: 0.0334s/iter; left time: 638.7949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 225 | Train Loss: 0.0161906 Vali Loss: 0.0157809 Test Loss: 0.0179186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0172052\n",
      "\tspeed: 0.0558s/iter; left time: 1061.0893s\n",
      "\titers: 200, epoch: 16 | loss: 0.0152363\n",
      "\tspeed: 0.0263s/iter; left time: 497.8089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 225 | Train Loss: 0.0161114 Vali Loss: 0.0158190 Test Loss: 0.0179464\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0186068\n",
      "\tspeed: 0.0673s/iter; left time: 1266.2018s\n",
      "\titers: 200, epoch: 17 | loss: 0.0161077\n",
      "\tspeed: 0.0351s/iter; left time: 656.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 225 | Train Loss: 0.0160482 Vali Loss: 0.0158060 Test Loss: 0.0179885\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0147823\n",
      "\tspeed: 0.0538s/iter; left time: 1000.1613s\n",
      "\titers: 200, epoch: 18 | loss: 0.0150528\n",
      "\tspeed: 0.0307s/iter; left time: 567.6914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0159649 Vali Loss: 0.0157838 Test Loss: 0.0179825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0155928\n",
      "\tspeed: 0.0593s/iter; left time: 1088.2279s\n",
      "\titers: 200, epoch: 19 | loss: 0.0147181\n",
      "\tspeed: 0.0312s/iter; left time: 569.2792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 225 | Train Loss: 0.0159203 Vali Loss: 0.0158155 Test Loss: 0.0180364\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0158121\n",
      "\tspeed: 0.0637s/iter; left time: 1155.4831s\n",
      "\titers: 200, epoch: 20 | loss: 0.0156867\n",
      "\tspeed: 0.0345s/iter; left time: 622.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 225 | Train Loss: 0.0158178 Vali Loss: 0.0158000 Test Loss: 0.0179819\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0155895\n",
      "\tspeed: 0.0548s/iter; left time: 980.2308s\n",
      "\titers: 200, epoch: 21 | loss: 0.0158620\n",
      "\tspeed: 0.0289s/iter; left time: 515.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0157976 Vali Loss: 0.0157882 Test Loss: 0.0180150\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0161253\n",
      "\tspeed: 0.0623s/iter; left time: 1100.6162s\n",
      "\titers: 200, epoch: 22 | loss: 0.0149056\n",
      "\tspeed: 0.0300s/iter; left time: 526.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 225 | Train Loss: 0.0157508 Vali Loss: 0.0158112 Test Loss: 0.0180414\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0168003\n",
      "\tspeed: 0.0554s/iter; left time: 966.6790s\n",
      "\titers: 200, epoch: 23 | loss: 0.0160291\n",
      "\tspeed: 0.0355s/iter; left time: 615.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 225 | Train Loss: 0.0157218 Vali Loss: 0.0158285 Test Loss: 0.0180852\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017803212627768517, rmse:0.1334286779165268, mae:0.08180394023656845, rse:0.5045081973075867\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:42.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ts_decomp_IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ts_decomp_IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0506961\n",
      "\tspeed: 0.0676s/iter; left time: 1514.8791s\n",
      "\titers: 200, epoch: 1 | loss: 0.0434178\n",
      "\tspeed: 0.0344s/iter; left time: 768.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 225 | Train Loss: 0.0503334 Vali Loss: 0.0368931 Test Loss: 0.0408223\n",
      "Validation loss decreased (inf --> 0.036893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0257164\n",
      "\tspeed: 0.0888s/iter; left time: 1970.1584s\n",
      "\titers: 200, epoch: 2 | loss: 0.0217644\n",
      "\tspeed: 0.0489s/iter; left time: 1080.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.16s\n",
      "Steps: 225 | Train Loss: 0.0272302 Vali Loss: 0.0194705 Test Loss: 0.0210699\n",
      "Validation loss decreased (0.036893 --> 0.019471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0223614\n",
      "\tspeed: 0.0886s/iter; left time: 1945.3772s\n",
      "\titers: 200, epoch: 3 | loss: 0.0198506\n",
      "\tspeed: 0.0486s/iter; left time: 1062.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.21s\n",
      "Steps: 225 | Train Loss: 0.0215152 Vali Loss: 0.0184542 Test Loss: 0.0200383\n",
      "Validation loss decreased (0.019471 --> 0.018454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0190125\n",
      "\tspeed: 0.0902s/iter; left time: 1959.1852s\n",
      "\titers: 200, epoch: 4 | loss: 0.0211241\n",
      "\tspeed: 0.0493s/iter; left time: 1065.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.31s\n",
      "Steps: 225 | Train Loss: 0.0204801 Vali Loss: 0.0180584 Test Loss: 0.0196614\n",
      "Validation loss decreased (0.018454 --> 0.018058).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0185759\n",
      "\tspeed: 0.0885s/iter; left time: 1902.8078s\n",
      "\titers: 200, epoch: 5 | loss: 0.0203622\n",
      "\tspeed: 0.0486s/iter; left time: 1040.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 225 | Train Loss: 0.0198778 Vali Loss: 0.0178510 Test Loss: 0.0194241\n",
      "Validation loss decreased (0.018058 --> 0.017851).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0208315\n",
      "\tspeed: 0.0883s/iter; left time: 1879.2563s\n",
      "\titers: 200, epoch: 6 | loss: 0.0172729\n",
      "\tspeed: 0.0481s/iter; left time: 1017.8850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.11s\n",
      "Steps: 225 | Train Loss: 0.0194679 Vali Loss: 0.0177488 Test Loss: 0.0192593\n",
      "Validation loss decreased (0.017851 --> 0.017749).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0172482\n",
      "\tspeed: 0.0869s/iter; left time: 1829.4538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0186308\n",
      "\tspeed: 0.0483s/iter; left time: 1012.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.97s\n",
      "Steps: 225 | Train Loss: 0.0191360 Vali Loss: 0.0177661 Test Loss: 0.0191440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0193071\n",
      "\tspeed: 0.0871s/iter; left time: 1814.1306s\n",
      "\titers: 200, epoch: 8 | loss: 0.0185706\n",
      "\tspeed: 0.0471s/iter; left time: 976.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.97s\n",
      "Steps: 225 | Train Loss: 0.0189352 Vali Loss: 0.0177398 Test Loss: 0.0190398\n",
      "Validation loss decreased (0.017749 --> 0.017740).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0183653\n",
      "\tspeed: 0.0858s/iter; left time: 1767.1173s\n",
      "\titers: 200, epoch: 9 | loss: 0.0181597\n",
      "\tspeed: 0.0474s/iter; left time: 972.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.03s\n",
      "Steps: 225 | Train Loss: 0.0187318 Vali Loss: 0.0178138 Test Loss: 0.0190202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0187022\n",
      "\tspeed: 0.0872s/iter; left time: 1776.6623s\n",
      "\titers: 200, epoch: 10 | loss: 0.0177875\n",
      "\tspeed: 0.0482s/iter; left time: 976.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.10s\n",
      "Steps: 225 | Train Loss: 0.0185414 Vali Loss: 0.0178180 Test Loss: 0.0189794\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0175327\n",
      "\tspeed: 0.0856s/iter; left time: 1725.4260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0181863\n",
      "\tspeed: 0.0488s/iter; left time: 977.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.15s\n",
      "Steps: 225 | Train Loss: 0.0183754 Vali Loss: 0.0177803 Test Loss: 0.0190018\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0174661\n",
      "\tspeed: 0.0874s/iter; left time: 1741.2727s\n",
      "\titers: 200, epoch: 12 | loss: 0.0184091\n",
      "\tspeed: 0.0480s/iter; left time: 950.8208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.11s\n",
      "Steps: 225 | Train Loss: 0.0182399 Vali Loss: 0.0178374 Test Loss: 0.0189758\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0181057\n",
      "\tspeed: 0.0844s/iter; left time: 1663.4012s\n",
      "\titers: 200, epoch: 13 | loss: 0.0172303\n",
      "\tspeed: 0.0485s/iter; left time: 949.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.08s\n",
      "Steps: 225 | Train Loss: 0.0180831 Vali Loss: 0.0178951 Test Loss: 0.0190489\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0180981\n",
      "\tspeed: 0.0875s/iter; left time: 1703.5181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0179996\n",
      "\tspeed: 0.0483s/iter; left time: 935.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.04s\n",
      "Steps: 225 | Train Loss: 0.0179621 Vali Loss: 0.0179250 Test Loss: 0.0190570\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0168550\n",
      "\tspeed: 0.0876s/iter; left time: 1687.2333s\n",
      "\titers: 200, epoch: 15 | loss: 0.0188148\n",
      "\tspeed: 0.0477s/iter; left time: 913.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.08s\n",
      "Steps: 225 | Train Loss: 0.0178600 Vali Loss: 0.0180246 Test Loss: 0.0190814\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0184088\n",
      "\tspeed: 0.0878s/iter; left time: 1670.6955s\n",
      "\titers: 200, epoch: 16 | loss: 0.0172866\n",
      "\tspeed: 0.0479s/iter; left time: 907.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.13s\n",
      "Steps: 225 | Train Loss: 0.0177449 Vali Loss: 0.0178746 Test Loss: 0.0191260\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0191272\n",
      "\tspeed: 0.0876s/iter; left time: 1646.0430s\n",
      "\titers: 200, epoch: 17 | loss: 0.0176109\n",
      "\tspeed: 0.0475s/iter; left time: 889.1229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.01s\n",
      "Steps: 225 | Train Loss: 0.0176496 Vali Loss: 0.0180301 Test Loss: 0.0191746\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0176716\n",
      "\tspeed: 0.0869s/iter; left time: 1613.4237s\n",
      "\titers: 200, epoch: 18 | loss: 0.0185039\n",
      "\tspeed: 0.0480s/iter; left time: 886.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.06s\n",
      "Steps: 225 | Train Loss: 0.0175396 Vali Loss: 0.0180294 Test Loss: 0.0192170\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ts_decomp_IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019039802253246307, rmse:0.13798479735851288, mae:0.08742713183164597, rse:0.5222201943397522\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:13.33s\n",
      "Intermediate time for IT: 00h:13m:08.68s\n",
      "Total time: 00h:24m:11.50s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == \"DE\" and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "                \n",
    "            model_id = f\"ts_decomp_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'FR',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.009935157373547554,\n",
       "  'RMSE': 0.0996752604842186,\n",
       "  'MAE': 0.056855376809835434},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.019186770543456078,\n",
       "  'RMSE': 0.13851632177829742,\n",
       "  'MAE': 0.08384789526462555},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.020805105566978455,\n",
       "  'RMSE': 0.14423975348472595,\n",
       "  'MAE': 0.08963675051927567},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.009922743774950504,\n",
       "  'RMSE': 0.09961297363042831,\n",
       "  'MAE': 0.05834198370575905},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.017803212627768517,\n",
       "  'RMSE': 0.1334286779165268,\n",
       "  'MAE': 0.08180394023656845},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.019039802253246307,\n",
       "  'RMSE': 0.13798479735851288,\n",
       "  'MAE': 0.08742713183164597}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.0852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1458  0.0891\n",
       "        96              0.0356  0.1887  0.1254\n",
       "        168             0.0380  0.1950  0.1324\n",
       "ES      24              0.0098  0.0991  0.0595\n",
       "        96              0.0186  0.1364  0.0868\n",
       "        168             0.0212  0.1455  0.0953\n",
       "FR      24              0.0099  0.0995  0.0542\n",
       "        96              0.0192  0.1385  0.0795\n",
       "        168             0.0207  0.1439  0.0857\n",
       "GB      24              0.0257  0.1603  0.1023\n",
       "        96              0.0442  0.2103  0.1428\n",
       "        168             0.0447  0.2114  0.1468\n",
       "IT      24              0.0101  0.1005  0.0569\n",
       "        96              0.0183  0.1353  0.0796\n",
       "        168             0.0199  0.1412  0.0852"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DE 24 Scaled mse:0.021180348470807076, rmse:0.1455346941947937, mae:0.09210523962974548, rse:0.5136120915412903\n",
    "#DE 96 Scaled mse:0.034971993416547775, rmse:0.18700800836086273, mae:0.12845256924629211, rse:0.6622331142425537\n",
    "# DE 168 Scaled mse:0.0376378670334816, rmse:0.1940048187971115, mae:0.1373552680015564, rse:0.6871806383132935\n",
    "# GB 24 Scaled mse:0.025741200894117355, rmse:0.16044063866138458, mae:0.10560756176710129, rse:0.5534747242927551\n",
    "# GB 96 Scaled mse:0.04417259246110916, rmse:0.21017277240753174, mae:0.1458372175693512, rse:0.7268067598342896\n",
    "# GB 168 Scaled mse:0.043342988938093185, rmse:0.20818978548049927, mae:0.14809077978134155, rse:0.7218239307403564\n",
    "# ES 24 Scaled mse:0.009966684505343437, rmse:0.09983327984809875, mae:0.06222286447882652, rse:0.2937972843647003\n",
    "# ES 96 Scaled mse:0.01854102313518524, rmse:0.13616542518138885, mae:0.09016308933496475, rse:0.4000130295753479\n",
    "# ES 168 Scaled mse:0.020919350907206535, rmse:0.14463523030281067, mae:0.09668708592653275, rse:0.424925297498703\n",
    "# FR 24 Scaled mse:0.009935157373547554, rmse:0.0996752604842186, mae:0.056855376809835434, rse:0.38454437255859375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [    {        'Country': 'DE',        \n",
    "                         'Pred_len': 24,       \n",
    "                           'Iteration': 1,        \n",
    "                           'MSE': 0.021180348470807076,        \n",
    "                           'RMSE': 0.1455346941947937,        \n",
    "                           'MAE': 0.09210523962974548    },    \n",
    "                           {        'Country': 'DE',        \n",
    "                            'Pred_len': 96,        \n",
    "                            'Iteration': 1,        \n",
    "                            'MSE': 0.034971993416547775,        \n",
    "                            'RMSE': 0.18700800836086273,        \n",
    "                            'MAE': 0.12845256924629211    },    \n",
    "                            {        'Country': 'DE',        \n",
    "                             'Pred_len': 168,        \n",
    "                             'Iteration': 1,        \n",
    "                             'MSE': 0.0376378670334816,        \n",
    "                             'RMSE': 0.1940048187971115,        \n",
    "                             'MAE': 0.1373552680015564    },    \n",
    "                             {        'Country': 'GB',        \n",
    "                              'Pred_len': 24,        \n",
    "                              'Iteration': 1,        \n",
    "                              'MSE': 0.025741200894117355,        \n",
    "                              'RMSE': 0.16044063866138458,        \n",
    "                              'MAE': 0.10560756176710129    },    \n",
    "                              {        'Country': 'GB',        \n",
    "                               'Pred_len': 96,        \n",
    "                               'Iteration': 1,        \n",
    "                               'MSE': 0.04417259246110916,        \n",
    "                               'RMSE': 0.21017277240753174,        \n",
    "                               'MAE': 0.1458372175693512    },    \n",
    "                               {        'Country': 'GB',        \n",
    "                                'Pred_len': 168,        \n",
    "                                'Iteration': 1,        \n",
    "                                'MSE': 0.043342988938093185,        \n",
    "                                'RMSE': 0.20818978548049927,        \n",
    "                                'MAE': 0.14809077978134155    },    \n",
    "                                {        'Country': 'ES',        \n",
    "                                 'Pred_len': 24,        \n",
    "                                 'Iteration': 1,        \n",
    "                                 'MSE': 0.009966684505343437,        \n",
    "                                 'RMSE': 0.09983327984809875,        \n",
    "                                 'MAE': 0.06222286447882652    },    \n",
    "                                 {        'Country': 'ES',        \n",
    "                                  'Pred_len': 96,        \n",
    "                                  'Iteration': 1,        \n",
    "                                  'MSE': 0.01854102313518524,        \n",
    "                                  'RMSE': 0.13616542518138885,        \n",
    "                                  'MAE': 0.09016308933496475    },    \n",
    "                                  {        'Country': 'ES',        \n",
    "                                   'Pred_len': 168,        \n",
    "                                   'Iteration': 1,        \n",
    "                                   'MSE': 0.020919350907206535,        \n",
    "                                   'RMSE': 0.14463523030281067,        \n",
    "                                   'MAE': 0.09668708592653275    },    \n",
    "                                   {        'Country': 'FR',        \n",
    "                                    'Pred_len': 24,        \n",
    "                                    'Iteration': 1,        \n",
    "                                    'MSE': 0.009935157373547554,        \n",
    "                                    'RMSE': 0.0996752604842186,        \n",
    "                                    'MAE': 0.056855376809835434    },\n",
    "                                    {'Country': 'FR',\n",
    "  'Pred_len': 96,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.019186770543456078,\n",
    "  'RMSE': 0.13851632177829742,\n",
    "  'MAE': 0.08384789526462555},\n",
    " {'Country': 'FR',\n",
    "  'Pred_len': 168,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.020805105566978455,\n",
    "  'RMSE': 0.14423975348472595,\n",
    "  'MAE': 0.08963675051927567},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 24,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.009922743774950504,\n",
    "  'RMSE': 0.09961297363042831,\n",
    "  'MAE': 0.05834198370575905},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 96,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.017803212627768517,\n",
    "  'RMSE': 0.1334286779165268,\n",
    "  'MAE': 0.08180394023656845},\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 168,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.019039802253246307,\n",
    "  'RMSE': 0.13798479735851288,\n",
    "  'MAE': 0.08742713183164597}]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
