{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No ReVIN no series decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"PatchTST\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0727204\n",
      "\tspeed: 0.0755s/iter; left time: 666.4886s\n",
      "\titers: 200, epoch: 1 | loss: 0.0688743\n",
      "\tspeed: 0.0498s/iter; left time: 434.4627s\n",
      "\titers: 300, epoch: 1 | loss: 0.0516021\n",
      "\tspeed: 0.0497s/iter; left time: 428.7006s\n",
      "\titers: 400, epoch: 1 | loss: 0.0495072\n",
      "\tspeed: 0.0502s/iter; left time: 428.0484s\n",
      "\titers: 500, epoch: 1 | loss: 0.0437808\n",
      "\tspeed: 0.0506s/iter; left time: 426.4952s\n",
      "\titers: 600, epoch: 1 | loss: 0.0428931\n",
      "\tspeed: 0.0502s/iter; left time: 418.2723s\n",
      "\titers: 700, epoch: 1 | loss: 0.0320932\n",
      "\tspeed: 0.0504s/iter; left time: 414.9536s\n",
      "\titers: 800, epoch: 1 | loss: 0.0331783\n",
      "\tspeed: 0.0516s/iter; left time: 419.7538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.46s\n",
      "Steps: 893 | Train Loss: 0.0498004 Vali Loss: 0.0255448 Test Loss: 0.0280030\n",
      "Validation loss decreased (inf --> 0.025545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0378902\n",
      "\tspeed: 0.1897s/iter; left time: 1505.8408s\n",
      "\titers: 200, epoch: 2 | loss: 0.0240782\n",
      "\tspeed: 0.0503s/iter; left time: 394.6369s\n",
      "\titers: 300, epoch: 2 | loss: 0.0178593\n",
      "\tspeed: 0.0511s/iter; left time: 395.6664s\n",
      "\titers: 400, epoch: 2 | loss: 0.0178865\n",
      "\tspeed: 0.0501s/iter; left time: 382.7045s\n",
      "\titers: 500, epoch: 2 | loss: 0.0165037\n",
      "\tspeed: 0.0502s/iter; left time: 378.3116s\n",
      "\titers: 600, epoch: 2 | loss: 0.0245665\n",
      "\tspeed: 0.0517s/iter; left time: 384.2986s\n",
      "\titers: 700, epoch: 2 | loss: 0.0180247\n",
      "\tspeed: 0.0505s/iter; left time: 370.3997s\n",
      "\titers: 800, epoch: 2 | loss: 0.0134593\n",
      "\tspeed: 0.0525s/iter; left time: 380.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 893 | Train Loss: 0.0221958 Vali Loss: 0.0241549 Test Loss: 0.0266339\n",
      "Validation loss decreased (0.025545 --> 0.024155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0108618\n",
      "\tspeed: 0.1850s/iter; left time: 1303.6733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0185118\n",
      "\tspeed: 0.0496s/iter; left time: 344.3685s\n",
      "\titers: 300, epoch: 3 | loss: 0.0139210\n",
      "\tspeed: 0.0515s/iter; left time: 352.4307s\n",
      "\titers: 400, epoch: 3 | loss: 0.0183757\n",
      "\tspeed: 0.0516s/iter; left time: 347.8122s\n",
      "\titers: 500, epoch: 3 | loss: 0.0199568\n",
      "\tspeed: 0.0514s/iter; left time: 341.4129s\n",
      "\titers: 600, epoch: 3 | loss: 0.0196962\n",
      "\tspeed: 0.0510s/iter; left time: 333.5654s\n",
      "\titers: 700, epoch: 3 | loss: 0.0111249\n",
      "\tspeed: 0.0511s/iter; left time: 329.0669s\n",
      "\titers: 800, epoch: 3 | loss: 0.0217283\n",
      "\tspeed: 0.0508s/iter; left time: 322.0530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 893 | Train Loss: 0.0193541 Vali Loss: 0.0226646 Test Loss: 0.0250265\n",
      "Validation loss decreased (0.024155 --> 0.022665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1591274\n",
      "\tspeed: 0.1847s/iter; left time: 1136.4781s\n",
      "\titers: 200, epoch: 4 | loss: 0.0155019\n",
      "\tspeed: 0.0509s/iter; left time: 307.9337s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206544\n",
      "\tspeed: 0.0509s/iter; left time: 302.7136s\n",
      "\titers: 400, epoch: 4 | loss: 0.0134120\n",
      "\tspeed: 0.0504s/iter; left time: 294.9777s\n",
      "\titers: 500, epoch: 4 | loss: 0.0228675\n",
      "\tspeed: 0.0506s/iter; left time: 291.0844s\n",
      "\titers: 600, epoch: 4 | loss: 0.0164165\n",
      "\tspeed: 0.0508s/iter; left time: 287.1375s\n",
      "\titers: 700, epoch: 4 | loss: 0.0154799\n",
      "\tspeed: 0.0512s/iter; left time: 284.0564s\n",
      "\titers: 800, epoch: 4 | loss: 0.0180907\n",
      "\tspeed: 0.0509s/iter; left time: 277.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.0289833 Vali Loss: 0.0553275 Test Loss: 0.0681509\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0187819\n",
      "\tspeed: 0.1835s/iter; left time: 965.2240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0430803\n",
      "\tspeed: 0.0509s/iter; left time: 262.6663s\n",
      "\titers: 300, epoch: 5 | loss: 0.0201250\n",
      "\tspeed: 0.0509s/iter; left time: 257.5518s\n",
      "\titers: 400, epoch: 5 | loss: 0.0188826\n",
      "\tspeed: 0.0507s/iter; left time: 251.1893s\n",
      "\titers: 500, epoch: 5 | loss: 0.0267068\n",
      "\tspeed: 0.0512s/iter; left time: 248.9562s\n",
      "\titers: 600, epoch: 5 | loss: 0.0236914\n",
      "\tspeed: 0.0515s/iter; left time: 244.9967s\n",
      "\titers: 700, epoch: 5 | loss: 0.0185285\n",
      "\tspeed: 0.0505s/iter; left time: 235.4112s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150043\n",
      "\tspeed: 0.0511s/iter; left time: 232.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 893 | Train Loss: 0.0254915 Vali Loss: 0.0233504 Test Loss: 0.0246644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0215895\n",
      "\tspeed: 0.1817s/iter; left time: 793.4856s\n",
      "\titers: 200, epoch: 6 | loss: 0.0187316\n",
      "\tspeed: 0.0512s/iter; left time: 218.3103s\n",
      "\titers: 300, epoch: 6 | loss: 0.0133694\n",
      "\tspeed: 0.0510s/iter; left time: 212.6339s\n",
      "\titers: 400, epoch: 6 | loss: 0.0100682\n",
      "\tspeed: 0.0505s/iter; left time: 205.2759s\n",
      "\titers: 500, epoch: 6 | loss: 0.0133072\n",
      "\tspeed: 0.0503s/iter; left time: 199.3034s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144815\n",
      "\tspeed: 0.0512s/iter; left time: 198.0326s\n",
      "\titers: 700, epoch: 6 | loss: 0.0108478\n",
      "\tspeed: 0.0517s/iter; left time: 194.5955s\n",
      "\titers: 800, epoch: 6 | loss: 0.0143594\n",
      "\tspeed: 0.0506s/iter; left time: 185.5360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0173059 Vali Loss: 0.0202137 Test Loss: 0.0222505\n",
      "Validation loss decreased (0.022665 --> 0.020214).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0151645\n",
      "\tspeed: 0.1836s/iter; left time: 637.5605s\n",
      "\titers: 200, epoch: 7 | loss: 0.0121527\n",
      "\tspeed: 0.0498s/iter; left time: 167.8698s\n",
      "\titers: 300, epoch: 7 | loss: 0.0148428\n",
      "\tspeed: 0.0501s/iter; left time: 163.9607s\n",
      "\titers: 400, epoch: 7 | loss: 0.0130999\n",
      "\tspeed: 0.0506s/iter; left time: 160.5437s\n",
      "\titers: 500, epoch: 7 | loss: 0.0147744\n",
      "\tspeed: 0.0508s/iter; left time: 156.1513s\n",
      "\titers: 600, epoch: 7 | loss: 0.0109115\n",
      "\tspeed: 0.0508s/iter; left time: 151.0952s\n",
      "\titers: 700, epoch: 7 | loss: 0.0117408\n",
      "\tspeed: 0.0508s/iter; left time: 146.0907s\n",
      "\titers: 800, epoch: 7 | loss: 0.0130151\n",
      "\tspeed: 0.0508s/iter; left time: 140.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.32s\n",
      "Steps: 893 | Train Loss: 0.0138396 Vali Loss: 0.0199291 Test Loss: 0.0221776\n",
      "Validation loss decreased (0.020214 --> 0.019929).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132367\n",
      "\tspeed: 0.1853s/iter; left time: 478.0415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0133071\n",
      "\tspeed: 0.0507s/iter; left time: 125.7069s\n",
      "\titers: 300, epoch: 8 | loss: 0.0146803\n",
      "\tspeed: 0.0509s/iter; left time: 121.0992s\n",
      "\titers: 400, epoch: 8 | loss: 0.0148187\n",
      "\tspeed: 0.0509s/iter; left time: 116.0250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0148767\n",
      "\tspeed: 0.0508s/iter; left time: 110.6992s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103235\n",
      "\tspeed: 0.0506s/iter; left time: 105.3205s\n",
      "\titers: 700, epoch: 8 | loss: 0.0116642\n",
      "\tspeed: 0.0506s/iter; left time: 100.1432s\n",
      "\titers: 800, epoch: 8 | loss: 0.0160350\n",
      "\tspeed: 0.0509s/iter; left time: 95.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 893 | Train Loss: 0.0132240 Vali Loss: 0.0206254 Test Loss: 0.0223201\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0099230\n",
      "\tspeed: 0.1830s/iter; left time: 308.7429s\n",
      "\titers: 200, epoch: 9 | loss: 0.0112927\n",
      "\tspeed: 0.0509s/iter; left time: 80.7863s\n",
      "\titers: 300, epoch: 9 | loss: 0.0115014\n",
      "\tspeed: 0.0507s/iter; left time: 75.3442s\n",
      "\titers: 400, epoch: 9 | loss: 0.0098618\n",
      "\tspeed: 0.0510s/iter; left time: 70.6789s\n",
      "\titers: 500, epoch: 9 | loss: 0.0128435\n",
      "\tspeed: 0.0513s/iter; left time: 66.0137s\n",
      "\titers: 600, epoch: 9 | loss: 0.0130007\n",
      "\tspeed: 0.0507s/iter; left time: 60.1578s\n",
      "\titers: 700, epoch: 9 | loss: 0.0124585\n",
      "\tspeed: 0.0509s/iter; left time: 55.2780s\n",
      "\titers: 800, epoch: 9 | loss: 0.0110741\n",
      "\tspeed: 0.0506s/iter; left time: 49.9554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 893 | Train Loss: 0.0128333 Vali Loss: 0.0198661 Test Loss: 0.0227560\n",
      "Validation loss decreased (0.019929 --> 0.019866).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0118321\n",
      "\tspeed: 0.1853s/iter; left time: 147.1247s\n",
      "\titers: 200, epoch: 10 | loss: 0.0099242\n",
      "\tspeed: 0.0508s/iter; left time: 35.2364s\n",
      "\titers: 300, epoch: 10 | loss: 0.0084647\n",
      "\tspeed: 0.0511s/iter; left time: 30.3284s\n",
      "\titers: 400, epoch: 10 | loss: 0.0142392\n",
      "\tspeed: 0.0508s/iter; left time: 25.0907s\n",
      "\titers: 500, epoch: 10 | loss: 0.0116700\n",
      "\tspeed: 0.0514s/iter; left time: 20.2358s\n",
      "\titers: 600, epoch: 10 | loss: 0.0120764\n",
      "\tspeed: 0.0505s/iter; left time: 14.8355s\n",
      "\titers: 700, epoch: 10 | loss: 0.0155301\n",
      "\tspeed: 0.0513s/iter; left time: 9.9431s\n",
      "\titers: 800, epoch: 10 | loss: 0.0116681\n",
      "\tspeed: 0.0503s/iter; left time: 4.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.0123163 Vali Loss: 0.0207767 Test Loss: 0.0239361\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02275596372783184, rmse:0.1508508026599884, mae:0.09933484345674515, rse:0.532733678817749\n",
      "Original data scale mse:17937842.0, rmse:4235.30908203125, mae:2700.571533203125, rse:0.21058809757232666\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0630893\n",
      "\tspeed: 0.0519s/iter; left time: 458.2744s\n",
      "\titers: 200, epoch: 1 | loss: 0.0617913\n",
      "\tspeed: 0.0497s/iter; left time: 433.7302s\n",
      "\titers: 300, epoch: 1 | loss: 0.0525470\n",
      "\tspeed: 0.0508s/iter; left time: 438.4758s\n",
      "\titers: 400, epoch: 1 | loss: 0.0434229\n",
      "\tspeed: 0.0508s/iter; left time: 433.3024s\n",
      "\titers: 500, epoch: 1 | loss: 0.0331395\n",
      "\tspeed: 0.0514s/iter; left time: 433.3308s\n",
      "\titers: 600, epoch: 1 | loss: 0.0337202\n",
      "\tspeed: 0.0510s/iter; left time: 425.2196s\n",
      "\titers: 700, epoch: 1 | loss: 0.0321468\n",
      "\tspeed: 0.0507s/iter; left time: 417.1783s\n",
      "\titers: 800, epoch: 1 | loss: 0.0301018\n",
      "\tspeed: 0.0513s/iter; left time: 417.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.0484691 Vali Loss: 0.0250252 Test Loss: 0.0273721\n",
      "Validation loss decreased (inf --> 0.025025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0382674\n",
      "\tspeed: 0.1850s/iter; left time: 1468.5774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0206077\n",
      "\tspeed: 0.0505s/iter; left time: 395.9632s\n",
      "\titers: 300, epoch: 2 | loss: 0.0196784\n",
      "\tspeed: 0.0507s/iter; left time: 392.0200s\n",
      "\titers: 400, epoch: 2 | loss: 0.0154511\n",
      "\tspeed: 0.0508s/iter; left time: 388.0200s\n",
      "\titers: 500, epoch: 2 | loss: 0.0195760\n",
      "\tspeed: 0.0509s/iter; left time: 383.5861s\n",
      "\titers: 600, epoch: 2 | loss: 0.0168603\n",
      "\tspeed: 0.0511s/iter; left time: 380.4507s\n",
      "\titers: 700, epoch: 2 | loss: 0.0190213\n",
      "\tspeed: 0.0504s/iter; left time: 369.6427s\n",
      "\titers: 800, epoch: 2 | loss: 0.0457725\n",
      "\tspeed: 0.0508s/iter; left time: 367.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.48s\n",
      "Steps: 893 | Train Loss: 0.0275582 Vali Loss: 0.0258817 Test Loss: 0.0285840\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0238563\n",
      "\tspeed: 0.1840s/iter; left time: 1296.4284s\n",
      "\titers: 200, epoch: 3 | loss: 0.0145440\n",
      "\tspeed: 0.0508s/iter; left time: 352.9129s\n",
      "\titers: 300, epoch: 3 | loss: 0.0193389\n",
      "\tspeed: 0.0510s/iter; left time: 348.8428s\n",
      "\titers: 400, epoch: 3 | loss: 0.0168762\n",
      "\tspeed: 0.0506s/iter; left time: 341.4557s\n",
      "\titers: 500, epoch: 3 | loss: 0.0190453\n",
      "\tspeed: 0.0509s/iter; left time: 338.5424s\n",
      "\titers: 600, epoch: 3 | loss: 0.0187749\n",
      "\tspeed: 0.0509s/iter; left time: 333.1262s\n",
      "\titers: 700, epoch: 3 | loss: 0.0201252\n",
      "\tspeed: 0.0507s/iter; left time: 326.7469s\n",
      "\titers: 800, epoch: 3 | loss: 0.0164555\n",
      "\tspeed: 0.0509s/iter; left time: 323.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.67s\n",
      "Steps: 893 | Train Loss: 0.0169959 Vali Loss: 0.0242355 Test Loss: 0.0260237\n",
      "Validation loss decreased (0.025025 --> 0.024235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0756164\n",
      "\tspeed: 0.1852s/iter; left time: 1139.5641s\n",
      "\titers: 200, epoch: 4 | loss: 0.0344469\n",
      "\tspeed: 0.0509s/iter; left time: 307.8119s\n",
      "\titers: 300, epoch: 4 | loss: 0.0271614\n",
      "\tspeed: 0.0506s/iter; left time: 301.3745s\n",
      "\titers: 400, epoch: 4 | loss: 0.0304677\n",
      "\tspeed: 0.0512s/iter; left time: 299.5690s\n",
      "\titers: 500, epoch: 4 | loss: 0.0145179\n",
      "\tspeed: 0.0507s/iter; left time: 291.4420s\n",
      "\titers: 600, epoch: 4 | loss: 0.0177252\n",
      "\tspeed: 0.0727s/iter; left time: 410.8487s\n",
      "\titers: 700, epoch: 4 | loss: 0.0200148\n",
      "\tspeed: 0.0503s/iter; left time: 279.5352s\n",
      "\titers: 800, epoch: 4 | loss: 0.0156927\n",
      "\tspeed: 0.0508s/iter; left time: 276.9305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 893 | Train Loss: 0.0305887 Vali Loss: 0.0891450 Test Loss: 0.0844128\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0235908\n",
      "\tspeed: 0.1819s/iter; left time: 956.4182s\n",
      "\titers: 200, epoch: 5 | loss: 0.0224511\n",
      "\tspeed: 0.0500s/iter; left time: 257.9302s\n",
      "\titers: 300, epoch: 5 | loss: 0.0360905\n",
      "\tspeed: 0.0502s/iter; left time: 253.9841s\n",
      "\titers: 400, epoch: 5 | loss: 0.0224273\n",
      "\tspeed: 0.0511s/iter; left time: 253.3608s\n",
      "\titers: 500, epoch: 5 | loss: 0.0162767\n",
      "\tspeed: 0.0506s/iter; left time: 246.0153s\n",
      "\titers: 600, epoch: 5 | loss: 0.0179131\n",
      "\tspeed: 0.0508s/iter; left time: 241.6584s\n",
      "\titers: 700, epoch: 5 | loss: 0.0451258\n",
      "\tspeed: 0.0507s/iter; left time: 236.0232s\n",
      "\titers: 800, epoch: 5 | loss: 0.0291768\n",
      "\tspeed: 0.0507s/iter; left time: 231.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.34s\n",
      "Steps: 893 | Train Loss: 0.0244987 Vali Loss: 0.0305114 Test Loss: 0.0339810\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0154643\n",
      "\tspeed: 0.1836s/iter; left time: 801.7510s\n",
      "\titers: 200, epoch: 6 | loss: 0.0154735\n",
      "\tspeed: 0.0509s/iter; left time: 217.2494s\n",
      "\titers: 300, epoch: 6 | loss: 0.0154974\n",
      "\tspeed: 0.0511s/iter; left time: 213.0575s\n",
      "\titers: 400, epoch: 6 | loss: 0.0171965\n",
      "\tspeed: 0.0513s/iter; left time: 208.5771s\n",
      "\titers: 500, epoch: 6 | loss: 0.0152446\n",
      "\tspeed: 0.0508s/iter; left time: 201.4764s\n",
      "\titers: 600, epoch: 6 | loss: 0.0258890\n",
      "\tspeed: 0.0508s/iter; left time: 196.3693s\n",
      "\titers: 700, epoch: 6 | loss: 0.0489950\n",
      "\tspeed: 0.0508s/iter; left time: 191.1826s\n",
      "\titers: 800, epoch: 6 | loss: 0.0197910\n",
      "\tspeed: 0.0511s/iter; left time: 187.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0228989 Vali Loss: 0.0220299 Test Loss: 0.0247207\n",
      "Validation loss decreased (0.024235 --> 0.022030).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0207843\n",
      "\tspeed: 0.1853s/iter; left time: 643.5170s\n",
      "\titers: 200, epoch: 7 | loss: 0.0169488\n",
      "\tspeed: 0.0510s/iter; left time: 172.1080s\n",
      "\titers: 300, epoch: 7 | loss: 0.0128568\n",
      "\tspeed: 0.0506s/iter; left time: 165.6781s\n",
      "\titers: 400, epoch: 7 | loss: 0.0139189\n",
      "\tspeed: 0.0507s/iter; left time: 161.0160s\n",
      "\titers: 500, epoch: 7 | loss: 0.0203434\n",
      "\tspeed: 0.0505s/iter; left time: 155.2466s\n",
      "\titers: 600, epoch: 7 | loss: 0.0155949\n",
      "\tspeed: 0.0505s/iter; left time: 150.1968s\n",
      "\titers: 700, epoch: 7 | loss: 0.0123993\n",
      "\tspeed: 0.0507s/iter; left time: 145.5335s\n",
      "\titers: 800, epoch: 7 | loss: 0.0220734\n",
      "\tspeed: 0.0507s/iter; left time: 140.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.0165875 Vali Loss: 0.0240857 Test Loss: 0.0266356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132901\n",
      "\tspeed: 0.1822s/iter; left time: 470.0518s\n",
      "\titers: 200, epoch: 8 | loss: 0.0147576\n",
      "\tspeed: 0.0511s/iter; left time: 126.6957s\n",
      "\titers: 300, epoch: 8 | loss: 0.0116578\n",
      "\tspeed: 0.0509s/iter; left time: 121.0896s\n",
      "\titers: 400, epoch: 8 | loss: 0.0117376\n",
      "\tspeed: 0.0506s/iter; left time: 115.3662s\n",
      "\titers: 500, epoch: 8 | loss: 0.0181731\n",
      "\tspeed: 0.0512s/iter; left time: 111.6834s\n",
      "\titers: 600, epoch: 8 | loss: 0.0119660\n",
      "\tspeed: 0.0510s/iter; left time: 106.0802s\n",
      "\titers: 700, epoch: 8 | loss: 0.0115851\n",
      "\tspeed: 0.0511s/iter; left time: 101.1881s\n",
      "\titers: 800, epoch: 8 | loss: 0.0173845\n",
      "\tspeed: 0.0509s/iter; left time: 95.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 893 | Train Loss: 0.0157776 Vali Loss: 0.0203106 Test Loss: 0.0232468\n",
      "Validation loss decreased (0.022030 --> 0.020311).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0132059\n",
      "\tspeed: 0.1840s/iter; left time: 310.4131s\n",
      "\titers: 200, epoch: 9 | loss: 0.0128770\n",
      "\tspeed: 0.0500s/iter; left time: 79.2723s\n",
      "\titers: 300, epoch: 9 | loss: 0.0140381\n",
      "\tspeed: 0.0502s/iter; left time: 74.6620s\n",
      "\titers: 400, epoch: 9 | loss: 0.0159804\n",
      "\tspeed: 0.0510s/iter; left time: 70.6758s\n",
      "\titers: 500, epoch: 9 | loss: 0.0158740\n",
      "\tspeed: 0.0506s/iter; left time: 65.1674s\n",
      "\titers: 600, epoch: 9 | loss: 0.0126490\n",
      "\tspeed: 0.0506s/iter; left time: 60.0698s\n",
      "\titers: 700, epoch: 9 | loss: 0.0142652\n",
      "\tspeed: 0.0510s/iter; left time: 55.3962s\n",
      "\titers: 800, epoch: 9 | loss: 0.0162107\n",
      "\tspeed: 0.0506s/iter; left time: 49.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.36s\n",
      "Steps: 893 | Train Loss: 0.0171276 Vali Loss: 0.0202876 Test Loss: 0.0231598\n",
      "Validation loss decreased (0.020311 --> 0.020288).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0123887\n",
      "\tspeed: 0.1859s/iter; left time: 147.6380s\n",
      "\titers: 200, epoch: 10 | loss: 0.0122240\n",
      "\tspeed: 0.0506s/iter; left time: 35.1404s\n",
      "\titers: 300, epoch: 10 | loss: 0.0185827\n",
      "\tspeed: 0.0508s/iter; left time: 30.1505s\n",
      "\titers: 400, epoch: 10 | loss: 0.0139132\n",
      "\tspeed: 0.0510s/iter; left time: 25.2107s\n",
      "\titers: 500, epoch: 10 | loss: 0.0885992\n",
      "\tspeed: 0.0508s/iter; left time: 20.0225s\n",
      "\titers: 600, epoch: 10 | loss: 0.0195187\n",
      "\tspeed: 0.0505s/iter; left time: 14.8439s\n",
      "\titers: 700, epoch: 10 | loss: 0.0125244\n",
      "\tspeed: 0.0512s/iter; left time: 9.9240s\n",
      "\titers: 800, epoch: 10 | loss: 0.0164415\n",
      "\tspeed: 0.0508s/iter; left time: 4.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.59s\n",
      "Steps: 893 | Train Loss: 0.0193419 Vali Loss: 0.0261223 Test Loss: 0.0303472\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02315976470708847, rmse:0.15218332409858704, mae:0.09934287518262863, rse:0.5374395251274109\n",
      "Original data scale mse:18291816.0, rmse:4276.89306640625, mae:2723.598876953125, rse:0.21265576779842377\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0898976\n",
      "\tspeed: 0.0741s/iter; left time: 653.1570s\n",
      "\titers: 200, epoch: 1 | loss: 0.0708223\n",
      "\tspeed: 0.0510s/iter; left time: 443.9286s\n",
      "\titers: 300, epoch: 1 | loss: 0.0569122\n",
      "\tspeed: 0.0517s/iter; left time: 445.4802s\n",
      "\titers: 400, epoch: 1 | loss: 0.0454593\n",
      "\tspeed: 0.0517s/iter; left time: 440.2670s\n",
      "\titers: 500, epoch: 1 | loss: 0.0442200\n",
      "\tspeed: 0.0514s/iter; left time: 431.9718s\n",
      "\titers: 600, epoch: 1 | loss: 0.0379681\n",
      "\tspeed: 0.0513s/iter; left time: 426.6789s\n",
      "\titers: 700, epoch: 1 | loss: 0.0379627\n",
      "\tspeed: 0.0515s/iter; left time: 422.8719s\n",
      "\titers: 800, epoch: 1 | loss: 0.0402865\n",
      "\tspeed: 0.0513s/iter; left time: 415.8829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.30s\n",
      "Steps: 891 | Train Loss: 0.0554252 Vali Loss: 0.0363158 Test Loss: 0.0423456\n",
      "Validation loss decreased (inf --> 0.036316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0401363\n",
      "\tspeed: 0.1849s/iter; left time: 1464.0327s\n",
      "\titers: 200, epoch: 2 | loss: 0.0252000\n",
      "\tspeed: 0.0514s/iter; left time: 401.9002s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294650\n",
      "\tspeed: 0.0513s/iter; left time: 396.2799s\n",
      "\titers: 400, epoch: 2 | loss: 0.0274815\n",
      "\tspeed: 0.0512s/iter; left time: 390.0853s\n",
      "\titers: 500, epoch: 2 | loss: 0.0206962\n",
      "\tspeed: 0.0517s/iter; left time: 388.6882s\n",
      "\titers: 600, epoch: 2 | loss: 0.0216226\n",
      "\tspeed: 0.0520s/iter; left time: 385.5134s\n",
      "\titers: 700, epoch: 2 | loss: 0.0229341\n",
      "\tspeed: 0.0513s/iter; left time: 375.4983s\n",
      "\titers: 800, epoch: 2 | loss: 0.0346711\n",
      "\tspeed: 0.0514s/iter; left time: 371.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 891 | Train Loss: 0.0331284 Vali Loss: 0.0436025 Test Loss: 0.0518451\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0250928\n",
      "\tspeed: 0.1892s/iter; left time: 1329.8842s\n",
      "\titers: 200, epoch: 3 | loss: 0.0223674\n",
      "\tspeed: 0.0517s/iter; left time: 358.4950s\n",
      "\titers: 300, epoch: 3 | loss: 0.0242723\n",
      "\tspeed: 0.0513s/iter; left time: 350.6152s\n",
      "\titers: 400, epoch: 3 | loss: 0.0220188\n",
      "\tspeed: 0.0512s/iter; left time: 344.4660s\n",
      "\titers: 500, epoch: 3 | loss: 0.0298991\n",
      "\tspeed: 0.0513s/iter; left time: 340.2392s\n",
      "\titers: 600, epoch: 3 | loss: 0.0232173\n",
      "\tspeed: 0.0522s/iter; left time: 340.7898s\n",
      "\titers: 700, epoch: 3 | loss: 0.0263925\n",
      "\tspeed: 0.0515s/iter; left time: 331.2999s\n",
      "\titers: 800, epoch: 3 | loss: 0.2027422\n",
      "\tspeed: 0.0519s/iter; left time: 328.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.32s\n",
      "Steps: 891 | Train Loss: 0.0348487 Vali Loss: 0.0603632 Test Loss: 0.0670758\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0358179\n",
      "\tspeed: 0.1837s/iter; left time: 1127.3000s\n",
      "\titers: 200, epoch: 4 | loss: 0.0302912\n",
      "\tspeed: 0.0514s/iter; left time: 310.5020s\n",
      "\titers: 300, epoch: 4 | loss: 0.0339807\n",
      "\tspeed: 0.0518s/iter; left time: 307.4406s\n",
      "\titers: 400, epoch: 4 | loss: 0.0344218\n",
      "\tspeed: 0.0515s/iter; left time: 300.8306s\n",
      "\titers: 500, epoch: 4 | loss: 0.0287116\n",
      "\tspeed: 0.0514s/iter; left time: 294.8065s\n",
      "\titers: 600, epoch: 4 | loss: 0.0322211\n",
      "\tspeed: 0.0520s/iter; left time: 292.9588s\n",
      "\titers: 700, epoch: 4 | loss: 0.0963653\n",
      "\tspeed: 0.0515s/iter; left time: 285.4436s\n",
      "\titers: 800, epoch: 4 | loss: 0.0292881\n",
      "\tspeed: 0.0519s/iter; left time: 282.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 891 | Train Loss: 0.0345918 Vali Loss: 0.0482134 Test Loss: 0.0535568\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042345594614744186, rmse:0.20578044652938843, mae:0.1441667377948761, rse:0.7287101745605469\n",
      "Original data scale mse:37627388.0, rmse:6134.11669921875, mae:4097.5498046875, rse:0.3054812252521515\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0852662\n",
      "\tspeed: 0.0539s/iter; left time: 474.7936s\n",
      "\titers: 200, epoch: 1 | loss: 0.0627623\n",
      "\tspeed: 0.0511s/iter; left time: 444.9615s\n",
      "\titers: 300, epoch: 1 | loss: 0.0662281\n",
      "\tspeed: 0.0516s/iter; left time: 444.7285s\n",
      "\titers: 400, epoch: 1 | loss: 0.0498636\n",
      "\tspeed: 0.0520s/iter; left time: 442.3610s\n",
      "\titers: 500, epoch: 1 | loss: 0.0424981\n",
      "\tspeed: 0.0512s/iter; left time: 430.7242s\n",
      "\titers: 600, epoch: 1 | loss: 0.0364280\n",
      "\tspeed: 0.0519s/iter; left time: 431.2911s\n",
      "\titers: 700, epoch: 1 | loss: 0.0357536\n",
      "\tspeed: 0.0515s/iter; left time: 422.4765s\n",
      "\titers: 800, epoch: 1 | loss: 0.0305926\n",
      "\tspeed: 0.0514s/iter; left time: 416.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 891 | Train Loss: 0.0545928 Vali Loss: 0.0358070 Test Loss: 0.0409772\n",
      "Validation loss decreased (inf --> 0.035807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0314706\n",
      "\tspeed: 0.1867s/iter; left time: 1478.6550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237816\n",
      "\tspeed: 0.0513s/iter; left time: 401.2282s\n",
      "\titers: 300, epoch: 2 | loss: 0.0336006\n",
      "\tspeed: 0.0515s/iter; left time: 397.4040s\n",
      "\titers: 400, epoch: 2 | loss: 0.0317686\n",
      "\tspeed: 0.0512s/iter; left time: 389.7871s\n",
      "\titers: 500, epoch: 2 | loss: 0.0207349\n",
      "\tspeed: 0.0521s/iter; left time: 391.6963s\n",
      "\titers: 600, epoch: 2 | loss: 0.0268169\n",
      "\tspeed: 0.0509s/iter; left time: 377.9925s\n",
      "\titers: 700, epoch: 2 | loss: 0.0245378\n",
      "\tspeed: 0.0543s/iter; left time: 397.2213s\n",
      "\titers: 800, epoch: 2 | loss: 0.0235130\n",
      "\tspeed: 0.0504s/iter; left time: 363.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.21s\n",
      "Steps: 891 | Train Loss: 0.0305210 Vali Loss: 0.0323818 Test Loss: 0.0381951\n",
      "Validation loss decreased (0.035807 --> 0.032382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0249535\n",
      "\tspeed: 0.1857s/iter; left time: 1305.0379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0215990\n",
      "\tspeed: 0.0516s/iter; left time: 357.2131s\n",
      "\titers: 300, epoch: 3 | loss: 0.0272987\n",
      "\tspeed: 0.0514s/iter; left time: 351.2427s\n",
      "\titers: 400, epoch: 3 | loss: 0.0321735\n",
      "\tspeed: 0.0520s/iter; left time: 349.9800s\n",
      "\titers: 500, epoch: 3 | loss: 0.0260557\n",
      "\tspeed: 0.0511s/iter; left time: 338.8483s\n",
      "\titers: 600, epoch: 3 | loss: 0.0302418\n",
      "\tspeed: 0.0517s/iter; left time: 337.6561s\n",
      "\titers: 700, epoch: 3 | loss: 0.0272865\n",
      "\tspeed: 0.0521s/iter; left time: 334.9479s\n",
      "\titers: 800, epoch: 3 | loss: 0.0454201\n",
      "\tspeed: 0.0523s/iter; left time: 330.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.38s\n",
      "Steps: 891 | Train Loss: 0.0308411 Vali Loss: 0.0486942 Test Loss: 0.0555486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1178505\n",
      "\tspeed: 0.1844s/iter; left time: 1131.5486s\n",
      "\titers: 200, epoch: 4 | loss: 0.0273620\n",
      "\tspeed: 0.0516s/iter; left time: 311.5729s\n",
      "\titers: 300, epoch: 4 | loss: 0.0237972\n",
      "\tspeed: 0.0513s/iter; left time: 304.7700s\n",
      "\titers: 400, epoch: 4 | loss: 0.0277754\n",
      "\tspeed: 0.0515s/iter; left time: 300.4807s\n",
      "\titers: 500, epoch: 4 | loss: 0.0218356\n",
      "\tspeed: 0.0520s/iter; left time: 298.6025s\n",
      "\titers: 600, epoch: 4 | loss: 0.0303578\n",
      "\tspeed: 0.0526s/iter; left time: 296.7779s\n",
      "\titers: 700, epoch: 4 | loss: 0.0658746\n",
      "\tspeed: 0.0517s/iter; left time: 286.5437s\n",
      "\titers: 800, epoch: 4 | loss: 0.0339334\n",
      "\tspeed: 0.0519s/iter; left time: 282.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.33s\n",
      "Steps: 891 | Train Loss: 0.0407891 Vali Loss: 0.0412829 Test Loss: 0.0475258\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0246762\n",
      "\tspeed: 0.1848s/iter; left time: 969.8898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0222932\n",
      "\tspeed: 0.0514s/iter; left time: 264.6840s\n",
      "\titers: 300, epoch: 5 | loss: 0.0228066\n",
      "\tspeed: 0.0516s/iter; left time: 260.2059s\n",
      "\titers: 400, epoch: 5 | loss: 0.0256367\n",
      "\tspeed: 0.0516s/iter; left time: 255.1761s\n",
      "\titers: 500, epoch: 5 | loss: 0.0274541\n",
      "\tspeed: 0.0517s/iter; left time: 250.5248s\n",
      "\titers: 600, epoch: 5 | loss: 0.0282266\n",
      "\tspeed: 0.0515s/iter; left time: 244.2806s\n",
      "\titers: 700, epoch: 5 | loss: 0.0263960\n",
      "\tspeed: 0.0515s/iter; left time: 239.3244s\n",
      "\titers: 800, epoch: 5 | loss: 0.0282295\n",
      "\tspeed: 0.0516s/iter; left time: 234.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 891 | Train Loss: 0.0290182 Vali Loss: 0.0334726 Test Loss: 0.0403731\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03819509223103523, rmse:0.19543564319610596, mae:0.13641740381717682, rse:0.6920771598815918\n",
      "Original data scale mse:34112108.0, rmse:5840.55712890625, mae:3830.144775390625, rse:0.2908618450164795\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0888382\n",
      "\tspeed: 0.0760s/iter; left time: 668.3962s\n",
      "\titers: 200, epoch: 1 | loss: 0.0694285\n",
      "\tspeed: 0.0516s/iter; left time: 448.6627s\n",
      "\titers: 300, epoch: 1 | loss: 0.0607677\n",
      "\tspeed: 0.0516s/iter; left time: 443.5817s\n",
      "\titers: 400, epoch: 1 | loss: 0.0541869\n",
      "\tspeed: 0.0514s/iter; left time: 436.6786s\n",
      "\titers: 500, epoch: 1 | loss: 0.0497022\n",
      "\tspeed: 0.0514s/iter; left time: 431.0021s\n",
      "\titers: 600, epoch: 1 | loss: 0.0400657\n",
      "\tspeed: 0.0519s/iter; left time: 430.0348s\n",
      "\titers: 700, epoch: 1 | loss: 0.0389284\n",
      "\tspeed: 0.0524s/iter; left time: 428.8792s\n",
      "\titers: 800, epoch: 1 | loss: 0.0374739\n",
      "\tspeed: 0.0526s/iter; left time: 425.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 889 | Train Loss: 0.0560617 Vali Loss: 0.0378708 Test Loss: 0.0443880\n",
      "Validation loss decreased (inf --> 0.037871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0429805\n",
      "\tspeed: 0.1863s/iter; left time: 1472.2925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277313\n",
      "\tspeed: 0.0527s/iter; left time: 411.0917s\n",
      "\titers: 300, epoch: 2 | loss: 0.0342847\n",
      "\tspeed: 0.0526s/iter; left time: 405.5029s\n",
      "\titers: 400, epoch: 2 | loss: 0.0299007\n",
      "\tspeed: 0.0523s/iter; left time: 397.9377s\n",
      "\titers: 500, epoch: 2 | loss: 0.0292404\n",
      "\tspeed: 0.0521s/iter; left time: 391.1038s\n",
      "\titers: 600, epoch: 2 | loss: 0.0252770\n",
      "\tspeed: 0.0527s/iter; left time: 390.3947s\n",
      "\titers: 700, epoch: 2 | loss: 0.0276976\n",
      "\tspeed: 0.0524s/iter; left time: 382.8406s\n",
      "\titers: 800, epoch: 2 | loss: 0.0280063\n",
      "\tspeed: 0.0518s/iter; left time: 372.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.75s\n",
      "Steps: 889 | Train Loss: 0.0323019 Vali Loss: 0.0385018 Test Loss: 0.0458075\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0251141\n",
      "\tspeed: 0.1863s/iter; left time: 1306.8397s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204771\n",
      "\tspeed: 0.0527s/iter; left time: 364.6193s\n",
      "\titers: 300, epoch: 3 | loss: 0.0273905\n",
      "\tspeed: 0.0525s/iter; left time: 357.4065s\n",
      "\titers: 400, epoch: 3 | loss: 0.0296237\n",
      "\tspeed: 0.0524s/iter; left time: 351.4474s\n",
      "\titers: 500, epoch: 3 | loss: 0.0332185\n",
      "\tspeed: 0.0524s/iter; left time: 346.2937s\n",
      "\titers: 600, epoch: 3 | loss: 0.0297045\n",
      "\tspeed: 0.0520s/iter; left time: 338.7931s\n",
      "\titers: 700, epoch: 3 | loss: 0.0273236\n",
      "\tspeed: 0.0530s/iter; left time: 339.8315s\n",
      "\titers: 800, epoch: 3 | loss: 0.0288009\n",
      "\tspeed: 0.0528s/iter; left time: 333.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 889 | Train Loss: 0.0321372 Vali Loss: 0.0508873 Test Loss: 0.0586393\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0730308\n",
      "\tspeed: 0.1861s/iter; left time: 1139.6871s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831938\n",
      "\tspeed: 0.0529s/iter; left time: 318.6523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0541538\n",
      "\tspeed: 0.0519s/iter; left time: 307.1927s\n",
      "\titers: 400, epoch: 4 | loss: 0.0337207\n",
      "\tspeed: 0.0527s/iter; left time: 306.6765s\n",
      "\titers: 500, epoch: 4 | loss: 0.0375476\n",
      "\tspeed: 0.0524s/iter; left time: 299.7874s\n",
      "\titers: 600, epoch: 4 | loss: 0.0319393\n",
      "\tspeed: 0.0526s/iter; left time: 295.5580s\n",
      "\titers: 700, epoch: 4 | loss: 0.0323389\n",
      "\tspeed: 0.0521s/iter; left time: 287.8345s\n",
      "\titers: 800, epoch: 4 | loss: 0.0331901\n",
      "\tspeed: 0.0524s/iter; left time: 284.3914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.94s\n",
      "Steps: 889 | Train Loss: 0.0464878 Vali Loss: 0.0371324 Test Loss: 0.0458050\n",
      "Validation loss decreased (0.037871 --> 0.037132).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0284479\n",
      "\tspeed: 0.1908s/iter; left time: 998.8633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0277144\n",
      "\tspeed: 0.0524s/iter; left time: 269.0983s\n",
      "\titers: 300, epoch: 5 | loss: 0.0289152\n",
      "\tspeed: 0.0512s/iter; left time: 257.7343s\n",
      "\titers: 400, epoch: 5 | loss: 0.0261952\n",
      "\tspeed: 0.0517s/iter; left time: 254.9652s\n",
      "\titers: 500, epoch: 5 | loss: 0.0281568\n",
      "\tspeed: 0.0518s/iter; left time: 250.6415s\n",
      "\titers: 600, epoch: 5 | loss: 0.0272779\n",
      "\tspeed: 0.0525s/iter; left time: 248.7681s\n",
      "\titers: 700, epoch: 5 | loss: 0.0282381\n",
      "\tspeed: 0.0528s/iter; left time: 244.5883s\n",
      "\titers: 800, epoch: 5 | loss: 0.0246174\n",
      "\tspeed: 0.0529s/iter; left time: 239.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 889 | Train Loss: 0.0286514 Vali Loss: 0.0340801 Test Loss: 0.0445965\n",
      "Validation loss decreased (0.037132 --> 0.034080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0276842\n",
      "\tspeed: 0.1870s/iter; left time: 812.8664s\n",
      "\titers: 200, epoch: 6 | loss: 0.0293742\n",
      "\tspeed: 0.0529s/iter; left time: 224.4712s\n",
      "\titers: 300, epoch: 6 | loss: 0.0289088\n",
      "\tspeed: 0.0526s/iter; left time: 218.0931s\n",
      "\titers: 400, epoch: 6 | loss: 0.0316670\n",
      "\tspeed: 0.0524s/iter; left time: 212.0398s\n",
      "\titers: 500, epoch: 6 | loss: 0.0327737\n",
      "\tspeed: 0.0526s/iter; left time: 207.4556s\n",
      "\titers: 600, epoch: 6 | loss: 0.0290152\n",
      "\tspeed: 0.0521s/iter; left time: 200.2658s\n",
      "\titers: 700, epoch: 6 | loss: 0.0240823\n",
      "\tspeed: 0.0519s/iter; left time: 194.5504s\n",
      "\titers: 800, epoch: 6 | loss: 0.0244310\n",
      "\tspeed: 0.0527s/iter; left time: 192.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.87s\n",
      "Steps: 889 | Train Loss: 0.0281667 Vali Loss: 0.0345875 Test Loss: 0.0458266\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0310720\n",
      "\tspeed: 0.1855s/iter; left time: 641.1078s\n",
      "\titers: 200, epoch: 7 | loss: 0.0398421\n",
      "\tspeed: 0.0524s/iter; left time: 175.9305s\n",
      "\titers: 300, epoch: 7 | loss: 0.0375238\n",
      "\tspeed: 0.0531s/iter; left time: 172.9533s\n",
      "\titers: 400, epoch: 7 | loss: 0.0233207\n",
      "\tspeed: 0.0524s/iter; left time: 165.5840s\n",
      "\titers: 500, epoch: 7 | loss: 0.0324207\n",
      "\tspeed: 0.0519s/iter; left time: 158.5145s\n",
      "\titers: 600, epoch: 7 | loss: 0.0249276\n",
      "\tspeed: 0.0523s/iter; left time: 154.7409s\n",
      "\titers: 700, epoch: 7 | loss: 0.0240854\n",
      "\tspeed: 0.0523s/iter; left time: 149.3477s\n",
      "\titers: 800, epoch: 7 | loss: 0.0238114\n",
      "\tspeed: 0.0521s/iter; left time: 143.5875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.80s\n",
      "Steps: 889 | Train Loss: 0.0310784 Vali Loss: 0.0371435 Test Loss: 0.0473995\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0250153\n",
      "\tspeed: 0.1857s/iter; left time: 476.9560s\n",
      "\titers: 200, epoch: 8 | loss: 0.0323935\n",
      "\tspeed: 0.0523s/iter; left time: 129.1913s\n",
      "\titers: 300, epoch: 8 | loss: 0.0215329\n",
      "\tspeed: 0.0524s/iter; left time: 124.1798s\n",
      "\titers: 400, epoch: 8 | loss: 0.0240333\n",
      "\tspeed: 0.0520s/iter; left time: 117.9454s\n",
      "\titers: 500, epoch: 8 | loss: 0.0226869\n",
      "\tspeed: 0.0518s/iter; left time: 112.3577s\n",
      "\titers: 600, epoch: 8 | loss: 0.0230713\n",
      "\tspeed: 0.0522s/iter; left time: 107.9746s\n",
      "\titers: 700, epoch: 8 | loss: 0.0370846\n",
      "\tspeed: 0.0522s/iter; left time: 102.6489s\n",
      "\titers: 800, epoch: 8 | loss: 0.0244681\n",
      "\tspeed: 0.0525s/iter; left time: 98.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.70s\n",
      "Steps: 889 | Train Loss: 0.0264354 Vali Loss: 0.0345099 Test Loss: 0.0478705\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459647461771965, rmse:0.21117877960205078, mae:0.1488092690706253, rse:0.7481427788734436\n",
      "Original data scale mse:40797516.0, rmse:6387.29345703125, mae:4201.81494140625, rse:0.31824561953544617\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0898091\n",
      "\tspeed: 0.0543s/iter; left time: 476.9160s\n",
      "\titers: 200, epoch: 1 | loss: 0.0683999\n",
      "\tspeed: 0.0509s/iter; left time: 442.0565s\n",
      "\titers: 300, epoch: 1 | loss: 0.0547635\n",
      "\tspeed: 0.0521s/iter; left time: 447.6564s\n",
      "\titers: 400, epoch: 1 | loss: 0.0432415\n",
      "\tspeed: 0.0523s/iter; left time: 443.8964s\n",
      "\titers: 500, epoch: 1 | loss: 0.0500627\n",
      "\tspeed: 0.0520s/iter; left time: 436.7469s\n",
      "\titers: 600, epoch: 1 | loss: 0.0379077\n",
      "\tspeed: 0.0518s/iter; left time: 429.7911s\n",
      "\titers: 700, epoch: 1 | loss: 0.0490888\n",
      "\tspeed: 0.0527s/iter; left time: 431.2757s\n",
      "\titers: 800, epoch: 1 | loss: 0.0428982\n",
      "\tspeed: 0.0529s/iter; left time: 428.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 889 | Train Loss: 0.0563741 Vali Loss: 0.0370020 Test Loss: 0.0429488\n",
      "Validation loss decreased (inf --> 0.037002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0338767\n",
      "\tspeed: 0.1905s/iter; left time: 1505.0263s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277708\n",
      "\tspeed: 0.0525s/iter; left time: 409.3009s\n",
      "\titers: 300, epoch: 2 | loss: 0.0251262\n",
      "\tspeed: 0.0519s/iter; left time: 399.6049s\n",
      "\titers: 400, epoch: 2 | loss: 0.0281210\n",
      "\tspeed: 0.0522s/iter; left time: 396.6558s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265468\n",
      "\tspeed: 0.0528s/iter; left time: 396.2313s\n",
      "\titers: 600, epoch: 2 | loss: 0.0296902\n",
      "\tspeed: 0.0528s/iter; left time: 390.5075s\n",
      "\titers: 700, epoch: 2 | loss: 0.0216061\n",
      "\tspeed: 0.0520s/iter; left time: 379.6128s\n",
      "\titers: 800, epoch: 2 | loss: 0.0272976\n",
      "\tspeed: 0.0523s/iter; left time: 376.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.86s\n",
      "Steps: 889 | Train Loss: 0.0323584 Vali Loss: 0.0381181 Test Loss: 0.0455699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0305601\n",
      "\tspeed: 0.1851s/iter; left time: 1298.3272s\n",
      "\titers: 200, epoch: 3 | loss: 0.0294327\n",
      "\tspeed: 0.0522s/iter; left time: 360.5374s\n",
      "\titers: 300, epoch: 3 | loss: 0.0276987\n",
      "\tspeed: 0.0520s/iter; left time: 354.2009s\n",
      "\titers: 400, epoch: 3 | loss: 0.0316389\n",
      "\tspeed: 0.0522s/iter; left time: 350.1903s\n",
      "\titers: 500, epoch: 3 | loss: 0.0310125\n",
      "\tspeed: 0.0522s/iter; left time: 344.9069s\n",
      "\titers: 600, epoch: 3 | loss: 0.0362121\n",
      "\tspeed: 0.0526s/iter; left time: 342.3597s\n",
      "\titers: 700, epoch: 3 | loss: 0.0596186\n",
      "\tspeed: 0.0517s/iter; left time: 331.5651s\n",
      "\titers: 800, epoch: 3 | loss: 0.0472811\n",
      "\tspeed: 0.0518s/iter; left time: 326.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 889 | Train Loss: 0.0373884 Vali Loss: 0.0452246 Test Loss: 0.0539904\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0430337\n",
      "\tspeed: 0.1855s/iter; left time: 1135.9358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0299234\n",
      "\tspeed: 0.0523s/iter; left time: 315.3036s\n",
      "\titers: 300, epoch: 4 | loss: 0.0335060\n",
      "\tspeed: 0.0525s/iter; left time: 311.2988s\n",
      "\titers: 400, epoch: 4 | loss: 0.0302610\n",
      "\tspeed: 0.0526s/iter; left time: 306.2596s\n",
      "\titers: 500, epoch: 4 | loss: 0.0276472\n",
      "\tspeed: 0.0520s/iter; left time: 297.6139s\n",
      "\titers: 600, epoch: 4 | loss: 0.0275331\n",
      "\tspeed: 0.0524s/iter; left time: 294.7657s\n",
      "\titers: 700, epoch: 4 | loss: 0.0314489\n",
      "\tspeed: 0.0522s/iter; left time: 288.3134s\n",
      "\titers: 800, epoch: 4 | loss: 0.0334173\n",
      "\tspeed: 0.0522s/iter; left time: 283.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.74s\n",
      "Steps: 889 | Train Loss: 0.0342779 Vali Loss: 0.0505663 Test Loss: 0.0559997\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042948778718709946, rmse:0.20724086463451385, mae:0.14715154469013214, rse:0.7341920137405396\n",
      "Original data scale mse:40016304.0, rmse:6325.84423828125, mae:4216.599609375, rse:0.31518393754959106\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2667935\n",
      "\tspeed: 0.0770s/iter; left time: 679.8272s\n",
      "\titers: 200, epoch: 1 | loss: 0.2580521\n",
      "\tspeed: 0.0508s/iter; left time: 443.3949s\n",
      "\titers: 300, epoch: 1 | loss: 0.2223780\n",
      "\tspeed: 0.0508s/iter; left time: 438.2336s\n",
      "\titers: 400, epoch: 1 | loss: 0.2138453\n",
      "\tspeed: 0.0510s/iter; left time: 434.7752s\n",
      "\titers: 500, epoch: 1 | loss: 0.2004627\n",
      "\tspeed: 0.0504s/iter; left time: 425.3362s\n",
      "\titers: 600, epoch: 1 | loss: 0.1992375\n",
      "\tspeed: 0.0506s/iter; left time: 421.2432s\n",
      "\titers: 700, epoch: 1 | loss: 0.1717654\n",
      "\tspeed: 0.0507s/iter; left time: 416.9749s\n",
      "\titers: 800, epoch: 1 | loss: 0.1729079\n",
      "\tspeed: 0.0508s/iter; left time: 413.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 893 | Train Loss: 0.2125009 Vali Loss: 0.0247184 Test Loss: 0.0270354\n",
      "Validation loss decreased (inf --> 0.024718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1863800\n",
      "\tspeed: 0.1870s/iter; left time: 1484.1128s\n",
      "\titers: 200, epoch: 2 | loss: 0.1660040\n",
      "\tspeed: 0.0505s/iter; left time: 395.7646s\n",
      "\titers: 300, epoch: 2 | loss: 0.1364938\n",
      "\tspeed: 0.0507s/iter; left time: 392.1121s\n",
      "\titers: 400, epoch: 2 | loss: 0.1331088\n",
      "\tspeed: 0.0505s/iter; left time: 385.4734s\n",
      "\titers: 500, epoch: 2 | loss: 0.1509917\n",
      "\tspeed: 0.0503s/iter; left time: 379.1606s\n",
      "\titers: 600, epoch: 2 | loss: 0.1571442\n",
      "\tspeed: 0.0509s/iter; left time: 378.5748s\n",
      "\titers: 700, epoch: 2 | loss: 0.1335184\n",
      "\tspeed: 0.0508s/iter; left time: 372.5700s\n",
      "\titers: 800, epoch: 2 | loss: 0.1152891\n",
      "\tspeed: 0.0509s/iter; left time: 368.5354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.1478759 Vali Loss: 0.0224017 Test Loss: 0.0247429\n",
      "Validation loss decreased (0.024718 --> 0.022402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1100226\n",
      "\tspeed: 0.1865s/iter; left time: 1313.5443s\n",
      "\titers: 200, epoch: 3 | loss: 0.1530367\n",
      "\tspeed: 0.0506s/iter; left time: 351.3994s\n",
      "\titers: 300, epoch: 3 | loss: 0.1144963\n",
      "\tspeed: 0.0510s/iter; left time: 348.9010s\n",
      "\titers: 400, epoch: 3 | loss: 0.1163256\n",
      "\tspeed: 0.0506s/iter; left time: 341.5512s\n",
      "\titers: 500, epoch: 3 | loss: 0.2570778\n",
      "\tspeed: 0.0507s/iter; left time: 336.8220s\n",
      "\titers: 600, epoch: 3 | loss: 0.1622165\n",
      "\tspeed: 0.0503s/iter; left time: 329.1960s\n",
      "\titers: 700, epoch: 3 | loss: 0.1049144\n",
      "\tspeed: 0.0506s/iter; left time: 326.1386s\n",
      "\titers: 800, epoch: 3 | loss: 0.1333985\n",
      "\tspeed: 0.0506s/iter; left time: 320.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.54s\n",
      "Steps: 893 | Train Loss: 0.1425496 Vali Loss: 0.0336046 Test Loss: 0.0357040\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1423023\n",
      "\tspeed: 0.1825s/iter; left time: 1122.8416s\n",
      "\titers: 200, epoch: 4 | loss: 0.1204192\n",
      "\tspeed: 0.0507s/iter; left time: 306.6315s\n",
      "\titers: 300, epoch: 4 | loss: 0.1236560\n",
      "\tspeed: 0.0506s/iter; left time: 301.2752s\n",
      "\titers: 400, epoch: 4 | loss: 0.1334927\n",
      "\tspeed: 0.0507s/iter; left time: 296.9205s\n",
      "\titers: 500, epoch: 4 | loss: 0.1478318\n",
      "\tspeed: 0.0506s/iter; left time: 290.8882s\n",
      "\titers: 600, epoch: 4 | loss: 0.1267568\n",
      "\tspeed: 0.0502s/iter; left time: 283.4616s\n",
      "\titers: 700, epoch: 4 | loss: 0.1415466\n",
      "\tspeed: 0.0518s/iter; left time: 287.5869s\n",
      "\titers: 800, epoch: 4 | loss: 0.1633215\n",
      "\tspeed: 0.0497s/iter; left time: 271.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.45s\n",
      "Steps: 893 | Train Loss: 0.1582891 Vali Loss: 0.0230042 Test Loss: 0.0254217\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1623549\n",
      "\tspeed: 0.1838s/iter; left time: 966.8244s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184670\n",
      "\tspeed: 0.0506s/iter; left time: 260.9303s\n",
      "\titers: 300, epoch: 5 | loss: 0.1306548\n",
      "\tspeed: 0.0509s/iter; left time: 257.3625s\n",
      "\titers: 400, epoch: 5 | loss: 0.1558392\n",
      "\tspeed: 0.0506s/iter; left time: 251.1717s\n",
      "\titers: 500, epoch: 5 | loss: 0.1227018\n",
      "\tspeed: 0.0508s/iter; left time: 246.7338s\n",
      "\titers: 600, epoch: 5 | loss: 0.1086328\n",
      "\tspeed: 0.0510s/iter; left time: 242.7029s\n",
      "\titers: 700, epoch: 5 | loss: 0.1170880\n",
      "\tspeed: 0.0505s/iter; left time: 235.1560s\n",
      "\titers: 800, epoch: 5 | loss: 0.1247232\n",
      "\tspeed: 0.0507s/iter; left time: 231.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 893 | Train Loss: 0.1374177 Vali Loss: 0.0319526 Test Loss: 0.0359744\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02474287711083889, rmse:0.15729868412017822, mae:0.1036575511097908, rse:0.555504560470581\n",
      "Original data scale mse:20196358.0, rmse:4494.03564453125, mae:2889.832275390625, rse:0.22345252335071564\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2779282\n",
      "\tspeed: 0.0531s/iter; left time: 469.1710s\n",
      "\titers: 200, epoch: 1 | loss: 0.2390803\n",
      "\tspeed: 0.0507s/iter; left time: 442.5337s\n",
      "\titers: 300, epoch: 1 | loss: 0.2268084\n",
      "\tspeed: 0.0506s/iter; left time: 437.0661s\n",
      "\titers: 400, epoch: 1 | loss: 0.2293802\n",
      "\tspeed: 0.0508s/iter; left time: 433.1358s\n",
      "\titers: 500, epoch: 1 | loss: 0.1837658\n",
      "\tspeed: 0.0507s/iter; left time: 427.1459s\n",
      "\titers: 600, epoch: 1 | loss: 0.1928408\n",
      "\tspeed: 0.0505s/iter; left time: 420.5952s\n",
      "\titers: 700, epoch: 1 | loss: 0.1705509\n",
      "\tspeed: 0.0509s/iter; left time: 418.8480s\n",
      "\titers: 800, epoch: 1 | loss: 0.1656219\n",
      "\tspeed: 0.0511s/iter; left time: 415.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 893 | Train Loss: 0.2138857 Vali Loss: 0.0251672 Test Loss: 0.0276361\n",
      "Validation loss decreased (inf --> 0.025167).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1909748\n",
      "\tspeed: 0.1847s/iter; left time: 1465.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1275921\n",
      "\tspeed: 0.0510s/iter; left time: 399.5991s\n",
      "\titers: 300, epoch: 2 | loss: 0.1509326\n",
      "\tspeed: 0.0507s/iter; left time: 392.5938s\n",
      "\titers: 400, epoch: 2 | loss: 0.1442390\n",
      "\tspeed: 0.0512s/iter; left time: 391.2926s\n",
      "\titers: 500, epoch: 2 | loss: 0.1396593\n",
      "\tspeed: 0.0508s/iter; left time: 382.8834s\n",
      "\titers: 600, epoch: 2 | loss: 0.1391160\n",
      "\tspeed: 0.0514s/iter; left time: 382.0740s\n",
      "\titers: 700, epoch: 2 | loss: 0.1435115\n",
      "\tspeed: 0.0508s/iter; left time: 372.7324s\n",
      "\titers: 800, epoch: 2 | loss: 0.1515477\n",
      "\tspeed: 0.0506s/iter; left time: 366.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 893 | Train Loss: 0.1543432 Vali Loss: 0.0273073 Test Loss: 0.0287653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1390001\n",
      "\tspeed: 0.1836s/iter; left time: 1293.7330s\n",
      "\titers: 200, epoch: 3 | loss: 0.1339426\n",
      "\tspeed: 0.0506s/iter; left time: 351.4549s\n",
      "\titers: 300, epoch: 3 | loss: 0.1209359\n",
      "\tspeed: 0.0512s/iter; left time: 350.1631s\n",
      "\titers: 400, epoch: 3 | loss: 0.1398292\n",
      "\tspeed: 0.0503s/iter; left time: 339.2226s\n",
      "\titers: 500, epoch: 3 | loss: 0.1186847\n",
      "\tspeed: 0.0505s/iter; left time: 335.6127s\n",
      "\titers: 600, epoch: 3 | loss: 0.1172402\n",
      "\tspeed: 0.0516s/iter; left time: 337.9809s\n",
      "\titers: 700, epoch: 3 | loss: 0.1051632\n",
      "\tspeed: 0.0500s/iter; left time: 322.4525s\n",
      "\titers: 800, epoch: 3 | loss: 0.1399918\n",
      "\tspeed: 0.0498s/iter; left time: 316.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.49s\n",
      "Steps: 893 | Train Loss: 0.1394945 Vali Loss: 0.0801272 Test Loss: 0.0930919\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1774376\n",
      "\tspeed: 0.1848s/iter; left time: 1136.9994s\n",
      "\titers: 200, epoch: 4 | loss: 0.1217093\n",
      "\tspeed: 0.0506s/iter; left time: 306.5269s\n",
      "\titers: 300, epoch: 4 | loss: 0.1273016\n",
      "\tspeed: 0.0509s/iter; left time: 303.0578s\n",
      "\titers: 400, epoch: 4 | loss: 0.1378618\n",
      "\tspeed: 0.0504s/iter; left time: 295.1823s\n",
      "\titers: 500, epoch: 4 | loss: 0.1201100\n",
      "\tspeed: 0.0507s/iter; left time: 291.3618s\n",
      "\titers: 600, epoch: 4 | loss: 0.2189487\n",
      "\tspeed: 0.0506s/iter; left time: 285.9912s\n",
      "\titers: 700, epoch: 4 | loss: 0.1587457\n",
      "\tspeed: 0.0509s/iter; left time: 282.5200s\n",
      "\titers: 800, epoch: 4 | loss: 0.1149479\n",
      "\tspeed: 0.0507s/iter; left time: 276.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.1554488 Vali Loss: 0.0265880 Test Loss: 0.0300949\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02763606794178486, rmse:0.16624099016189575, mae:0.11141800880432129, rse:0.5870845913887024\n",
      "Original data scale mse:23053352.0, rmse:4801.390625, mae:3150.207275390625, rse:0.23873482644557953\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2982178\n",
      "\tspeed: 0.0751s/iter; left time: 661.4704s\n",
      "\titers: 200, epoch: 1 | loss: 0.2624930\n",
      "\tspeed: 0.0509s/iter; left time: 443.5324s\n",
      "\titers: 300, epoch: 1 | loss: 0.2324546\n",
      "\tspeed: 0.0510s/iter; left time: 438.7809s\n",
      "\titers: 400, epoch: 1 | loss: 0.2067106\n",
      "\tspeed: 0.0506s/iter; left time: 430.4419s\n",
      "\titers: 500, epoch: 1 | loss: 0.2036902\n",
      "\tspeed: 0.0521s/iter; left time: 438.1799s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889434\n",
      "\tspeed: 0.0511s/iter; left time: 424.5144s\n",
      "\titers: 700, epoch: 1 | loss: 0.1896021\n",
      "\tspeed: 0.0516s/iter; left time: 423.9716s\n",
      "\titers: 800, epoch: 1 | loss: 0.1980770\n",
      "\tspeed: 0.0518s/iter; left time: 420.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.18s\n",
      "Steps: 891 | Train Loss: 0.2272330 Vali Loss: 0.0357202 Test Loss: 0.0417701\n",
      "Validation loss decreased (inf --> 0.035720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2064929\n",
      "\tspeed: 0.1881s/iter; left time: 1489.4069s\n",
      "\titers: 200, epoch: 2 | loss: 0.1637664\n",
      "\tspeed: 0.0510s/iter; left time: 398.8077s\n",
      "\titers: 300, epoch: 2 | loss: 0.1592103\n",
      "\tspeed: 0.0512s/iter; left time: 395.5734s\n",
      "\titers: 400, epoch: 2 | loss: 0.1687467\n",
      "\tspeed: 0.0515s/iter; left time: 392.4766s\n",
      "\titers: 500, epoch: 2 | loss: 0.1409779\n",
      "\tspeed: 0.0512s/iter; left time: 384.8180s\n",
      "\titers: 600, epoch: 2 | loss: 0.1440497\n",
      "\tspeed: 0.0512s/iter; left time: 380.0027s\n",
      "\titers: 700, epoch: 2 | loss: 0.1645725\n",
      "\tspeed: 0.0517s/iter; left time: 378.4540s\n",
      "\titers: 800, epoch: 2 | loss: 0.1665554\n",
      "\tspeed: 0.0516s/iter; left time: 372.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 891 | Train Loss: 0.1765515 Vali Loss: 0.0402867 Test Loss: 0.0526145\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1581760\n",
      "\tspeed: 0.1832s/iter; left time: 1288.0547s\n",
      "\titers: 200, epoch: 3 | loss: 0.1500348\n",
      "\tspeed: 0.0514s/iter; left time: 356.4477s\n",
      "\titers: 300, epoch: 3 | loss: 0.1761549\n",
      "\tspeed: 0.0516s/iter; left time: 352.2687s\n",
      "\titers: 400, epoch: 3 | loss: 0.1564396\n",
      "\tspeed: 0.0508s/iter; left time: 341.5919s\n",
      "\titers: 500, epoch: 3 | loss: 0.1672223\n",
      "\tspeed: 0.0506s/iter; left time: 335.6370s\n",
      "\titers: 600, epoch: 3 | loss: 0.1538464\n",
      "\tspeed: 0.0510s/iter; left time: 332.9534s\n",
      "\titers: 700, epoch: 3 | loss: 0.1710698\n",
      "\tspeed: 0.0515s/iter; left time: 330.9106s\n",
      "\titers: 800, epoch: 3 | loss: 0.1853437\n",
      "\tspeed: 0.0514s/iter; left time: 325.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 891 | Train Loss: 0.1772448 Vali Loss: 0.0513917 Test Loss: 0.0559006\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1734857\n",
      "\tspeed: 0.1846s/iter; left time: 1133.2929s\n",
      "\titers: 200, epoch: 4 | loss: 0.2071112\n",
      "\tspeed: 0.0512s/iter; left time: 308.9393s\n",
      "\titers: 300, epoch: 4 | loss: 0.1732179\n",
      "\tspeed: 0.0517s/iter; left time: 306.7429s\n",
      "\titers: 400, epoch: 4 | loss: 0.1830900\n",
      "\tspeed: 0.0515s/iter; left time: 300.8052s\n",
      "\titers: 500, epoch: 4 | loss: 0.1908277\n",
      "\tspeed: 0.0514s/iter; left time: 295.1813s\n",
      "\titers: 600, epoch: 4 | loss: 0.1779769\n",
      "\tspeed: 0.0510s/iter; left time: 287.7171s\n",
      "\titers: 700, epoch: 4 | loss: 0.1641509\n",
      "\tspeed: 0.0516s/iter; left time: 285.9883s\n",
      "\titers: 800, epoch: 4 | loss: 0.1536071\n",
      "\tspeed: 0.0514s/iter; left time: 279.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 891 | Train Loss: 0.1759789 Vali Loss: 0.0377152 Test Loss: 0.0450661\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0417700931429863, rmse:0.20437732338905334, mae:0.14354148507118225, rse:0.7237414717674255\n",
      "Original data scale mse:37400496.0, rmse:6115.5947265625, mae:4083.6396484375, rse:0.30455881357192993\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905224\n",
      "\tspeed: 0.0541s/iter; left time: 476.3775s\n",
      "\titers: 200, epoch: 1 | loss: 0.2478231\n",
      "\tspeed: 0.0514s/iter; left time: 447.4780s\n",
      "\titers: 300, epoch: 1 | loss: 0.2508713\n",
      "\tspeed: 0.0511s/iter; left time: 440.3011s\n",
      "\titers: 400, epoch: 1 | loss: 0.2173596\n",
      "\tspeed: 0.0514s/iter; left time: 437.1737s\n",
      "\titers: 500, epoch: 1 | loss: 0.2019476\n",
      "\tspeed: 0.0515s/iter; left time: 433.2517s\n",
      "\titers: 600, epoch: 1 | loss: 0.1851319\n",
      "\tspeed: 0.0513s/iter; left time: 426.6779s\n",
      "\titers: 700, epoch: 1 | loss: 0.1852116\n",
      "\tspeed: 0.0518s/iter; left time: 425.1461s\n",
      "\titers: 800, epoch: 1 | loss: 0.1701697\n",
      "\tspeed: 0.0523s/iter; left time: 423.8960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 891 | Train Loss: 0.2257705 Vali Loss: 0.0356901 Test Loss: 0.0408679\n",
      "Validation loss decreased (inf --> 0.035690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1766219\n",
      "\tspeed: 0.1867s/iter; left time: 1478.4495s\n",
      "\titers: 200, epoch: 2 | loss: 0.1569152\n",
      "\tspeed: 0.0518s/iter; left time: 405.0618s\n",
      "\titers: 300, epoch: 2 | loss: 0.1903155\n",
      "\tspeed: 0.0515s/iter; left time: 397.5906s\n",
      "\titers: 400, epoch: 2 | loss: 0.1766812\n",
      "\tspeed: 0.0516s/iter; left time: 392.8595s\n",
      "\titers: 500, epoch: 2 | loss: 0.1464813\n",
      "\tspeed: 0.0521s/iter; left time: 391.8746s\n",
      "\titers: 600, epoch: 2 | loss: 0.1728570\n",
      "\tspeed: 0.0519s/iter; left time: 384.8997s\n",
      "\titers: 700, epoch: 2 | loss: 0.1685364\n",
      "\tspeed: 0.0522s/iter; left time: 382.0112s\n",
      "\titers: 800, epoch: 2 | loss: 0.1575332\n",
      "\tspeed: 0.0516s/iter; left time: 372.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 891 | Train Loss: 0.1764099 Vali Loss: 0.0326616 Test Loss: 0.0390360\n",
      "Validation loss decreased (0.035690 --> 0.032662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1591886\n",
      "\tspeed: 0.1862s/iter; left time: 1308.8118s\n",
      "\titers: 200, epoch: 3 | loss: 0.1482840\n",
      "\tspeed: 0.0544s/iter; left time: 377.0902s\n",
      "\titers: 300, epoch: 3 | loss: 0.1686443\n",
      "\tspeed: 0.0508s/iter; left time: 346.8492s\n",
      "\titers: 400, epoch: 3 | loss: 0.1573136\n",
      "\tspeed: 0.0507s/iter; left time: 341.3352s\n",
      "\titers: 500, epoch: 3 | loss: 0.1550483\n",
      "\tspeed: 0.0519s/iter; left time: 343.7490s\n",
      "\titers: 600, epoch: 3 | loss: 0.3653665\n",
      "\tspeed: 0.0516s/iter; left time: 336.7873s\n",
      "\titers: 700, epoch: 3 | loss: 0.2134402\n",
      "\tspeed: 0.0517s/iter; left time: 332.2702s\n",
      "\titers: 800, epoch: 3 | loss: 0.1850701\n",
      "\tspeed: 0.0518s/iter; left time: 328.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.43s\n",
      "Steps: 891 | Train Loss: 0.1822032 Vali Loss: 0.0443810 Test Loss: 0.0515197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1735435\n",
      "\tspeed: 0.1836s/iter; left time: 1127.1271s\n",
      "\titers: 200, epoch: 4 | loss: 0.1826856\n",
      "\tspeed: 0.0519s/iter; left time: 313.6510s\n",
      "\titers: 300, epoch: 4 | loss: 0.1559070\n",
      "\tspeed: 0.0516s/iter; left time: 306.6730s\n",
      "\titers: 400, epoch: 4 | loss: 0.1708269\n",
      "\tspeed: 0.0516s/iter; left time: 301.1164s\n",
      "\titers: 500, epoch: 4 | loss: 0.1657308\n",
      "\tspeed: 0.0514s/iter; left time: 294.7803s\n",
      "\titers: 600, epoch: 4 | loss: 0.1688064\n",
      "\tspeed: 0.0518s/iter; left time: 291.9739s\n",
      "\titers: 700, epoch: 4 | loss: 0.1750592\n",
      "\tspeed: 0.0518s/iter; left time: 286.8813s\n",
      "\titers: 800, epoch: 4 | loss: 0.1598610\n",
      "\tspeed: 0.0515s/iter; left time: 280.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.27s\n",
      "Steps: 891 | Train Loss: 0.1785153 Vali Loss: 0.0372040 Test Loss: 0.0437215\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1626792\n",
      "\tspeed: 0.1856s/iter; left time: 973.9020s\n",
      "\titers: 200, epoch: 5 | loss: 0.1442192\n",
      "\tspeed: 0.0514s/iter; left time: 264.6148s\n",
      "\titers: 300, epoch: 5 | loss: 0.1605345\n",
      "\tspeed: 0.0517s/iter; left time: 260.9906s\n",
      "\titers: 400, epoch: 5 | loss: 0.1693277\n",
      "\tspeed: 0.0522s/iter; left time: 258.0418s\n",
      "\titers: 500, epoch: 5 | loss: 0.1601463\n",
      "\tspeed: 0.0515s/iter; left time: 249.7224s\n",
      "\titers: 600, epoch: 5 | loss: 0.1603393\n",
      "\tspeed: 0.0515s/iter; left time: 244.3627s\n",
      "\titers: 700, epoch: 5 | loss: 0.2077260\n",
      "\tspeed: 0.0519s/iter; left time: 241.1582s\n",
      "\titers: 800, epoch: 5 | loss: 0.1633071\n",
      "\tspeed: 0.0517s/iter; left time: 234.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.39s\n",
      "Steps: 891 | Train Loss: 0.1763571 Vali Loss: 0.0333679 Test Loss: 0.0416124\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03903603553771973, rmse:0.1975753903388977, mae:0.13909867405891418, rse:0.6996544003486633\n",
      "Original data scale mse:34960184.0, rmse:5912.7138671875, mae:3935.287109375, rse:0.29445526003837585\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2962539\n",
      "\tspeed: 0.0766s/iter; left time: 673.3237s\n",
      "\titers: 200, epoch: 1 | loss: 0.2597189\n",
      "\tspeed: 0.0519s/iter; left time: 450.8672s\n",
      "\titers: 300, epoch: 1 | loss: 0.2409032\n",
      "\tspeed: 0.0528s/iter; left time: 453.9701s\n",
      "\titers: 400, epoch: 1 | loss: 0.2257529\n",
      "\tspeed: 0.0528s/iter; left time: 448.4342s\n",
      "\titers: 500, epoch: 1 | loss: 0.2161573\n",
      "\tspeed: 0.0531s/iter; left time: 445.6228s\n",
      "\titers: 600, epoch: 1 | loss: 0.1973591\n",
      "\tspeed: 0.0519s/iter; left time: 430.0998s\n",
      "\titers: 700, epoch: 1 | loss: 0.1953906\n",
      "\tspeed: 0.0519s/iter; left time: 425.2627s\n",
      "\titers: 800, epoch: 1 | loss: 0.1903252\n",
      "\tspeed: 0.0530s/iter; left time: 428.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 889 | Train Loss: 0.2289548 Vali Loss: 0.0373104 Test Loss: 0.0437779\n",
      "Validation loss decreased (inf --> 0.037310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1962126\n",
      "\tspeed: 0.1977s/iter; left time: 1562.4157s\n",
      "\titers: 200, epoch: 2 | loss: 0.1616807\n",
      "\tspeed: 0.0521s/iter; left time: 406.6628s\n",
      "\titers: 300, epoch: 2 | loss: 0.1807901\n",
      "\tspeed: 0.0532s/iter; left time: 409.7283s\n",
      "\titers: 400, epoch: 2 | loss: 0.1725992\n",
      "\tspeed: 0.0527s/iter; left time: 400.4995s\n",
      "\titers: 500, epoch: 2 | loss: 0.1667260\n",
      "\tspeed: 0.0521s/iter; left time: 391.0279s\n",
      "\titers: 600, epoch: 2 | loss: 0.1616608\n",
      "\tspeed: 0.0527s/iter; left time: 389.8426s\n",
      "\titers: 700, epoch: 2 | loss: 0.1625210\n",
      "\tspeed: 0.0526s/iter; left time: 383.9866s\n",
      "\titers: 800, epoch: 2 | loss: 0.1661494\n",
      "\tspeed: 0.0535s/iter; left time: 385.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 889 | Train Loss: 0.1778594 Vali Loss: 0.0342725 Test Loss: 0.0409164\n",
      "Validation loss decreased (0.037310 --> 0.034272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1574290\n",
      "\tspeed: 0.1887s/iter; left time: 1323.0146s\n",
      "\titers: 200, epoch: 3 | loss: 0.1431362\n",
      "\tspeed: 0.0524s/iter; left time: 362.1318s\n",
      "\titers: 300, epoch: 3 | loss: 0.1815083\n",
      "\tspeed: 0.0526s/iter; left time: 358.5971s\n",
      "\titers: 400, epoch: 3 | loss: 0.2047267\n",
      "\tspeed: 0.0530s/iter; left time: 355.5157s\n",
      "\titers: 500, epoch: 3 | loss: 0.1969939\n",
      "\tspeed: 0.0531s/iter; left time: 350.9622s\n",
      "\titers: 600, epoch: 3 | loss: 0.2014310\n",
      "\tspeed: 0.0529s/iter; left time: 344.6922s\n",
      "\titers: 700, epoch: 3 | loss: 0.1706726\n",
      "\tspeed: 0.0525s/iter; left time: 336.9412s\n",
      "\titers: 800, epoch: 3 | loss: 0.1971276\n",
      "\tspeed: 0.0528s/iter; left time: 333.2130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 889 | Train Loss: 0.1877892 Vali Loss: 0.0515518 Test Loss: 0.0571752\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1694866\n",
      "\tspeed: 0.1845s/iter; left time: 1129.9909s\n",
      "\titers: 200, epoch: 4 | loss: 0.1533536\n",
      "\tspeed: 0.0522s/iter; left time: 314.6850s\n",
      "\titers: 300, epoch: 4 | loss: 0.1712260\n",
      "\tspeed: 0.0528s/iter; left time: 312.5277s\n",
      "\titers: 400, epoch: 4 | loss: 0.1704170\n",
      "\tspeed: 0.0521s/iter; left time: 303.1909s\n",
      "\titers: 500, epoch: 4 | loss: 0.2027668\n",
      "\tspeed: 0.0523s/iter; left time: 299.2828s\n",
      "\titers: 600, epoch: 4 | loss: 0.1704978\n",
      "\tspeed: 0.0524s/iter; left time: 294.8546s\n",
      "\titers: 700, epoch: 4 | loss: 0.1803890\n",
      "\tspeed: 0.0520s/iter; left time: 287.2567s\n",
      "\titers: 800, epoch: 4 | loss: 0.1712807\n",
      "\tspeed: 0.0518s/iter; left time: 280.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.78s\n",
      "Steps: 889 | Train Loss: 0.1717168 Vali Loss: 0.0379079 Test Loss: 0.0476264\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1698242\n",
      "\tspeed: 0.1842s/iter; left time: 964.3124s\n",
      "\titers: 200, epoch: 5 | loss: 0.2546397\n",
      "\tspeed: 0.0528s/iter; left time: 271.2411s\n",
      "\titers: 300, epoch: 5 | loss: 0.1922085\n",
      "\tspeed: 0.0529s/iter; left time: 266.1309s\n",
      "\titers: 400, epoch: 5 | loss: 0.1765233\n",
      "\tspeed: 0.0523s/iter; left time: 257.8884s\n",
      "\titers: 500, epoch: 5 | loss: 0.1747154\n",
      "\tspeed: 0.0527s/iter; left time: 254.8064s\n",
      "\titers: 600, epoch: 5 | loss: 0.1772095\n",
      "\tspeed: 0.0527s/iter; left time: 249.4396s\n",
      "\titers: 700, epoch: 5 | loss: 0.1871462\n",
      "\tspeed: 0.0519s/iter; left time: 240.7609s\n",
      "\titers: 800, epoch: 5 | loss: 0.1633518\n",
      "\tspeed: 0.0514s/iter; left time: 233.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.77s\n",
      "Steps: 889 | Train Loss: 0.1771401 Vali Loss: 0.0421679 Test Loss: 0.0515530\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04091637581586838, rmse:0.20227797329425812, mae:0.1402643620967865, rse:0.7166099548339844\n",
      "Original data scale mse:35232612.0, rmse:5935.70654296875, mae:3864.7724609375, rse:0.2957454323768616\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3126400\n",
      "\tspeed: 0.0553s/iter; left time: 486.2099s\n",
      "\titers: 200, epoch: 1 | loss: 0.2838092\n",
      "\tspeed: 0.0526s/iter; left time: 456.7842s\n",
      "\titers: 300, epoch: 1 | loss: 0.2556389\n",
      "\tspeed: 0.0529s/iter; left time: 454.8392s\n",
      "\titers: 400, epoch: 1 | loss: 0.2314915\n",
      "\tspeed: 0.0525s/iter; left time: 445.4127s\n",
      "\titers: 500, epoch: 1 | loss: 0.2110980\n",
      "\tspeed: 0.0527s/iter; left time: 442.4977s\n",
      "\titers: 600, epoch: 1 | loss: 0.1892689\n",
      "\tspeed: 0.0520s/iter; left time: 431.2933s\n",
      "\titers: 700, epoch: 1 | loss: 0.1940349\n",
      "\tspeed: 0.0525s/iter; left time: 430.3962s\n",
      "\titers: 800, epoch: 1 | loss: 0.1824178\n",
      "\tspeed: 0.0530s/iter; left time: 428.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 889 | Train Loss: 0.2303312 Vali Loss: 0.0366757 Test Loss: 0.0426439\n",
      "Validation loss decreased (inf --> 0.036676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1810439\n",
      "\tspeed: 0.1862s/iter; left time: 1471.5125s\n",
      "\titers: 200, epoch: 2 | loss: 0.1716500\n",
      "\tspeed: 0.0529s/iter; left time: 412.8334s\n",
      "\titers: 300, epoch: 2 | loss: 0.1776369\n",
      "\tspeed: 0.0525s/iter; left time: 404.0041s\n",
      "\titers: 400, epoch: 2 | loss: 0.1776479\n",
      "\tspeed: 0.0524s/iter; left time: 398.2469s\n",
      "\titers: 500, epoch: 2 | loss: 0.1882042\n",
      "\tspeed: 0.0527s/iter; left time: 395.2423s\n",
      "\titers: 600, epoch: 2 | loss: 0.1689138\n",
      "\tspeed: 0.0524s/iter; left time: 388.1669s\n",
      "\titers: 700, epoch: 2 | loss: 0.1543402\n",
      "\tspeed: 0.0525s/iter; left time: 383.6116s\n",
      "\titers: 800, epoch: 2 | loss: 0.1663143\n",
      "\tspeed: 0.0523s/iter; left time: 376.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.98s\n",
      "Steps: 889 | Train Loss: 0.1789434 Vali Loss: 0.0574112 Test Loss: 0.0628860\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1614779\n",
      "\tspeed: 0.1846s/iter; left time: 1294.6501s\n",
      "\titers: 200, epoch: 3 | loss: 0.1795685\n",
      "\tspeed: 0.0522s/iter; left time: 360.7042s\n",
      "\titers: 300, epoch: 3 | loss: 0.1917062\n",
      "\tspeed: 0.0536s/iter; left time: 364.9258s\n",
      "\titers: 400, epoch: 3 | loss: 0.1910664\n",
      "\tspeed: 0.0524s/iter; left time: 352.0160s\n",
      "\titers: 500, epoch: 3 | loss: 0.2224540\n",
      "\tspeed: 0.0518s/iter; left time: 342.3536s\n",
      "\titers: 600, epoch: 3 | loss: 0.1679021\n",
      "\tspeed: 0.0524s/iter; left time: 341.1466s\n",
      "\titers: 700, epoch: 3 | loss: 0.1858870\n",
      "\tspeed: 0.0522s/iter; left time: 334.5338s\n",
      "\titers: 800, epoch: 3 | loss: 0.2021402\n",
      "\tspeed: 0.0515s/iter; left time: 325.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.78s\n",
      "Steps: 889 | Train Loss: 0.1894913 Vali Loss: 0.0425699 Test Loss: 0.0521171\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1760504\n",
      "\tspeed: 0.1841s/iter; left time: 1127.7219s\n",
      "\titers: 200, epoch: 4 | loss: 0.1538943\n",
      "\tspeed: 0.0519s/iter; left time: 312.9038s\n",
      "\titers: 300, epoch: 4 | loss: 0.1770946\n",
      "\tspeed: 0.0520s/iter; left time: 308.0655s\n",
      "\titers: 400, epoch: 4 | loss: 0.1555688\n",
      "\tspeed: 0.0529s/iter; left time: 308.3697s\n",
      "\titers: 500, epoch: 4 | loss: 0.1820136\n",
      "\tspeed: 0.0523s/iter; left time: 299.2411s\n",
      "\titers: 600, epoch: 4 | loss: 0.1585305\n",
      "\tspeed: 0.0513s/iter; left time: 288.6103s\n",
      "\titers: 700, epoch: 4 | loss: 0.1991186\n",
      "\tspeed: 0.0511s/iter; left time: 282.1199s\n",
      "\titers: 800, epoch: 4 | loss: 0.1716689\n",
      "\tspeed: 0.0525s/iter; left time: 284.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.58s\n",
      "Steps: 889 | Train Loss: 0.1715612 Vali Loss: 0.0393669 Test Loss: 0.0481006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0426439493894577, rmse:0.20650412142276764, mae:0.14669473469257355, rse:0.7315818667411804\n",
      "Original data scale mse:39467032.0, rmse:6282.279296875, mae:4191.44921875, rse:0.31301331520080566\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1997931\n",
      "\tspeed: 0.0744s/iter; left time: 657.4145s\n",
      "\titers: 200, epoch: 1 | loss: 0.1910664\n",
      "\tspeed: 0.0501s/iter; left time: 437.7558s\n",
      "\titers: 300, epoch: 1 | loss: 0.1661717\n",
      "\tspeed: 0.0503s/iter; left time: 434.3696s\n",
      "\titers: 400, epoch: 1 | loss: 0.1595792\n",
      "\tspeed: 0.0505s/iter; left time: 430.6001s\n",
      "\titers: 500, epoch: 1 | loss: 0.1507766\n",
      "\tspeed: 0.0506s/iter; left time: 426.4744s\n",
      "\titers: 600, epoch: 1 | loss: 0.1500345\n",
      "\tspeed: 0.0509s/iter; left time: 424.2414s\n",
      "\titers: 700, epoch: 1 | loss: 0.1288310\n",
      "\tspeed: 0.0513s/iter; left time: 422.5751s\n",
      "\titers: 800, epoch: 1 | loss: 0.1301010\n",
      "\tspeed: 0.0506s/iter; left time: 411.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.1598665 Vali Loss: 0.1094445 Test Loss: 0.1122075\n",
      "Validation loss decreased (inf --> 0.109444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1560906\n",
      "\tspeed: 0.1850s/iter; left time: 1468.3269s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256281\n",
      "\tspeed: 0.0510s/iter; left time: 399.3529s\n",
      "\titers: 300, epoch: 2 | loss: 0.1037456\n",
      "\tspeed: 0.0510s/iter; left time: 394.3048s\n",
      "\titers: 400, epoch: 2 | loss: 0.1085704\n",
      "\tspeed: 0.0508s/iter; left time: 387.8506s\n",
      "\titers: 500, epoch: 2 | loss: 0.1069496\n",
      "\tspeed: 0.0504s/iter; left time: 379.9537s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993467\n",
      "\tspeed: 0.0510s/iter; left time: 379.2701s\n",
      "\titers: 700, epoch: 2 | loss: 0.0953315\n",
      "\tspeed: 0.0511s/iter; left time: 375.0899s\n",
      "\titers: 800, epoch: 2 | loss: 0.0859820\n",
      "\tspeed: 0.0506s/iter; left time: 366.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.63s\n",
      "Steps: 893 | Train Loss: 0.1134260 Vali Loss: 0.0984555 Test Loss: 0.1021205\n",
      "Validation loss decreased (0.109444 --> 0.098455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0723415\n",
      "\tspeed: 0.1857s/iter; left time: 1308.2224s\n",
      "\titers: 200, epoch: 3 | loss: 0.0859736\n",
      "\tspeed: 0.0509s/iter; left time: 353.2183s\n",
      "\titers: 300, epoch: 3 | loss: 0.0840666\n",
      "\tspeed: 0.0512s/iter; left time: 350.2460s\n",
      "\titers: 400, epoch: 3 | loss: 0.0838655\n",
      "\tspeed: 0.0507s/iter; left time: 342.0209s\n",
      "\titers: 500, epoch: 3 | loss: 0.0852574\n",
      "\tspeed: 0.0513s/iter; left time: 340.9700s\n",
      "\titers: 600, epoch: 3 | loss: 0.0989086\n",
      "\tspeed: 0.0511s/iter; left time: 334.2882s\n",
      "\titers: 700, epoch: 3 | loss: 0.0686446\n",
      "\tspeed: 0.0503s/iter; left time: 324.3028s\n",
      "\titers: 800, epoch: 3 | loss: 0.1060894\n",
      "\tspeed: 0.0512s/iter; left time: 325.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 893 | Train Loss: 0.0890301 Vali Loss: 0.1076463 Test Loss: 0.1092328\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0889363\n",
      "\tspeed: 0.1844s/iter; left time: 1134.4264s\n",
      "\titers: 200, epoch: 4 | loss: 0.0875304\n",
      "\tspeed: 0.0502s/iter; left time: 303.7476s\n",
      "\titers: 300, epoch: 4 | loss: 0.0844679\n",
      "\tspeed: 0.0497s/iter; left time: 295.8210s\n",
      "\titers: 400, epoch: 4 | loss: 0.0738833\n",
      "\tspeed: 0.0499s/iter; left time: 292.2832s\n",
      "\titers: 500, epoch: 4 | loss: 0.0962841\n",
      "\tspeed: 0.0515s/iter; left time: 296.2194s\n",
      "\titers: 600, epoch: 4 | loss: 0.0890386\n",
      "\tspeed: 0.0502s/iter; left time: 283.8183s\n",
      "\titers: 700, epoch: 4 | loss: 0.0706904\n",
      "\tspeed: 0.0503s/iter; left time: 279.3749s\n",
      "\titers: 800, epoch: 4 | loss: 0.0899874\n",
      "\tspeed: 0.0513s/iter; left time: 279.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.41s\n",
      "Steps: 893 | Train Loss: 0.0867351 Vali Loss: 0.0989426 Test Loss: 0.1015717\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785159\n",
      "\tspeed: 0.1836s/iter; left time: 965.5045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728950\n",
      "\tspeed: 0.0508s/iter; left time: 262.0787s\n",
      "\titers: 300, epoch: 5 | loss: 0.0859396\n",
      "\tspeed: 0.0511s/iter; left time: 258.4462s\n",
      "\titers: 400, epoch: 5 | loss: 0.0733304\n",
      "\tspeed: 0.0511s/iter; left time: 253.4452s\n",
      "\titers: 500, epoch: 5 | loss: 0.0842119\n",
      "\tspeed: 0.0508s/iter; left time: 246.7513s\n",
      "\titers: 600, epoch: 5 | loss: 0.0684475\n",
      "\tspeed: 0.0521s/iter; left time: 247.8785s\n",
      "\titers: 700, epoch: 5 | loss: 0.0841173\n",
      "\tspeed: 0.0510s/iter; left time: 237.3777s\n",
      "\titers: 800, epoch: 5 | loss: 0.1220546\n",
      "\tspeed: 0.0512s/iter; left time: 233.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 893 | Train Loss: 0.0841638 Vali Loss: 0.0951009 Test Loss: 0.0974293\n",
      "Validation loss decreased (0.098455 --> 0.095101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0697004\n",
      "\tspeed: 0.1848s/iter; left time: 807.0222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0861662\n",
      "\tspeed: 0.0510s/iter; left time: 217.6993s\n",
      "\titers: 300, epoch: 6 | loss: 0.0765070\n",
      "\tspeed: 0.0507s/iter; left time: 211.1037s\n",
      "\titers: 400, epoch: 6 | loss: 0.0644519\n",
      "\tspeed: 0.0508s/iter; left time: 206.6133s\n",
      "\titers: 500, epoch: 6 | loss: 0.0770516\n",
      "\tspeed: 0.0512s/iter; left time: 202.9512s\n",
      "\titers: 600, epoch: 6 | loss: 0.0821126\n",
      "\tspeed: 0.0512s/iter; left time: 197.8304s\n",
      "\titers: 700, epoch: 6 | loss: 0.0706967\n",
      "\tspeed: 0.0513s/iter; left time: 193.0715s\n",
      "\titers: 800, epoch: 6 | loss: 0.0797850\n",
      "\tspeed: 0.0514s/iter; left time: 188.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 893 | Train Loss: 0.0789132 Vali Loss: 0.0939661 Test Loss: 0.0975538\n",
      "Validation loss decreased (0.095101 --> 0.093966).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0796635\n",
      "\tspeed: 0.1848s/iter; left time: 641.8362s\n",
      "\titers: 200, epoch: 7 | loss: 0.0687510\n",
      "\tspeed: 0.0514s/iter; left time: 173.3989s\n",
      "\titers: 300, epoch: 7 | loss: 0.0841762\n",
      "\tspeed: 0.0511s/iter; left time: 167.1700s\n",
      "\titers: 400, epoch: 7 | loss: 0.0754226\n",
      "\tspeed: 0.0505s/iter; left time: 160.1251s\n",
      "\titers: 500, epoch: 7 | loss: 0.0820318\n",
      "\tspeed: 0.0503s/iter; left time: 154.6583s\n",
      "\titers: 600, epoch: 7 | loss: 0.0727707\n",
      "\tspeed: 0.0507s/iter; left time: 150.8418s\n",
      "\titers: 700, epoch: 7 | loss: 0.0769150\n",
      "\tspeed: 0.0511s/iter; left time: 146.7950s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783799\n",
      "\tspeed: 0.0512s/iter; left time: 142.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.68s\n",
      "Steps: 893 | Train Loss: 0.0767029 Vali Loss: 0.0906185 Test Loss: 0.0952226\n",
      "Validation loss decreased (0.093966 --> 0.090618).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0707073\n",
      "\tspeed: 0.1849s/iter; left time: 476.9150s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752434\n",
      "\tspeed: 0.0533s/iter; left time: 132.1413s\n",
      "\titers: 300, epoch: 8 | loss: 0.0653987\n",
      "\tspeed: 0.0499s/iter; left time: 118.6536s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776333\n",
      "\tspeed: 0.0507s/iter; left time: 115.5024s\n",
      "\titers: 500, epoch: 8 | loss: 0.0796481\n",
      "\tspeed: 0.0505s/iter; left time: 110.0598s\n",
      "\titers: 600, epoch: 8 | loss: 0.0609225\n",
      "\tspeed: 0.0507s/iter; left time: 105.5272s\n",
      "\titers: 700, epoch: 8 | loss: 0.0696919\n",
      "\tspeed: 0.0504s/iter; left time: 99.7131s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806831\n",
      "\tspeed: 0.0506s/iter; left time: 95.1642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 893 | Train Loss: 0.0739587 Vali Loss: 0.1017428 Test Loss: 0.1021738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600137\n",
      "\tspeed: 0.1820s/iter; left time: 307.0766s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684734\n",
      "\tspeed: 0.0507s/iter; left time: 80.4106s\n",
      "\titers: 300, epoch: 9 | loss: 0.0719938\n",
      "\tspeed: 0.0516s/iter; left time: 76.7267s\n",
      "\titers: 400, epoch: 9 | loss: 0.0641858\n",
      "\tspeed: 0.0510s/iter; left time: 70.6727s\n",
      "\titers: 500, epoch: 9 | loss: 0.0699579\n",
      "\tspeed: 0.0513s/iter; left time: 66.0260s\n",
      "\titers: 600, epoch: 9 | loss: 0.0762686\n",
      "\tspeed: 0.0514s/iter; left time: 60.9553s\n",
      "\titers: 700, epoch: 9 | loss: 0.0735367\n",
      "\tspeed: 0.0519s/iter; left time: 56.4041s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660792\n",
      "\tspeed: 0.0515s/iter; left time: 50.8301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 893 | Train Loss: 0.0714821 Vali Loss: 0.0913283 Test Loss: 0.0946512\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738563\n",
      "\tspeed: 0.1814s/iter; left time: 144.0335s\n",
      "\titers: 200, epoch: 10 | loss: 0.0659100\n",
      "\tspeed: 0.0511s/iter; left time: 35.4628s\n",
      "\titers: 300, epoch: 10 | loss: 0.0619273\n",
      "\tspeed: 0.0518s/iter; left time: 30.7744s\n",
      "\titers: 400, epoch: 10 | loss: 0.0765655\n",
      "\tspeed: 0.0513s/iter; left time: 25.3249s\n",
      "\titers: 500, epoch: 10 | loss: 0.0660495\n",
      "\tspeed: 0.0508s/iter; left time: 20.0043s\n",
      "\titers: 600, epoch: 10 | loss: 0.0688389\n",
      "\tspeed: 0.0514s/iter; left time: 15.1221s\n",
      "\titers: 700, epoch: 10 | loss: 0.0744282\n",
      "\tspeed: 0.0519s/iter; left time: 10.0697s\n",
      "\titers: 800, epoch: 10 | loss: 0.0680481\n",
      "\tspeed: 0.0514s/iter; left time: 4.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 893 | Train Loss: 0.0700369 Vali Loss: 0.0908857 Test Loss: 0.0951032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022842537611722946, rmse:0.15113748610019684, mae:0.09522261470556259, rse:0.533746063709259\n",
      "Original data scale mse:17627044.0, rmse:4198.45751953125, mae:2560.031982421875, rse:0.208755761384964\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1832071\n",
      "\tspeed: 0.0532s/iter; left time: 469.5229s\n",
      "\titers: 200, epoch: 1 | loss: 0.1858170\n",
      "\tspeed: 0.0513s/iter; left time: 447.4949s\n",
      "\titers: 300, epoch: 1 | loss: 0.1677893\n",
      "\tspeed: 0.0514s/iter; left time: 443.6954s\n",
      "\titers: 400, epoch: 1 | loss: 0.1518474\n",
      "\tspeed: 0.0511s/iter; left time: 435.6898s\n",
      "\titers: 500, epoch: 1 | loss: 0.1351320\n",
      "\tspeed: 0.0512s/iter; left time: 431.9127s\n",
      "\titers: 600, epoch: 1 | loss: 0.1306523\n",
      "\tspeed: 0.0505s/iter; left time: 420.8642s\n",
      "\titers: 700, epoch: 1 | loss: 0.1308791\n",
      "\tspeed: 0.0512s/iter; left time: 421.5326s\n",
      "\titers: 800, epoch: 1 | loss: 0.1226921\n",
      "\tspeed: 0.0513s/iter; left time: 417.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 893 | Train Loss: 0.1575953 Vali Loss: 0.1089087 Test Loss: 0.1117898\n",
      "Validation loss decreased (inf --> 0.108909).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1677086\n",
      "\tspeed: 0.1886s/iter; left time: 1496.7126s\n",
      "\titers: 200, epoch: 2 | loss: 0.1173048\n",
      "\tspeed: 0.0505s/iter; left time: 395.8875s\n",
      "\titers: 300, epoch: 2 | loss: 0.1048325\n",
      "\tspeed: 0.0512s/iter; left time: 395.9287s\n",
      "\titers: 400, epoch: 2 | loss: 0.1069137\n",
      "\tspeed: 0.0516s/iter; left time: 393.7406s\n",
      "\titers: 500, epoch: 2 | loss: 0.1053712\n",
      "\tspeed: 0.0510s/iter; left time: 384.1904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1057843\n",
      "\tspeed: 0.0506s/iter; left time: 376.2398s\n",
      "\titers: 700, epoch: 2 | loss: 0.1155008\n",
      "\tspeed: 0.0534s/iter; left time: 391.5302s\n",
      "\titers: 800, epoch: 2 | loss: 0.0857749\n",
      "\tspeed: 0.0575s/iter; left time: 416.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.50s\n",
      "Steps: 893 | Train Loss: 0.1172667 Vali Loss: 0.1017002 Test Loss: 0.1048007\n",
      "Validation loss decreased (0.108909 --> 0.101700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029922\n",
      "\tspeed: 0.1864s/iter; left time: 1313.0460s\n",
      "\titers: 200, epoch: 3 | loss: 0.0860792\n",
      "\tspeed: 0.0508s/iter; left time: 353.0912s\n",
      "\titers: 300, epoch: 3 | loss: 0.0915276\n",
      "\tspeed: 0.0509s/iter; left time: 348.5063s\n",
      "\titers: 400, epoch: 3 | loss: 0.1055479\n",
      "\tspeed: 0.0512s/iter; left time: 345.3710s\n",
      "\titers: 500, epoch: 3 | loss: 0.1176642\n",
      "\tspeed: 0.0514s/iter; left time: 341.2853s\n",
      "\titers: 600, epoch: 3 | loss: 0.0908892\n",
      "\tspeed: 0.0508s/iter; left time: 332.3336s\n",
      "\titers: 700, epoch: 3 | loss: 0.1077004\n",
      "\tspeed: 0.0512s/iter; left time: 329.9343s\n",
      "\titers: 800, epoch: 3 | loss: 0.0854108\n",
      "\tspeed: 0.0517s/iter; left time: 328.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 893 | Train Loss: 0.0939500 Vali Loss: 0.0990608 Test Loss: 0.1020935\n",
      "Validation loss decreased (0.101700 --> 0.099061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944565\n",
      "\tspeed: 0.1849s/iter; left time: 1137.4237s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823357\n",
      "\tspeed: 0.0509s/iter; left time: 307.9393s\n",
      "\titers: 300, epoch: 4 | loss: 0.0779113\n",
      "\tspeed: 0.0509s/iter; left time: 303.0753s\n",
      "\titers: 400, epoch: 4 | loss: 0.0860680\n",
      "\tspeed: 0.0519s/iter; left time: 303.6130s\n",
      "\titers: 500, epoch: 4 | loss: 0.0714134\n",
      "\tspeed: 0.0510s/iter; left time: 293.5821s\n",
      "\titers: 600, epoch: 4 | loss: 0.0896662\n",
      "\tspeed: 0.0511s/iter; left time: 288.7413s\n",
      "\titers: 700, epoch: 4 | loss: 0.0857838\n",
      "\tspeed: 0.0514s/iter; left time: 285.5240s\n",
      "\titers: 800, epoch: 4 | loss: 0.0812388\n",
      "\tspeed: 0.0510s/iter; left time: 278.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 893 | Train Loss: 0.0838707 Vali Loss: 0.0962228 Test Loss: 0.1000479\n",
      "Validation loss decreased (0.099061 --> 0.096223).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0893224\n",
      "\tspeed: 0.1844s/iter; left time: 969.5413s\n",
      "\titers: 200, epoch: 5 | loss: 0.1343427\n",
      "\tspeed: 0.0511s/iter; left time: 263.8450s\n",
      "\titers: 300, epoch: 5 | loss: 0.0967780\n",
      "\tspeed: 0.0513s/iter; left time: 259.5527s\n",
      "\titers: 400, epoch: 5 | loss: 0.0797359\n",
      "\tspeed: 0.0508s/iter; left time: 251.7118s\n",
      "\titers: 500, epoch: 5 | loss: 0.0830635\n",
      "\tspeed: 0.0508s/iter; left time: 246.8456s\n",
      "\titers: 600, epoch: 5 | loss: 0.0844677\n",
      "\tspeed: 0.0514s/iter; left time: 244.5341s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755263\n",
      "\tspeed: 0.0516s/iter; left time: 240.5879s\n",
      "\titers: 800, epoch: 5 | loss: 0.0798598\n",
      "\tspeed: 0.0517s/iter; left time: 235.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 893 | Train Loss: 0.0836162 Vali Loss: 0.0969208 Test Loss: 0.1004519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0761862\n",
      "\tspeed: 0.1884s/iter; left time: 822.4918s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739761\n",
      "\tspeed: 0.0507s/iter; left time: 216.1246s\n",
      "\titers: 300, epoch: 6 | loss: 0.0641037\n",
      "\tspeed: 0.0513s/iter; left time: 213.9222s\n",
      "\titers: 400, epoch: 6 | loss: 0.0843469\n",
      "\tspeed: 0.0517s/iter; left time: 210.3612s\n",
      "\titers: 500, epoch: 6 | loss: 0.0818670\n",
      "\tspeed: 0.0506s/iter; left time: 200.7129s\n",
      "\titers: 600, epoch: 6 | loss: 0.0814780\n",
      "\tspeed: 0.0509s/iter; left time: 196.7117s\n",
      "\titers: 700, epoch: 6 | loss: 0.0829946\n",
      "\tspeed: 0.0508s/iter; left time: 191.3410s\n",
      "\titers: 800, epoch: 6 | loss: 0.0819412\n",
      "\tspeed: 0.0504s/iter; left time: 184.9303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0802414 Vali Loss: 0.0915390 Test Loss: 0.0948459\n",
      "Validation loss decreased (0.096223 --> 0.091539).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0885544\n",
      "\tspeed: 0.1859s/iter; left time: 645.4666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0815407\n",
      "\tspeed: 0.0518s/iter; left time: 174.7278s\n",
      "\titers: 300, epoch: 7 | loss: 0.0668346\n",
      "\tspeed: 0.0507s/iter; left time: 166.1018s\n",
      "\titers: 400, epoch: 7 | loss: 0.0695636\n",
      "\tspeed: 0.0509s/iter; left time: 161.4036s\n",
      "\titers: 500, epoch: 7 | loss: 0.0808255\n",
      "\tspeed: 0.0514s/iter; left time: 157.8522s\n",
      "\titers: 600, epoch: 7 | loss: 0.0791186\n",
      "\tspeed: 0.0516s/iter; left time: 153.3046s\n",
      "\titers: 700, epoch: 7 | loss: 0.0720446\n",
      "\tspeed: 0.0511s/iter; left time: 146.7753s\n",
      "\titers: 800, epoch: 7 | loss: 0.0754880\n",
      "\tspeed: 0.0509s/iter; left time: 141.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 893 | Train Loss: 0.0769128 Vali Loss: 0.0904774 Test Loss: 0.0941006\n",
      "Validation loss decreased (0.091539 --> 0.090477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0674545\n",
      "\tspeed: 0.1851s/iter; left time: 477.5766s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833068\n",
      "\tspeed: 0.0510s/iter; left time: 126.4944s\n",
      "\titers: 300, epoch: 8 | loss: 0.0665762\n",
      "\tspeed: 0.0513s/iter; left time: 122.1486s\n",
      "\titers: 400, epoch: 8 | loss: 0.0724693\n",
      "\tspeed: 0.0515s/iter; left time: 117.4608s\n",
      "\titers: 500, epoch: 8 | loss: 0.0730056\n",
      "\tspeed: 0.0514s/iter; left time: 112.0850s\n",
      "\titers: 600, epoch: 8 | loss: 0.0686800\n",
      "\tspeed: 0.0507s/iter; left time: 105.5182s\n",
      "\titers: 700, epoch: 8 | loss: 0.0649278\n",
      "\tspeed: 0.0511s/iter; left time: 101.2660s\n",
      "\titers: 800, epoch: 8 | loss: 0.0850345\n",
      "\tspeed: 0.0509s/iter; left time: 95.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 893 | Train Loss: 0.0749879 Vali Loss: 0.0909365 Test Loss: 0.0953605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0625933\n",
      "\tspeed: 0.1835s/iter; left time: 309.5661s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698991\n",
      "\tspeed: 0.0512s/iter; left time: 81.2578s\n",
      "\titers: 300, epoch: 9 | loss: 0.0667722\n",
      "\tspeed: 0.0509s/iter; left time: 75.7332s\n",
      "\titers: 400, epoch: 9 | loss: 0.0757758\n",
      "\tspeed: 0.0511s/iter; left time: 70.8514s\n",
      "\titers: 500, epoch: 9 | loss: 0.0772626\n",
      "\tspeed: 0.0510s/iter; left time: 65.6148s\n",
      "\titers: 600, epoch: 9 | loss: 0.0653457\n",
      "\tspeed: 0.0512s/iter; left time: 60.7315s\n",
      "\titers: 700, epoch: 9 | loss: 0.0675535\n",
      "\tspeed: 0.0504s/iter; left time: 54.8038s\n",
      "\titers: 800, epoch: 9 | loss: 0.0745159\n",
      "\tspeed: 0.0499s/iter; left time: 49.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.59s\n",
      "Steps: 893 | Train Loss: 0.0732028 Vali Loss: 0.0908117 Test Loss: 0.0952647\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0662176\n",
      "\tspeed: 0.1814s/iter; left time: 144.0253s\n",
      "\titers: 200, epoch: 10 | loss: 0.0735994\n",
      "\tspeed: 0.0507s/iter; left time: 35.1721s\n",
      "\titers: 300, epoch: 10 | loss: 0.0742005\n",
      "\tspeed: 0.0507s/iter; left time: 30.1156s\n",
      "\titers: 400, epoch: 10 | loss: 0.0719053\n",
      "\tspeed: 0.0512s/iter; left time: 25.2685s\n",
      "\titers: 500, epoch: 10 | loss: 0.0750361\n",
      "\tspeed: 0.0511s/iter; left time: 20.1190s\n",
      "\titers: 600, epoch: 10 | loss: 0.0787530\n",
      "\tspeed: 0.0513s/iter; left time: 15.0883s\n",
      "\titers: 700, epoch: 10 | loss: 0.0630169\n",
      "\tspeed: 0.0510s/iter; left time: 9.8954s\n",
      "\titers: 800, epoch: 10 | loss: 0.0687266\n",
      "\tspeed: 0.0504s/iter; left time: 4.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 893 | Train Loss: 0.0714551 Vali Loss: 0.0901754 Test Loss: 0.0949099\n",
      "Validation loss decreased (0.090477 --> 0.090175).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02348499372601509, rmse:0.1532481461763382, mae:0.0949099212884903, rse:0.5411999821662903\n",
      "Original data scale mse:18100182.0, rmse:4254.4306640625, mae:2555.05517578125, rse:0.2115388810634613\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2232037\n",
      "\tspeed: 0.0758s/iter; left time: 667.5456s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966674\n",
      "\tspeed: 0.0518s/iter; left time: 451.4272s\n",
      "\titers: 300, epoch: 1 | loss: 0.1742013\n",
      "\tspeed: 0.0513s/iter; left time: 441.3148s\n",
      "\titers: 400, epoch: 1 | loss: 0.1564720\n",
      "\tspeed: 0.0518s/iter; left time: 440.8153s\n",
      "\titers: 500, epoch: 1 | loss: 0.1540881\n",
      "\tspeed: 0.0522s/iter; left time: 438.6978s\n",
      "\titers: 600, epoch: 1 | loss: 0.1432428\n",
      "\tspeed: 0.0519s/iter; left time: 431.4100s\n",
      "\titers: 700, epoch: 1 | loss: 0.1426363\n",
      "\tspeed: 0.0519s/iter; left time: 425.7691s\n",
      "\titers: 800, epoch: 1 | loss: 0.1474556\n",
      "\tspeed: 0.0513s/iter; left time: 416.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.59s\n",
      "Steps: 891 | Train Loss: 0.1705530 Vali Loss: 0.1345120 Test Loss: 0.1430094\n",
      "Validation loss decreased (inf --> 0.134512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471382\n",
      "\tspeed: 0.1852s/iter; left time: 1466.5815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1251901\n",
      "\tspeed: 0.0516s/iter; left time: 403.4385s\n",
      "\titers: 300, epoch: 2 | loss: 0.1217593\n",
      "\tspeed: 0.0518s/iter; left time: 399.6226s\n",
      "\titers: 400, epoch: 2 | loss: 0.1290254\n",
      "\tspeed: 0.0514s/iter; left time: 391.5931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037664\n",
      "\tspeed: 0.0526s/iter; left time: 395.3687s\n",
      "\titers: 600, epoch: 2 | loss: 0.0984934\n",
      "\tspeed: 0.0518s/iter; left time: 384.2070s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177443\n",
      "\tspeed: 0.0516s/iter; left time: 377.9106s\n",
      "\titers: 800, epoch: 2 | loss: 0.1195117\n",
      "\tspeed: 0.0517s/iter; left time: 373.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 891 | Train Loss: 0.1325551 Vali Loss: 0.1309508 Test Loss: 0.1432606\n",
      "Validation loss decreased (0.134512 --> 0.130951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161637\n",
      "\tspeed: 0.1887s/iter; left time: 1326.6517s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061514\n",
      "\tspeed: 0.0516s/iter; left time: 357.4565s\n",
      "\titers: 300, epoch: 3 | loss: 0.1083067\n",
      "\tspeed: 0.0509s/iter; left time: 347.6406s\n",
      "\titers: 400, epoch: 3 | loss: 0.1091669\n",
      "\tspeed: 0.0504s/iter; left time: 339.1564s\n",
      "\titers: 500, epoch: 3 | loss: 0.1130476\n",
      "\tspeed: 0.0509s/iter; left time: 337.7064s\n",
      "\titers: 600, epoch: 3 | loss: 0.1183236\n",
      "\tspeed: 0.0520s/iter; left time: 339.2946s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176359\n",
      "\tspeed: 0.0523s/iter; left time: 336.0965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1227058\n",
      "\tspeed: 0.0517s/iter; left time: 327.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 891 | Train Loss: 0.1114686 Vali Loss: 0.1283390 Test Loss: 0.1400744\n",
      "Validation loss decreased (0.130951 --> 0.128339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1108759\n",
      "\tspeed: 0.1860s/iter; left time: 1141.9659s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192250\n",
      "\tspeed: 0.0516s/iter; left time: 311.4837s\n",
      "\titers: 300, epoch: 4 | loss: 0.1148024\n",
      "\tspeed: 0.0516s/iter; left time: 306.4875s\n",
      "\titers: 400, epoch: 4 | loss: 0.1095063\n",
      "\tspeed: 0.0516s/iter; left time: 301.1138s\n",
      "\titers: 500, epoch: 4 | loss: 0.0985132\n",
      "\tspeed: 0.0518s/iter; left time: 297.0840s\n",
      "\titers: 600, epoch: 4 | loss: 0.1161646\n",
      "\tspeed: 0.0562s/iter; left time: 316.5857s\n",
      "\titers: 700, epoch: 4 | loss: 0.1203122\n",
      "\tspeed: 0.0584s/iter; left time: 323.2994s\n",
      "\titers: 800, epoch: 4 | loss: 0.0941837\n",
      "\tspeed: 0.0514s/iter; left time: 279.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 891 | Train Loss: 0.1087535 Vali Loss: 0.1241450 Test Loss: 0.1341353\n",
      "Validation loss decreased (0.128339 --> 0.124145).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1068043\n",
      "\tspeed: 0.1854s/iter; left time: 972.8108s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072559\n",
      "\tspeed: 0.0516s/iter; left time: 265.6594s\n",
      "\titers: 300, epoch: 5 | loss: 0.1111848\n",
      "\tspeed: 0.0520s/iter; left time: 262.2508s\n",
      "\titers: 400, epoch: 5 | loss: 0.0968150\n",
      "\tspeed: 0.0514s/iter; left time: 254.2593s\n",
      "\titers: 500, epoch: 5 | loss: 0.1114944\n",
      "\tspeed: 0.0516s/iter; left time: 250.1938s\n",
      "\titers: 600, epoch: 5 | loss: 0.1012555\n",
      "\tspeed: 0.0518s/iter; left time: 245.7725s\n",
      "\titers: 700, epoch: 5 | loss: 0.0870723\n",
      "\tspeed: 0.0516s/iter; left time: 239.9190s\n",
      "\titers: 800, epoch: 5 | loss: 0.0921054\n",
      "\tspeed: 0.0514s/iter; left time: 233.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 891 | Train Loss: 0.1034870 Vali Loss: 0.1260645 Test Loss: 0.1364085\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862945\n",
      "\tspeed: 0.1836s/iter; left time: 799.5851s\n",
      "\titers: 200, epoch: 6 | loss: 0.0951162\n",
      "\tspeed: 0.0515s/iter; left time: 219.3357s\n",
      "\titers: 300, epoch: 6 | loss: 0.1098691\n",
      "\tspeed: 0.0515s/iter; left time: 213.9820s\n",
      "\titers: 400, epoch: 6 | loss: 0.1062306\n",
      "\tspeed: 0.0518s/iter; left time: 210.2817s\n",
      "\titers: 500, epoch: 6 | loss: 0.0924442\n",
      "\tspeed: 0.0517s/iter; left time: 204.4544s\n",
      "\titers: 600, epoch: 6 | loss: 0.1007303\n",
      "\tspeed: 0.0513s/iter; left time: 197.7445s\n",
      "\titers: 700, epoch: 6 | loss: 0.1088045\n",
      "\tspeed: 0.0519s/iter; left time: 194.9009s\n",
      "\titers: 800, epoch: 6 | loss: 0.0973611\n",
      "\tspeed: 0.0526s/iter; left time: 192.3921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 891 | Train Loss: 0.0989994 Vali Loss: 0.1312096 Test Loss: 0.1416587\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0975444\n",
      "\tspeed: 0.1820s/iter; left time: 630.7088s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928570\n",
      "\tspeed: 0.0505s/iter; left time: 169.8512s\n",
      "\titers: 300, epoch: 7 | loss: 0.0948609\n",
      "\tspeed: 0.0505s/iter; left time: 164.7337s\n",
      "\titers: 400, epoch: 7 | loss: 0.0950938\n",
      "\tspeed: 0.0523s/iter; left time: 165.5171s\n",
      "\titers: 500, epoch: 7 | loss: 0.0930621\n",
      "\tspeed: 0.0518s/iter; left time: 158.8299s\n",
      "\titers: 600, epoch: 7 | loss: 0.0890538\n",
      "\tspeed: 0.0524s/iter; left time: 155.2283s\n",
      "\titers: 700, epoch: 7 | loss: 0.1064823\n",
      "\tspeed: 0.0518s/iter; left time: 148.4581s\n",
      "\titers: 800, epoch: 7 | loss: 0.0912062\n",
      "\tspeed: 0.0518s/iter; left time: 143.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.19s\n",
      "Steps: 891 | Train Loss: 0.0943194 Vali Loss: 0.1268835 Test Loss: 0.1368058\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03928346186876297, rmse:0.1982005536556244, mae:0.13413530588150024, rse:0.7018682956695557\n",
      "Original data scale mse:32837766.0, rmse:5730.4248046875, mae:3682.619140625, rse:0.28537717461586\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2265643\n",
      "\tspeed: 0.0552s/iter; left time: 486.5719s\n",
      "\titers: 200, epoch: 1 | loss: 0.1886556\n",
      "\tspeed: 0.0525s/iter; left time: 457.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.1644631\n",
      "\tspeed: 0.0524s/iter; left time: 451.1958s\n",
      "\titers: 400, epoch: 1 | loss: 0.1629343\n",
      "\tspeed: 0.0524s/iter; left time: 445.8804s\n",
      "\titers: 500, epoch: 1 | loss: 0.1452929\n",
      "\tspeed: 0.0525s/iter; left time: 441.2000s\n",
      "\titers: 600, epoch: 1 | loss: 0.1416558\n",
      "\tspeed: 0.0592s/iter; left time: 492.3007s\n",
      "\titers: 700, epoch: 1 | loss: 0.1496234\n",
      "\tspeed: 0.0601s/iter; left time: 493.8752s\n",
      "\titers: 800, epoch: 1 | loss: 0.1375968\n",
      "\tspeed: 0.0530s/iter; left time: 429.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 891 | Train Loss: 0.1697492 Vali Loss: 0.1331158 Test Loss: 0.1416903\n",
      "Validation loss decreased (inf --> 0.133116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1534266\n",
      "\tspeed: 0.1870s/iter; left time: 1481.4142s\n",
      "\titers: 200, epoch: 2 | loss: 0.1198043\n",
      "\tspeed: 0.0527s/iter; left time: 411.8037s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239595\n",
      "\tspeed: 0.0513s/iter; left time: 395.7049s\n",
      "\titers: 400, epoch: 2 | loss: 0.1364685\n",
      "\tspeed: 0.0520s/iter; left time: 396.0726s\n",
      "\titers: 500, epoch: 2 | loss: 0.1119902\n",
      "\tspeed: 0.0516s/iter; left time: 388.3199s\n",
      "\titers: 600, epoch: 2 | loss: 0.1173515\n",
      "\tspeed: 0.0530s/iter; left time: 393.2550s\n",
      "\titers: 700, epoch: 2 | loss: 0.1285220\n",
      "\tspeed: 0.0513s/iter; left time: 375.2750s\n",
      "\titers: 800, epoch: 2 | loss: 0.1078363\n",
      "\tspeed: 0.0517s/iter; left time: 373.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 891 | Train Loss: 0.1300853 Vali Loss: 0.1237499 Test Loss: 0.1356043\n",
      "Validation loss decreased (0.133116 --> 0.123750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023868\n",
      "\tspeed: 0.1861s/iter; left time: 1308.0944s\n",
      "\titers: 200, epoch: 3 | loss: 0.1103000\n",
      "\tspeed: 0.0520s/iter; left time: 360.5814s\n",
      "\titers: 300, epoch: 3 | loss: 0.1102674\n",
      "\tspeed: 0.0520s/iter; left time: 354.8473s\n",
      "\titers: 400, epoch: 3 | loss: 0.1194403\n",
      "\tspeed: 0.0519s/iter; left time: 349.0869s\n",
      "\titers: 500, epoch: 3 | loss: 0.1059762\n",
      "\tspeed: 0.0519s/iter; left time: 343.9031s\n",
      "\titers: 600, epoch: 3 | loss: 0.1115333\n",
      "\tspeed: 0.0523s/iter; left time: 341.5180s\n",
      "\titers: 700, epoch: 3 | loss: 0.1141522\n",
      "\tspeed: 0.0517s/iter; left time: 332.5856s\n",
      "\titers: 800, epoch: 3 | loss: 0.1146121\n",
      "\tspeed: 0.0516s/iter; left time: 326.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.40s\n",
      "Steps: 891 | Train Loss: 0.1119773 Vali Loss: 0.1340968 Test Loss: 0.1472080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0965063\n",
      "\tspeed: 0.1907s/iter; left time: 1170.4750s\n",
      "\titers: 200, epoch: 4 | loss: 0.1043790\n",
      "\tspeed: 0.0517s/iter; left time: 312.3123s\n",
      "\titers: 300, epoch: 4 | loss: 0.1071067\n",
      "\tspeed: 0.0526s/iter; left time: 312.4934s\n",
      "\titers: 400, epoch: 4 | loss: 0.1017503\n",
      "\tspeed: 0.0525s/iter; left time: 306.6844s\n",
      "\titers: 500, epoch: 4 | loss: 0.1170304\n",
      "\tspeed: 0.0515s/iter; left time: 295.6545s\n",
      "\titers: 600, epoch: 4 | loss: 0.1083326\n",
      "\tspeed: 0.0525s/iter; left time: 296.1853s\n",
      "\titers: 700, epoch: 4 | loss: 0.1062443\n",
      "\tspeed: 0.0515s/iter; left time: 285.2325s\n",
      "\titers: 800, epoch: 4 | loss: 0.1106692\n",
      "\tspeed: 0.0513s/iter; left time: 278.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.43s\n",
      "Steps: 891 | Train Loss: 0.1081631 Vali Loss: 0.1262663 Test Loss: 0.1396926\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1013816\n",
      "\tspeed: 0.1843s/iter; left time: 967.2579s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064511\n",
      "\tspeed: 0.0519s/iter; left time: 267.0437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0976876\n",
      "\tspeed: 0.0521s/iter; left time: 263.1868s\n",
      "\titers: 400, epoch: 5 | loss: 0.1135138\n",
      "\tspeed: 0.0515s/iter; left time: 254.9177s\n",
      "\titers: 500, epoch: 5 | loss: 0.1021511\n",
      "\tspeed: 0.0513s/iter; left time: 248.6113s\n",
      "\titers: 600, epoch: 5 | loss: 0.1141687\n",
      "\tspeed: 0.0513s/iter; left time: 243.5550s\n",
      "\titers: 700, epoch: 5 | loss: 0.0989732\n",
      "\tspeed: 0.0527s/iter; left time: 244.6953s\n",
      "\titers: 800, epoch: 5 | loss: 0.0909392\n",
      "\tspeed: 0.0524s/iter; left time: 238.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.53s\n",
      "Steps: 891 | Train Loss: 0.1049430 Vali Loss: 0.1277877 Test Loss: 0.1400883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04233036935329437, rmse:0.2057434618473053, mae:0.13560429215431213, rse:0.7285791635513306\n",
      "Original data scale mse:33165298.0, rmse:5758.93212890625, mae:3640.189208984375, rse:0.2867968678474426\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2229090\n",
      "\tspeed: 0.0745s/iter; left time: 654.8279s\n",
      "\titers: 200, epoch: 1 | loss: 0.1946270\n",
      "\tspeed: 0.0518s/iter; left time: 450.6136s\n",
      "\titers: 300, epoch: 1 | loss: 0.1828846\n",
      "\tspeed: 0.0529s/iter; left time: 454.4900s\n",
      "\titers: 400, epoch: 1 | loss: 0.1709642\n",
      "\tspeed: 0.0526s/iter; left time: 446.8180s\n",
      "\titers: 500, epoch: 1 | loss: 0.1666662\n",
      "\tspeed: 0.0526s/iter; left time: 441.3946s\n",
      "\titers: 600, epoch: 1 | loss: 0.1467172\n",
      "\tspeed: 0.0529s/iter; left time: 438.9510s\n",
      "\titers: 700, epoch: 1 | loss: 0.1457421\n",
      "\tspeed: 0.0526s/iter; left time: 431.0600s\n",
      "\titers: 800, epoch: 1 | loss: 0.1420146\n",
      "\tspeed: 0.0525s/iter; left time: 424.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 889 | Train Loss: 0.1722314 Vali Loss: 0.1382293 Test Loss: 0.1478910\n",
      "Validation loss decreased (inf --> 0.138229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497356\n",
      "\tspeed: 0.1843s/iter; left time: 1456.6008s\n",
      "\titers: 200, epoch: 2 | loss: 0.1173222\n",
      "\tspeed: 0.0519s/iter; left time: 405.0756s\n",
      "\titers: 300, epoch: 2 | loss: 0.1381475\n",
      "\tspeed: 0.0525s/iter; left time: 404.2796s\n",
      "\titers: 400, epoch: 2 | loss: 0.1262460\n",
      "\tspeed: 0.0521s/iter; left time: 395.7712s\n",
      "\titers: 500, epoch: 2 | loss: 0.1217887\n",
      "\tspeed: 0.0513s/iter; left time: 384.6152s\n",
      "\titers: 600, epoch: 2 | loss: 0.1152534\n",
      "\tspeed: 0.0516s/iter; left time: 382.2048s\n",
      "\titers: 700, epoch: 2 | loss: 0.1169293\n",
      "\tspeed: 0.0531s/iter; left time: 387.4973s\n",
      "\titers: 800, epoch: 2 | loss: 0.1216763\n",
      "\tspeed: 0.0537s/iter; left time: 387.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.85s\n",
      "Steps: 889 | Train Loss: 0.1309007 Vali Loss: 0.1385292 Test Loss: 0.1479903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1159356\n",
      "\tspeed: 0.1844s/iter; left time: 1293.2554s\n",
      "\titers: 200, epoch: 3 | loss: 0.1099259\n",
      "\tspeed: 0.0537s/iter; left time: 371.1857s\n",
      "\titers: 300, epoch: 3 | loss: 0.1227691\n",
      "\tspeed: 0.0528s/iter; left time: 359.9081s\n",
      "\titers: 400, epoch: 3 | loss: 0.1282663\n",
      "\tspeed: 0.0532s/iter; left time: 356.9682s\n",
      "\titers: 500, epoch: 3 | loss: 0.1190669\n",
      "\tspeed: 0.0524s/iter; left time: 346.4936s\n",
      "\titers: 600, epoch: 3 | loss: 0.1182712\n",
      "\tspeed: 0.0528s/iter; left time: 343.6932s\n",
      "\titers: 700, epoch: 3 | loss: 0.1082339\n",
      "\tspeed: 0.0539s/iter; left time: 345.6066s\n",
      "\titers: 800, epoch: 3 | loss: 0.1311277\n",
      "\tspeed: 0.0527s/iter; left time: 332.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 889 | Train Loss: 0.1150055 Vali Loss: 0.1366656 Test Loss: 0.1528236\n",
      "Validation loss decreased (0.138229 --> 0.136666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1121051\n",
      "\tspeed: 0.1877s/iter; left time: 1149.2680s\n",
      "\titers: 200, epoch: 4 | loss: 0.1090651\n",
      "\tspeed: 0.0526s/iter; left time: 317.0222s\n",
      "\titers: 300, epoch: 4 | loss: 0.1249205\n",
      "\tspeed: 0.0521s/iter; left time: 308.4433s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038693\n",
      "\tspeed: 0.0650s/iter; left time: 378.6445s\n",
      "\titers: 500, epoch: 4 | loss: 0.1172951\n",
      "\tspeed: 0.0536s/iter; left time: 306.9378s\n",
      "\titers: 600, epoch: 4 | loss: 0.1042813\n",
      "\tspeed: 0.0536s/iter; left time: 301.5907s\n",
      "\titers: 700, epoch: 4 | loss: 0.1192200\n",
      "\tspeed: 0.0536s/iter; left time: 296.2520s\n",
      "\titers: 800, epoch: 4 | loss: 0.1179966\n",
      "\tspeed: 0.0522s/iter; left time: 283.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 889 | Train Loss: 0.1105371 Vali Loss: 0.1403287 Test Loss: 0.1583499\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1017207\n",
      "\tspeed: 0.1830s/iter; left time: 957.9791s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020666\n",
      "\tspeed: 0.0525s/iter; left time: 269.4856s\n",
      "\titers: 300, epoch: 5 | loss: 0.1118475\n",
      "\tspeed: 0.0531s/iter; left time: 267.5355s\n",
      "\titers: 400, epoch: 5 | loss: 0.0997806\n",
      "\tspeed: 0.0525s/iter; left time: 259.1623s\n",
      "\titers: 500, epoch: 5 | loss: 0.1119611\n",
      "\tspeed: 0.0526s/iter; left time: 254.4907s\n",
      "\titers: 600, epoch: 5 | loss: 0.0957659\n",
      "\tspeed: 0.0523s/iter; left time: 247.8341s\n",
      "\titers: 700, epoch: 5 | loss: 0.1159966\n",
      "\tspeed: 0.0534s/iter; left time: 247.4836s\n",
      "\titers: 800, epoch: 5 | loss: 0.0946089\n",
      "\tspeed: 0.0532s/iter; left time: 241.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 889 | Train Loss: 0.1036050 Vali Loss: 0.1320792 Test Loss: 0.1500000\n",
      "Validation loss decreased (0.136666 --> 0.132079).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1039378\n",
      "\tspeed: 0.1898s/iter; left time: 824.8487s\n",
      "\titers: 200, epoch: 6 | loss: 0.1045938\n",
      "\tspeed: 0.0512s/iter; left time: 217.5832s\n",
      "\titers: 300, epoch: 6 | loss: 0.1015098\n",
      "\tspeed: 0.0513s/iter; left time: 212.5474s\n",
      "\titers: 400, epoch: 6 | loss: 0.0929108\n",
      "\tspeed: 0.0532s/iter; left time: 215.0662s\n",
      "\titers: 500, epoch: 6 | loss: 0.0981993\n",
      "\tspeed: 0.0528s/iter; left time: 208.3888s\n",
      "\titers: 600, epoch: 6 | loss: 0.0997548\n",
      "\tspeed: 0.0526s/iter; left time: 202.1950s\n",
      "\titers: 700, epoch: 6 | loss: 0.0923686\n",
      "\tspeed: 0.0532s/iter; left time: 199.4468s\n",
      "\titers: 800, epoch: 6 | loss: 0.0974962\n",
      "\tspeed: 0.0523s/iter; left time: 190.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.85s\n",
      "Steps: 889 | Train Loss: 0.0967752 Vali Loss: 0.1382042 Test Loss: 0.1573263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917292\n",
      "\tspeed: 0.1837s/iter; left time: 635.1573s\n",
      "\titers: 200, epoch: 7 | loss: 0.0955683\n",
      "\tspeed: 0.0526s/iter; left time: 176.4893s\n",
      "\titers: 300, epoch: 7 | loss: 0.0945315\n",
      "\tspeed: 0.0529s/iter; left time: 172.1459s\n",
      "\titers: 400, epoch: 7 | loss: 0.0817248\n",
      "\tspeed: 0.0524s/iter; left time: 165.4618s\n",
      "\titers: 500, epoch: 7 | loss: 0.0978655\n",
      "\tspeed: 0.0527s/iter; left time: 161.0320s\n",
      "\titers: 600, epoch: 7 | loss: 0.0863217\n",
      "\tspeed: 0.0536s/iter; left time: 158.4177s\n",
      "\titers: 700, epoch: 7 | loss: 0.1002630\n",
      "\tspeed: 0.0523s/iter; left time: 149.5144s\n",
      "\titers: 800, epoch: 7 | loss: 0.0905504\n",
      "\tspeed: 0.0531s/iter; left time: 146.4705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 889 | Train Loss: 0.0906701 Vali Loss: 0.1368014 Test Loss: 0.1557852\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839699\n",
      "\tspeed: 0.1839s/iter; left time: 472.2639s\n",
      "\titers: 200, epoch: 8 | loss: 0.0912413\n",
      "\tspeed: 0.0537s/iter; left time: 132.5558s\n",
      "\titers: 300, epoch: 8 | loss: 0.0776646\n",
      "\tspeed: 0.0519s/iter; left time: 123.0113s\n",
      "\titers: 400, epoch: 8 | loss: 0.0831299\n",
      "\tspeed: 0.0521s/iter; left time: 118.1250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0833446\n",
      "\tspeed: 0.0535s/iter; left time: 115.9907s\n",
      "\titers: 600, epoch: 8 | loss: 0.0817312\n",
      "\tspeed: 0.0515s/iter; left time: 106.5611s\n",
      "\titers: 700, epoch: 8 | loss: 0.0856518\n",
      "\tspeed: 0.0526s/iter; left time: 103.4944s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806153\n",
      "\tspeed: 0.0531s/iter; left time: 99.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 889 | Train Loss: 0.0829492 Vali Loss: 0.1373000 Test Loss: 0.1556918\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05118086189031601, rmse:0.2262318730354309, mae:0.15000008046627045, rse:0.8014714121818542\n",
      "Original data scale mse:41286724.0, rmse:6425.474609375, mae:4055.570556640625, rse:0.3201479911804199\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2245519\n",
      "\tspeed: 0.0544s/iter; left time: 478.2133s\n",
      "\titers: 200, epoch: 1 | loss: 0.1977614\n",
      "\tspeed: 0.0526s/iter; left time: 457.2859s\n",
      "\titers: 300, epoch: 1 | loss: 0.1724228\n",
      "\tspeed: 0.0521s/iter; left time: 447.6395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1547159\n",
      "\tspeed: 0.0523s/iter; left time: 444.2199s\n",
      "\titers: 500, epoch: 1 | loss: 0.1681565\n",
      "\tspeed: 0.0522s/iter; left time: 438.1442s\n",
      "\titers: 600, epoch: 1 | loss: 0.1430618\n",
      "\tspeed: 0.0524s/iter; left time: 434.6264s\n",
      "\titers: 700, epoch: 1 | loss: 0.1669483\n",
      "\tspeed: 0.0533s/iter; left time: 436.3090s\n",
      "\titers: 800, epoch: 1 | loss: 0.1547149\n",
      "\tspeed: 0.0527s/iter; left time: 426.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.82s\n",
      "Steps: 889 | Train Loss: 0.1728516 Vali Loss: 0.1376716 Test Loss: 0.1467767\n",
      "Validation loss decreased (inf --> 0.137672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1391693\n",
      "\tspeed: 0.1909s/iter; left time: 1508.6452s\n",
      "\titers: 200, epoch: 2 | loss: 0.1230830\n",
      "\tspeed: 0.0535s/iter; left time: 417.2418s\n",
      "\titers: 300, epoch: 2 | loss: 0.1179087\n",
      "\tspeed: 0.0531s/iter; left time: 408.7941s\n",
      "\titers: 400, epoch: 2 | loss: 0.1215570\n",
      "\tspeed: 0.0531s/iter; left time: 403.8397s\n",
      "\titers: 500, epoch: 2 | loss: 0.1157699\n",
      "\tspeed: 0.0532s/iter; left time: 398.7627s\n",
      "\titers: 600, epoch: 2 | loss: 0.1237864\n",
      "\tspeed: 0.0529s/iter; left time: 391.4616s\n",
      "\titers: 700, epoch: 2 | loss: 0.1067871\n",
      "\tspeed: 0.0525s/iter; left time: 383.4866s\n",
      "\titers: 800, epoch: 2 | loss: 0.1219706\n",
      "\tspeed: 0.0538s/iter; left time: 387.3703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 889 | Train Loss: 0.1314889 Vali Loss: 0.1318049 Test Loss: 0.1438061\n",
      "Validation loss decreased (0.137672 --> 0.131805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1279833\n",
      "\tspeed: 0.1866s/iter; left time: 1308.3495s\n",
      "\titers: 200, epoch: 3 | loss: 0.1165558\n",
      "\tspeed: 0.0526s/iter; left time: 363.9423s\n",
      "\titers: 300, epoch: 3 | loss: 0.1229332\n",
      "\tspeed: 0.0527s/iter; left time: 359.0429s\n",
      "\titers: 400, epoch: 3 | loss: 0.1180273\n",
      "\tspeed: 0.0530s/iter; left time: 355.9840s\n",
      "\titers: 500, epoch: 3 | loss: 0.1168011\n",
      "\tspeed: 0.0532s/iter; left time: 351.7963s\n",
      "\titers: 600, epoch: 3 | loss: 0.1151624\n",
      "\tspeed: 0.0530s/iter; left time: 345.3458s\n",
      "\titers: 700, epoch: 3 | loss: 0.1090609\n",
      "\tspeed: 0.0527s/iter; left time: 337.9455s\n",
      "\titers: 800, epoch: 3 | loss: 0.1037146\n",
      "\tspeed: 0.0532s/iter; left time: 336.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 889 | Train Loss: 0.1173820 Vali Loss: 0.1337178 Test Loss: 0.1478508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083791\n",
      "\tspeed: 0.1828s/iter; left time: 1119.2665s\n",
      "\titers: 200, epoch: 4 | loss: 0.1039568\n",
      "\tspeed: 0.0596s/iter; left time: 358.8981s\n",
      "\titers: 300, epoch: 4 | loss: 0.1089210\n",
      "\tspeed: 0.0567s/iter; left time: 336.0860s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045069\n",
      "\tspeed: 0.0527s/iter; left time: 306.9602s\n",
      "\titers: 500, epoch: 4 | loss: 0.1028276\n",
      "\tspeed: 0.0528s/iter; left time: 302.3259s\n",
      "\titers: 600, epoch: 4 | loss: 0.1068846\n",
      "\tspeed: 0.0535s/iter; left time: 301.1577s\n",
      "\titers: 700, epoch: 4 | loss: 0.1333390\n",
      "\tspeed: 0.0529s/iter; left time: 292.1512s\n",
      "\titers: 800, epoch: 4 | loss: 0.1104628\n",
      "\tspeed: 0.0525s/iter; left time: 284.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 889 | Train Loss: 0.1102818 Vali Loss: 0.1336649 Test Loss: 0.1505475\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0996400\n",
      "\tspeed: 0.1854s/iter; left time: 970.4906s\n",
      "\titers: 200, epoch: 5 | loss: 0.1084849\n",
      "\tspeed: 0.0525s/iter; left time: 269.5183s\n",
      "\titers: 300, epoch: 5 | loss: 0.1067280\n",
      "\tspeed: 0.0532s/iter; left time: 268.0623s\n",
      "\titers: 400, epoch: 5 | loss: 0.1079533\n",
      "\tspeed: 0.0538s/iter; left time: 265.4900s\n",
      "\titers: 500, epoch: 5 | loss: 0.1006398\n",
      "\tspeed: 0.0530s/iter; left time: 256.1937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1073959\n",
      "\tspeed: 0.0518s/iter; left time: 245.2186s\n",
      "\titers: 700, epoch: 5 | loss: 0.1026590\n",
      "\tspeed: 0.0514s/iter; left time: 238.0201s\n",
      "\titers: 800, epoch: 5 | loss: 0.1027110\n",
      "\tspeed: 0.0521s/iter; left time: 236.1855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 889 | Train Loss: 0.1043101 Vali Loss: 0.1280563 Test Loss: 0.1499850\n",
      "Validation loss decreased (0.131805 --> 0.128056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0869850\n",
      "\tspeed: 0.1878s/iter; left time: 816.3260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0934649\n",
      "\tspeed: 0.0527s/iter; left time: 223.6080s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898110\n",
      "\tspeed: 0.0522s/iter; left time: 216.4474s\n",
      "\titers: 400, epoch: 6 | loss: 0.0944954\n",
      "\tspeed: 0.0536s/iter; left time: 217.0590s\n",
      "\titers: 500, epoch: 6 | loss: 0.0984644\n",
      "\tspeed: 0.0538s/iter; left time: 212.2448s\n",
      "\titers: 600, epoch: 6 | loss: 0.0992838\n",
      "\tspeed: 0.0530s/iter; left time: 203.7306s\n",
      "\titers: 700, epoch: 6 | loss: 0.0999130\n",
      "\tspeed: 0.0529s/iter; left time: 198.0184s\n",
      "\titers: 800, epoch: 6 | loss: 0.0916463\n",
      "\tspeed: 0.0537s/iter; left time: 195.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.49s\n",
      "Steps: 889 | Train Loss: 0.0973510 Vali Loss: 0.1362427 Test Loss: 0.1581157\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0956656\n",
      "\tspeed: 0.1852s/iter; left time: 640.3442s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925599\n",
      "\tspeed: 0.0529s/iter; left time: 177.6409s\n",
      "\titers: 300, epoch: 7 | loss: 0.0882274\n",
      "\tspeed: 0.0527s/iter; left time: 171.6819s\n",
      "\titers: 400, epoch: 7 | loss: 0.0966856\n",
      "\tspeed: 0.0524s/iter; left time: 165.3662s\n",
      "\titers: 500, epoch: 7 | loss: 0.0997394\n",
      "\tspeed: 0.0531s/iter; left time: 162.2971s\n",
      "\titers: 600, epoch: 7 | loss: 0.0822036\n",
      "\tspeed: 0.0525s/iter; left time: 155.3887s\n",
      "\titers: 700, epoch: 7 | loss: 0.0924724\n",
      "\tspeed: 0.0529s/iter; left time: 151.1146s\n",
      "\titers: 800, epoch: 7 | loss: 0.0839960\n",
      "\tspeed: 0.0530s/iter; left time: 146.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 889 | Train Loss: 0.0900631 Vali Loss: 0.1363450 Test Loss: 0.1621987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0882982\n",
      "\tspeed: 0.1840s/iter; left time: 472.5315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0913990\n",
      "\tspeed: 0.0518s/iter; left time: 127.7934s\n",
      "\titers: 300, epoch: 8 | loss: 0.0786889\n",
      "\tspeed: 0.0528s/iter; left time: 125.1057s\n",
      "\titers: 400, epoch: 8 | loss: 0.0767405\n",
      "\tspeed: 0.0528s/iter; left time: 119.7012s\n",
      "\titers: 500, epoch: 8 | loss: 0.0899009\n",
      "\tspeed: 0.0525s/iter; left time: 113.7531s\n",
      "\titers: 600, epoch: 8 | loss: 0.0859587\n",
      "\tspeed: 0.0525s/iter; left time: 108.6387s\n",
      "\titers: 700, epoch: 8 | loss: 0.0790938\n",
      "\tspeed: 0.0527s/iter; left time: 103.6371s\n",
      "\titers: 800, epoch: 8 | loss: 0.0811212\n",
      "\tspeed: 0.0527s/iter; left time: 98.4679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 889 | Train Loss: 0.0835015 Vali Loss: 0.1360593 Test Loss: 0.1674986\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.050571780651807785, rmse:0.22488170862197876, mae:0.14998504519462585, rse:0.7966881990432739\n",
      "Original data scale mse:40031320.0, rmse:6327.03076171875, mae:4023.649658203125, rse:0.31524309515953064\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\" \\\n",
    "              --revin 0 \\\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.5871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.7019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.7286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.8015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0228  0.1509  0.0993  0.5327\n",
       "              2         24        0.0232  0.1522  0.0993  0.5374\n",
       "              1         96        0.0423  0.2058  0.1442  0.7287\n",
       "              2         96        0.0382  0.1954  0.1364  0.6921\n",
       "              1         168       0.0446  0.2112  0.1488  0.7481\n",
       "              2         168       0.0429  0.2072  0.1472  0.7342\n",
       "RMSE          1         24        0.0247  0.1573  0.1037  0.5555\n",
       "              2         24        0.0276  0.1662  0.1114  0.5871\n",
       "              1         96        0.0418  0.2044  0.1435  0.7237\n",
       "              2         96        0.0390  0.1976  0.1391  0.6997\n",
       "              1         168       0.0409  0.2023  0.1403  0.7166\n",
       "              2         168       0.0426  0.2065  0.1467  0.7316\n",
       "MAE           1         24        0.0228  0.1511  0.0952  0.5337\n",
       "              2         24        0.0235  0.1532  0.0949  0.5412\n",
       "              1         96        0.0393  0.1982  0.1341  0.7019\n",
       "              2         96        0.0423  0.2057  0.1356  0.7286\n",
       "              1         168       0.0512  0.2262  0.1500  0.8015\n",
       "              2         168       0.0506  0.2249  0.1500  0.7967"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_no_revin.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_no_revin.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17937842.0</td>\n",
       "      <td>4235.3091</td>\n",
       "      <td>2700.5715</td>\n",
       "      <td>0.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18291816.0</td>\n",
       "      <td>4276.8931</td>\n",
       "      <td>2723.5989</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37627388.0</td>\n",
       "      <td>6134.1167</td>\n",
       "      <td>4097.5498</td>\n",
       "      <td>0.3055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34112108.0</td>\n",
       "      <td>5840.5571</td>\n",
       "      <td>3830.1448</td>\n",
       "      <td>0.2909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>40797516.0</td>\n",
       "      <td>6387.2935</td>\n",
       "      <td>4201.8149</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40016304.0</td>\n",
       "      <td>6325.8442</td>\n",
       "      <td>4216.5996</td>\n",
       "      <td>0.3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20196358.0</td>\n",
       "      <td>4494.0356</td>\n",
       "      <td>2889.8323</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>23053352.0</td>\n",
       "      <td>4801.3906</td>\n",
       "      <td>3150.2073</td>\n",
       "      <td>0.2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37400496.0</td>\n",
       "      <td>6115.5947</td>\n",
       "      <td>4083.6396</td>\n",
       "      <td>0.3046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34960184.0</td>\n",
       "      <td>5912.7139</td>\n",
       "      <td>3935.2871</td>\n",
       "      <td>0.2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35232612.0</td>\n",
       "      <td>5935.7065</td>\n",
       "      <td>3864.7725</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39467032.0</td>\n",
       "      <td>6282.2793</td>\n",
       "      <td>4191.4492</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17627044.0</td>\n",
       "      <td>4198.4575</td>\n",
       "      <td>2560.0320</td>\n",
       "      <td>0.2088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18100182.0</td>\n",
       "      <td>4254.4307</td>\n",
       "      <td>2555.0552</td>\n",
       "      <td>0.2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32837766.0</td>\n",
       "      <td>5730.4248</td>\n",
       "      <td>3682.6191</td>\n",
       "      <td>0.2854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33165298.0</td>\n",
       "      <td>5758.9321</td>\n",
       "      <td>3640.1892</td>\n",
       "      <td>0.2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41286724.0</td>\n",
       "      <td>6425.4746</td>\n",
       "      <td>4055.5706</td>\n",
       "      <td>0.3201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40031320.0</td>\n",
       "      <td>6327.0308</td>\n",
       "      <td>4023.6497</td>\n",
       "      <td>0.3152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17937842.0  4235.3091  2700.5715  0.2106\n",
       "              2         24        18291816.0  4276.8931  2723.5989  0.2127\n",
       "              1         96        37627388.0  6134.1167  4097.5498  0.3055\n",
       "              2         96        34112108.0  5840.5571  3830.1448  0.2909\n",
       "              1         168       40797516.0  6387.2935  4201.8149  0.3182\n",
       "              2         168       40016304.0  6325.8442  4216.5996  0.3152\n",
       "RMSE          1         24        20196358.0  4494.0356  2889.8323  0.2235\n",
       "              2         24        23053352.0  4801.3906  3150.2073  0.2387\n",
       "              1         96        37400496.0  6115.5947  4083.6396  0.3046\n",
       "              2         96        34960184.0  5912.7139  3935.2871  0.2945\n",
       "              1         168       35232612.0  5935.7065  3864.7725  0.2957\n",
       "              2         168       39467032.0  6282.2793  4191.4492  0.3130\n",
       "MAE           1         24        17627044.0  4198.4575  2560.0320  0.2088\n",
       "              2         24        18100182.0  4254.4307  2555.0552  0.2115\n",
       "              1         96        32837766.0  5730.4248  3682.6191  0.2854\n",
       "              2         96        33165298.0  5758.9321  3640.1892  0.2868\n",
       "              1         168       41286724.0  6425.4746  4055.5706  0.3201\n",
       "              2         168       40031320.0  6327.0308  4023.6497  0.3152"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.7117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.7412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0232  0.1522  0.0951  0.5375\n",
       "         MSE            0.0230  0.1515  0.0993  0.5351\n",
       "         RMSE           0.0262  0.1618  0.1075  0.5713\n",
       "96       MAE            0.0408  0.2020  0.1349  0.7152\n",
       "         MSE            0.0403  0.2006  0.1403  0.7104\n",
       "         RMSE           0.0404  0.2010  0.1413  0.7117\n",
       "168      MAE            0.0509  0.2256  0.1500  0.7991\n",
       "         MSE            0.0438  0.2092  0.1480  0.7412\n",
       "         RMSE           0.0418  0.2044  0.1435  0.7241"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17863613.0</td>\n",
       "      <td>4226.4441</td>\n",
       "      <td>2557.5436</td>\n",
       "      <td>0.2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18114829.0</td>\n",
       "      <td>4256.1011</td>\n",
       "      <td>2712.0852</td>\n",
       "      <td>0.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>21624855.0</td>\n",
       "      <td>4647.7131</td>\n",
       "      <td>3020.0198</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33001532.0</td>\n",
       "      <td>5744.6785</td>\n",
       "      <td>3661.4042</td>\n",
       "      <td>0.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>35869748.0</td>\n",
       "      <td>5987.3369</td>\n",
       "      <td>3963.8473</td>\n",
       "      <td>0.2982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>36180340.0</td>\n",
       "      <td>6014.1543</td>\n",
       "      <td>4009.4634</td>\n",
       "      <td>0.2995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40659022.0</td>\n",
       "      <td>6376.2527</td>\n",
       "      <td>4039.6101</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>40406910.0</td>\n",
       "      <td>6356.5688</td>\n",
       "      <td>4209.2073</td>\n",
       "      <td>0.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37349822.0</td>\n",
       "      <td>6108.9929</td>\n",
       "      <td>4028.1108</td>\n",
       "      <td>0.3044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17863613.0  4226.4441  2557.5436  0.2101\n",
       "         MSE            18114829.0  4256.1011  2712.0852  0.2116\n",
       "         RMSE           21624855.0  4647.7131  3020.0198  0.2311\n",
       "96       MAE            33001532.0  5744.6785  3661.4042  0.2861\n",
       "         MSE            35869748.0  5987.3369  3963.8473  0.2982\n",
       "         RMSE           36180340.0  6014.1543  4009.4634  0.2995\n",
       "168      MAE            40659022.0  6376.2527  4039.6101  0.3177\n",
       "         MSE            40406910.0  6356.5688  4209.2073  0.3167\n",
       "         RMSE           37349822.0  6108.9929  4028.1108  0.3044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled_no_revin'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS decomposition + ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0250204\n",
      "\tspeed: 0.1222s/iter; left time: 1078.7689s\n",
      "\titers: 200, epoch: 1 | loss: 0.0161410\n",
      "\tspeed: 0.0984s/iter; left time: 859.3937s\n",
      "\titers: 300, epoch: 1 | loss: 0.0180938\n",
      "\tspeed: 0.0995s/iter; left time: 859.0633s\n",
      "\titers: 400, epoch: 1 | loss: 0.0191886\n",
      "\tspeed: 0.0994s/iter; left time: 848.1152s\n",
      "\titers: 500, epoch: 1 | loss: 0.0194585\n",
      "\tspeed: 0.0993s/iter; left time: 837.3737s\n",
      "\titers: 600, epoch: 1 | loss: 0.0162254\n",
      "\tspeed: 0.0995s/iter; left time: 828.8440s\n",
      "\titers: 700, epoch: 1 | loss: 0.0150733\n",
      "\tspeed: 0.0990s/iter; left time: 814.8926s\n",
      "\titers: 800, epoch: 1 | loss: 0.0154237\n",
      "\tspeed: 0.0992s/iter; left time: 806.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 893 | Train Loss: 0.0189747 Vali Loss: 0.0218837 Test Loss: 0.0237212\n",
      "Validation loss decreased (inf --> 0.021884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0159415\n",
      "\tspeed: 0.3435s/iter; left time: 2726.3221s\n",
      "\titers: 200, epoch: 2 | loss: 0.0152666\n",
      "\tspeed: 0.1000s/iter; left time: 783.4140s\n",
      "\titers: 300, epoch: 2 | loss: 0.0136102\n",
      "\tspeed: 0.0994s/iter; left time: 769.2195s\n",
      "\titers: 400, epoch: 2 | loss: 0.0130686\n",
      "\tspeed: 0.0994s/iter; left time: 759.5956s\n",
      "\titers: 500, epoch: 2 | loss: 0.0143287\n",
      "\tspeed: 0.1001s/iter; left time: 754.1799s\n",
      "\titers: 600, epoch: 2 | loss: 0.0134632\n",
      "\tspeed: 0.1002s/iter; left time: 745.4738s\n",
      "\titers: 700, epoch: 2 | loss: 0.0199528\n",
      "\tspeed: 0.1001s/iter; left time: 734.8883s\n",
      "\titers: 800, epoch: 2 | loss: 0.0150846\n",
      "\tspeed: 0.1000s/iter; left time: 724.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.45s\n",
      "Steps: 893 | Train Loss: 0.0143353 Vali Loss: 0.0213097 Test Loss: 0.0236056\n",
      "Validation loss decreased (0.021884 --> 0.021310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0114070\n",
      "\tspeed: 0.3466s/iter; left time: 2441.9971s\n",
      "\titers: 200, epoch: 3 | loss: 0.0148940\n",
      "\tspeed: 0.0997s/iter; left time: 692.4434s\n",
      "\titers: 300, epoch: 3 | loss: 0.0104133\n",
      "\tspeed: 0.1002s/iter; left time: 685.9234s\n",
      "\titers: 400, epoch: 3 | loss: 0.0123678\n",
      "\tspeed: 0.1002s/iter; left time: 676.1278s\n",
      "\titers: 500, epoch: 3 | loss: 0.0122751\n",
      "\tspeed: 0.1001s/iter; left time: 664.9684s\n",
      "\titers: 600, epoch: 3 | loss: 0.0120990\n",
      "\tspeed: 0.1001s/iter; left time: 655.2921s\n",
      "\titers: 700, epoch: 3 | loss: 0.0099288\n",
      "\tspeed: 0.1000s/iter; left time: 644.6901s\n",
      "\titers: 800, epoch: 3 | loss: 0.0109738\n",
      "\tspeed: 0.1003s/iter; left time: 636.3825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.73s\n",
      "Steps: 893 | Train Loss: 0.0125311 Vali Loss: 0.0213073 Test Loss: 0.0237687\n",
      "Validation loss decreased (0.021310 --> 0.021307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0116703\n",
      "\tspeed: 0.3460s/iter; left time: 2128.3162s\n",
      "\titers: 200, epoch: 4 | loss: 0.0106035\n",
      "\tspeed: 0.1000s/iter; left time: 604.9358s\n",
      "\titers: 300, epoch: 4 | loss: 0.0109973\n",
      "\tspeed: 0.0994s/iter; left time: 591.6932s\n",
      "\titers: 400, epoch: 4 | loss: 0.0110361\n",
      "\tspeed: 0.1002s/iter; left time: 586.4418s\n",
      "\titers: 500, epoch: 4 | loss: 0.0121710\n",
      "\tspeed: 0.1003s/iter; left time: 576.9195s\n",
      "\titers: 600, epoch: 4 | loss: 0.0132155\n",
      "\tspeed: 0.1002s/iter; left time: 566.5938s\n",
      "\titers: 700, epoch: 4 | loss: 0.0116915\n",
      "\tspeed: 0.0998s/iter; left time: 553.9770s\n",
      "\titers: 800, epoch: 4 | loss: 0.0137536\n",
      "\tspeed: 0.1001s/iter; left time: 545.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.59s\n",
      "Steps: 893 | Train Loss: 0.0114015 Vali Loss: 0.0226249 Test Loss: 0.0249652\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0134808\n",
      "\tspeed: 0.3415s/iter; left time: 1796.0441s\n",
      "\titers: 200, epoch: 5 | loss: 0.0085449\n",
      "\tspeed: 0.1001s/iter; left time: 516.3552s\n",
      "\titers: 300, epoch: 5 | loss: 0.0076896\n",
      "\tspeed: 0.1000s/iter; left time: 506.0816s\n",
      "\titers: 400, epoch: 5 | loss: 0.0091464\n",
      "\tspeed: 0.1070s/iter; left time: 530.6899s\n",
      "\titers: 500, epoch: 5 | loss: 0.0081384\n",
      "\tspeed: 0.1003s/iter; left time: 487.5269s\n",
      "\titers: 600, epoch: 5 | loss: 0.0103404\n",
      "\tspeed: 0.1004s/iter; left time: 477.7191s\n",
      "\titers: 700, epoch: 5 | loss: 0.0090021\n",
      "\tspeed: 0.1005s/iter; left time: 468.1255s\n",
      "\titers: 800, epoch: 5 | loss: 0.0117690\n",
      "\tspeed: 0.1002s/iter; left time: 456.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.46s\n",
      "Steps: 893 | Train Loss: 0.0100589 Vali Loss: 0.0251963 Test Loss: 0.0269997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0084843\n",
      "\tspeed: 0.3418s/iter; left time: 1492.1052s\n",
      "\titers: 200, epoch: 6 | loss: 0.0114648\n",
      "\tspeed: 0.1001s/iter; left time: 426.9235s\n",
      "\titers: 300, epoch: 6 | loss: 0.0091330\n",
      "\tspeed: 0.0996s/iter; left time: 414.8944s\n",
      "\titers: 400, epoch: 6 | loss: 0.0072352\n",
      "\tspeed: 0.1001s/iter; left time: 407.1754s\n",
      "\titers: 500, epoch: 6 | loss: 0.0114895\n",
      "\tspeed: 0.1000s/iter; left time: 396.6055s\n",
      "\titers: 600, epoch: 6 | loss: 0.0092098\n",
      "\tspeed: 0.1004s/iter; left time: 388.2879s\n",
      "\titers: 700, epoch: 6 | loss: 0.0107946\n",
      "\tspeed: 0.1002s/iter; left time: 377.3403s\n",
      "\titers: 800, epoch: 6 | loss: 0.0085713\n",
      "\tspeed: 0.1001s/iter; left time: 367.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.57s\n",
      "Steps: 893 | Train Loss: 0.0083201 Vali Loss: 0.0258428 Test Loss: 0.0284938\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023768704384565353, rmse:0.15417101979255676, mae:0.0996347963809967, rse:0.5444591641426086\n",
      "Original data scale mse:18796964.0, rmse:4335.54638671875, mae:2721.77587890625, rse:0.21557210385799408\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0263207\n",
      "\tspeed: 0.1024s/iter; left time: 904.5590s\n",
      "\titers: 200, epoch: 1 | loss: 0.0221171\n",
      "\tspeed: 0.1000s/iter; left time: 873.4623s\n",
      "\titers: 300, epoch: 1 | loss: 0.0170024\n",
      "\tspeed: 0.1001s/iter; left time: 864.1611s\n",
      "\titers: 400, epoch: 1 | loss: 0.0156061\n",
      "\tspeed: 0.0999s/iter; left time: 852.6519s\n",
      "\titers: 500, epoch: 1 | loss: 0.0162821\n",
      "\tspeed: 0.1001s/iter; left time: 843.5284s\n",
      "\titers: 600, epoch: 1 | loss: 0.0118867\n",
      "\tspeed: 0.1002s/iter; left time: 834.4582s\n",
      "\titers: 700, epoch: 1 | loss: 0.0155099\n",
      "\tspeed: 0.1002s/iter; left time: 824.7586s\n",
      "\titers: 800, epoch: 1 | loss: 0.0217869\n",
      "\tspeed: 0.1002s/iter; left time: 815.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.71s\n",
      "Steps: 893 | Train Loss: 0.0189622 Vali Loss: 0.0218688 Test Loss: 0.0238022\n",
      "Validation loss decreased (inf --> 0.021869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0164408\n",
      "\tspeed: 0.3668s/iter; left time: 2911.7025s\n",
      "\titers: 200, epoch: 2 | loss: 0.0149818\n",
      "\tspeed: 0.0993s/iter; left time: 778.1236s\n",
      "\titers: 300, epoch: 2 | loss: 0.0184301\n",
      "\tspeed: 0.1001s/iter; left time: 774.5374s\n",
      "\titers: 400, epoch: 2 | loss: 0.0116514\n",
      "\tspeed: 0.1006s/iter; left time: 768.5595s\n",
      "\titers: 500, epoch: 2 | loss: 0.0158564\n",
      "\tspeed: 0.1003s/iter; left time: 756.1827s\n",
      "\titers: 600, epoch: 2 | loss: 0.0163931\n",
      "\tspeed: 0.0998s/iter; left time: 742.3954s\n",
      "\titers: 700, epoch: 2 | loss: 0.0174571\n",
      "\tspeed: 0.1001s/iter; left time: 734.5196s\n",
      "\titers: 800, epoch: 2 | loss: 0.0143050\n",
      "\tspeed: 0.1005s/iter; left time: 727.4270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.68s\n",
      "Steps: 893 | Train Loss: 0.0142561 Vali Loss: 0.0212641 Test Loss: 0.0227214\n",
      "Validation loss decreased (0.021869 --> 0.021264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0098570\n",
      "\tspeed: 0.3505s/iter; left time: 2469.0937s\n",
      "\titers: 200, epoch: 3 | loss: 0.0131653\n",
      "\tspeed: 0.1002s/iter; left time: 695.9118s\n",
      "\titers: 300, epoch: 3 | loss: 0.0127829\n",
      "\tspeed: 0.1001s/iter; left time: 685.2637s\n",
      "\titers: 400, epoch: 3 | loss: 0.0191016\n",
      "\tspeed: 0.1004s/iter; left time: 677.2125s\n",
      "\titers: 500, epoch: 3 | loss: 0.0107752\n",
      "\tspeed: 0.1000s/iter; left time: 664.7277s\n",
      "\titers: 600, epoch: 3 | loss: 0.0116865\n",
      "\tspeed: 0.1002s/iter; left time: 655.5349s\n",
      "\titers: 700, epoch: 3 | loss: 0.0152703\n",
      "\tspeed: 0.1001s/iter; left time: 644.8450s\n",
      "\titers: 800, epoch: 3 | loss: 0.0098216\n",
      "\tspeed: 0.1005s/iter; left time: 637.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.80s\n",
      "Steps: 893 | Train Loss: 0.0124601 Vali Loss: 0.0212953 Test Loss: 0.0236000\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0144396\n",
      "\tspeed: 0.3429s/iter; left time: 2109.7693s\n",
      "\titers: 200, epoch: 4 | loss: 0.0109294\n",
      "\tspeed: 0.0996s/iter; left time: 602.5193s\n",
      "\titers: 300, epoch: 4 | loss: 0.0094097\n",
      "\tspeed: 0.1001s/iter; left time: 595.7936s\n",
      "\titers: 400, epoch: 4 | loss: 0.0115612\n",
      "\tspeed: 0.0999s/iter; left time: 584.7088s\n",
      "\titers: 500, epoch: 4 | loss: 0.0097925\n",
      "\tspeed: 0.1003s/iter; left time: 577.0731s\n",
      "\titers: 600, epoch: 4 | loss: 0.0099123\n",
      "\tspeed: 0.1002s/iter; left time: 566.3202s\n",
      "\titers: 700, epoch: 4 | loss: 0.0127190\n",
      "\tspeed: 0.1003s/iter; left time: 557.1236s\n",
      "\titers: 800, epoch: 4 | loss: 0.0117602\n",
      "\tspeed: 0.1003s/iter; left time: 546.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.65s\n",
      "Steps: 893 | Train Loss: 0.0112267 Vali Loss: 0.0224512 Test Loss: 0.0243126\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0107177\n",
      "\tspeed: 0.3429s/iter; left time: 1803.0759s\n",
      "\titers: 200, epoch: 5 | loss: 0.0102347\n",
      "\tspeed: 0.1000s/iter; left time: 516.0412s\n",
      "\titers: 300, epoch: 5 | loss: 0.0098997\n",
      "\tspeed: 0.1001s/iter; left time: 506.2520s\n",
      "\titers: 400, epoch: 5 | loss: 0.0109414\n",
      "\tspeed: 0.0999s/iter; left time: 495.4881s\n",
      "\titers: 500, epoch: 5 | loss: 0.0100466\n",
      "\tspeed: 0.1000s/iter; left time: 485.6654s\n",
      "\titers: 600, epoch: 5 | loss: 0.0093074\n",
      "\tspeed: 0.1063s/iter; left time: 505.6982s\n",
      "\titers: 700, epoch: 5 | loss: 0.0072933\n",
      "\tspeed: 0.0997s/iter; left time: 464.2817s\n",
      "\titers: 800, epoch: 5 | loss: 0.0083183\n",
      "\tspeed: 0.1004s/iter; left time: 457.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.20s\n",
      "Steps: 893 | Train Loss: 0.0097154 Vali Loss: 0.0233928 Test Loss: 0.0263324\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02272137999534607, rmse:0.15073612332344055, mae:0.0970846563577652, rse:0.532328724861145\n",
      "Original data scale mse:18245456.0, rmse:4271.47021484375, mae:2664.433349609375, rse:0.2123861014842987\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0327503\n",
      "\tspeed: 0.1237s/iter; left time: 1090.2462s\n",
      "\titers: 200, epoch: 1 | loss: 0.0262829\n",
      "\tspeed: 0.1011s/iter; left time: 880.3998s\n",
      "\titers: 300, epoch: 1 | loss: 0.0293562\n",
      "\tspeed: 0.1010s/iter; left time: 869.3768s\n",
      "\titers: 400, epoch: 1 | loss: 0.0256942\n",
      "\tspeed: 0.1013s/iter; left time: 861.7972s\n",
      "\titers: 500, epoch: 1 | loss: 0.0267532\n",
      "\tspeed: 0.1013s/iter; left time: 852.4311s\n",
      "\titers: 600, epoch: 1 | loss: 0.0237004\n",
      "\tspeed: 0.1012s/iter; left time: 841.3348s\n",
      "\titers: 700, epoch: 1 | loss: 0.0268090\n",
      "\tspeed: 0.1013s/iter; left time: 831.8671s\n",
      "\titers: 800, epoch: 1 | loss: 0.0239700\n",
      "\tspeed: 0.1015s/iter; left time: 823.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.70s\n",
      "Steps: 891 | Train Loss: 0.0274781 Vali Loss: 0.0321247 Test Loss: 0.0367571\n",
      "Validation loss decreased (inf --> 0.032125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0211876\n",
      "\tspeed: 0.3607s/iter; left time: 2856.9480s\n",
      "\titers: 200, epoch: 2 | loss: 0.0253655\n",
      "\tspeed: 0.1010s/iter; left time: 789.7856s\n",
      "\titers: 300, epoch: 2 | loss: 0.0251610\n",
      "\tspeed: 0.1011s/iter; left time: 780.6685s\n",
      "\titers: 400, epoch: 2 | loss: 0.0216260\n",
      "\tspeed: 0.1010s/iter; left time: 769.6009s\n",
      "\titers: 500, epoch: 2 | loss: 0.0194951\n",
      "\tspeed: 0.1010s/iter; left time: 759.5395s\n",
      "\titers: 600, epoch: 2 | loss: 0.0246698\n",
      "\tspeed: 0.1072s/iter; left time: 795.2446s\n",
      "\titers: 700, epoch: 2 | loss: 0.0184642\n",
      "\tspeed: 0.1013s/iter; left time: 741.4953s\n",
      "\titers: 800, epoch: 2 | loss: 0.0177508\n",
      "\tspeed: 0.1016s/iter; left time: 733.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.98s\n",
      "Steps: 891 | Train Loss: 0.0219764 Vali Loss: 0.0327437 Test Loss: 0.0384048\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0183868\n",
      "\tspeed: 0.3501s/iter; left time: 2460.7440s\n",
      "\titers: 200, epoch: 3 | loss: 0.0192546\n",
      "\tspeed: 0.1015s/iter; left time: 703.1209s\n",
      "\titers: 300, epoch: 3 | loss: 0.0177915\n",
      "\tspeed: 0.1016s/iter; left time: 693.7091s\n",
      "\titers: 400, epoch: 3 | loss: 0.0146075\n",
      "\tspeed: 0.1008s/iter; left time: 678.6054s\n",
      "\titers: 500, epoch: 3 | loss: 0.0131921\n",
      "\tspeed: 0.1011s/iter; left time: 670.3573s\n",
      "\titers: 600, epoch: 3 | loss: 0.0145929\n",
      "\tspeed: 0.1014s/iter; left time: 661.9234s\n",
      "\titers: 700, epoch: 3 | loss: 0.0150446\n",
      "\tspeed: 0.1015s/iter; left time: 652.7752s\n",
      "\titers: 800, epoch: 3 | loss: 0.0134283\n",
      "\tspeed: 0.1014s/iter; left time: 642.0133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.52s\n",
      "Steps: 891 | Train Loss: 0.0165288 Vali Loss: 0.0377990 Test Loss: 0.0434666\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0140053\n",
      "\tspeed: 0.3456s/iter; left time: 2121.3805s\n",
      "\titers: 200, epoch: 4 | loss: 0.0134569\n",
      "\tspeed: 0.1010s/iter; left time: 609.9749s\n",
      "\titers: 300, epoch: 4 | loss: 0.0122084\n",
      "\tspeed: 0.1016s/iter; left time: 603.3730s\n",
      "\titers: 400, epoch: 4 | loss: 0.0111954\n",
      "\tspeed: 0.1015s/iter; left time: 592.4220s\n",
      "\titers: 500, epoch: 4 | loss: 0.0114070\n",
      "\tspeed: 0.1015s/iter; left time: 582.2551s\n",
      "\titers: 600, epoch: 4 | loss: 0.0128317\n",
      "\tspeed: 0.1014s/iter; left time: 571.4391s\n",
      "\titers: 700, epoch: 4 | loss: 0.0092958\n",
      "\tspeed: 0.1016s/iter; left time: 562.4941s\n",
      "\titers: 800, epoch: 4 | loss: 0.0100666\n",
      "\tspeed: 0.1013s/iter; left time: 550.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.58s\n",
      "Steps: 891 | Train Loss: 0.0114905 Vali Loss: 0.0422338 Test Loss: 0.0465786\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03675707057118416, rmse:0.1917213350534439, mae:0.13927190005779266, rse:0.678924024105072\n",
      "Original data scale mse:32576136.0, rmse:5707.55078125, mae:3937.265380859375, rse:0.2842380702495575\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0382264\n",
      "\tspeed: 0.1025s/iter; left time: 903.2447s\n",
      "\titers: 200, epoch: 1 | loss: 0.0264393\n",
      "\tspeed: 0.1014s/iter; left time: 883.0579s\n",
      "\titers: 300, epoch: 1 | loss: 0.0288211\n",
      "\tspeed: 0.1014s/iter; left time: 873.3937s\n",
      "\titers: 400, epoch: 1 | loss: 0.0260314\n",
      "\tspeed: 0.1015s/iter; left time: 863.6064s\n",
      "\titers: 500, epoch: 1 | loss: 0.0234698\n",
      "\tspeed: 0.1012s/iter; left time: 851.3933s\n",
      "\titers: 600, epoch: 1 | loss: 0.0260674\n",
      "\tspeed: 0.1015s/iter; left time: 843.2000s\n",
      "\titers: 700, epoch: 1 | loss: 0.0286936\n",
      "\tspeed: 0.1014s/iter; left time: 832.8374s\n",
      "\titers: 800, epoch: 1 | loss: 0.0253467\n",
      "\tspeed: 0.1013s/iter; left time: 821.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.49s\n",
      "Steps: 891 | Train Loss: 0.0273990 Vali Loss: 0.0319471 Test Loss: 0.0366235\n",
      "Validation loss decreased (inf --> 0.031947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0264486\n",
      "\tspeed: 0.3561s/iter; left time: 2820.1774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0244496\n",
      "\tspeed: 0.1013s/iter; left time: 791.8717s\n",
      "\titers: 300, epoch: 2 | loss: 0.0199609\n",
      "\tspeed: 0.1013s/iter; left time: 782.3928s\n",
      "\titers: 400, epoch: 2 | loss: 0.0198013\n",
      "\tspeed: 0.1014s/iter; left time: 772.8283s\n",
      "\titers: 500, epoch: 2 | loss: 0.0202789\n",
      "\tspeed: 0.1012s/iter; left time: 760.8625s\n",
      "\titers: 600, epoch: 2 | loss: 0.0181506\n",
      "\tspeed: 0.1012s/iter; left time: 751.0044s\n",
      "\titers: 700, epoch: 2 | loss: 0.0206327\n",
      "\tspeed: 0.1015s/iter; left time: 742.7680s\n",
      "\titers: 800, epoch: 2 | loss: 0.0202239\n",
      "\tspeed: 0.1015s/iter; left time: 733.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.52s\n",
      "Steps: 891 | Train Loss: 0.0219797 Vali Loss: 0.0330328 Test Loss: 0.0397619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0160927\n",
      "\tspeed: 0.3475s/iter; left time: 2442.6549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0158412\n",
      "\tspeed: 0.1013s/iter; left time: 702.1134s\n",
      "\titers: 300, epoch: 3 | loss: 0.0174945\n",
      "\tspeed: 0.1016s/iter; left time: 693.7913s\n",
      "\titers: 400, epoch: 3 | loss: 0.0198519\n",
      "\tspeed: 0.1015s/iter; left time: 682.9803s\n",
      "\titers: 500, epoch: 3 | loss: 0.0136133\n",
      "\tspeed: 0.1014s/iter; left time: 672.4195s\n",
      "\titers: 600, epoch: 3 | loss: 0.0163058\n",
      "\tspeed: 0.1013s/iter; left time: 661.4103s\n",
      "\titers: 700, epoch: 3 | loss: 0.0157446\n",
      "\tspeed: 0.1014s/iter; left time: 651.7602s\n",
      "\titers: 800, epoch: 3 | loss: 0.0155512\n",
      "\tspeed: 0.1013s/iter; left time: 641.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.64s\n",
      "Steps: 891 | Train Loss: 0.0166423 Vali Loss: 0.0375858 Test Loss: 0.0464106\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0130548\n",
      "\tspeed: 0.3468s/iter; left time: 2128.5453s\n",
      "\titers: 200, epoch: 4 | loss: 0.0129319\n",
      "\tspeed: 0.1012s/iter; left time: 611.3327s\n",
      "\titers: 300, epoch: 4 | loss: 0.0125000\n",
      "\tspeed: 0.1012s/iter; left time: 601.1274s\n",
      "\titers: 400, epoch: 4 | loss: 0.0115957\n",
      "\tspeed: 0.1013s/iter; left time: 591.4601s\n",
      "\titers: 500, epoch: 4 | loss: 0.0113158\n",
      "\tspeed: 0.1015s/iter; left time: 582.5091s\n",
      "\titers: 600, epoch: 4 | loss: 0.0106036\n",
      "\tspeed: 0.1010s/iter; left time: 569.6195s\n",
      "\titers: 700, epoch: 4 | loss: 0.0108752\n",
      "\tspeed: 0.1013s/iter; left time: 560.7431s\n",
      "\titers: 800, epoch: 4 | loss: 0.0090805\n",
      "\tspeed: 0.1013s/iter; left time: 550.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.51s\n",
      "Steps: 891 | Train Loss: 0.0114968 Vali Loss: 0.0405091 Test Loss: 0.0499736\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036623552441596985, rmse:0.191372811794281, mae:0.1387537121772766, rse:0.677689790725708\n",
      "Original data scale mse:32513784.0, rmse:5702.0859375, mae:3915.39990234375, rse:0.28396591544151306\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0329751\n",
      "\tspeed: 0.1275s/iter; left time: 1120.4442s\n",
      "\titers: 200, epoch: 1 | loss: 0.0302103\n",
      "\tspeed: 0.1022s/iter; left time: 888.1497s\n",
      "\titers: 300, epoch: 1 | loss: 0.0210769\n",
      "\tspeed: 0.1025s/iter; left time: 880.3150s\n",
      "\titers: 400, epoch: 1 | loss: 0.0292853\n",
      "\tspeed: 0.1028s/iter; left time: 872.4910s\n",
      "\titers: 500, epoch: 1 | loss: 0.0312676\n",
      "\tspeed: 0.1026s/iter; left time: 861.1138s\n",
      "\titers: 600, epoch: 1 | loss: 0.0261065\n",
      "\tspeed: 0.1028s/iter; left time: 852.3453s\n",
      "\titers: 700, epoch: 1 | loss: 0.0269883\n",
      "\tspeed: 0.1029s/iter; left time: 843.0378s\n",
      "\titers: 800, epoch: 1 | loss: 0.0249038\n",
      "\tspeed: 0.1029s/iter; left time: 832.4214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.76s\n",
      "Steps: 889 | Train Loss: 0.0293717 Vali Loss: 0.0335006 Test Loss: 0.0389744\n",
      "Validation loss decreased (inf --> 0.033501).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0232621\n",
      "\tspeed: 0.3538s/iter; left time: 2795.3788s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277241\n",
      "\tspeed: 0.1027s/iter; left time: 801.1901s\n",
      "\titers: 300, epoch: 2 | loss: 0.0202454\n",
      "\tspeed: 0.1027s/iter; left time: 790.8849s\n",
      "\titers: 400, epoch: 2 | loss: 0.0243682\n",
      "\tspeed: 0.1026s/iter; left time: 780.1019s\n",
      "\titers: 500, epoch: 2 | loss: 0.0224484\n",
      "\tspeed: 0.1024s/iter; left time: 768.0869s\n",
      "\titers: 600, epoch: 2 | loss: 0.0209818\n",
      "\tspeed: 0.1026s/iter; left time: 759.7700s\n",
      "\titers: 700, epoch: 2 | loss: 0.0239148\n",
      "\tspeed: 0.1027s/iter; left time: 750.1300s\n",
      "\titers: 800, epoch: 2 | loss: 0.0214718\n",
      "\tspeed: 0.1025s/iter; left time: 738.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.42s\n",
      "Steps: 889 | Train Loss: 0.0233015 Vali Loss: 0.0363447 Test Loss: 0.0428185\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0193062\n",
      "\tspeed: 0.3505s/iter; left time: 2458.1214s\n",
      "\titers: 200, epoch: 3 | loss: 0.0193152\n",
      "\tspeed: 0.1021s/iter; left time: 705.5885s\n",
      "\titers: 300, epoch: 3 | loss: 0.0158285\n",
      "\tspeed: 0.1026s/iter; left time: 698.9946s\n",
      "\titers: 400, epoch: 3 | loss: 0.0184073\n",
      "\tspeed: 0.1021s/iter; left time: 685.6948s\n",
      "\titers: 500, epoch: 3 | loss: 0.0172221\n",
      "\tspeed: 0.1027s/iter; left time: 679.1720s\n",
      "\titers: 600, epoch: 3 | loss: 0.0159562\n",
      "\tspeed: 0.1025s/iter; left time: 667.8806s\n",
      "\titers: 700, epoch: 3 | loss: 0.0129145\n",
      "\tspeed: 0.1024s/iter; left time: 656.9615s\n",
      "\titers: 800, epoch: 3 | loss: 0.0114991\n",
      "\tspeed: 0.1023s/iter; left time: 646.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.32s\n",
      "Steps: 889 | Train Loss: 0.0157740 Vali Loss: 0.0418079 Test Loss: 0.0474243\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0133276\n",
      "\tspeed: 0.3501s/iter; left time: 2144.1952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0116193\n",
      "\tspeed: 0.1023s/iter; left time: 616.2045s\n",
      "\titers: 300, epoch: 4 | loss: 0.0108973\n",
      "\tspeed: 0.1023s/iter; left time: 605.8381s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101240\n",
      "\tspeed: 0.1022s/iter; left time: 595.0809s\n",
      "\titers: 500, epoch: 4 | loss: 0.0093291\n",
      "\tspeed: 0.1021s/iter; left time: 584.3069s\n",
      "\titers: 600, epoch: 4 | loss: 0.0100550\n",
      "\tspeed: 0.1025s/iter; left time: 576.3586s\n",
      "\titers: 700, epoch: 4 | loss: 0.0099626\n",
      "\tspeed: 0.1027s/iter; left time: 567.5882s\n",
      "\titers: 800, epoch: 4 | loss: 0.0079959\n",
      "\tspeed: 0.1022s/iter; left time: 554.1911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:31.23s\n",
      "Steps: 889 | Train Loss: 0.0102438 Vali Loss: 0.0412948 Test Loss: 0.0510369\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03897438570857048, rmse:0.19741931557655334, mae:0.1455087959766388, rse:0.6993971467018127\n",
      "Original data scale mse:35581968.0, rmse:5965.0625, mae:4137.59130859375, rse:0.2972080409526825\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0301745\n",
      "\tspeed: 0.1049s/iter; left time: 922.0199s\n",
      "\titers: 200, epoch: 1 | loss: 0.0369365\n",
      "\tspeed: 0.1022s/iter; left time: 888.3606s\n",
      "\titers: 300, epoch: 1 | loss: 0.0304137\n",
      "\tspeed: 0.1026s/iter; left time: 881.7459s\n",
      "\titers: 400, epoch: 1 | loss: 0.0315972\n",
      "\tspeed: 0.1019s/iter; left time: 865.2065s\n",
      "\titers: 500, epoch: 1 | loss: 0.0243908\n",
      "\tspeed: 0.1025s/iter; left time: 860.3018s\n",
      "\titers: 600, epoch: 1 | loss: 0.0255326\n",
      "\tspeed: 0.1022s/iter; left time: 847.6179s\n",
      "\titers: 700, epoch: 1 | loss: 0.0284485\n",
      "\tspeed: 0.1022s/iter; left time: 836.8070s\n",
      "\titers: 800, epoch: 1 | loss: 0.0249516\n",
      "\tspeed: 0.1025s/iter; left time: 829.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.31s\n",
      "Steps: 889 | Train Loss: 0.0295046 Vali Loss: 0.0333166 Test Loss: 0.0391259\n",
      "Validation loss decreased (inf --> 0.033317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0288603\n",
      "\tspeed: 0.3566s/iter; left time: 2817.8363s\n",
      "\titers: 200, epoch: 2 | loss: 0.0228738\n",
      "\tspeed: 0.1023s/iter; left time: 797.9090s\n",
      "\titers: 300, epoch: 2 | loss: 0.0267623\n",
      "\tspeed: 0.1023s/iter; left time: 788.1871s\n",
      "\titers: 400, epoch: 2 | loss: 0.0224815\n",
      "\tspeed: 0.1026s/iter; left time: 780.1437s\n",
      "\titers: 500, epoch: 2 | loss: 0.0238039\n",
      "\tspeed: 0.1023s/iter; left time: 767.6862s\n",
      "\titers: 600, epoch: 2 | loss: 0.0209078\n",
      "\tspeed: 0.1022s/iter; left time: 756.7733s\n",
      "\titers: 700, epoch: 2 | loss: 0.0232442\n",
      "\tspeed: 0.1030s/iter; left time: 751.9972s\n",
      "\titers: 800, epoch: 2 | loss: 0.0219636\n",
      "\tspeed: 0.1025s/iter; left time: 738.0004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.44s\n",
      "Steps: 889 | Train Loss: 0.0233668 Vali Loss: 0.0360251 Test Loss: 0.0447615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0207481\n",
      "\tspeed: 0.3506s/iter; left time: 2458.6508s\n",
      "\titers: 200, epoch: 3 | loss: 0.0189345\n",
      "\tspeed: 0.1022s/iter; left time: 706.5958s\n",
      "\titers: 300, epoch: 3 | loss: 0.0168745\n",
      "\tspeed: 0.1028s/iter; left time: 700.4210s\n",
      "\titers: 400, epoch: 3 | loss: 0.0182991\n",
      "\tspeed: 0.1026s/iter; left time: 688.4556s\n",
      "\titers: 500, epoch: 3 | loss: 0.0136624\n",
      "\tspeed: 0.1022s/iter; left time: 675.8339s\n",
      "\titers: 600, epoch: 3 | loss: 0.0156653\n",
      "\tspeed: 0.1022s/iter; left time: 665.7353s\n",
      "\titers: 700, epoch: 3 | loss: 0.0137504\n",
      "\tspeed: 0.1022s/iter; left time: 655.1350s\n",
      "\titers: 800, epoch: 3 | loss: 0.0123701\n",
      "\tspeed: 0.1025s/iter; left time: 647.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.31s\n",
      "Steps: 889 | Train Loss: 0.0158702 Vali Loss: 0.0429540 Test Loss: 0.0515168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120087\n",
      "\tspeed: 0.3500s/iter; left time: 2143.2615s\n",
      "\titers: 200, epoch: 4 | loss: 0.0110773\n",
      "\tspeed: 0.1025s/iter; left time: 617.7165s\n",
      "\titers: 300, epoch: 4 | loss: 0.0112820\n",
      "\tspeed: 0.1024s/iter; left time: 606.5034s\n",
      "\titers: 400, epoch: 4 | loss: 0.0110209\n",
      "\tspeed: 0.1024s/iter; left time: 596.1571s\n",
      "\titers: 500, epoch: 4 | loss: 0.0103259\n",
      "\tspeed: 0.1026s/iter; left time: 587.4641s\n",
      "\titers: 600, epoch: 4 | loss: 0.0106260\n",
      "\tspeed: 0.1021s/iter; left time: 574.2784s\n",
      "\titers: 700, epoch: 4 | loss: 0.0086661\n",
      "\tspeed: 0.1084s/iter; left time: 598.8706s\n",
      "\titers: 800, epoch: 4 | loss: 0.0096271\n",
      "\tspeed: 0.1027s/iter; left time: 557.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:32.02s\n",
      "Steps: 889 | Train Loss: 0.0105550 Vali Loss: 0.0425693 Test Loss: 0.0485613\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039125923067331314, rmse:0.19780273735523224, mae:0.14511321485042572, rse:0.7007555365562439\n",
      "Original data scale mse:35745328.0, rmse:5978.73974609375, mae:4123.7763671875, rse:0.2978895306587219\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1573519\n",
      "\tspeed: 0.1228s/iter; left time: 1084.7493s\n",
      "\titers: 200, epoch: 1 | loss: 0.1259782\n",
      "\tspeed: 0.0996s/iter; left time: 870.0162s\n",
      "\titers: 300, epoch: 1 | loss: 0.1331639\n",
      "\tspeed: 0.1000s/iter; left time: 862.9307s\n",
      "\titers: 400, epoch: 1 | loss: 0.1367401\n",
      "\tspeed: 0.1000s/iter; left time: 853.1637s\n",
      "\titers: 500, epoch: 1 | loss: 0.1383681\n",
      "\tspeed: 0.1000s/iter; left time: 843.4668s\n",
      "\titers: 600, epoch: 1 | loss: 0.1260612\n",
      "\tspeed: 0.1005s/iter; left time: 837.1494s\n",
      "\titers: 700, epoch: 1 | loss: 0.1217330\n",
      "\tspeed: 0.1001s/iter; left time: 823.7155s\n",
      "\titers: 800, epoch: 1 | loss: 0.1231874\n",
      "\tspeed: 0.1000s/iter; left time: 813.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.72s\n",
      "Steps: 893 | Train Loss: 0.1355000 Vali Loss: 0.0216965 Test Loss: 0.0234739\n",
      "Validation loss decreased (inf --> 0.021697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1244515\n",
      "\tspeed: 0.3426s/iter; left time: 2719.9340s\n",
      "\titers: 200, epoch: 2 | loss: 0.1263057\n",
      "\tspeed: 0.1001s/iter; left time: 784.7525s\n",
      "\titers: 300, epoch: 2 | loss: 0.1147372\n",
      "\tspeed: 0.1001s/iter; left time: 774.8662s\n",
      "\titers: 400, epoch: 2 | loss: 0.1141386\n",
      "\tspeed: 0.1000s/iter; left time: 763.5739s\n",
      "\titers: 500, epoch: 2 | loss: 0.1186799\n",
      "\tspeed: 0.1003s/iter; left time: 756.0970s\n",
      "\titers: 600, epoch: 2 | loss: 0.1163394\n",
      "\tspeed: 0.1003s/iter; left time: 745.7673s\n",
      "\titers: 700, epoch: 2 | loss: 0.1430827\n",
      "\tspeed: 0.1046s/iter; left time: 767.4204s\n",
      "\titers: 800, epoch: 2 | loss: 0.1235607\n",
      "\tspeed: 0.1000s/iter; left time: 723.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.08s\n",
      "Steps: 893 | Train Loss: 0.1195583 Vali Loss: 0.0213497 Test Loss: 0.0235815\n",
      "Validation loss decreased (0.021697 --> 0.021350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058956\n",
      "\tspeed: 0.3461s/iter; left time: 2438.4974s\n",
      "\titers: 200, epoch: 3 | loss: 0.1184494\n",
      "\tspeed: 0.1002s/iter; left time: 695.7767s\n",
      "\titers: 300, epoch: 3 | loss: 0.1030438\n",
      "\tspeed: 0.1003s/iter; left time: 686.4650s\n",
      "\titers: 400, epoch: 3 | loss: 0.1124754\n",
      "\tspeed: 0.1002s/iter; left time: 676.1785s\n",
      "\titers: 500, epoch: 3 | loss: 0.1130432\n",
      "\tspeed: 0.1000s/iter; left time: 664.6171s\n",
      "\titers: 600, epoch: 3 | loss: 0.1122882\n",
      "\tspeed: 0.1003s/iter; left time: 656.2091s\n",
      "\titers: 700, epoch: 3 | loss: 0.1045999\n",
      "\tspeed: 0.1006s/iter; left time: 648.2018s\n",
      "\titers: 800, epoch: 3 | loss: 0.1017052\n",
      "\tspeed: 0.1002s/iter; left time: 635.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.77s\n",
      "Steps: 893 | Train Loss: 0.1118374 Vali Loss: 0.0212329 Test Loss: 0.0237287\n",
      "Validation loss decreased (0.021350 --> 0.021233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083505\n",
      "\tspeed: 0.3454s/iter; left time: 2124.9147s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011756\n",
      "\tspeed: 0.1000s/iter; left time: 605.3150s\n",
      "\titers: 300, epoch: 4 | loss: 0.1070213\n",
      "\tspeed: 0.1002s/iter; left time: 596.5703s\n",
      "\titers: 400, epoch: 4 | loss: 0.1029233\n",
      "\tspeed: 0.1003s/iter; left time: 586.7585s\n",
      "\titers: 500, epoch: 4 | loss: 0.1113488\n",
      "\tspeed: 0.1004s/iter; left time: 577.7005s\n",
      "\titers: 600, epoch: 4 | loss: 0.1116291\n",
      "\tspeed: 0.1000s/iter; left time: 565.3304s\n",
      "\titers: 700, epoch: 4 | loss: 0.1079608\n",
      "\tspeed: 0.1000s/iter; left time: 554.9440s\n",
      "\titers: 800, epoch: 4 | loss: 0.1111363\n",
      "\tspeed: 0.1004s/iter; left time: 547.2268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.68s\n",
      "Steps: 893 | Train Loss: 0.1068656 Vali Loss: 0.0225129 Test Loss: 0.0247555\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1174607\n",
      "\tspeed: 0.3398s/iter; left time: 1787.1798s\n",
      "\titers: 200, epoch: 5 | loss: 0.0940258\n",
      "\tspeed: 0.1005s/iter; left time: 518.2506s\n",
      "\titers: 300, epoch: 5 | loss: 0.0812438\n",
      "\tspeed: 0.1004s/iter; left time: 508.1072s\n",
      "\titers: 400, epoch: 5 | loss: 0.0987705\n",
      "\tspeed: 0.1006s/iter; left time: 498.6830s\n",
      "\titers: 500, epoch: 5 | loss: 0.0929177\n",
      "\tspeed: 0.1000s/iter; left time: 486.0747s\n",
      "\titers: 600, epoch: 5 | loss: 0.1030069\n",
      "\tspeed: 0.1004s/iter; left time: 477.8585s\n",
      "\titers: 700, epoch: 5 | loss: 0.0917541\n",
      "\tspeed: 0.1004s/iter; left time: 467.5947s\n",
      "\titers: 800, epoch: 5 | loss: 0.1119580\n",
      "\tspeed: 0.1003s/iter; left time: 457.3426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.77s\n",
      "Steps: 893 | Train Loss: 0.1003476 Vali Loss: 0.0238972 Test Loss: 0.0255243\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913099\n",
      "\tspeed: 0.3400s/iter; left time: 1484.6304s\n",
      "\titers: 200, epoch: 6 | loss: 0.1039536\n",
      "\tspeed: 0.1003s/iter; left time: 427.8203s\n",
      "\titers: 300, epoch: 6 | loss: 0.0872551\n",
      "\tspeed: 0.1004s/iter; left time: 418.1983s\n",
      "\titers: 400, epoch: 6 | loss: 0.0862279\n",
      "\tspeed: 0.1002s/iter; left time: 407.2593s\n",
      "\titers: 500, epoch: 6 | loss: 0.1017545\n",
      "\tspeed: 0.1004s/iter; left time: 398.2936s\n",
      "\titers: 600, epoch: 6 | loss: 0.0908461\n",
      "\tspeed: 0.1004s/iter; left time: 388.2950s\n",
      "\titers: 700, epoch: 6 | loss: 0.0998904\n",
      "\tspeed: 0.1004s/iter; left time: 378.0421s\n",
      "\titers: 800, epoch: 6 | loss: 0.0870332\n",
      "\tspeed: 0.1005s/iter; left time: 368.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.89s\n",
      "Steps: 893 | Train Loss: 0.0912288 Vali Loss: 0.0259186 Test Loss: 0.0288958\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023728730157017708, rmse:0.1540413200855255, mae:0.09950573742389679, rse:0.5440011620521545\n",
      "Original data scale mse:19014310.0, rmse:4360.5400390625, mae:2722.31640625, rse:0.2168148308992386\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1611899\n",
      "\tspeed: 0.1019s/iter; left time: 899.8426s\n",
      "\titers: 200, epoch: 1 | loss: 0.1475048\n",
      "\tspeed: 0.1001s/iter; left time: 873.8574s\n",
      "\titers: 300, epoch: 1 | loss: 0.1290432\n",
      "\tspeed: 0.1003s/iter; left time: 865.4253s\n",
      "\titers: 400, epoch: 1 | loss: 0.1234133\n",
      "\tspeed: 0.1004s/iter; left time: 856.5036s\n",
      "\titers: 500, epoch: 1 | loss: 0.1259775\n",
      "\tspeed: 0.1002s/iter; left time: 844.4563s\n",
      "\titers: 600, epoch: 1 | loss: 0.1074422\n",
      "\tspeed: 0.1005s/iter; left time: 837.2786s\n",
      "\titers: 700, epoch: 1 | loss: 0.1239220\n",
      "\tspeed: 0.1001s/iter; left time: 824.1239s\n",
      "\titers: 800, epoch: 1 | loss: 0.1472817\n",
      "\tspeed: 0.1002s/iter; left time: 814.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.74s\n",
      "Steps: 893 | Train Loss: 0.1354189 Vali Loss: 0.0216321 Test Loss: 0.0235290\n",
      "Validation loss decreased (inf --> 0.021632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1273680\n",
      "\tspeed: 0.3519s/iter; left time: 2793.5373s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224252\n",
      "\tspeed: 0.1002s/iter; left time: 785.0062s\n",
      "\titers: 300, epoch: 2 | loss: 0.1338779\n",
      "\tspeed: 0.1004s/iter; left time: 776.6306s\n",
      "\titers: 400, epoch: 2 | loss: 0.1081931\n",
      "\tspeed: 0.1003s/iter; left time: 766.2987s\n",
      "\titers: 500, epoch: 2 | loss: 0.1294309\n",
      "\tspeed: 0.1005s/iter; left time: 757.6378s\n",
      "\titers: 600, epoch: 2 | loss: 0.1269091\n",
      "\tspeed: 0.1003s/iter; left time: 745.6711s\n",
      "\titers: 700, epoch: 2 | loss: 0.1301175\n",
      "\tspeed: 0.1001s/iter; left time: 734.5489s\n",
      "\titers: 800, epoch: 2 | loss: 0.1241563\n",
      "\tspeed: 0.1006s/iter; left time: 728.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.83s\n",
      "Steps: 893 | Train Loss: 0.1190053 Vali Loss: 0.0211034 Test Loss: 0.0227366\n",
      "Validation loss decreased (0.021632 --> 0.021103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0974308\n",
      "\tspeed: 0.3647s/iter; left time: 2569.5161s\n",
      "\titers: 200, epoch: 3 | loss: 0.1156164\n",
      "\tspeed: 0.1004s/iter; left time: 696.9488s\n",
      "\titers: 300, epoch: 3 | loss: 0.1127484\n",
      "\tspeed: 0.1007s/iter; left time: 689.1665s\n",
      "\titers: 400, epoch: 3 | loss: 0.1423346\n",
      "\tspeed: 0.1000s/iter; left time: 674.8044s\n",
      "\titers: 500, epoch: 3 | loss: 0.1012676\n",
      "\tspeed: 0.0999s/iter; left time: 663.8556s\n",
      "\titers: 600, epoch: 3 | loss: 0.1097981\n",
      "\tspeed: 0.1002s/iter; left time: 655.7899s\n",
      "\titers: 700, epoch: 3 | loss: 0.1254074\n",
      "\tspeed: 0.1004s/iter; left time: 647.0553s\n",
      "\titers: 800, epoch: 3 | loss: 0.0991895\n",
      "\tspeed: 0.1000s/iter; left time: 634.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.73s\n",
      "Steps: 893 | Train Loss: 0.1108082 Vali Loss: 0.0209596 Test Loss: 0.0233248\n",
      "Validation loss decreased (0.021103 --> 0.020960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1197609\n",
      "\tspeed: 0.3492s/iter; left time: 2147.9992s\n",
      "\titers: 200, epoch: 4 | loss: 0.1084272\n",
      "\tspeed: 0.1001s/iter; left time: 605.8411s\n",
      "\titers: 300, epoch: 4 | loss: 0.0970571\n",
      "\tspeed: 0.1003s/iter; left time: 597.1463s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045604\n",
      "\tspeed: 0.1001s/iter; left time: 585.8961s\n",
      "\titers: 500, epoch: 4 | loss: 0.0981709\n",
      "\tspeed: 0.1004s/iter; left time: 577.5036s\n",
      "\titers: 600, epoch: 4 | loss: 0.1017167\n",
      "\tspeed: 0.1005s/iter; left time: 568.2873s\n",
      "\titers: 700, epoch: 4 | loss: 0.1148854\n",
      "\tspeed: 0.1004s/iter; left time: 557.3164s\n",
      "\titers: 800, epoch: 4 | loss: 0.1100623\n",
      "\tspeed: 0.1004s/iter; left time: 547.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.80s\n",
      "Steps: 893 | Train Loss: 0.1055940 Vali Loss: 0.0223435 Test Loss: 0.0243504\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1049735\n",
      "\tspeed: 0.3473s/iter; left time: 1826.2051s\n",
      "\titers: 200, epoch: 5 | loss: 0.1016913\n",
      "\tspeed: 0.1004s/iter; left time: 517.7345s\n",
      "\titers: 300, epoch: 5 | loss: 0.0959913\n",
      "\tspeed: 0.1003s/iter; left time: 507.3544s\n",
      "\titers: 400, epoch: 5 | loss: 0.1048184\n",
      "\tspeed: 0.1001s/iter; left time: 496.5547s\n",
      "\titers: 500, epoch: 5 | loss: 0.0991100\n",
      "\tspeed: 0.1003s/iter; left time: 487.4962s\n",
      "\titers: 600, epoch: 5 | loss: 0.0963814\n",
      "\tspeed: 0.1003s/iter; left time: 477.2595s\n",
      "\titers: 700, epoch: 5 | loss: 0.0836786\n",
      "\tspeed: 0.1005s/iter; left time: 468.0003s\n",
      "\titers: 800, epoch: 5 | loss: 0.0887809\n",
      "\tspeed: 0.1001s/iter; left time: 456.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.29s\n",
      "Steps: 893 | Train Loss: 0.0984701 Vali Loss: 0.0238658 Test Loss: 0.0258268\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0905790\n",
      "\tspeed: 0.3476s/iter; left time: 1517.7981s\n",
      "\titers: 200, epoch: 6 | loss: 0.0955320\n",
      "\tspeed: 0.1001s/iter; left time: 427.1428s\n",
      "\titers: 300, epoch: 6 | loss: 0.0847089\n",
      "\tspeed: 0.1002s/iter; left time: 417.5899s\n",
      "\titers: 400, epoch: 6 | loss: 0.0861121\n",
      "\tspeed: 0.1003s/iter; left time: 407.9613s\n",
      "\titers: 500, epoch: 6 | loss: 0.1039285\n",
      "\tspeed: 0.1006s/iter; left time: 399.1655s\n",
      "\titers: 600, epoch: 6 | loss: 0.0776776\n",
      "\tspeed: 0.1001s/iter; left time: 387.1629s\n",
      "\titers: 700, epoch: 6 | loss: 0.0784389\n",
      "\tspeed: 0.1005s/iter; left time: 378.4197s\n",
      "\titers: 800, epoch: 6 | loss: 0.0883446\n",
      "\tspeed: 0.1004s/iter; left time: 368.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.82s\n",
      "Steps: 893 | Train Loss: 0.0894217 Vali Loss: 0.0254184 Test Loss: 0.0278818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023324845358729362, rmse:0.1527247428894043, mae:0.09801636636257172, rse:0.5393515229225159\n",
      "Original data scale mse:18353394.0, rmse:4284.0859375, mae:2661.82763671875, rse:0.2130134105682373\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1805840\n",
      "\tspeed: 0.1302s/iter; left time: 1146.7567s\n",
      "\titers: 200, epoch: 1 | loss: 0.1617109\n",
      "\tspeed: 0.1010s/iter; left time: 879.8489s\n",
      "\titers: 300, epoch: 1 | loss: 0.1709142\n",
      "\tspeed: 0.1016s/iter; left time: 874.5797s\n",
      "\titers: 400, epoch: 1 | loss: 0.1598741\n",
      "\tspeed: 0.1012s/iter; left time: 861.3344s\n",
      "\titers: 500, epoch: 1 | loss: 0.1630758\n",
      "\tspeed: 0.1011s/iter; left time: 850.4651s\n",
      "\titers: 600, epoch: 1 | loss: 0.1535434\n",
      "\tspeed: 0.1014s/iter; left time: 842.6667s\n",
      "\titers: 700, epoch: 1 | loss: 0.1631742\n",
      "\tspeed: 0.1014s/iter; left time: 832.6687s\n",
      "\titers: 800, epoch: 1 | loss: 0.1543314\n",
      "\tspeed: 0.1014s/iter; left time: 822.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.24s\n",
      "Steps: 891 | Train Loss: 0.1648356 Vali Loss: 0.0320007 Test Loss: 0.0366033\n",
      "Validation loss decreased (inf --> 0.032001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1463625\n",
      "\tspeed: 0.3521s/iter; left time: 2789.0079s\n",
      "\titers: 200, epoch: 2 | loss: 0.1608256\n",
      "\tspeed: 0.1014s/iter; left time: 792.9744s\n",
      "\titers: 300, epoch: 2 | loss: 0.1603539\n",
      "\tspeed: 0.1017s/iter; left time: 785.1825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1497591\n",
      "\tspeed: 0.1013s/iter; left time: 772.0188s\n",
      "\titers: 500, epoch: 2 | loss: 0.1405143\n",
      "\tspeed: 0.1011s/iter; left time: 760.2090s\n",
      "\titers: 600, epoch: 2 | loss: 0.1585390\n",
      "\tspeed: 0.1013s/iter; left time: 751.6266s\n",
      "\titers: 700, epoch: 2 | loss: 0.1330275\n",
      "\tspeed: 0.1015s/iter; left time: 743.3220s\n",
      "\titers: 800, epoch: 2 | loss: 0.1326836\n",
      "\tspeed: 0.1015s/iter; left time: 733.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.59s\n",
      "Steps: 891 | Train Loss: 0.1480168 Vali Loss: 0.0329370 Test Loss: 0.0380207\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1357170\n",
      "\tspeed: 0.3463s/iter; left time: 2434.1138s\n",
      "\titers: 200, epoch: 3 | loss: 0.1400878\n",
      "\tspeed: 0.1066s/iter; left time: 738.4194s\n",
      "\titers: 300, epoch: 3 | loss: 0.1347101\n",
      "\tspeed: 0.1015s/iter; left time: 693.0788s\n",
      "\titers: 400, epoch: 3 | loss: 0.1242025\n",
      "\tspeed: 0.1014s/iter; left time: 682.4897s\n",
      "\titers: 500, epoch: 3 | loss: 0.1183062\n",
      "\tspeed: 0.1013s/iter; left time: 671.7550s\n",
      "\titers: 600, epoch: 3 | loss: 0.1209134\n",
      "\tspeed: 0.1013s/iter; left time: 661.2770s\n",
      "\titers: 700, epoch: 3 | loss: 0.1229451\n",
      "\tspeed: 0.1013s/iter; left time: 651.0256s\n",
      "\titers: 800, epoch: 3 | loss: 0.1171292\n",
      "\tspeed: 0.1010s/iter; left time: 639.2770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.06s\n",
      "Steps: 891 | Train Loss: 0.1287168 Vali Loss: 0.0378419 Test Loss: 0.0429586\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1142807\n",
      "\tspeed: 0.3458s/iter; left time: 2122.2728s\n",
      "\titers: 200, epoch: 4 | loss: 0.1143978\n",
      "\tspeed: 0.1013s/iter; left time: 611.4848s\n",
      "\titers: 300, epoch: 4 | loss: 0.1076153\n",
      "\tspeed: 0.1015s/iter; left time: 602.8378s\n",
      "\titers: 400, epoch: 4 | loss: 0.1065834\n",
      "\tspeed: 0.1011s/iter; left time: 590.3578s\n",
      "\titers: 500, epoch: 4 | loss: 0.1121684\n",
      "\tspeed: 0.1013s/iter; left time: 581.4792s\n",
      "\titers: 600, epoch: 4 | loss: 0.1129457\n",
      "\tspeed: 0.1014s/iter; left time: 571.4157s\n",
      "\titers: 700, epoch: 4 | loss: 0.0939118\n",
      "\tspeed: 0.1015s/iter; left time: 561.9104s\n",
      "\titers: 800, epoch: 4 | loss: 0.0974709\n",
      "\tspeed: 0.1013s/iter; left time: 551.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.53s\n",
      "Steps: 891 | Train Loss: 0.1058249 Vali Loss: 0.0437333 Test Loss: 0.0472448\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036603327840566635, rmse:0.19131995737552643, mae:0.13838830590248108, rse:0.6775026321411133\n",
      "Original data scale mse:32360570.0, rmse:5688.63525390625, mae:3905.592041015625, rse:0.28329604864120483\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1952264\n",
      "\tspeed: 0.1035s/iter; left time: 912.1407s\n",
      "\titers: 200, epoch: 1 | loss: 0.1621492\n",
      "\tspeed: 0.1069s/iter; left time: 931.1643s\n",
      "\titers: 300, epoch: 1 | loss: 0.1693379\n",
      "\tspeed: 0.1035s/iter; left time: 891.6288s\n",
      "\titers: 400, epoch: 1 | loss: 0.1607978\n",
      "\tspeed: 0.1012s/iter; left time: 861.6327s\n",
      "\titers: 500, epoch: 1 | loss: 0.1524535\n",
      "\tspeed: 0.1014s/iter; left time: 852.8902s\n",
      "\titers: 600, epoch: 1 | loss: 0.1610103\n",
      "\tspeed: 0.1012s/iter; left time: 840.7983s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688292\n",
      "\tspeed: 0.1010s/iter; left time: 828.9623s\n",
      "\titers: 800, epoch: 1 | loss: 0.1587957\n",
      "\tspeed: 0.1011s/iter; left time: 820.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.26s\n",
      "Steps: 891 | Train Loss: 0.1645731 Vali Loss: 0.0318549 Test Loss: 0.0364859\n",
      "Validation loss decreased (inf --> 0.031855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626220\n",
      "\tspeed: 0.3539s/iter; left time: 2802.7061s\n",
      "\titers: 200, epoch: 2 | loss: 0.1561028\n",
      "\tspeed: 0.1008s/iter; left time: 788.3386s\n",
      "\titers: 300, epoch: 2 | loss: 0.1408677\n",
      "\tspeed: 0.1015s/iter; left time: 783.4204s\n",
      "\titers: 400, epoch: 2 | loss: 0.1409497\n",
      "\tspeed: 0.1014s/iter; left time: 772.6113s\n",
      "\titers: 500, epoch: 2 | loss: 0.1434509\n",
      "\tspeed: 0.1015s/iter; left time: 762.9138s\n",
      "\titers: 600, epoch: 2 | loss: 0.1367914\n",
      "\tspeed: 0.1014s/iter; left time: 752.2948s\n",
      "\titers: 700, epoch: 2 | loss: 0.1462361\n",
      "\tspeed: 0.1015s/iter; left time: 742.8230s\n",
      "\titers: 800, epoch: 2 | loss: 0.1419257\n",
      "\tspeed: 0.1015s/iter; left time: 732.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.61s\n",
      "Steps: 891 | Train Loss: 0.1479053 Vali Loss: 0.0337854 Test Loss: 0.0402032\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1242544\n",
      "\tspeed: 0.3462s/iter; left time: 2433.7291s\n",
      "\titers: 200, epoch: 3 | loss: 0.1272509\n",
      "\tspeed: 0.1012s/iter; left time: 701.1839s\n",
      "\titers: 300, epoch: 3 | loss: 0.1288482\n",
      "\tspeed: 0.1010s/iter; left time: 689.9265s\n",
      "\titers: 400, epoch: 3 | loss: 0.1393355\n",
      "\tspeed: 0.1018s/iter; left time: 685.2854s\n",
      "\titers: 500, epoch: 3 | loss: 0.1171228\n",
      "\tspeed: 0.1014s/iter; left time: 672.4890s\n",
      "\titers: 600, epoch: 3 | loss: 0.1278188\n",
      "\tspeed: 0.1013s/iter; left time: 661.4066s\n",
      "\titers: 700, epoch: 3 | loss: 0.1233531\n",
      "\tspeed: 0.1012s/iter; left time: 650.3361s\n",
      "\titers: 800, epoch: 3 | loss: 0.1174964\n",
      "\tspeed: 0.1015s/iter; left time: 642.5724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.49s\n",
      "Steps: 891 | Train Loss: 0.1288594 Vali Loss: 0.0374324 Test Loss: 0.0468877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1158727\n",
      "\tspeed: 0.3475s/iter; left time: 2132.9875s\n",
      "\titers: 200, epoch: 4 | loss: 0.1093341\n",
      "\tspeed: 0.1011s/iter; left time: 610.5776s\n",
      "\titers: 300, epoch: 4 | loss: 0.1101140\n",
      "\tspeed: 0.1016s/iter; left time: 603.4769s\n",
      "\titers: 400, epoch: 4 | loss: 0.1086028\n",
      "\tspeed: 0.1011s/iter; left time: 590.3911s\n",
      "\titers: 500, epoch: 4 | loss: 0.1044558\n",
      "\tspeed: 0.1012s/iter; left time: 580.6165s\n",
      "\titers: 600, epoch: 4 | loss: 0.1027884\n",
      "\tspeed: 0.1014s/iter; left time: 571.5013s\n",
      "\titers: 700, epoch: 4 | loss: 0.1035529\n",
      "\tspeed: 0.1012s/iter; left time: 560.1714s\n",
      "\titers: 800, epoch: 4 | loss: 0.0961915\n",
      "\tspeed: 0.1016s/iter; left time: 552.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.52s\n",
      "Steps: 891 | Train Loss: 0.1071378 Vali Loss: 0.0396865 Test Loss: 0.0500152\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03648588806390762, rmse:0.19101279973983765, mae:0.13797330856323242, rse:0.6764149069786072\n",
      "Original data scale mse:32326948.0, rmse:5685.67919921875, mae:3887.625732421875, rse:0.283148854970932\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1813537\n",
      "\tspeed: 0.1245s/iter; left time: 1094.8493s\n",
      "\titers: 200, epoch: 1 | loss: 0.1736036\n",
      "\tspeed: 0.1018s/iter; left time: 884.5341s\n",
      "\titers: 300, epoch: 1 | loss: 0.1446208\n",
      "\tspeed: 0.1079s/iter; left time: 927.0436s\n",
      "\titers: 400, epoch: 1 | loss: 0.1706987\n",
      "\tspeed: 0.1021s/iter; left time: 866.6565s\n",
      "\titers: 500, epoch: 1 | loss: 0.1764388\n",
      "\tspeed: 0.1020s/iter; left time: 855.4799s\n",
      "\titers: 600, epoch: 1 | loss: 0.1612300\n",
      "\tspeed: 0.1017s/iter; left time: 843.5418s\n",
      "\titers: 700, epoch: 1 | loss: 0.1638638\n",
      "\tspeed: 0.1022s/iter; left time: 837.1827s\n",
      "\titers: 800, epoch: 1 | loss: 0.1574917\n",
      "\tspeed: 0.1022s/iter; left time: 826.7324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.78s\n",
      "Steps: 889 | Train Loss: 0.1706613 Vali Loss: 0.0334000 Test Loss: 0.0388627\n",
      "Validation loss decreased (inf --> 0.033400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1532820\n",
      "\tspeed: 0.3535s/iter; left time: 2793.4223s\n",
      "\titers: 200, epoch: 2 | loss: 0.1649505\n",
      "\tspeed: 0.1022s/iter; left time: 797.3908s\n",
      "\titers: 300, epoch: 2 | loss: 0.1429061\n",
      "\tspeed: 0.1024s/iter; left time: 788.4841s\n",
      "\titers: 400, epoch: 2 | loss: 0.1566984\n",
      "\tspeed: 0.1023s/iter; left time: 777.7978s\n",
      "\titers: 500, epoch: 2 | loss: 0.1473633\n",
      "\tspeed: 0.1023s/iter; left time: 767.2785s\n",
      "\titers: 600, epoch: 2 | loss: 0.1482671\n",
      "\tspeed: 0.1022s/iter; left time: 756.4657s\n",
      "\titers: 700, epoch: 2 | loss: 0.1530723\n",
      "\tspeed: 0.1021s/iter; left time: 745.7355s\n",
      "\titers: 800, epoch: 2 | loss: 0.1483534\n",
      "\tspeed: 0.1026s/iter; left time: 738.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.16s\n",
      "Steps: 889 | Train Loss: 0.1519806 Vali Loss: 0.0380029 Test Loss: 0.0453029\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1350376\n",
      "\tspeed: 0.3477s/iter; left time: 2438.2802s\n",
      "\titers: 200, epoch: 3 | loss: 0.1375475\n",
      "\tspeed: 0.1022s/iter; left time: 706.4793s\n",
      "\titers: 300, epoch: 3 | loss: 0.1280418\n",
      "\tspeed: 0.1021s/iter; left time: 695.4533s\n",
      "\titers: 400, epoch: 3 | loss: 0.1359251\n",
      "\tspeed: 0.1021s/iter; left time: 685.2563s\n",
      "\titers: 500, epoch: 3 | loss: 0.1330425\n",
      "\tspeed: 0.1025s/iter; left time: 677.8106s\n",
      "\titers: 600, epoch: 3 | loss: 0.1251386\n",
      "\tspeed: 0.1023s/iter; left time: 665.9687s\n",
      "\titers: 700, epoch: 3 | loss: 0.1168282\n",
      "\tspeed: 0.1025s/iter; left time: 657.3609s\n",
      "\titers: 800, epoch: 3 | loss: 0.1101920\n",
      "\tspeed: 0.1027s/iter; left time: 648.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.16s\n",
      "Steps: 889 | Train Loss: 0.1247783 Vali Loss: 0.0402519 Test Loss: 0.0477227\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1119974\n",
      "\tspeed: 0.3483s/iter; left time: 2132.9281s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102067\n",
      "\tspeed: 0.1024s/iter; left time: 617.0133s\n",
      "\titers: 300, epoch: 4 | loss: 0.1018137\n",
      "\tspeed: 0.1020s/iter; left time: 604.0923s\n",
      "\titers: 400, epoch: 4 | loss: 0.0994680\n",
      "\tspeed: 0.1025s/iter; left time: 596.9458s\n",
      "\titers: 500, epoch: 4 | loss: 0.0942658\n",
      "\tspeed: 0.1020s/iter; left time: 583.8645s\n",
      "\titers: 600, epoch: 4 | loss: 0.0989845\n",
      "\tspeed: 0.1024s/iter; left time: 576.1157s\n",
      "\titers: 700, epoch: 4 | loss: 0.0970582\n",
      "\tspeed: 0.1026s/iter; left time: 567.0062s\n",
      "\titers: 800, epoch: 4 | loss: 0.0898547\n",
      "\tspeed: 0.1026s/iter; left time: 556.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:31.20s\n",
      "Steps: 889 | Train Loss: 0.1006073 Vali Loss: 0.0423293 Test Loss: 0.0502917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0388626903295517, rmse:0.19713622331619263, mae:0.14482037723064423, rse:0.6983942985534668\n",
      "Original data scale mse:35409284.0, rmse:5950.56982421875, mae:4112.27734375, rse:0.2964859902858734\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1734459\n",
      "\tspeed: 0.1041s/iter; left time: 915.3580s\n",
      "\titers: 200, epoch: 1 | loss: 0.1919643\n",
      "\tspeed: 0.1018s/iter; left time: 885.0965s\n",
      "\titers: 300, epoch: 1 | loss: 0.1739493\n",
      "\tspeed: 0.1042s/iter; left time: 895.0286s\n",
      "\titers: 400, epoch: 1 | loss: 0.1773008\n",
      "\tspeed: 0.1077s/iter; left time: 914.8116s\n",
      "\titers: 500, epoch: 1 | loss: 0.1556721\n",
      "\tspeed: 0.1023s/iter; left time: 858.3326s\n",
      "\titers: 600, epoch: 1 | loss: 0.1593454\n",
      "\tspeed: 0.1025s/iter; left time: 850.0519s\n",
      "\titers: 700, epoch: 1 | loss: 0.1684908\n",
      "\tspeed: 0.1024s/iter; left time: 838.3941s\n",
      "\titers: 800, epoch: 1 | loss: 0.1576264\n",
      "\tspeed: 0.1023s/iter; left time: 827.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.93s\n",
      "Steps: 889 | Train Loss: 0.1709800 Vali Loss: 0.0332334 Test Loss: 0.0390132\n",
      "Validation loss decreased (inf --> 0.033233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1700018\n",
      "\tspeed: 0.3628s/iter; left time: 2866.9157s\n",
      "\titers: 200, epoch: 2 | loss: 0.1513699\n",
      "\tspeed: 0.1021s/iter; left time: 796.4754s\n",
      "\titers: 300, epoch: 2 | loss: 0.1636273\n",
      "\tspeed: 0.1020s/iter; left time: 785.6384s\n",
      "\titers: 400, epoch: 2 | loss: 0.1498606\n",
      "\tspeed: 0.1019s/iter; left time: 774.7611s\n",
      "\titers: 500, epoch: 2 | loss: 0.1548591\n",
      "\tspeed: 0.1021s/iter; left time: 765.6991s\n",
      "\titers: 600, epoch: 2 | loss: 0.1442621\n",
      "\tspeed: 0.1028s/iter; left time: 761.1198s\n",
      "\titers: 700, epoch: 2 | loss: 0.1558722\n",
      "\tspeed: 0.1022s/iter; left time: 746.2668s\n",
      "\titers: 800, epoch: 2 | loss: 0.1472188\n",
      "\tspeed: 0.1022s/iter; left time: 735.8812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.08s\n",
      "Steps: 889 | Train Loss: 0.1526996 Vali Loss: 0.0358865 Test Loss: 0.0440398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1444306\n",
      "\tspeed: 0.3498s/iter; left time: 2453.4767s\n",
      "\titers: 200, epoch: 3 | loss: 0.1377799\n",
      "\tspeed: 0.1024s/iter; left time: 707.8682s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303597\n",
      "\tspeed: 0.1026s/iter; left time: 698.7994s\n",
      "\titers: 400, epoch: 3 | loss: 0.1362117\n",
      "\tspeed: 0.1019s/iter; left time: 684.2048s\n",
      "\titers: 500, epoch: 3 | loss: 0.1155152\n",
      "\tspeed: 0.1024s/iter; left time: 677.3831s\n",
      "\titers: 600, epoch: 3 | loss: 0.1282833\n",
      "\tspeed: 0.1025s/iter; left time: 667.6253s\n",
      "\titers: 700, epoch: 3 | loss: 0.1170158\n",
      "\tspeed: 0.1027s/iter; left time: 658.5512s\n",
      "\titers: 800, epoch: 3 | loss: 0.1080970\n",
      "\tspeed: 0.1024s/iter; left time: 646.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.18s\n",
      "Steps: 889 | Train Loss: 0.1258240 Vali Loss: 0.0417803 Test Loss: 0.0507655\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117596\n",
      "\tspeed: 0.3499s/iter; left time: 2142.8857s\n",
      "\titers: 200, epoch: 4 | loss: 0.1035002\n",
      "\tspeed: 0.1020s/iter; left time: 614.5542s\n",
      "\titers: 300, epoch: 4 | loss: 0.1072839\n",
      "\tspeed: 0.1023s/iter; left time: 605.8743s\n",
      "\titers: 400, epoch: 4 | loss: 0.1025885\n",
      "\tspeed: 0.1025s/iter; left time: 596.7733s\n",
      "\titers: 500, epoch: 4 | loss: 0.1002028\n",
      "\tspeed: 0.1028s/iter; left time: 588.4270s\n",
      "\titers: 600, epoch: 4 | loss: 0.1014473\n",
      "\tspeed: 0.1026s/iter; left time: 576.8188s\n",
      "\titers: 700, epoch: 4 | loss: 0.0892512\n",
      "\tspeed: 0.1027s/iter; left time: 567.0987s\n",
      "\titers: 800, epoch: 4 | loss: 0.0937425\n",
      "\tspeed: 0.1022s/iter; left time: 554.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:31.33s\n",
      "Steps: 889 | Train Loss: 0.1014797 Vali Loss: 0.0426364 Test Loss: 0.0509998\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039013225585222244, rmse:0.19751766324043274, mae:0.14449027180671692, rse:0.6997455954551697\n",
      "Original data scale mse:35583288.0, rmse:5965.1728515625, mae:4101.09814453125, rse:0.2972135543823242\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1200973\n",
      "\tspeed: 0.1236s/iter; left time: 1091.5092s\n",
      "\titers: 200, epoch: 1 | loss: 0.0960080\n",
      "\tspeed: 0.0998s/iter; left time: 871.5025s\n",
      "\titers: 300, epoch: 1 | loss: 0.0960452\n",
      "\tspeed: 0.1027s/iter; left time: 886.6902s\n",
      "\titers: 400, epoch: 1 | loss: 0.0973126\n",
      "\tspeed: 0.1036s/iter; left time: 883.6317s\n",
      "\titers: 500, epoch: 1 | loss: 0.1016097\n",
      "\tspeed: 0.1002s/iter; left time: 844.3987s\n",
      "\titers: 600, epoch: 1 | loss: 0.0896932\n",
      "\tspeed: 0.1000s/iter; left time: 833.3169s\n",
      "\titers: 700, epoch: 1 | loss: 0.0829105\n",
      "\tspeed: 0.0998s/iter; left time: 821.4385s\n",
      "\titers: 800, epoch: 1 | loss: 0.0847440\n",
      "\tspeed: 0.1001s/iter; left time: 813.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.35s\n",
      "Steps: 893 | Train Loss: 0.0984340 Vali Loss: 0.0973669 Test Loss: 0.0992441\n",
      "Validation loss decreased (inf --> 0.097367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0843725\n",
      "\tspeed: 0.3418s/iter; left time: 2713.0299s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824214\n",
      "\tspeed: 0.0997s/iter; left time: 781.6544s\n",
      "\titers: 300, epoch: 2 | loss: 0.0782013\n",
      "\tspeed: 0.0998s/iter; left time: 772.5924s\n",
      "\titers: 400, epoch: 2 | loss: 0.0754754\n",
      "\tspeed: 0.0997s/iter; left time: 761.8229s\n",
      "\titers: 500, epoch: 2 | loss: 0.0793686\n",
      "\tspeed: 0.1005s/iter; left time: 757.6348s\n",
      "\titers: 600, epoch: 2 | loss: 0.0771859\n",
      "\tspeed: 0.1003s/iter; left time: 745.9429s\n",
      "\titers: 700, epoch: 2 | loss: 0.0978021\n",
      "\tspeed: 0.1004s/iter; left time: 736.5873s\n",
      "\titers: 800, epoch: 2 | loss: 0.0781258\n",
      "\tspeed: 0.1002s/iter; left time: 725.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.61s\n",
      "Steps: 893 | Train Loss: 0.0790634 Vali Loss: 0.0938786 Test Loss: 0.0956575\n",
      "Validation loss decreased (0.097367 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0694974\n",
      "\tspeed: 0.3506s/iter; left time: 2469.6746s\n",
      "\titers: 200, epoch: 3 | loss: 0.0830274\n",
      "\tspeed: 0.1000s/iter; left time: 694.7123s\n",
      "\titers: 300, epoch: 3 | loss: 0.0714424\n",
      "\tspeed: 0.0998s/iter; left time: 683.2368s\n",
      "\titers: 400, epoch: 3 | loss: 0.0721425\n",
      "\tspeed: 0.1000s/iter; left time: 674.5646s\n",
      "\titers: 500, epoch: 3 | loss: 0.0733056\n",
      "\tspeed: 0.1000s/iter; left time: 664.2954s\n",
      "\titers: 600, epoch: 3 | loss: 0.0739291\n",
      "\tspeed: 0.1004s/iter; left time: 656.8092s\n",
      "\titers: 700, epoch: 3 | loss: 0.0679637\n",
      "\tspeed: 0.1002s/iter; left time: 645.9142s\n",
      "\titers: 800, epoch: 3 | loss: 0.0677225\n",
      "\tspeed: 0.1001s/iter; left time: 635.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.61s\n",
      "Steps: 893 | Train Loss: 0.0732614 Vali Loss: 0.0928523 Test Loss: 0.0957954\n",
      "Validation loss decreased (0.093879 --> 0.092852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0709998\n",
      "\tspeed: 0.3443s/iter; left time: 2118.3509s\n",
      "\titers: 200, epoch: 4 | loss: 0.0624692\n",
      "\tspeed: 0.1005s/iter; left time: 608.2383s\n",
      "\titers: 300, epoch: 4 | loss: 0.0712063\n",
      "\tspeed: 0.1002s/iter; left time: 596.5334s\n",
      "\titers: 400, epoch: 4 | loss: 0.0677904\n",
      "\tspeed: 0.1000s/iter; left time: 585.0449s\n",
      "\titers: 500, epoch: 4 | loss: 0.0750721\n",
      "\tspeed: 0.1003s/iter; left time: 577.1935s\n",
      "\titers: 600, epoch: 4 | loss: 0.0744733\n",
      "\tspeed: 0.1003s/iter; left time: 566.7080s\n",
      "\titers: 700, epoch: 4 | loss: 0.0693998\n",
      "\tspeed: 0.1003s/iter; left time: 556.6343s\n",
      "\titers: 800, epoch: 4 | loss: 0.0777812\n",
      "\tspeed: 0.1003s/iter; left time: 546.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.66s\n",
      "Steps: 893 | Train Loss: 0.0703738 Vali Loss: 0.0941312 Test Loss: 0.0961550\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0790049\n",
      "\tspeed: 0.3465s/iter; left time: 1822.0858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606358\n",
      "\tspeed: 0.1005s/iter; left time: 518.4606s\n",
      "\titers: 300, epoch: 5 | loss: 0.0520899\n",
      "\tspeed: 0.1002s/iter; left time: 506.6901s\n",
      "\titers: 400, epoch: 5 | loss: 0.0682277\n",
      "\tspeed: 0.1001s/iter; left time: 496.1485s\n",
      "\titers: 500, epoch: 5 | loss: 0.0614379\n",
      "\tspeed: 0.1001s/iter; left time: 486.6164s\n",
      "\titers: 600, epoch: 5 | loss: 0.0701793\n",
      "\tspeed: 0.1041s/iter; left time: 495.2686s\n",
      "\titers: 700, epoch: 5 | loss: 0.0585977\n",
      "\tspeed: 0.0999s/iter; left time: 465.5390s\n",
      "\titers: 800, epoch: 5 | loss: 0.0735921\n",
      "\tspeed: 0.1001s/iter; left time: 456.4652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.02s\n",
      "Steps: 893 | Train Loss: 0.0671491 Vali Loss: 0.0947798 Test Loss: 0.0976988\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651934\n",
      "\tspeed: 0.3421s/iter; left time: 1493.6206s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720185\n",
      "\tspeed: 0.1000s/iter; left time: 426.5822s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727205\n",
      "\tspeed: 0.1004s/iter; left time: 418.0833s\n",
      "\titers: 400, epoch: 6 | loss: 0.0585615\n",
      "\tspeed: 0.1000s/iter; left time: 406.5034s\n",
      "\titers: 500, epoch: 6 | loss: 0.0706859\n",
      "\tspeed: 0.1004s/iter; left time: 398.2795s\n",
      "\titers: 600, epoch: 6 | loss: 0.0593604\n",
      "\tspeed: 0.1003s/iter; left time: 387.7106s\n",
      "\titers: 700, epoch: 6 | loss: 0.0681933\n",
      "\tspeed: 0.1002s/iter; left time: 377.4639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0593371\n",
      "\tspeed: 0.1001s/iter; left time: 367.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.69s\n",
      "Steps: 893 | Train Loss: 0.0633515 Vali Loss: 0.0958709 Test Loss: 0.1000129\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023316901177167892, rmse:0.15269872546195984, mae:0.0957954004406929, rse:0.539259672164917\n",
      "Original data scale mse:18010934.0, rmse:4243.92919921875, mae:2587.850341796875, rse:0.2110167145729065\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1285629\n",
      "\tspeed: 0.1022s/iter; left time: 902.1200s\n",
      "\titers: 200, epoch: 1 | loss: 0.1115011\n",
      "\tspeed: 0.1004s/iter; left time: 876.7351s\n",
      "\titers: 300, epoch: 1 | loss: 0.0924628\n",
      "\tspeed: 0.1001s/iter; left time: 864.1967s\n",
      "\titers: 400, epoch: 1 | loss: 0.0887829\n",
      "\tspeed: 0.1001s/iter; left time: 854.0918s\n",
      "\titers: 500, epoch: 1 | loss: 0.0891219\n",
      "\tspeed: 0.1001s/iter; left time: 843.6443s\n",
      "\titers: 600, epoch: 1 | loss: 0.0737124\n",
      "\tspeed: 0.1001s/iter; left time: 833.5303s\n",
      "\titers: 700, epoch: 1 | loss: 0.0858261\n",
      "\tspeed: 0.1001s/iter; left time: 824.0016s\n",
      "\titers: 800, epoch: 1 | loss: 0.0988472\n",
      "\tspeed: 0.1001s/iter; left time: 813.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.69s\n",
      "Steps: 893 | Train Loss: 0.0984511 Vali Loss: 0.0973818 Test Loss: 0.0990048\n",
      "Validation loss decreased (inf --> 0.097382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0849656\n",
      "\tspeed: 0.3483s/iter; left time: 2765.0294s\n",
      "\titers: 200, epoch: 2 | loss: 0.0819675\n",
      "\tspeed: 0.0999s/iter; left time: 783.2148s\n",
      "\titers: 300, epoch: 2 | loss: 0.0886862\n",
      "\tspeed: 0.1003s/iter; left time: 776.3776s\n",
      "\titers: 400, epoch: 2 | loss: 0.0725104\n",
      "\tspeed: 0.1003s/iter; left time: 765.8310s\n",
      "\titers: 500, epoch: 2 | loss: 0.0802856\n",
      "\tspeed: 0.0996s/iter; left time: 750.8005s\n",
      "\titers: 600, epoch: 2 | loss: 0.0821624\n",
      "\tspeed: 0.1006s/iter; left time: 747.9580s\n",
      "\titers: 700, epoch: 2 | loss: 0.0851737\n",
      "\tspeed: 0.1001s/iter; left time: 734.5923s\n",
      "\titers: 800, epoch: 2 | loss: 0.0794775\n",
      "\tspeed: 0.0996s/iter; left time: 720.7018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.58s\n",
      "Steps: 893 | Train Loss: 0.0788863 Vali Loss: 0.0941028 Test Loss: 0.0958893\n",
      "Validation loss decreased (0.097382 --> 0.094103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0660634\n",
      "\tspeed: 0.3446s/iter; left time: 2427.7634s\n",
      "\titers: 200, epoch: 3 | loss: 0.0760424\n",
      "\tspeed: 0.1000s/iter; left time: 694.4604s\n",
      "\titers: 300, epoch: 3 | loss: 0.0696000\n",
      "\tspeed: 0.1002s/iter; left time: 686.0413s\n",
      "\titers: 400, epoch: 3 | loss: 0.0891248\n",
      "\tspeed: 0.1002s/iter; left time: 676.1202s\n",
      "\titers: 500, epoch: 3 | loss: 0.0644646\n",
      "\tspeed: 0.1002s/iter; left time: 666.1167s\n",
      "\titers: 600, epoch: 3 | loss: 0.0701678\n",
      "\tspeed: 0.1002s/iter; left time: 655.8402s\n",
      "\titers: 700, epoch: 3 | loss: 0.0843375\n",
      "\tspeed: 0.1005s/iter; left time: 647.4855s\n",
      "\titers: 800, epoch: 3 | loss: 0.0649505\n",
      "\tspeed: 0.1002s/iter; left time: 635.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.76s\n",
      "Steps: 893 | Train Loss: 0.0729236 Vali Loss: 0.0915015 Test Loss: 0.0949013\n",
      "Validation loss decreased (0.094103 --> 0.091502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787428\n",
      "\tspeed: 0.3451s/iter; left time: 2122.7692s\n",
      "\titers: 200, epoch: 4 | loss: 0.0679867\n",
      "\tspeed: 0.1003s/iter; left time: 606.7572s\n",
      "\titers: 300, epoch: 4 | loss: 0.0606556\n",
      "\tspeed: 0.0999s/iter; left time: 594.4971s\n",
      "\titers: 400, epoch: 4 | loss: 0.0732759\n",
      "\tspeed: 0.1005s/iter; left time: 588.2953s\n",
      "\titers: 500, epoch: 4 | loss: 0.0676788\n",
      "\tspeed: 0.1004s/iter; left time: 577.4478s\n",
      "\titers: 600, epoch: 4 | loss: 0.0672780\n",
      "\tspeed: 0.1002s/iter; left time: 566.3102s\n",
      "\titers: 700, epoch: 4 | loss: 0.0718775\n",
      "\tspeed: 0.1001s/iter; left time: 555.7268s\n",
      "\titers: 800, epoch: 4 | loss: 0.0742015\n",
      "\tspeed: 0.0999s/iter; left time: 544.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.67s\n",
      "Steps: 893 | Train Loss: 0.0698874 Vali Loss: 0.0923485 Test Loss: 0.0957890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0676645\n",
      "\tspeed: 0.3410s/iter; left time: 1793.4771s\n",
      "\titers: 200, epoch: 5 | loss: 0.0694908\n",
      "\tspeed: 0.1002s/iter; left time: 516.8451s\n",
      "\titers: 300, epoch: 5 | loss: 0.0677868\n",
      "\tspeed: 0.1001s/iter; left time: 506.2019s\n",
      "\titers: 400, epoch: 5 | loss: 0.0716307\n",
      "\tspeed: 0.1000s/iter; left time: 495.8767s\n",
      "\titers: 500, epoch: 5 | loss: 0.0674858\n",
      "\tspeed: 0.1003s/iter; left time: 487.5921s\n",
      "\titers: 600, epoch: 5 | loss: 0.0696147\n",
      "\tspeed: 0.1001s/iter; left time: 476.4583s\n",
      "\titers: 700, epoch: 5 | loss: 0.0578832\n",
      "\tspeed: 0.1003s/iter; left time: 467.1052s\n",
      "\titers: 800, epoch: 5 | loss: 0.0617297\n",
      "\tspeed: 0.1000s/iter; left time: 455.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.63s\n",
      "Steps: 893 | Train Loss: 0.0666300 Vali Loss: 0.0941932 Test Loss: 0.0972754\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0607351\n",
      "\tspeed: 0.3424s/iter; left time: 1494.7855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0625508\n",
      "\tspeed: 0.1000s/iter; left time: 426.7291s\n",
      "\titers: 300, epoch: 6 | loss: 0.0551316\n",
      "\tspeed: 0.1001s/iter; left time: 417.0205s\n",
      "\titers: 400, epoch: 6 | loss: 0.0632569\n",
      "\tspeed: 0.1000s/iter; left time: 406.7817s\n",
      "\titers: 500, epoch: 6 | loss: 0.0658557\n",
      "\tspeed: 0.1002s/iter; left time: 397.5078s\n",
      "\titers: 600, epoch: 6 | loss: 0.0593156\n",
      "\tspeed: 0.1004s/iter; left time: 388.3081s\n",
      "\titers: 700, epoch: 6 | loss: 0.0639014\n",
      "\tspeed: 0.1001s/iter; left time: 376.9391s\n",
      "\titers: 800, epoch: 6 | loss: 0.0603856\n",
      "\tspeed: 0.1001s/iter; left time: 366.8961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.67s\n",
      "Steps: 893 | Train Loss: 0.0627865 Vali Loss: 0.0960309 Test Loss: 0.0989485\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02310037985444069, rmse:0.15198808908462524, mae:0.09490125626325607, rse:0.536750078201294\n",
      "Original data scale mse:17940912.0, rmse:4235.67138671875, mae:2567.298828125, rse:0.21060611307621002\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1405462\n",
      "\tspeed: 0.1250s/iter; left time: 1101.2793s\n",
      "\titers: 200, epoch: 1 | loss: 0.1253485\n",
      "\tspeed: 0.1011s/iter; left time: 880.4348s\n",
      "\titers: 300, epoch: 1 | loss: 0.1268495\n",
      "\tspeed: 0.1011s/iter; left time: 870.5070s\n",
      "\titers: 400, epoch: 1 | loss: 0.1178507\n",
      "\tspeed: 0.1012s/iter; left time: 861.2362s\n",
      "\titers: 500, epoch: 1 | loss: 0.1178404\n",
      "\tspeed: 0.1011s/iter; left time: 850.6238s\n",
      "\titers: 600, epoch: 1 | loss: 0.1064667\n",
      "\tspeed: 0.1012s/iter; left time: 840.7336s\n",
      "\titers: 700, epoch: 1 | loss: 0.1166244\n",
      "\tspeed: 0.1014s/iter; left time: 832.7316s\n",
      "\titers: 800, epoch: 1 | loss: 0.1076130\n",
      "\tspeed: 0.1067s/iter; left time: 865.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.24s\n",
      "Steps: 891 | Train Loss: 0.1211557 Vali Loss: 0.1238740 Test Loss: 0.1303339\n",
      "Validation loss decreased (inf --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974789\n",
      "\tspeed: 0.3504s/iter; left time: 2774.8621s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091900\n",
      "\tspeed: 0.1012s/iter; left time: 791.6580s\n",
      "\titers: 300, epoch: 2 | loss: 0.1112887\n",
      "\tspeed: 0.1014s/iter; left time: 782.6784s\n",
      "\titers: 400, epoch: 2 | loss: 0.1022903\n",
      "\tspeed: 0.1010s/iter; left time: 769.6121s\n",
      "\titers: 500, epoch: 2 | loss: 0.0997768\n",
      "\tspeed: 0.1012s/iter; left time: 760.9268s\n",
      "\titers: 600, epoch: 2 | loss: 0.1148842\n",
      "\tspeed: 0.1012s/iter; left time: 750.5635s\n",
      "\titers: 700, epoch: 2 | loss: 0.0928982\n",
      "\tspeed: 0.1010s/iter; left time: 739.4928s\n",
      "\titers: 800, epoch: 2 | loss: 0.0911896\n",
      "\tspeed: 0.1011s/iter; left time: 729.8531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.38s\n",
      "Steps: 891 | Train Loss: 0.1025866 Vali Loss: 0.1218623 Test Loss: 0.1305734\n",
      "Validation loss decreased (0.123874 --> 0.121862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930635\n",
      "\tspeed: 0.3475s/iter; left time: 2442.3015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0965855\n",
      "\tspeed: 0.1012s/iter; left time: 700.8733s\n",
      "\titers: 300, epoch: 3 | loss: 0.0959147\n",
      "\tspeed: 0.1008s/iter; left time: 688.4265s\n",
      "\titers: 400, epoch: 3 | loss: 0.0877690\n",
      "\tspeed: 0.1015s/iter; left time: 682.9098s\n",
      "\titers: 500, epoch: 3 | loss: 0.0839224\n",
      "\tspeed: 0.1016s/iter; left time: 673.3809s\n",
      "\titers: 600, epoch: 3 | loss: 0.0871063\n",
      "\tspeed: 0.1015s/iter; left time: 662.5480s\n",
      "\titers: 700, epoch: 3 | loss: 0.0867681\n",
      "\tspeed: 0.1015s/iter; left time: 652.5818s\n",
      "\titers: 800, epoch: 3 | loss: 0.0847024\n",
      "\tspeed: 0.1012s/iter; left time: 640.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.87s\n",
      "Steps: 891 | Train Loss: 0.0912032 Vali Loss: 0.1269986 Test Loss: 0.1376983\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0903430\n",
      "\tspeed: 0.3541s/iter; left time: 2173.2912s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851180\n",
      "\tspeed: 0.1013s/iter; left time: 611.6676s\n",
      "\titers: 300, epoch: 4 | loss: 0.0805335\n",
      "\tspeed: 0.1014s/iter; left time: 601.8647s\n",
      "\titers: 400, epoch: 4 | loss: 0.0770309\n",
      "\tspeed: 0.1012s/iter; left time: 590.5732s\n",
      "\titers: 500, epoch: 4 | loss: 0.0778691\n",
      "\tspeed: 0.1010s/iter; left time: 579.4908s\n",
      "\titers: 600, epoch: 4 | loss: 0.0860237\n",
      "\tspeed: 0.1010s/iter; left time: 569.5285s\n",
      "\titers: 700, epoch: 4 | loss: 0.0736070\n",
      "\tspeed: 0.1009s/iter; left time: 558.9379s\n",
      "\titers: 800, epoch: 4 | loss: 0.0707810\n",
      "\tspeed: 0.1013s/iter; left time: 550.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.36s\n",
      "Steps: 891 | Train Loss: 0.0793320 Vali Loss: 0.1316009 Test Loss: 0.1369859\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0685460\n",
      "\tspeed: 0.3448s/iter; left time: 1809.0836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0660181\n",
      "\tspeed: 0.1012s/iter; left time: 520.6546s\n",
      "\titers: 300, epoch: 5 | loss: 0.0671617\n",
      "\tspeed: 0.1014s/iter; left time: 511.9872s\n",
      "\titers: 400, epoch: 5 | loss: 0.0670180\n",
      "\tspeed: 0.1013s/iter; left time: 501.0936s\n",
      "\titers: 500, epoch: 5 | loss: 0.0645318\n",
      "\tspeed: 0.1013s/iter; left time: 490.8010s\n",
      "\titers: 600, epoch: 5 | loss: 0.0656060\n",
      "\tspeed: 0.1011s/iter; left time: 479.7594s\n",
      "\titers: 700, epoch: 5 | loss: 0.0687921\n",
      "\tspeed: 0.1013s/iter; left time: 470.5624s\n",
      "\titers: 800, epoch: 5 | loss: 0.0657431\n",
      "\tspeed: 0.1011s/iter; left time: 459.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.37s\n",
      "Steps: 891 | Train Loss: 0.0667082 Vali Loss: 0.1323775 Test Loss: 0.1421715\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038427021354436874, rmse:0.19602811336517334, mae:0.13057343661785126, rse:0.6941751837730408\n",
      "Original data scale mse:33274860.0, rmse:5768.4365234375, mae:3605.2802734375, rse:0.287270188331604\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1428803\n",
      "\tspeed: 0.1037s/iter; left time: 913.9205s\n",
      "\titers: 200, epoch: 1 | loss: 0.1325968\n",
      "\tspeed: 0.1010s/iter; left time: 880.1563s\n",
      "\titers: 300, epoch: 1 | loss: 0.1287008\n",
      "\tspeed: 0.1012s/iter; left time: 871.5581s\n",
      "\titers: 400, epoch: 1 | loss: 0.1189653\n",
      "\tspeed: 0.1011s/iter; left time: 860.2244s\n",
      "\titers: 500, epoch: 1 | loss: 0.1124482\n",
      "\tspeed: 0.1009s/iter; left time: 848.9900s\n",
      "\titers: 600, epoch: 1 | loss: 0.1062321\n",
      "\tspeed: 0.1007s/iter; left time: 836.6452s\n",
      "\titers: 700, epoch: 1 | loss: 0.1146088\n",
      "\tspeed: 0.1010s/iter; left time: 829.2892s\n",
      "\titers: 800, epoch: 1 | loss: 0.1128326\n",
      "\tspeed: 0.1011s/iter; left time: 819.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.35s\n",
      "Steps: 891 | Train Loss: 0.1219497 Vali Loss: 0.1236036 Test Loss: 0.1302091\n",
      "Validation loss decreased (inf --> 0.123604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0954148\n",
      "\tspeed: 0.3514s/iter; left time: 2782.7110s\n",
      "\titers: 200, epoch: 2 | loss: 0.1080692\n",
      "\tspeed: 0.1009s/iter; left time: 789.1977s\n",
      "\titers: 300, epoch: 2 | loss: 0.1013039\n",
      "\tspeed: 0.1012s/iter; left time: 781.4993s\n",
      "\titers: 400, epoch: 2 | loss: 0.1107389\n",
      "\tspeed: 0.1012s/iter; left time: 770.9092s\n",
      "\titers: 500, epoch: 2 | loss: 0.0930151\n",
      "\tspeed: 0.1013s/iter; left time: 762.0155s\n",
      "\titers: 600, epoch: 2 | loss: 0.1011813\n",
      "\tspeed: 0.1013s/iter; left time: 751.6201s\n",
      "\titers: 700, epoch: 2 | loss: 0.0994270\n",
      "\tspeed: 0.1012s/iter; left time: 740.5910s\n",
      "\titers: 800, epoch: 2 | loss: 0.0998952\n",
      "\tspeed: 0.1010s/iter; left time: 729.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.37s\n",
      "Steps: 891 | Train Loss: 0.1026212 Vali Loss: 0.1219946 Test Loss: 0.1311745\n",
      "Validation loss decreased (0.123604 --> 0.121995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982830\n",
      "\tspeed: 0.3651s/iter; left time: 2566.3515s\n",
      "\titers: 200, epoch: 3 | loss: 0.0905217\n",
      "\tspeed: 0.1010s/iter; left time: 699.6211s\n",
      "\titers: 300, epoch: 3 | loss: 0.0933340\n",
      "\tspeed: 0.1010s/iter; left time: 689.6966s\n",
      "\titers: 400, epoch: 3 | loss: 0.0878250\n",
      "\tspeed: 0.1009s/iter; left time: 679.0693s\n",
      "\titers: 500, epoch: 3 | loss: 0.0864820\n",
      "\tspeed: 0.1009s/iter; left time: 668.6691s\n",
      "\titers: 600, epoch: 3 | loss: 0.0918261\n",
      "\tspeed: 0.1015s/iter; left time: 662.5603s\n",
      "\titers: 700, epoch: 3 | loss: 0.0864400\n",
      "\tspeed: 0.1012s/iter; left time: 650.4054s\n",
      "\titers: 800, epoch: 3 | loss: 0.0793763\n",
      "\tspeed: 0.1013s/iter; left time: 641.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.01s\n",
      "Steps: 891 | Train Loss: 0.0910344 Vali Loss: 0.1277552 Test Loss: 0.1379314\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0916627\n",
      "\tspeed: 0.3465s/iter; left time: 2126.9383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764010\n",
      "\tspeed: 0.1011s/iter; left time: 610.5616s\n",
      "\titers: 300, epoch: 4 | loss: 0.0781498\n",
      "\tspeed: 0.1010s/iter; left time: 599.7202s\n",
      "\titers: 400, epoch: 4 | loss: 0.0778020\n",
      "\tspeed: 0.1013s/iter; left time: 591.3492s\n",
      "\titers: 500, epoch: 4 | loss: 0.0804866\n",
      "\tspeed: 0.1012s/iter; left time: 580.4250s\n",
      "\titers: 600, epoch: 4 | loss: 0.0854915\n",
      "\tspeed: 0.1012s/iter; left time: 570.3699s\n",
      "\titers: 700, epoch: 4 | loss: 0.0639883\n",
      "\tspeed: 0.1010s/iter; left time: 559.5035s\n",
      "\titers: 800, epoch: 4 | loss: 0.0762494\n",
      "\tspeed: 0.1015s/iter; left time: 551.8783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.37s\n",
      "Steps: 891 | Train Loss: 0.0792461 Vali Loss: 0.1298763 Test Loss: 0.1405116\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723844\n",
      "\tspeed: 0.3471s/iter; left time: 1821.0910s\n",
      "\titers: 200, epoch: 5 | loss: 0.0667428\n",
      "\tspeed: 0.1016s/iter; left time: 522.8907s\n",
      "\titers: 300, epoch: 5 | loss: 0.0708914\n",
      "\tspeed: 0.1013s/iter; left time: 511.0267s\n",
      "\titers: 400, epoch: 5 | loss: 0.0711935\n",
      "\tspeed: 0.1012s/iter; left time: 500.8340s\n",
      "\titers: 500, epoch: 5 | loss: 0.0622643\n",
      "\tspeed: 0.1006s/iter; left time: 487.3814s\n",
      "\titers: 600, epoch: 5 | loss: 0.0661490\n",
      "\tspeed: 0.1009s/iter; left time: 478.8371s\n",
      "\titers: 700, epoch: 5 | loss: 0.0686211\n",
      "\tspeed: 0.1014s/iter; left time: 471.0352s\n",
      "\titers: 800, epoch: 5 | loss: 0.0581368\n",
      "\tspeed: 0.1011s/iter; left time: 459.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.41s\n",
      "Steps: 891 | Train Loss: 0.0675893 Vali Loss: 0.1329272 Test Loss: 0.1432505\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03792143985629082, rmse:0.19473427534103394, mae:0.13117457926273346, rse:0.6895934343338013\n",
      "Original data scale mse:32594430.0, rmse:5709.1533203125, mae:3625.574951171875, rse:0.28431788086891174\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1420826\n",
      "\tspeed: 0.1247s/iter; left time: 1096.6263s\n",
      "\titers: 200, epoch: 1 | loss: 0.1324039\n",
      "\tspeed: 0.1017s/iter; left time: 883.8677s\n",
      "\titers: 300, epoch: 1 | loss: 0.1096003\n",
      "\tspeed: 0.1023s/iter; left time: 878.4533s\n",
      "\titers: 400, epoch: 1 | loss: 0.1229929\n",
      "\tspeed: 0.1021s/iter; left time: 866.7550s\n",
      "\titers: 500, epoch: 1 | loss: 0.1271168\n",
      "\tspeed: 0.1020s/iter; left time: 856.3001s\n",
      "\titers: 600, epoch: 1 | loss: 0.1133723\n",
      "\tspeed: 0.1020s/iter; left time: 845.4108s\n",
      "\titers: 700, epoch: 1 | loss: 0.1140171\n",
      "\tspeed: 0.1019s/iter; left time: 834.9291s\n",
      "\titers: 800, epoch: 1 | loss: 0.1113313\n",
      "\tspeed: 0.1025s/iter; left time: 829.0681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.28s\n",
      "Steps: 889 | Train Loss: 0.1258706 Vali Loss: 0.1271601 Test Loss: 0.1351263\n",
      "Validation loss decreased (inf --> 0.127160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1080882\n",
      "\tspeed: 0.3502s/iter; left time: 2767.1614s\n",
      "\titers: 200, epoch: 2 | loss: 0.1185483\n",
      "\tspeed: 0.1022s/iter; left time: 797.3528s\n",
      "\titers: 300, epoch: 2 | loss: 0.0983756\n",
      "\tspeed: 0.1027s/iter; left time: 791.2847s\n",
      "\titers: 400, epoch: 2 | loss: 0.1100124\n",
      "\tspeed: 0.1022s/iter; left time: 777.0636s\n",
      "\titers: 500, epoch: 2 | loss: 0.1042793\n",
      "\tspeed: 0.1024s/iter; left time: 768.1068s\n",
      "\titers: 600, epoch: 2 | loss: 0.1023884\n",
      "\tspeed: 0.1024s/iter; left time: 758.2550s\n",
      "\titers: 700, epoch: 2 | loss: 0.1155412\n",
      "\tspeed: 0.1021s/iter; left time: 745.7282s\n",
      "\titers: 800, epoch: 2 | loss: 0.1057258\n",
      "\tspeed: 0.1025s/iter; left time: 737.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.20s\n",
      "Steps: 889 | Train Loss: 0.1067853 Vali Loss: 0.1289725 Test Loss: 0.1388414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0973514\n",
      "\tspeed: 0.3459s/iter; left time: 2425.8738s\n",
      "\titers: 200, epoch: 3 | loss: 0.0998890\n",
      "\tspeed: 0.1022s/iter; left time: 706.6320s\n",
      "\titers: 300, epoch: 3 | loss: 0.0904271\n",
      "\tspeed: 0.1021s/iter; left time: 695.3222s\n",
      "\titers: 400, epoch: 3 | loss: 0.0993887\n",
      "\tspeed: 0.1019s/iter; left time: 684.0502s\n",
      "\titers: 500, epoch: 3 | loss: 0.1013474\n",
      "\tspeed: 0.1022s/iter; left time: 676.1492s\n",
      "\titers: 600, epoch: 3 | loss: 0.0884258\n",
      "\tspeed: 0.1018s/iter; left time: 662.7874s\n",
      "\titers: 700, epoch: 3 | loss: 0.0851810\n",
      "\tspeed: 0.1022s/iter; left time: 655.6970s\n",
      "\titers: 800, epoch: 3 | loss: 0.0799662\n",
      "\tspeed: 0.1025s/iter; left time: 647.0694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.02s\n",
      "Steps: 889 | Train Loss: 0.0909680 Vali Loss: 0.1346084 Test Loss: 0.1435879\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866258\n",
      "\tspeed: 0.3431s/iter; left time: 2101.2693s\n",
      "\titers: 200, epoch: 4 | loss: 0.0821673\n",
      "\tspeed: 0.1112s/iter; left time: 669.5971s\n",
      "\titers: 300, epoch: 4 | loss: 0.0764502\n",
      "\tspeed: 0.1021s/iter; left time: 604.8802s\n",
      "\titers: 400, epoch: 4 | loss: 0.0754020\n",
      "\tspeed: 0.1023s/iter; left time: 595.7975s\n",
      "\titers: 500, epoch: 4 | loss: 0.0737909\n",
      "\tspeed: 0.1019s/iter; left time: 583.5585s\n",
      "\titers: 600, epoch: 4 | loss: 0.0730855\n",
      "\tspeed: 0.1023s/iter; left time: 575.5395s\n",
      "\titers: 700, epoch: 4 | loss: 0.0720085\n",
      "\tspeed: 0.1024s/iter; left time: 565.9274s\n",
      "\titers: 800, epoch: 4 | loss: 0.0658216\n",
      "\tspeed: 0.1022s/iter; left time: 554.3572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:31.90s\n",
      "Steps: 889 | Train Loss: 0.0757893 Vali Loss: 0.1391399 Test Loss: 0.1467695\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038899242877960205, rmse:0.19722890853881836, mae:0.1351262629032135, rse:0.6987226605415344\n",
      "Original data scale mse:34130992.0, rmse:5842.17333984375, mae:3749.273681640625, rse:0.2910851538181305\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1366846\n",
      "\tspeed: 0.1045s/iter; left time: 918.4551s\n",
      "\titers: 200, epoch: 1 | loss: 0.1474006\n",
      "\tspeed: 0.1021s/iter; left time: 887.5733s\n",
      "\titers: 300, epoch: 1 | loss: 0.1311585\n",
      "\tspeed: 0.1023s/iter; left time: 879.0721s\n",
      "\titers: 400, epoch: 1 | loss: 0.1313006\n",
      "\tspeed: 0.1025s/iter; left time: 870.1071s\n",
      "\titers: 500, epoch: 1 | loss: 0.1123293\n",
      "\tspeed: 0.1026s/iter; left time: 860.8583s\n",
      "\titers: 600, epoch: 1 | loss: 0.1125556\n",
      "\tspeed: 0.1024s/iter; left time: 848.6703s\n",
      "\titers: 700, epoch: 1 | loss: 0.1196498\n",
      "\tspeed: 0.1027s/iter; left time: 840.8113s\n",
      "\titers: 800, epoch: 1 | loss: 0.1095642\n",
      "\tspeed: 0.1021s/iter; left time: 826.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.28s\n",
      "Steps: 889 | Train Loss: 0.1259274 Vali Loss: 0.1271536 Test Loss: 0.1352856\n",
      "Validation loss decreased (inf --> 0.127154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1204928\n",
      "\tspeed: 0.3517s/iter; left time: 2779.2767s\n",
      "\titers: 200, epoch: 2 | loss: 0.1066924\n",
      "\tspeed: 0.1074s/iter; left time: 838.0889s\n",
      "\titers: 300, epoch: 2 | loss: 0.1118856\n",
      "\tspeed: 0.1028s/iter; left time: 791.5940s\n",
      "\titers: 400, epoch: 2 | loss: 0.1024003\n",
      "\tspeed: 0.1023s/iter; left time: 778.0370s\n",
      "\titers: 500, epoch: 2 | loss: 0.1064344\n",
      "\tspeed: 0.1028s/iter; left time: 771.0071s\n",
      "\titers: 600, epoch: 2 | loss: 0.0996226\n",
      "\tspeed: 0.1030s/iter; left time: 762.7292s\n",
      "\titers: 700, epoch: 2 | loss: 0.1079840\n",
      "\tspeed: 0.1024s/iter; left time: 747.3786s\n",
      "\titers: 800, epoch: 2 | loss: 0.1059086\n",
      "\tspeed: 0.1024s/iter; left time: 737.3258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.91s\n",
      "Steps: 889 | Train Loss: 0.1068079 Vali Loss: 0.1293224 Test Loss: 0.1388070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1038584\n",
      "\tspeed: 0.3491s/iter; left time: 2448.1450s\n",
      "\titers: 200, epoch: 3 | loss: 0.0978088\n",
      "\tspeed: 0.1024s/iter; left time: 707.9138s\n",
      "\titers: 300, epoch: 3 | loss: 0.0943302\n",
      "\tspeed: 0.1026s/iter; left time: 699.3035s\n",
      "\titers: 400, epoch: 3 | loss: 0.0951579\n",
      "\tspeed: 0.1022s/iter; left time: 686.1952s\n",
      "\titers: 500, epoch: 3 | loss: 0.0859426\n",
      "\tspeed: 0.1028s/iter; left time: 679.8288s\n",
      "\titers: 600, epoch: 3 | loss: 0.0896803\n",
      "\tspeed: 0.1024s/iter; left time: 667.1899s\n",
      "\titers: 700, epoch: 3 | loss: 0.0883901\n",
      "\tspeed: 0.1025s/iter; left time: 657.5511s\n",
      "\titers: 800, epoch: 3 | loss: 0.0783906\n",
      "\tspeed: 0.1023s/iter; left time: 645.8123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.35s\n",
      "Steps: 889 | Train Loss: 0.0907625 Vali Loss: 0.1358490 Test Loss: 0.1530101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836557\n",
      "\tspeed: 0.3503s/iter; left time: 2145.2480s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760240\n",
      "\tspeed: 0.1023s/iter; left time: 616.1679s\n",
      "\titers: 300, epoch: 4 | loss: 0.0782461\n",
      "\tspeed: 0.1115s/iter; left time: 660.2458s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769828\n",
      "\tspeed: 0.1026s/iter; left time: 597.5627s\n",
      "\titers: 500, epoch: 4 | loss: 0.0756592\n",
      "\tspeed: 0.1026s/iter; left time: 587.3882s\n",
      "\titers: 600, epoch: 4 | loss: 0.0788848\n",
      "\tspeed: 0.1024s/iter; left time: 575.9136s\n",
      "\titers: 700, epoch: 4 | loss: 0.0665435\n",
      "\tspeed: 0.1021s/iter; left time: 563.9488s\n",
      "\titers: 800, epoch: 4 | loss: 0.0697073\n",
      "\tspeed: 0.1025s/iter; left time: 555.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:32.22s\n",
      "Steps: 889 | Train Loss: 0.0749698 Vali Loss: 0.1356939 Test Loss: 0.1515654\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03914948180317879, rmse:0.19786228239536285, mae:0.13528558611869812, rse:0.700966477394104\n",
      "Original data scale mse:34361140.0, rmse:5861.83740234375, mae:3752.2724609375, rse:0.292064905166626\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\" \\\n",
    "              --decomposition 1 \n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.6777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.5440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.5394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.6764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.1971</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.6984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.5393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.5368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.6942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.6896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.6987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.7010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0238  0.1542  0.0996  0.5445\n",
       "              2         24        0.0227  0.1507  0.0971  0.5323\n",
       "              1         96        0.0368  0.1917  0.1393  0.6789\n",
       "              2         96        0.0366  0.1914  0.1388  0.6777\n",
       "              1         168       0.0390  0.1974  0.1455  0.6994\n",
       "              2         168       0.0391  0.1978  0.1451  0.7008\n",
       "RMSE          1         24        0.0237  0.1540  0.0995  0.5440\n",
       "              2         24        0.0233  0.1527  0.0980  0.5394\n",
       "              1         96        0.0366  0.1913  0.1384  0.6775\n",
       "              2         96        0.0365  0.1910  0.1380  0.6764\n",
       "              1         168       0.0389  0.1971  0.1448  0.6984\n",
       "              2         168       0.0390  0.1975  0.1445  0.6997\n",
       "MAE           1         24        0.0233  0.1527  0.0958  0.5393\n",
       "              2         24        0.0231  0.1520  0.0949  0.5368\n",
       "              1         96        0.0384  0.1960  0.1306  0.6942\n",
       "              2         96        0.0379  0.1947  0.1312  0.6896\n",
       "              1         168       0.0389  0.1972  0.1351  0.6987\n",
       "              2         168       0.0391  0.1979  0.1353  0.7010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_decomposition.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_decomposition.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18796964.0</td>\n",
       "      <td>4335.5464</td>\n",
       "      <td>2721.7759</td>\n",
       "      <td>0.2156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18245456.0</td>\n",
       "      <td>4271.4702</td>\n",
       "      <td>2664.4333</td>\n",
       "      <td>0.2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32576136.0</td>\n",
       "      <td>5707.5508</td>\n",
       "      <td>3937.2654</td>\n",
       "      <td>0.2842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32513784.0</td>\n",
       "      <td>5702.0859</td>\n",
       "      <td>3915.3999</td>\n",
       "      <td>0.2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35581968.0</td>\n",
       "      <td>5965.0625</td>\n",
       "      <td>4137.5913</td>\n",
       "      <td>0.2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35745328.0</td>\n",
       "      <td>5978.7397</td>\n",
       "      <td>4123.7764</td>\n",
       "      <td>0.2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19014310.0</td>\n",
       "      <td>4360.5400</td>\n",
       "      <td>2722.3164</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18353394.0</td>\n",
       "      <td>4284.0859</td>\n",
       "      <td>2661.8276</td>\n",
       "      <td>0.2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32360570.0</td>\n",
       "      <td>5688.6353</td>\n",
       "      <td>3905.5920</td>\n",
       "      <td>0.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32326948.0</td>\n",
       "      <td>5685.6792</td>\n",
       "      <td>3887.6257</td>\n",
       "      <td>0.2831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35409284.0</td>\n",
       "      <td>5950.5698</td>\n",
       "      <td>4112.2773</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35583288.0</td>\n",
       "      <td>5965.1729</td>\n",
       "      <td>4101.0981</td>\n",
       "      <td>0.2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18010934.0</td>\n",
       "      <td>4243.9292</td>\n",
       "      <td>2587.8503</td>\n",
       "      <td>0.2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17940912.0</td>\n",
       "      <td>4235.6714</td>\n",
       "      <td>2567.2988</td>\n",
       "      <td>0.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>33274860.0</td>\n",
       "      <td>5768.4365</td>\n",
       "      <td>3605.2803</td>\n",
       "      <td>0.2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32594430.0</td>\n",
       "      <td>5709.1533</td>\n",
       "      <td>3625.5750</td>\n",
       "      <td>0.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34130992.0</td>\n",
       "      <td>5842.1733</td>\n",
       "      <td>3749.2737</td>\n",
       "      <td>0.2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34361140.0</td>\n",
       "      <td>5861.8374</td>\n",
       "      <td>3752.2725</td>\n",
       "      <td>0.2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18796964.0  4335.5464  2721.7759  0.2156\n",
       "              2         24        18245456.0  4271.4702  2664.4333  0.2124\n",
       "              1         96        32576136.0  5707.5508  3937.2654  0.2842\n",
       "              2         96        32513784.0  5702.0859  3915.3999  0.2840\n",
       "              1         168       35581968.0  5965.0625  4137.5913  0.2972\n",
       "              2         168       35745328.0  5978.7397  4123.7764  0.2979\n",
       "RMSE          1         24        19014310.0  4360.5400  2722.3164  0.2168\n",
       "              2         24        18353394.0  4284.0859  2661.8276  0.2130\n",
       "              1         96        32360570.0  5688.6353  3905.5920  0.2833\n",
       "              2         96        32326948.0  5685.6792  3887.6257  0.2831\n",
       "              1         168       35409284.0  5950.5698  4112.2773  0.2965\n",
       "              2         168       35583288.0  5965.1729  4101.0981  0.2972\n",
       "MAE           1         24        18010934.0  4243.9292  2587.8503  0.2110\n",
       "              2         24        17940912.0  4235.6714  2567.2988  0.2106\n",
       "              1         96        33274860.0  5768.4365  3605.2803  0.2873\n",
       "              2         96        32594430.0  5709.1533  3625.5750  0.2843\n",
       "              1         168       34130992.0  5842.1733  3749.2737  0.2911\n",
       "              2         168       34361140.0  5861.8374  3752.2725  0.2921"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0984</td>\n",
       "      <td>0.5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.5417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.6919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.6783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.6770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.6991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0232  0.1523  0.0953  0.5380\n",
       "         MSE            0.0232  0.1525  0.0984  0.5384\n",
       "         RMSE           0.0235  0.1534  0.0988  0.5417\n",
       "96       MAE            0.0382  0.1954  0.1309  0.6919\n",
       "         MSE            0.0367  0.1915  0.1390  0.6783\n",
       "         RMSE           0.0365  0.1912  0.1382  0.6770\n",
       "168      MAE            0.0390  0.1975  0.1352  0.6998\n",
       "         MSE            0.0391  0.1976  0.1453  0.7001\n",
       "         RMSE           0.0389  0.1973  0.1447  0.6991"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17975923.0</td>\n",
       "      <td>4239.8003</td>\n",
       "      <td>2577.5746</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18521210.0</td>\n",
       "      <td>4303.5083</td>\n",
       "      <td>2693.1046</td>\n",
       "      <td>0.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>18683852.0</td>\n",
       "      <td>4322.3130</td>\n",
       "      <td>2692.0720</td>\n",
       "      <td>0.2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32934645.0</td>\n",
       "      <td>5738.7949</td>\n",
       "      <td>3615.4276</td>\n",
       "      <td>0.2858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>32544960.0</td>\n",
       "      <td>5704.8184</td>\n",
       "      <td>3926.3326</td>\n",
       "      <td>0.2841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32343759.0</td>\n",
       "      <td>5687.1572</td>\n",
       "      <td>3896.6089</td>\n",
       "      <td>0.2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34246066.0</td>\n",
       "      <td>5852.0054</td>\n",
       "      <td>3750.7731</td>\n",
       "      <td>0.2916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>35663648.0</td>\n",
       "      <td>5971.9011</td>\n",
       "      <td>4130.6838</td>\n",
       "      <td>0.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35496286.0</td>\n",
       "      <td>5957.8713</td>\n",
       "      <td>4106.6877</td>\n",
       "      <td>0.2968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17975923.0  4239.8003  2577.5746  0.2108\n",
       "         MSE            18521210.0  4303.5083  2693.1046  0.2140\n",
       "         RMSE           18683852.0  4322.3130  2692.0720  0.2149\n",
       "96       MAE            32934645.0  5738.7949  3615.4276  0.2858\n",
       "         MSE            32544960.0  5704.8184  3926.3326  0.2841\n",
       "         RMSE           32343759.0  5687.1572  3896.6089  0.2832\n",
       "168      MAE            34246066.0  5852.0054  3750.7731  0.2916\n",
       "         MSE            35663648.0  5971.9011  4130.6838  0.2975\n",
       "         RMSE           35496286.0  5957.8713  4106.6877  0.2968"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled_decomposition'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS decomposition and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0991971\n",
      "\tspeed: 0.1232s/iter; left time: 1088.2537s\n",
      "\titers: 200, epoch: 1 | loss: 0.0741107\n",
      "\tspeed: 0.0992s/iter; left time: 866.1752s\n",
      "\titers: 300, epoch: 1 | loss: 0.0675753\n",
      "\tspeed: 0.0992s/iter; left time: 856.1515s\n",
      "\titers: 400, epoch: 1 | loss: 0.0614896\n",
      "\tspeed: 0.0998s/iter; left time: 851.2912s\n",
      "\titers: 500, epoch: 1 | loss: 0.0595473\n",
      "\tspeed: 0.0993s/iter; left time: 837.4080s\n",
      "\titers: 600, epoch: 1 | loss: 0.0464051\n",
      "\tspeed: 0.0997s/iter; left time: 830.3893s\n",
      "\titers: 700, epoch: 1 | loss: 0.0431098\n",
      "\tspeed: 0.0995s/iter; left time: 818.6646s\n",
      "\titers: 800, epoch: 1 | loss: 0.0405632\n",
      "\tspeed: 0.0996s/iter; left time: 809.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.24s\n",
      "Steps: 893 | Train Loss: 0.0641828 Vali Loss: 0.0324184 Test Loss: 0.0364738\n",
      "Validation loss decreased (inf --> 0.032418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0409713\n",
      "\tspeed: 0.3391s/iter; left time: 2691.4256s\n",
      "\titers: 200, epoch: 2 | loss: 0.0244230\n",
      "\tspeed: 0.0994s/iter; left time: 779.2378s\n",
      "\titers: 300, epoch: 2 | loss: 0.0182213\n",
      "\tspeed: 0.0989s/iter; left time: 765.2332s\n",
      "\titers: 400, epoch: 2 | loss: 0.0263414\n",
      "\tspeed: 0.0991s/iter; left time: 756.8663s\n",
      "\titers: 500, epoch: 2 | loss: 0.0190832\n",
      "\tspeed: 0.0989s/iter; left time: 745.6876s\n",
      "\titers: 600, epoch: 2 | loss: 0.0169339\n",
      "\tspeed: 0.0988s/iter; left time: 734.7002s\n",
      "\titers: 700, epoch: 2 | loss: 0.0233993\n",
      "\tspeed: 0.0988s/iter; left time: 724.7659s\n",
      "\titers: 800, epoch: 2 | loss: 0.0244609\n",
      "\tspeed: 0.0990s/iter; left time: 716.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.72s\n",
      "Steps: 893 | Train Loss: 0.0273071 Vali Loss: 0.0282438 Test Loss: 0.0352854\n",
      "Validation loss decreased (0.032418 --> 0.028244).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0208462\n",
      "\tspeed: 0.3391s/iter; left time: 2388.6641s\n",
      "\titers: 200, epoch: 3 | loss: 0.0251642\n",
      "\tspeed: 0.0992s/iter; left time: 689.0600s\n",
      "\titers: 300, epoch: 3 | loss: 0.0168715\n",
      "\tspeed: 0.0988s/iter; left time: 676.3762s\n",
      "\titers: 400, epoch: 3 | loss: 0.0195523\n",
      "\tspeed: 0.0985s/iter; left time: 664.1863s\n",
      "\titers: 500, epoch: 3 | loss: 0.0276113\n",
      "\tspeed: 0.0987s/iter; left time: 656.0853s\n",
      "\titers: 600, epoch: 3 | loss: 0.0183458\n",
      "\tspeed: 0.0985s/iter; left time: 644.5176s\n",
      "\titers: 700, epoch: 3 | loss: 0.0149048\n",
      "\tspeed: 0.0990s/iter; left time: 637.7503s\n",
      "\titers: 800, epoch: 3 | loss: 0.0132381\n",
      "\tspeed: 0.0987s/iter; left time: 626.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:28.44s\n",
      "Steps: 893 | Train Loss: 0.0210292 Vali Loss: 0.0567734 Test Loss: 0.0636093\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0182733\n",
      "\tspeed: 0.3380s/iter; left time: 2079.3403s\n",
      "\titers: 200, epoch: 4 | loss: 0.0390727\n",
      "\tspeed: 0.0992s/iter; left time: 600.3206s\n",
      "\titers: 300, epoch: 4 | loss: 0.0228014\n",
      "\tspeed: 0.0987s/iter; left time: 587.7156s\n",
      "\titers: 400, epoch: 4 | loss: 0.0179545\n",
      "\tspeed: 0.0987s/iter; left time: 577.7187s\n",
      "\titers: 500, epoch: 4 | loss: 0.0237725\n",
      "\tspeed: 0.0989s/iter; left time: 568.8761s\n",
      "\titers: 600, epoch: 4 | loss: 0.0303427\n",
      "\tspeed: 0.0994s/iter; left time: 562.0471s\n",
      "\titers: 700, epoch: 4 | loss: 0.0285375\n",
      "\tspeed: 0.0986s/iter; left time: 547.4569s\n",
      "\titers: 800, epoch: 4 | loss: 0.0221438\n",
      "\tspeed: 0.0990s/iter; left time: 539.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0269816 Vali Loss: 0.0235418 Test Loss: 0.0263330\n",
      "Validation loss decreased (0.028244 --> 0.023542).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0228909\n",
      "\tspeed: 0.3376s/iter; left time: 1775.5873s\n",
      "\titers: 200, epoch: 5 | loss: 0.0121273\n",
      "\tspeed: 0.0989s/iter; left time: 510.2437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0152664\n",
      "\tspeed: 0.0987s/iter; left time: 499.2174s\n",
      "\titers: 400, epoch: 5 | loss: 0.0169893\n",
      "\tspeed: 0.0987s/iter; left time: 489.5137s\n",
      "\titers: 500, epoch: 5 | loss: 0.0138938\n",
      "\tspeed: 0.0989s/iter; left time: 480.6153s\n",
      "\titers: 600, epoch: 5 | loss: 0.0146267\n",
      "\tspeed: 0.0987s/iter; left time: 469.9253s\n",
      "\titers: 700, epoch: 5 | loss: 0.0139640\n",
      "\tspeed: 0.0986s/iter; left time: 459.1889s\n",
      "\titers: 800, epoch: 5 | loss: 0.0171312\n",
      "\tspeed: 0.0987s/iter; left time: 450.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.44s\n",
      "Steps: 893 | Train Loss: 0.0167735 Vali Loss: 0.0217572 Test Loss: 0.0253639\n",
      "Validation loss decreased (0.023542 --> 0.021757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0154043\n",
      "\tspeed: 0.3417s/iter; left time: 1491.6552s\n",
      "\titers: 200, epoch: 6 | loss: 0.0195756\n",
      "\tspeed: 0.0989s/iter; left time: 421.8154s\n",
      "\titers: 300, epoch: 6 | loss: 0.0165294\n",
      "\tspeed: 0.0990s/iter; left time: 412.5265s\n",
      "\titers: 400, epoch: 6 | loss: 0.0115898\n",
      "\tspeed: 0.0990s/iter; left time: 402.4525s\n",
      "\titers: 500, epoch: 6 | loss: 0.0185661\n",
      "\tspeed: 0.1064s/iter; left time: 422.1291s\n",
      "\titers: 600, epoch: 6 | loss: 0.0143534\n",
      "\tspeed: 0.0990s/iter; left time: 382.5830s\n",
      "\titers: 700, epoch: 6 | loss: 0.0176603\n",
      "\tspeed: 0.0988s/iter; left time: 372.1739s\n",
      "\titers: 800, epoch: 6 | loss: 0.0143466\n",
      "\tspeed: 0.0987s/iter; left time: 361.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.33s\n",
      "Steps: 893 | Train Loss: 0.0148907 Vali Loss: 0.0233775 Test Loss: 0.0261718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0106492\n",
      "\tspeed: 0.3372s/iter; left time: 1171.0497s\n",
      "\titers: 200, epoch: 7 | loss: 0.0127228\n",
      "\tspeed: 0.0987s/iter; left time: 332.8432s\n",
      "\titers: 300, epoch: 7 | loss: 0.0159201\n",
      "\tspeed: 0.0988s/iter; left time: 323.3281s\n",
      "\titers: 400, epoch: 7 | loss: 0.0153921\n",
      "\tspeed: 0.0986s/iter; left time: 312.9118s\n",
      "\titers: 500, epoch: 7 | loss: 0.0138969\n",
      "\tspeed: 0.0985s/iter; left time: 302.6616s\n",
      "\titers: 600, epoch: 7 | loss: 0.0112189\n",
      "\tspeed: 0.0990s/iter; left time: 294.2369s\n",
      "\titers: 700, epoch: 7 | loss: 0.0140749\n",
      "\tspeed: 0.0987s/iter; left time: 283.5610s\n",
      "\titers: 800, epoch: 7 | loss: 0.0143148\n",
      "\tspeed: 0.0990s/iter; left time: 274.6144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.41s\n",
      "Steps: 893 | Train Loss: 0.0138667 Vali Loss: 0.0223567 Test Loss: 0.0261245\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132616\n",
      "\tspeed: 0.3412s/iter; left time: 880.3078s\n",
      "\titers: 200, epoch: 8 | loss: 0.0150986\n",
      "\tspeed: 0.0987s/iter; left time: 244.6727s\n",
      "\titers: 300, epoch: 8 | loss: 0.0161552\n",
      "\tspeed: 0.0991s/iter; left time: 235.8689s\n",
      "\titers: 400, epoch: 8 | loss: 0.0097937\n",
      "\tspeed: 0.0990s/iter; left time: 225.7837s\n",
      "\titers: 500, epoch: 8 | loss: 0.0135325\n",
      "\tspeed: 0.0992s/iter; left time: 216.3466s\n",
      "\titers: 600, epoch: 8 | loss: 0.0121509\n",
      "\tspeed: 0.0985s/iter; left time: 204.7879s\n",
      "\titers: 700, epoch: 8 | loss: 0.0129308\n",
      "\tspeed: 0.0986s/iter; left time: 195.3016s\n",
      "\titers: 800, epoch: 8 | loss: 0.0126028\n",
      "\tspeed: 0.0988s/iter; left time: 185.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.48s\n",
      "Steps: 893 | Train Loss: 0.0130401 Vali Loss: 0.0220442 Test Loss: 0.0258507\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025363877415657043, rmse:0.15926040709018707, mae:0.10556025803089142, rse:0.5624324083328247\n",
      "Original data scale mse:19506484.0, rmse:4416.61474609375, mae:2876.10693359375, rse:0.21960297226905823\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0816898\n",
      "\tspeed: 0.1018s/iter; left time: 898.7222s\n",
      "\titers: 200, epoch: 1 | loss: 0.0993700\n",
      "\tspeed: 0.0997s/iter; left time: 870.0600s\n",
      "\titers: 300, epoch: 1 | loss: 0.0709737\n",
      "\tspeed: 0.1000s/iter; left time: 863.1573s\n",
      "\titers: 400, epoch: 1 | loss: 0.0689276\n",
      "\tspeed: 0.0996s/iter; left time: 849.8509s\n",
      "\titers: 500, epoch: 1 | loss: 0.0472147\n",
      "\tspeed: 0.1000s/iter; left time: 843.4557s\n",
      "\titers: 600, epoch: 1 | loss: 0.0459359\n",
      "\tspeed: 0.0998s/iter; left time: 831.1309s\n",
      "\titers: 700, epoch: 1 | loss: 0.0502915\n",
      "\tspeed: 0.0996s/iter; left time: 820.1017s\n",
      "\titers: 800, epoch: 1 | loss: 0.0386579\n",
      "\tspeed: 0.0997s/iter; left time: 810.8163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.31s\n",
      "Steps: 893 | Train Loss: 0.0652689 Vali Loss: 0.0320216 Test Loss: 0.0357591\n",
      "Validation loss decreased (inf --> 0.032022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0361739\n",
      "\tspeed: 0.3429s/iter; left time: 2721.9689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0185374\n",
      "\tspeed: 0.0998s/iter; left time: 782.0442s\n",
      "\titers: 300, epoch: 2 | loss: 0.0205634\n",
      "\tspeed: 0.0989s/iter; left time: 765.0844s\n",
      "\titers: 400, epoch: 2 | loss: 0.0236795\n",
      "\tspeed: 0.0989s/iter; left time: 755.4102s\n",
      "\titers: 500, epoch: 2 | loss: 0.0187417\n",
      "\tspeed: 0.0990s/iter; left time: 746.1457s\n",
      "\titers: 600, epoch: 2 | loss: 0.0264386\n",
      "\tspeed: 0.0989s/iter; left time: 735.2870s\n",
      "\titers: 700, epoch: 2 | loss: 0.0177155\n",
      "\tspeed: 0.0991s/iter; left time: 727.3778s\n",
      "\titers: 800, epoch: 2 | loss: 0.0207544\n",
      "\tspeed: 0.0987s/iter; left time: 714.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.76s\n",
      "Steps: 893 | Train Loss: 0.0262969 Vali Loss: 0.0236909 Test Loss: 0.0266878\n",
      "Validation loss decreased (0.032022 --> 0.023691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0213916\n",
      "\tspeed: 0.3417s/iter; left time: 2407.2652s\n",
      "\titers: 200, epoch: 3 | loss: 0.0176026\n",
      "\tspeed: 0.0993s/iter; left time: 689.6146s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205289\n",
      "\tspeed: 0.0991s/iter; left time: 678.4060s\n",
      "\titers: 400, epoch: 3 | loss: 0.0186071\n",
      "\tspeed: 0.0992s/iter; left time: 668.8606s\n",
      "\titers: 500, epoch: 3 | loss: 0.0175084\n",
      "\tspeed: 0.0989s/iter; left time: 657.2625s\n",
      "\titers: 600, epoch: 3 | loss: 0.0220864\n",
      "\tspeed: 0.0993s/iter; left time: 650.0273s\n",
      "\titers: 700, epoch: 3 | loss: 0.0126424\n",
      "\tspeed: 0.0991s/iter; left time: 638.7610s\n",
      "\titers: 800, epoch: 3 | loss: 0.0137571\n",
      "\tspeed: 0.0989s/iter; left time: 627.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:28.71s\n",
      "Steps: 893 | Train Loss: 0.0197884 Vali Loss: 0.0491734 Test Loss: 0.0521580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0249354\n",
      "\tspeed: 0.3404s/iter; left time: 2093.9822s\n",
      "\titers: 200, epoch: 4 | loss: 0.0338022\n",
      "\tspeed: 0.0985s/iter; left time: 596.2228s\n",
      "\titers: 300, epoch: 4 | loss: 0.0216207\n",
      "\tspeed: 0.0990s/iter; left time: 589.0793s\n",
      "\titers: 400, epoch: 4 | loss: 0.0161910\n",
      "\tspeed: 0.0990s/iter; left time: 579.0951s\n",
      "\titers: 500, epoch: 4 | loss: 0.0205072\n",
      "\tspeed: 0.0987s/iter; left time: 567.9535s\n",
      "\titers: 600, epoch: 4 | loss: 0.0409236\n",
      "\tspeed: 0.0992s/iter; left time: 560.4293s\n",
      "\titers: 700, epoch: 4 | loss: 0.0332770\n",
      "\tspeed: 0.0988s/iter; left time: 548.2828s\n",
      "\titers: 800, epoch: 4 | loss: 0.0202874\n",
      "\tspeed: 0.0985s/iter; left time: 536.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.58s\n",
      "Steps: 893 | Train Loss: 0.0289599 Vali Loss: 0.0273894 Test Loss: 0.0301515\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0246340\n",
      "\tspeed: 0.3387s/iter; left time: 1780.9640s\n",
      "\titers: 200, epoch: 5 | loss: 0.0261954\n",
      "\tspeed: 0.0990s/iter; left time: 510.6317s\n",
      "\titers: 300, epoch: 5 | loss: 0.0293262\n",
      "\tspeed: 0.0987s/iter; left time: 499.1658s\n",
      "\titers: 400, epoch: 5 | loss: 0.0266030\n",
      "\tspeed: 0.0989s/iter; left time: 490.5948s\n",
      "\titers: 500, epoch: 5 | loss: 0.0356065\n",
      "\tspeed: 0.0989s/iter; left time: 480.4341s\n",
      "\titers: 600, epoch: 5 | loss: 0.0218241\n",
      "\tspeed: 0.0987s/iter; left time: 469.5253s\n",
      "\titers: 700, epoch: 5 | loss: 0.0242892\n",
      "\tspeed: 0.0985s/iter; left time: 459.0271s\n",
      "\titers: 800, epoch: 5 | loss: 0.0174877\n",
      "\tspeed: 0.0990s/iter; left time: 451.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.45s\n",
      "Steps: 893 | Train Loss: 0.0229118 Vali Loss: 0.0226311 Test Loss: 0.0256347\n",
      "Validation loss decreased (0.023691 --> 0.022631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0171736\n",
      "\tspeed: 0.3418s/iter; left time: 1492.4550s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144758\n",
      "\tspeed: 0.0990s/iter; left time: 422.1877s\n",
      "\titers: 300, epoch: 6 | loss: 0.0147442\n",
      "\tspeed: 0.0989s/iter; left time: 412.1808s\n",
      "\titers: 400, epoch: 6 | loss: 0.0137402\n",
      "\tspeed: 0.0990s/iter; left time: 402.7363s\n",
      "\titers: 500, epoch: 6 | loss: 0.0166622\n",
      "\tspeed: 0.0990s/iter; left time: 392.6789s\n",
      "\titers: 600, epoch: 6 | loss: 0.0175483\n",
      "\tspeed: 0.0991s/iter; left time: 382.9608s\n",
      "\titers: 700, epoch: 6 | loss: 0.0157049\n",
      "\tspeed: 0.0990s/iter; left time: 372.7640s\n",
      "\titers: 800, epoch: 6 | loss: 0.0250909\n",
      "\tspeed: 0.0993s/iter; left time: 364.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:28.65s\n",
      "Steps: 893 | Train Loss: 0.0179470 Vali Loss: 0.0230527 Test Loss: 0.0251401\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0168323\n",
      "\tspeed: 0.3380s/iter; left time: 1173.8232s\n",
      "\titers: 200, epoch: 7 | loss: 0.0155507\n",
      "\tspeed: 0.0989s/iter; left time: 333.5220s\n",
      "\titers: 300, epoch: 7 | loss: 0.0186981\n",
      "\tspeed: 0.0988s/iter; left time: 323.3828s\n",
      "\titers: 400, epoch: 7 | loss: 0.0136928\n",
      "\tspeed: 0.0988s/iter; left time: 313.4731s\n",
      "\titers: 500, epoch: 7 | loss: 0.0189265\n",
      "\tspeed: 0.0989s/iter; left time: 304.0633s\n",
      "\titers: 600, epoch: 7 | loss: 0.0164623\n",
      "\tspeed: 0.0989s/iter; left time: 294.1059s\n",
      "\titers: 700, epoch: 7 | loss: 0.0104731\n",
      "\tspeed: 0.0986s/iter; left time: 283.2650s\n",
      "\titers: 800, epoch: 7 | loss: 0.0174298\n",
      "\tspeed: 0.0989s/iter; left time: 274.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.53s\n",
      "Steps: 893 | Train Loss: 0.0151901 Vali Loss: 0.0214039 Test Loss: 0.0240552\n",
      "Validation loss decreased (0.022631 --> 0.021404).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0155992\n",
      "\tspeed: 0.3441s/iter; left time: 887.8194s\n",
      "\titers: 200, epoch: 8 | loss: 0.0126877\n",
      "\tspeed: 0.0991s/iter; left time: 245.6913s\n",
      "\titers: 300, epoch: 8 | loss: 0.0143699\n",
      "\tspeed: 0.0991s/iter; left time: 235.7413s\n",
      "\titers: 400, epoch: 8 | loss: 0.0141782\n",
      "\tspeed: 0.0990s/iter; left time: 225.7341s\n",
      "\titers: 500, epoch: 8 | loss: 0.0178012\n",
      "\tspeed: 0.0987s/iter; left time: 215.2332s\n",
      "\titers: 600, epoch: 8 | loss: 0.0163778\n",
      "\tspeed: 0.0987s/iter; left time: 205.3026s\n",
      "\titers: 700, epoch: 8 | loss: 0.0130136\n",
      "\tspeed: 0.0993s/iter; left time: 196.6741s\n",
      "\titers: 800, epoch: 8 | loss: 0.0130586\n",
      "\tspeed: 0.0990s/iter; left time: 186.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.71s\n",
      "Steps: 893 | Train Loss: 0.0139354 Vali Loss: 0.0219774 Test Loss: 0.0255025\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0116471\n",
      "\tspeed: 0.3431s/iter; left time: 578.8681s\n",
      "\titers: 200, epoch: 9 | loss: 0.0137673\n",
      "\tspeed: 0.0990s/iter; left time: 157.1128s\n",
      "\titers: 300, epoch: 9 | loss: 0.0152045\n",
      "\tspeed: 0.0989s/iter; left time: 147.0734s\n",
      "\titers: 400, epoch: 9 | loss: 0.0131677\n",
      "\tspeed: 0.0990s/iter; left time: 137.3761s\n",
      "\titers: 500, epoch: 9 | loss: 0.0137396\n",
      "\tspeed: 0.0989s/iter; left time: 127.2702s\n",
      "\titers: 600, epoch: 9 | loss: 0.0133378\n",
      "\tspeed: 0.0988s/iter; left time: 117.2824s\n",
      "\titers: 700, epoch: 9 | loss: 0.0151649\n",
      "\tspeed: 0.0989s/iter; left time: 107.4966s\n",
      "\titers: 800, epoch: 9 | loss: 0.0119743\n",
      "\tspeed: 0.0983s/iter; left time: 97.0442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:29.12s\n",
      "Steps: 893 | Train Loss: 0.0133371 Vali Loss: 0.0221730 Test Loss: 0.0252949\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0124478\n",
      "\tspeed: 0.3437s/iter; left time: 272.9348s\n",
      "\titers: 200, epoch: 10 | loss: 0.0128909\n",
      "\tspeed: 0.0988s/iter; left time: 68.5776s\n",
      "\titers: 300, epoch: 10 | loss: 0.0135512\n",
      "\tspeed: 0.0987s/iter; left time: 58.6006s\n",
      "\titers: 400, epoch: 10 | loss: 0.0130243\n",
      "\tspeed: 0.0993s/iter; left time: 49.0683s\n",
      "\titers: 500, epoch: 10 | loss: 0.0138263\n",
      "\tspeed: 0.0998s/iter; left time: 39.3110s\n",
      "\titers: 600, epoch: 10 | loss: 0.0141517\n",
      "\tspeed: 0.0989s/iter; left time: 29.0870s\n",
      "\titers: 700, epoch: 10 | loss: 0.0150198\n",
      "\tspeed: 0.0989s/iter; left time: 19.1829s\n",
      "\titers: 800, epoch: 10 | loss: 0.0141574\n",
      "\tspeed: 0.0988s/iter; left time: 9.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:28.70s\n",
      "Steps: 893 | Train Loss: 0.0126803 Vali Loss: 0.0228215 Test Loss: 0.0265758\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024055205285549164, rmse:0.15509741008281708, mae:0.10238756239414215, rse:0.5477306842803955\n",
      "Original data scale mse:19008062.0, rmse:4359.82373046875, mae:2790.5966796875, rse:0.2167792171239853\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1057100\n",
      "\tspeed: 0.1238s/iter; left time: 1090.8275s\n",
      "\titers: 200, epoch: 1 | loss: 0.0778599\n",
      "\tspeed: 0.1007s/iter; left time: 877.3276s\n",
      "\titers: 300, epoch: 1 | loss: 0.0780777\n",
      "\tspeed: 0.1009s/iter; left time: 869.2635s\n",
      "\titers: 400, epoch: 1 | loss: 0.0620050\n",
      "\tspeed: 0.1015s/iter; left time: 863.6059s\n",
      "\titers: 500, epoch: 1 | loss: 0.0597906\n",
      "\tspeed: 0.1011s/iter; left time: 850.3843s\n",
      "\titers: 600, epoch: 1 | loss: 0.0467604\n",
      "\tspeed: 0.1007s/iter; left time: 836.8006s\n",
      "\titers: 700, epoch: 1 | loss: 0.0499052\n",
      "\tspeed: 0.1007s/iter; left time: 826.7454s\n",
      "\titers: 800, epoch: 1 | loss: 0.0447024\n",
      "\tspeed: 0.1002s/iter; left time: 813.1127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.29s\n",
      "Steps: 891 | Train Loss: 0.0696075 Vali Loss: 0.0475808 Test Loss: 0.0564717\n",
      "Validation loss decreased (inf --> 0.047581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0353202\n",
      "\tspeed: 0.3445s/iter; left time: 2728.7025s\n",
      "\titers: 200, epoch: 2 | loss: 0.0372869\n",
      "\tspeed: 0.1008s/iter; left time: 788.3336s\n",
      "\titers: 300, epoch: 2 | loss: 0.0335235\n",
      "\tspeed: 0.1011s/iter; left time: 780.3893s\n",
      "\titers: 400, epoch: 2 | loss: 0.0267683\n",
      "\tspeed: 0.1009s/iter; left time: 769.1377s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265715\n",
      "\tspeed: 0.1010s/iter; left time: 759.3809s\n",
      "\titers: 600, epoch: 2 | loss: 0.0299747\n",
      "\tspeed: 0.1008s/iter; left time: 747.7892s\n",
      "\titers: 700, epoch: 2 | loss: 0.0271649\n",
      "\tspeed: 0.1005s/iter; left time: 735.9196s\n",
      "\titers: 800, epoch: 2 | loss: 0.0248243\n",
      "\tspeed: 0.1003s/iter; left time: 724.3486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.05s\n",
      "Steps: 891 | Train Loss: 0.0325911 Vali Loss: 0.0370493 Test Loss: 0.0451677\n",
      "Validation loss decreased (0.047581 --> 0.037049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0257509\n",
      "\tspeed: 0.3443s/iter; left time: 2419.9219s\n",
      "\titers: 200, epoch: 3 | loss: 0.0256515\n",
      "\tspeed: 0.1076s/iter; left time: 745.2657s\n",
      "\titers: 300, epoch: 3 | loss: 0.0368301\n",
      "\tspeed: 0.1002s/iter; left time: 684.2238s\n",
      "\titers: 400, epoch: 3 | loss: 0.0312922\n",
      "\tspeed: 0.1004s/iter; left time: 675.9178s\n",
      "\titers: 500, epoch: 3 | loss: 0.0235352\n",
      "\tspeed: 0.1003s/iter; left time: 664.8261s\n",
      "\titers: 600, epoch: 3 | loss: 0.0274414\n",
      "\tspeed: 0.1004s/iter; left time: 655.6610s\n",
      "\titers: 700, epoch: 3 | loss: 0.0307707\n",
      "\tspeed: 0.1003s/iter; left time: 644.6018s\n",
      "\titers: 800, epoch: 3 | loss: 0.0320354\n",
      "\tspeed: 0.0998s/iter; left time: 631.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.25s\n",
      "Steps: 891 | Train Loss: 0.0293059 Vali Loss: 0.0352834 Test Loss: 0.0420122\n",
      "Validation loss decreased (0.037049 --> 0.035283).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0267536\n",
      "\tspeed: 0.3512s/iter; left time: 2155.4249s\n",
      "\titers: 200, epoch: 4 | loss: 0.0286982\n",
      "\tspeed: 0.1003s/iter; left time: 605.3785s\n",
      "\titers: 300, epoch: 4 | loss: 0.0212118\n",
      "\tspeed: 0.1004s/iter; left time: 596.1785s\n",
      "\titers: 400, epoch: 4 | loss: 0.0251871\n",
      "\tspeed: 0.1007s/iter; left time: 587.8852s\n",
      "\titers: 500, epoch: 4 | loss: 0.0228936\n",
      "\tspeed: 0.1003s/iter; left time: 575.6825s\n",
      "\titers: 600, epoch: 4 | loss: 0.0229943\n",
      "\tspeed: 0.1007s/iter; left time: 567.5503s\n",
      "\titers: 700, epoch: 4 | loss: 0.0185313\n",
      "\tspeed: 0.1003s/iter; left time: 555.2249s\n",
      "\titers: 800, epoch: 4 | loss: 0.0205671\n",
      "\tspeed: 0.1006s/iter; left time: 547.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.76s\n",
      "Steps: 891 | Train Loss: 0.0239127 Vali Loss: 0.0369266 Test Loss: 0.0472747\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0196775\n",
      "\tspeed: 0.3432s/iter; left time: 1800.5505s\n",
      "\titers: 200, epoch: 5 | loss: 0.0183268\n",
      "\tspeed: 0.1005s/iter; left time: 517.5152s\n",
      "\titers: 300, epoch: 5 | loss: 0.0209935\n",
      "\tspeed: 0.1000s/iter; left time: 504.4541s\n",
      "\titers: 400, epoch: 5 | loss: 0.0406535\n",
      "\tspeed: 0.1005s/iter; left time: 497.2064s\n",
      "\titers: 500, epoch: 5 | loss: 0.0255618\n",
      "\tspeed: 0.1005s/iter; left time: 487.0676s\n",
      "\titers: 600, epoch: 5 | loss: 0.0204070\n",
      "\tspeed: 0.1003s/iter; left time: 476.0156s\n",
      "\titers: 700, epoch: 5 | loss: 0.0192793\n",
      "\tspeed: 0.1003s/iter; left time: 466.1966s\n",
      "\titers: 800, epoch: 5 | loss: 0.0192840\n",
      "\tspeed: 0.0998s/iter; left time: 453.7877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.62s\n",
      "Steps: 891 | Train Loss: 0.0212863 Vali Loss: 0.0390813 Test Loss: 0.0481879\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0173657\n",
      "\tspeed: 0.3430s/iter; left time: 1493.9985s\n",
      "\titers: 200, epoch: 6 | loss: 0.0200069\n",
      "\tspeed: 0.1005s/iter; left time: 427.6709s\n",
      "\titers: 300, epoch: 6 | loss: 0.0166087\n",
      "\tspeed: 0.1005s/iter; left time: 417.6497s\n",
      "\titers: 400, epoch: 6 | loss: 0.0184187\n",
      "\tspeed: 0.1003s/iter; left time: 406.6335s\n",
      "\titers: 500, epoch: 6 | loss: 0.0162138\n",
      "\tspeed: 0.1006s/iter; left time: 398.1188s\n",
      "\titers: 600, epoch: 6 | loss: 0.0170810\n",
      "\tspeed: 0.1006s/iter; left time: 387.9552s\n",
      "\titers: 700, epoch: 6 | loss: 0.0178144\n",
      "\tspeed: 0.1004s/iter; left time: 377.2485s\n",
      "\titers: 800, epoch: 6 | loss: 0.0152936\n",
      "\tspeed: 0.1004s/iter; left time: 367.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.75s\n",
      "Steps: 891 | Train Loss: 0.0166825 Vali Loss: 0.0418121 Test Loss: 0.0512790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04201221838593483, rmse:0.20496882498264313, mae:0.143634632229805, rse:0.7258360385894775\n",
      "Original data scale mse:36130940.0, rmse:6010.90185546875, mae:4012.98876953125, rse:0.29934507608413696\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0835247\n",
      "\tspeed: 0.1030s/iter; left time: 907.1800s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925564\n",
      "\tspeed: 0.1011s/iter; left time: 880.5624s\n",
      "\titers: 300, epoch: 1 | loss: 0.0770536\n",
      "\tspeed: 0.1010s/iter; left time: 869.8603s\n",
      "\titers: 400, epoch: 1 | loss: 0.0735145\n",
      "\tspeed: 0.1009s/iter; left time: 858.9532s\n",
      "\titers: 500, epoch: 1 | loss: 0.0540107\n",
      "\tspeed: 0.1010s/iter; left time: 849.4610s\n",
      "\titers: 600, epoch: 1 | loss: 0.0515694\n",
      "\tspeed: 0.1006s/iter; left time: 836.2078s\n",
      "\titers: 700, epoch: 1 | loss: 0.0444639\n",
      "\tspeed: 0.1004s/iter; left time: 824.4184s\n",
      "\titers: 800, epoch: 1 | loss: 0.0447146\n",
      "\tspeed: 0.1009s/iter; left time: 818.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.10s\n",
      "Steps: 891 | Train Loss: 0.0693650 Vali Loss: 0.0424248 Test Loss: 0.0497724\n",
      "Validation loss decreased (inf --> 0.042425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0408475\n",
      "\tspeed: 0.3470s/iter; left time: 2748.5074s\n",
      "\titers: 200, epoch: 2 | loss: 0.0338487\n",
      "\tspeed: 0.1010s/iter; left time: 789.9313s\n",
      "\titers: 300, epoch: 2 | loss: 0.0341225\n",
      "\tspeed: 0.1008s/iter; left time: 778.3315s\n",
      "\titers: 400, epoch: 2 | loss: 0.0267082\n",
      "\tspeed: 0.1010s/iter; left time: 769.4657s\n",
      "\titers: 500, epoch: 2 | loss: 0.0273998\n",
      "\tspeed: 0.1006s/iter; left time: 756.5536s\n",
      "\titers: 600, epoch: 2 | loss: 0.0434994\n",
      "\tspeed: 0.1004s/iter; left time: 744.9439s\n",
      "\titers: 700, epoch: 2 | loss: 0.0246698\n",
      "\tspeed: 0.1010s/iter; left time: 738.9935s\n",
      "\titers: 800, epoch: 2 | loss: 0.0257600\n",
      "\tspeed: 0.1007s/iter; left time: 726.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.05s\n",
      "Steps: 891 | Train Loss: 0.0335720 Vali Loss: 0.0356871 Test Loss: 0.0413986\n",
      "Validation loss decreased (0.042425 --> 0.035687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0303883\n",
      "\tspeed: 0.3485s/iter; left time: 2449.5888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0250801\n",
      "\tspeed: 0.1008s/iter; left time: 698.3592s\n",
      "\titers: 300, epoch: 3 | loss: 0.0300603\n",
      "\tspeed: 0.1005s/iter; left time: 686.4751s\n",
      "\titers: 400, epoch: 3 | loss: 0.0223833\n",
      "\tspeed: 0.1055s/iter; left time: 709.8375s\n",
      "\titers: 500, epoch: 3 | loss: 0.0757810\n",
      "\tspeed: 0.1005s/iter; left time: 666.3322s\n",
      "\titers: 600, epoch: 3 | loss: 0.0295666\n",
      "\tspeed: 0.0998s/iter; left time: 651.8255s\n",
      "\titers: 700, epoch: 3 | loss: 0.0243848\n",
      "\tspeed: 0.1001s/iter; left time: 643.6002s\n",
      "\titers: 800, epoch: 3 | loss: 0.0259367\n",
      "\tspeed: 0.1008s/iter; left time: 637.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.25s\n",
      "Steps: 891 | Train Loss: 0.0280868 Vali Loss: 0.0345037 Test Loss: 0.0425274\n",
      "Validation loss decreased (0.035687 --> 0.034504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0219262\n",
      "\tspeed: 0.3467s/iter; left time: 2128.1742s\n",
      "\titers: 200, epoch: 4 | loss: 0.0273528\n",
      "\tspeed: 0.1006s/iter; left time: 607.3798s\n",
      "\titers: 300, epoch: 4 | loss: 0.0324510\n",
      "\tspeed: 0.1003s/iter; left time: 595.6344s\n",
      "\titers: 400, epoch: 4 | loss: 0.0242999\n",
      "\tspeed: 0.1007s/iter; left time: 587.6933s\n",
      "\titers: 500, epoch: 4 | loss: 0.0204436\n",
      "\tspeed: 0.1006s/iter; left time: 577.1548s\n",
      "\titers: 600, epoch: 4 | loss: 0.0260187\n",
      "\tspeed: 0.1007s/iter; left time: 567.9458s\n",
      "\titers: 700, epoch: 4 | loss: 0.0237379\n",
      "\tspeed: 0.1007s/iter; left time: 557.6725s\n",
      "\titers: 800, epoch: 4 | loss: 0.0208649\n",
      "\tspeed: 0.1001s/iter; left time: 544.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.86s\n",
      "Steps: 891 | Train Loss: 0.0247058 Vali Loss: 0.0367919 Test Loss: 0.0442024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0185023\n",
      "\tspeed: 0.3422s/iter; left time: 1795.3011s\n",
      "\titers: 200, epoch: 5 | loss: 0.0210345\n",
      "\tspeed: 0.1005s/iter; left time: 517.1060s\n",
      "\titers: 300, epoch: 5 | loss: 0.0175444\n",
      "\tspeed: 0.1009s/iter; left time: 509.1914s\n",
      "\titers: 400, epoch: 5 | loss: 0.0178449\n",
      "\tspeed: 0.1004s/iter; left time: 496.7838s\n",
      "\titers: 500, epoch: 5 | loss: 0.0165945\n",
      "\tspeed: 0.1002s/iter; left time: 485.4412s\n",
      "\titers: 600, epoch: 5 | loss: 0.0168794\n",
      "\tspeed: 0.1037s/iter; left time: 492.1118s\n",
      "\titers: 700, epoch: 5 | loss: 0.0162599\n",
      "\tspeed: 0.1000s/iter; left time: 464.8399s\n",
      "\titers: 800, epoch: 5 | loss: 0.0166127\n",
      "\tspeed: 0.1006s/iter; left time: 457.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.05s\n",
      "Steps: 891 | Train Loss: 0.0193061 Vali Loss: 0.0371815 Test Loss: 0.0439121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0200551\n",
      "\tspeed: 0.3453s/iter; left time: 1503.9867s\n",
      "\titers: 200, epoch: 6 | loss: 0.0167350\n",
      "\tspeed: 0.1004s/iter; left time: 427.5075s\n",
      "\titers: 300, epoch: 6 | loss: 0.0167904\n",
      "\tspeed: 0.1003s/iter; left time: 416.9365s\n",
      "\titers: 400, epoch: 6 | loss: 0.0205772\n",
      "\tspeed: 0.1009s/iter; left time: 409.2011s\n",
      "\titers: 500, epoch: 6 | loss: 0.0171112\n",
      "\tspeed: 0.1005s/iter; left time: 397.5391s\n",
      "\titers: 600, epoch: 6 | loss: 0.0176704\n",
      "\tspeed: 0.1005s/iter; left time: 387.3746s\n",
      "\titers: 700, epoch: 6 | loss: 0.0172682\n",
      "\tspeed: 0.1003s/iter; left time: 376.8432s\n",
      "\titers: 800, epoch: 6 | loss: 0.0181905\n",
      "\tspeed: 0.1006s/iter; left time: 367.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.84s\n",
      "Steps: 891 | Train Loss: 0.0167392 Vali Loss: 0.0422238 Test Loss: 0.0514628\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04252741485834122, rmse:0.20622175931930542, mae:0.14252053201198578, rse:0.7302729487419128\n",
      "Original data scale mse:36122992.0, rmse:6010.24072265625, mae:3954.746826171875, rse:0.29931214451789856\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0947882\n",
      "\tspeed: 0.1244s/iter; left time: 1093.7589s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887581\n",
      "\tspeed: 0.1014s/iter; left time: 881.3874s\n",
      "\titers: 300, epoch: 1 | loss: 0.0601465\n",
      "\tspeed: 0.1018s/iter; left time: 874.6151s\n",
      "\titers: 400, epoch: 1 | loss: 0.0625624\n",
      "\tspeed: 0.1015s/iter; left time: 861.9572s\n",
      "\titers: 500, epoch: 1 | loss: 0.0605082\n",
      "\tspeed: 0.1039s/iter; left time: 871.7854s\n",
      "\titers: 600, epoch: 1 | loss: 0.0524227\n",
      "\tspeed: 0.1049s/iter; left time: 870.0041s\n",
      "\titers: 700, epoch: 1 | loss: 0.0513396\n",
      "\tspeed: 0.1019s/iter; left time: 834.7878s\n",
      "\titers: 800, epoch: 1 | loss: 0.0469411\n",
      "\tspeed: 0.1019s/iter; left time: 824.1001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.42s\n",
      "Steps: 889 | Train Loss: 0.0693988 Vali Loss: 0.0474673 Test Loss: 0.0565924\n",
      "Validation loss decreased (inf --> 0.047467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0380023\n",
      "\tspeed: 0.3466s/iter; left time: 2738.4717s\n",
      "\titers: 200, epoch: 2 | loss: 0.0447465\n",
      "\tspeed: 0.1017s/iter; left time: 793.1815s\n",
      "\titers: 300, epoch: 2 | loss: 0.0287378\n",
      "\tspeed: 0.1017s/iter; left time: 783.0946s\n",
      "\titers: 400, epoch: 2 | loss: 0.0332961\n",
      "\tspeed: 0.1019s/iter; left time: 774.7487s\n",
      "\titers: 500, epoch: 2 | loss: 0.0275244\n",
      "\tspeed: 0.1015s/iter; left time: 761.6640s\n",
      "\titers: 600, epoch: 2 | loss: 0.0282260\n",
      "\tspeed: 0.1016s/iter; left time: 752.3618s\n",
      "\titers: 700, epoch: 2 | loss: 0.0322559\n",
      "\tspeed: 0.1014s/iter; left time: 740.1029s\n",
      "\titers: 800, epoch: 2 | loss: 0.0300881\n",
      "\tspeed: 0.1015s/iter; left time: 731.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.56s\n",
      "Steps: 889 | Train Loss: 0.0350339 Vali Loss: 0.0376624 Test Loss: 0.0449137\n",
      "Validation loss decreased (0.047467 --> 0.037662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0313799\n",
      "\tspeed: 0.3494s/iter; left time: 2450.2092s\n",
      "\titers: 200, epoch: 3 | loss: 0.0288663\n",
      "\tspeed: 0.1015s/iter; left time: 701.8939s\n",
      "\titers: 300, epoch: 3 | loss: 0.0251867\n",
      "\tspeed: 0.1014s/iter; left time: 690.9455s\n",
      "\titers: 400, epoch: 3 | loss: 0.0312164\n",
      "\tspeed: 0.1011s/iter; left time: 678.8394s\n",
      "\titers: 500, epoch: 3 | loss: 0.0351483\n",
      "\tspeed: 0.1016s/iter; left time: 671.5753s\n",
      "\titers: 600, epoch: 3 | loss: 0.0358052\n",
      "\tspeed: 0.1017s/iter; left time: 662.5501s\n",
      "\titers: 700, epoch: 3 | loss: 0.0324881\n",
      "\tspeed: 0.1086s/iter; left time: 696.7182s\n",
      "\titers: 800, epoch: 3 | loss: 0.0314974\n",
      "\tspeed: 0.1018s/iter; left time: 642.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.17s\n",
      "Steps: 889 | Train Loss: 0.0301937 Vali Loss: 0.0385852 Test Loss: 0.0479914\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0290097\n",
      "\tspeed: 0.3444s/iter; left time: 2109.0329s\n",
      "\titers: 200, epoch: 4 | loss: 0.0252325\n",
      "\tspeed: 0.1018s/iter; left time: 613.0806s\n",
      "\titers: 300, epoch: 4 | loss: 0.0234091\n",
      "\tspeed: 0.1016s/iter; left time: 601.8440s\n",
      "\titers: 400, epoch: 4 | loss: 0.0225765\n",
      "\tspeed: 0.1015s/iter; left time: 591.3867s\n",
      "\titers: 500, epoch: 4 | loss: 0.0230059\n",
      "\tspeed: 0.1016s/iter; left time: 581.6192s\n",
      "\titers: 600, epoch: 4 | loss: 0.0214383\n",
      "\tspeed: 0.1012s/iter; left time: 569.1626s\n",
      "\titers: 700, epoch: 4 | loss: 0.0216720\n",
      "\tspeed: 0.1009s/iter; left time: 557.4635s\n",
      "\titers: 800, epoch: 4 | loss: 0.0220983\n",
      "\tspeed: 0.1015s/iter; left time: 550.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.38s\n",
      "Steps: 889 | Train Loss: 0.0233427 Vali Loss: 0.0443860 Test Loss: 0.0582714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0185117\n",
      "\tspeed: 0.3426s/iter; left time: 1793.7440s\n",
      "\titers: 200, epoch: 5 | loss: 0.0181859\n",
      "\tspeed: 0.1016s/iter; left time: 521.5284s\n",
      "\titers: 300, epoch: 5 | loss: 0.0212371\n",
      "\tspeed: 0.1016s/iter; left time: 511.4542s\n",
      "\titers: 400, epoch: 5 | loss: 0.0189111\n",
      "\tspeed: 0.1007s/iter; left time: 496.7585s\n",
      "\titers: 500, epoch: 5 | loss: 0.0170250\n",
      "\tspeed: 0.1014s/iter; left time: 490.0502s\n",
      "\titers: 600, epoch: 5 | loss: 0.0155229\n",
      "\tspeed: 0.1013s/iter; left time: 479.5495s\n",
      "\titers: 700, epoch: 5 | loss: 0.0200166\n",
      "\tspeed: 0.1013s/iter; left time: 469.3029s\n",
      "\titers: 800, epoch: 5 | loss: 0.0201345\n",
      "\tspeed: 0.1071s/iter; left time: 485.7576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.89s\n",
      "Steps: 889 | Train Loss: 0.0188186 Vali Loss: 0.0471067 Test Loss: 0.0605238\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04491367191076279, rmse:0.21192845702171326, mae:0.14999113976955414, rse:0.7507987022399902\n",
      "Original data scale mse:39282812.0, rmse:6267.60009765625, mae:4202.294921875, rse:0.3122819662094116\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1045424\n",
      "\tspeed: 0.1039s/iter; left time: 913.4358s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887825\n",
      "\tspeed: 0.1016s/iter; left time: 883.2106s\n",
      "\titers: 300, epoch: 1 | loss: 0.0790596\n",
      "\tspeed: 0.1019s/iter; left time: 875.0479s\n",
      "\titers: 400, epoch: 1 | loss: 0.0649724\n",
      "\tspeed: 0.1017s/iter; left time: 863.7433s\n",
      "\titers: 500, epoch: 1 | loss: 0.0590219\n",
      "\tspeed: 0.1019s/iter; left time: 854.6570s\n",
      "\titers: 600, epoch: 1 | loss: 0.0519615\n",
      "\tspeed: 0.1020s/iter; left time: 845.3882s\n",
      "\titers: 700, epoch: 1 | loss: 0.0535588\n",
      "\tspeed: 0.1019s/iter; left time: 834.5396s\n",
      "\titers: 800, epoch: 1 | loss: 0.0493650\n",
      "\tspeed: 0.1019s/iter; left time: 824.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.80s\n",
      "Steps: 889 | Train Loss: 0.0707902 Vali Loss: 0.0446584 Test Loss: 0.0524972\n",
      "Validation loss decreased (inf --> 0.044658).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0471433\n",
      "\tspeed: 0.3493s/iter; left time: 2760.1815s\n",
      "\titers: 200, epoch: 2 | loss: 0.0347378\n",
      "\tspeed: 0.1016s/iter; left time: 792.9861s\n",
      "\titers: 300, epoch: 2 | loss: 0.0339422\n",
      "\tspeed: 0.1013s/iter; left time: 780.3609s\n",
      "\titers: 400, epoch: 2 | loss: 0.0312041\n",
      "\tspeed: 0.1019s/iter; left time: 774.2851s\n",
      "\titers: 500, epoch: 2 | loss: 0.0245469\n",
      "\tspeed: 0.1018s/iter; left time: 763.7175s\n",
      "\titers: 600, epoch: 2 | loss: 0.0357782\n",
      "\tspeed: 0.1017s/iter; left time: 752.5518s\n",
      "\titers: 700, epoch: 2 | loss: 0.0270601\n",
      "\tspeed: 0.1017s/iter; left time: 742.9203s\n",
      "\titers: 800, epoch: 2 | loss: 0.0263664\n",
      "\tspeed: 0.1090s/iter; left time: 785.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:31.47s\n",
      "Steps: 889 | Train Loss: 0.0343300 Vali Loss: 0.0390042 Test Loss: 0.0488479\n",
      "Validation loss decreased (0.044658 --> 0.039004).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0348750\n",
      "\tspeed: 0.3523s/iter; left time: 2470.6571s\n",
      "\titers: 200, epoch: 3 | loss: 0.0277884\n",
      "\tspeed: 0.1019s/iter; left time: 704.4757s\n",
      "\titers: 300, epoch: 3 | loss: 0.0325305\n",
      "\tspeed: 0.1016s/iter; left time: 692.0192s\n",
      "\titers: 400, epoch: 3 | loss: 0.0350216\n",
      "\tspeed: 0.1019s/iter; left time: 684.1209s\n",
      "\titers: 500, epoch: 3 | loss: 0.0257085\n",
      "\tspeed: 0.1015s/iter; left time: 671.5170s\n",
      "\titers: 600, epoch: 3 | loss: 0.0289112\n",
      "\tspeed: 0.1015s/iter; left time: 660.8709s\n",
      "\titers: 700, epoch: 3 | loss: 0.0255862\n",
      "\tspeed: 0.1015s/iter; left time: 650.6594s\n",
      "\titers: 800, epoch: 3 | loss: 0.0224415\n",
      "\tspeed: 0.1017s/iter; left time: 642.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.64s\n",
      "Steps: 889 | Train Loss: 0.0283569 Vali Loss: 0.0413208 Test Loss: 0.0517466\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1051837\n",
      "\tspeed: 0.3463s/iter; left time: 2120.8067s\n",
      "\titers: 200, epoch: 4 | loss: 0.0377445\n",
      "\tspeed: 0.1013s/iter; left time: 609.9736s\n",
      "\titers: 300, epoch: 4 | loss: 0.0332258\n",
      "\tspeed: 0.1013s/iter; left time: 600.2234s\n",
      "\titers: 400, epoch: 4 | loss: 0.0280473\n",
      "\tspeed: 0.1015s/iter; left time: 591.1626s\n",
      "\titers: 500, epoch: 4 | loss: 0.0230899\n",
      "\tspeed: 0.1012s/iter; left time: 579.5077s\n",
      "\titers: 600, epoch: 4 | loss: 0.0208434\n",
      "\tspeed: 0.1017s/iter; left time: 572.0064s\n",
      "\titers: 700, epoch: 4 | loss: 0.0206993\n",
      "\tspeed: 0.1014s/iter; left time: 560.3745s\n",
      "\titers: 800, epoch: 4 | loss: 0.0239729\n",
      "\tspeed: 0.1017s/iter; left time: 551.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.44s\n",
      "Steps: 889 | Train Loss: 0.0284620 Vali Loss: 0.0389327 Test Loss: 0.0480744\n",
      "Validation loss decreased (0.039004 --> 0.038933).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0229931\n",
      "\tspeed: 0.3497s/iter; left time: 1830.8212s\n",
      "\titers: 200, epoch: 5 | loss: 0.0213658\n",
      "\tspeed: 0.1013s/iter; left time: 520.1647s\n",
      "\titers: 300, epoch: 5 | loss: 0.0224696\n",
      "\tspeed: 0.1014s/iter; left time: 510.7841s\n",
      "\titers: 400, epoch: 5 | loss: 0.0209696\n",
      "\tspeed: 0.1015s/iter; left time: 501.0711s\n",
      "\titers: 500, epoch: 5 | loss: 0.0197579\n",
      "\tspeed: 0.1018s/iter; left time: 492.0026s\n",
      "\titers: 600, epoch: 5 | loss: 0.0156157\n",
      "\tspeed: 0.1017s/iter; left time: 481.5019s\n",
      "\titers: 700, epoch: 5 | loss: 0.0178417\n",
      "\tspeed: 0.1017s/iter; left time: 471.5438s\n",
      "\titers: 800, epoch: 5 | loss: 0.0179496\n",
      "\tspeed: 0.1016s/iter; left time: 460.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.60s\n",
      "Steps: 889 | Train Loss: 0.0194136 Vali Loss: 0.0461523 Test Loss: 0.0532340\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0163560\n",
      "\tspeed: 0.3435s/iter; left time: 1492.9032s\n",
      "\titers: 200, epoch: 6 | loss: 0.0173187\n",
      "\tspeed: 0.1010s/iter; left time: 428.8434s\n",
      "\titers: 300, epoch: 6 | loss: 0.0178944\n",
      "\tspeed: 0.1014s/iter; left time: 420.3910s\n",
      "\titers: 400, epoch: 6 | loss: 0.0137138\n",
      "\tspeed: 0.1013s/iter; left time: 409.7459s\n",
      "\titers: 500, epoch: 6 | loss: 0.0138716\n",
      "\tspeed: 0.1012s/iter; left time: 399.5298s\n",
      "\titers: 600, epoch: 6 | loss: 0.0157736\n",
      "\tspeed: 0.1014s/iter; left time: 390.0864s\n",
      "\titers: 700, epoch: 6 | loss: 0.0140351\n",
      "\tspeed: 0.1014s/iter; left time: 379.7982s\n",
      "\titers: 800, epoch: 6 | loss: 0.0173133\n",
      "\tspeed: 0.1014s/iter; left time: 369.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.31s\n",
      "Steps: 889 | Train Loss: 0.0159272 Vali Loss: 0.0501505 Test Loss: 0.0571509\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0152139\n",
      "\tspeed: 0.3437s/iter; left time: 1188.2031s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149456\n",
      "\tspeed: 0.1013s/iter; left time: 340.2191s\n",
      "\titers: 300, epoch: 7 | loss: 0.0138470\n",
      "\tspeed: 0.1016s/iter; left time: 330.7627s\n",
      "\titers: 400, epoch: 7 | loss: 0.0123385\n",
      "\tspeed: 0.1016s/iter; left time: 320.8566s\n",
      "\titers: 500, epoch: 7 | loss: 0.0142809\n",
      "\tspeed: 0.1014s/iter; left time: 310.0351s\n",
      "\titers: 600, epoch: 7 | loss: 0.0126598\n",
      "\tspeed: 0.1015s/iter; left time: 300.1528s\n",
      "\titers: 700, epoch: 7 | loss: 0.0113294\n",
      "\tspeed: 0.1014s/iter; left time: 289.8274s\n",
      "\titers: 800, epoch: 7 | loss: 0.0125918\n",
      "\tspeed: 0.1012s/iter; left time: 279.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:30.47s\n",
      "Steps: 889 | Train Loss: 0.0136974 Vali Loss: 0.0483307 Test Loss: 0.0563092\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0480743870139122, rmse:0.21925872564315796, mae:0.15089073777198792, rse:0.7767676115036011\n",
      "Original data scale mse:40928480.0, rmse:6397.537109375, mae:4202.4697265625, rse:0.3187560439109802\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3119751\n",
      "\tspeed: 0.1251s/iter; left time: 1104.6911s\n",
      "\titers: 200, epoch: 1 | loss: 0.2687303\n",
      "\tspeed: 0.0997s/iter; left time: 870.2768s\n",
      "\titers: 300, epoch: 1 | loss: 0.2528731\n",
      "\tspeed: 0.1001s/iter; left time: 863.6312s\n",
      "\titers: 400, epoch: 1 | loss: 0.2363542\n",
      "\tspeed: 0.1003s/iter; left time: 855.8063s\n",
      "\titers: 500, epoch: 1 | loss: 0.2356088\n",
      "\tspeed: 0.1001s/iter; left time: 843.5462s\n",
      "\titers: 600, epoch: 1 | loss: 0.2011895\n",
      "\tspeed: 0.1003s/iter; left time: 835.2590s\n",
      "\titers: 700, epoch: 1 | loss: 0.1963557\n",
      "\tspeed: 0.1005s/iter; left time: 827.3045s\n",
      "\titers: 800, epoch: 1 | loss: 0.1913563\n",
      "\tspeed: 0.0998s/iter; left time: 811.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.98s\n",
      "Steps: 893 | Train Loss: 0.2408001 Vali Loss: 0.0306270 Test Loss: 0.0341863\n",
      "Validation loss decreased (inf --> 0.030627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1798523\n",
      "\tspeed: 0.3677s/iter; left time: 2918.6449s\n",
      "\titers: 200, epoch: 2 | loss: 0.1497240\n",
      "\tspeed: 0.0996s/iter; left time: 780.3719s\n",
      "\titers: 300, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0994s/iter; left time: 769.2084s\n",
      "\titers: 400, epoch: 2 | loss: 0.1586751\n",
      "\tspeed: 0.0996s/iter; left time: 761.0465s\n",
      "\titers: 500, epoch: 2 | loss: 0.1439730\n",
      "\tspeed: 0.0995s/iter; left time: 750.1034s\n",
      "\titers: 600, epoch: 2 | loss: 0.1374251\n",
      "\tspeed: 0.0994s/iter; left time: 739.1869s\n",
      "\titers: 700, epoch: 2 | loss: 0.1821500\n",
      "\tspeed: 0.0989s/iter; left time: 725.5133s\n",
      "\titers: 800, epoch: 2 | loss: 0.1454188\n",
      "\tspeed: 0.0990s/iter; left time: 716.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 893 | Train Loss: 0.1603449 Vali Loss: 0.0241168 Test Loss: 0.0285046\n",
      "Validation loss decreased (0.030627 --> 0.024117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1324912\n",
      "\tspeed: 0.3466s/iter; left time: 2441.5654s\n",
      "\titers: 200, epoch: 3 | loss: 0.1661048\n",
      "\tspeed: 0.0993s/iter; left time: 689.6915s\n",
      "\titers: 300, epoch: 3 | loss: 0.1307280\n",
      "\tspeed: 0.0990s/iter; left time: 677.3655s\n",
      "\titers: 400, epoch: 3 | loss: 0.1771441\n",
      "\tspeed: 0.0992s/iter; left time: 669.4041s\n",
      "\titers: 500, epoch: 3 | loss: 0.1493734\n",
      "\tspeed: 0.0993s/iter; left time: 659.5761s\n",
      "\titers: 600, epoch: 3 | loss: 0.1886032\n",
      "\tspeed: 0.0991s/iter; left time: 648.4867s\n",
      "\titers: 700, epoch: 3 | loss: 0.1218876\n",
      "\tspeed: 0.0993s/iter; left time: 639.7773s\n",
      "\titers: 800, epoch: 3 | loss: 0.1253480\n",
      "\tspeed: 0.0992s/iter; left time: 629.2962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:28.87s\n",
      "Steps: 893 | Train Loss: 0.1437712 Vali Loss: 0.0243205 Test Loss: 0.0270176\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1300851\n",
      "\tspeed: 0.3472s/iter; left time: 2136.2213s\n",
      "\titers: 200, epoch: 4 | loss: 0.1445681\n",
      "\tspeed: 0.0991s/iter; left time: 599.9049s\n",
      "\titers: 300, epoch: 4 | loss: 0.1278089\n",
      "\tspeed: 0.0993s/iter; left time: 590.9584s\n",
      "\titers: 400, epoch: 4 | loss: 0.1304532\n",
      "\tspeed: 0.0993s/iter; left time: 581.2372s\n",
      "\titers: 500, epoch: 4 | loss: 0.1423497\n",
      "\tspeed: 0.0995s/iter; left time: 572.4360s\n",
      "\titers: 600, epoch: 4 | loss: 0.1480086\n",
      "\tspeed: 0.0992s/iter; left time: 560.7628s\n",
      "\titers: 700, epoch: 4 | loss: 0.1356694\n",
      "\tspeed: 0.0992s/iter; left time: 550.6514s\n",
      "\titers: 800, epoch: 4 | loss: 0.1339165\n",
      "\tspeed: 0.0993s/iter; left time: 541.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.79s\n",
      "Steps: 893 | Train Loss: 0.1368440 Vali Loss: 0.0218112 Test Loss: 0.0245521\n",
      "Validation loss decreased (0.024117 --> 0.021811).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1430645\n",
      "\tspeed: 0.3447s/iter; left time: 1812.7089s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071908\n",
      "\tspeed: 0.0989s/iter; left time: 510.2655s\n",
      "\titers: 300, epoch: 5 | loss: 0.1072370\n",
      "\tspeed: 0.0988s/iter; left time: 499.8428s\n",
      "\titers: 400, epoch: 5 | loss: 0.1177880\n",
      "\tspeed: 0.0990s/iter; left time: 490.9204s\n",
      "\titers: 500, epoch: 5 | loss: 0.1103637\n",
      "\tspeed: 0.0988s/iter; left time: 479.8498s\n",
      "\titers: 600, epoch: 5 | loss: 0.1187765\n",
      "\tspeed: 0.0987s/iter; left time: 469.6531s\n",
      "\titers: 700, epoch: 5 | loss: 0.1123698\n",
      "\tspeed: 0.0989s/iter; left time: 460.6642s\n",
      "\titers: 800, epoch: 5 | loss: 0.1249231\n",
      "\tspeed: 0.0989s/iter; left time: 450.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.49s\n",
      "Steps: 893 | Train Loss: 0.1202062 Vali Loss: 0.0214475 Test Loss: 0.0239205\n",
      "Validation loss decreased (0.021811 --> 0.021448).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1197086\n",
      "\tspeed: 0.3414s/iter; left time: 1490.6730s\n",
      "\titers: 200, epoch: 6 | loss: 0.1364237\n",
      "\tspeed: 0.0988s/iter; left time: 421.2883s\n",
      "\titers: 300, epoch: 6 | loss: 0.1210241\n",
      "\tspeed: 0.1037s/iter; left time: 431.9777s\n",
      "\titers: 400, epoch: 6 | loss: 0.1009743\n",
      "\tspeed: 0.0992s/iter; left time: 403.2040s\n",
      "\titers: 500, epoch: 6 | loss: 0.1270935\n",
      "\tspeed: 0.0991s/iter; left time: 393.1713s\n",
      "\titers: 600, epoch: 6 | loss: 0.1093042\n",
      "\tspeed: 0.0987s/iter; left time: 381.5499s\n",
      "\titers: 700, epoch: 6 | loss: 0.1299805\n",
      "\tspeed: 0.0985s/iter; left time: 370.9909s\n",
      "\titers: 800, epoch: 6 | loss: 0.1206778\n",
      "\tspeed: 0.0989s/iter; left time: 362.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.11s\n",
      "Steps: 893 | Train Loss: 0.1158589 Vali Loss: 0.0233603 Test Loss: 0.0271833\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0982039\n",
      "\tspeed: 0.3390s/iter; left time: 1177.1863s\n",
      "\titers: 200, epoch: 7 | loss: 0.1104366\n",
      "\tspeed: 0.0989s/iter; left time: 333.4514s\n",
      "\titers: 300, epoch: 7 | loss: 0.1191452\n",
      "\tspeed: 0.0989s/iter; left time: 323.7602s\n",
      "\titers: 400, epoch: 7 | loss: 0.1151330\n",
      "\tspeed: 0.0993s/iter; left time: 315.1385s\n",
      "\titers: 500, epoch: 7 | loss: 0.1087277\n",
      "\tspeed: 0.0985s/iter; left time: 302.5779s\n",
      "\titers: 600, epoch: 7 | loss: 0.0974394\n",
      "\tspeed: 0.0987s/iter; left time: 293.5810s\n",
      "\titers: 700, epoch: 7 | loss: 0.1050017\n",
      "\tspeed: 0.0988s/iter; left time: 283.9241s\n",
      "\titers: 800, epoch: 7 | loss: 0.1094091\n",
      "\tspeed: 0.0990s/iter; left time: 274.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.52s\n",
      "Steps: 893 | Train Loss: 0.1111351 Vali Loss: 0.0242172 Test Loss: 0.0283753\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1143424\n",
      "\tspeed: 0.3362s/iter; left time: 867.3217s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076255\n",
      "\tspeed: 0.0987s/iter; left time: 244.8778s\n",
      "\titers: 300, epoch: 8 | loss: 0.1334700\n",
      "\tspeed: 0.0988s/iter; left time: 235.0717s\n",
      "\titers: 400, epoch: 8 | loss: 0.0976090\n",
      "\tspeed: 0.1024s/iter; left time: 233.5621s\n",
      "\titers: 500, epoch: 8 | loss: 0.1050223\n",
      "\tspeed: 0.1017s/iter; left time: 221.8023s\n",
      "\titers: 600, epoch: 8 | loss: 0.1028479\n",
      "\tspeed: 0.0989s/iter; left time: 205.7581s\n",
      "\titers: 700, epoch: 8 | loss: 0.1022391\n",
      "\tspeed: 0.0989s/iter; left time: 195.8809s\n",
      "\titers: 800, epoch: 8 | loss: 0.1028526\n",
      "\tspeed: 0.0991s/iter; left time: 186.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:29.25s\n",
      "Steps: 893 | Train Loss: 0.1057393 Vali Loss: 0.0247623 Test Loss: 0.0290283\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023920543491840363, rmse:0.15466268360614777, mae:0.10372508317232132, rse:0.546195387840271\n",
      "Original data scale mse:19043724.0, rmse:4363.91162109375, mae:2849.044189453125, rse:0.21698248386383057\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2834153\n",
      "\tspeed: 0.1023s/iter; left time: 903.0568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3088479\n",
      "\tspeed: 0.0999s/iter; left time: 872.0841s\n",
      "\titers: 300, epoch: 1 | loss: 0.2581985\n",
      "\tspeed: 0.1000s/iter; left time: 862.6800s\n",
      "\titers: 400, epoch: 1 | loss: 0.2507281\n",
      "\tspeed: 0.1002s/iter; left time: 854.7785s\n",
      "\titers: 500, epoch: 1 | loss: 0.2027353\n",
      "\tspeed: 0.1000s/iter; left time: 843.3400s\n",
      "\titers: 600, epoch: 1 | loss: 0.2031734\n",
      "\tspeed: 0.1001s/iter; left time: 834.3280s\n",
      "\titers: 700, epoch: 1 | loss: 0.2132137\n",
      "\tspeed: 0.0999s/iter; left time: 822.2465s\n",
      "\titers: 800, epoch: 1 | loss: 0.1852324\n",
      "\tspeed: 0.1003s/iter; left time: 815.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.62s\n",
      "Steps: 893 | Train Loss: 0.2421935 Vali Loss: 0.0303944 Test Loss: 0.0338393\n",
      "Validation loss decreased (inf --> 0.030394).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1984762\n",
      "\tspeed: 0.3429s/iter; left time: 2721.7977s\n",
      "\titers: 200, epoch: 2 | loss: 0.1421874\n",
      "\tspeed: 0.0996s/iter; left time: 781.0125s\n",
      "\titers: 300, epoch: 2 | loss: 0.1915530\n",
      "\tspeed: 0.0993s/iter; left time: 768.0742s\n",
      "\titers: 400, epoch: 2 | loss: 0.1667751\n",
      "\tspeed: 0.0996s/iter; left time: 760.8789s\n",
      "\titers: 500, epoch: 2 | loss: 0.1351736\n",
      "\tspeed: 0.1035s/iter; left time: 780.4042s\n",
      "\titers: 600, epoch: 2 | loss: 0.1429658\n",
      "\tspeed: 0.0992s/iter; left time: 737.7728s\n",
      "\titers: 700, epoch: 2 | loss: 0.1412620\n",
      "\tspeed: 0.0991s/iter; left time: 727.2241s\n",
      "\titers: 800, epoch: 2 | loss: 0.1501957\n",
      "\tspeed: 0.0989s/iter; left time: 716.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.45s\n",
      "Steps: 893 | Train Loss: 0.1619039 Vali Loss: 0.0240957 Test Loss: 0.0267190\n",
      "Validation loss decreased (0.030394 --> 0.024096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1389558\n",
      "\tspeed: 0.3481s/iter; left time: 2452.3308s\n",
      "\titers: 200, epoch: 3 | loss: 0.1219203\n",
      "\tspeed: 0.0989s/iter; left time: 686.9588s\n",
      "\titers: 300, epoch: 3 | loss: 0.1380037\n",
      "\tspeed: 0.0989s/iter; left time: 676.9585s\n",
      "\titers: 400, epoch: 3 | loss: 0.1412655\n",
      "\tspeed: 0.0991s/iter; left time: 668.4143s\n",
      "\titers: 500, epoch: 3 | loss: 0.1561089\n",
      "\tspeed: 0.0990s/iter; left time: 657.8122s\n",
      "\titers: 600, epoch: 3 | loss: 0.1421354\n",
      "\tspeed: 0.0993s/iter; left time: 650.1974s\n",
      "\titers: 700, epoch: 3 | loss: 0.1215367\n",
      "\tspeed: 0.0990s/iter; left time: 638.2971s\n",
      "\titers: 800, epoch: 3 | loss: 0.1393289\n",
      "\tspeed: 0.0991s/iter; left time: 628.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:28.80s\n",
      "Steps: 893 | Train Loss: 0.1466758 Vali Loss: 0.0254645 Test Loss: 0.0274923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1357583\n",
      "\tspeed: 0.3407s/iter; left time: 2096.0264s\n",
      "\titers: 200, epoch: 4 | loss: 0.1349886\n",
      "\tspeed: 0.0992s/iter; left time: 600.1372s\n",
      "\titers: 300, epoch: 4 | loss: 0.1276219\n",
      "\tspeed: 0.0990s/iter; left time: 589.5318s\n",
      "\titers: 400, epoch: 4 | loss: 0.1176364\n",
      "\tspeed: 0.0991s/iter; left time: 580.2114s\n",
      "\titers: 500, epoch: 4 | loss: 0.1589938\n",
      "\tspeed: 0.0994s/iter; left time: 571.8600s\n",
      "\titers: 600, epoch: 4 | loss: 0.1302531\n",
      "\tspeed: 0.0986s/iter; left time: 557.3340s\n",
      "\titers: 700, epoch: 4 | loss: 0.1514039\n",
      "\tspeed: 0.0989s/iter; left time: 549.3492s\n",
      "\titers: 800, epoch: 4 | loss: 0.1287941\n",
      "\tspeed: 0.0991s/iter; left time: 540.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.74s\n",
      "Steps: 893 | Train Loss: 0.1316664 Vali Loss: 0.0222347 Test Loss: 0.0245601\n",
      "Validation loss decreased (0.024096 --> 0.022235).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1393411\n",
      "\tspeed: 0.3462s/iter; left time: 1820.6294s\n",
      "\titers: 200, epoch: 5 | loss: 0.1322993\n",
      "\tspeed: 0.0988s/iter; left time: 509.6613s\n",
      "\titers: 300, epoch: 5 | loss: 0.1329746\n",
      "\tspeed: 0.0993s/iter; left time: 502.5173s\n",
      "\titers: 400, epoch: 5 | loss: 0.1208111\n",
      "\tspeed: 0.0990s/iter; left time: 491.1880s\n",
      "\titers: 500, epoch: 5 | loss: 0.1287270\n",
      "\tspeed: 0.0993s/iter; left time: 482.6762s\n",
      "\titers: 600, epoch: 5 | loss: 0.1208047\n",
      "\tspeed: 0.0989s/iter; left time: 470.4720s\n",
      "\titers: 700, epoch: 5 | loss: 0.1279666\n",
      "\tspeed: 0.0990s/iter; left time: 461.2599s\n",
      "\titers: 800, epoch: 5 | loss: 0.1155474\n",
      "\tspeed: 0.0991s/iter; left time: 451.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.75s\n",
      "Steps: 893 | Train Loss: 0.1225326 Vali Loss: 0.0211855 Test Loss: 0.0240403\n",
      "Validation loss decreased (0.022235 --> 0.021185).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1157856\n",
      "\tspeed: 0.3414s/iter; left time: 1490.5646s\n",
      "\titers: 200, epoch: 6 | loss: 0.1123463\n",
      "\tspeed: 0.0988s/iter; left time: 421.4332s\n",
      "\titers: 300, epoch: 6 | loss: 0.1094559\n",
      "\tspeed: 0.0994s/iter; left time: 414.1389s\n",
      "\titers: 400, epoch: 6 | loss: 0.1096972\n",
      "\tspeed: 0.0995s/iter; left time: 404.5668s\n",
      "\titers: 500, epoch: 6 | loss: 0.1271596\n",
      "\tspeed: 0.0988s/iter; left time: 392.0098s\n",
      "\titers: 600, epoch: 6 | loss: 0.1155807\n",
      "\tspeed: 0.0993s/iter; left time: 383.8070s\n",
      "\titers: 700, epoch: 6 | loss: 0.1162018\n",
      "\tspeed: 0.0990s/iter; left time: 372.9308s\n",
      "\titers: 800, epoch: 6 | loss: 0.1198730\n",
      "\tspeed: 0.0992s/iter; left time: 363.8176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:28.79s\n",
      "Steps: 893 | Train Loss: 0.1156449 Vali Loss: 0.0228653 Test Loss: 0.0254431\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1150981\n",
      "\tspeed: 0.3446s/iter; left time: 1196.7270s\n",
      "\titers: 200, epoch: 7 | loss: 0.1081226\n",
      "\tspeed: 0.0990s/iter; left time: 334.0573s\n",
      "\titers: 300, epoch: 7 | loss: 0.1213813\n",
      "\tspeed: 0.0991s/iter; left time: 324.4631s\n",
      "\titers: 400, epoch: 7 | loss: 0.1120377\n",
      "\tspeed: 0.0992s/iter; left time: 314.7857s\n",
      "\titers: 500, epoch: 7 | loss: 0.1224175\n",
      "\tspeed: 0.0991s/iter; left time: 304.4199s\n",
      "\titers: 600, epoch: 7 | loss: 0.1247628\n",
      "\tspeed: 0.0993s/iter; left time: 295.3026s\n",
      "\titers: 700, epoch: 7 | loss: 0.1039832\n",
      "\tspeed: 0.0989s/iter; left time: 284.1973s\n",
      "\titers: 800, epoch: 7 | loss: 0.1230954\n",
      "\tspeed: 0.0991s/iter; left time: 274.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.78s\n",
      "Steps: 893 | Train Loss: 0.1130534 Vali Loss: 0.0234236 Test Loss: 0.0273822\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098113\n",
      "\tspeed: 0.3397s/iter; left time: 876.4459s\n",
      "\titers: 200, epoch: 8 | loss: 0.1004768\n",
      "\tspeed: 0.0990s/iter; left time: 245.4564s\n",
      "\titers: 300, epoch: 8 | loss: 0.1070496\n",
      "\tspeed: 0.0988s/iter; left time: 235.1893s\n",
      "\titers: 400, epoch: 8 | loss: 0.1094294\n",
      "\tspeed: 0.0992s/iter; left time: 226.2238s\n",
      "\titers: 500, epoch: 8 | loss: 0.1177006\n",
      "\tspeed: 0.0992s/iter; left time: 216.2505s\n",
      "\titers: 600, epoch: 8 | loss: 0.1191125\n",
      "\tspeed: 0.0992s/iter; left time: 206.2796s\n",
      "\titers: 700, epoch: 8 | loss: 0.0995629\n",
      "\tspeed: 0.0991s/iter; left time: 196.1242s\n",
      "\titers: 800, epoch: 8 | loss: 0.1081214\n",
      "\tspeed: 0.0987s/iter; left time: 185.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.75s\n",
      "Steps: 893 | Train Loss: 0.1066161 Vali Loss: 0.0238699 Test Loss: 0.0281685\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024040305987000465, rmse:0.1550493687391281, mae:0.10435939580202103, rse:0.54756098985672\n",
      "Original data scale mse:19401690.0, rmse:4404.73486328125, mae:2870.5693359375, rse:0.2190122902393341\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3233960\n",
      "\tspeed: 0.1240s/iter; left time: 1092.5312s\n",
      "\titers: 200, epoch: 1 | loss: 0.2763235\n",
      "\tspeed: 0.1006s/iter; left time: 876.3190s\n",
      "\titers: 300, epoch: 1 | loss: 0.2720335\n",
      "\tspeed: 0.1010s/iter; left time: 869.3088s\n",
      "\titers: 400, epoch: 1 | loss: 0.2370163\n",
      "\tspeed: 0.1009s/iter; left time: 858.5241s\n",
      "\titers: 500, epoch: 1 | loss: 0.2364084\n",
      "\tspeed: 0.1010s/iter; left time: 849.7796s\n",
      "\titers: 600, epoch: 1 | loss: 0.2052633\n",
      "\tspeed: 0.1010s/iter; left time: 839.2963s\n",
      "\titers: 700, epoch: 1 | loss: 0.2154188\n",
      "\tspeed: 0.1010s/iter; left time: 829.6421s\n",
      "\titers: 800, epoch: 1 | loss: 0.2061429\n",
      "\tspeed: 0.1008s/iter; left time: 817.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.39s\n",
      "Steps: 891 | Train Loss: 0.2529160 Vali Loss: 0.0461246 Test Loss: 0.0540616\n",
      "Validation loss decreased (inf --> 0.046125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1844720\n",
      "\tspeed: 0.3466s/iter; left time: 2744.7972s\n",
      "\titers: 200, epoch: 2 | loss: 0.1917748\n",
      "\tspeed: 0.1008s/iter; left time: 788.6197s\n",
      "\titers: 300, epoch: 2 | loss: 0.1847743\n",
      "\tspeed: 0.1009s/iter; left time: 779.2534s\n",
      "\titers: 400, epoch: 2 | loss: 0.1665137\n",
      "\tspeed: 0.1009s/iter; left time: 768.7382s\n",
      "\titers: 500, epoch: 2 | loss: 0.1667559\n",
      "\tspeed: 0.1007s/iter; left time: 756.9719s\n",
      "\titers: 600, epoch: 2 | loss: 0.1706077\n",
      "\tspeed: 0.1006s/iter; left time: 746.8210s\n",
      "\titers: 700, epoch: 2 | loss: 0.1759230\n",
      "\tspeed: 0.1009s/iter; left time: 738.8534s\n",
      "\titers: 800, epoch: 2 | loss: 0.1602517\n",
      "\tspeed: 0.1001s/iter; left time: 722.8938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.44s\n",
      "Steps: 891 | Train Loss: 0.1831155 Vali Loss: 0.0379007 Test Loss: 0.0476016\n",
      "Validation loss decreased (0.046125 --> 0.037901).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1751523\n",
      "\tspeed: 0.3524s/iter; left time: 2476.8996s\n",
      "\titers: 200, epoch: 3 | loss: 0.1769161\n",
      "\tspeed: 0.1003s/iter; left time: 695.1797s\n",
      "\titers: 300, epoch: 3 | loss: 0.1729967\n",
      "\tspeed: 0.1003s/iter; left time: 685.2365s\n",
      "\titers: 400, epoch: 3 | loss: 0.2155060\n",
      "\tspeed: 0.1003s/iter; left time: 674.6770s\n",
      "\titers: 500, epoch: 3 | loss: 0.1544757\n",
      "\tspeed: 0.1001s/iter; left time: 663.8275s\n",
      "\titers: 600, epoch: 3 | loss: 0.1549823\n",
      "\tspeed: 0.1006s/iter; left time: 656.6671s\n",
      "\titers: 700, epoch: 3 | loss: 0.1685071\n",
      "\tspeed: 0.1005s/iter; left time: 646.2724s\n",
      "\titers: 800, epoch: 3 | loss: 0.1481873\n",
      "\tspeed: 0.1005s/iter; left time: 636.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.61s\n",
      "Steps: 891 | Train Loss: 0.1678437 Vali Loss: 0.0416122 Test Loss: 0.0477508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1530192\n",
      "\tspeed: 0.3424s/iter; left time: 2101.5139s\n",
      "\titers: 200, epoch: 4 | loss: 0.1603169\n",
      "\tspeed: 0.1006s/iter; left time: 607.1388s\n",
      "\titers: 300, epoch: 4 | loss: 0.1458100\n",
      "\tspeed: 0.1006s/iter; left time: 597.3960s\n",
      "\titers: 400, epoch: 4 | loss: 0.1558808\n",
      "\tspeed: 0.1005s/iter; left time: 586.7110s\n",
      "\titers: 500, epoch: 4 | loss: 0.1486968\n",
      "\tspeed: 0.1007s/iter; left time: 577.9533s\n",
      "\titers: 600, epoch: 4 | loss: 0.1485243\n",
      "\tspeed: 0.1006s/iter; left time: 567.2316s\n",
      "\titers: 700, epoch: 4 | loss: 0.1323584\n",
      "\tspeed: 0.1005s/iter; left time: 556.4106s\n",
      "\titers: 800, epoch: 4 | loss: 0.1425703\n",
      "\tspeed: 0.1004s/iter; left time: 545.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.72s\n",
      "Steps: 891 | Train Loss: 0.1475250 Vali Loss: 0.0389221 Test Loss: 0.0481405\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1371497\n",
      "\tspeed: 0.3414s/iter; left time: 1791.0959s\n",
      "\titers: 200, epoch: 5 | loss: 0.1287748\n",
      "\tspeed: 0.1006s/iter; left time: 517.5783s\n",
      "\titers: 300, epoch: 5 | loss: 0.1446898\n",
      "\tspeed: 0.1005s/iter; left time: 507.2640s\n",
      "\titers: 400, epoch: 5 | loss: 0.1326863\n",
      "\tspeed: 0.1008s/iter; left time: 498.6802s\n",
      "\titers: 500, epoch: 5 | loss: 0.1333211\n",
      "\tspeed: 0.1000s/iter; left time: 484.5041s\n",
      "\titers: 600, epoch: 5 | loss: 0.1360008\n",
      "\tspeed: 0.1005s/iter; left time: 477.1570s\n",
      "\titers: 700, epoch: 5 | loss: 0.1306292\n",
      "\tspeed: 0.1008s/iter; left time: 468.2900s\n",
      "\titers: 800, epoch: 5 | loss: 0.1325940\n",
      "\tspeed: 0.1003s/iter; left time: 456.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.77s\n",
      "Steps: 891 | Train Loss: 0.1332562 Vali Loss: 0.0422387 Test Loss: 0.0495486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04760156199336052, rmse:0.21817782521247864, mae:0.1525401920080185, rse:0.7726117968559265\n",
      "Original data scale mse:38907712.0, rmse:6237.6044921875, mae:4236.4296875, rse:0.31063494086265564\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3098243\n",
      "\tspeed: 0.1029s/iter; left time: 906.5133s\n",
      "\titers: 200, epoch: 1 | loss: 0.2853111\n",
      "\tspeed: 0.1009s/iter; left time: 879.2542s\n",
      "\titers: 300, epoch: 1 | loss: 0.2648452\n",
      "\tspeed: 0.1013s/iter; left time: 872.0964s\n",
      "\titers: 400, epoch: 1 | loss: 0.2409943\n",
      "\tspeed: 0.1011s/iter; left time: 860.2194s\n",
      "\titers: 500, epoch: 1 | loss: 0.2201771\n",
      "\tspeed: 0.1010s/iter; left time: 849.1806s\n",
      "\titers: 600, epoch: 1 | loss: 0.2117838\n",
      "\tspeed: 0.1009s/iter; left time: 838.6490s\n",
      "\titers: 700, epoch: 1 | loss: 0.2067982\n",
      "\tspeed: 0.1008s/iter; left time: 828.0251s\n",
      "\titers: 800, epoch: 1 | loss: 0.2053541\n",
      "\tspeed: 0.1005s/iter; left time: 814.8497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.17s\n",
      "Steps: 891 | Train Loss: 0.2500025 Vali Loss: 0.0411604 Test Loss: 0.0479991\n",
      "Validation loss decreased (inf --> 0.041160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1807195\n",
      "\tspeed: 0.3719s/iter; left time: 2945.4979s\n",
      "\titers: 200, epoch: 2 | loss: 0.1866263\n",
      "\tspeed: 0.1011s/iter; left time: 790.4399s\n",
      "\titers: 300, epoch: 2 | loss: 0.1746513\n",
      "\tspeed: 0.1009s/iter; left time: 778.6113s\n",
      "\titers: 400, epoch: 2 | loss: 0.1772306\n",
      "\tspeed: 0.1009s/iter; left time: 768.6316s\n",
      "\titers: 500, epoch: 2 | loss: 0.1564138\n",
      "\tspeed: 0.1005s/iter; left time: 756.0839s\n",
      "\titers: 600, epoch: 2 | loss: 0.1922639\n",
      "\tspeed: 0.1008s/iter; left time: 747.7550s\n",
      "\titers: 700, epoch: 2 | loss: 0.1675027\n",
      "\tspeed: 0.1008s/iter; left time: 737.5773s\n",
      "\titers: 800, epoch: 2 | loss: 0.1753932\n",
      "\tspeed: 0.1008s/iter; left time: 728.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.17s\n",
      "Steps: 891 | Train Loss: 0.1819329 Vali Loss: 0.0428211 Test Loss: 0.0472156\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1728081\n",
      "\tspeed: 0.3447s/iter; left time: 2422.9584s\n",
      "\titers: 200, epoch: 3 | loss: 0.1554142\n",
      "\tspeed: 0.1002s/iter; left time: 694.4952s\n",
      "\titers: 300, epoch: 3 | loss: 0.1867336\n",
      "\tspeed: 0.1007s/iter; left time: 687.5938s\n",
      "\titers: 400, epoch: 3 | loss: 0.1575169\n",
      "\tspeed: 0.1006s/iter; left time: 677.1814s\n",
      "\titers: 500, epoch: 3 | loss: 0.1794522\n",
      "\tspeed: 0.1008s/iter; left time: 668.1241s\n",
      "\titers: 600, epoch: 3 | loss: 0.2279409\n",
      "\tspeed: 0.1006s/iter; left time: 656.9897s\n",
      "\titers: 700, epoch: 3 | loss: 0.1697339\n",
      "\tspeed: 0.1001s/iter; left time: 643.8569s\n",
      "\titers: 800, epoch: 3 | loss: 0.1450731\n",
      "\tspeed: 0.0999s/iter; left time: 631.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.74s\n",
      "Steps: 891 | Train Loss: 0.1771172 Vali Loss: 0.0394028 Test Loss: 0.0452506\n",
      "Validation loss decreased (0.041160 --> 0.039403).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1678795\n",
      "\tspeed: 0.3552s/iter; left time: 2179.9757s\n",
      "\titers: 200, epoch: 4 | loss: 0.1527184\n",
      "\tspeed: 0.1003s/iter; left time: 605.6821s\n",
      "\titers: 300, epoch: 4 | loss: 0.1579676\n",
      "\tspeed: 0.1005s/iter; left time: 596.9202s\n",
      "\titers: 400, epoch: 4 | loss: 0.1500165\n",
      "\tspeed: 0.1004s/iter; left time: 586.4013s\n",
      "\titers: 500, epoch: 4 | loss: 0.1657487\n",
      "\tspeed: 0.1007s/iter; left time: 577.9156s\n",
      "\titers: 600, epoch: 4 | loss: 0.1603698\n",
      "\tspeed: 0.1005s/iter; left time: 566.5627s\n",
      "\titers: 700, epoch: 4 | loss: 0.1301298\n",
      "\tspeed: 0.1006s/iter; left time: 557.1208s\n",
      "\titers: 800, epoch: 4 | loss: 0.1493688\n",
      "\tspeed: 0.1003s/iter; left time: 545.2753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.72s\n",
      "Steps: 891 | Train Loss: 0.1564478 Vali Loss: 0.0359839 Test Loss: 0.0457921\n",
      "Validation loss decreased (0.039403 --> 0.035984).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1340609\n",
      "\tspeed: 0.3477s/iter; left time: 1824.5811s\n",
      "\titers: 200, epoch: 5 | loss: 0.1401764\n",
      "\tspeed: 0.1006s/iter; left time: 517.6688s\n",
      "\titers: 300, epoch: 5 | loss: 0.1564682\n",
      "\tspeed: 0.1007s/iter; left time: 507.9862s\n",
      "\titers: 400, epoch: 5 | loss: 0.1512408\n",
      "\tspeed: 0.1004s/iter; left time: 496.6245s\n",
      "\titers: 500, epoch: 5 | loss: 0.1299691\n",
      "\tspeed: 0.1005s/iter; left time: 487.3310s\n",
      "\titers: 600, epoch: 5 | loss: 0.1432363\n",
      "\tspeed: 0.1006s/iter; left time: 477.5391s\n",
      "\titers: 700, epoch: 5 | loss: 0.1441161\n",
      "\tspeed: 0.1006s/iter; left time: 467.4717s\n",
      "\titers: 800, epoch: 5 | loss: 0.1320746\n",
      "\tspeed: 0.1005s/iter; left time: 457.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.90s\n",
      "Steps: 891 | Train Loss: 0.1407181 Vali Loss: 0.0384902 Test Loss: 0.0476424\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1278519\n",
      "\tspeed: 0.3443s/iter; left time: 1499.7193s\n",
      "\titers: 200, epoch: 6 | loss: 0.1318893\n",
      "\tspeed: 0.1070s/iter; left time: 455.5320s\n",
      "\titers: 300, epoch: 6 | loss: 0.1185490\n",
      "\tspeed: 0.1020s/iter; left time: 423.9061s\n",
      "\titers: 400, epoch: 6 | loss: 0.1178336\n",
      "\tspeed: 0.1007s/iter; left time: 408.3407s\n",
      "\titers: 500, epoch: 6 | loss: 0.1193936\n",
      "\tspeed: 0.1006s/iter; left time: 398.0014s\n",
      "\titers: 600, epoch: 6 | loss: 0.1154709\n",
      "\tspeed: 0.1007s/iter; left time: 388.3842s\n",
      "\titers: 700, epoch: 6 | loss: 0.1175231\n",
      "\tspeed: 0.1006s/iter; left time: 377.9122s\n",
      "\titers: 800, epoch: 6 | loss: 0.1179729\n",
      "\tspeed: 0.1009s/iter; left time: 368.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.73s\n",
      "Steps: 891 | Train Loss: 0.1258377 Vali Loss: 0.0389521 Test Loss: 0.0483296\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1290351\n",
      "\tspeed: 0.3445s/iter; left time: 1193.6229s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075460\n",
      "\tspeed: 0.1006s/iter; left time: 338.6408s\n",
      "\titers: 300, epoch: 7 | loss: 0.1183309\n",
      "\tspeed: 0.1006s/iter; left time: 328.3451s\n",
      "\titers: 400, epoch: 7 | loss: 0.1197236\n",
      "\tspeed: 0.1007s/iter; left time: 318.8602s\n",
      "\titers: 500, epoch: 7 | loss: 0.1123948\n",
      "\tspeed: 0.1005s/iter; left time: 307.9722s\n",
      "\titers: 600, epoch: 7 | loss: 0.1135068\n",
      "\tspeed: 0.1004s/iter; left time: 297.8007s\n",
      "\titers: 700, epoch: 7 | loss: 0.1136553\n",
      "\tspeed: 0.1000s/iter; left time: 286.6348s\n",
      "\titers: 800, epoch: 7 | loss: 0.1177305\n",
      "\tspeed: 0.1002s/iter; left time: 277.1359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:29.74s\n",
      "Steps: 891 | Train Loss: 0.1141507 Vali Loss: 0.0412420 Test Loss: 0.0504307\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04579208791255951, rmse:0.21399085223674774, mae:0.14176172018051147, rse:0.757784903049469\n",
      "Original data scale mse:37945684.0, rmse:6160.0068359375, mae:3876.059326171875, rse:0.30677053332328796\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3060444\n",
      "\tspeed: 0.1249s/iter; left time: 1098.3907s\n",
      "\titers: 200, epoch: 1 | loss: 0.2931899\n",
      "\tspeed: 0.1018s/iter; left time: 884.6482s\n",
      "\titers: 300, epoch: 1 | loss: 0.2388343\n",
      "\tspeed: 0.1019s/iter; left time: 875.5587s\n",
      "\titers: 400, epoch: 1 | loss: 0.2412417\n",
      "\tspeed: 0.1018s/iter; left time: 864.2631s\n",
      "\titers: 500, epoch: 1 | loss: 0.2394292\n",
      "\tspeed: 0.1020s/iter; left time: 855.7302s\n",
      "\titers: 600, epoch: 1 | loss: 0.2219165\n",
      "\tspeed: 0.1018s/iter; left time: 844.0081s\n",
      "\titers: 700, epoch: 1 | loss: 0.2223854\n",
      "\tspeed: 0.1017s/iter; left time: 833.2948s\n",
      "\titers: 800, epoch: 1 | loss: 0.2139860\n",
      "\tspeed: 0.1019s/iter; left time: 824.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.99s\n",
      "Steps: 889 | Train Loss: 0.2540876 Vali Loss: 0.0457445 Test Loss: 0.0544260\n",
      "Validation loss decreased (inf --> 0.045744).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2016554\n",
      "\tspeed: 0.3485s/iter; left time: 2753.5792s\n",
      "\titers: 200, epoch: 2 | loss: 0.2185957\n",
      "\tspeed: 0.1015s/iter; left time: 792.0868s\n",
      "\titers: 300, epoch: 2 | loss: 0.1667532\n",
      "\tspeed: 0.1017s/iter; left time: 783.0917s\n",
      "\titers: 400, epoch: 2 | loss: 0.1817673\n",
      "\tspeed: 0.1016s/iter; left time: 772.3065s\n",
      "\titers: 500, epoch: 2 | loss: 0.1635672\n",
      "\tspeed: 0.1016s/iter; left time: 762.3250s\n",
      "\titers: 600, epoch: 2 | loss: 0.1787573\n",
      "\tspeed: 0.1015s/iter; left time: 751.4307s\n",
      "\titers: 700, epoch: 2 | loss: 0.1810467\n",
      "\tspeed: 0.1018s/iter; left time: 743.6757s\n",
      "\titers: 800, epoch: 2 | loss: 0.1749804\n",
      "\tspeed: 0.1019s/iter; left time: 733.9398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.68s\n",
      "Steps: 889 | Train Loss: 0.1880852 Vali Loss: 0.0394631 Test Loss: 0.0468496\n",
      "Validation loss decreased (0.045744 --> 0.039463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1842614\n",
      "\tspeed: 0.3502s/iter; left time: 2456.0826s\n",
      "\titers: 200, epoch: 3 | loss: 0.1793237\n",
      "\tspeed: 0.1013s/iter; left time: 700.4151s\n",
      "\titers: 300, epoch: 3 | loss: 0.1601504\n",
      "\tspeed: 0.1074s/iter; left time: 731.9107s\n",
      "\titers: 400, epoch: 3 | loss: 0.1733156\n",
      "\tspeed: 0.1014s/iter; left time: 680.5261s\n",
      "\titers: 500, epoch: 3 | loss: 0.1736267\n",
      "\tspeed: 0.1014s/iter; left time: 670.2752s\n",
      "\titers: 600, epoch: 3 | loss: 0.1682543\n",
      "\tspeed: 0.1014s/iter; left time: 660.3643s\n",
      "\titers: 700, epoch: 3 | loss: 0.1527036\n",
      "\tspeed: 0.1016s/iter; left time: 651.6286s\n",
      "\titers: 800, epoch: 3 | loss: 0.1574736\n",
      "\tspeed: 0.1016s/iter; left time: 641.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.09s\n",
      "Steps: 889 | Train Loss: 0.1668156 Vali Loss: 0.0373288 Test Loss: 0.0443402\n",
      "Validation loss decreased (0.039463 --> 0.037329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1554583\n",
      "\tspeed: 0.3473s/iter; left time: 2126.8161s\n",
      "\titers: 200, epoch: 4 | loss: 0.1506293\n",
      "\tspeed: 0.1015s/iter; left time: 611.5138s\n",
      "\titers: 300, epoch: 4 | loss: 0.1497672\n",
      "\tspeed: 0.1016s/iter; left time: 601.6027s\n",
      "\titers: 400, epoch: 4 | loss: 0.1461608\n",
      "\tspeed: 0.1014s/iter; left time: 590.4291s\n",
      "\titers: 500, epoch: 4 | loss: 0.1472175\n",
      "\tspeed: 0.1013s/iter; left time: 579.6230s\n",
      "\titers: 600, epoch: 4 | loss: 0.1426928\n",
      "\tspeed: 0.1014s/iter; left time: 570.4991s\n",
      "\titers: 700, epoch: 4 | loss: 0.1463919\n",
      "\tspeed: 0.1020s/iter; left time: 563.6856s\n",
      "\titers: 800, epoch: 4 | loss: 0.1442363\n",
      "\tspeed: 0.1017s/iter; left time: 551.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.44s\n",
      "Steps: 889 | Train Loss: 0.1465867 Vali Loss: 0.0401815 Test Loss: 0.0516594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1383046\n",
      "\tspeed: 0.3426s/iter; left time: 1793.5310s\n",
      "\titers: 200, epoch: 5 | loss: 0.1349668\n",
      "\tspeed: 0.1019s/iter; left time: 523.1721s\n",
      "\titers: 300, epoch: 5 | loss: 0.1368662\n",
      "\tspeed: 0.1012s/iter; left time: 509.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.1288198\n",
      "\tspeed: 0.1054s/iter; left time: 520.0082s\n",
      "\titers: 500, epoch: 5 | loss: 0.1364193\n",
      "\tspeed: 0.1018s/iter; left time: 492.3059s\n",
      "\titers: 600, epoch: 5 | loss: 0.1260519\n",
      "\tspeed: 0.1018s/iter; left time: 481.8586s\n",
      "\titers: 700, epoch: 5 | loss: 0.1217756\n",
      "\tspeed: 0.1015s/iter; left time: 470.4951s\n",
      "\titers: 800, epoch: 5 | loss: 0.1333477\n",
      "\tspeed: 0.1014s/iter; left time: 459.8954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.85s\n",
      "Steps: 889 | Train Loss: 0.1331256 Vali Loss: 0.0433528 Test Loss: 0.0562732\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1245407\n",
      "\tspeed: 0.3449s/iter; left time: 1499.1492s\n",
      "\titers: 200, epoch: 6 | loss: 0.1211800\n",
      "\tspeed: 0.1014s/iter; left time: 430.6146s\n",
      "\titers: 300, epoch: 6 | loss: 0.1208557\n",
      "\tspeed: 0.1012s/iter; left time: 419.6084s\n",
      "\titers: 400, epoch: 6 | loss: 0.1311956\n",
      "\tspeed: 0.1011s/iter; left time: 409.2325s\n",
      "\titers: 500, epoch: 6 | loss: 0.1167630\n",
      "\tspeed: 0.1010s/iter; left time: 398.6753s\n",
      "\titers: 600, epoch: 6 | loss: 0.1123308\n",
      "\tspeed: 0.1013s/iter; left time: 389.7639s\n",
      "\titers: 700, epoch: 6 | loss: 0.1124836\n",
      "\tspeed: 0.1014s/iter; left time: 379.9339s\n",
      "\titers: 800, epoch: 6 | loss: 0.1127105\n",
      "\tspeed: 0.1014s/iter; left time: 369.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.27s\n",
      "Steps: 889 | Train Loss: 0.1209244 Vali Loss: 0.0455252 Test Loss: 0.0598614\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04434015229344368, rmse:0.2105710208415985, mae:0.1473398208618164, rse:0.7459896802902222\n",
      "Original data scale mse:38489120.0, rmse:6203.9599609375, mae:4120.31298828125, rse:0.309111088514328\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3404464\n",
      "\tspeed: 0.1038s/iter; left time: 912.4571s\n",
      "\titers: 200, epoch: 1 | loss: 0.3002555\n",
      "\tspeed: 0.1019s/iter; left time: 885.2175s\n",
      "\titers: 300, epoch: 1 | loss: 0.2712404\n",
      "\tspeed: 0.1017s/iter; left time: 873.7609s\n",
      "\titers: 400, epoch: 1 | loss: 0.2603263\n",
      "\tspeed: 0.1068s/iter; left time: 906.4480s\n",
      "\titers: 500, epoch: 1 | loss: 0.2265813\n",
      "\tspeed: 0.1058s/iter; left time: 888.1035s\n",
      "\titers: 600, epoch: 1 | loss: 0.2237435\n",
      "\tspeed: 0.1023s/iter; left time: 848.3759s\n",
      "\titers: 700, epoch: 1 | loss: 0.2114621\n",
      "\tspeed: 0.1021s/iter; left time: 836.2633s\n",
      "\titers: 800, epoch: 1 | loss: 0.2065192\n",
      "\tspeed: 0.1022s/iter; left time: 827.0849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.80s\n",
      "Steps: 889 | Train Loss: 0.2556601 Vali Loss: 0.0448885 Test Loss: 0.0524649\n",
      "Validation loss decreased (inf --> 0.044889).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2253740\n",
      "\tspeed: 0.3530s/iter; left time: 2789.3840s\n",
      "\titers: 200, epoch: 2 | loss: 0.2066349\n",
      "\tspeed: 0.1025s/iter; left time: 799.3444s\n",
      "\titers: 300, epoch: 2 | loss: 0.1799187\n",
      "\tspeed: 0.1017s/iter; left time: 782.9281s\n",
      "\titers: 400, epoch: 2 | loss: 0.1783092\n",
      "\tspeed: 0.1016s/iter; left time: 772.3652s\n",
      "\titers: 500, epoch: 2 | loss: 0.1809697\n",
      "\tspeed: 0.1017s/iter; left time: 762.7758s\n",
      "\titers: 600, epoch: 2 | loss: 0.1818963\n",
      "\tspeed: 0.1017s/iter; left time: 752.8030s\n",
      "\titers: 700, epoch: 2 | loss: 0.1834946\n",
      "\tspeed: 0.1015s/iter; left time: 741.2864s\n",
      "\titers: 800, epoch: 2 | loss: 0.1754887\n",
      "\tspeed: 0.1017s/iter; left time: 732.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.72s\n",
      "Steps: 889 | Train Loss: 0.1878062 Vali Loss: 0.0414471 Test Loss: 0.0491418\n",
      "Validation loss decreased (0.044889 --> 0.041447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1751232\n",
      "\tspeed: 0.3519s/iter; left time: 2467.6754s\n",
      "\titers: 200, epoch: 3 | loss: 0.1684553\n",
      "\tspeed: 0.1016s/iter; left time: 702.1468s\n",
      "\titers: 300, epoch: 3 | loss: 0.1789401\n",
      "\tspeed: 0.1014s/iter; left time: 690.7707s\n",
      "\titers: 400, epoch: 3 | loss: 0.1646640\n",
      "\tspeed: 0.1019s/iter; left time: 684.0133s\n",
      "\titers: 500, epoch: 3 | loss: 0.1577094\n",
      "\tspeed: 0.1043s/iter; left time: 689.6833s\n",
      "\titers: 600, epoch: 3 | loss: 0.1734572\n",
      "\tspeed: 0.1074s/iter; left time: 699.2828s\n",
      "\titers: 700, epoch: 3 | loss: 0.1514696\n",
      "\tspeed: 0.1016s/iter; left time: 651.2588s\n",
      "\titers: 800, epoch: 3 | loss: 0.1650498\n",
      "\tspeed: 0.1014s/iter; left time: 640.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.32s\n",
      "Steps: 889 | Train Loss: 0.1678110 Vali Loss: 0.0364978 Test Loss: 0.0447154\n",
      "Validation loss decreased (0.041447 --> 0.036498).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1617577\n",
      "\tspeed: 0.3486s/iter; left time: 2135.0506s\n",
      "\titers: 200, epoch: 4 | loss: 0.1518683\n",
      "\tspeed: 0.1015s/iter; left time: 611.3221s\n",
      "\titers: 300, epoch: 4 | loss: 0.1579919\n",
      "\tspeed: 0.1012s/iter; left time: 599.4919s\n",
      "\titers: 400, epoch: 4 | loss: 0.1498938\n",
      "\tspeed: 0.1013s/iter; left time: 589.7833s\n",
      "\titers: 500, epoch: 4 | loss: 0.1460329\n",
      "\tspeed: 0.1018s/iter; left time: 582.5783s\n",
      "\titers: 600, epoch: 4 | loss: 0.1269531\n",
      "\tspeed: 0.1014s/iter; left time: 570.0309s\n",
      "\titers: 700, epoch: 4 | loss: 0.1389209\n",
      "\tspeed: 0.1014s/iter; left time: 560.2167s\n",
      "\titers: 800, epoch: 4 | loss: 0.1444364\n",
      "\tspeed: 0.1016s/iter; left time: 550.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.44s\n",
      "Steps: 889 | Train Loss: 0.1471211 Vali Loss: 0.0434320 Test Loss: 0.0529540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1384399\n",
      "\tspeed: 0.3444s/iter; left time: 1802.9022s\n",
      "\titers: 200, epoch: 5 | loss: 0.1397000\n",
      "\tspeed: 0.1015s/iter; left time: 521.0247s\n",
      "\titers: 300, epoch: 5 | loss: 0.1398632\n",
      "\tspeed: 0.1014s/iter; left time: 510.4186s\n",
      "\titers: 400, epoch: 5 | loss: 0.1249702\n",
      "\tspeed: 0.1015s/iter; left time: 500.9839s\n",
      "\titers: 500, epoch: 5 | loss: 0.1250722\n",
      "\tspeed: 0.1015s/iter; left time: 490.5218s\n",
      "\titers: 600, epoch: 5 | loss: 0.1343551\n",
      "\tspeed: 0.1014s/iter; left time: 479.9577s\n",
      "\titers: 700, epoch: 5 | loss: 0.1401857\n",
      "\tspeed: 0.1017s/iter; left time: 471.2816s\n",
      "\titers: 800, epoch: 5 | loss: 0.1302380\n",
      "\tspeed: 0.1014s/iter; left time: 459.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.48s\n",
      "Steps: 889 | Train Loss: 0.1336244 Vali Loss: 0.0466640 Test Loss: 0.0583943\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1211683\n",
      "\tspeed: 0.3469s/iter; left time: 1507.7741s\n",
      "\titers: 200, epoch: 6 | loss: 0.1255175\n",
      "\tspeed: 0.1013s/iter; left time: 430.0271s\n",
      "\titers: 300, epoch: 6 | loss: 0.1202208\n",
      "\tspeed: 0.1013s/iter; left time: 420.1689s\n",
      "\titers: 400, epoch: 6 | loss: 0.1243150\n",
      "\tspeed: 0.1017s/iter; left time: 411.3655s\n",
      "\titers: 500, epoch: 6 | loss: 0.1226426\n",
      "\tspeed: 0.1013s/iter; left time: 399.9260s\n",
      "\titers: 600, epoch: 6 | loss: 0.1151162\n",
      "\tspeed: 0.1016s/iter; left time: 390.5615s\n",
      "\titers: 700, epoch: 6 | loss: 0.1095449\n",
      "\tspeed: 0.1019s/iter; left time: 381.8123s\n",
      "\titers: 800, epoch: 6 | loss: 0.1117611\n",
      "\tspeed: 0.1021s/iter; left time: 372.1159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.60s\n",
      "Steps: 889 | Train Loss: 0.1192161 Vali Loss: 0.0487978 Test Loss: 0.0581846\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04471543803811073, rmse:0.21146024763584137, mae:0.14908143877983093, rse:0.7491400241851807\n",
      "Original data scale mse:39429468.0, rmse:6279.28857421875, mae:4190.6279296875, rse:0.3128643333911896\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2292073\n",
      "\tspeed: 0.1213s/iter; left time: 1071.5867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1988064\n",
      "\tspeed: 0.0995s/iter; left time: 868.7851s\n",
      "\titers: 300, epoch: 1 | loss: 0.1905196\n",
      "\tspeed: 0.0995s/iter; left time: 858.6306s\n",
      "\titers: 400, epoch: 1 | loss: 0.1776907\n",
      "\tspeed: 0.0998s/iter; left time: 851.1023s\n",
      "\titers: 500, epoch: 1 | loss: 0.1735107\n",
      "\tspeed: 0.0995s/iter; left time: 839.0024s\n",
      "\titers: 600, epoch: 1 | loss: 0.1573161\n",
      "\tspeed: 0.1098s/iter; left time: 915.0079s\n",
      "\titers: 700, epoch: 1 | loss: 0.1488366\n",
      "\tspeed: 0.0996s/iter; left time: 820.0631s\n",
      "\titers: 800, epoch: 1 | loss: 0.1497791\n",
      "\tspeed: 0.0997s/iter; left time: 810.5721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.43s\n",
      "Steps: 893 | Train Loss: 0.1814019 Vali Loss: 0.1317607 Test Loss: 0.1386320\n",
      "Validation loss decreased (inf --> 0.131761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1609834\n",
      "\tspeed: 0.3421s/iter; left time: 2715.3510s\n",
      "\titers: 200, epoch: 2 | loss: 0.1257431\n",
      "\tspeed: 0.0995s/iter; left time: 780.1250s\n",
      "\titers: 300, epoch: 2 | loss: 0.1040097\n",
      "\tspeed: 0.0994s/iter; left time: 768.8813s\n",
      "\titers: 400, epoch: 2 | loss: 0.1123770\n",
      "\tspeed: 0.0990s/iter; left time: 756.2374s\n",
      "\titers: 500, epoch: 2 | loss: 0.1061517\n",
      "\tspeed: 0.0988s/iter; left time: 744.8584s\n",
      "\titers: 600, epoch: 2 | loss: 0.1000993\n",
      "\tspeed: 0.0989s/iter; left time: 735.3882s\n",
      "\titers: 700, epoch: 2 | loss: 0.1249921\n",
      "\tspeed: 0.0991s/iter; left time: 726.8723s\n",
      "\titers: 800, epoch: 2 | loss: 0.0995329\n",
      "\tspeed: 0.0991s/iter; left time: 717.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.74s\n",
      "Steps: 893 | Train Loss: 0.1219483 Vali Loss: 0.1105535 Test Loss: 0.1179964\n",
      "Validation loss decreased (0.131761 --> 0.110553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924571\n",
      "\tspeed: 0.3389s/iter; left time: 2387.9022s\n",
      "\titers: 200, epoch: 3 | loss: 0.1263756\n",
      "\tspeed: 0.0989s/iter; left time: 686.9274s\n",
      "\titers: 300, epoch: 3 | loss: 0.0905853\n",
      "\tspeed: 0.0990s/iter; left time: 677.4712s\n",
      "\titers: 400, epoch: 3 | loss: 0.1046256\n",
      "\tspeed: 0.0988s/iter; left time: 666.6031s\n",
      "\titers: 500, epoch: 3 | loss: 0.0949641\n",
      "\tspeed: 0.0990s/iter; left time: 657.5986s\n",
      "\titers: 600, epoch: 3 | loss: 0.1006824\n",
      "\tspeed: 0.0985s/iter; left time: 644.5482s\n",
      "\titers: 700, epoch: 3 | loss: 0.0839154\n",
      "\tspeed: 0.0987s/iter; left time: 635.8227s\n",
      "\titers: 800, epoch: 3 | loss: 0.0854259\n",
      "\tspeed: 0.1068s/iter; left time: 677.8072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.26s\n",
      "Steps: 893 | Train Loss: 0.0982903 Vali Loss: 0.1137577 Test Loss: 0.1198356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0877667\n",
      "\tspeed: 0.3362s/iter; left time: 2068.0870s\n",
      "\titers: 200, epoch: 4 | loss: 0.1018494\n",
      "\tspeed: 0.0987s/iter; left time: 597.1797s\n",
      "\titers: 300, epoch: 4 | loss: 0.0854650\n",
      "\tspeed: 0.0992s/iter; left time: 590.1479s\n",
      "\titers: 400, epoch: 4 | loss: 0.0883080\n",
      "\tspeed: 0.0991s/iter; left time: 579.9041s\n",
      "\titers: 500, epoch: 4 | loss: 0.0907238\n",
      "\tspeed: 0.0990s/iter; left time: 569.5202s\n",
      "\titers: 600, epoch: 4 | loss: 0.0940479\n",
      "\tspeed: 0.0987s/iter; left time: 557.7555s\n",
      "\titers: 700, epoch: 4 | loss: 0.0931534\n",
      "\tspeed: 0.0990s/iter; left time: 549.8513s\n",
      "\titers: 800, epoch: 4 | loss: 0.0919886\n",
      "\tspeed: 0.0988s/iter; left time: 538.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.54s\n",
      "Steps: 893 | Train Loss: 0.0932401 Vali Loss: 0.1030065 Test Loss: 0.1073363\n",
      "Validation loss decreased (0.110553 --> 0.103006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0949704\n",
      "\tspeed: 0.3388s/iter; left time: 1781.5880s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797919\n",
      "\tspeed: 0.0989s/iter; left time: 510.4704s\n",
      "\titers: 300, epoch: 5 | loss: 0.0731735\n",
      "\tspeed: 0.0990s/iter; left time: 501.0815s\n",
      "\titers: 400, epoch: 5 | loss: 0.0808368\n",
      "\tspeed: 0.0990s/iter; left time: 490.9208s\n",
      "\titers: 500, epoch: 5 | loss: 0.0856495\n",
      "\tspeed: 0.0989s/iter; left time: 480.3299s\n",
      "\titers: 600, epoch: 5 | loss: 0.0910785\n",
      "\tspeed: 0.0989s/iter; left time: 470.8798s\n",
      "\titers: 700, epoch: 5 | loss: 0.0862894\n",
      "\tspeed: 0.0986s/iter; left time: 459.2980s\n",
      "\titers: 800, epoch: 5 | loss: 0.0915499\n",
      "\tspeed: 0.0988s/iter; left time: 450.5476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.57s\n",
      "Steps: 893 | Train Loss: 0.0884393 Vali Loss: 0.0975299 Test Loss: 0.1042703\n",
      "Validation loss decreased (0.103006 --> 0.097530).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0853408\n",
      "\tspeed: 0.3406s/iter; left time: 1486.9093s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042048\n",
      "\tspeed: 0.0984s/iter; left time: 419.5962s\n",
      "\titers: 300, epoch: 6 | loss: 0.0926579\n",
      "\tspeed: 0.0989s/iter; left time: 411.8116s\n",
      "\titers: 400, epoch: 6 | loss: 0.0723715\n",
      "\tspeed: 0.0991s/iter; left time: 402.9517s\n",
      "\titers: 500, epoch: 6 | loss: 0.0890285\n",
      "\tspeed: 0.0988s/iter; left time: 391.8172s\n",
      "\titers: 600, epoch: 6 | loss: 0.0769851\n",
      "\tspeed: 0.0989s/iter; left time: 382.5062s\n",
      "\titers: 700, epoch: 6 | loss: 0.0933018\n",
      "\tspeed: 0.0989s/iter; left time: 372.3185s\n",
      "\titers: 800, epoch: 6 | loss: 0.0810298\n",
      "\tspeed: 0.0991s/iter; left time: 363.3176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:28.48s\n",
      "Steps: 893 | Train Loss: 0.0844768 Vali Loss: 0.0993735 Test Loss: 0.1060721\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0705387\n",
      "\tspeed: 0.3362s/iter; left time: 1167.4818s\n",
      "\titers: 200, epoch: 7 | loss: 0.0766590\n",
      "\tspeed: 0.0994s/iter; left time: 335.2789s\n",
      "\titers: 300, epoch: 7 | loss: 0.0852005\n",
      "\tspeed: 0.0989s/iter; left time: 323.8388s\n",
      "\titers: 400, epoch: 7 | loss: 0.0762255\n",
      "\tspeed: 0.0984s/iter; left time: 312.0803s\n",
      "\titers: 500, epoch: 7 | loss: 0.0813481\n",
      "\tspeed: 0.0989s/iter; left time: 303.9322s\n",
      "\titers: 600, epoch: 7 | loss: 0.0705123\n",
      "\tspeed: 0.0990s/iter; left time: 294.3101s\n",
      "\titers: 700, epoch: 7 | loss: 0.0787565\n",
      "\tspeed: 0.0989s/iter; left time: 284.2414s\n",
      "\titers: 800, epoch: 7 | loss: 0.0790704\n",
      "\tspeed: 0.0990s/iter; left time: 274.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.58s\n",
      "Steps: 893 | Train Loss: 0.0779480 Vali Loss: 0.0992495 Test Loss: 0.1118831\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0763997\n",
      "\tspeed: 0.3369s/iter; left time: 869.1141s\n",
      "\titers: 200, epoch: 8 | loss: 0.0777500\n",
      "\tspeed: 0.0985s/iter; left time: 244.3821s\n",
      "\titers: 300, epoch: 8 | loss: 0.0871314\n",
      "\tspeed: 0.0991s/iter; left time: 235.8534s\n",
      "\titers: 400, epoch: 8 | loss: 0.0659322\n",
      "\tspeed: 0.0989s/iter; left time: 225.5211s\n",
      "\titers: 500, epoch: 8 | loss: 0.0716916\n",
      "\tspeed: 0.0987s/iter; left time: 215.1817s\n",
      "\titers: 600, epoch: 8 | loss: 0.0712011\n",
      "\tspeed: 0.0987s/iter; left time: 205.2171s\n",
      "\titers: 700, epoch: 8 | loss: 0.0746020\n",
      "\tspeed: 0.0988s/iter; left time: 195.5928s\n",
      "\titers: 800, epoch: 8 | loss: 0.0757519\n",
      "\tspeed: 0.0990s/iter; left time: 186.1301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.49s\n",
      "Steps: 893 | Train Loss: 0.0748978 Vali Loss: 0.0962306 Test Loss: 0.1032414\n",
      "Validation loss decreased (0.097530 --> 0.096231).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0784058\n",
      "\tspeed: 0.3380s/iter; left time: 570.2146s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757586\n",
      "\tspeed: 0.0987s/iter; left time: 156.5606s\n",
      "\titers: 300, epoch: 9 | loss: 0.0664227\n",
      "\tspeed: 0.0987s/iter; left time: 146.8186s\n",
      "\titers: 400, epoch: 9 | loss: 0.0721452\n",
      "\tspeed: 0.0992s/iter; left time: 137.5685s\n",
      "\titers: 500, epoch: 9 | loss: 0.0703225\n",
      "\tspeed: 0.0989s/iter; left time: 127.2818s\n",
      "\titers: 600, epoch: 9 | loss: 0.0633610\n",
      "\tspeed: 0.0990s/iter; left time: 117.4738s\n",
      "\titers: 700, epoch: 9 | loss: 0.0727269\n",
      "\tspeed: 0.0992s/iter; left time: 107.7895s\n",
      "\titers: 800, epoch: 9 | loss: 0.0643247\n",
      "\tspeed: 0.0988s/iter; left time: 97.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:28.56s\n",
      "Steps: 893 | Train Loss: 0.0719157 Vali Loss: 0.0964786 Test Loss: 0.1044543\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0646911\n",
      "\tspeed: 0.3365s/iter; left time: 267.1850s\n",
      "\titers: 200, epoch: 10 | loss: 0.0697292\n",
      "\tspeed: 0.0992s/iter; left time: 68.8216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0643499\n",
      "\tspeed: 0.0989s/iter; left time: 58.7199s\n",
      "\titers: 400, epoch: 10 | loss: 0.0660228\n",
      "\tspeed: 0.0992s/iter; left time: 49.0035s\n",
      "\titers: 500, epoch: 10 | loss: 0.0706059\n",
      "\tspeed: 0.0987s/iter; left time: 38.8727s\n",
      "\titers: 600, epoch: 10 | loss: 0.0751768\n",
      "\tspeed: 0.0992s/iter; left time: 29.1578s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724675\n",
      "\tspeed: 0.0990s/iter; left time: 19.2091s\n",
      "\titers: 800, epoch: 10 | loss: 0.0638413\n",
      "\tspeed: 0.0989s/iter; left time: 9.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:28.62s\n",
      "Steps: 893 | Train Loss: 0.0687550 Vali Loss: 0.0993372 Test Loss: 0.1119688\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027019083499908447, rmse:0.16437482833862305, mae:0.10324142873287201, rse:0.5804941058158875\n",
      "Original data scale mse:19359624.0, rmse:4399.95703125, mae:2728.831298828125, rse:0.21877475082874298\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2289343\n",
      "\tspeed: 0.1021s/iter; left time: 901.6049s\n",
      "\titers: 200, epoch: 1 | loss: 0.2143202\n",
      "\tspeed: 0.0999s/iter; left time: 872.2704s\n",
      "\titers: 300, epoch: 1 | loss: 0.2100070\n",
      "\tspeed: 0.1004s/iter; left time: 866.1679s\n",
      "\titers: 400, epoch: 1 | loss: 0.1792823\n",
      "\tspeed: 0.0998s/iter; left time: 851.4509s\n",
      "\titers: 500, epoch: 1 | loss: 0.1703821\n",
      "\tspeed: 0.0999s/iter; left time: 842.3494s\n",
      "\titers: 600, epoch: 1 | loss: 0.1588728\n",
      "\tspeed: 0.1001s/iter; left time: 833.9242s\n",
      "\titers: 700, epoch: 1 | loss: 0.1433534\n",
      "\tspeed: 0.0999s/iter; left time: 822.3421s\n",
      "\titers: 800, epoch: 1 | loss: 0.1345008\n",
      "\tspeed: 0.1000s/iter; left time: 812.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.56s\n",
      "Steps: 893 | Train Loss: 0.1849599 Vali Loss: 0.1296813 Test Loss: 0.1348021\n",
      "Validation loss decreased (inf --> 0.129681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1692795\n",
      "\tspeed: 0.3415s/iter; left time: 2710.9171s\n",
      "\titers: 200, epoch: 2 | loss: 0.1274398\n",
      "\tspeed: 0.0996s/iter; left time: 780.4056s\n",
      "\titers: 300, epoch: 2 | loss: 0.1154247\n",
      "\tspeed: 0.1045s/iter; left time: 808.9233s\n",
      "\titers: 400, epoch: 2 | loss: 0.1033195\n",
      "\tspeed: 0.0997s/iter; left time: 761.7169s\n",
      "\titers: 500, epoch: 2 | loss: 0.1182129\n",
      "\tspeed: 0.0992s/iter; left time: 748.0143s\n",
      "\titers: 600, epoch: 2 | loss: 0.1032981\n",
      "\tspeed: 0.0993s/iter; left time: 738.7672s\n",
      "\titers: 700, epoch: 2 | loss: 0.0994728\n",
      "\tspeed: 0.0993s/iter; left time: 728.6299s\n",
      "\titers: 800, epoch: 2 | loss: 0.1015295\n",
      "\tspeed: 0.0991s/iter; left time: 717.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.44s\n",
      "Steps: 893 | Train Loss: 0.1208889 Vali Loss: 0.1106298 Test Loss: 0.1123332\n",
      "Validation loss decreased (0.129681 --> 0.110630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0987163\n",
      "\tspeed: 0.3430s/iter; left time: 2416.0875s\n",
      "\titers: 200, epoch: 3 | loss: 0.1122702\n",
      "\tspeed: 0.0989s/iter; left time: 686.9674s\n",
      "\titers: 300, epoch: 3 | loss: 0.0980768\n",
      "\tspeed: 0.0989s/iter; left time: 676.6864s\n",
      "\titers: 400, epoch: 3 | loss: 0.0832454\n",
      "\tspeed: 0.0989s/iter; left time: 667.1440s\n",
      "\titers: 500, epoch: 3 | loss: 0.1334562\n",
      "\tspeed: 0.0990s/iter; left time: 658.0559s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914965\n",
      "\tspeed: 0.0987s/iter; left time: 645.7446s\n",
      "\titers: 700, epoch: 3 | loss: 0.1079113\n",
      "\tspeed: 0.0988s/iter; left time: 636.9993s\n",
      "\titers: 800, epoch: 3 | loss: 0.0938518\n",
      "\tspeed: 0.0994s/iter; left time: 630.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:28.65s\n",
      "Steps: 893 | Train Loss: 0.0973017 Vali Loss: 0.1033081 Test Loss: 0.1070807\n",
      "Validation loss decreased (0.110630 --> 0.103308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0950336\n",
      "\tspeed: 0.3409s/iter; left time: 2097.4230s\n",
      "\titers: 200, epoch: 4 | loss: 0.1065823\n",
      "\tspeed: 0.0987s/iter; left time: 597.5896s\n",
      "\titers: 300, epoch: 4 | loss: 0.0867369\n",
      "\tspeed: 0.0994s/iter; left time: 591.4700s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832504\n",
      "\tspeed: 0.1038s/iter; left time: 607.4226s\n",
      "\titers: 500, epoch: 4 | loss: 0.0855674\n",
      "\tspeed: 0.0989s/iter; left time: 568.8759s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902407\n",
      "\tspeed: 0.0987s/iter; left time: 558.0888s\n",
      "\titers: 700, epoch: 4 | loss: 0.0850996\n",
      "\tspeed: 0.0988s/iter; left time: 548.7655s\n",
      "\titers: 800, epoch: 4 | loss: 0.1005058\n",
      "\tspeed: 0.0987s/iter; left time: 538.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.04s\n",
      "Steps: 893 | Train Loss: 0.0925447 Vali Loss: 0.1078629 Test Loss: 0.1111314\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0875196\n",
      "\tspeed: 0.3378s/iter; left time: 1776.7516s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790974\n",
      "\tspeed: 0.0988s/iter; left time: 509.8210s\n",
      "\titers: 300, epoch: 5 | loss: 0.0919155\n",
      "\tspeed: 0.0991s/iter; left time: 501.5278s\n",
      "\titers: 400, epoch: 5 | loss: 0.0891245\n",
      "\tspeed: 0.0990s/iter; left time: 490.9168s\n",
      "\titers: 500, epoch: 5 | loss: 0.0953984\n",
      "\tspeed: 0.0990s/iter; left time: 480.9078s\n",
      "\titers: 600, epoch: 5 | loss: 0.0984171\n",
      "\tspeed: 0.0987s/iter; left time: 469.8401s\n",
      "\titers: 700, epoch: 5 | loss: 0.0729400\n",
      "\tspeed: 0.0989s/iter; left time: 460.6168s\n",
      "\titers: 800, epoch: 5 | loss: 0.0928185\n",
      "\tspeed: 0.0988s/iter; left time: 450.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.57s\n",
      "Steps: 893 | Train Loss: 0.0893169 Vali Loss: 0.1171769 Test Loss: 0.1204297\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0898273\n",
      "\tspeed: 0.3393s/iter; left time: 1481.5943s\n",
      "\titers: 200, epoch: 6 | loss: 0.0749131\n",
      "\tspeed: 0.0985s/iter; left time: 420.0170s\n",
      "\titers: 300, epoch: 6 | loss: 0.0845870\n",
      "\tspeed: 0.0988s/iter; left time: 411.7015s\n",
      "\titers: 400, epoch: 6 | loss: 0.0820411\n",
      "\tspeed: 0.0990s/iter; left time: 402.4105s\n",
      "\titers: 500, epoch: 6 | loss: 0.0880788\n",
      "\tspeed: 0.0994s/iter; left time: 394.2846s\n",
      "\titers: 600, epoch: 6 | loss: 0.0891764\n",
      "\tspeed: 0.1053s/iter; left time: 407.0717s\n",
      "\titers: 700, epoch: 6 | loss: 0.0834054\n",
      "\tspeed: 0.0990s/iter; left time: 372.7720s\n",
      "\titers: 800, epoch: 6 | loss: 0.0787018\n",
      "\tspeed: 0.0993s/iter; left time: 364.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.35s\n",
      "Steps: 893 | Train Loss: 0.0825816 Vali Loss: 0.0952076 Test Loss: 0.0995796\n",
      "Validation loss decreased (0.103308 --> 0.095208).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0755711\n",
      "\tspeed: 0.3417s/iter; left time: 1186.7832s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794233\n",
      "\tspeed: 0.0989s/iter; left time: 333.7214s\n",
      "\titers: 300, epoch: 7 | loss: 0.0815718\n",
      "\tspeed: 0.0992s/iter; left time: 324.6616s\n",
      "\titers: 400, epoch: 7 | loss: 0.0752372\n",
      "\tspeed: 0.0992s/iter; left time: 314.8601s\n",
      "\titers: 500, epoch: 7 | loss: 0.0741354\n",
      "\tspeed: 0.0990s/iter; left time: 304.1092s\n",
      "\titers: 600, epoch: 7 | loss: 0.0759419\n",
      "\tspeed: 0.0994s/iter; left time: 295.3882s\n",
      "\titers: 700, epoch: 7 | loss: 0.0815353\n",
      "\tspeed: 0.0987s/iter; left time: 283.4790s\n",
      "\titers: 800, epoch: 7 | loss: 0.0685812\n",
      "\tspeed: 0.0988s/iter; left time: 273.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.66s\n",
      "Steps: 893 | Train Loss: 0.0767084 Vali Loss: 0.0966136 Test Loss: 0.1021578\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728520\n",
      "\tspeed: 0.3368s/iter; left time: 868.9360s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810004\n",
      "\tspeed: 0.0990s/iter; left time: 245.4829s\n",
      "\titers: 300, epoch: 8 | loss: 0.0842951\n",
      "\tspeed: 0.0988s/iter; left time: 235.1953s\n",
      "\titers: 400, epoch: 8 | loss: 0.0845143\n",
      "\tspeed: 0.0989s/iter; left time: 225.5484s\n",
      "\titers: 500, epoch: 8 | loss: 0.0752154\n",
      "\tspeed: 0.0988s/iter; left time: 215.4338s\n",
      "\titers: 600, epoch: 8 | loss: 0.0821099\n",
      "\tspeed: 0.0992s/iter; left time: 206.2791s\n",
      "\titers: 700, epoch: 8 | loss: 0.0756243\n",
      "\tspeed: 0.0991s/iter; left time: 196.2714s\n",
      "\titers: 800, epoch: 8 | loss: 0.0743818\n",
      "\tspeed: 0.0992s/iter; left time: 186.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.64s\n",
      "Steps: 893 | Train Loss: 0.0747838 Vali Loss: 0.0970665 Test Loss: 0.1047419\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0619247\n",
      "\tspeed: 0.3369s/iter; left time: 568.4281s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626060\n",
      "\tspeed: 0.0990s/iter; left time: 157.1294s\n",
      "\titers: 300, epoch: 9 | loss: 0.0809061\n",
      "\tspeed: 0.0988s/iter; left time: 146.9135s\n",
      "\titers: 400, epoch: 9 | loss: 0.0662113\n",
      "\tspeed: 0.0989s/iter; left time: 137.2239s\n",
      "\titers: 500, epoch: 9 | loss: 0.0702679\n",
      "\tspeed: 0.0989s/iter; left time: 127.3418s\n",
      "\titers: 600, epoch: 9 | loss: 0.0658615\n",
      "\tspeed: 0.0988s/iter; left time: 117.2755s\n",
      "\titers: 700, epoch: 9 | loss: 0.0623687\n",
      "\tspeed: 0.0991s/iter; left time: 107.6977s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671080\n",
      "\tspeed: 0.0987s/iter; left time: 97.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:28.61s\n",
      "Steps: 893 | Train Loss: 0.0715014 Vali Loss: 0.0987344 Test Loss: 0.1062102\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024862198159098625, rmse:0.1576775163412094, mae:0.09957965463399887, rse:0.5568423867225647\n",
      "Original data scale mse:18901044.0, rmse:4347.533203125, mae:2686.691650390625, rse:0.2161681205034256\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2397192\n",
      "\tspeed: 0.1229s/iter; left time: 1083.0449s\n",
      "\titers: 200, epoch: 1 | loss: 0.2065110\n",
      "\tspeed: 0.1008s/iter; left time: 877.6677s\n",
      "\titers: 300, epoch: 1 | loss: 0.2038824\n",
      "\tspeed: 0.1009s/iter; left time: 868.8380s\n",
      "\titers: 400, epoch: 1 | loss: 0.1806380\n",
      "\tspeed: 0.1010s/iter; left time: 859.5839s\n",
      "\titers: 500, epoch: 1 | loss: 0.1801859\n",
      "\tspeed: 0.1013s/iter; left time: 852.1528s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575187\n",
      "\tspeed: 0.1010s/iter; left time: 839.4769s\n",
      "\titers: 700, epoch: 1 | loss: 0.1653003\n",
      "\tspeed: 0.1009s/iter; left time: 828.4240s\n",
      "\titers: 800, epoch: 1 | loss: 0.1555918\n",
      "\tspeed: 0.1009s/iter; left time: 818.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.37s\n",
      "Steps: 891 | Train Loss: 0.1908029 Vali Loss: 0.1614973 Test Loss: 0.1750467\n",
      "Validation loss decreased (inf --> 0.161497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1419446\n",
      "\tspeed: 0.3517s/iter; left time: 2785.0854s\n",
      "\titers: 200, epoch: 2 | loss: 0.1347740\n",
      "\tspeed: 0.1012s/iter; left time: 791.3042s\n",
      "\titers: 300, epoch: 2 | loss: 0.1322251\n",
      "\tspeed: 0.1010s/iter; left time: 779.7389s\n",
      "\titers: 400, epoch: 2 | loss: 0.1186568\n",
      "\tspeed: 0.1010s/iter; left time: 769.5986s\n",
      "\titers: 500, epoch: 2 | loss: 0.1171819\n",
      "\tspeed: 0.1007s/iter; left time: 757.4078s\n",
      "\titers: 600, epoch: 2 | loss: 0.1300116\n",
      "\tspeed: 0.1010s/iter; left time: 749.4084s\n",
      "\titers: 700, epoch: 2 | loss: 0.1218010\n",
      "\tspeed: 0.1008s/iter; left time: 738.1254s\n",
      "\titers: 800, epoch: 2 | loss: 0.1139661\n",
      "\tspeed: 0.1002s/iter; left time: 723.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.05s\n",
      "Steps: 891 | Train Loss: 0.1326921 Vali Loss: 0.1339702 Test Loss: 0.1491182\n",
      "Validation loss decreased (0.161497 --> 0.133970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1185480\n",
      "\tspeed: 0.3447s/iter; left time: 2423.0388s\n",
      "\titers: 200, epoch: 3 | loss: 0.1154652\n",
      "\tspeed: 0.1008s/iter; left time: 698.2694s\n",
      "\titers: 300, epoch: 3 | loss: 0.1163591\n",
      "\tspeed: 0.1006s/iter; left time: 686.8880s\n",
      "\titers: 400, epoch: 3 | loss: 0.1154384\n",
      "\tspeed: 0.1007s/iter; left time: 677.6534s\n",
      "\titers: 500, epoch: 3 | loss: 0.1018013\n",
      "\tspeed: 0.1005s/iter; left time: 666.0363s\n",
      "\titers: 600, epoch: 3 | loss: 0.1106702\n",
      "\tspeed: 0.1004s/iter; left time: 655.7334s\n",
      "\titers: 700, epoch: 3 | loss: 0.1272781\n",
      "\tspeed: 0.1007s/iter; left time: 647.4422s\n",
      "\titers: 800, epoch: 3 | loss: 0.1013503\n",
      "\tspeed: 0.1004s/iter; left time: 635.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.80s\n",
      "Steps: 891 | Train Loss: 0.1139189 Vali Loss: 0.1360290 Test Loss: 0.1505660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190880\n",
      "\tspeed: 0.3420s/iter; left time: 2099.4435s\n",
      "\titers: 200, epoch: 4 | loss: 0.1428114\n",
      "\tspeed: 0.1008s/iter; left time: 608.7407s\n",
      "\titers: 300, epoch: 4 | loss: 0.1025546\n",
      "\tspeed: 0.1007s/iter; left time: 597.7752s\n",
      "\titers: 400, epoch: 4 | loss: 0.1173676\n",
      "\tspeed: 0.1007s/iter; left time: 587.7265s\n",
      "\titers: 500, epoch: 4 | loss: 0.1150932\n",
      "\tspeed: 0.1005s/iter; left time: 576.9114s\n",
      "\titers: 600, epoch: 4 | loss: 0.1151950\n",
      "\tspeed: 0.1008s/iter; left time: 568.4391s\n",
      "\titers: 700, epoch: 4 | loss: 0.1051176\n",
      "\tspeed: 0.1006s/iter; left time: 557.0081s\n",
      "\titers: 800, epoch: 4 | loss: 0.1034084\n",
      "\tspeed: 0.1008s/iter; left time: 548.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.83s\n",
      "Steps: 891 | Train Loss: 0.1095265 Vali Loss: 0.1335754 Test Loss: 0.1483816\n",
      "Validation loss decreased (0.133970 --> 0.133575).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0949231\n",
      "\tspeed: 0.3471s/iter; left time: 1821.2752s\n",
      "\titers: 200, epoch: 5 | loss: 0.0960537\n",
      "\tspeed: 0.1007s/iter; left time: 518.2646s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986129\n",
      "\tspeed: 0.1003s/iter; left time: 505.9825s\n",
      "\titers: 400, epoch: 5 | loss: 0.1005731\n",
      "\tspeed: 0.1006s/iter; left time: 497.6815s\n",
      "\titers: 500, epoch: 5 | loss: 0.1006241\n",
      "\tspeed: 0.1008s/iter; left time: 488.7005s\n",
      "\titers: 600, epoch: 5 | loss: 0.1049619\n",
      "\tspeed: 0.1007s/iter; left time: 478.2348s\n",
      "\titers: 700, epoch: 5 | loss: 0.1042803\n",
      "\tspeed: 0.1007s/iter; left time: 468.1235s\n",
      "\titers: 800, epoch: 5 | loss: 0.0997868\n",
      "\tspeed: 0.1005s/iter; left time: 456.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.83s\n",
      "Steps: 891 | Train Loss: 0.1008562 Vali Loss: 0.1344455 Test Loss: 0.1440922\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0907936\n",
      "\tspeed: 0.3422s/iter; left time: 1490.6619s\n",
      "\titers: 200, epoch: 6 | loss: 0.0969139\n",
      "\tspeed: 0.1002s/iter; left time: 426.6373s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902574\n",
      "\tspeed: 0.1003s/iter; left time: 416.8961s\n",
      "\titers: 400, epoch: 6 | loss: 0.0884402\n",
      "\tspeed: 0.1008s/iter; left time: 408.8232s\n",
      "\titers: 500, epoch: 6 | loss: 0.0849023\n",
      "\tspeed: 0.1010s/iter; left time: 399.7441s\n",
      "\titers: 600, epoch: 6 | loss: 0.0943049\n",
      "\tspeed: 0.1005s/iter; left time: 387.6174s\n",
      "\titers: 700, epoch: 6 | loss: 0.0929298\n",
      "\tspeed: 0.1006s/iter; left time: 378.0032s\n",
      "\titers: 800, epoch: 6 | loss: 0.0880411\n",
      "\tspeed: 0.1005s/iter; left time: 367.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.83s\n",
      "Steps: 891 | Train Loss: 0.0899120 Vali Loss: 0.1328725 Test Loss: 0.1464849\n",
      "Validation loss decreased (0.133575 --> 0.132872).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787447\n",
      "\tspeed: 0.3497s/iter; left time: 1211.7279s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800088\n",
      "\tspeed: 0.1005s/iter; left time: 338.0310s\n",
      "\titers: 300, epoch: 7 | loss: 0.0830061\n",
      "\tspeed: 0.1007s/iter; left time: 328.8440s\n",
      "\titers: 400, epoch: 7 | loss: 0.0829217\n",
      "\tspeed: 0.1002s/iter; left time: 317.2811s\n",
      "\titers: 500, epoch: 7 | loss: 0.0818865\n",
      "\tspeed: 0.1001s/iter; left time: 306.7791s\n",
      "\titers: 600, epoch: 7 | loss: 0.0806457\n",
      "\tspeed: 0.1005s/iter; left time: 297.9204s\n",
      "\titers: 700, epoch: 7 | loss: 0.0784802\n",
      "\tspeed: 0.1005s/iter; left time: 288.0484s\n",
      "\titers: 800, epoch: 7 | loss: 0.0775431\n",
      "\tspeed: 0.1005s/iter; left time: 277.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:29.71s\n",
      "Steps: 891 | Train Loss: 0.0796611 Vali Loss: 0.1358465 Test Loss: 0.1501063\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0667976\n",
      "\tspeed: 0.3675s/iter; left time: 945.9494s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833603\n",
      "\tspeed: 0.1005s/iter; left time: 248.6365s\n",
      "\titers: 300, epoch: 8 | loss: 0.0681193\n",
      "\tspeed: 0.1006s/iter; left time: 238.8130s\n",
      "\titers: 400, epoch: 8 | loss: 0.0687775\n",
      "\tspeed: 0.1006s/iter; left time: 228.8024s\n",
      "\titers: 500, epoch: 8 | loss: 0.0741098\n",
      "\tspeed: 0.1003s/iter; left time: 218.0824s\n",
      "\titers: 600, epoch: 8 | loss: 0.0687745\n",
      "\tspeed: 0.1003s/iter; left time: 208.1192s\n",
      "\titers: 700, epoch: 8 | loss: 0.0775179\n",
      "\tspeed: 0.1004s/iter; left time: 198.1524s\n",
      "\titers: 800, epoch: 8 | loss: 0.0742499\n",
      "\tspeed: 0.1004s/iter; left time: 188.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:29.82s\n",
      "Steps: 891 | Train Loss: 0.0726016 Vali Loss: 0.1370009 Test Loss: 0.1558739\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0732721\n",
      "\tspeed: 0.3472s/iter; left time: 584.2736s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705487\n",
      "\tspeed: 0.1005s/iter; left time: 159.1519s\n",
      "\titers: 300, epoch: 9 | loss: 0.0610659\n",
      "\tspeed: 0.1006s/iter; left time: 149.1711s\n",
      "\titers: 400, epoch: 9 | loss: 0.0685035\n",
      "\tspeed: 0.1006s/iter; left time: 139.1410s\n",
      "\titers: 500, epoch: 9 | loss: 0.0679642\n",
      "\tspeed: 0.1005s/iter; left time: 128.9637s\n",
      "\titers: 600, epoch: 9 | loss: 0.0643893\n",
      "\tspeed: 0.1007s/iter; left time: 119.0790s\n",
      "\titers: 700, epoch: 9 | loss: 0.0625431\n",
      "\tspeed: 0.1003s/iter; left time: 108.6390s\n",
      "\titers: 800, epoch: 9 | loss: 0.0770260\n",
      "\tspeed: 0.1005s/iter; left time: 98.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:29.85s\n",
      "Steps: 891 | Train Loss: 0.0665107 Vali Loss: 0.1356861 Test Loss: 0.1515146\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04956701025366783, rmse:0.22263649106025696, mae:0.14648491144180298, rse:0.7884008884429932\n",
      "Original data scale mse:38852912.0, rmse:6233.21044921875, mae:3966.372802734375, rse:0.3104161322116852\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2298145\n",
      "\tspeed: 0.1032s/iter; left time: 909.6039s\n",
      "\titers: 200, epoch: 1 | loss: 0.2055642\n",
      "\tspeed: 0.1008s/iter; left time: 877.7645s\n",
      "\titers: 300, epoch: 1 | loss: 0.2120944\n",
      "\tspeed: 0.1008s/iter; left time: 868.2524s\n",
      "\titers: 400, epoch: 1 | loss: 0.1969031\n",
      "\tspeed: 0.1013s/iter; left time: 862.1082s\n",
      "\titers: 500, epoch: 1 | loss: 0.1599426\n",
      "\tspeed: 0.1009s/iter; left time: 848.5114s\n",
      "\titers: 600, epoch: 1 | loss: 0.1821941\n",
      "\tspeed: 0.1011s/iter; left time: 840.3326s\n",
      "\titers: 700, epoch: 1 | loss: 0.1685472\n",
      "\tspeed: 0.1009s/iter; left time: 828.3045s\n",
      "\titers: 800, epoch: 1 | loss: 0.1524158\n",
      "\tspeed: 0.1006s/iter; left time: 816.3047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.20s\n",
      "Steps: 891 | Train Loss: 0.1912920 Vali Loss: 0.1582104 Test Loss: 0.1702184\n",
      "Validation loss decreased (inf --> 0.158210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1393150\n",
      "\tspeed: 0.3500s/iter; left time: 2771.7421s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364069\n",
      "\tspeed: 0.1012s/iter; left time: 791.0622s\n",
      "\titers: 300, epoch: 2 | loss: 0.1308155\n",
      "\tspeed: 0.1007s/iter; left time: 777.5056s\n",
      "\titers: 400, epoch: 2 | loss: 0.1202693\n",
      "\tspeed: 0.1009s/iter; left time: 768.5333s\n",
      "\titers: 500, epoch: 2 | loss: 0.1198138\n",
      "\tspeed: 0.1008s/iter; left time: 757.9295s\n",
      "\titers: 600, epoch: 2 | loss: 0.1130483\n",
      "\tspeed: 0.1009s/iter; left time: 748.8317s\n",
      "\titers: 700, epoch: 2 | loss: 0.1046654\n",
      "\tspeed: 0.1006s/iter; left time: 736.6395s\n",
      "\titers: 800, epoch: 2 | loss: 0.1118513\n",
      "\tspeed: 0.1007s/iter; left time: 726.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.03s\n",
      "Steps: 891 | Train Loss: 0.1331687 Vali Loss: 0.1355421 Test Loss: 0.1435478\n",
      "Validation loss decreased (0.158210 --> 0.135542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1235423\n",
      "\tspeed: 0.3460s/iter; left time: 2431.7085s\n",
      "\titers: 200, epoch: 3 | loss: 0.1194293\n",
      "\tspeed: 0.1063s/iter; left time: 736.6291s\n",
      "\titers: 300, epoch: 3 | loss: 0.1116619\n",
      "\tspeed: 0.1003s/iter; left time: 684.6502s\n",
      "\titers: 400, epoch: 3 | loss: 0.1154796\n",
      "\tspeed: 0.1009s/iter; left time: 678.7269s\n",
      "\titers: 500, epoch: 3 | loss: 0.1047079\n",
      "\tspeed: 0.1005s/iter; left time: 665.9806s\n",
      "\titers: 600, epoch: 3 | loss: 0.1161982\n",
      "\tspeed: 0.1005s/iter; left time: 656.2170s\n",
      "\titers: 700, epoch: 3 | loss: 0.1124992\n",
      "\tspeed: 0.1004s/iter; left time: 645.7239s\n",
      "\titers: 800, epoch: 3 | loss: 0.1212164\n",
      "\tspeed: 0.1002s/iter; left time: 634.1671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.27s\n",
      "Steps: 891 | Train Loss: 0.1162380 Vali Loss: 0.1345640 Test Loss: 0.1490825\n",
      "Validation loss decreased (0.135542 --> 0.134564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016894\n",
      "\tspeed: 0.3464s/iter; left time: 2125.9044s\n",
      "\titers: 200, epoch: 4 | loss: 0.1157226\n",
      "\tspeed: 0.1001s/iter; left time: 604.6863s\n",
      "\titers: 300, epoch: 4 | loss: 0.1039916\n",
      "\tspeed: 0.1006s/iter; left time: 597.6578s\n",
      "\titers: 400, epoch: 4 | loss: 0.1005628\n",
      "\tspeed: 0.1003s/iter; left time: 585.4441s\n",
      "\titers: 500, epoch: 4 | loss: 0.1162122\n",
      "\tspeed: 0.1002s/iter; left time: 574.8134s\n",
      "\titers: 600, epoch: 4 | loss: 0.1039602\n",
      "\tspeed: 0.1004s/iter; left time: 566.3297s\n",
      "\titers: 700, epoch: 4 | loss: 0.1087918\n",
      "\tspeed: 0.1008s/iter; left time: 558.4829s\n",
      "\titers: 800, epoch: 4 | loss: 0.1257364\n",
      "\tspeed: 0.1005s/iter; left time: 546.6239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.73s\n",
      "Steps: 891 | Train Loss: 0.1110095 Vali Loss: 0.1376320 Test Loss: 0.1505949\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1080788\n",
      "\tspeed: 0.3404s/iter; left time: 1785.9642s\n",
      "\titers: 200, epoch: 5 | loss: 0.1090300\n",
      "\tspeed: 0.1007s/iter; left time: 518.3205s\n",
      "\titers: 300, epoch: 5 | loss: 0.1018303\n",
      "\tspeed: 0.1004s/iter; left time: 506.6143s\n",
      "\titers: 400, epoch: 5 | loss: 0.1029458\n",
      "\tspeed: 0.1004s/iter; left time: 496.5874s\n",
      "\titers: 500, epoch: 5 | loss: 0.1015626\n",
      "\tspeed: 0.1004s/iter; left time: 486.4026s\n",
      "\titers: 600, epoch: 5 | loss: 0.1002073\n",
      "\tspeed: 0.1009s/iter; left time: 478.9389s\n",
      "\titers: 700, epoch: 5 | loss: 0.1026300\n",
      "\tspeed: 0.1005s/iter; left time: 467.0198s\n",
      "\titers: 800, epoch: 5 | loss: 0.0942251\n",
      "\tspeed: 0.0999s/iter; left time: 454.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.64s\n",
      "Steps: 891 | Train Loss: 0.1012461 Vali Loss: 0.1325881 Test Loss: 0.1467436\n",
      "Validation loss decreased (0.134564 --> 0.132588).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058249\n",
      "\tspeed: 0.3534s/iter; left time: 1539.4016s\n",
      "\titers: 200, epoch: 6 | loss: 0.0989638\n",
      "\tspeed: 0.1004s/iter; left time: 427.4649s\n",
      "\titers: 300, epoch: 6 | loss: 0.0878821\n",
      "\tspeed: 0.1005s/iter; left time: 417.8111s\n",
      "\titers: 400, epoch: 6 | loss: 0.1065645\n",
      "\tspeed: 0.1005s/iter; left time: 407.4907s\n",
      "\titers: 500, epoch: 6 | loss: 0.0938731\n",
      "\tspeed: 0.1004s/iter; left time: 397.1369s\n",
      "\titers: 600, epoch: 6 | loss: 0.0851824\n",
      "\tspeed: 0.1004s/iter; left time: 387.2056s\n",
      "\titers: 700, epoch: 6 | loss: 0.0970766\n",
      "\tspeed: 0.1008s/iter; left time: 378.5803s\n",
      "\titers: 800, epoch: 6 | loss: 0.0848683\n",
      "\tspeed: 0.1005s/iter; left time: 367.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.78s\n",
      "Steps: 891 | Train Loss: 0.0919591 Vali Loss: 0.1376792 Test Loss: 0.1540182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0883620\n",
      "\tspeed: 0.3421s/iter; left time: 1185.4874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851708\n",
      "\tspeed: 0.1008s/iter; left time: 339.0547s\n",
      "\titers: 300, epoch: 7 | loss: 0.0843513\n",
      "\tspeed: 0.1003s/iter; left time: 327.4725s\n",
      "\titers: 400, epoch: 7 | loss: 0.0768327\n",
      "\tspeed: 0.1075s/iter; left time: 340.1657s\n",
      "\titers: 500, epoch: 7 | loss: 0.0780179\n",
      "\tspeed: 0.1003s/iter; left time: 307.5182s\n",
      "\titers: 600, epoch: 7 | loss: 0.0747017\n",
      "\tspeed: 0.1005s/iter; left time: 298.1128s\n",
      "\titers: 700, epoch: 7 | loss: 0.0846794\n",
      "\tspeed: 0.1008s/iter; left time: 288.8548s\n",
      "\titers: 800, epoch: 7 | loss: 0.0691558\n",
      "\tspeed: 0.1003s/iter; left time: 277.3079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:30.51s\n",
      "Steps: 891 | Train Loss: 0.0818185 Vali Loss: 0.1448310 Test Loss: 0.1597978\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0819370\n",
      "\tspeed: 0.3460s/iter; left time: 890.6911s\n",
      "\titers: 200, epoch: 8 | loss: 0.0711598\n",
      "\tspeed: 0.1004s/iter; left time: 248.4556s\n",
      "\titers: 300, epoch: 8 | loss: 0.0731892\n",
      "\tspeed: 0.1006s/iter; left time: 238.7230s\n",
      "\titers: 400, epoch: 8 | loss: 0.0722533\n",
      "\tspeed: 0.1002s/iter; left time: 227.7468s\n",
      "\titers: 500, epoch: 8 | loss: 0.0655215\n",
      "\tspeed: 0.1008s/iter; left time: 219.1741s\n",
      "\titers: 600, epoch: 8 | loss: 0.0685561\n",
      "\tspeed: 0.1004s/iter; left time: 208.1460s\n",
      "\titers: 700, epoch: 8 | loss: 0.0713495\n",
      "\tspeed: 0.1003s/iter; left time: 197.9224s\n",
      "\titers: 800, epoch: 8 | loss: 0.0690993\n",
      "\tspeed: 0.1007s/iter; left time: 188.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:29.85s\n",
      "Steps: 891 | Train Loss: 0.0748094 Vali Loss: 0.1448612 Test Loss: 0.1629034\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049553606659173965, rmse:0.22260639071464539, mae:0.1467435657978058, rse:0.78829425573349\n",
      "Original data scale mse:39954652.0, rmse:6320.96923828125, mae:3986.60498046875, rse:0.31478652358055115\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2236252\n",
      "\tspeed: 0.1248s/iter; left time: 1097.2235s\n",
      "\titers: 200, epoch: 1 | loss: 0.2221477\n",
      "\tspeed: 0.1015s/iter; left time: 882.4016s\n",
      "\titers: 300, epoch: 1 | loss: 0.1788471\n",
      "\tspeed: 0.1018s/iter; left time: 874.3153s\n",
      "\titers: 400, epoch: 1 | loss: 0.1820258\n",
      "\tspeed: 0.1021s/iter; left time: 866.9304s\n",
      "\titers: 500, epoch: 1 | loss: 0.1811135\n",
      "\tspeed: 0.1016s/iter; left time: 852.3578s\n",
      "\titers: 600, epoch: 1 | loss: 0.1701757\n",
      "\tspeed: 0.1019s/iter; left time: 844.8177s\n",
      "\titers: 700, epoch: 1 | loss: 0.1694463\n",
      "\tspeed: 0.1015s/iter; left time: 831.4029s\n",
      "\titers: 800, epoch: 1 | loss: 0.1621404\n",
      "\tspeed: 0.1020s/iter; left time: 825.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:30.93s\n",
      "Steps: 889 | Train Loss: 0.1916557 Vali Loss: 0.1636720 Test Loss: 0.1788683\n",
      "Validation loss decreased (inf --> 0.163672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1393545\n",
      "\tspeed: 0.3520s/iter; left time: 2781.2725s\n",
      "\titers: 200, epoch: 2 | loss: 0.1579906\n",
      "\tspeed: 0.1019s/iter; left time: 794.9159s\n",
      "\titers: 300, epoch: 2 | loss: 0.1165630\n",
      "\tspeed: 0.1020s/iter; left time: 785.2570s\n",
      "\titers: 400, epoch: 2 | loss: 0.1331789\n",
      "\tspeed: 0.1022s/iter; left time: 777.2916s\n",
      "\titers: 500, epoch: 2 | loss: 0.1195820\n",
      "\tspeed: 0.1017s/iter; left time: 763.2499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1176796\n",
      "\tspeed: 0.1017s/iter; left time: 752.5136s\n",
      "\titers: 700, epoch: 2 | loss: 0.1330948\n",
      "\tspeed: 0.1015s/iter; left time: 741.4661s\n",
      "\titers: 800, epoch: 2 | loss: 0.1264216\n",
      "\tspeed: 0.1017s/iter; left time: 732.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.77s\n",
      "Steps: 889 | Train Loss: 0.1344875 Vali Loss: 0.1415911 Test Loss: 0.1621272\n",
      "Validation loss decreased (0.163672 --> 0.141591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1258177\n",
      "\tspeed: 0.3479s/iter; left time: 2439.8381s\n",
      "\titers: 200, epoch: 3 | loss: 0.1283277\n",
      "\tspeed: 0.1017s/iter; left time: 703.1585s\n",
      "\titers: 300, epoch: 3 | loss: 0.1088434\n",
      "\tspeed: 0.1014s/iter; left time: 690.9335s\n",
      "\titers: 400, epoch: 3 | loss: 0.1277032\n",
      "\tspeed: 0.1014s/iter; left time: 680.7591s\n",
      "\titers: 500, epoch: 3 | loss: 0.1284314\n",
      "\tspeed: 0.1014s/iter; left time: 670.7443s\n",
      "\titers: 600, epoch: 3 | loss: 0.1173171\n",
      "\tspeed: 0.1017s/iter; left time: 662.4980s\n",
      "\titers: 700, epoch: 3 | loss: 0.1159218\n",
      "\tspeed: 0.1015s/iter; left time: 650.8279s\n",
      "\titers: 800, epoch: 3 | loss: 0.1106673\n",
      "\tspeed: 0.1016s/iter; left time: 641.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.47s\n",
      "Steps: 889 | Train Loss: 0.1171044 Vali Loss: 0.1378510 Test Loss: 0.1595040\n",
      "Validation loss decreased (0.141591 --> 0.137851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125350\n",
      "\tspeed: 0.3484s/iter; left time: 2133.3859s\n",
      "\titers: 200, epoch: 4 | loss: 0.1142907\n",
      "\tspeed: 0.1015s/iter; left time: 611.2717s\n",
      "\titers: 300, epoch: 4 | loss: 0.1104191\n",
      "\tspeed: 0.1016s/iter; left time: 602.1526s\n",
      "\titers: 400, epoch: 4 | loss: 0.1102095\n",
      "\tspeed: 0.1015s/iter; left time: 591.2603s\n",
      "\titers: 500, epoch: 4 | loss: 0.1027346\n",
      "\tspeed: 0.1015s/iter; left time: 581.0280s\n",
      "\titers: 600, epoch: 4 | loss: 0.1020633\n",
      "\tspeed: 0.1014s/iter; left time: 570.0401s\n",
      "\titers: 700, epoch: 4 | loss: 0.1099289\n",
      "\tspeed: 0.1012s/iter; left time: 559.2431s\n",
      "\titers: 800, epoch: 4 | loss: 0.1028571\n",
      "\tspeed: 0.1015s/iter; left time: 550.4062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.49s\n",
      "Steps: 889 | Train Loss: 0.1087393 Vali Loss: 0.1390958 Test Loss: 0.1623551\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0995421\n",
      "\tspeed: 0.3448s/iter; left time: 1805.0488s\n",
      "\titers: 200, epoch: 5 | loss: 0.0955067\n",
      "\tspeed: 0.1015s/iter; left time: 520.9470s\n",
      "\titers: 300, epoch: 5 | loss: 0.1076343\n",
      "\tspeed: 0.1015s/iter; left time: 511.1962s\n",
      "\titers: 400, epoch: 5 | loss: 0.1021213\n",
      "\tspeed: 0.1016s/iter; left time: 501.2089s\n",
      "\titers: 500, epoch: 5 | loss: 0.0914531\n",
      "\tspeed: 0.1090s/iter; left time: 527.1015s\n",
      "\titers: 600, epoch: 5 | loss: 0.0936433\n",
      "\tspeed: 0.1012s/iter; left time: 479.0655s\n",
      "\titers: 700, epoch: 5 | loss: 0.0924483\n",
      "\tspeed: 0.1016s/iter; left time: 470.9017s\n",
      "\titers: 800, epoch: 5 | loss: 0.1026052\n",
      "\tspeed: 0.1016s/iter; left time: 460.9438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:31.16s\n",
      "Steps: 889 | Train Loss: 0.0990277 Vali Loss: 0.1352574 Test Loss: 0.1603709\n",
      "Validation loss decreased (0.137851 --> 0.135257).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0969623\n",
      "\tspeed: 0.3465s/iter; left time: 1505.8168s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844042\n",
      "\tspeed: 0.1015s/iter; left time: 430.7979s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898786\n",
      "\tspeed: 0.1016s/iter; left time: 421.0330s\n",
      "\titers: 400, epoch: 6 | loss: 0.0897832\n",
      "\tspeed: 0.1017s/iter; left time: 411.4992s\n",
      "\titers: 500, epoch: 6 | loss: 0.0846805\n",
      "\tspeed: 0.1017s/iter; left time: 401.3367s\n",
      "\titers: 600, epoch: 6 | loss: 0.0797097\n",
      "\tspeed: 0.1018s/iter; left time: 391.6084s\n",
      "\titers: 700, epoch: 6 | loss: 0.0803243\n",
      "\tspeed: 0.1017s/iter; left time: 380.8792s\n",
      "\titers: 800, epoch: 6 | loss: 0.0809511\n",
      "\tspeed: 0.1017s/iter; left time: 370.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.58s\n",
      "Steps: 889 | Train Loss: 0.0868865 Vali Loss: 0.1386303 Test Loss: 0.1596169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0795640\n",
      "\tspeed: 0.3427s/iter; left time: 1184.8549s\n",
      "\titers: 200, epoch: 7 | loss: 0.0795091\n",
      "\tspeed: 0.1016s/iter; left time: 340.9195s\n",
      "\titers: 300, epoch: 7 | loss: 0.0759916\n",
      "\tspeed: 0.1016s/iter; left time: 331.0290s\n",
      "\titers: 400, epoch: 7 | loss: 0.0748528\n",
      "\tspeed: 0.1013s/iter; left time: 319.9304s\n",
      "\titers: 500, epoch: 7 | loss: 0.0806245\n",
      "\tspeed: 0.1013s/iter; left time: 309.5307s\n",
      "\titers: 600, epoch: 7 | loss: 0.0809601\n",
      "\tspeed: 0.1061s/iter; left time: 313.7846s\n",
      "\titers: 700, epoch: 7 | loss: 0.0729587\n",
      "\tspeed: 0.1018s/iter; left time: 290.9203s\n",
      "\titers: 800, epoch: 7 | loss: 0.0787459\n",
      "\tspeed: 0.1014s/iter; left time: 279.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:30.92s\n",
      "Steps: 889 | Train Loss: 0.0783990 Vali Loss: 0.1434864 Test Loss: 0.1644492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0764437\n",
      "\tspeed: 0.3423s/iter; left time: 879.0835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0679816\n",
      "\tspeed: 0.1016s/iter; left time: 250.8299s\n",
      "\titers: 300, epoch: 8 | loss: 0.0779132\n",
      "\tspeed: 0.1014s/iter; left time: 240.0918s\n",
      "\titers: 400, epoch: 8 | loss: 0.0715075\n",
      "\tspeed: 0.1016s/iter; left time: 230.3340s\n",
      "\titers: 500, epoch: 8 | loss: 0.0697670\n",
      "\tspeed: 0.1015s/iter; left time: 220.0713s\n",
      "\titers: 600, epoch: 8 | loss: 0.0688509\n",
      "\tspeed: 0.1015s/iter; left time: 209.9154s\n",
      "\titers: 700, epoch: 8 | loss: 0.0696828\n",
      "\tspeed: 0.1014s/iter; left time: 199.5933s\n",
      "\titers: 800, epoch: 8 | loss: 0.0673326\n",
      "\tspeed: 0.1016s/iter; left time: 189.7002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:30.46s\n",
      "Steps: 889 | Train Loss: 0.0712541 Vali Loss: 0.1406319 Test Loss: 0.1585930\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06031554564833641, rmse:0.24559223651885986, mae:0.16037097573280334, rse:0.8700593113899231\n",
      "Original data scale mse:43195992.0, rmse:6572.36572265625, mae:4203.34130859375, rse:0.32746684551239014\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2440297\n",
      "\tspeed: 0.1044s/iter; left time: 917.5934s\n",
      "\titers: 200, epoch: 1 | loss: 0.2182793\n",
      "\tspeed: 0.1018s/iter; left time: 885.0163s\n",
      "\titers: 300, epoch: 1 | loss: 0.2166271\n",
      "\tspeed: 0.1015s/iter; left time: 872.0130s\n",
      "\titers: 400, epoch: 1 | loss: 0.1881135\n",
      "\tspeed: 0.1020s/iter; left time: 865.9839s\n",
      "\titers: 500, epoch: 1 | loss: 0.1775274\n",
      "\tspeed: 0.1019s/iter; left time: 855.2773s\n",
      "\titers: 600, epoch: 1 | loss: 0.1650314\n",
      "\tspeed: 0.1020s/iter; left time: 845.3812s\n",
      "\titers: 700, epoch: 1 | loss: 0.1587565\n",
      "\tspeed: 0.1094s/iter; left time: 896.4637s\n",
      "\titers: 800, epoch: 1 | loss: 0.1637951\n",
      "\tspeed: 0.1018s/iter; left time: 823.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:31.61s\n",
      "Steps: 889 | Train Loss: 0.1920632 Vali Loss: 0.1607627 Test Loss: 0.1755518\n",
      "Validation loss decreased (inf --> 0.160763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1613922\n",
      "\tspeed: 0.3476s/iter; left time: 2746.3436s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398044\n",
      "\tspeed: 0.1021s/iter; left time: 796.8612s\n",
      "\titers: 300, epoch: 2 | loss: 0.1325991\n",
      "\tspeed: 0.1018s/iter; left time: 783.9915s\n",
      "\titers: 400, epoch: 2 | loss: 0.1275826\n",
      "\tspeed: 0.1017s/iter; left time: 772.8986s\n",
      "\titers: 500, epoch: 2 | loss: 0.1230926\n",
      "\tspeed: 0.1018s/iter; left time: 763.8410s\n",
      "\titers: 600, epoch: 2 | loss: 0.1102595\n",
      "\tspeed: 0.1016s/iter; left time: 752.1657s\n",
      "\titers: 700, epoch: 2 | loss: 0.1233910\n",
      "\tspeed: 0.1017s/iter; left time: 742.8188s\n",
      "\titers: 800, epoch: 2 | loss: 0.1255830\n",
      "\tspeed: 0.1019s/iter; left time: 734.0118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:30.77s\n",
      "Steps: 889 | Train Loss: 0.1339563 Vali Loss: 0.1383737 Test Loss: 0.1471476\n",
      "Validation loss decreased (0.160763 --> 0.138374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1387115\n",
      "\tspeed: 0.3483s/iter; left time: 2442.8820s\n",
      "\titers: 200, epoch: 3 | loss: 0.1303143\n",
      "\tspeed: 0.1018s/iter; left time: 703.5005s\n",
      "\titers: 300, epoch: 3 | loss: 0.1220810\n",
      "\tspeed: 0.1017s/iter; left time: 692.9596s\n",
      "\titers: 400, epoch: 3 | loss: 0.1073986\n",
      "\tspeed: 0.1015s/iter; left time: 681.6310s\n",
      "\titers: 500, epoch: 3 | loss: 0.1088516\n",
      "\tspeed: 0.1014s/iter; left time: 670.2711s\n",
      "\titers: 600, epoch: 3 | loss: 0.1206331\n",
      "\tspeed: 0.1014s/iter; left time: 660.3053s\n",
      "\titers: 700, epoch: 3 | loss: 0.1086496\n",
      "\tspeed: 0.1013s/iter; left time: 649.8903s\n",
      "\titers: 800, epoch: 3 | loss: 0.1142807\n",
      "\tspeed: 0.1073s/iter; left time: 677.6613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.11s\n",
      "Steps: 889 | Train Loss: 0.1178297 Vali Loss: 0.1364477 Test Loss: 0.1522671\n",
      "Validation loss decreased (0.138374 --> 0.136448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061430\n",
      "\tspeed: 0.3451s/iter; left time: 2113.6115s\n",
      "\titers: 200, epoch: 4 | loss: 0.1271660\n",
      "\tspeed: 0.1015s/iter; left time: 611.3514s\n",
      "\titers: 300, epoch: 4 | loss: 0.1105505\n",
      "\tspeed: 0.1013s/iter; left time: 600.1759s\n",
      "\titers: 400, epoch: 4 | loss: 0.1156312\n",
      "\tspeed: 0.1014s/iter; left time: 590.7318s\n",
      "\titers: 500, epoch: 4 | loss: 0.1150059\n",
      "\tspeed: 0.1019s/iter; left time: 583.1517s\n",
      "\titers: 600, epoch: 4 | loss: 0.1022635\n",
      "\tspeed: 0.1013s/iter; left time: 569.5913s\n",
      "\titers: 700, epoch: 4 | loss: 0.1031489\n",
      "\tspeed: 0.1015s/iter; left time: 560.4519s\n",
      "\titers: 800, epoch: 4 | loss: 0.1027978\n",
      "\tspeed: 0.1015s/iter; left time: 550.4996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.47s\n",
      "Steps: 889 | Train Loss: 0.1086743 Vali Loss: 0.1553946 Test Loss: 0.1906406\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0964478\n",
      "\tspeed: 0.3433s/iter; left time: 1797.0983s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043508\n",
      "\tspeed: 0.1018s/iter; left time: 522.4983s\n",
      "\titers: 300, epoch: 5 | loss: 0.1025670\n",
      "\tspeed: 0.1010s/iter; left time: 508.7783s\n",
      "\titers: 400, epoch: 5 | loss: 0.1081744\n",
      "\tspeed: 0.1009s/iter; left time: 497.8542s\n",
      "\titers: 500, epoch: 5 | loss: 0.1046892\n",
      "\tspeed: 0.1014s/iter; left time: 490.4454s\n",
      "\titers: 600, epoch: 5 | loss: 0.1027988\n",
      "\tspeed: 0.1015s/iter; left time: 480.6543s\n",
      "\titers: 700, epoch: 5 | loss: 0.0927894\n",
      "\tspeed: 0.1014s/iter; left time: 470.0301s\n",
      "\titers: 800, epoch: 5 | loss: 0.0960981\n",
      "\tspeed: 0.1012s/iter; left time: 459.1640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.89s\n",
      "Steps: 889 | Train Loss: 0.0978278 Vali Loss: 0.1361251 Test Loss: 0.1560469\n",
      "Validation loss decreased (0.136448 --> 0.136125).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916229\n",
      "\tspeed: 0.3503s/iter; left time: 1522.4020s\n",
      "\titers: 200, epoch: 6 | loss: 0.0866323\n",
      "\tspeed: 0.1016s/iter; left time: 431.2408s\n",
      "\titers: 300, epoch: 6 | loss: 0.0858737\n",
      "\tspeed: 0.1020s/iter; left time: 422.7086s\n",
      "\titers: 400, epoch: 6 | loss: 0.0900371\n",
      "\tspeed: 0.1012s/iter; left time: 409.6097s\n",
      "\titers: 500, epoch: 6 | loss: 0.0906123\n",
      "\tspeed: 0.1017s/iter; left time: 401.2733s\n",
      "\titers: 600, epoch: 6 | loss: 0.0857399\n",
      "\tspeed: 0.1019s/iter; left time: 391.7697s\n",
      "\titers: 700, epoch: 6 | loss: 0.0927337\n",
      "\tspeed: 0.1016s/iter; left time: 380.5087s\n",
      "\titers: 800, epoch: 6 | loss: 0.0868835\n",
      "\tspeed: 0.1014s/iter; left time: 369.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:30.58s\n",
      "Steps: 889 | Train Loss: 0.0856878 Vali Loss: 0.1468961 Test Loss: 0.1642924\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749827\n",
      "\tspeed: 0.3444s/iter; left time: 1190.7021s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811734\n",
      "\tspeed: 0.1014s/iter; left time: 340.5516s\n",
      "\titers: 300, epoch: 7 | loss: 0.0719872\n",
      "\tspeed: 0.1013s/iter; left time: 329.9527s\n",
      "\titers: 400, epoch: 7 | loss: 0.0802579\n",
      "\tspeed: 0.1012s/iter; left time: 319.5670s\n",
      "\titers: 500, epoch: 7 | loss: 0.0732059\n",
      "\tspeed: 0.1013s/iter; left time: 309.7491s\n",
      "\titers: 600, epoch: 7 | loss: 0.0707942\n",
      "\tspeed: 0.1013s/iter; left time: 299.4730s\n",
      "\titers: 700, epoch: 7 | loss: 0.0728021\n",
      "\tspeed: 0.1014s/iter; left time: 289.7250s\n",
      "\titers: 800, epoch: 7 | loss: 0.0748281\n",
      "\tspeed: 0.1015s/iter; left time: 279.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:30.40s\n",
      "Steps: 889 | Train Loss: 0.0774466 Vali Loss: 0.1378009 Test Loss: 0.1584621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0703291\n",
      "\tspeed: 0.3591s/iter; left time: 922.1386s\n",
      "\titers: 200, epoch: 8 | loss: 0.0698420\n",
      "\tspeed: 0.1014s/iter; left time: 250.2535s\n",
      "\titers: 300, epoch: 8 | loss: 0.0724632\n",
      "\tspeed: 0.1016s/iter; left time: 240.4707s\n",
      "\titers: 400, epoch: 8 | loss: 0.0749760\n",
      "\tspeed: 0.1016s/iter; left time: 230.3807s\n",
      "\titers: 500, epoch: 8 | loss: 0.0708299\n",
      "\tspeed: 0.1018s/iter; left time: 220.7604s\n",
      "\titers: 600, epoch: 8 | loss: 0.0744385\n",
      "\tspeed: 0.1012s/iter; left time: 209.2087s\n",
      "\titers: 700, epoch: 8 | loss: 0.0698501\n",
      "\tspeed: 0.1017s/iter; left time: 200.0833s\n",
      "\titers: 800, epoch: 8 | loss: 0.0704337\n",
      "\tspeed: 0.1013s/iter; left time: 189.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:30.48s\n",
      "Steps: 889 | Train Loss: 0.0719310 Vali Loss: 0.1390350 Test Loss: 0.1598472\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.054536111652851105, rmse:0.2335296869277954, mae:0.15604688227176666, rse:0.8273254036903381\n",
      "Original data scale mse:45199216.0, rmse:6723.0361328125, mae:4282.54345703125, rse:0.3349739611148834\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\" \\\n",
    "              --revin 0 \\\n",
    "              --decomposition 1\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.5477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.7258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2062</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.7768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.5462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.5476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.7460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.7884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0254  0.1593  0.1056  0.5624\n",
       "              2         24        0.0241  0.1551  0.1024  0.5477\n",
       "              1         96        0.0420  0.2050  0.1436  0.7258\n",
       "              2         96        0.0425  0.2062  0.1425  0.7303\n",
       "              1         168       0.0449  0.2119  0.1500  0.7508\n",
       "              2         168       0.0481  0.2193  0.1509  0.7768\n",
       "RMSE          1         24        0.0239  0.1547  0.1037  0.5462\n",
       "              2         24        0.0240  0.1550  0.1044  0.5476\n",
       "              1         96        0.0476  0.2182  0.1525  0.7726\n",
       "              2         96        0.0458  0.2140  0.1418  0.7578\n",
       "              1         168       0.0443  0.2106  0.1473  0.7460\n",
       "              2         168       0.0447  0.2115  0.1491  0.7491\n",
       "MAE           1         24        0.0270  0.1644  0.1032  0.5805\n",
       "              2         24        0.0249  0.1577  0.0996  0.5568\n",
       "              1         96        0.0496  0.2226  0.1465  0.7884\n",
       "              2         96        0.0496  0.2226  0.1467  0.7883\n",
       "              1         168       0.0603  0.2456  0.1604  0.8701\n",
       "              2         168       0.0545  0.2335  0.1560  0.8273"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_no_revin_decomposition.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_no_revin_decomposition.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19506484.0</td>\n",
       "      <td>4416.6147</td>\n",
       "      <td>2876.1069</td>\n",
       "      <td>0.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19008062.0</td>\n",
       "      <td>4359.8237</td>\n",
       "      <td>2790.5967</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36130940.0</td>\n",
       "      <td>6010.9019</td>\n",
       "      <td>4012.9888</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36122992.0</td>\n",
       "      <td>6010.2407</td>\n",
       "      <td>3954.7468</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39282812.0</td>\n",
       "      <td>6267.6001</td>\n",
       "      <td>4202.2949</td>\n",
       "      <td>0.3123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40928480.0</td>\n",
       "      <td>6397.5371</td>\n",
       "      <td>4202.4697</td>\n",
       "      <td>0.3188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19043724.0</td>\n",
       "      <td>4363.9116</td>\n",
       "      <td>2849.0442</td>\n",
       "      <td>0.2170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19401690.0</td>\n",
       "      <td>4404.7349</td>\n",
       "      <td>2870.5693</td>\n",
       "      <td>0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38907712.0</td>\n",
       "      <td>6237.6045</td>\n",
       "      <td>4236.4297</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37945684.0</td>\n",
       "      <td>6160.0068</td>\n",
       "      <td>3876.0593</td>\n",
       "      <td>0.3068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38489120.0</td>\n",
       "      <td>6203.9600</td>\n",
       "      <td>4120.3130</td>\n",
       "      <td>0.3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39429468.0</td>\n",
       "      <td>6279.2886</td>\n",
       "      <td>4190.6279</td>\n",
       "      <td>0.3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19359624.0</td>\n",
       "      <td>4399.9570</td>\n",
       "      <td>2728.8313</td>\n",
       "      <td>0.2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18901044.0</td>\n",
       "      <td>4347.5332</td>\n",
       "      <td>2686.6917</td>\n",
       "      <td>0.2162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38852912.0</td>\n",
       "      <td>6233.2104</td>\n",
       "      <td>3966.3728</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>39954652.0</td>\n",
       "      <td>6320.9692</td>\n",
       "      <td>3986.6050</td>\n",
       "      <td>0.3148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>43195992.0</td>\n",
       "      <td>6572.3657</td>\n",
       "      <td>4203.3413</td>\n",
       "      <td>0.3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45199216.0</td>\n",
       "      <td>6723.0361</td>\n",
       "      <td>4282.5435</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        19506484.0  4416.6147  2876.1069  0.2196\n",
       "              2         24        19008062.0  4359.8237  2790.5967  0.2168\n",
       "              1         96        36130940.0  6010.9019  4012.9888  0.2993\n",
       "              2         96        36122992.0  6010.2407  3954.7468  0.2993\n",
       "              1         168       39282812.0  6267.6001  4202.2949  0.3123\n",
       "              2         168       40928480.0  6397.5371  4202.4697  0.3188\n",
       "RMSE          1         24        19043724.0  4363.9116  2849.0442  0.2170\n",
       "              2         24        19401690.0  4404.7349  2870.5693  0.2190\n",
       "              1         96        38907712.0  6237.6045  4236.4297  0.3106\n",
       "              2         96        37945684.0  6160.0068  3876.0593  0.3068\n",
       "              1         168       38489120.0  6203.9600  4120.3130  0.3091\n",
       "              2         168       39429468.0  6279.2886  4190.6279  0.3129\n",
       "MAE           1         24        19359624.0  4399.9570  2728.8313  0.2188\n",
       "              2         24        18901044.0  4347.5332  2686.6917  0.2162\n",
       "              1         96        38852912.0  6233.2104  3966.3728  0.3104\n",
       "              2         96        39954652.0  6320.9692  3986.6050  0.3148\n",
       "              1         168       43195992.0  6572.3657  4203.3413  0.3275\n",
       "              2         168       45199216.0  6723.0361  4282.5435  0.3350"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.5687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.8487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.7476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0259  0.1610  0.1014  0.5687\n",
       "         MSE            0.0247  0.1572  0.1040  0.5551\n",
       "         RMSE           0.0240  0.1549  0.1040  0.5469\n",
       "96       MAE            0.0496  0.2226  0.1466  0.7883\n",
       "         MSE            0.0423  0.2056  0.1431  0.7281\n",
       "         RMSE           0.0467  0.2161  0.1472  0.7652\n",
       "168      MAE            0.0574  0.2396  0.1582  0.8487\n",
       "         MSE            0.0465  0.2156  0.1504  0.7638\n",
       "         RMSE           0.0445  0.2110  0.1482  0.7476"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19130334.0</td>\n",
       "      <td>4373.7451</td>\n",
       "      <td>2707.7615</td>\n",
       "      <td>0.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19257273.0</td>\n",
       "      <td>4388.2192</td>\n",
       "      <td>2833.3518</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19222707.0</td>\n",
       "      <td>4384.3232</td>\n",
       "      <td>2859.8068</td>\n",
       "      <td>0.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39403782.0</td>\n",
       "      <td>6277.0898</td>\n",
       "      <td>3976.4889</td>\n",
       "      <td>0.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36126966.0</td>\n",
       "      <td>6010.5713</td>\n",
       "      <td>3983.8678</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38426698.0</td>\n",
       "      <td>6198.8057</td>\n",
       "      <td>4056.2445</td>\n",
       "      <td>0.3087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>44197604.0</td>\n",
       "      <td>6647.7009</td>\n",
       "      <td>4242.9424</td>\n",
       "      <td>0.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>40105646.0</td>\n",
       "      <td>6332.5686</td>\n",
       "      <td>4202.3823</td>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38959294.0</td>\n",
       "      <td>6241.6243</td>\n",
       "      <td>4155.4705</td>\n",
       "      <td>0.3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19130334.0  4373.7451  2707.7615  0.2175\n",
       "         MSE            19257273.0  4388.2192  2833.3518  0.2182\n",
       "         RMSE           19222707.0  4384.3232  2859.8068  0.2180\n",
       "96       MAE            39403782.0  6277.0898  3976.4889  0.3126\n",
       "         MSE            36126966.0  6010.5713  3983.8678  0.2993\n",
       "         RMSE           38426698.0  6198.8057  4056.2445  0.3087\n",
       "168      MAE            44197604.0  6647.7009  4242.9424  0.3312\n",
       "         MSE            40105646.0  6332.5686  4202.3823  0.3155\n",
       "         RMSE           38959294.0  6241.6243  4155.4705  0.3110"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled_no_revin_decomposition'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
