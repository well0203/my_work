{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"PatchTST\"\n",
    "dataset = 'DE_data.csv'\n",
    "loss = \"MAE\"\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0727204\n",
      "\tspeed: 0.0755s/iter; left time: 666.4886s\n",
      "\titers: 200, epoch: 1 | loss: 0.0688743\n",
      "\tspeed: 0.0498s/iter; left time: 434.4627s\n",
      "\titers: 300, epoch: 1 | loss: 0.0516021\n",
      "\tspeed: 0.0497s/iter; left time: 428.7006s\n",
      "\titers: 400, epoch: 1 | loss: 0.0495072\n",
      "\tspeed: 0.0502s/iter; left time: 428.0484s\n",
      "\titers: 500, epoch: 1 | loss: 0.0437808\n",
      "\tspeed: 0.0506s/iter; left time: 426.4952s\n",
      "\titers: 600, epoch: 1 | loss: 0.0428931\n",
      "\tspeed: 0.0502s/iter; left time: 418.2723s\n",
      "\titers: 700, epoch: 1 | loss: 0.0320932\n",
      "\tspeed: 0.0504s/iter; left time: 414.9536s\n",
      "\titers: 800, epoch: 1 | loss: 0.0331783\n",
      "\tspeed: 0.0516s/iter; left time: 419.7538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.46s\n",
      "Steps: 893 | Train Loss: 0.0498004 Vali Loss: 0.0255448 Test Loss: 0.0280030\n",
      "Validation loss decreased (inf --> 0.025545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0378902\n",
      "\tspeed: 0.1897s/iter; left time: 1505.8408s\n",
      "\titers: 200, epoch: 2 | loss: 0.0240782\n",
      "\tspeed: 0.0503s/iter; left time: 394.6369s\n",
      "\titers: 300, epoch: 2 | loss: 0.0178593\n",
      "\tspeed: 0.0511s/iter; left time: 395.6664s\n",
      "\titers: 400, epoch: 2 | loss: 0.0178865\n",
      "\tspeed: 0.0501s/iter; left time: 382.7045s\n",
      "\titers: 500, epoch: 2 | loss: 0.0165037\n",
      "\tspeed: 0.0502s/iter; left time: 378.3116s\n",
      "\titers: 600, epoch: 2 | loss: 0.0245665\n",
      "\tspeed: 0.0517s/iter; left time: 384.2986s\n",
      "\titers: 700, epoch: 2 | loss: 0.0180247\n",
      "\tspeed: 0.0505s/iter; left time: 370.3997s\n",
      "\titers: 800, epoch: 2 | loss: 0.0134593\n",
      "\tspeed: 0.0525s/iter; left time: 380.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 893 | Train Loss: 0.0221958 Vali Loss: 0.0241549 Test Loss: 0.0266339\n",
      "Validation loss decreased (0.025545 --> 0.024155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0108618\n",
      "\tspeed: 0.1850s/iter; left time: 1303.6733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0185118\n",
      "\tspeed: 0.0496s/iter; left time: 344.3685s\n",
      "\titers: 300, epoch: 3 | loss: 0.0139210\n",
      "\tspeed: 0.0515s/iter; left time: 352.4307s\n",
      "\titers: 400, epoch: 3 | loss: 0.0183757\n",
      "\tspeed: 0.0516s/iter; left time: 347.8122s\n",
      "\titers: 500, epoch: 3 | loss: 0.0199568\n",
      "\tspeed: 0.0514s/iter; left time: 341.4129s\n",
      "\titers: 600, epoch: 3 | loss: 0.0196962\n",
      "\tspeed: 0.0510s/iter; left time: 333.5654s\n",
      "\titers: 700, epoch: 3 | loss: 0.0111249\n",
      "\tspeed: 0.0511s/iter; left time: 329.0669s\n",
      "\titers: 800, epoch: 3 | loss: 0.0217283\n",
      "\tspeed: 0.0508s/iter; left time: 322.0530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 893 | Train Loss: 0.0193541 Vali Loss: 0.0226646 Test Loss: 0.0250265\n",
      "Validation loss decreased (0.024155 --> 0.022665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1591274\n",
      "\tspeed: 0.1847s/iter; left time: 1136.4781s\n",
      "\titers: 200, epoch: 4 | loss: 0.0155019\n",
      "\tspeed: 0.0509s/iter; left time: 307.9337s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206544\n",
      "\tspeed: 0.0509s/iter; left time: 302.7136s\n",
      "\titers: 400, epoch: 4 | loss: 0.0134120\n",
      "\tspeed: 0.0504s/iter; left time: 294.9777s\n",
      "\titers: 500, epoch: 4 | loss: 0.0228675\n",
      "\tspeed: 0.0506s/iter; left time: 291.0844s\n",
      "\titers: 600, epoch: 4 | loss: 0.0164165\n",
      "\tspeed: 0.0508s/iter; left time: 287.1375s\n",
      "\titers: 700, epoch: 4 | loss: 0.0154799\n",
      "\tspeed: 0.0512s/iter; left time: 284.0564s\n",
      "\titers: 800, epoch: 4 | loss: 0.0180907\n",
      "\tspeed: 0.0509s/iter; left time: 277.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.0289833 Vali Loss: 0.0553275 Test Loss: 0.0681509\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0187819\n",
      "\tspeed: 0.1835s/iter; left time: 965.2240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0430803\n",
      "\tspeed: 0.0509s/iter; left time: 262.6663s\n",
      "\titers: 300, epoch: 5 | loss: 0.0201250\n",
      "\tspeed: 0.0509s/iter; left time: 257.5518s\n",
      "\titers: 400, epoch: 5 | loss: 0.0188826\n",
      "\tspeed: 0.0507s/iter; left time: 251.1893s\n",
      "\titers: 500, epoch: 5 | loss: 0.0267068\n",
      "\tspeed: 0.0512s/iter; left time: 248.9562s\n",
      "\titers: 600, epoch: 5 | loss: 0.0236914\n",
      "\tspeed: 0.0515s/iter; left time: 244.9967s\n",
      "\titers: 700, epoch: 5 | loss: 0.0185285\n",
      "\tspeed: 0.0505s/iter; left time: 235.4112s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150043\n",
      "\tspeed: 0.0511s/iter; left time: 232.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 893 | Train Loss: 0.0254915 Vali Loss: 0.0233504 Test Loss: 0.0246644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0215895\n",
      "\tspeed: 0.1817s/iter; left time: 793.4856s\n",
      "\titers: 200, epoch: 6 | loss: 0.0187316\n",
      "\tspeed: 0.0512s/iter; left time: 218.3103s\n",
      "\titers: 300, epoch: 6 | loss: 0.0133694\n",
      "\tspeed: 0.0510s/iter; left time: 212.6339s\n",
      "\titers: 400, epoch: 6 | loss: 0.0100682\n",
      "\tspeed: 0.0505s/iter; left time: 205.2759s\n",
      "\titers: 500, epoch: 6 | loss: 0.0133072\n",
      "\tspeed: 0.0503s/iter; left time: 199.3034s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144815\n",
      "\tspeed: 0.0512s/iter; left time: 198.0326s\n",
      "\titers: 700, epoch: 6 | loss: 0.0108478\n",
      "\tspeed: 0.0517s/iter; left time: 194.5955s\n",
      "\titers: 800, epoch: 6 | loss: 0.0143594\n",
      "\tspeed: 0.0506s/iter; left time: 185.5360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0173059 Vali Loss: 0.0202137 Test Loss: 0.0222505\n",
      "Validation loss decreased (0.022665 --> 0.020214).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0151645\n",
      "\tspeed: 0.1836s/iter; left time: 637.5605s\n",
      "\titers: 200, epoch: 7 | loss: 0.0121527\n",
      "\tspeed: 0.0498s/iter; left time: 167.8698s\n",
      "\titers: 300, epoch: 7 | loss: 0.0148428\n",
      "\tspeed: 0.0501s/iter; left time: 163.9607s\n",
      "\titers: 400, epoch: 7 | loss: 0.0130999\n",
      "\tspeed: 0.0506s/iter; left time: 160.5437s\n",
      "\titers: 500, epoch: 7 | loss: 0.0147744\n",
      "\tspeed: 0.0508s/iter; left time: 156.1513s\n",
      "\titers: 600, epoch: 7 | loss: 0.0109115\n",
      "\tspeed: 0.0508s/iter; left time: 151.0952s\n",
      "\titers: 700, epoch: 7 | loss: 0.0117408\n",
      "\tspeed: 0.0508s/iter; left time: 146.0907s\n",
      "\titers: 800, epoch: 7 | loss: 0.0130151\n",
      "\tspeed: 0.0508s/iter; left time: 140.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.32s\n",
      "Steps: 893 | Train Loss: 0.0138396 Vali Loss: 0.0199291 Test Loss: 0.0221776\n",
      "Validation loss decreased (0.020214 --> 0.019929).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132367\n",
      "\tspeed: 0.1853s/iter; left time: 478.0415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0133071\n",
      "\tspeed: 0.0507s/iter; left time: 125.7069s\n",
      "\titers: 300, epoch: 8 | loss: 0.0146803\n",
      "\tspeed: 0.0509s/iter; left time: 121.0992s\n",
      "\titers: 400, epoch: 8 | loss: 0.0148187\n",
      "\tspeed: 0.0509s/iter; left time: 116.0250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0148767\n",
      "\tspeed: 0.0508s/iter; left time: 110.6992s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103235\n",
      "\tspeed: 0.0506s/iter; left time: 105.3205s\n",
      "\titers: 700, epoch: 8 | loss: 0.0116642\n",
      "\tspeed: 0.0506s/iter; left time: 100.1432s\n",
      "\titers: 800, epoch: 8 | loss: 0.0160350\n",
      "\tspeed: 0.0509s/iter; left time: 95.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 893 | Train Loss: 0.0132240 Vali Loss: 0.0206254 Test Loss: 0.0223201\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0099230\n",
      "\tspeed: 0.1830s/iter; left time: 308.7429s\n",
      "\titers: 200, epoch: 9 | loss: 0.0112927\n",
      "\tspeed: 0.0509s/iter; left time: 80.7863s\n",
      "\titers: 300, epoch: 9 | loss: 0.0115014\n",
      "\tspeed: 0.0507s/iter; left time: 75.3442s\n",
      "\titers: 400, epoch: 9 | loss: 0.0098618\n",
      "\tspeed: 0.0510s/iter; left time: 70.6789s\n",
      "\titers: 500, epoch: 9 | loss: 0.0128435\n",
      "\tspeed: 0.0513s/iter; left time: 66.0137s\n",
      "\titers: 600, epoch: 9 | loss: 0.0130007\n",
      "\tspeed: 0.0507s/iter; left time: 60.1578s\n",
      "\titers: 700, epoch: 9 | loss: 0.0124585\n",
      "\tspeed: 0.0509s/iter; left time: 55.2780s\n",
      "\titers: 800, epoch: 9 | loss: 0.0110741\n",
      "\tspeed: 0.0506s/iter; left time: 49.9554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 893 | Train Loss: 0.0128333 Vali Loss: 0.0198661 Test Loss: 0.0227560\n",
      "Validation loss decreased (0.019929 --> 0.019866).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0118321\n",
      "\tspeed: 0.1853s/iter; left time: 147.1247s\n",
      "\titers: 200, epoch: 10 | loss: 0.0099242\n",
      "\tspeed: 0.0508s/iter; left time: 35.2364s\n",
      "\titers: 300, epoch: 10 | loss: 0.0084647\n",
      "\tspeed: 0.0511s/iter; left time: 30.3284s\n",
      "\titers: 400, epoch: 10 | loss: 0.0142392\n",
      "\tspeed: 0.0508s/iter; left time: 25.0907s\n",
      "\titers: 500, epoch: 10 | loss: 0.0116700\n",
      "\tspeed: 0.0514s/iter; left time: 20.2358s\n",
      "\titers: 600, epoch: 10 | loss: 0.0120764\n",
      "\tspeed: 0.0505s/iter; left time: 14.8355s\n",
      "\titers: 700, epoch: 10 | loss: 0.0155301\n",
      "\tspeed: 0.0513s/iter; left time: 9.9431s\n",
      "\titers: 800, epoch: 10 | loss: 0.0116681\n",
      "\tspeed: 0.0503s/iter; left time: 4.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.0123163 Vali Loss: 0.0207767 Test Loss: 0.0239361\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02275596372783184, rmse:0.1508508026599884, mae:0.09933484345674515, rse:0.532733678817749\n",
      "Original data scale mse:17937842.0, rmse:4235.30908203125, mae:2700.571533203125, rse:0.21058809757232666\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0630893\n",
      "\tspeed: 0.0519s/iter; left time: 458.2744s\n",
      "\titers: 200, epoch: 1 | loss: 0.0617913\n",
      "\tspeed: 0.0497s/iter; left time: 433.7302s\n",
      "\titers: 300, epoch: 1 | loss: 0.0525470\n",
      "\tspeed: 0.0508s/iter; left time: 438.4758s\n",
      "\titers: 400, epoch: 1 | loss: 0.0434229\n",
      "\tspeed: 0.0508s/iter; left time: 433.3024s\n",
      "\titers: 500, epoch: 1 | loss: 0.0331395\n",
      "\tspeed: 0.0514s/iter; left time: 433.3308s\n",
      "\titers: 600, epoch: 1 | loss: 0.0337202\n",
      "\tspeed: 0.0510s/iter; left time: 425.2196s\n",
      "\titers: 700, epoch: 1 | loss: 0.0321468\n",
      "\tspeed: 0.0507s/iter; left time: 417.1783s\n",
      "\titers: 800, epoch: 1 | loss: 0.0301018\n",
      "\tspeed: 0.0513s/iter; left time: 417.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.0484691 Vali Loss: 0.0250252 Test Loss: 0.0273721\n",
      "Validation loss decreased (inf --> 0.025025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0382674\n",
      "\tspeed: 0.1850s/iter; left time: 1468.5774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0206077\n",
      "\tspeed: 0.0505s/iter; left time: 395.9632s\n",
      "\titers: 300, epoch: 2 | loss: 0.0196784\n",
      "\tspeed: 0.0507s/iter; left time: 392.0200s\n",
      "\titers: 400, epoch: 2 | loss: 0.0154511\n",
      "\tspeed: 0.0508s/iter; left time: 388.0200s\n",
      "\titers: 500, epoch: 2 | loss: 0.0195760\n",
      "\tspeed: 0.0509s/iter; left time: 383.5861s\n",
      "\titers: 600, epoch: 2 | loss: 0.0168603\n",
      "\tspeed: 0.0511s/iter; left time: 380.4507s\n",
      "\titers: 700, epoch: 2 | loss: 0.0190213\n",
      "\tspeed: 0.0504s/iter; left time: 369.6427s\n",
      "\titers: 800, epoch: 2 | loss: 0.0457725\n",
      "\tspeed: 0.0508s/iter; left time: 367.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.48s\n",
      "Steps: 893 | Train Loss: 0.0275582 Vali Loss: 0.0258817 Test Loss: 0.0285840\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0238563\n",
      "\tspeed: 0.1840s/iter; left time: 1296.4284s\n",
      "\titers: 200, epoch: 3 | loss: 0.0145440\n",
      "\tspeed: 0.0508s/iter; left time: 352.9129s\n",
      "\titers: 300, epoch: 3 | loss: 0.0193389\n",
      "\tspeed: 0.0510s/iter; left time: 348.8428s\n",
      "\titers: 400, epoch: 3 | loss: 0.0168762\n",
      "\tspeed: 0.0506s/iter; left time: 341.4557s\n",
      "\titers: 500, epoch: 3 | loss: 0.0190453\n",
      "\tspeed: 0.0509s/iter; left time: 338.5424s\n",
      "\titers: 600, epoch: 3 | loss: 0.0187749\n",
      "\tspeed: 0.0509s/iter; left time: 333.1262s\n",
      "\titers: 700, epoch: 3 | loss: 0.0201252\n",
      "\tspeed: 0.0507s/iter; left time: 326.7469s\n",
      "\titers: 800, epoch: 3 | loss: 0.0164555\n",
      "\tspeed: 0.0509s/iter; left time: 323.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.67s\n",
      "Steps: 893 | Train Loss: 0.0169959 Vali Loss: 0.0242355 Test Loss: 0.0260237\n",
      "Validation loss decreased (0.025025 --> 0.024235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0756164\n",
      "\tspeed: 0.1852s/iter; left time: 1139.5641s\n",
      "\titers: 200, epoch: 4 | loss: 0.0344469\n",
      "\tspeed: 0.0509s/iter; left time: 307.8119s\n",
      "\titers: 300, epoch: 4 | loss: 0.0271614\n",
      "\tspeed: 0.0506s/iter; left time: 301.3745s\n",
      "\titers: 400, epoch: 4 | loss: 0.0304677\n",
      "\tspeed: 0.0512s/iter; left time: 299.5690s\n",
      "\titers: 500, epoch: 4 | loss: 0.0145179\n",
      "\tspeed: 0.0507s/iter; left time: 291.4420s\n",
      "\titers: 600, epoch: 4 | loss: 0.0177252\n",
      "\tspeed: 0.0727s/iter; left time: 410.8487s\n",
      "\titers: 700, epoch: 4 | loss: 0.0200148\n",
      "\tspeed: 0.0503s/iter; left time: 279.5352s\n",
      "\titers: 800, epoch: 4 | loss: 0.0156927\n",
      "\tspeed: 0.0508s/iter; left time: 276.9305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 893 | Train Loss: 0.0305887 Vali Loss: 0.0891450 Test Loss: 0.0844128\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0235908\n",
      "\tspeed: 0.1819s/iter; left time: 956.4182s\n",
      "\titers: 200, epoch: 5 | loss: 0.0224511\n",
      "\tspeed: 0.0500s/iter; left time: 257.9302s\n",
      "\titers: 300, epoch: 5 | loss: 0.0360905\n",
      "\tspeed: 0.0502s/iter; left time: 253.9841s\n",
      "\titers: 400, epoch: 5 | loss: 0.0224273\n",
      "\tspeed: 0.0511s/iter; left time: 253.3608s\n",
      "\titers: 500, epoch: 5 | loss: 0.0162767\n",
      "\tspeed: 0.0506s/iter; left time: 246.0153s\n",
      "\titers: 600, epoch: 5 | loss: 0.0179131\n",
      "\tspeed: 0.0508s/iter; left time: 241.6584s\n",
      "\titers: 700, epoch: 5 | loss: 0.0451258\n",
      "\tspeed: 0.0507s/iter; left time: 236.0232s\n",
      "\titers: 800, epoch: 5 | loss: 0.0291768\n",
      "\tspeed: 0.0507s/iter; left time: 231.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.34s\n",
      "Steps: 893 | Train Loss: 0.0244987 Vali Loss: 0.0305114 Test Loss: 0.0339810\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0154643\n",
      "\tspeed: 0.1836s/iter; left time: 801.7510s\n",
      "\titers: 200, epoch: 6 | loss: 0.0154735\n",
      "\tspeed: 0.0509s/iter; left time: 217.2494s\n",
      "\titers: 300, epoch: 6 | loss: 0.0154974\n",
      "\tspeed: 0.0511s/iter; left time: 213.0575s\n",
      "\titers: 400, epoch: 6 | loss: 0.0171965\n",
      "\tspeed: 0.0513s/iter; left time: 208.5771s\n",
      "\titers: 500, epoch: 6 | loss: 0.0152446\n",
      "\tspeed: 0.0508s/iter; left time: 201.4764s\n",
      "\titers: 600, epoch: 6 | loss: 0.0258890\n",
      "\tspeed: 0.0508s/iter; left time: 196.3693s\n",
      "\titers: 700, epoch: 6 | loss: 0.0489950\n",
      "\tspeed: 0.0508s/iter; left time: 191.1826s\n",
      "\titers: 800, epoch: 6 | loss: 0.0197910\n",
      "\tspeed: 0.0511s/iter; left time: 187.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0228989 Vali Loss: 0.0220299 Test Loss: 0.0247207\n",
      "Validation loss decreased (0.024235 --> 0.022030).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0207843\n",
      "\tspeed: 0.1853s/iter; left time: 643.5170s\n",
      "\titers: 200, epoch: 7 | loss: 0.0169488\n",
      "\tspeed: 0.0510s/iter; left time: 172.1080s\n",
      "\titers: 300, epoch: 7 | loss: 0.0128568\n",
      "\tspeed: 0.0506s/iter; left time: 165.6781s\n",
      "\titers: 400, epoch: 7 | loss: 0.0139189\n",
      "\tspeed: 0.0507s/iter; left time: 161.0160s\n",
      "\titers: 500, epoch: 7 | loss: 0.0203434\n",
      "\tspeed: 0.0505s/iter; left time: 155.2466s\n",
      "\titers: 600, epoch: 7 | loss: 0.0155949\n",
      "\tspeed: 0.0505s/iter; left time: 150.1968s\n",
      "\titers: 700, epoch: 7 | loss: 0.0123993\n",
      "\tspeed: 0.0507s/iter; left time: 145.5335s\n",
      "\titers: 800, epoch: 7 | loss: 0.0220734\n",
      "\tspeed: 0.0507s/iter; left time: 140.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.0165875 Vali Loss: 0.0240857 Test Loss: 0.0266356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132901\n",
      "\tspeed: 0.1822s/iter; left time: 470.0518s\n",
      "\titers: 200, epoch: 8 | loss: 0.0147576\n",
      "\tspeed: 0.0511s/iter; left time: 126.6957s\n",
      "\titers: 300, epoch: 8 | loss: 0.0116578\n",
      "\tspeed: 0.0509s/iter; left time: 121.0896s\n",
      "\titers: 400, epoch: 8 | loss: 0.0117376\n",
      "\tspeed: 0.0506s/iter; left time: 115.3662s\n",
      "\titers: 500, epoch: 8 | loss: 0.0181731\n",
      "\tspeed: 0.0512s/iter; left time: 111.6834s\n",
      "\titers: 600, epoch: 8 | loss: 0.0119660\n",
      "\tspeed: 0.0510s/iter; left time: 106.0802s\n",
      "\titers: 700, epoch: 8 | loss: 0.0115851\n",
      "\tspeed: 0.0511s/iter; left time: 101.1881s\n",
      "\titers: 800, epoch: 8 | loss: 0.0173845\n",
      "\tspeed: 0.0509s/iter; left time: 95.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 893 | Train Loss: 0.0157776 Vali Loss: 0.0203106 Test Loss: 0.0232468\n",
      "Validation loss decreased (0.022030 --> 0.020311).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0132059\n",
      "\tspeed: 0.1840s/iter; left time: 310.4131s\n",
      "\titers: 200, epoch: 9 | loss: 0.0128770\n",
      "\tspeed: 0.0500s/iter; left time: 79.2723s\n",
      "\titers: 300, epoch: 9 | loss: 0.0140381\n",
      "\tspeed: 0.0502s/iter; left time: 74.6620s\n",
      "\titers: 400, epoch: 9 | loss: 0.0159804\n",
      "\tspeed: 0.0510s/iter; left time: 70.6758s\n",
      "\titers: 500, epoch: 9 | loss: 0.0158740\n",
      "\tspeed: 0.0506s/iter; left time: 65.1674s\n",
      "\titers: 600, epoch: 9 | loss: 0.0126490\n",
      "\tspeed: 0.0506s/iter; left time: 60.0698s\n",
      "\titers: 700, epoch: 9 | loss: 0.0142652\n",
      "\tspeed: 0.0510s/iter; left time: 55.3962s\n",
      "\titers: 800, epoch: 9 | loss: 0.0162107\n",
      "\tspeed: 0.0506s/iter; left time: 49.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.36s\n",
      "Steps: 893 | Train Loss: 0.0171276 Vali Loss: 0.0202876 Test Loss: 0.0231598\n",
      "Validation loss decreased (0.020311 --> 0.020288).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0123887\n",
      "\tspeed: 0.1859s/iter; left time: 147.6380s\n",
      "\titers: 200, epoch: 10 | loss: 0.0122240\n",
      "\tspeed: 0.0506s/iter; left time: 35.1404s\n",
      "\titers: 300, epoch: 10 | loss: 0.0185827\n",
      "\tspeed: 0.0508s/iter; left time: 30.1505s\n",
      "\titers: 400, epoch: 10 | loss: 0.0139132\n",
      "\tspeed: 0.0510s/iter; left time: 25.2107s\n",
      "\titers: 500, epoch: 10 | loss: 0.0885992\n",
      "\tspeed: 0.0508s/iter; left time: 20.0225s\n",
      "\titers: 600, epoch: 10 | loss: 0.0195187\n",
      "\tspeed: 0.0505s/iter; left time: 14.8439s\n",
      "\titers: 700, epoch: 10 | loss: 0.0125244\n",
      "\tspeed: 0.0512s/iter; left time: 9.9240s\n",
      "\titers: 800, epoch: 10 | loss: 0.0164415\n",
      "\tspeed: 0.0508s/iter; left time: 4.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.59s\n",
      "Steps: 893 | Train Loss: 0.0193419 Vali Loss: 0.0261223 Test Loss: 0.0303472\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02315976470708847, rmse:0.15218332409858704, mae:0.09934287518262863, rse:0.5374395251274109\n",
      "Original data scale mse:18291816.0, rmse:4276.89306640625, mae:2723.598876953125, rse:0.21265576779842377\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0898976\n",
      "\tspeed: 0.0741s/iter; left time: 653.1570s\n",
      "\titers: 200, epoch: 1 | loss: 0.0708223\n",
      "\tspeed: 0.0510s/iter; left time: 443.9286s\n",
      "\titers: 300, epoch: 1 | loss: 0.0569122\n",
      "\tspeed: 0.0517s/iter; left time: 445.4802s\n",
      "\titers: 400, epoch: 1 | loss: 0.0454593\n",
      "\tspeed: 0.0517s/iter; left time: 440.2670s\n",
      "\titers: 500, epoch: 1 | loss: 0.0442200\n",
      "\tspeed: 0.0514s/iter; left time: 431.9718s\n",
      "\titers: 600, epoch: 1 | loss: 0.0379681\n",
      "\tspeed: 0.0513s/iter; left time: 426.6789s\n",
      "\titers: 700, epoch: 1 | loss: 0.0379627\n",
      "\tspeed: 0.0515s/iter; left time: 422.8719s\n",
      "\titers: 800, epoch: 1 | loss: 0.0402865\n",
      "\tspeed: 0.0513s/iter; left time: 415.8829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.30s\n",
      "Steps: 891 | Train Loss: 0.0554252 Vali Loss: 0.0363158 Test Loss: 0.0423456\n",
      "Validation loss decreased (inf --> 0.036316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0401363\n",
      "\tspeed: 0.1849s/iter; left time: 1464.0327s\n",
      "\titers: 200, epoch: 2 | loss: 0.0252000\n",
      "\tspeed: 0.0514s/iter; left time: 401.9002s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294650\n",
      "\tspeed: 0.0513s/iter; left time: 396.2799s\n",
      "\titers: 400, epoch: 2 | loss: 0.0274815\n",
      "\tspeed: 0.0512s/iter; left time: 390.0853s\n",
      "\titers: 500, epoch: 2 | loss: 0.0206962\n",
      "\tspeed: 0.0517s/iter; left time: 388.6882s\n",
      "\titers: 600, epoch: 2 | loss: 0.0216226\n",
      "\tspeed: 0.0520s/iter; left time: 385.5134s\n",
      "\titers: 700, epoch: 2 | loss: 0.0229341\n",
      "\tspeed: 0.0513s/iter; left time: 375.4983s\n",
      "\titers: 800, epoch: 2 | loss: 0.0346711\n",
      "\tspeed: 0.0514s/iter; left time: 371.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 891 | Train Loss: 0.0331284 Vali Loss: 0.0436025 Test Loss: 0.0518451\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0250928\n",
      "\tspeed: 0.1892s/iter; left time: 1329.8842s\n",
      "\titers: 200, epoch: 3 | loss: 0.0223674\n",
      "\tspeed: 0.0517s/iter; left time: 358.4950s\n",
      "\titers: 300, epoch: 3 | loss: 0.0242723\n",
      "\tspeed: 0.0513s/iter; left time: 350.6152s\n",
      "\titers: 400, epoch: 3 | loss: 0.0220188\n",
      "\tspeed: 0.0512s/iter; left time: 344.4660s\n",
      "\titers: 500, epoch: 3 | loss: 0.0298991\n",
      "\tspeed: 0.0513s/iter; left time: 340.2392s\n",
      "\titers: 600, epoch: 3 | loss: 0.0232173\n",
      "\tspeed: 0.0522s/iter; left time: 340.7898s\n",
      "\titers: 700, epoch: 3 | loss: 0.0263925\n",
      "\tspeed: 0.0515s/iter; left time: 331.2999s\n",
      "\titers: 800, epoch: 3 | loss: 0.2027422\n",
      "\tspeed: 0.0519s/iter; left time: 328.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.32s\n",
      "Steps: 891 | Train Loss: 0.0348487 Vali Loss: 0.0603632 Test Loss: 0.0670758\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0358179\n",
      "\tspeed: 0.1837s/iter; left time: 1127.3000s\n",
      "\titers: 200, epoch: 4 | loss: 0.0302912\n",
      "\tspeed: 0.0514s/iter; left time: 310.5020s\n",
      "\titers: 300, epoch: 4 | loss: 0.0339807\n",
      "\tspeed: 0.0518s/iter; left time: 307.4406s\n",
      "\titers: 400, epoch: 4 | loss: 0.0344218\n",
      "\tspeed: 0.0515s/iter; left time: 300.8306s\n",
      "\titers: 500, epoch: 4 | loss: 0.0287116\n",
      "\tspeed: 0.0514s/iter; left time: 294.8065s\n",
      "\titers: 600, epoch: 4 | loss: 0.0322211\n",
      "\tspeed: 0.0520s/iter; left time: 292.9588s\n",
      "\titers: 700, epoch: 4 | loss: 0.0963653\n",
      "\tspeed: 0.0515s/iter; left time: 285.4436s\n",
      "\titers: 800, epoch: 4 | loss: 0.0292881\n",
      "\tspeed: 0.0519s/iter; left time: 282.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 891 | Train Loss: 0.0345918 Vali Loss: 0.0482134 Test Loss: 0.0535568\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042345594614744186, rmse:0.20578044652938843, mae:0.1441667377948761, rse:0.7287101745605469\n",
      "Original data scale mse:37627388.0, rmse:6134.11669921875, mae:4097.5498046875, rse:0.3054812252521515\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0852662\n",
      "\tspeed: 0.0539s/iter; left time: 474.7936s\n",
      "\titers: 200, epoch: 1 | loss: 0.0627623\n",
      "\tspeed: 0.0511s/iter; left time: 444.9615s\n",
      "\titers: 300, epoch: 1 | loss: 0.0662281\n",
      "\tspeed: 0.0516s/iter; left time: 444.7285s\n",
      "\titers: 400, epoch: 1 | loss: 0.0498636\n",
      "\tspeed: 0.0520s/iter; left time: 442.3610s\n",
      "\titers: 500, epoch: 1 | loss: 0.0424981\n",
      "\tspeed: 0.0512s/iter; left time: 430.7242s\n",
      "\titers: 600, epoch: 1 | loss: 0.0364280\n",
      "\tspeed: 0.0519s/iter; left time: 431.2911s\n",
      "\titers: 700, epoch: 1 | loss: 0.0357536\n",
      "\tspeed: 0.0515s/iter; left time: 422.4765s\n",
      "\titers: 800, epoch: 1 | loss: 0.0305926\n",
      "\tspeed: 0.0514s/iter; left time: 416.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 891 | Train Loss: 0.0545928 Vali Loss: 0.0358070 Test Loss: 0.0409772\n",
      "Validation loss decreased (inf --> 0.035807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0314706\n",
      "\tspeed: 0.1867s/iter; left time: 1478.6550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237816\n",
      "\tspeed: 0.0513s/iter; left time: 401.2282s\n",
      "\titers: 300, epoch: 2 | loss: 0.0336006\n",
      "\tspeed: 0.0515s/iter; left time: 397.4040s\n",
      "\titers: 400, epoch: 2 | loss: 0.0317686\n",
      "\tspeed: 0.0512s/iter; left time: 389.7871s\n",
      "\titers: 500, epoch: 2 | loss: 0.0207349\n",
      "\tspeed: 0.0521s/iter; left time: 391.6963s\n",
      "\titers: 600, epoch: 2 | loss: 0.0268169\n",
      "\tspeed: 0.0509s/iter; left time: 377.9925s\n",
      "\titers: 700, epoch: 2 | loss: 0.0245378\n",
      "\tspeed: 0.0543s/iter; left time: 397.2213s\n",
      "\titers: 800, epoch: 2 | loss: 0.0235130\n",
      "\tspeed: 0.0504s/iter; left time: 363.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.21s\n",
      "Steps: 891 | Train Loss: 0.0305210 Vali Loss: 0.0323818 Test Loss: 0.0381951\n",
      "Validation loss decreased (0.035807 --> 0.032382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0249535\n",
      "\tspeed: 0.1857s/iter; left time: 1305.0379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0215990\n",
      "\tspeed: 0.0516s/iter; left time: 357.2131s\n",
      "\titers: 300, epoch: 3 | loss: 0.0272987\n",
      "\tspeed: 0.0514s/iter; left time: 351.2427s\n",
      "\titers: 400, epoch: 3 | loss: 0.0321735\n",
      "\tspeed: 0.0520s/iter; left time: 349.9800s\n",
      "\titers: 500, epoch: 3 | loss: 0.0260557\n",
      "\tspeed: 0.0511s/iter; left time: 338.8483s\n",
      "\titers: 600, epoch: 3 | loss: 0.0302418\n",
      "\tspeed: 0.0517s/iter; left time: 337.6561s\n",
      "\titers: 700, epoch: 3 | loss: 0.0272865\n",
      "\tspeed: 0.0521s/iter; left time: 334.9479s\n",
      "\titers: 800, epoch: 3 | loss: 0.0454201\n",
      "\tspeed: 0.0523s/iter; left time: 330.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.38s\n",
      "Steps: 891 | Train Loss: 0.0308411 Vali Loss: 0.0486942 Test Loss: 0.0555486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1178505\n",
      "\tspeed: 0.1844s/iter; left time: 1131.5486s\n",
      "\titers: 200, epoch: 4 | loss: 0.0273620\n",
      "\tspeed: 0.0516s/iter; left time: 311.5729s\n",
      "\titers: 300, epoch: 4 | loss: 0.0237972\n",
      "\tspeed: 0.0513s/iter; left time: 304.7700s\n",
      "\titers: 400, epoch: 4 | loss: 0.0277754\n",
      "\tspeed: 0.0515s/iter; left time: 300.4807s\n",
      "\titers: 500, epoch: 4 | loss: 0.0218356\n",
      "\tspeed: 0.0520s/iter; left time: 298.6025s\n",
      "\titers: 600, epoch: 4 | loss: 0.0303578\n",
      "\tspeed: 0.0526s/iter; left time: 296.7779s\n",
      "\titers: 700, epoch: 4 | loss: 0.0658746\n",
      "\tspeed: 0.0517s/iter; left time: 286.5437s\n",
      "\titers: 800, epoch: 4 | loss: 0.0339334\n",
      "\tspeed: 0.0519s/iter; left time: 282.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.33s\n",
      "Steps: 891 | Train Loss: 0.0407891 Vali Loss: 0.0412829 Test Loss: 0.0475258\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0246762\n",
      "\tspeed: 0.1848s/iter; left time: 969.8898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0222932\n",
      "\tspeed: 0.0514s/iter; left time: 264.6840s\n",
      "\titers: 300, epoch: 5 | loss: 0.0228066\n",
      "\tspeed: 0.0516s/iter; left time: 260.2059s\n",
      "\titers: 400, epoch: 5 | loss: 0.0256367\n",
      "\tspeed: 0.0516s/iter; left time: 255.1761s\n",
      "\titers: 500, epoch: 5 | loss: 0.0274541\n",
      "\tspeed: 0.0517s/iter; left time: 250.5248s\n",
      "\titers: 600, epoch: 5 | loss: 0.0282266\n",
      "\tspeed: 0.0515s/iter; left time: 244.2806s\n",
      "\titers: 700, epoch: 5 | loss: 0.0263960\n",
      "\tspeed: 0.0515s/iter; left time: 239.3244s\n",
      "\titers: 800, epoch: 5 | loss: 0.0282295\n",
      "\tspeed: 0.0516s/iter; left time: 234.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 891 | Train Loss: 0.0290182 Vali Loss: 0.0334726 Test Loss: 0.0403731\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03819509223103523, rmse:0.19543564319610596, mae:0.13641740381717682, rse:0.6920771598815918\n",
      "Original data scale mse:34112108.0, rmse:5840.55712890625, mae:3830.144775390625, rse:0.2908618450164795\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0888382\n",
      "\tspeed: 0.0760s/iter; left time: 668.3962s\n",
      "\titers: 200, epoch: 1 | loss: 0.0694285\n",
      "\tspeed: 0.0516s/iter; left time: 448.6627s\n",
      "\titers: 300, epoch: 1 | loss: 0.0607677\n",
      "\tspeed: 0.0516s/iter; left time: 443.5817s\n",
      "\titers: 400, epoch: 1 | loss: 0.0541869\n",
      "\tspeed: 0.0514s/iter; left time: 436.6786s\n",
      "\titers: 500, epoch: 1 | loss: 0.0497022\n",
      "\tspeed: 0.0514s/iter; left time: 431.0021s\n",
      "\titers: 600, epoch: 1 | loss: 0.0400657\n",
      "\tspeed: 0.0519s/iter; left time: 430.0348s\n",
      "\titers: 700, epoch: 1 | loss: 0.0389284\n",
      "\tspeed: 0.0524s/iter; left time: 428.8792s\n",
      "\titers: 800, epoch: 1 | loss: 0.0374739\n",
      "\tspeed: 0.0526s/iter; left time: 425.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 889 | Train Loss: 0.0560617 Vali Loss: 0.0378708 Test Loss: 0.0443880\n",
      "Validation loss decreased (inf --> 0.037871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0429805\n",
      "\tspeed: 0.1863s/iter; left time: 1472.2925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277313\n",
      "\tspeed: 0.0527s/iter; left time: 411.0917s\n",
      "\titers: 300, epoch: 2 | loss: 0.0342847\n",
      "\tspeed: 0.0526s/iter; left time: 405.5029s\n",
      "\titers: 400, epoch: 2 | loss: 0.0299007\n",
      "\tspeed: 0.0523s/iter; left time: 397.9377s\n",
      "\titers: 500, epoch: 2 | loss: 0.0292404\n",
      "\tspeed: 0.0521s/iter; left time: 391.1038s\n",
      "\titers: 600, epoch: 2 | loss: 0.0252770\n",
      "\tspeed: 0.0527s/iter; left time: 390.3947s\n",
      "\titers: 700, epoch: 2 | loss: 0.0276976\n",
      "\tspeed: 0.0524s/iter; left time: 382.8406s\n",
      "\titers: 800, epoch: 2 | loss: 0.0280063\n",
      "\tspeed: 0.0518s/iter; left time: 372.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.75s\n",
      "Steps: 889 | Train Loss: 0.0323019 Vali Loss: 0.0385018 Test Loss: 0.0458075\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0251141\n",
      "\tspeed: 0.1863s/iter; left time: 1306.8397s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204771\n",
      "\tspeed: 0.0527s/iter; left time: 364.6193s\n",
      "\titers: 300, epoch: 3 | loss: 0.0273905\n",
      "\tspeed: 0.0525s/iter; left time: 357.4065s\n",
      "\titers: 400, epoch: 3 | loss: 0.0296237\n",
      "\tspeed: 0.0524s/iter; left time: 351.4474s\n",
      "\titers: 500, epoch: 3 | loss: 0.0332185\n",
      "\tspeed: 0.0524s/iter; left time: 346.2937s\n",
      "\titers: 600, epoch: 3 | loss: 0.0297045\n",
      "\tspeed: 0.0520s/iter; left time: 338.7931s\n",
      "\titers: 700, epoch: 3 | loss: 0.0273236\n",
      "\tspeed: 0.0530s/iter; left time: 339.8315s\n",
      "\titers: 800, epoch: 3 | loss: 0.0288009\n",
      "\tspeed: 0.0528s/iter; left time: 333.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 889 | Train Loss: 0.0321372 Vali Loss: 0.0508873 Test Loss: 0.0586393\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0730308\n",
      "\tspeed: 0.1861s/iter; left time: 1139.6871s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831938\n",
      "\tspeed: 0.0529s/iter; left time: 318.6523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0541538\n",
      "\tspeed: 0.0519s/iter; left time: 307.1927s\n",
      "\titers: 400, epoch: 4 | loss: 0.0337207\n",
      "\tspeed: 0.0527s/iter; left time: 306.6765s\n",
      "\titers: 500, epoch: 4 | loss: 0.0375476\n",
      "\tspeed: 0.0524s/iter; left time: 299.7874s\n",
      "\titers: 600, epoch: 4 | loss: 0.0319393\n",
      "\tspeed: 0.0526s/iter; left time: 295.5580s\n",
      "\titers: 700, epoch: 4 | loss: 0.0323389\n",
      "\tspeed: 0.0521s/iter; left time: 287.8345s\n",
      "\titers: 800, epoch: 4 | loss: 0.0331901\n",
      "\tspeed: 0.0524s/iter; left time: 284.3914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.94s\n",
      "Steps: 889 | Train Loss: 0.0464878 Vali Loss: 0.0371324 Test Loss: 0.0458050\n",
      "Validation loss decreased (0.037871 --> 0.037132).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0284479\n",
      "\tspeed: 0.1908s/iter; left time: 998.8633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0277144\n",
      "\tspeed: 0.0524s/iter; left time: 269.0983s\n",
      "\titers: 300, epoch: 5 | loss: 0.0289152\n",
      "\tspeed: 0.0512s/iter; left time: 257.7343s\n",
      "\titers: 400, epoch: 5 | loss: 0.0261952\n",
      "\tspeed: 0.0517s/iter; left time: 254.9652s\n",
      "\titers: 500, epoch: 5 | loss: 0.0281568\n",
      "\tspeed: 0.0518s/iter; left time: 250.6415s\n",
      "\titers: 600, epoch: 5 | loss: 0.0272779\n",
      "\tspeed: 0.0525s/iter; left time: 248.7681s\n",
      "\titers: 700, epoch: 5 | loss: 0.0282381\n",
      "\tspeed: 0.0528s/iter; left time: 244.5883s\n",
      "\titers: 800, epoch: 5 | loss: 0.0246174\n",
      "\tspeed: 0.0529s/iter; left time: 239.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 889 | Train Loss: 0.0286514 Vali Loss: 0.0340801 Test Loss: 0.0445965\n",
      "Validation loss decreased (0.037132 --> 0.034080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0276842\n",
      "\tspeed: 0.1870s/iter; left time: 812.8664s\n",
      "\titers: 200, epoch: 6 | loss: 0.0293742\n",
      "\tspeed: 0.0529s/iter; left time: 224.4712s\n",
      "\titers: 300, epoch: 6 | loss: 0.0289088\n",
      "\tspeed: 0.0526s/iter; left time: 218.0931s\n",
      "\titers: 400, epoch: 6 | loss: 0.0316670\n",
      "\tspeed: 0.0524s/iter; left time: 212.0398s\n",
      "\titers: 500, epoch: 6 | loss: 0.0327737\n",
      "\tspeed: 0.0526s/iter; left time: 207.4556s\n",
      "\titers: 600, epoch: 6 | loss: 0.0290152\n",
      "\tspeed: 0.0521s/iter; left time: 200.2658s\n",
      "\titers: 700, epoch: 6 | loss: 0.0240823\n",
      "\tspeed: 0.0519s/iter; left time: 194.5504s\n",
      "\titers: 800, epoch: 6 | loss: 0.0244310\n",
      "\tspeed: 0.0527s/iter; left time: 192.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.87s\n",
      "Steps: 889 | Train Loss: 0.0281667 Vali Loss: 0.0345875 Test Loss: 0.0458266\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0310720\n",
      "\tspeed: 0.1855s/iter; left time: 641.1078s\n",
      "\titers: 200, epoch: 7 | loss: 0.0398421\n",
      "\tspeed: 0.0524s/iter; left time: 175.9305s\n",
      "\titers: 300, epoch: 7 | loss: 0.0375238\n",
      "\tspeed: 0.0531s/iter; left time: 172.9533s\n",
      "\titers: 400, epoch: 7 | loss: 0.0233207\n",
      "\tspeed: 0.0524s/iter; left time: 165.5840s\n",
      "\titers: 500, epoch: 7 | loss: 0.0324207\n",
      "\tspeed: 0.0519s/iter; left time: 158.5145s\n",
      "\titers: 600, epoch: 7 | loss: 0.0249276\n",
      "\tspeed: 0.0523s/iter; left time: 154.7409s\n",
      "\titers: 700, epoch: 7 | loss: 0.0240854\n",
      "\tspeed: 0.0523s/iter; left time: 149.3477s\n",
      "\titers: 800, epoch: 7 | loss: 0.0238114\n",
      "\tspeed: 0.0521s/iter; left time: 143.5875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.80s\n",
      "Steps: 889 | Train Loss: 0.0310784 Vali Loss: 0.0371435 Test Loss: 0.0473995\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0250153\n",
      "\tspeed: 0.1857s/iter; left time: 476.9560s\n",
      "\titers: 200, epoch: 8 | loss: 0.0323935\n",
      "\tspeed: 0.0523s/iter; left time: 129.1913s\n",
      "\titers: 300, epoch: 8 | loss: 0.0215329\n",
      "\tspeed: 0.0524s/iter; left time: 124.1798s\n",
      "\titers: 400, epoch: 8 | loss: 0.0240333\n",
      "\tspeed: 0.0520s/iter; left time: 117.9454s\n",
      "\titers: 500, epoch: 8 | loss: 0.0226869\n",
      "\tspeed: 0.0518s/iter; left time: 112.3577s\n",
      "\titers: 600, epoch: 8 | loss: 0.0230713\n",
      "\tspeed: 0.0522s/iter; left time: 107.9746s\n",
      "\titers: 700, epoch: 8 | loss: 0.0370846\n",
      "\tspeed: 0.0522s/iter; left time: 102.6489s\n",
      "\titers: 800, epoch: 8 | loss: 0.0244681\n",
      "\tspeed: 0.0525s/iter; left time: 98.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.70s\n",
      "Steps: 889 | Train Loss: 0.0264354 Vali Loss: 0.0345099 Test Loss: 0.0478705\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459647461771965, rmse:0.21117877960205078, mae:0.1488092690706253, rse:0.7481427788734436\n",
      "Original data scale mse:40797516.0, rmse:6387.29345703125, mae:4201.81494140625, rse:0.31824561953544617\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0898091\n",
      "\tspeed: 0.0543s/iter; left time: 476.9160s\n",
      "\titers: 200, epoch: 1 | loss: 0.0683999\n",
      "\tspeed: 0.0509s/iter; left time: 442.0565s\n",
      "\titers: 300, epoch: 1 | loss: 0.0547635\n",
      "\tspeed: 0.0521s/iter; left time: 447.6564s\n",
      "\titers: 400, epoch: 1 | loss: 0.0432415\n",
      "\tspeed: 0.0523s/iter; left time: 443.8964s\n",
      "\titers: 500, epoch: 1 | loss: 0.0500627\n",
      "\tspeed: 0.0520s/iter; left time: 436.7469s\n",
      "\titers: 600, epoch: 1 | loss: 0.0379077\n",
      "\tspeed: 0.0518s/iter; left time: 429.7911s\n",
      "\titers: 700, epoch: 1 | loss: 0.0490888\n",
      "\tspeed: 0.0527s/iter; left time: 431.2757s\n",
      "\titers: 800, epoch: 1 | loss: 0.0428982\n",
      "\tspeed: 0.0529s/iter; left time: 428.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 889 | Train Loss: 0.0563741 Vali Loss: 0.0370020 Test Loss: 0.0429488\n",
      "Validation loss decreased (inf --> 0.037002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0338767\n",
      "\tspeed: 0.1905s/iter; left time: 1505.0263s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277708\n",
      "\tspeed: 0.0525s/iter; left time: 409.3009s\n",
      "\titers: 300, epoch: 2 | loss: 0.0251262\n",
      "\tspeed: 0.0519s/iter; left time: 399.6049s\n",
      "\titers: 400, epoch: 2 | loss: 0.0281210\n",
      "\tspeed: 0.0522s/iter; left time: 396.6558s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265468\n",
      "\tspeed: 0.0528s/iter; left time: 396.2313s\n",
      "\titers: 600, epoch: 2 | loss: 0.0296902\n",
      "\tspeed: 0.0528s/iter; left time: 390.5075s\n",
      "\titers: 700, epoch: 2 | loss: 0.0216061\n",
      "\tspeed: 0.0520s/iter; left time: 379.6128s\n",
      "\titers: 800, epoch: 2 | loss: 0.0272976\n",
      "\tspeed: 0.0523s/iter; left time: 376.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.86s\n",
      "Steps: 889 | Train Loss: 0.0323584 Vali Loss: 0.0381181 Test Loss: 0.0455699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0305601\n",
      "\tspeed: 0.1851s/iter; left time: 1298.3272s\n",
      "\titers: 200, epoch: 3 | loss: 0.0294327\n",
      "\tspeed: 0.0522s/iter; left time: 360.5374s\n",
      "\titers: 300, epoch: 3 | loss: 0.0276987\n",
      "\tspeed: 0.0520s/iter; left time: 354.2009s\n",
      "\titers: 400, epoch: 3 | loss: 0.0316389\n",
      "\tspeed: 0.0522s/iter; left time: 350.1903s\n",
      "\titers: 500, epoch: 3 | loss: 0.0310125\n",
      "\tspeed: 0.0522s/iter; left time: 344.9069s\n",
      "\titers: 600, epoch: 3 | loss: 0.0362121\n",
      "\tspeed: 0.0526s/iter; left time: 342.3597s\n",
      "\titers: 700, epoch: 3 | loss: 0.0596186\n",
      "\tspeed: 0.0517s/iter; left time: 331.5651s\n",
      "\titers: 800, epoch: 3 | loss: 0.0472811\n",
      "\tspeed: 0.0518s/iter; left time: 326.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 889 | Train Loss: 0.0373884 Vali Loss: 0.0452246 Test Loss: 0.0539904\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0430337\n",
      "\tspeed: 0.1855s/iter; left time: 1135.9358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0299234\n",
      "\tspeed: 0.0523s/iter; left time: 315.3036s\n",
      "\titers: 300, epoch: 4 | loss: 0.0335060\n",
      "\tspeed: 0.0525s/iter; left time: 311.2988s\n",
      "\titers: 400, epoch: 4 | loss: 0.0302610\n",
      "\tspeed: 0.0526s/iter; left time: 306.2596s\n",
      "\titers: 500, epoch: 4 | loss: 0.0276472\n",
      "\tspeed: 0.0520s/iter; left time: 297.6139s\n",
      "\titers: 600, epoch: 4 | loss: 0.0275331\n",
      "\tspeed: 0.0524s/iter; left time: 294.7657s\n",
      "\titers: 700, epoch: 4 | loss: 0.0314489\n",
      "\tspeed: 0.0522s/iter; left time: 288.3134s\n",
      "\titers: 800, epoch: 4 | loss: 0.0334173\n",
      "\tspeed: 0.0522s/iter; left time: 283.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.74s\n",
      "Steps: 889 | Train Loss: 0.0342779 Vali Loss: 0.0505663 Test Loss: 0.0559997\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042948778718709946, rmse:0.20724086463451385, mae:0.14715154469013214, rse:0.7341920137405396\n",
      "Original data scale mse:40016304.0, rmse:6325.84423828125, mae:4216.599609375, rse:0.31518393754959106\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2667935\n",
      "\tspeed: 0.0770s/iter; left time: 679.8272s\n",
      "\titers: 200, epoch: 1 | loss: 0.2580521\n",
      "\tspeed: 0.0508s/iter; left time: 443.3949s\n",
      "\titers: 300, epoch: 1 | loss: 0.2223780\n",
      "\tspeed: 0.0508s/iter; left time: 438.2336s\n",
      "\titers: 400, epoch: 1 | loss: 0.2138453\n",
      "\tspeed: 0.0510s/iter; left time: 434.7752s\n",
      "\titers: 500, epoch: 1 | loss: 0.2004627\n",
      "\tspeed: 0.0504s/iter; left time: 425.3362s\n",
      "\titers: 600, epoch: 1 | loss: 0.1992375\n",
      "\tspeed: 0.0506s/iter; left time: 421.2432s\n",
      "\titers: 700, epoch: 1 | loss: 0.1717654\n",
      "\tspeed: 0.0507s/iter; left time: 416.9749s\n",
      "\titers: 800, epoch: 1 | loss: 0.1729079\n",
      "\tspeed: 0.0508s/iter; left time: 413.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 893 | Train Loss: 0.2125009 Vali Loss: 0.0247184 Test Loss: 0.0270354\n",
      "Validation loss decreased (inf --> 0.024718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1863800\n",
      "\tspeed: 0.1870s/iter; left time: 1484.1128s\n",
      "\titers: 200, epoch: 2 | loss: 0.1660040\n",
      "\tspeed: 0.0505s/iter; left time: 395.7646s\n",
      "\titers: 300, epoch: 2 | loss: 0.1364938\n",
      "\tspeed: 0.0507s/iter; left time: 392.1121s\n",
      "\titers: 400, epoch: 2 | loss: 0.1331088\n",
      "\tspeed: 0.0505s/iter; left time: 385.4734s\n",
      "\titers: 500, epoch: 2 | loss: 0.1509917\n",
      "\tspeed: 0.0503s/iter; left time: 379.1606s\n",
      "\titers: 600, epoch: 2 | loss: 0.1571442\n",
      "\tspeed: 0.0509s/iter; left time: 378.5748s\n",
      "\titers: 700, epoch: 2 | loss: 0.1335184\n",
      "\tspeed: 0.0508s/iter; left time: 372.5700s\n",
      "\titers: 800, epoch: 2 | loss: 0.1152891\n",
      "\tspeed: 0.0509s/iter; left time: 368.5354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.1478759 Vali Loss: 0.0224017 Test Loss: 0.0247429\n",
      "Validation loss decreased (0.024718 --> 0.022402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1100226\n",
      "\tspeed: 0.1865s/iter; left time: 1313.5443s\n",
      "\titers: 200, epoch: 3 | loss: 0.1530367\n",
      "\tspeed: 0.0506s/iter; left time: 351.3994s\n",
      "\titers: 300, epoch: 3 | loss: 0.1144963\n",
      "\tspeed: 0.0510s/iter; left time: 348.9010s\n",
      "\titers: 400, epoch: 3 | loss: 0.1163256\n",
      "\tspeed: 0.0506s/iter; left time: 341.5512s\n",
      "\titers: 500, epoch: 3 | loss: 0.2570778\n",
      "\tspeed: 0.0507s/iter; left time: 336.8220s\n",
      "\titers: 600, epoch: 3 | loss: 0.1622165\n",
      "\tspeed: 0.0503s/iter; left time: 329.1960s\n",
      "\titers: 700, epoch: 3 | loss: 0.1049144\n",
      "\tspeed: 0.0506s/iter; left time: 326.1386s\n",
      "\titers: 800, epoch: 3 | loss: 0.1333985\n",
      "\tspeed: 0.0506s/iter; left time: 320.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.54s\n",
      "Steps: 893 | Train Loss: 0.1425496 Vali Loss: 0.0336046 Test Loss: 0.0357040\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1423023\n",
      "\tspeed: 0.1825s/iter; left time: 1122.8416s\n",
      "\titers: 200, epoch: 4 | loss: 0.1204192\n",
      "\tspeed: 0.0507s/iter; left time: 306.6315s\n",
      "\titers: 300, epoch: 4 | loss: 0.1236560\n",
      "\tspeed: 0.0506s/iter; left time: 301.2752s\n",
      "\titers: 400, epoch: 4 | loss: 0.1334927\n",
      "\tspeed: 0.0507s/iter; left time: 296.9205s\n",
      "\titers: 500, epoch: 4 | loss: 0.1478318\n",
      "\tspeed: 0.0506s/iter; left time: 290.8882s\n",
      "\titers: 600, epoch: 4 | loss: 0.1267568\n",
      "\tspeed: 0.0502s/iter; left time: 283.4616s\n",
      "\titers: 700, epoch: 4 | loss: 0.1415466\n",
      "\tspeed: 0.0518s/iter; left time: 287.5869s\n",
      "\titers: 800, epoch: 4 | loss: 0.1633215\n",
      "\tspeed: 0.0497s/iter; left time: 271.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.45s\n",
      "Steps: 893 | Train Loss: 0.1582891 Vali Loss: 0.0230042 Test Loss: 0.0254217\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1623549\n",
      "\tspeed: 0.1838s/iter; left time: 966.8244s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184670\n",
      "\tspeed: 0.0506s/iter; left time: 260.9303s\n",
      "\titers: 300, epoch: 5 | loss: 0.1306548\n",
      "\tspeed: 0.0509s/iter; left time: 257.3625s\n",
      "\titers: 400, epoch: 5 | loss: 0.1558392\n",
      "\tspeed: 0.0506s/iter; left time: 251.1717s\n",
      "\titers: 500, epoch: 5 | loss: 0.1227018\n",
      "\tspeed: 0.0508s/iter; left time: 246.7338s\n",
      "\titers: 600, epoch: 5 | loss: 0.1086328\n",
      "\tspeed: 0.0510s/iter; left time: 242.7029s\n",
      "\titers: 700, epoch: 5 | loss: 0.1170880\n",
      "\tspeed: 0.0505s/iter; left time: 235.1560s\n",
      "\titers: 800, epoch: 5 | loss: 0.1247232\n",
      "\tspeed: 0.0507s/iter; left time: 231.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 893 | Train Loss: 0.1374177 Vali Loss: 0.0319526 Test Loss: 0.0359744\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02474287711083889, rmse:0.15729868412017822, mae:0.1036575511097908, rse:0.555504560470581\n",
      "Original data scale mse:20196358.0, rmse:4494.03564453125, mae:2889.832275390625, rse:0.22345252335071564\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2779282\n",
      "\tspeed: 0.0531s/iter; left time: 469.1710s\n",
      "\titers: 200, epoch: 1 | loss: 0.2390803\n",
      "\tspeed: 0.0507s/iter; left time: 442.5337s\n",
      "\titers: 300, epoch: 1 | loss: 0.2268084\n",
      "\tspeed: 0.0506s/iter; left time: 437.0661s\n",
      "\titers: 400, epoch: 1 | loss: 0.2293802\n",
      "\tspeed: 0.0508s/iter; left time: 433.1358s\n",
      "\titers: 500, epoch: 1 | loss: 0.1837658\n",
      "\tspeed: 0.0507s/iter; left time: 427.1459s\n",
      "\titers: 600, epoch: 1 | loss: 0.1928408\n",
      "\tspeed: 0.0505s/iter; left time: 420.5952s\n",
      "\titers: 700, epoch: 1 | loss: 0.1705509\n",
      "\tspeed: 0.0509s/iter; left time: 418.8480s\n",
      "\titers: 800, epoch: 1 | loss: 0.1656219\n",
      "\tspeed: 0.0511s/iter; left time: 415.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 893 | Train Loss: 0.2138857 Vali Loss: 0.0251672 Test Loss: 0.0276361\n",
      "Validation loss decreased (inf --> 0.025167).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1909748\n",
      "\tspeed: 0.1847s/iter; left time: 1465.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1275921\n",
      "\tspeed: 0.0510s/iter; left time: 399.5991s\n",
      "\titers: 300, epoch: 2 | loss: 0.1509326\n",
      "\tspeed: 0.0507s/iter; left time: 392.5938s\n",
      "\titers: 400, epoch: 2 | loss: 0.1442390\n",
      "\tspeed: 0.0512s/iter; left time: 391.2926s\n",
      "\titers: 500, epoch: 2 | loss: 0.1396593\n",
      "\tspeed: 0.0508s/iter; left time: 382.8834s\n",
      "\titers: 600, epoch: 2 | loss: 0.1391160\n",
      "\tspeed: 0.0514s/iter; left time: 382.0740s\n",
      "\titers: 700, epoch: 2 | loss: 0.1435115\n",
      "\tspeed: 0.0508s/iter; left time: 372.7324s\n",
      "\titers: 800, epoch: 2 | loss: 0.1515477\n",
      "\tspeed: 0.0506s/iter; left time: 366.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 893 | Train Loss: 0.1543432 Vali Loss: 0.0273073 Test Loss: 0.0287653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1390001\n",
      "\tspeed: 0.1836s/iter; left time: 1293.7330s\n",
      "\titers: 200, epoch: 3 | loss: 0.1339426\n",
      "\tspeed: 0.0506s/iter; left time: 351.4549s\n",
      "\titers: 300, epoch: 3 | loss: 0.1209359\n",
      "\tspeed: 0.0512s/iter; left time: 350.1631s\n",
      "\titers: 400, epoch: 3 | loss: 0.1398292\n",
      "\tspeed: 0.0503s/iter; left time: 339.2226s\n",
      "\titers: 500, epoch: 3 | loss: 0.1186847\n",
      "\tspeed: 0.0505s/iter; left time: 335.6127s\n",
      "\titers: 600, epoch: 3 | loss: 0.1172402\n",
      "\tspeed: 0.0516s/iter; left time: 337.9809s\n",
      "\titers: 700, epoch: 3 | loss: 0.1051632\n",
      "\tspeed: 0.0500s/iter; left time: 322.4525s\n",
      "\titers: 800, epoch: 3 | loss: 0.1399918\n",
      "\tspeed: 0.0498s/iter; left time: 316.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.49s\n",
      "Steps: 893 | Train Loss: 0.1394945 Vali Loss: 0.0801272 Test Loss: 0.0930919\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1774376\n",
      "\tspeed: 0.1848s/iter; left time: 1136.9994s\n",
      "\titers: 200, epoch: 4 | loss: 0.1217093\n",
      "\tspeed: 0.0506s/iter; left time: 306.5269s\n",
      "\titers: 300, epoch: 4 | loss: 0.1273016\n",
      "\tspeed: 0.0509s/iter; left time: 303.0578s\n",
      "\titers: 400, epoch: 4 | loss: 0.1378618\n",
      "\tspeed: 0.0504s/iter; left time: 295.1823s\n",
      "\titers: 500, epoch: 4 | loss: 0.1201100\n",
      "\tspeed: 0.0507s/iter; left time: 291.3618s\n",
      "\titers: 600, epoch: 4 | loss: 0.2189487\n",
      "\tspeed: 0.0506s/iter; left time: 285.9912s\n",
      "\titers: 700, epoch: 4 | loss: 0.1587457\n",
      "\tspeed: 0.0509s/iter; left time: 282.5200s\n",
      "\titers: 800, epoch: 4 | loss: 0.1149479\n",
      "\tspeed: 0.0507s/iter; left time: 276.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 893 | Train Loss: 0.1554488 Vali Loss: 0.0265880 Test Loss: 0.0300949\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02763606794178486, rmse:0.16624099016189575, mae:0.11141800880432129, rse:0.5870845913887024\n",
      "Original data scale mse:23053352.0, rmse:4801.390625, mae:3150.207275390625, rse:0.23873482644557953\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2982178\n",
      "\tspeed: 0.0751s/iter; left time: 661.4704s\n",
      "\titers: 200, epoch: 1 | loss: 0.2624930\n",
      "\tspeed: 0.0509s/iter; left time: 443.5324s\n",
      "\titers: 300, epoch: 1 | loss: 0.2324546\n",
      "\tspeed: 0.0510s/iter; left time: 438.7809s\n",
      "\titers: 400, epoch: 1 | loss: 0.2067106\n",
      "\tspeed: 0.0506s/iter; left time: 430.4419s\n",
      "\titers: 500, epoch: 1 | loss: 0.2036902\n",
      "\tspeed: 0.0521s/iter; left time: 438.1799s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889434\n",
      "\tspeed: 0.0511s/iter; left time: 424.5144s\n",
      "\titers: 700, epoch: 1 | loss: 0.1896021\n",
      "\tspeed: 0.0516s/iter; left time: 423.9716s\n",
      "\titers: 800, epoch: 1 | loss: 0.1980770\n",
      "\tspeed: 0.0518s/iter; left time: 420.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.18s\n",
      "Steps: 891 | Train Loss: 0.2272330 Vali Loss: 0.0357202 Test Loss: 0.0417701\n",
      "Validation loss decreased (inf --> 0.035720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2064929\n",
      "\tspeed: 0.1881s/iter; left time: 1489.4069s\n",
      "\titers: 200, epoch: 2 | loss: 0.1637664\n",
      "\tspeed: 0.0510s/iter; left time: 398.8077s\n",
      "\titers: 300, epoch: 2 | loss: 0.1592103\n",
      "\tspeed: 0.0512s/iter; left time: 395.5734s\n",
      "\titers: 400, epoch: 2 | loss: 0.1687467\n",
      "\tspeed: 0.0515s/iter; left time: 392.4766s\n",
      "\titers: 500, epoch: 2 | loss: 0.1409779\n",
      "\tspeed: 0.0512s/iter; left time: 384.8180s\n",
      "\titers: 600, epoch: 2 | loss: 0.1440497\n",
      "\tspeed: 0.0512s/iter; left time: 380.0027s\n",
      "\titers: 700, epoch: 2 | loss: 0.1645725\n",
      "\tspeed: 0.0517s/iter; left time: 378.4540s\n",
      "\titers: 800, epoch: 2 | loss: 0.1665554\n",
      "\tspeed: 0.0516s/iter; left time: 372.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 891 | Train Loss: 0.1765515 Vali Loss: 0.0402867 Test Loss: 0.0526145\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1581760\n",
      "\tspeed: 0.1832s/iter; left time: 1288.0547s\n",
      "\titers: 200, epoch: 3 | loss: 0.1500348\n",
      "\tspeed: 0.0514s/iter; left time: 356.4477s\n",
      "\titers: 300, epoch: 3 | loss: 0.1761549\n",
      "\tspeed: 0.0516s/iter; left time: 352.2687s\n",
      "\titers: 400, epoch: 3 | loss: 0.1564396\n",
      "\tspeed: 0.0508s/iter; left time: 341.5919s\n",
      "\titers: 500, epoch: 3 | loss: 0.1672223\n",
      "\tspeed: 0.0506s/iter; left time: 335.6370s\n",
      "\titers: 600, epoch: 3 | loss: 0.1538464\n",
      "\tspeed: 0.0510s/iter; left time: 332.9534s\n",
      "\titers: 700, epoch: 3 | loss: 0.1710698\n",
      "\tspeed: 0.0515s/iter; left time: 330.9106s\n",
      "\titers: 800, epoch: 3 | loss: 0.1853437\n",
      "\tspeed: 0.0514s/iter; left time: 325.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 891 | Train Loss: 0.1772448 Vali Loss: 0.0513917 Test Loss: 0.0559006\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1734857\n",
      "\tspeed: 0.1846s/iter; left time: 1133.2929s\n",
      "\titers: 200, epoch: 4 | loss: 0.2071112\n",
      "\tspeed: 0.0512s/iter; left time: 308.9393s\n",
      "\titers: 300, epoch: 4 | loss: 0.1732179\n",
      "\tspeed: 0.0517s/iter; left time: 306.7429s\n",
      "\titers: 400, epoch: 4 | loss: 0.1830900\n",
      "\tspeed: 0.0515s/iter; left time: 300.8052s\n",
      "\titers: 500, epoch: 4 | loss: 0.1908277\n",
      "\tspeed: 0.0514s/iter; left time: 295.1813s\n",
      "\titers: 600, epoch: 4 | loss: 0.1779769\n",
      "\tspeed: 0.0510s/iter; left time: 287.7171s\n",
      "\titers: 700, epoch: 4 | loss: 0.1641509\n",
      "\tspeed: 0.0516s/iter; left time: 285.9883s\n",
      "\titers: 800, epoch: 4 | loss: 0.1536071\n",
      "\tspeed: 0.0514s/iter; left time: 279.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 891 | Train Loss: 0.1759789 Vali Loss: 0.0377152 Test Loss: 0.0450661\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0417700931429863, rmse:0.20437732338905334, mae:0.14354148507118225, rse:0.7237414717674255\n",
      "Original data scale mse:37400496.0, rmse:6115.5947265625, mae:4083.6396484375, rse:0.30455881357192993\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905224\n",
      "\tspeed: 0.0541s/iter; left time: 476.3775s\n",
      "\titers: 200, epoch: 1 | loss: 0.2478231\n",
      "\tspeed: 0.0514s/iter; left time: 447.4780s\n",
      "\titers: 300, epoch: 1 | loss: 0.2508713\n",
      "\tspeed: 0.0511s/iter; left time: 440.3011s\n",
      "\titers: 400, epoch: 1 | loss: 0.2173596\n",
      "\tspeed: 0.0514s/iter; left time: 437.1737s\n",
      "\titers: 500, epoch: 1 | loss: 0.2019476\n",
      "\tspeed: 0.0515s/iter; left time: 433.2517s\n",
      "\titers: 600, epoch: 1 | loss: 0.1851319\n",
      "\tspeed: 0.0513s/iter; left time: 426.6779s\n",
      "\titers: 700, epoch: 1 | loss: 0.1852116\n",
      "\tspeed: 0.0518s/iter; left time: 425.1461s\n",
      "\titers: 800, epoch: 1 | loss: 0.1701697\n",
      "\tspeed: 0.0523s/iter; left time: 423.8960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 891 | Train Loss: 0.2257705 Vali Loss: 0.0356901 Test Loss: 0.0408679\n",
      "Validation loss decreased (inf --> 0.035690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1766219\n",
      "\tspeed: 0.1867s/iter; left time: 1478.4495s\n",
      "\titers: 200, epoch: 2 | loss: 0.1569152\n",
      "\tspeed: 0.0518s/iter; left time: 405.0618s\n",
      "\titers: 300, epoch: 2 | loss: 0.1903155\n",
      "\tspeed: 0.0515s/iter; left time: 397.5906s\n",
      "\titers: 400, epoch: 2 | loss: 0.1766812\n",
      "\tspeed: 0.0516s/iter; left time: 392.8595s\n",
      "\titers: 500, epoch: 2 | loss: 0.1464813\n",
      "\tspeed: 0.0521s/iter; left time: 391.8746s\n",
      "\titers: 600, epoch: 2 | loss: 0.1728570\n",
      "\tspeed: 0.0519s/iter; left time: 384.8997s\n",
      "\titers: 700, epoch: 2 | loss: 0.1685364\n",
      "\tspeed: 0.0522s/iter; left time: 382.0112s\n",
      "\titers: 800, epoch: 2 | loss: 0.1575332\n",
      "\tspeed: 0.0516s/iter; left time: 372.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 891 | Train Loss: 0.1764099 Vali Loss: 0.0326616 Test Loss: 0.0390360\n",
      "Validation loss decreased (0.035690 --> 0.032662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1591886\n",
      "\tspeed: 0.1862s/iter; left time: 1308.8118s\n",
      "\titers: 200, epoch: 3 | loss: 0.1482840\n",
      "\tspeed: 0.0544s/iter; left time: 377.0902s\n",
      "\titers: 300, epoch: 3 | loss: 0.1686443\n",
      "\tspeed: 0.0508s/iter; left time: 346.8492s\n",
      "\titers: 400, epoch: 3 | loss: 0.1573136\n",
      "\tspeed: 0.0507s/iter; left time: 341.3352s\n",
      "\titers: 500, epoch: 3 | loss: 0.1550483\n",
      "\tspeed: 0.0519s/iter; left time: 343.7490s\n",
      "\titers: 600, epoch: 3 | loss: 0.3653665\n",
      "\tspeed: 0.0516s/iter; left time: 336.7873s\n",
      "\titers: 700, epoch: 3 | loss: 0.2134402\n",
      "\tspeed: 0.0517s/iter; left time: 332.2702s\n",
      "\titers: 800, epoch: 3 | loss: 0.1850701\n",
      "\tspeed: 0.0518s/iter; left time: 328.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.43s\n",
      "Steps: 891 | Train Loss: 0.1822032 Vali Loss: 0.0443810 Test Loss: 0.0515197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1735435\n",
      "\tspeed: 0.1836s/iter; left time: 1127.1271s\n",
      "\titers: 200, epoch: 4 | loss: 0.1826856\n",
      "\tspeed: 0.0519s/iter; left time: 313.6510s\n",
      "\titers: 300, epoch: 4 | loss: 0.1559070\n",
      "\tspeed: 0.0516s/iter; left time: 306.6730s\n",
      "\titers: 400, epoch: 4 | loss: 0.1708269\n",
      "\tspeed: 0.0516s/iter; left time: 301.1164s\n",
      "\titers: 500, epoch: 4 | loss: 0.1657308\n",
      "\tspeed: 0.0514s/iter; left time: 294.7803s\n",
      "\titers: 600, epoch: 4 | loss: 0.1688064\n",
      "\tspeed: 0.0518s/iter; left time: 291.9739s\n",
      "\titers: 700, epoch: 4 | loss: 0.1750592\n",
      "\tspeed: 0.0518s/iter; left time: 286.8813s\n",
      "\titers: 800, epoch: 4 | loss: 0.1598610\n",
      "\tspeed: 0.0515s/iter; left time: 280.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.27s\n",
      "Steps: 891 | Train Loss: 0.1785153 Vali Loss: 0.0372040 Test Loss: 0.0437215\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1626792\n",
      "\tspeed: 0.1856s/iter; left time: 973.9020s\n",
      "\titers: 200, epoch: 5 | loss: 0.1442192\n",
      "\tspeed: 0.0514s/iter; left time: 264.6148s\n",
      "\titers: 300, epoch: 5 | loss: 0.1605345\n",
      "\tspeed: 0.0517s/iter; left time: 260.9906s\n",
      "\titers: 400, epoch: 5 | loss: 0.1693277\n",
      "\tspeed: 0.0522s/iter; left time: 258.0418s\n",
      "\titers: 500, epoch: 5 | loss: 0.1601463\n",
      "\tspeed: 0.0515s/iter; left time: 249.7224s\n",
      "\titers: 600, epoch: 5 | loss: 0.1603393\n",
      "\tspeed: 0.0515s/iter; left time: 244.3627s\n",
      "\titers: 700, epoch: 5 | loss: 0.2077260\n",
      "\tspeed: 0.0519s/iter; left time: 241.1582s\n",
      "\titers: 800, epoch: 5 | loss: 0.1633071\n",
      "\tspeed: 0.0517s/iter; left time: 234.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.39s\n",
      "Steps: 891 | Train Loss: 0.1763571 Vali Loss: 0.0333679 Test Loss: 0.0416124\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03903603553771973, rmse:0.1975753903388977, mae:0.13909867405891418, rse:0.6996544003486633\n",
      "Original data scale mse:34960184.0, rmse:5912.7138671875, mae:3935.287109375, rse:0.29445526003837585\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2962539\n",
      "\tspeed: 0.0766s/iter; left time: 673.3237s\n",
      "\titers: 200, epoch: 1 | loss: 0.2597189\n",
      "\tspeed: 0.0519s/iter; left time: 450.8672s\n",
      "\titers: 300, epoch: 1 | loss: 0.2409032\n",
      "\tspeed: 0.0528s/iter; left time: 453.9701s\n",
      "\titers: 400, epoch: 1 | loss: 0.2257529\n",
      "\tspeed: 0.0528s/iter; left time: 448.4342s\n",
      "\titers: 500, epoch: 1 | loss: 0.2161573\n",
      "\tspeed: 0.0531s/iter; left time: 445.6228s\n",
      "\titers: 600, epoch: 1 | loss: 0.1973591\n",
      "\tspeed: 0.0519s/iter; left time: 430.0998s\n",
      "\titers: 700, epoch: 1 | loss: 0.1953906\n",
      "\tspeed: 0.0519s/iter; left time: 425.2627s\n",
      "\titers: 800, epoch: 1 | loss: 0.1903252\n",
      "\tspeed: 0.0530s/iter; left time: 428.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 889 | Train Loss: 0.2289548 Vali Loss: 0.0373104 Test Loss: 0.0437779\n",
      "Validation loss decreased (inf --> 0.037310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1962126\n",
      "\tspeed: 0.1977s/iter; left time: 1562.4157s\n",
      "\titers: 200, epoch: 2 | loss: 0.1616807\n",
      "\tspeed: 0.0521s/iter; left time: 406.6628s\n",
      "\titers: 300, epoch: 2 | loss: 0.1807901\n",
      "\tspeed: 0.0532s/iter; left time: 409.7283s\n",
      "\titers: 400, epoch: 2 | loss: 0.1725992\n",
      "\tspeed: 0.0527s/iter; left time: 400.4995s\n",
      "\titers: 500, epoch: 2 | loss: 0.1667260\n",
      "\tspeed: 0.0521s/iter; left time: 391.0279s\n",
      "\titers: 600, epoch: 2 | loss: 0.1616608\n",
      "\tspeed: 0.0527s/iter; left time: 389.8426s\n",
      "\titers: 700, epoch: 2 | loss: 0.1625210\n",
      "\tspeed: 0.0526s/iter; left time: 383.9866s\n",
      "\titers: 800, epoch: 2 | loss: 0.1661494\n",
      "\tspeed: 0.0535s/iter; left time: 385.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 889 | Train Loss: 0.1778594 Vali Loss: 0.0342725 Test Loss: 0.0409164\n",
      "Validation loss decreased (0.037310 --> 0.034272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1574290\n",
      "\tspeed: 0.1887s/iter; left time: 1323.0146s\n",
      "\titers: 200, epoch: 3 | loss: 0.1431362\n",
      "\tspeed: 0.0524s/iter; left time: 362.1318s\n",
      "\titers: 300, epoch: 3 | loss: 0.1815083\n",
      "\tspeed: 0.0526s/iter; left time: 358.5971s\n",
      "\titers: 400, epoch: 3 | loss: 0.2047267\n",
      "\tspeed: 0.0530s/iter; left time: 355.5157s\n",
      "\titers: 500, epoch: 3 | loss: 0.1969939\n",
      "\tspeed: 0.0531s/iter; left time: 350.9622s\n",
      "\titers: 600, epoch: 3 | loss: 0.2014310\n",
      "\tspeed: 0.0529s/iter; left time: 344.6922s\n",
      "\titers: 700, epoch: 3 | loss: 0.1706726\n",
      "\tspeed: 0.0525s/iter; left time: 336.9412s\n",
      "\titers: 800, epoch: 3 | loss: 0.1971276\n",
      "\tspeed: 0.0528s/iter; left time: 333.2130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 889 | Train Loss: 0.1877892 Vali Loss: 0.0515518 Test Loss: 0.0571752\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1694866\n",
      "\tspeed: 0.1845s/iter; left time: 1129.9909s\n",
      "\titers: 200, epoch: 4 | loss: 0.1533536\n",
      "\tspeed: 0.0522s/iter; left time: 314.6850s\n",
      "\titers: 300, epoch: 4 | loss: 0.1712260\n",
      "\tspeed: 0.0528s/iter; left time: 312.5277s\n",
      "\titers: 400, epoch: 4 | loss: 0.1704170\n",
      "\tspeed: 0.0521s/iter; left time: 303.1909s\n",
      "\titers: 500, epoch: 4 | loss: 0.2027668\n",
      "\tspeed: 0.0523s/iter; left time: 299.2828s\n",
      "\titers: 600, epoch: 4 | loss: 0.1704978\n",
      "\tspeed: 0.0524s/iter; left time: 294.8546s\n",
      "\titers: 700, epoch: 4 | loss: 0.1803890\n",
      "\tspeed: 0.0520s/iter; left time: 287.2567s\n",
      "\titers: 800, epoch: 4 | loss: 0.1712807\n",
      "\tspeed: 0.0518s/iter; left time: 280.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.78s\n",
      "Steps: 889 | Train Loss: 0.1717168 Vali Loss: 0.0379079 Test Loss: 0.0476264\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1698242\n",
      "\tspeed: 0.1842s/iter; left time: 964.3124s\n",
      "\titers: 200, epoch: 5 | loss: 0.2546397\n",
      "\tspeed: 0.0528s/iter; left time: 271.2411s\n",
      "\titers: 300, epoch: 5 | loss: 0.1922085\n",
      "\tspeed: 0.0529s/iter; left time: 266.1309s\n",
      "\titers: 400, epoch: 5 | loss: 0.1765233\n",
      "\tspeed: 0.0523s/iter; left time: 257.8884s\n",
      "\titers: 500, epoch: 5 | loss: 0.1747154\n",
      "\tspeed: 0.0527s/iter; left time: 254.8064s\n",
      "\titers: 600, epoch: 5 | loss: 0.1772095\n",
      "\tspeed: 0.0527s/iter; left time: 249.4396s\n",
      "\titers: 700, epoch: 5 | loss: 0.1871462\n",
      "\tspeed: 0.0519s/iter; left time: 240.7609s\n",
      "\titers: 800, epoch: 5 | loss: 0.1633518\n",
      "\tspeed: 0.0514s/iter; left time: 233.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.77s\n",
      "Steps: 889 | Train Loss: 0.1771401 Vali Loss: 0.0421679 Test Loss: 0.0515530\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04091637581586838, rmse:0.20227797329425812, mae:0.1402643620967865, rse:0.7166099548339844\n",
      "Original data scale mse:35232612.0, rmse:5935.70654296875, mae:3864.7724609375, rse:0.2957454323768616\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3126400\n",
      "\tspeed: 0.0553s/iter; left time: 486.2099s\n",
      "\titers: 200, epoch: 1 | loss: 0.2838092\n",
      "\tspeed: 0.0526s/iter; left time: 456.7842s\n",
      "\titers: 300, epoch: 1 | loss: 0.2556389\n",
      "\tspeed: 0.0529s/iter; left time: 454.8392s\n",
      "\titers: 400, epoch: 1 | loss: 0.2314915\n",
      "\tspeed: 0.0525s/iter; left time: 445.4127s\n",
      "\titers: 500, epoch: 1 | loss: 0.2110980\n",
      "\tspeed: 0.0527s/iter; left time: 442.4977s\n",
      "\titers: 600, epoch: 1 | loss: 0.1892689\n",
      "\tspeed: 0.0520s/iter; left time: 431.2933s\n",
      "\titers: 700, epoch: 1 | loss: 0.1940349\n",
      "\tspeed: 0.0525s/iter; left time: 430.3962s\n",
      "\titers: 800, epoch: 1 | loss: 0.1824178\n",
      "\tspeed: 0.0530s/iter; left time: 428.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 889 | Train Loss: 0.2303312 Vali Loss: 0.0366757 Test Loss: 0.0426439\n",
      "Validation loss decreased (inf --> 0.036676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1810439\n",
      "\tspeed: 0.1862s/iter; left time: 1471.5125s\n",
      "\titers: 200, epoch: 2 | loss: 0.1716500\n",
      "\tspeed: 0.0529s/iter; left time: 412.8334s\n",
      "\titers: 300, epoch: 2 | loss: 0.1776369\n",
      "\tspeed: 0.0525s/iter; left time: 404.0041s\n",
      "\titers: 400, epoch: 2 | loss: 0.1776479\n",
      "\tspeed: 0.0524s/iter; left time: 398.2469s\n",
      "\titers: 500, epoch: 2 | loss: 0.1882042\n",
      "\tspeed: 0.0527s/iter; left time: 395.2423s\n",
      "\titers: 600, epoch: 2 | loss: 0.1689138\n",
      "\tspeed: 0.0524s/iter; left time: 388.1669s\n",
      "\titers: 700, epoch: 2 | loss: 0.1543402\n",
      "\tspeed: 0.0525s/iter; left time: 383.6116s\n",
      "\titers: 800, epoch: 2 | loss: 0.1663143\n",
      "\tspeed: 0.0523s/iter; left time: 376.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.98s\n",
      "Steps: 889 | Train Loss: 0.1789434 Vali Loss: 0.0574112 Test Loss: 0.0628860\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1614779\n",
      "\tspeed: 0.1846s/iter; left time: 1294.6501s\n",
      "\titers: 200, epoch: 3 | loss: 0.1795685\n",
      "\tspeed: 0.0522s/iter; left time: 360.7042s\n",
      "\titers: 300, epoch: 3 | loss: 0.1917062\n",
      "\tspeed: 0.0536s/iter; left time: 364.9258s\n",
      "\titers: 400, epoch: 3 | loss: 0.1910664\n",
      "\tspeed: 0.0524s/iter; left time: 352.0160s\n",
      "\titers: 500, epoch: 3 | loss: 0.2224540\n",
      "\tspeed: 0.0518s/iter; left time: 342.3536s\n",
      "\titers: 600, epoch: 3 | loss: 0.1679021\n",
      "\tspeed: 0.0524s/iter; left time: 341.1466s\n",
      "\titers: 700, epoch: 3 | loss: 0.1858870\n",
      "\tspeed: 0.0522s/iter; left time: 334.5338s\n",
      "\titers: 800, epoch: 3 | loss: 0.2021402\n",
      "\tspeed: 0.0515s/iter; left time: 325.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.78s\n",
      "Steps: 889 | Train Loss: 0.1894913 Vali Loss: 0.0425699 Test Loss: 0.0521171\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1760504\n",
      "\tspeed: 0.1841s/iter; left time: 1127.7219s\n",
      "\titers: 200, epoch: 4 | loss: 0.1538943\n",
      "\tspeed: 0.0519s/iter; left time: 312.9038s\n",
      "\titers: 300, epoch: 4 | loss: 0.1770946\n",
      "\tspeed: 0.0520s/iter; left time: 308.0655s\n",
      "\titers: 400, epoch: 4 | loss: 0.1555688\n",
      "\tspeed: 0.0529s/iter; left time: 308.3697s\n",
      "\titers: 500, epoch: 4 | loss: 0.1820136\n",
      "\tspeed: 0.0523s/iter; left time: 299.2411s\n",
      "\titers: 600, epoch: 4 | loss: 0.1585305\n",
      "\tspeed: 0.0513s/iter; left time: 288.6103s\n",
      "\titers: 700, epoch: 4 | loss: 0.1991186\n",
      "\tspeed: 0.0511s/iter; left time: 282.1199s\n",
      "\titers: 800, epoch: 4 | loss: 0.1716689\n",
      "\tspeed: 0.0525s/iter; left time: 284.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.58s\n",
      "Steps: 889 | Train Loss: 0.1715612 Vali Loss: 0.0393669 Test Loss: 0.0481006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0426439493894577, rmse:0.20650412142276764, mae:0.14669473469257355, rse:0.7315818667411804\n",
      "Original data scale mse:39467032.0, rmse:6282.279296875, mae:4191.44921875, rse:0.31301331520080566\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1997931\n",
      "\tspeed: 0.0744s/iter; left time: 657.4145s\n",
      "\titers: 200, epoch: 1 | loss: 0.1910664\n",
      "\tspeed: 0.0501s/iter; left time: 437.7558s\n",
      "\titers: 300, epoch: 1 | loss: 0.1661717\n",
      "\tspeed: 0.0503s/iter; left time: 434.3696s\n",
      "\titers: 400, epoch: 1 | loss: 0.1595792\n",
      "\tspeed: 0.0505s/iter; left time: 430.6001s\n",
      "\titers: 500, epoch: 1 | loss: 0.1507766\n",
      "\tspeed: 0.0506s/iter; left time: 426.4744s\n",
      "\titers: 600, epoch: 1 | loss: 0.1500345\n",
      "\tspeed: 0.0509s/iter; left time: 424.2414s\n",
      "\titers: 700, epoch: 1 | loss: 0.1288310\n",
      "\tspeed: 0.0513s/iter; left time: 422.5751s\n",
      "\titers: 800, epoch: 1 | loss: 0.1301010\n",
      "\tspeed: 0.0506s/iter; left time: 411.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.1598665 Vali Loss: 0.1094445 Test Loss: 0.1122075\n",
      "Validation loss decreased (inf --> 0.109444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1560906\n",
      "\tspeed: 0.1850s/iter; left time: 1468.3269s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256281\n",
      "\tspeed: 0.0510s/iter; left time: 399.3529s\n",
      "\titers: 300, epoch: 2 | loss: 0.1037456\n",
      "\tspeed: 0.0510s/iter; left time: 394.3048s\n",
      "\titers: 400, epoch: 2 | loss: 0.1085704\n",
      "\tspeed: 0.0508s/iter; left time: 387.8506s\n",
      "\titers: 500, epoch: 2 | loss: 0.1069496\n",
      "\tspeed: 0.0504s/iter; left time: 379.9537s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993467\n",
      "\tspeed: 0.0510s/iter; left time: 379.2701s\n",
      "\titers: 700, epoch: 2 | loss: 0.0953315\n",
      "\tspeed: 0.0511s/iter; left time: 375.0899s\n",
      "\titers: 800, epoch: 2 | loss: 0.0859820\n",
      "\tspeed: 0.0506s/iter; left time: 366.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.63s\n",
      "Steps: 893 | Train Loss: 0.1134260 Vali Loss: 0.0984555 Test Loss: 0.1021205\n",
      "Validation loss decreased (0.109444 --> 0.098455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0723415\n",
      "\tspeed: 0.1857s/iter; left time: 1308.2224s\n",
      "\titers: 200, epoch: 3 | loss: 0.0859736\n",
      "\tspeed: 0.0509s/iter; left time: 353.2183s\n",
      "\titers: 300, epoch: 3 | loss: 0.0840666\n",
      "\tspeed: 0.0512s/iter; left time: 350.2460s\n",
      "\titers: 400, epoch: 3 | loss: 0.0838655\n",
      "\tspeed: 0.0507s/iter; left time: 342.0209s\n",
      "\titers: 500, epoch: 3 | loss: 0.0852574\n",
      "\tspeed: 0.0513s/iter; left time: 340.9700s\n",
      "\titers: 600, epoch: 3 | loss: 0.0989086\n",
      "\tspeed: 0.0511s/iter; left time: 334.2882s\n",
      "\titers: 700, epoch: 3 | loss: 0.0686446\n",
      "\tspeed: 0.0503s/iter; left time: 324.3028s\n",
      "\titers: 800, epoch: 3 | loss: 0.1060894\n",
      "\tspeed: 0.0512s/iter; left time: 325.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 893 | Train Loss: 0.0890301 Vali Loss: 0.1076463 Test Loss: 0.1092328\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0889363\n",
      "\tspeed: 0.1844s/iter; left time: 1134.4264s\n",
      "\titers: 200, epoch: 4 | loss: 0.0875304\n",
      "\tspeed: 0.0502s/iter; left time: 303.7476s\n",
      "\titers: 300, epoch: 4 | loss: 0.0844679\n",
      "\tspeed: 0.0497s/iter; left time: 295.8210s\n",
      "\titers: 400, epoch: 4 | loss: 0.0738833\n",
      "\tspeed: 0.0499s/iter; left time: 292.2832s\n",
      "\titers: 500, epoch: 4 | loss: 0.0962841\n",
      "\tspeed: 0.0515s/iter; left time: 296.2194s\n",
      "\titers: 600, epoch: 4 | loss: 0.0890386\n",
      "\tspeed: 0.0502s/iter; left time: 283.8183s\n",
      "\titers: 700, epoch: 4 | loss: 0.0706904\n",
      "\tspeed: 0.0503s/iter; left time: 279.3749s\n",
      "\titers: 800, epoch: 4 | loss: 0.0899874\n",
      "\tspeed: 0.0513s/iter; left time: 279.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.41s\n",
      "Steps: 893 | Train Loss: 0.0867351 Vali Loss: 0.0989426 Test Loss: 0.1015717\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785159\n",
      "\tspeed: 0.1836s/iter; left time: 965.5045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728950\n",
      "\tspeed: 0.0508s/iter; left time: 262.0787s\n",
      "\titers: 300, epoch: 5 | loss: 0.0859396\n",
      "\tspeed: 0.0511s/iter; left time: 258.4462s\n",
      "\titers: 400, epoch: 5 | loss: 0.0733304\n",
      "\tspeed: 0.0511s/iter; left time: 253.4452s\n",
      "\titers: 500, epoch: 5 | loss: 0.0842119\n",
      "\tspeed: 0.0508s/iter; left time: 246.7513s\n",
      "\titers: 600, epoch: 5 | loss: 0.0684475\n",
      "\tspeed: 0.0521s/iter; left time: 247.8785s\n",
      "\titers: 700, epoch: 5 | loss: 0.0841173\n",
      "\tspeed: 0.0510s/iter; left time: 237.3777s\n",
      "\titers: 800, epoch: 5 | loss: 0.1220546\n",
      "\tspeed: 0.0512s/iter; left time: 233.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 893 | Train Loss: 0.0841638 Vali Loss: 0.0951009 Test Loss: 0.0974293\n",
      "Validation loss decreased (0.098455 --> 0.095101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0697004\n",
      "\tspeed: 0.1848s/iter; left time: 807.0222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0861662\n",
      "\tspeed: 0.0510s/iter; left time: 217.6993s\n",
      "\titers: 300, epoch: 6 | loss: 0.0765070\n",
      "\tspeed: 0.0507s/iter; left time: 211.1037s\n",
      "\titers: 400, epoch: 6 | loss: 0.0644519\n",
      "\tspeed: 0.0508s/iter; left time: 206.6133s\n",
      "\titers: 500, epoch: 6 | loss: 0.0770516\n",
      "\tspeed: 0.0512s/iter; left time: 202.9512s\n",
      "\titers: 600, epoch: 6 | loss: 0.0821126\n",
      "\tspeed: 0.0512s/iter; left time: 197.8304s\n",
      "\titers: 700, epoch: 6 | loss: 0.0706967\n",
      "\tspeed: 0.0513s/iter; left time: 193.0715s\n",
      "\titers: 800, epoch: 6 | loss: 0.0797850\n",
      "\tspeed: 0.0514s/iter; left time: 188.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 893 | Train Loss: 0.0789132 Vali Loss: 0.0939661 Test Loss: 0.0975538\n",
      "Validation loss decreased (0.095101 --> 0.093966).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0796635\n",
      "\tspeed: 0.1848s/iter; left time: 641.8362s\n",
      "\titers: 200, epoch: 7 | loss: 0.0687510\n",
      "\tspeed: 0.0514s/iter; left time: 173.3989s\n",
      "\titers: 300, epoch: 7 | loss: 0.0841762\n",
      "\tspeed: 0.0511s/iter; left time: 167.1700s\n",
      "\titers: 400, epoch: 7 | loss: 0.0754226\n",
      "\tspeed: 0.0505s/iter; left time: 160.1251s\n",
      "\titers: 500, epoch: 7 | loss: 0.0820318\n",
      "\tspeed: 0.0503s/iter; left time: 154.6583s\n",
      "\titers: 600, epoch: 7 | loss: 0.0727707\n",
      "\tspeed: 0.0507s/iter; left time: 150.8418s\n",
      "\titers: 700, epoch: 7 | loss: 0.0769150\n",
      "\tspeed: 0.0511s/iter; left time: 146.7950s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783799\n",
      "\tspeed: 0.0512s/iter; left time: 142.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.68s\n",
      "Steps: 893 | Train Loss: 0.0767029 Vali Loss: 0.0906185 Test Loss: 0.0952226\n",
      "Validation loss decreased (0.093966 --> 0.090618).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0707073\n",
      "\tspeed: 0.1849s/iter; left time: 476.9150s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752434\n",
      "\tspeed: 0.0533s/iter; left time: 132.1413s\n",
      "\titers: 300, epoch: 8 | loss: 0.0653987\n",
      "\tspeed: 0.0499s/iter; left time: 118.6536s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776333\n",
      "\tspeed: 0.0507s/iter; left time: 115.5024s\n",
      "\titers: 500, epoch: 8 | loss: 0.0796481\n",
      "\tspeed: 0.0505s/iter; left time: 110.0598s\n",
      "\titers: 600, epoch: 8 | loss: 0.0609225\n",
      "\tspeed: 0.0507s/iter; left time: 105.5272s\n",
      "\titers: 700, epoch: 8 | loss: 0.0696919\n",
      "\tspeed: 0.0504s/iter; left time: 99.7131s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806831\n",
      "\tspeed: 0.0506s/iter; left time: 95.1642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 893 | Train Loss: 0.0739587 Vali Loss: 0.1017428 Test Loss: 0.1021738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600137\n",
      "\tspeed: 0.1820s/iter; left time: 307.0766s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684734\n",
      "\tspeed: 0.0507s/iter; left time: 80.4106s\n",
      "\titers: 300, epoch: 9 | loss: 0.0719938\n",
      "\tspeed: 0.0516s/iter; left time: 76.7267s\n",
      "\titers: 400, epoch: 9 | loss: 0.0641858\n",
      "\tspeed: 0.0510s/iter; left time: 70.6727s\n",
      "\titers: 500, epoch: 9 | loss: 0.0699579\n",
      "\tspeed: 0.0513s/iter; left time: 66.0260s\n",
      "\titers: 600, epoch: 9 | loss: 0.0762686\n",
      "\tspeed: 0.0514s/iter; left time: 60.9553s\n",
      "\titers: 700, epoch: 9 | loss: 0.0735367\n",
      "\tspeed: 0.0519s/iter; left time: 56.4041s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660792\n",
      "\tspeed: 0.0515s/iter; left time: 50.8301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 893 | Train Loss: 0.0714821 Vali Loss: 0.0913283 Test Loss: 0.0946512\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738563\n",
      "\tspeed: 0.1814s/iter; left time: 144.0335s\n",
      "\titers: 200, epoch: 10 | loss: 0.0659100\n",
      "\tspeed: 0.0511s/iter; left time: 35.4628s\n",
      "\titers: 300, epoch: 10 | loss: 0.0619273\n",
      "\tspeed: 0.0518s/iter; left time: 30.7744s\n",
      "\titers: 400, epoch: 10 | loss: 0.0765655\n",
      "\tspeed: 0.0513s/iter; left time: 25.3249s\n",
      "\titers: 500, epoch: 10 | loss: 0.0660495\n",
      "\tspeed: 0.0508s/iter; left time: 20.0043s\n",
      "\titers: 600, epoch: 10 | loss: 0.0688389\n",
      "\tspeed: 0.0514s/iter; left time: 15.1221s\n",
      "\titers: 700, epoch: 10 | loss: 0.0744282\n",
      "\tspeed: 0.0519s/iter; left time: 10.0697s\n",
      "\titers: 800, epoch: 10 | loss: 0.0680481\n",
      "\tspeed: 0.0514s/iter; left time: 4.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 893 | Train Loss: 0.0700369 Vali Loss: 0.0908857 Test Loss: 0.0951032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022842537611722946, rmse:0.15113748610019684, mae:0.09522261470556259, rse:0.533746063709259\n",
      "Original data scale mse:17627044.0, rmse:4198.45751953125, mae:2560.031982421875, rse:0.208755761384964\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1832071\n",
      "\tspeed: 0.0532s/iter; left time: 469.5229s\n",
      "\titers: 200, epoch: 1 | loss: 0.1858170\n",
      "\tspeed: 0.0513s/iter; left time: 447.4949s\n",
      "\titers: 300, epoch: 1 | loss: 0.1677893\n",
      "\tspeed: 0.0514s/iter; left time: 443.6954s\n",
      "\titers: 400, epoch: 1 | loss: 0.1518474\n",
      "\tspeed: 0.0511s/iter; left time: 435.6898s\n",
      "\titers: 500, epoch: 1 | loss: 0.1351320\n",
      "\tspeed: 0.0512s/iter; left time: 431.9127s\n",
      "\titers: 600, epoch: 1 | loss: 0.1306523\n",
      "\tspeed: 0.0505s/iter; left time: 420.8642s\n",
      "\titers: 700, epoch: 1 | loss: 0.1308791\n",
      "\tspeed: 0.0512s/iter; left time: 421.5326s\n",
      "\titers: 800, epoch: 1 | loss: 0.1226921\n",
      "\tspeed: 0.0513s/iter; left time: 417.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 893 | Train Loss: 0.1575953 Vali Loss: 0.1089087 Test Loss: 0.1117898\n",
      "Validation loss decreased (inf --> 0.108909).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1677086\n",
      "\tspeed: 0.1886s/iter; left time: 1496.7126s\n",
      "\titers: 200, epoch: 2 | loss: 0.1173048\n",
      "\tspeed: 0.0505s/iter; left time: 395.8875s\n",
      "\titers: 300, epoch: 2 | loss: 0.1048325\n",
      "\tspeed: 0.0512s/iter; left time: 395.9287s\n",
      "\titers: 400, epoch: 2 | loss: 0.1069137\n",
      "\tspeed: 0.0516s/iter; left time: 393.7406s\n",
      "\titers: 500, epoch: 2 | loss: 0.1053712\n",
      "\tspeed: 0.0510s/iter; left time: 384.1904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1057843\n",
      "\tspeed: 0.0506s/iter; left time: 376.2398s\n",
      "\titers: 700, epoch: 2 | loss: 0.1155008\n",
      "\tspeed: 0.0534s/iter; left time: 391.5302s\n",
      "\titers: 800, epoch: 2 | loss: 0.0857749\n",
      "\tspeed: 0.0575s/iter; left time: 416.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.50s\n",
      "Steps: 893 | Train Loss: 0.1172667 Vali Loss: 0.1017002 Test Loss: 0.1048007\n",
      "Validation loss decreased (0.108909 --> 0.101700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029922\n",
      "\tspeed: 0.1864s/iter; left time: 1313.0460s\n",
      "\titers: 200, epoch: 3 | loss: 0.0860792\n",
      "\tspeed: 0.0508s/iter; left time: 353.0912s\n",
      "\titers: 300, epoch: 3 | loss: 0.0915276\n",
      "\tspeed: 0.0509s/iter; left time: 348.5063s\n",
      "\titers: 400, epoch: 3 | loss: 0.1055479\n",
      "\tspeed: 0.0512s/iter; left time: 345.3710s\n",
      "\titers: 500, epoch: 3 | loss: 0.1176642\n",
      "\tspeed: 0.0514s/iter; left time: 341.2853s\n",
      "\titers: 600, epoch: 3 | loss: 0.0908892\n",
      "\tspeed: 0.0508s/iter; left time: 332.3336s\n",
      "\titers: 700, epoch: 3 | loss: 0.1077004\n",
      "\tspeed: 0.0512s/iter; left time: 329.9343s\n",
      "\titers: 800, epoch: 3 | loss: 0.0854108\n",
      "\tspeed: 0.0517s/iter; left time: 328.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 893 | Train Loss: 0.0939500 Vali Loss: 0.0990608 Test Loss: 0.1020935\n",
      "Validation loss decreased (0.101700 --> 0.099061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944565\n",
      "\tspeed: 0.1849s/iter; left time: 1137.4237s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823357\n",
      "\tspeed: 0.0509s/iter; left time: 307.9393s\n",
      "\titers: 300, epoch: 4 | loss: 0.0779113\n",
      "\tspeed: 0.0509s/iter; left time: 303.0753s\n",
      "\titers: 400, epoch: 4 | loss: 0.0860680\n",
      "\tspeed: 0.0519s/iter; left time: 303.6130s\n",
      "\titers: 500, epoch: 4 | loss: 0.0714134\n",
      "\tspeed: 0.0510s/iter; left time: 293.5821s\n",
      "\titers: 600, epoch: 4 | loss: 0.0896662\n",
      "\tspeed: 0.0511s/iter; left time: 288.7413s\n",
      "\titers: 700, epoch: 4 | loss: 0.0857838\n",
      "\tspeed: 0.0514s/iter; left time: 285.5240s\n",
      "\titers: 800, epoch: 4 | loss: 0.0812388\n",
      "\tspeed: 0.0510s/iter; left time: 278.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 893 | Train Loss: 0.0838707 Vali Loss: 0.0962228 Test Loss: 0.1000479\n",
      "Validation loss decreased (0.099061 --> 0.096223).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0893224\n",
      "\tspeed: 0.1844s/iter; left time: 969.5413s\n",
      "\titers: 200, epoch: 5 | loss: 0.1343427\n",
      "\tspeed: 0.0511s/iter; left time: 263.8450s\n",
      "\titers: 300, epoch: 5 | loss: 0.0967780\n",
      "\tspeed: 0.0513s/iter; left time: 259.5527s\n",
      "\titers: 400, epoch: 5 | loss: 0.0797359\n",
      "\tspeed: 0.0508s/iter; left time: 251.7118s\n",
      "\titers: 500, epoch: 5 | loss: 0.0830635\n",
      "\tspeed: 0.0508s/iter; left time: 246.8456s\n",
      "\titers: 600, epoch: 5 | loss: 0.0844677\n",
      "\tspeed: 0.0514s/iter; left time: 244.5341s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755263\n",
      "\tspeed: 0.0516s/iter; left time: 240.5879s\n",
      "\titers: 800, epoch: 5 | loss: 0.0798598\n",
      "\tspeed: 0.0517s/iter; left time: 235.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 893 | Train Loss: 0.0836162 Vali Loss: 0.0969208 Test Loss: 0.1004519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0761862\n",
      "\tspeed: 0.1884s/iter; left time: 822.4918s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739761\n",
      "\tspeed: 0.0507s/iter; left time: 216.1246s\n",
      "\titers: 300, epoch: 6 | loss: 0.0641037\n",
      "\tspeed: 0.0513s/iter; left time: 213.9222s\n",
      "\titers: 400, epoch: 6 | loss: 0.0843469\n",
      "\tspeed: 0.0517s/iter; left time: 210.3612s\n",
      "\titers: 500, epoch: 6 | loss: 0.0818670\n",
      "\tspeed: 0.0506s/iter; left time: 200.7129s\n",
      "\titers: 600, epoch: 6 | loss: 0.0814780\n",
      "\tspeed: 0.0509s/iter; left time: 196.7117s\n",
      "\titers: 700, epoch: 6 | loss: 0.0829946\n",
      "\tspeed: 0.0508s/iter; left time: 191.3410s\n",
      "\titers: 800, epoch: 6 | loss: 0.0819412\n",
      "\tspeed: 0.0504s/iter; left time: 184.9303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 893 | Train Loss: 0.0802414 Vali Loss: 0.0915390 Test Loss: 0.0948459\n",
      "Validation loss decreased (0.096223 --> 0.091539).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0885544\n",
      "\tspeed: 0.1859s/iter; left time: 645.4666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0815407\n",
      "\tspeed: 0.0518s/iter; left time: 174.7278s\n",
      "\titers: 300, epoch: 7 | loss: 0.0668346\n",
      "\tspeed: 0.0507s/iter; left time: 166.1018s\n",
      "\titers: 400, epoch: 7 | loss: 0.0695636\n",
      "\tspeed: 0.0509s/iter; left time: 161.4036s\n",
      "\titers: 500, epoch: 7 | loss: 0.0808255\n",
      "\tspeed: 0.0514s/iter; left time: 157.8522s\n",
      "\titers: 600, epoch: 7 | loss: 0.0791186\n",
      "\tspeed: 0.0516s/iter; left time: 153.3046s\n",
      "\titers: 700, epoch: 7 | loss: 0.0720446\n",
      "\tspeed: 0.0511s/iter; left time: 146.7753s\n",
      "\titers: 800, epoch: 7 | loss: 0.0754880\n",
      "\tspeed: 0.0509s/iter; left time: 141.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 893 | Train Loss: 0.0769128 Vali Loss: 0.0904774 Test Loss: 0.0941006\n",
      "Validation loss decreased (0.091539 --> 0.090477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0674545\n",
      "\tspeed: 0.1851s/iter; left time: 477.5766s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833068\n",
      "\tspeed: 0.0510s/iter; left time: 126.4944s\n",
      "\titers: 300, epoch: 8 | loss: 0.0665762\n",
      "\tspeed: 0.0513s/iter; left time: 122.1486s\n",
      "\titers: 400, epoch: 8 | loss: 0.0724693\n",
      "\tspeed: 0.0515s/iter; left time: 117.4608s\n",
      "\titers: 500, epoch: 8 | loss: 0.0730056\n",
      "\tspeed: 0.0514s/iter; left time: 112.0850s\n",
      "\titers: 600, epoch: 8 | loss: 0.0686800\n",
      "\tspeed: 0.0507s/iter; left time: 105.5182s\n",
      "\titers: 700, epoch: 8 | loss: 0.0649278\n",
      "\tspeed: 0.0511s/iter; left time: 101.2660s\n",
      "\titers: 800, epoch: 8 | loss: 0.0850345\n",
      "\tspeed: 0.0509s/iter; left time: 95.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 893 | Train Loss: 0.0749879 Vali Loss: 0.0909365 Test Loss: 0.0953605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0625933\n",
      "\tspeed: 0.1835s/iter; left time: 309.5661s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698991\n",
      "\tspeed: 0.0512s/iter; left time: 81.2578s\n",
      "\titers: 300, epoch: 9 | loss: 0.0667722\n",
      "\tspeed: 0.0509s/iter; left time: 75.7332s\n",
      "\titers: 400, epoch: 9 | loss: 0.0757758\n",
      "\tspeed: 0.0511s/iter; left time: 70.8514s\n",
      "\titers: 500, epoch: 9 | loss: 0.0772626\n",
      "\tspeed: 0.0510s/iter; left time: 65.6148s\n",
      "\titers: 600, epoch: 9 | loss: 0.0653457\n",
      "\tspeed: 0.0512s/iter; left time: 60.7315s\n",
      "\titers: 700, epoch: 9 | loss: 0.0675535\n",
      "\tspeed: 0.0504s/iter; left time: 54.8038s\n",
      "\titers: 800, epoch: 9 | loss: 0.0745159\n",
      "\tspeed: 0.0499s/iter; left time: 49.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.59s\n",
      "Steps: 893 | Train Loss: 0.0732028 Vali Loss: 0.0908117 Test Loss: 0.0952647\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0662176\n",
      "\tspeed: 0.1814s/iter; left time: 144.0253s\n",
      "\titers: 200, epoch: 10 | loss: 0.0735994\n",
      "\tspeed: 0.0507s/iter; left time: 35.1721s\n",
      "\titers: 300, epoch: 10 | loss: 0.0742005\n",
      "\tspeed: 0.0507s/iter; left time: 30.1156s\n",
      "\titers: 400, epoch: 10 | loss: 0.0719053\n",
      "\tspeed: 0.0512s/iter; left time: 25.2685s\n",
      "\titers: 500, epoch: 10 | loss: 0.0750361\n",
      "\tspeed: 0.0511s/iter; left time: 20.1190s\n",
      "\titers: 600, epoch: 10 | loss: 0.0787530\n",
      "\tspeed: 0.0513s/iter; left time: 15.0883s\n",
      "\titers: 700, epoch: 10 | loss: 0.0630169\n",
      "\tspeed: 0.0510s/iter; left time: 9.8954s\n",
      "\titers: 800, epoch: 10 | loss: 0.0687266\n",
      "\tspeed: 0.0504s/iter; left time: 4.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 893 | Train Loss: 0.0714551 Vali Loss: 0.0901754 Test Loss: 0.0949099\n",
      "Validation loss decreased (0.090477 --> 0.090175).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02348499372601509, rmse:0.1532481461763382, mae:0.0949099212884903, rse:0.5411999821662903\n",
      "Original data scale mse:18100182.0, rmse:4254.4306640625, mae:2555.05517578125, rse:0.2115388810634613\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2232037\n",
      "\tspeed: 0.0758s/iter; left time: 667.5456s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966674\n",
      "\tspeed: 0.0518s/iter; left time: 451.4272s\n",
      "\titers: 300, epoch: 1 | loss: 0.1742013\n",
      "\tspeed: 0.0513s/iter; left time: 441.3148s\n",
      "\titers: 400, epoch: 1 | loss: 0.1564720\n",
      "\tspeed: 0.0518s/iter; left time: 440.8153s\n",
      "\titers: 500, epoch: 1 | loss: 0.1540881\n",
      "\tspeed: 0.0522s/iter; left time: 438.6978s\n",
      "\titers: 600, epoch: 1 | loss: 0.1432428\n",
      "\tspeed: 0.0519s/iter; left time: 431.4100s\n",
      "\titers: 700, epoch: 1 | loss: 0.1426363\n",
      "\tspeed: 0.0519s/iter; left time: 425.7691s\n",
      "\titers: 800, epoch: 1 | loss: 0.1474556\n",
      "\tspeed: 0.0513s/iter; left time: 416.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.59s\n",
      "Steps: 891 | Train Loss: 0.1705530 Vali Loss: 0.1345120 Test Loss: 0.1430094\n",
      "Validation loss decreased (inf --> 0.134512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471382\n",
      "\tspeed: 0.1852s/iter; left time: 1466.5815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1251901\n",
      "\tspeed: 0.0516s/iter; left time: 403.4385s\n",
      "\titers: 300, epoch: 2 | loss: 0.1217593\n",
      "\tspeed: 0.0518s/iter; left time: 399.6226s\n",
      "\titers: 400, epoch: 2 | loss: 0.1290254\n",
      "\tspeed: 0.0514s/iter; left time: 391.5931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037664\n",
      "\tspeed: 0.0526s/iter; left time: 395.3687s\n",
      "\titers: 600, epoch: 2 | loss: 0.0984934\n",
      "\tspeed: 0.0518s/iter; left time: 384.2070s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177443\n",
      "\tspeed: 0.0516s/iter; left time: 377.9106s\n",
      "\titers: 800, epoch: 2 | loss: 0.1195117\n",
      "\tspeed: 0.0517s/iter; left time: 373.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 891 | Train Loss: 0.1325551 Vali Loss: 0.1309508 Test Loss: 0.1432606\n",
      "Validation loss decreased (0.134512 --> 0.130951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161637\n",
      "\tspeed: 0.1887s/iter; left time: 1326.6517s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061514\n",
      "\tspeed: 0.0516s/iter; left time: 357.4565s\n",
      "\titers: 300, epoch: 3 | loss: 0.1083067\n",
      "\tspeed: 0.0509s/iter; left time: 347.6406s\n",
      "\titers: 400, epoch: 3 | loss: 0.1091669\n",
      "\tspeed: 0.0504s/iter; left time: 339.1564s\n",
      "\titers: 500, epoch: 3 | loss: 0.1130476\n",
      "\tspeed: 0.0509s/iter; left time: 337.7064s\n",
      "\titers: 600, epoch: 3 | loss: 0.1183236\n",
      "\tspeed: 0.0520s/iter; left time: 339.2946s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176359\n",
      "\tspeed: 0.0523s/iter; left time: 336.0965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1227058\n",
      "\tspeed: 0.0517s/iter; left time: 327.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 891 | Train Loss: 0.1114686 Vali Loss: 0.1283390 Test Loss: 0.1400744\n",
      "Validation loss decreased (0.130951 --> 0.128339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1108759\n",
      "\tspeed: 0.1860s/iter; left time: 1141.9659s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192250\n",
      "\tspeed: 0.0516s/iter; left time: 311.4837s\n",
      "\titers: 300, epoch: 4 | loss: 0.1148024\n",
      "\tspeed: 0.0516s/iter; left time: 306.4875s\n",
      "\titers: 400, epoch: 4 | loss: 0.1095063\n",
      "\tspeed: 0.0516s/iter; left time: 301.1138s\n",
      "\titers: 500, epoch: 4 | loss: 0.0985132\n",
      "\tspeed: 0.0518s/iter; left time: 297.0840s\n",
      "\titers: 600, epoch: 4 | loss: 0.1161646\n",
      "\tspeed: 0.0562s/iter; left time: 316.5857s\n",
      "\titers: 700, epoch: 4 | loss: 0.1203122\n",
      "\tspeed: 0.0584s/iter; left time: 323.2994s\n",
      "\titers: 800, epoch: 4 | loss: 0.0941837\n",
      "\tspeed: 0.0514s/iter; left time: 279.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 891 | Train Loss: 0.1087535 Vali Loss: 0.1241450 Test Loss: 0.1341353\n",
      "Validation loss decreased (0.128339 --> 0.124145).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1068043\n",
      "\tspeed: 0.1854s/iter; left time: 972.8108s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072559\n",
      "\tspeed: 0.0516s/iter; left time: 265.6594s\n",
      "\titers: 300, epoch: 5 | loss: 0.1111848\n",
      "\tspeed: 0.0520s/iter; left time: 262.2508s\n",
      "\titers: 400, epoch: 5 | loss: 0.0968150\n",
      "\tspeed: 0.0514s/iter; left time: 254.2593s\n",
      "\titers: 500, epoch: 5 | loss: 0.1114944\n",
      "\tspeed: 0.0516s/iter; left time: 250.1938s\n",
      "\titers: 600, epoch: 5 | loss: 0.1012555\n",
      "\tspeed: 0.0518s/iter; left time: 245.7725s\n",
      "\titers: 700, epoch: 5 | loss: 0.0870723\n",
      "\tspeed: 0.0516s/iter; left time: 239.9190s\n",
      "\titers: 800, epoch: 5 | loss: 0.0921054\n",
      "\tspeed: 0.0514s/iter; left time: 233.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 891 | Train Loss: 0.1034870 Vali Loss: 0.1260645 Test Loss: 0.1364085\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862945\n",
      "\tspeed: 0.1836s/iter; left time: 799.5851s\n",
      "\titers: 200, epoch: 6 | loss: 0.0951162\n",
      "\tspeed: 0.0515s/iter; left time: 219.3357s\n",
      "\titers: 300, epoch: 6 | loss: 0.1098691\n",
      "\tspeed: 0.0515s/iter; left time: 213.9820s\n",
      "\titers: 400, epoch: 6 | loss: 0.1062306\n",
      "\tspeed: 0.0518s/iter; left time: 210.2817s\n",
      "\titers: 500, epoch: 6 | loss: 0.0924442\n",
      "\tspeed: 0.0517s/iter; left time: 204.4544s\n",
      "\titers: 600, epoch: 6 | loss: 0.1007303\n",
      "\tspeed: 0.0513s/iter; left time: 197.7445s\n",
      "\titers: 700, epoch: 6 | loss: 0.1088045\n",
      "\tspeed: 0.0519s/iter; left time: 194.9009s\n",
      "\titers: 800, epoch: 6 | loss: 0.0973611\n",
      "\tspeed: 0.0526s/iter; left time: 192.3921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 891 | Train Loss: 0.0989994 Vali Loss: 0.1312096 Test Loss: 0.1416587\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0975444\n",
      "\tspeed: 0.1820s/iter; left time: 630.7088s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928570\n",
      "\tspeed: 0.0505s/iter; left time: 169.8512s\n",
      "\titers: 300, epoch: 7 | loss: 0.0948609\n",
      "\tspeed: 0.0505s/iter; left time: 164.7337s\n",
      "\titers: 400, epoch: 7 | loss: 0.0950938\n",
      "\tspeed: 0.0523s/iter; left time: 165.5171s\n",
      "\titers: 500, epoch: 7 | loss: 0.0930621\n",
      "\tspeed: 0.0518s/iter; left time: 158.8299s\n",
      "\titers: 600, epoch: 7 | loss: 0.0890538\n",
      "\tspeed: 0.0524s/iter; left time: 155.2283s\n",
      "\titers: 700, epoch: 7 | loss: 0.1064823\n",
      "\tspeed: 0.0518s/iter; left time: 148.4581s\n",
      "\titers: 800, epoch: 7 | loss: 0.0912062\n",
      "\tspeed: 0.0518s/iter; left time: 143.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.19s\n",
      "Steps: 891 | Train Loss: 0.0943194 Vali Loss: 0.1268835 Test Loss: 0.1368058\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03928346186876297, rmse:0.1982005536556244, mae:0.13413530588150024, rse:0.7018682956695557\n",
      "Original data scale mse:32837766.0, rmse:5730.4248046875, mae:3682.619140625, rse:0.28537717461586\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2265643\n",
      "\tspeed: 0.0552s/iter; left time: 486.5719s\n",
      "\titers: 200, epoch: 1 | loss: 0.1886556\n",
      "\tspeed: 0.0525s/iter; left time: 457.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.1644631\n",
      "\tspeed: 0.0524s/iter; left time: 451.1958s\n",
      "\titers: 400, epoch: 1 | loss: 0.1629343\n",
      "\tspeed: 0.0524s/iter; left time: 445.8804s\n",
      "\titers: 500, epoch: 1 | loss: 0.1452929\n",
      "\tspeed: 0.0525s/iter; left time: 441.2000s\n",
      "\titers: 600, epoch: 1 | loss: 0.1416558\n",
      "\tspeed: 0.0592s/iter; left time: 492.3007s\n",
      "\titers: 700, epoch: 1 | loss: 0.1496234\n",
      "\tspeed: 0.0601s/iter; left time: 493.8752s\n",
      "\titers: 800, epoch: 1 | loss: 0.1375968\n",
      "\tspeed: 0.0530s/iter; left time: 429.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 891 | Train Loss: 0.1697492 Vali Loss: 0.1331158 Test Loss: 0.1416903\n",
      "Validation loss decreased (inf --> 0.133116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1534266\n",
      "\tspeed: 0.1870s/iter; left time: 1481.4142s\n",
      "\titers: 200, epoch: 2 | loss: 0.1198043\n",
      "\tspeed: 0.0527s/iter; left time: 411.8037s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239595\n",
      "\tspeed: 0.0513s/iter; left time: 395.7049s\n",
      "\titers: 400, epoch: 2 | loss: 0.1364685\n",
      "\tspeed: 0.0520s/iter; left time: 396.0726s\n",
      "\titers: 500, epoch: 2 | loss: 0.1119902\n",
      "\tspeed: 0.0516s/iter; left time: 388.3199s\n",
      "\titers: 600, epoch: 2 | loss: 0.1173515\n",
      "\tspeed: 0.0530s/iter; left time: 393.2550s\n",
      "\titers: 700, epoch: 2 | loss: 0.1285220\n",
      "\tspeed: 0.0513s/iter; left time: 375.2750s\n",
      "\titers: 800, epoch: 2 | loss: 0.1078363\n",
      "\tspeed: 0.0517s/iter; left time: 373.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 891 | Train Loss: 0.1300853 Vali Loss: 0.1237499 Test Loss: 0.1356043\n",
      "Validation loss decreased (0.133116 --> 0.123750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023868\n",
      "\tspeed: 0.1861s/iter; left time: 1308.0944s\n",
      "\titers: 200, epoch: 3 | loss: 0.1103000\n",
      "\tspeed: 0.0520s/iter; left time: 360.5814s\n",
      "\titers: 300, epoch: 3 | loss: 0.1102674\n",
      "\tspeed: 0.0520s/iter; left time: 354.8473s\n",
      "\titers: 400, epoch: 3 | loss: 0.1194403\n",
      "\tspeed: 0.0519s/iter; left time: 349.0869s\n",
      "\titers: 500, epoch: 3 | loss: 0.1059762\n",
      "\tspeed: 0.0519s/iter; left time: 343.9031s\n",
      "\titers: 600, epoch: 3 | loss: 0.1115333\n",
      "\tspeed: 0.0523s/iter; left time: 341.5180s\n",
      "\titers: 700, epoch: 3 | loss: 0.1141522\n",
      "\tspeed: 0.0517s/iter; left time: 332.5856s\n",
      "\titers: 800, epoch: 3 | loss: 0.1146121\n",
      "\tspeed: 0.0516s/iter; left time: 326.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.40s\n",
      "Steps: 891 | Train Loss: 0.1119773 Vali Loss: 0.1340968 Test Loss: 0.1472080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0965063\n",
      "\tspeed: 0.1907s/iter; left time: 1170.4750s\n",
      "\titers: 200, epoch: 4 | loss: 0.1043790\n",
      "\tspeed: 0.0517s/iter; left time: 312.3123s\n",
      "\titers: 300, epoch: 4 | loss: 0.1071067\n",
      "\tspeed: 0.0526s/iter; left time: 312.4934s\n",
      "\titers: 400, epoch: 4 | loss: 0.1017503\n",
      "\tspeed: 0.0525s/iter; left time: 306.6844s\n",
      "\titers: 500, epoch: 4 | loss: 0.1170304\n",
      "\tspeed: 0.0515s/iter; left time: 295.6545s\n",
      "\titers: 600, epoch: 4 | loss: 0.1083326\n",
      "\tspeed: 0.0525s/iter; left time: 296.1853s\n",
      "\titers: 700, epoch: 4 | loss: 0.1062443\n",
      "\tspeed: 0.0515s/iter; left time: 285.2325s\n",
      "\titers: 800, epoch: 4 | loss: 0.1106692\n",
      "\tspeed: 0.0513s/iter; left time: 278.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.43s\n",
      "Steps: 891 | Train Loss: 0.1081631 Vali Loss: 0.1262663 Test Loss: 0.1396926\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1013816\n",
      "\tspeed: 0.1843s/iter; left time: 967.2579s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064511\n",
      "\tspeed: 0.0519s/iter; left time: 267.0437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0976876\n",
      "\tspeed: 0.0521s/iter; left time: 263.1868s\n",
      "\titers: 400, epoch: 5 | loss: 0.1135138\n",
      "\tspeed: 0.0515s/iter; left time: 254.9177s\n",
      "\titers: 500, epoch: 5 | loss: 0.1021511\n",
      "\tspeed: 0.0513s/iter; left time: 248.6113s\n",
      "\titers: 600, epoch: 5 | loss: 0.1141687\n",
      "\tspeed: 0.0513s/iter; left time: 243.5550s\n",
      "\titers: 700, epoch: 5 | loss: 0.0989732\n",
      "\tspeed: 0.0527s/iter; left time: 244.6953s\n",
      "\titers: 800, epoch: 5 | loss: 0.0909392\n",
      "\tspeed: 0.0524s/iter; left time: 238.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.53s\n",
      "Steps: 891 | Train Loss: 0.1049430 Vali Loss: 0.1277877 Test Loss: 0.1400883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04233036935329437, rmse:0.2057434618473053, mae:0.13560429215431213, rse:0.7285791635513306\n",
      "Original data scale mse:33165298.0, rmse:5758.93212890625, mae:3640.189208984375, rse:0.2867968678474426\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2229090\n",
      "\tspeed: 0.0745s/iter; left time: 654.8279s\n",
      "\titers: 200, epoch: 1 | loss: 0.1946270\n",
      "\tspeed: 0.0518s/iter; left time: 450.6136s\n",
      "\titers: 300, epoch: 1 | loss: 0.1828846\n",
      "\tspeed: 0.0529s/iter; left time: 454.4900s\n",
      "\titers: 400, epoch: 1 | loss: 0.1709642\n",
      "\tspeed: 0.0526s/iter; left time: 446.8180s\n",
      "\titers: 500, epoch: 1 | loss: 0.1666662\n",
      "\tspeed: 0.0526s/iter; left time: 441.3946s\n",
      "\titers: 600, epoch: 1 | loss: 0.1467172\n",
      "\tspeed: 0.0529s/iter; left time: 438.9510s\n",
      "\titers: 700, epoch: 1 | loss: 0.1457421\n",
      "\tspeed: 0.0526s/iter; left time: 431.0600s\n",
      "\titers: 800, epoch: 1 | loss: 0.1420146\n",
      "\tspeed: 0.0525s/iter; left time: 424.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 889 | Train Loss: 0.1722314 Vali Loss: 0.1382293 Test Loss: 0.1478910\n",
      "Validation loss decreased (inf --> 0.138229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497356\n",
      "\tspeed: 0.1843s/iter; left time: 1456.6008s\n",
      "\titers: 200, epoch: 2 | loss: 0.1173222\n",
      "\tspeed: 0.0519s/iter; left time: 405.0756s\n",
      "\titers: 300, epoch: 2 | loss: 0.1381475\n",
      "\tspeed: 0.0525s/iter; left time: 404.2796s\n",
      "\titers: 400, epoch: 2 | loss: 0.1262460\n",
      "\tspeed: 0.0521s/iter; left time: 395.7712s\n",
      "\titers: 500, epoch: 2 | loss: 0.1217887\n",
      "\tspeed: 0.0513s/iter; left time: 384.6152s\n",
      "\titers: 600, epoch: 2 | loss: 0.1152534\n",
      "\tspeed: 0.0516s/iter; left time: 382.2048s\n",
      "\titers: 700, epoch: 2 | loss: 0.1169293\n",
      "\tspeed: 0.0531s/iter; left time: 387.4973s\n",
      "\titers: 800, epoch: 2 | loss: 0.1216763\n",
      "\tspeed: 0.0537s/iter; left time: 387.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.85s\n",
      "Steps: 889 | Train Loss: 0.1309007 Vali Loss: 0.1385292 Test Loss: 0.1479903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1159356\n",
      "\tspeed: 0.1844s/iter; left time: 1293.2554s\n",
      "\titers: 200, epoch: 3 | loss: 0.1099259\n",
      "\tspeed: 0.0537s/iter; left time: 371.1857s\n",
      "\titers: 300, epoch: 3 | loss: 0.1227691\n",
      "\tspeed: 0.0528s/iter; left time: 359.9081s\n",
      "\titers: 400, epoch: 3 | loss: 0.1282663\n",
      "\tspeed: 0.0532s/iter; left time: 356.9682s\n",
      "\titers: 500, epoch: 3 | loss: 0.1190669\n",
      "\tspeed: 0.0524s/iter; left time: 346.4936s\n",
      "\titers: 600, epoch: 3 | loss: 0.1182712\n",
      "\tspeed: 0.0528s/iter; left time: 343.6932s\n",
      "\titers: 700, epoch: 3 | loss: 0.1082339\n",
      "\tspeed: 0.0539s/iter; left time: 345.6066s\n",
      "\titers: 800, epoch: 3 | loss: 0.1311277\n",
      "\tspeed: 0.0527s/iter; left time: 332.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 889 | Train Loss: 0.1150055 Vali Loss: 0.1366656 Test Loss: 0.1528236\n",
      "Validation loss decreased (0.138229 --> 0.136666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1121051\n",
      "\tspeed: 0.1877s/iter; left time: 1149.2680s\n",
      "\titers: 200, epoch: 4 | loss: 0.1090651\n",
      "\tspeed: 0.0526s/iter; left time: 317.0222s\n",
      "\titers: 300, epoch: 4 | loss: 0.1249205\n",
      "\tspeed: 0.0521s/iter; left time: 308.4433s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038693\n",
      "\tspeed: 0.0650s/iter; left time: 378.6445s\n",
      "\titers: 500, epoch: 4 | loss: 0.1172951\n",
      "\tspeed: 0.0536s/iter; left time: 306.9378s\n",
      "\titers: 600, epoch: 4 | loss: 0.1042813\n",
      "\tspeed: 0.0536s/iter; left time: 301.5907s\n",
      "\titers: 700, epoch: 4 | loss: 0.1192200\n",
      "\tspeed: 0.0536s/iter; left time: 296.2520s\n",
      "\titers: 800, epoch: 4 | loss: 0.1179966\n",
      "\tspeed: 0.0522s/iter; left time: 283.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 889 | Train Loss: 0.1105371 Vali Loss: 0.1403287 Test Loss: 0.1583499\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1017207\n",
      "\tspeed: 0.1830s/iter; left time: 957.9791s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020666\n",
      "\tspeed: 0.0525s/iter; left time: 269.4856s\n",
      "\titers: 300, epoch: 5 | loss: 0.1118475\n",
      "\tspeed: 0.0531s/iter; left time: 267.5355s\n",
      "\titers: 400, epoch: 5 | loss: 0.0997806\n",
      "\tspeed: 0.0525s/iter; left time: 259.1623s\n",
      "\titers: 500, epoch: 5 | loss: 0.1119611\n",
      "\tspeed: 0.0526s/iter; left time: 254.4907s\n",
      "\titers: 600, epoch: 5 | loss: 0.0957659\n",
      "\tspeed: 0.0523s/iter; left time: 247.8341s\n",
      "\titers: 700, epoch: 5 | loss: 0.1159966\n",
      "\tspeed: 0.0534s/iter; left time: 247.4836s\n",
      "\titers: 800, epoch: 5 | loss: 0.0946089\n",
      "\tspeed: 0.0532s/iter; left time: 241.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 889 | Train Loss: 0.1036050 Vali Loss: 0.1320792 Test Loss: 0.1500000\n",
      "Validation loss decreased (0.136666 --> 0.132079).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1039378\n",
      "\tspeed: 0.1898s/iter; left time: 824.8487s\n",
      "\titers: 200, epoch: 6 | loss: 0.1045938\n",
      "\tspeed: 0.0512s/iter; left time: 217.5832s\n",
      "\titers: 300, epoch: 6 | loss: 0.1015098\n",
      "\tspeed: 0.0513s/iter; left time: 212.5474s\n",
      "\titers: 400, epoch: 6 | loss: 0.0929108\n",
      "\tspeed: 0.0532s/iter; left time: 215.0662s\n",
      "\titers: 500, epoch: 6 | loss: 0.0981993\n",
      "\tspeed: 0.0528s/iter; left time: 208.3888s\n",
      "\titers: 600, epoch: 6 | loss: 0.0997548\n",
      "\tspeed: 0.0526s/iter; left time: 202.1950s\n",
      "\titers: 700, epoch: 6 | loss: 0.0923686\n",
      "\tspeed: 0.0532s/iter; left time: 199.4468s\n",
      "\titers: 800, epoch: 6 | loss: 0.0974962\n",
      "\tspeed: 0.0523s/iter; left time: 190.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.85s\n",
      "Steps: 889 | Train Loss: 0.0967752 Vali Loss: 0.1382042 Test Loss: 0.1573263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917292\n",
      "\tspeed: 0.1837s/iter; left time: 635.1573s\n",
      "\titers: 200, epoch: 7 | loss: 0.0955683\n",
      "\tspeed: 0.0526s/iter; left time: 176.4893s\n",
      "\titers: 300, epoch: 7 | loss: 0.0945315\n",
      "\tspeed: 0.0529s/iter; left time: 172.1459s\n",
      "\titers: 400, epoch: 7 | loss: 0.0817248\n",
      "\tspeed: 0.0524s/iter; left time: 165.4618s\n",
      "\titers: 500, epoch: 7 | loss: 0.0978655\n",
      "\tspeed: 0.0527s/iter; left time: 161.0320s\n",
      "\titers: 600, epoch: 7 | loss: 0.0863217\n",
      "\tspeed: 0.0536s/iter; left time: 158.4177s\n",
      "\titers: 700, epoch: 7 | loss: 0.1002630\n",
      "\tspeed: 0.0523s/iter; left time: 149.5144s\n",
      "\titers: 800, epoch: 7 | loss: 0.0905504\n",
      "\tspeed: 0.0531s/iter; left time: 146.4705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 889 | Train Loss: 0.0906701 Vali Loss: 0.1368014 Test Loss: 0.1557852\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839699\n",
      "\tspeed: 0.1839s/iter; left time: 472.2639s\n",
      "\titers: 200, epoch: 8 | loss: 0.0912413\n",
      "\tspeed: 0.0537s/iter; left time: 132.5558s\n",
      "\titers: 300, epoch: 8 | loss: 0.0776646\n",
      "\tspeed: 0.0519s/iter; left time: 123.0113s\n",
      "\titers: 400, epoch: 8 | loss: 0.0831299\n",
      "\tspeed: 0.0521s/iter; left time: 118.1250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0833446\n",
      "\tspeed: 0.0535s/iter; left time: 115.9907s\n",
      "\titers: 600, epoch: 8 | loss: 0.0817312\n",
      "\tspeed: 0.0515s/iter; left time: 106.5611s\n",
      "\titers: 700, epoch: 8 | loss: 0.0856518\n",
      "\tspeed: 0.0526s/iter; left time: 103.4944s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806153\n",
      "\tspeed: 0.0531s/iter; left time: 99.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 889 | Train Loss: 0.0829492 Vali Loss: 0.1373000 Test Loss: 0.1556918\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05118086189031601, rmse:0.2262318730354309, mae:0.15000008046627045, rse:0.8014714121818542\n",
      "Original data scale mse:41286724.0, rmse:6425.474609375, mae:4055.570556640625, rse:0.3201479911804199\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2245519\n",
      "\tspeed: 0.0544s/iter; left time: 478.2133s\n",
      "\titers: 200, epoch: 1 | loss: 0.1977614\n",
      "\tspeed: 0.0526s/iter; left time: 457.2859s\n",
      "\titers: 300, epoch: 1 | loss: 0.1724228\n",
      "\tspeed: 0.0521s/iter; left time: 447.6395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1547159\n",
      "\tspeed: 0.0523s/iter; left time: 444.2199s\n",
      "\titers: 500, epoch: 1 | loss: 0.1681565\n",
      "\tspeed: 0.0522s/iter; left time: 438.1442s\n",
      "\titers: 600, epoch: 1 | loss: 0.1430618\n",
      "\tspeed: 0.0524s/iter; left time: 434.6264s\n",
      "\titers: 700, epoch: 1 | loss: 0.1669483\n",
      "\tspeed: 0.0533s/iter; left time: 436.3090s\n",
      "\titers: 800, epoch: 1 | loss: 0.1547149\n",
      "\tspeed: 0.0527s/iter; left time: 426.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.82s\n",
      "Steps: 889 | Train Loss: 0.1728516 Vali Loss: 0.1376716 Test Loss: 0.1467767\n",
      "Validation loss decreased (inf --> 0.137672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1391693\n",
      "\tspeed: 0.1909s/iter; left time: 1508.6452s\n",
      "\titers: 200, epoch: 2 | loss: 0.1230830\n",
      "\tspeed: 0.0535s/iter; left time: 417.2418s\n",
      "\titers: 300, epoch: 2 | loss: 0.1179087\n",
      "\tspeed: 0.0531s/iter; left time: 408.7941s\n",
      "\titers: 400, epoch: 2 | loss: 0.1215570\n",
      "\tspeed: 0.0531s/iter; left time: 403.8397s\n",
      "\titers: 500, epoch: 2 | loss: 0.1157699\n",
      "\tspeed: 0.0532s/iter; left time: 398.7627s\n",
      "\titers: 600, epoch: 2 | loss: 0.1237864\n",
      "\tspeed: 0.0529s/iter; left time: 391.4616s\n",
      "\titers: 700, epoch: 2 | loss: 0.1067871\n",
      "\tspeed: 0.0525s/iter; left time: 383.4866s\n",
      "\titers: 800, epoch: 2 | loss: 0.1219706\n",
      "\tspeed: 0.0538s/iter; left time: 387.3703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 889 | Train Loss: 0.1314889 Vali Loss: 0.1318049 Test Loss: 0.1438061\n",
      "Validation loss decreased (0.137672 --> 0.131805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1279833\n",
      "\tspeed: 0.1866s/iter; left time: 1308.3495s\n",
      "\titers: 200, epoch: 3 | loss: 0.1165558\n",
      "\tspeed: 0.0526s/iter; left time: 363.9423s\n",
      "\titers: 300, epoch: 3 | loss: 0.1229332\n",
      "\tspeed: 0.0527s/iter; left time: 359.0429s\n",
      "\titers: 400, epoch: 3 | loss: 0.1180273\n",
      "\tspeed: 0.0530s/iter; left time: 355.9840s\n",
      "\titers: 500, epoch: 3 | loss: 0.1168011\n",
      "\tspeed: 0.0532s/iter; left time: 351.7963s\n",
      "\titers: 600, epoch: 3 | loss: 0.1151624\n",
      "\tspeed: 0.0530s/iter; left time: 345.3458s\n",
      "\titers: 700, epoch: 3 | loss: 0.1090609\n",
      "\tspeed: 0.0527s/iter; left time: 337.9455s\n",
      "\titers: 800, epoch: 3 | loss: 0.1037146\n",
      "\tspeed: 0.0532s/iter; left time: 336.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 889 | Train Loss: 0.1173820 Vali Loss: 0.1337178 Test Loss: 0.1478508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083791\n",
      "\tspeed: 0.1828s/iter; left time: 1119.2665s\n",
      "\titers: 200, epoch: 4 | loss: 0.1039568\n",
      "\tspeed: 0.0596s/iter; left time: 358.8981s\n",
      "\titers: 300, epoch: 4 | loss: 0.1089210\n",
      "\tspeed: 0.0567s/iter; left time: 336.0860s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045069\n",
      "\tspeed: 0.0527s/iter; left time: 306.9602s\n",
      "\titers: 500, epoch: 4 | loss: 0.1028276\n",
      "\tspeed: 0.0528s/iter; left time: 302.3259s\n",
      "\titers: 600, epoch: 4 | loss: 0.1068846\n",
      "\tspeed: 0.0535s/iter; left time: 301.1577s\n",
      "\titers: 700, epoch: 4 | loss: 0.1333390\n",
      "\tspeed: 0.0529s/iter; left time: 292.1512s\n",
      "\titers: 800, epoch: 4 | loss: 0.1104628\n",
      "\tspeed: 0.0525s/iter; left time: 284.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 889 | Train Loss: 0.1102818 Vali Loss: 0.1336649 Test Loss: 0.1505475\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0996400\n",
      "\tspeed: 0.1854s/iter; left time: 970.4906s\n",
      "\titers: 200, epoch: 5 | loss: 0.1084849\n",
      "\tspeed: 0.0525s/iter; left time: 269.5183s\n",
      "\titers: 300, epoch: 5 | loss: 0.1067280\n",
      "\tspeed: 0.0532s/iter; left time: 268.0623s\n",
      "\titers: 400, epoch: 5 | loss: 0.1079533\n",
      "\tspeed: 0.0538s/iter; left time: 265.4900s\n",
      "\titers: 500, epoch: 5 | loss: 0.1006398\n",
      "\tspeed: 0.0530s/iter; left time: 256.1937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1073959\n",
      "\tspeed: 0.0518s/iter; left time: 245.2186s\n",
      "\titers: 700, epoch: 5 | loss: 0.1026590\n",
      "\tspeed: 0.0514s/iter; left time: 238.0201s\n",
      "\titers: 800, epoch: 5 | loss: 0.1027110\n",
      "\tspeed: 0.0521s/iter; left time: 236.1855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 889 | Train Loss: 0.1043101 Vali Loss: 0.1280563 Test Loss: 0.1499850\n",
      "Validation loss decreased (0.131805 --> 0.128056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0869850\n",
      "\tspeed: 0.1878s/iter; left time: 816.3260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0934649\n",
      "\tspeed: 0.0527s/iter; left time: 223.6080s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898110\n",
      "\tspeed: 0.0522s/iter; left time: 216.4474s\n",
      "\titers: 400, epoch: 6 | loss: 0.0944954\n",
      "\tspeed: 0.0536s/iter; left time: 217.0590s\n",
      "\titers: 500, epoch: 6 | loss: 0.0984644\n",
      "\tspeed: 0.0538s/iter; left time: 212.2448s\n",
      "\titers: 600, epoch: 6 | loss: 0.0992838\n",
      "\tspeed: 0.0530s/iter; left time: 203.7306s\n",
      "\titers: 700, epoch: 6 | loss: 0.0999130\n",
      "\tspeed: 0.0529s/iter; left time: 198.0184s\n",
      "\titers: 800, epoch: 6 | loss: 0.0916463\n",
      "\tspeed: 0.0537s/iter; left time: 195.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.49s\n",
      "Steps: 889 | Train Loss: 0.0973510 Vali Loss: 0.1362427 Test Loss: 0.1581157\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0956656\n",
      "\tspeed: 0.1852s/iter; left time: 640.3442s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925599\n",
      "\tspeed: 0.0529s/iter; left time: 177.6409s\n",
      "\titers: 300, epoch: 7 | loss: 0.0882274\n",
      "\tspeed: 0.0527s/iter; left time: 171.6819s\n",
      "\titers: 400, epoch: 7 | loss: 0.0966856\n",
      "\tspeed: 0.0524s/iter; left time: 165.3662s\n",
      "\titers: 500, epoch: 7 | loss: 0.0997394\n",
      "\tspeed: 0.0531s/iter; left time: 162.2971s\n",
      "\titers: 600, epoch: 7 | loss: 0.0822036\n",
      "\tspeed: 0.0525s/iter; left time: 155.3887s\n",
      "\titers: 700, epoch: 7 | loss: 0.0924724\n",
      "\tspeed: 0.0529s/iter; left time: 151.1146s\n",
      "\titers: 800, epoch: 7 | loss: 0.0839960\n",
      "\tspeed: 0.0530s/iter; left time: 146.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 889 | Train Loss: 0.0900631 Vali Loss: 0.1363450 Test Loss: 0.1621987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0882982\n",
      "\tspeed: 0.1840s/iter; left time: 472.5315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0913990\n",
      "\tspeed: 0.0518s/iter; left time: 127.7934s\n",
      "\titers: 300, epoch: 8 | loss: 0.0786889\n",
      "\tspeed: 0.0528s/iter; left time: 125.1057s\n",
      "\titers: 400, epoch: 8 | loss: 0.0767405\n",
      "\tspeed: 0.0528s/iter; left time: 119.7012s\n",
      "\titers: 500, epoch: 8 | loss: 0.0899009\n",
      "\tspeed: 0.0525s/iter; left time: 113.7531s\n",
      "\titers: 600, epoch: 8 | loss: 0.0859587\n",
      "\tspeed: 0.0525s/iter; left time: 108.6387s\n",
      "\titers: 700, epoch: 8 | loss: 0.0790938\n",
      "\tspeed: 0.0527s/iter; left time: 103.6371s\n",
      "\titers: 800, epoch: 8 | loss: 0.0811212\n",
      "\tspeed: 0.0527s/iter; left time: 98.4679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 889 | Train Loss: 0.0835015 Vali Loss: 0.1360593 Test Loss: 0.1674986\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.050571780651807785, rmse:0.22488170862197876, mae:0.14998504519462585, rse:0.7966881990432739\n",
      "Original data scale mse:40031320.0, rmse:6327.03076171875, mae:4023.649658203125, rse:0.31524309515953064\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "    log_file.write(statement_1)\n",
    "    print(statement_1)  # Print to notebook\n",
    "\n",
    "    for pred_len in pred_lens:\n",
    "        statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "        log_file.write(statement_2)\n",
    "        print(statement_2) \n",
    "        model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "        # Command arguments\n",
    "        command = f\"\"\"\n",
    "        python {script_path} \\\n",
    "            --random_seed 2021 \\\n",
    "            --is_training 1 \\\n",
    "            --root_path \"{data_path}\" \\\n",
    "            --data_path \"{dataset}\" \\\n",
    "            --model_id {model_id} \\\n",
    "            --model \"{model}\" \\\n",
    "            --data \"custom\" \\\n",
    "            --features M \\\n",
    "            --seq_len {seq_len} \\\n",
    "            --label_len 5 \\\n",
    "            --pred_len {pred_len} \\\n",
    "            --e_layers 2 \\\n",
    "            --d_layers 1 \\\n",
    "            --factor 5 \\\n",
    "            --enc_in 5 \\\n",
    "            --dec_in 5 \\\n",
    "            --c_out 5 \\\n",
    "            --des 'Exp' \\\n",
    "            --train_epochs 20 \\\n",
    "            --patience 3 \\\n",
    "            --overlapping_windows \\\n",
    "            --inverse \\\n",
    "            --scaler_type minmax \\\n",
    "            --if_relu \\\n",
    "            --loss_fnc \"{loss}\" \\\n",
    "            --itr {itr} --batch_size 32 --learning_rate \"{lr}\" \\\n",
    "            --revin 0 \\\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the command and capture the output\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "        # Capture the output in real-time\n",
    "        output = []\n",
    "        for line in process.stdout:\n",
    "            output.append(line)\n",
    "            print(line, end='')  # Print in the .ipynb cell\n",
    "            log_file.write(line)  # Write to the log file\n",
    "\n",
    "        # Wait for the process to complete\n",
    "        process.wait()\n",
    "\n",
    "        # Delete the checkpoints folder and all its contents\n",
    "        shutil.rmtree('./checkpoints' )\n",
    "\n",
    "        # Extract metrics for each iteration\n",
    "        iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "        iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "        # Log the extracted metrics and save them\n",
    "        for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "            log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "            log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "            log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "            # Append the results to the informer_results lists\n",
    "            metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "            for result_list, metrics in metrics_data:\n",
    "                result_list.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.5871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.7019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.7286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.8015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0228  0.1509  0.0993  0.5327\n",
       "              2         24        0.0232  0.1522  0.0993  0.5374\n",
       "              1         96        0.0423  0.2058  0.1442  0.7287\n",
       "              2         96        0.0382  0.1954  0.1364  0.6921\n",
       "              1         168       0.0446  0.2112  0.1488  0.7481\n",
       "              2         168       0.0429  0.2072  0.1472  0.7342\n",
       "RMSE          1         24        0.0247  0.1573  0.1037  0.5555\n",
       "              2         24        0.0276  0.1662  0.1114  0.5871\n",
       "              1         96        0.0418  0.2044  0.1435  0.7237\n",
       "              2         96        0.0390  0.1976  0.1391  0.6997\n",
       "              1         168       0.0409  0.2023  0.1403  0.7166\n",
       "              2         168       0.0426  0.2065  0.1467  0.7316\n",
       "MAE           1         24        0.0228  0.1511  0.0952  0.5337\n",
       "              2         24        0.0235  0.1532  0.0949  0.5412\n",
       "              1         96        0.0393  0.1982  0.1341  0.7019\n",
       "              2         96        0.0423  0.2057  0.1356  0.7286\n",
       "              1         168       0.0512  0.2262  0.1500  0.8015\n",
       "              2         168       0.0506  0.2249  0.1500  0.7967"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_no_revin.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_no_revin.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17937842.0</td>\n",
       "      <td>4235.3091</td>\n",
       "      <td>2700.5715</td>\n",
       "      <td>0.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18291816.0</td>\n",
       "      <td>4276.8931</td>\n",
       "      <td>2723.5989</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37627388.0</td>\n",
       "      <td>6134.1167</td>\n",
       "      <td>4097.5498</td>\n",
       "      <td>0.3055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34112108.0</td>\n",
       "      <td>5840.5571</td>\n",
       "      <td>3830.1448</td>\n",
       "      <td>0.2909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>40797516.0</td>\n",
       "      <td>6387.2935</td>\n",
       "      <td>4201.8149</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40016304.0</td>\n",
       "      <td>6325.8442</td>\n",
       "      <td>4216.5996</td>\n",
       "      <td>0.3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20196358.0</td>\n",
       "      <td>4494.0356</td>\n",
       "      <td>2889.8323</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>23053352.0</td>\n",
       "      <td>4801.3906</td>\n",
       "      <td>3150.2073</td>\n",
       "      <td>0.2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37400496.0</td>\n",
       "      <td>6115.5947</td>\n",
       "      <td>4083.6396</td>\n",
       "      <td>0.3046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34960184.0</td>\n",
       "      <td>5912.7139</td>\n",
       "      <td>3935.2871</td>\n",
       "      <td>0.2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35232612.0</td>\n",
       "      <td>5935.7065</td>\n",
       "      <td>3864.7725</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39467032.0</td>\n",
       "      <td>6282.2793</td>\n",
       "      <td>4191.4492</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17627044.0</td>\n",
       "      <td>4198.4575</td>\n",
       "      <td>2560.0320</td>\n",
       "      <td>0.2088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18100182.0</td>\n",
       "      <td>4254.4307</td>\n",
       "      <td>2555.0552</td>\n",
       "      <td>0.2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32837766.0</td>\n",
       "      <td>5730.4248</td>\n",
       "      <td>3682.6191</td>\n",
       "      <td>0.2854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33165298.0</td>\n",
       "      <td>5758.9321</td>\n",
       "      <td>3640.1892</td>\n",
       "      <td>0.2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41286724.0</td>\n",
       "      <td>6425.4746</td>\n",
       "      <td>4055.5706</td>\n",
       "      <td>0.3201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40031320.0</td>\n",
       "      <td>6327.0308</td>\n",
       "      <td>4023.6497</td>\n",
       "      <td>0.3152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17937842.0  4235.3091  2700.5715  0.2106\n",
       "              2         24        18291816.0  4276.8931  2723.5989  0.2127\n",
       "              1         96        37627388.0  6134.1167  4097.5498  0.3055\n",
       "              2         96        34112108.0  5840.5571  3830.1448  0.2909\n",
       "              1         168       40797516.0  6387.2935  4201.8149  0.3182\n",
       "              2         168       40016304.0  6325.8442  4216.5996  0.3152\n",
       "RMSE          1         24        20196358.0  4494.0356  2889.8323  0.2235\n",
       "              2         24        23053352.0  4801.3906  3150.2073  0.2387\n",
       "              1         96        37400496.0  6115.5947  4083.6396  0.3046\n",
       "              2         96        34960184.0  5912.7139  3935.2871  0.2945\n",
       "              1         168       35232612.0  5935.7065  3864.7725  0.2957\n",
       "              2         168       39467032.0  6282.2793  4191.4492  0.3130\n",
       "MAE           1         24        17627044.0  4198.4575  2560.0320  0.2088\n",
       "              2         24        18100182.0  4254.4307  2555.0552  0.2115\n",
       "              1         96        32837766.0  5730.4248  3682.6191  0.2854\n",
       "              2         96        33165298.0  5758.9321  3640.1892  0.2868\n",
       "              1         168       41286724.0  6425.4746  4055.5706  0.3201\n",
       "              2         168       40031320.0  6327.0308  4023.6497  0.3152"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.7117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.7412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0232  0.1522  0.0951  0.5375\n",
       "         MSE            0.0230  0.1515  0.0993  0.5351\n",
       "         RMSE           0.0262  0.1618  0.1075  0.5713\n",
       "96       MAE            0.0408  0.2020  0.1349  0.7152\n",
       "         MSE            0.0403  0.2006  0.1403  0.7104\n",
       "         RMSE           0.0404  0.2010  0.1413  0.7117\n",
       "168      MAE            0.0509  0.2256  0.1500  0.7991\n",
       "         MSE            0.0438  0.2092  0.1480  0.7412\n",
       "         RMSE           0.0418  0.2044  0.1435  0.7241"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17863613.0</td>\n",
       "      <td>4226.4441</td>\n",
       "      <td>2557.5436</td>\n",
       "      <td>0.2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18114829.0</td>\n",
       "      <td>4256.1011</td>\n",
       "      <td>2712.0852</td>\n",
       "      <td>0.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>21624855.0</td>\n",
       "      <td>4647.7131</td>\n",
       "      <td>3020.0198</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33001532.0</td>\n",
       "      <td>5744.6785</td>\n",
       "      <td>3661.4042</td>\n",
       "      <td>0.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>35869748.0</td>\n",
       "      <td>5987.3369</td>\n",
       "      <td>3963.8473</td>\n",
       "      <td>0.2982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>36180340.0</td>\n",
       "      <td>6014.1543</td>\n",
       "      <td>4009.4634</td>\n",
       "      <td>0.2995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40659022.0</td>\n",
       "      <td>6376.2527</td>\n",
       "      <td>4039.6101</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>40406910.0</td>\n",
       "      <td>6356.5688</td>\n",
       "      <td>4209.2073</td>\n",
       "      <td>0.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37349822.0</td>\n",
       "      <td>6108.9929</td>\n",
       "      <td>4028.1108</td>\n",
       "      <td>0.3044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17863613.0  4226.4441  2557.5436  0.2101\n",
       "         MSE            18114829.0  4256.1011  2712.0852  0.2116\n",
       "         RMSE           21624855.0  4647.7131  3020.0198  0.2311\n",
       "96       MAE            33001532.0  5744.6785  3661.4042  0.2861\n",
       "         MSE            35869748.0  5987.3369  3963.8473  0.2982\n",
       "         RMSE           36180340.0  6014.1543  4009.4634  0.2995\n",
       "168      MAE            40659022.0  6376.2527  4039.6101  0.3177\n",
       "         MSE            40406910.0  6356.5688  4209.2073  0.3167\n",
       "         RMSE           37349822.0  6108.9929  4028.1108  0.3044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_no_revin'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0159983\n",
      "\tspeed: 0.4466s/iter; left time: 3944.0895s\n",
      "\titers: 200, epoch: 1 | loss: 0.0151741\n",
      "\tspeed: 0.4246s/iter; left time: 3706.9438s\n",
      "\titers: 300, epoch: 1 | loss: 0.0162803\n",
      "\tspeed: 0.4261s/iter; left time: 3677.6496s\n",
      "\titers: 400, epoch: 1 | loss: 0.0144529\n",
      "\tspeed: 0.4271s/iter; left time: 3643.9391s\n",
      "\titers: 500, epoch: 1 | loss: 0.0147686\n",
      "\tspeed: 0.4271s/iter; left time: 3600.4990s\n",
      "\titers: 600, epoch: 1 | loss: 0.0140562\n",
      "\tspeed: 0.4263s/iter; left time: 3551.1751s\n",
      "\titers: 700, epoch: 1 | loss: 0.0211861\n",
      "\tspeed: 0.4262s/iter; left time: 3508.3361s\n",
      "\titers: 800, epoch: 1 | loss: 0.0159478\n",
      "\tspeed: 0.4259s/iter; left time: 3463.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:20.28s\n",
      "Steps: 893 | Train Loss: 0.0162301 Vali Loss: 0.0219798 Test Loss: 0.0232814\n",
      "Validation loss decreased (inf --> 0.021980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0204746\n",
      "\tspeed: 1.4185s/iter; left time: 11260.1502s\n",
      "\titers: 200, epoch: 2 | loss: 0.0212501\n",
      "\tspeed: 0.4263s/iter; left time: 3341.7028s\n",
      "\titers: 300, epoch: 2 | loss: 0.0236576\n",
      "\tspeed: 0.4268s/iter; left time: 3302.6581s\n",
      "\titers: 400, epoch: 2 | loss: 0.0216763\n",
      "\tspeed: 0.4265s/iter; left time: 3257.7797s\n",
      "\titers: 500, epoch: 2 | loss: 0.0207986\n",
      "\tspeed: 0.4265s/iter; left time: 3215.2643s\n",
      "\titers: 600, epoch: 2 | loss: 0.0160506\n",
      "\tspeed: 0.4266s/iter; left time: 3173.3548s\n",
      "\titers: 700, epoch: 2 | loss: 0.0608136\n",
      "\tspeed: 0.4268s/iter; left time: 3131.9612s\n",
      "\titers: 800, epoch: 2 | loss: 0.0228775\n",
      "\tspeed: 0.4268s/iter; left time: 3089.1310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:20.99s\n",
      "Steps: 893 | Train Loss: 0.0238137 Vali Loss: 0.0238658 Test Loss: 0.0268473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0216015\n",
      "\tspeed: 1.4139s/iter; left time: 9960.8378s\n",
      "\titers: 200, epoch: 3 | loss: 0.0132737\n",
      "\tspeed: 0.4267s/iter; left time: 2963.6229s\n",
      "\titers: 300, epoch: 3 | loss: 0.0161186\n",
      "\tspeed: 0.4266s/iter; left time: 2919.9562s\n",
      "\titers: 400, epoch: 3 | loss: 0.0147336\n",
      "\tspeed: 0.4267s/iter; left time: 2877.7982s\n",
      "\titers: 500, epoch: 3 | loss: 0.0786173\n",
      "\tspeed: 0.4269s/iter; left time: 2837.0434s\n",
      "\titers: 600, epoch: 3 | loss: 0.0256643\n",
      "\tspeed: 0.4263s/iter; left time: 2790.0236s\n",
      "\titers: 700, epoch: 3 | loss: 0.0184893\n",
      "\tspeed: 0.4268s/iter; left time: 2750.7137s\n",
      "\titers: 800, epoch: 3 | loss: 0.0169230\n",
      "\tspeed: 0.4270s/iter; left time: 2709.1483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:20.99s\n",
      "Steps: 893 | Train Loss: 0.0203130 Vali Loss: 0.0225768 Test Loss: 0.0248816\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0184133\n",
      "\tspeed: 1.4146s/iter; left time: 8702.9177s\n",
      "\titers: 200, epoch: 4 | loss: 0.0232558\n",
      "\tspeed: 0.4264s/iter; left time: 2580.6738s\n",
      "\titers: 300, epoch: 4 | loss: 0.0254692\n",
      "\tspeed: 0.4266s/iter; left time: 2539.3908s\n",
      "\titers: 400, epoch: 4 | loss: 0.0192265\n",
      "\tspeed: 0.4269s/iter; left time: 2498.0838s\n",
      "\titers: 500, epoch: 4 | loss: 0.0210347\n",
      "\tspeed: 0.4266s/iter; left time: 2453.9463s\n",
      "\titers: 600, epoch: 4 | loss: 0.0186680\n",
      "\tspeed: 0.4272s/iter; left time: 2414.5043s\n",
      "\titers: 700, epoch: 4 | loss: 0.0213243\n",
      "\tspeed: 0.4264s/iter; left time: 2367.5458s\n",
      "\titers: 800, epoch: 4 | loss: 0.0225429\n",
      "\tspeed: 0.4270s/iter; left time: 2328.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:21.14s\n",
      "Steps: 893 | Train Loss: 0.0290584 Vali Loss: 0.3028123 Test Loss: 0.1787224\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023281414061784744, rmse:0.15258248150348663, mae:0.09980779886245728, rse:0.5388491749763489\n",
      "Original data scale mse:18841468.0, rmse:4340.67578125, mae:2766.09130859375, rse:0.21582716703414917\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0137522\n",
      "\tspeed: 0.4255s/iter; left time: 3757.7828s\n",
      "\titers: 200, epoch: 1 | loss: 0.0170864\n",
      "\tspeed: 0.4249s/iter; left time: 3709.7145s\n",
      "\titers: 300, epoch: 1 | loss: 0.0171908\n",
      "\tspeed: 0.4257s/iter; left time: 3674.4355s\n",
      "\titers: 400, epoch: 1 | loss: 0.0145090\n",
      "\tspeed: 0.4254s/iter; left time: 3629.1097s\n",
      "\titers: 500, epoch: 1 | loss: 0.0160575\n",
      "\tspeed: 0.4252s/iter; left time: 3584.8350s\n",
      "\titers: 600, epoch: 1 | loss: 0.0153515\n",
      "\tspeed: 0.4253s/iter; left time: 3543.2743s\n",
      "\titers: 700, epoch: 1 | loss: 0.0142388\n",
      "\tspeed: 0.4252s/iter; left time: 3499.9549s\n",
      "\titers: 800, epoch: 1 | loss: 0.0125991\n",
      "\tspeed: 0.4256s/iter; left time: 3460.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:19.94s\n",
      "Steps: 893 | Train Loss: 0.0161571 Vali Loss: 0.0224723 Test Loss: 0.0237119\n",
      "Validation loss decreased (inf --> 0.022472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0212262\n",
      "\tspeed: 1.4151s/iter; left time: 11233.3084s\n",
      "\titers: 200, epoch: 2 | loss: 0.0121720\n",
      "\tspeed: 0.4258s/iter; left time: 3337.3960s\n",
      "\titers: 300, epoch: 2 | loss: 0.0154114\n",
      "\tspeed: 0.4262s/iter; left time: 3297.5925s\n",
      "\titers: 400, epoch: 2 | loss: 0.0145996\n",
      "\tspeed: 0.4261s/iter; left time: 3254.3143s\n",
      "\titers: 500, epoch: 2 | loss: 0.0211421\n",
      "\tspeed: 0.4264s/iter; left time: 3214.0325s\n",
      "\titers: 600, epoch: 2 | loss: 0.0190222\n",
      "\tspeed: 0.4255s/iter; left time: 3164.9829s\n",
      "\titers: 700, epoch: 2 | loss: 0.0133625\n",
      "\tspeed: 0.4260s/iter; left time: 3125.9255s\n",
      "\titers: 800, epoch: 2 | loss: 0.0184891\n",
      "\tspeed: 0.4259s/iter; left time: 3082.6246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:20.38s\n",
      "Steps: 893 | Train Loss: 0.0193460 Vali Loss: 0.0273594 Test Loss: 0.0300448\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0150479\n",
      "\tspeed: 1.4117s/iter; left time: 9945.6080s\n",
      "\titers: 200, epoch: 3 | loss: 0.0525334\n",
      "\tspeed: 0.4254s/iter; left time: 2954.4416s\n",
      "\titers: 300, epoch: 3 | loss: 0.0284726\n",
      "\tspeed: 0.4260s/iter; left time: 2915.6994s\n",
      "\titers: 400, epoch: 3 | loss: 0.0604720\n",
      "\tspeed: 0.4263s/iter; left time: 2875.5301s\n",
      "\titers: 500, epoch: 3 | loss: 0.0177555\n",
      "\tspeed: 0.4256s/iter; left time: 2828.1499s\n",
      "\titers: 600, epoch: 3 | loss: 0.0231219\n",
      "\tspeed: 0.4262s/iter; left time: 2789.5283s\n",
      "\titers: 700, epoch: 3 | loss: 0.0151925\n",
      "\tspeed: 0.4262s/iter; left time: 2747.0814s\n",
      "\titers: 800, epoch: 3 | loss: 0.0150942\n",
      "\tspeed: 0.4257s/iter; left time: 2701.2223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:20.45s\n",
      "Steps: 893 | Train Loss: 0.0233471 Vali Loss: 0.0227019 Test Loss: 0.0254924\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0176684\n",
      "\tspeed: 1.4118s/iter; left time: 8685.1158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0149879\n",
      "\tspeed: 0.4258s/iter; left time: 2576.8910s\n",
      "\titers: 300, epoch: 4 | loss: 0.0169961\n",
      "\tspeed: 0.4260s/iter; left time: 2535.5882s\n",
      "\titers: 400, epoch: 4 | loss: 0.0284357\n",
      "\tspeed: 0.4260s/iter; left time: 2492.7156s\n",
      "\titers: 500, epoch: 4 | loss: 0.0677423\n",
      "\tspeed: 0.4263s/iter; left time: 2452.0808s\n",
      "\titers: 600, epoch: 4 | loss: 0.0404034\n",
      "\tspeed: 0.4256s/iter; left time: 2405.7270s\n",
      "\titers: 700, epoch: 4 | loss: 0.1013965\n",
      "\tspeed: 0.4260s/iter; left time: 2365.2537s\n",
      "\titers: 800, epoch: 4 | loss: 0.0244614\n",
      "\tspeed: 0.4262s/iter; left time: 2323.7041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:20.34s\n",
      "Steps: 893 | Train Loss: 0.0302476 Vali Loss: 0.0282414 Test Loss: 0.0323118\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02371194027364254, rmse:0.15398681163787842, mae:0.10092131793498993, rse:0.54380863904953\n",
      "Original data scale mse:19352864.0, rmse:4399.18896484375, mae:2810.34423828125, rse:0.21873655915260315\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0222462\n",
      "\tspeed: 0.4519s/iter; left time: 3981.5254s\n",
      "\titers: 200, epoch: 1 | loss: 0.0222523\n",
      "\tspeed: 0.4293s/iter; left time: 3739.3918s\n",
      "\titers: 300, epoch: 1 | loss: 0.0268871\n",
      "\tspeed: 0.4293s/iter; left time: 3696.9213s\n",
      "\titers: 400, epoch: 1 | loss: 0.0252161\n",
      "\tspeed: 0.4293s/iter; left time: 3654.0880s\n",
      "\titers: 500, epoch: 1 | loss: 0.0217361\n",
      "\tspeed: 0.4293s/iter; left time: 3610.9605s\n",
      "\titers: 600, epoch: 1 | loss: 0.0252452\n",
      "\tspeed: 0.4297s/iter; left time: 3571.4175s\n",
      "\titers: 700, epoch: 1 | loss: 0.0206350\n",
      "\tspeed: 0.4292s/iter; left time: 3524.3182s\n",
      "\titers: 800, epoch: 1 | loss: 0.0254453\n",
      "\tspeed: 0.4294s/iter; left time: 3483.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:22.60s\n",
      "Steps: 891 | Train Loss: 0.0256970 Vali Loss: 0.0323255 Test Loss: 0.0376841\n",
      "Validation loss decreased (inf --> 0.032325).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0223880\n",
      "\tspeed: 1.4439s/iter; left time: 11435.9361s\n",
      "\titers: 200, epoch: 2 | loss: 0.0296699\n",
      "\tspeed: 0.4295s/iter; left time: 3358.7177s\n",
      "\titers: 300, epoch: 2 | loss: 0.0240102\n",
      "\tspeed: 0.4296s/iter; left time: 3316.8330s\n",
      "\titers: 400, epoch: 2 | loss: 0.0232873\n",
      "\tspeed: 0.4297s/iter; left time: 3274.5771s\n",
      "\titers: 500, epoch: 2 | loss: 0.0267397\n",
      "\tspeed: 0.4300s/iter; left time: 3233.4363s\n",
      "\titers: 600, epoch: 2 | loss: 0.0214270\n",
      "\tspeed: 0.4297s/iter; left time: 3188.2310s\n",
      "\titers: 700, epoch: 2 | loss: 0.0261149\n",
      "\tspeed: 0.4296s/iter; left time: 3144.6348s\n",
      "\titers: 800, epoch: 2 | loss: 0.0273755\n",
      "\tspeed: 0.4298s/iter; left time: 3103.2695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:22.73s\n",
      "Steps: 891 | Train Loss: 0.0262244 Vali Loss: 0.0316550 Test Loss: 0.0370419\n",
      "Validation loss decreased (0.032325 --> 0.031655).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0597988\n",
      "\tspeed: 1.4345s/iter; left time: 10083.2517s\n",
      "\titers: 200, epoch: 3 | loss: 0.0354255\n",
      "\tspeed: 0.4294s/iter; left time: 2975.0357s\n",
      "\titers: 300, epoch: 3 | loss: 0.0363769\n",
      "\tspeed: 0.4293s/iter; left time: 2931.8927s\n",
      "\titers: 400, epoch: 3 | loss: 0.0280856\n",
      "\tspeed: 0.4295s/iter; left time: 2890.3028s\n",
      "\titers: 500, epoch: 3 | loss: 0.0264658\n",
      "\tspeed: 0.4296s/iter; left time: 2847.6861s\n",
      "\titers: 600, epoch: 3 | loss: 0.0242176\n",
      "\tspeed: 0.4293s/iter; left time: 2803.0420s\n",
      "\titers: 700, epoch: 3 | loss: 0.0420146\n",
      "\tspeed: 0.4294s/iter; left time: 2760.8057s\n",
      "\titers: 800, epoch: 3 | loss: 0.0263332\n",
      "\tspeed: 0.4294s/iter; left time: 2717.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:22.56s\n",
      "Steps: 891 | Train Loss: 0.0400085 Vali Loss: 0.0357261 Test Loss: 0.0404480\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0239349\n",
      "\tspeed: 1.4059s/iter; left time: 8629.3775s\n",
      "\titers: 200, epoch: 4 | loss: 0.0280026\n",
      "\tspeed: 0.4298s/iter; left time: 2594.9360s\n",
      "\titers: 300, epoch: 4 | loss: 0.0218398\n",
      "\tspeed: 0.4297s/iter; left time: 2551.5696s\n",
      "\titers: 400, epoch: 4 | loss: 0.0247327\n",
      "\tspeed: 0.4296s/iter; left time: 2508.0740s\n",
      "\titers: 500, epoch: 4 | loss: 0.0251883\n",
      "\tspeed: 0.4294s/iter; left time: 2464.0913s\n",
      "\titers: 600, epoch: 4 | loss: 0.0264505\n",
      "\tspeed: 0.4296s/iter; left time: 2422.3185s\n",
      "\titers: 700, epoch: 4 | loss: 0.0277012\n",
      "\tspeed: 0.4297s/iter; left time: 2379.5890s\n",
      "\titers: 800, epoch: 4 | loss: 0.0231278\n",
      "\tspeed: 0.4295s/iter; left time: 2335.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:22.73s\n",
      "Steps: 891 | Train Loss: 0.0252621 Vali Loss: 0.0344654 Test Loss: 0.0409837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0211185\n",
      "\tspeed: 1.4054s/iter; left time: 7374.0689s\n",
      "\titers: 200, epoch: 5 | loss: 0.0261652\n",
      "\tspeed: 0.4296s/iter; left time: 2211.3241s\n",
      "\titers: 300, epoch: 5 | loss: 0.0294711\n",
      "\tspeed: 0.4297s/iter; left time: 2168.6941s\n",
      "\titers: 400, epoch: 5 | loss: 0.0223806\n",
      "\tspeed: 0.4295s/iter; left time: 2124.7881s\n",
      "\titers: 500, epoch: 5 | loss: 0.0285733\n",
      "\tspeed: 0.4300s/iter; left time: 2083.9874s\n",
      "\titers: 600, epoch: 5 | loss: 0.0455436\n",
      "\tspeed: 0.4296s/iter; left time: 2039.1189s\n",
      "\titers: 700, epoch: 5 | loss: 0.0358742\n",
      "\tspeed: 0.4295s/iter; left time: 1996.0971s\n",
      "\titers: 800, epoch: 5 | loss: 0.0294519\n",
      "\tspeed: 0.4297s/iter; left time: 1953.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:06m:22.74s\n",
      "Steps: 891 | Train Loss: 0.0304034 Vali Loss: 0.0333504 Test Loss: 0.0393541\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03704188019037247, rmse:0.19246266782283783, mae:0.1346161961555481, rse:0.6815491914749146\n",
      "Original data scale mse:32061372.0, rmse:5662.2763671875, mae:3745.734375, rse:0.2819833755493164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0264608\n",
      "\tspeed: 0.4281s/iter; left time: 3772.0503s\n",
      "\titers: 200, epoch: 1 | loss: 0.0226697\n",
      "\tspeed: 0.4292s/iter; left time: 3738.6264s\n",
      "\titers: 300, epoch: 1 | loss: 0.0233232\n",
      "\tspeed: 0.4293s/iter; left time: 3696.3086s\n",
      "\titers: 400, epoch: 1 | loss: 0.0304091\n",
      "\tspeed: 0.4293s/iter; left time: 3653.7947s\n",
      "\titers: 500, epoch: 1 | loss: 0.0235247\n",
      "\tspeed: 0.4291s/iter; left time: 3608.9401s\n",
      "\titers: 600, epoch: 1 | loss: 0.0228788\n",
      "\tspeed: 0.4295s/iter; left time: 3569.2601s\n",
      "\titers: 700, epoch: 1 | loss: 0.0307671\n",
      "\tspeed: 0.4290s/iter; left time: 3522.5083s\n",
      "\titers: 800, epoch: 1 | loss: 0.0238893\n",
      "\tspeed: 0.4290s/iter; left time: 3479.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:22.34s\n",
      "Steps: 891 | Train Loss: 0.0257759 Vali Loss: 0.0332403 Test Loss: 0.0388305\n",
      "Validation loss decreased (inf --> 0.033240).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0393647\n",
      "\tspeed: 1.4165s/iter; left time: 11218.5053s\n",
      "\titers: 200, epoch: 2 | loss: 0.0272740\n",
      "\tspeed: 0.4294s/iter; left time: 3357.8331s\n",
      "\titers: 300, epoch: 2 | loss: 0.0263371\n",
      "\tspeed: 0.4293s/iter; left time: 3314.2785s\n",
      "\titers: 400, epoch: 2 | loss: 0.0340006\n",
      "\tspeed: 0.4297s/iter; left time: 3274.0503s\n",
      "\titers: 500, epoch: 2 | loss: 0.0269659\n",
      "\tspeed: 0.4298s/iter; left time: 3231.9411s\n",
      "\titers: 600, epoch: 2 | loss: 0.0155291\n",
      "\tspeed: 0.4292s/iter; left time: 3184.4176s\n",
      "\titers: 700, epoch: 2 | loss: 0.0228806\n",
      "\tspeed: 0.4299s/iter; left time: 3147.1856s\n",
      "\titers: 800, epoch: 2 | loss: 0.0245437\n",
      "\tspeed: 0.4297s/iter; left time: 3102.3814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:22.68s\n",
      "Steps: 891 | Train Loss: 0.0293425 Vali Loss: 0.0320610 Test Loss: 0.0364089\n",
      "Validation loss decreased (0.033240 --> 0.032061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0270521\n",
      "\tspeed: 1.4188s/iter; left time: 9973.0904s\n",
      "\titers: 200, epoch: 3 | loss: 0.0345561\n",
      "\tspeed: 0.4299s/iter; left time: 2978.4912s\n",
      "\titers: 300, epoch: 3 | loss: 0.0827537\n",
      "\tspeed: 0.4297s/iter; left time: 2934.1340s\n",
      "\titers: 400, epoch: 3 | loss: 0.0247520\n",
      "\tspeed: 0.4293s/iter; left time: 2888.6854s\n",
      "\titers: 500, epoch: 3 | loss: 0.0211362\n",
      "\tspeed: 0.4296s/iter; left time: 2847.7902s\n",
      "\titers: 600, epoch: 3 | loss: 0.0277196\n",
      "\tspeed: 0.4298s/iter; left time: 2806.1178s\n",
      "\titers: 700, epoch: 3 | loss: 0.0238475\n",
      "\tspeed: 0.4299s/iter; left time: 2763.7734s\n",
      "\titers: 800, epoch: 3 | loss: 0.0294090\n",
      "\tspeed: 0.4295s/iter; left time: 2718.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:22.84s\n",
      "Steps: 891 | Train Loss: 0.0285950 Vali Loss: 0.0374628 Test Loss: 0.0437557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0279634\n",
      "\tspeed: 1.4061s/iter; left time: 8630.9468s\n",
      "\titers: 200, epoch: 4 | loss: 0.0287956\n",
      "\tspeed: 0.4296s/iter; left time: 2593.9548s\n",
      "\titers: 300, epoch: 4 | loss: 0.0461964\n",
      "\tspeed: 0.4297s/iter; left time: 2551.3477s\n",
      "\titers: 400, epoch: 4 | loss: 0.0257409\n",
      "\tspeed: 0.4296s/iter; left time: 2508.2573s\n",
      "\titers: 500, epoch: 4 | loss: 0.0497160\n",
      "\tspeed: 0.4296s/iter; left time: 2465.2327s\n",
      "\titers: 600, epoch: 4 | loss: 0.0265465\n",
      "\tspeed: 0.4295s/iter; left time: 2421.6741s\n",
      "\titers: 700, epoch: 4 | loss: 0.0473226\n",
      "\tspeed: 0.4298s/iter; left time: 2380.1976s\n",
      "\titers: 800, epoch: 4 | loss: 0.0273597\n",
      "\tspeed: 0.4297s/iter; left time: 2336.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:22.78s\n",
      "Steps: 891 | Train Loss: 0.0322772 Vali Loss: 0.0334612 Test Loss: 0.0390127\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0249864\n",
      "\tspeed: 1.4061s/iter; left time: 7377.6438s\n",
      "\titers: 200, epoch: 5 | loss: 0.0252246\n",
      "\tspeed: 0.4295s/iter; left time: 2210.3879s\n",
      "\titers: 300, epoch: 5 | loss: 0.0424091\n",
      "\tspeed: 0.4294s/iter; left time: 2167.1898s\n",
      "\titers: 400, epoch: 5 | loss: 0.0245012\n",
      "\tspeed: 0.4297s/iter; left time: 2125.5750s\n",
      "\titers: 500, epoch: 5 | loss: 0.0244570\n",
      "\tspeed: 0.4298s/iter; left time: 2083.1550s\n",
      "\titers: 600, epoch: 5 | loss: 0.0273184\n",
      "\tspeed: 0.4296s/iter; left time: 2039.4369s\n",
      "\titers: 700, epoch: 5 | loss: 0.0356373\n",
      "\tspeed: 0.4294s/iter; left time: 1995.4684s\n",
      "\titers: 800, epoch: 5 | loss: 0.0293081\n",
      "\tspeed: 0.4297s/iter; left time: 1953.6905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:06m:22.67s\n",
      "Steps: 891 | Train Loss: 0.0300744 Vali Loss: 0.0361560 Test Loss: 0.0415212\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036408960819244385, rmse:0.19081132113933563, mae:0.13220149278640747, rse:0.6757014989852905\n",
      "Original data scale mse:31682290.0, rmse:5628.7021484375, mae:3664.7568359375, rse:0.2803114056587219\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0263314\n",
      "\tspeed: 0.4571s/iter; left time: 4017.9987s\n",
      "\titers: 200, epoch: 1 | loss: 0.0304800\n",
      "\tspeed: 0.4326s/iter; left time: 3760.0946s\n",
      "\titers: 300, epoch: 1 | loss: 0.0245533\n",
      "\tspeed: 0.4331s/iter; left time: 3721.1601s\n",
      "\titers: 400, epoch: 1 | loss: 0.0257120\n",
      "\tspeed: 0.4325s/iter; left time: 3672.3811s\n",
      "\titers: 500, epoch: 1 | loss: 0.0284799\n",
      "\tspeed: 0.4329s/iter; left time: 3632.6926s\n",
      "\titers: 600, epoch: 1 | loss: 0.0238627\n",
      "\tspeed: 0.4331s/iter; left time: 3590.8576s\n",
      "\titers: 700, epoch: 1 | loss: 0.0252320\n",
      "\tspeed: 0.4329s/iter; left time: 3546.1348s\n",
      "\titers: 800, epoch: 1 | loss: 0.0311972\n",
      "\tspeed: 0.4331s/iter; left time: 3503.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:24.99s\n",
      "Steps: 889 | Train Loss: 0.0278562 Vali Loss: 0.0334661 Test Loss: 0.0397636\n",
      "Validation loss decreased (inf --> 0.033466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0450863\n",
      "\tspeed: 1.4281s/iter; left time: 11284.5069s\n",
      "\titers: 200, epoch: 2 | loss: 0.0311006\n",
      "\tspeed: 0.4336s/iter; left time: 3382.7075s\n",
      "\titers: 300, epoch: 2 | loss: 0.0269753\n",
      "\tspeed: 0.4331s/iter; left time: 3336.0842s\n",
      "\titers: 400, epoch: 2 | loss: 0.0305270\n",
      "\tspeed: 0.4336s/iter; left time: 3296.0079s\n",
      "\titers: 500, epoch: 2 | loss: 0.0287632\n",
      "\tspeed: 0.4335s/iter; left time: 3252.3969s\n",
      "\titers: 600, epoch: 2 | loss: 0.0267414\n",
      "\tspeed: 0.4334s/iter; left time: 3207.8745s\n",
      "\titers: 700, epoch: 2 | loss: 0.0242928\n",
      "\tspeed: 0.4333s/iter; left time: 3164.2171s\n",
      "\titers: 800, epoch: 2 | loss: 0.0311260\n",
      "\tspeed: 0.4333s/iter; left time: 3120.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:25.23s\n",
      "Steps: 889 | Train Loss: 0.0301149 Vali Loss: 0.0338407 Test Loss: 0.0413307\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0242542\n",
      "\tspeed: 1.4012s/iter; left time: 9826.9355s\n",
      "\titers: 200, epoch: 3 | loss: 0.0225715\n",
      "\tspeed: 0.4334s/iter; left time: 2995.8603s\n",
      "\titers: 300, epoch: 3 | loss: 0.0252023\n",
      "\tspeed: 0.4336s/iter; left time: 2954.3316s\n",
      "\titers: 400, epoch: 3 | loss: 0.0277086\n",
      "\tspeed: 0.4335s/iter; left time: 2910.4081s\n",
      "\titers: 500, epoch: 3 | loss: 0.0258089\n",
      "\tspeed: 0.4333s/iter; left time: 2865.1128s\n",
      "\titers: 600, epoch: 3 | loss: 0.0351314\n",
      "\tspeed: 0.4331s/iter; left time: 2820.9269s\n",
      "\titers: 700, epoch: 3 | loss: 0.0410178\n",
      "\tspeed: 0.4334s/iter; left time: 2779.2740s\n",
      "\titers: 800, epoch: 3 | loss: 0.0303996\n",
      "\tspeed: 0.4331s/iter; left time: 2733.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:25.22s\n",
      "Steps: 889 | Train Loss: 0.0292495 Vali Loss: 0.0379014 Test Loss: 0.0421503\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0359746\n",
      "\tspeed: 1.4000s/iter; left time: 8573.8107s\n",
      "\titers: 200, epoch: 4 | loss: 0.0541042\n",
      "\tspeed: 0.4327s/iter; left time: 2606.5347s\n",
      "\titers: 300, epoch: 4 | loss: 0.0585116\n",
      "\tspeed: 0.4331s/iter; left time: 2565.4411s\n",
      "\titers: 400, epoch: 4 | loss: 0.0536977\n",
      "\tspeed: 0.4328s/iter; left time: 2520.8099s\n",
      "\titers: 500, epoch: 4 | loss: 0.0335974\n",
      "\tspeed: 0.4334s/iter; left time: 2480.6295s\n",
      "\titers: 600, epoch: 4 | loss: 0.0355108\n",
      "\tspeed: 0.4335s/iter; left time: 2438.1228s\n",
      "\titers: 700, epoch: 4 | loss: 0.0251306\n",
      "\tspeed: 0.4339s/iter; left time: 2396.8018s\n",
      "\titers: 800, epoch: 4 | loss: 0.0282786\n",
      "\tspeed: 0.4338s/iter; left time: 2352.7133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:25.15s\n",
      "Steps: 889 | Train Loss: 0.0479492 Vali Loss: 0.0372989 Test Loss: 0.0428262\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03976361081004143, rmse:0.199408158659935, mae:0.14151641726493835, rse:0.7064430117607117\n",
      "Original data scale mse:36300660.0, rmse:6025.0029296875, mae:3998.170654296875, rse:0.3001945912837982\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0295258\n",
      "\tspeed: 0.4316s/iter; left time: 3794.2959s\n",
      "\titers: 200, epoch: 1 | loss: 0.0273040\n",
      "\tspeed: 0.4323s/iter; left time: 3756.9710s\n",
      "\titers: 300, epoch: 1 | loss: 0.0295736\n",
      "\tspeed: 0.4328s/iter; left time: 3718.3748s\n",
      "\titers: 400, epoch: 1 | loss: 0.0290820\n",
      "\tspeed: 0.4326s/iter; left time: 3673.4872s\n",
      "\titers: 500, epoch: 1 | loss: 0.0252079\n",
      "\tspeed: 0.4324s/iter; left time: 3628.6296s\n",
      "\titers: 600, epoch: 1 | loss: 0.0247434\n",
      "\tspeed: 0.4327s/iter; left time: 3587.4627s\n",
      "\titers: 700, epoch: 1 | loss: 0.0270574\n",
      "\tspeed: 0.4326s/iter; left time: 3543.0415s\n",
      "\titers: 800, epoch: 1 | loss: 0.0282636\n",
      "\tspeed: 0.4328s/iter; left time: 3502.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:24.56s\n",
      "Steps: 889 | Train Loss: 0.0276719 Vali Loss: 0.0337188 Test Loss: 0.0396588\n",
      "Validation loss decreased (inf --> 0.033719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0313039\n",
      "\tspeed: 1.4188s/iter; left time: 11211.7492s\n",
      "\titers: 200, epoch: 2 | loss: 0.0305577\n",
      "\tspeed: 0.4333s/iter; left time: 3380.4976s\n",
      "\titers: 300, epoch: 2 | loss: 0.0332012\n",
      "\tspeed: 0.4329s/iter; left time: 3334.4502s\n",
      "\titers: 400, epoch: 2 | loss: 0.0265207\n",
      "\tspeed: 0.4328s/iter; left time: 3289.9885s\n",
      "\titers: 500, epoch: 2 | loss: 0.0393136\n",
      "\tspeed: 0.4332s/iter; left time: 3249.9898s\n",
      "\titers: 600, epoch: 2 | loss: 0.0274440\n",
      "\tspeed: 0.4329s/iter; left time: 3204.3571s\n",
      "\titers: 700, epoch: 2 | loss: 0.0293092\n",
      "\tspeed: 0.4330s/iter; left time: 3161.8002s\n",
      "\titers: 800, epoch: 2 | loss: 0.0308485\n",
      "\tspeed: 0.4333s/iter; left time: 3120.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:24.93s\n",
      "Steps: 889 | Train Loss: 0.0312136 Vali Loss: 0.0361187 Test Loss: 0.0431717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0288224\n",
      "\tspeed: 1.3987s/iter; left time: 9808.8765s\n",
      "\titers: 200, epoch: 3 | loss: 0.0310063\n",
      "\tspeed: 0.4326s/iter; left time: 2990.7922s\n",
      "\titers: 300, epoch: 3 | loss: 0.0352842\n",
      "\tspeed: 0.4330s/iter; left time: 2949.9029s\n",
      "\titers: 400, epoch: 3 | loss: 0.0418466\n",
      "\tspeed: 0.4329s/iter; left time: 2905.8803s\n",
      "\titers: 500, epoch: 3 | loss: 0.0344101\n",
      "\tspeed: 0.4331s/iter; left time: 2864.3059s\n",
      "\titers: 600, epoch: 3 | loss: 0.0319634\n",
      "\tspeed: 0.4331s/iter; left time: 2821.0603s\n",
      "\titers: 700, epoch: 3 | loss: 0.0236920\n",
      "\tspeed: 0.4327s/iter; left time: 2774.9954s\n",
      "\titers: 800, epoch: 3 | loss: 0.0330941\n",
      "\tspeed: 0.4328s/iter; left time: 2732.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:24.86s\n",
      "Steps: 889 | Train Loss: 0.0305178 Vali Loss: 0.0368927 Test Loss: 0.0426430\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0269050\n",
      "\tspeed: 1.4011s/iter; left time: 8580.4898s\n",
      "\titers: 200, epoch: 4 | loss: 0.0329594\n",
      "\tspeed: 0.4326s/iter; left time: 2606.2009s\n",
      "\titers: 300, epoch: 4 | loss: 0.0453819\n",
      "\tspeed: 0.4323s/iter; left time: 2561.0831s\n",
      "\titers: 400, epoch: 4 | loss: 0.1658331\n",
      "\tspeed: 0.4326s/iter; left time: 2519.4913s\n",
      "\titers: 500, epoch: 4 | loss: 0.1501592\n",
      "\tspeed: 0.4332s/iter; left time: 2479.5750s\n",
      "\titers: 600, epoch: 4 | loss: 0.1033865\n",
      "\tspeed: 0.4331s/iter; left time: 2435.6009s\n",
      "\titers: 700, epoch: 4 | loss: 0.1256969\n",
      "\tspeed: 0.4328s/iter; left time: 2390.7842s\n",
      "\titers: 800, epoch: 4 | loss: 0.1280188\n",
      "\tspeed: 0.4327s/iter; left time: 2347.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:06m:24.75s\n",
      "Steps: 889 | Train Loss: 0.0997957 Vali Loss: 0.1454913 Test Loss: 0.1583640\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0396588034927845, rmse:0.19914518296718597, mae:0.14097996056079865, rse:0.7055113911628723\n",
      "Original data scale mse:35193636.0, rmse:5932.42236328125, mae:3945.4326171875, rse:0.29558178782463074\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1258403\n",
      "\tspeed: 0.4489s/iter; left time: 3964.5330s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231065\n",
      "\tspeed: 0.4253s/iter; left time: 3713.0306s\n",
      "\titers: 300, epoch: 1 | loss: 0.1272605\n",
      "\tspeed: 0.4249s/iter; left time: 3667.4698s\n",
      "\titers: 400, epoch: 1 | loss: 0.1197788\n",
      "\tspeed: 0.4254s/iter; left time: 3628.7174s\n",
      "\titers: 500, epoch: 1 | loss: 0.1216038\n",
      "\tspeed: 0.4249s/iter; left time: 3582.3071s\n",
      "\titers: 600, epoch: 1 | loss: 0.1185465\n",
      "\tspeed: 0.4247s/iter; left time: 3538.2887s\n",
      "\titers: 700, epoch: 1 | loss: 0.1460749\n",
      "\tspeed: 0.4256s/iter; left time: 3502.9367s\n",
      "\titers: 800, epoch: 1 | loss: 0.1255088\n",
      "\tspeed: 0.4246s/iter; left time: 3452.2695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:06m:19.64s\n",
      "Steps: 893 | Train Loss: 0.1264653 Vali Loss: 0.0220948 Test Loss: 0.0234206\n",
      "Validation loss decreased (inf --> 0.022095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1478567\n",
      "\tspeed: 1.4139s/iter; left time: 11223.6173s\n",
      "\titers: 200, epoch: 2 | loss: 0.1473418\n",
      "\tspeed: 0.4254s/iter; left time: 3334.1920s\n",
      "\titers: 300, epoch: 2 | loss: 0.1416407\n",
      "\tspeed: 0.4260s/iter; left time: 3296.0953s\n",
      "\titers: 400, epoch: 2 | loss: 0.1644028\n",
      "\tspeed: 0.4254s/iter; left time: 3248.9787s\n",
      "\titers: 500, epoch: 2 | loss: 0.1363324\n",
      "\tspeed: 0.4260s/iter; left time: 3211.0683s\n",
      "\titers: 600, epoch: 2 | loss: 0.1191079\n",
      "\tspeed: 0.4258s/iter; left time: 3166.7741s\n",
      "\titers: 700, epoch: 2 | loss: 0.1210496\n",
      "\tspeed: 0.4256s/iter; left time: 3123.3851s\n",
      "\titers: 800, epoch: 2 | loss: 0.1277977\n",
      "\tspeed: 0.4259s/iter; left time: 3082.6791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:06m:20.08s\n",
      "Steps: 893 | Train Loss: 0.1437065 Vali Loss: 0.0237258 Test Loss: 0.0251481\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1425114\n",
      "\tspeed: 1.4092s/iter; left time: 9927.8968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1176238\n",
      "\tspeed: 0.4258s/iter; left time: 2956.8666s\n",
      "\titers: 300, epoch: 3 | loss: 0.1337754\n",
      "\tspeed: 0.4254s/iter; left time: 2911.6912s\n",
      "\titers: 400, epoch: 3 | loss: 0.1355311\n",
      "\tspeed: 0.4256s/iter; left time: 2870.9680s\n",
      "\titers: 500, epoch: 3 | loss: 0.1333648\n",
      "\tspeed: 0.4258s/iter; left time: 2829.5563s\n",
      "\titers: 600, epoch: 3 | loss: 0.1398519\n",
      "\tspeed: 0.4252s/iter; left time: 2783.1934s\n",
      "\titers: 700, epoch: 3 | loss: 0.1573943\n",
      "\tspeed: 0.4255s/iter; left time: 2742.5956s\n",
      "\titers: 800, epoch: 3 | loss: 0.1679125\n",
      "\tspeed: 0.4255s/iter; left time: 2699.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:06m:19.96s\n",
      "Steps: 893 | Train Loss: 0.1376971 Vali Loss: 0.0223714 Test Loss: 0.0252050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1316965\n",
      "\tspeed: 1.4097s/iter; left time: 8672.2531s\n",
      "\titers: 200, epoch: 4 | loss: 0.2191950\n",
      "\tspeed: 0.4253s/iter; left time: 2574.1027s\n",
      "\titers: 300, epoch: 4 | loss: 0.1456622\n",
      "\tspeed: 0.4262s/iter; left time: 2536.6648s\n",
      "\titers: 400, epoch: 4 | loss: 0.1390803\n",
      "\tspeed: 0.4254s/iter; left time: 2489.6949s\n",
      "\titers: 500, epoch: 4 | loss: 0.1344619\n",
      "\tspeed: 0.4257s/iter; left time: 2448.4979s\n",
      "\titers: 600, epoch: 4 | loss: 0.1343464\n",
      "\tspeed: 0.4257s/iter; left time: 2406.1904s\n",
      "\titers: 700, epoch: 4 | loss: 0.1201495\n",
      "\tspeed: 0.4253s/iter; left time: 2361.3019s\n",
      "\titers: 800, epoch: 4 | loss: 0.2329763\n",
      "\tspeed: 0.4257s/iter; left time: 2320.9253s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 64\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "    log_file.write(statement_1)\n",
    "    print(statement_1)  # Print to notebook\n",
    "\n",
    "    for pred_len in pred_lens:\n",
    "        statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "        log_file.write(statement_2)\n",
    "        print(statement_2) \n",
    "        model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "        # Command arguments\n",
    "        command = f\"\"\"\n",
    "        python {script_path} \\\n",
    "            --random_seed 2021 \\\n",
    "            --is_training 1 \\\n",
    "            --root_path \"{data_path}\" \\\n",
    "            --data_path \"{dataset}\" \\\n",
    "            --model_id {model_id} \\\n",
    "            --model \"{model}\" \\\n",
    "            --data \"custom\" \\\n",
    "            --features M \\\n",
    "            --seq_len {seq_len} \\\n",
    "            --label_len 5 \\\n",
    "            --pred_len {pred_len} \\\n",
    "            --e_layers 2 \\\n",
    "            --d_layers 1 \\\n",
    "            --factor 5 \\\n",
    "            --enc_in 5 \\\n",
    "            --dec_in 5 \\\n",
    "            --c_out 5 \\\n",
    "            --des 'Exp' \\\n",
    "            --train_epochs 10 \\\n",
    "            --patience 3 \\\n",
    "            --overlapping_windows \\\n",
    "            --inverse \\\n",
    "            --scaler_type minmax \\\n",
    "            --if_relu \\\n",
    "            --loss_fnc \"{loss}\" \\\n",
    "            --patch_len 1 \\\n",
    "            --stride 1 \\\n",
    "            --itr {itr} --batch_size 32 --learning_rate \"{lr}\" \\\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the command and capture the output\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "        # Capture the output in real-time\n",
    "        output = []\n",
    "        for line in process.stdout:\n",
    "            output.append(line)\n",
    "            print(line, end='')  # Print in the .ipynb cell\n",
    "            log_file.write(line)  # Write to the log file\n",
    "\n",
    "        # Wait for the process to complete\n",
    "        process.wait()\n",
    "\n",
    "        # Delete the checkpoints folder and all its contents\n",
    "        shutil.rmtree('./checkpoints' )\n",
    "\n",
    "        # Extract metrics for each iteration\n",
    "        iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "        iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "        # Log the extracted metrics and save them\n",
    "        for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "            log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "            log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "            log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "            # Append the results to the informer_results lists\n",
    "            metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "            for result_list, metrics in metrics_data:\n",
    "                result_list.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.5477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.7258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2062</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.7508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.7768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.5462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.5476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.7460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.7884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0254  0.1593  0.1056  0.5624\n",
       "              2         24        0.0241  0.1551  0.1024  0.5477\n",
       "              1         96        0.0420  0.2050  0.1436  0.7258\n",
       "              2         96        0.0425  0.2062  0.1425  0.7303\n",
       "              1         168       0.0449  0.2119  0.1500  0.7508\n",
       "              2         168       0.0481  0.2193  0.1509  0.7768\n",
       "RMSE          1         24        0.0239  0.1547  0.1037  0.5462\n",
       "              2         24        0.0240  0.1550  0.1044  0.5476\n",
       "              1         96        0.0476  0.2182  0.1525  0.7726\n",
       "              2         96        0.0458  0.2140  0.1418  0.7578\n",
       "              1         168       0.0443  0.2106  0.1473  0.7460\n",
       "              2         168       0.0447  0.2115  0.1491  0.7491\n",
       "MAE           1         24        0.0270  0.1644  0.1032  0.5805\n",
       "              2         24        0.0249  0.1577  0.0996  0.5568\n",
       "              1         96        0.0496  0.2226  0.1465  0.7884\n",
       "              2         96        0.0496  0.2226  0.1467  0.7883\n",
       "              1         168       0.0603  0.2456  0.1604  0.8701\n",
       "              2         168       0.0545  0.2335  0.1560  0.8273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_no_patching.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_no_patching.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19506484.0</td>\n",
       "      <td>4416.6147</td>\n",
       "      <td>2876.1069</td>\n",
       "      <td>0.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19008062.0</td>\n",
       "      <td>4359.8237</td>\n",
       "      <td>2790.5967</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36130940.0</td>\n",
       "      <td>6010.9019</td>\n",
       "      <td>4012.9888</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36122992.0</td>\n",
       "      <td>6010.2407</td>\n",
       "      <td>3954.7468</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39282812.0</td>\n",
       "      <td>6267.6001</td>\n",
       "      <td>4202.2949</td>\n",
       "      <td>0.3123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40928480.0</td>\n",
       "      <td>6397.5371</td>\n",
       "      <td>4202.4697</td>\n",
       "      <td>0.3188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19043724.0</td>\n",
       "      <td>4363.9116</td>\n",
       "      <td>2849.0442</td>\n",
       "      <td>0.2170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19401690.0</td>\n",
       "      <td>4404.7349</td>\n",
       "      <td>2870.5693</td>\n",
       "      <td>0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38907712.0</td>\n",
       "      <td>6237.6045</td>\n",
       "      <td>4236.4297</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37945684.0</td>\n",
       "      <td>6160.0068</td>\n",
       "      <td>3876.0593</td>\n",
       "      <td>0.3068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38489120.0</td>\n",
       "      <td>6203.9600</td>\n",
       "      <td>4120.3130</td>\n",
       "      <td>0.3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39429468.0</td>\n",
       "      <td>6279.2886</td>\n",
       "      <td>4190.6279</td>\n",
       "      <td>0.3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19359624.0</td>\n",
       "      <td>4399.9570</td>\n",
       "      <td>2728.8313</td>\n",
       "      <td>0.2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18901044.0</td>\n",
       "      <td>4347.5332</td>\n",
       "      <td>2686.6917</td>\n",
       "      <td>0.2162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38852912.0</td>\n",
       "      <td>6233.2104</td>\n",
       "      <td>3966.3728</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>39954652.0</td>\n",
       "      <td>6320.9692</td>\n",
       "      <td>3986.6050</td>\n",
       "      <td>0.3148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>43195992.0</td>\n",
       "      <td>6572.3657</td>\n",
       "      <td>4203.3413</td>\n",
       "      <td>0.3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45199216.0</td>\n",
       "      <td>6723.0361</td>\n",
       "      <td>4282.5435</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        19506484.0  4416.6147  2876.1069  0.2196\n",
       "              2         24        19008062.0  4359.8237  2790.5967  0.2168\n",
       "              1         96        36130940.0  6010.9019  4012.9888  0.2993\n",
       "              2         96        36122992.0  6010.2407  3954.7468  0.2993\n",
       "              1         168       39282812.0  6267.6001  4202.2949  0.3123\n",
       "              2         168       40928480.0  6397.5371  4202.4697  0.3188\n",
       "RMSE          1         24        19043724.0  4363.9116  2849.0442  0.2170\n",
       "              2         24        19401690.0  4404.7349  2870.5693  0.2190\n",
       "              1         96        38907712.0  6237.6045  4236.4297  0.3106\n",
       "              2         96        37945684.0  6160.0068  3876.0593  0.3068\n",
       "              1         168       38489120.0  6203.9600  4120.3130  0.3091\n",
       "              2         168       39429468.0  6279.2886  4190.6279  0.3129\n",
       "MAE           1         24        19359624.0  4399.9570  2728.8313  0.2188\n",
       "              2         24        18901044.0  4347.5332  2686.6917  0.2162\n",
       "              1         96        38852912.0  6233.2104  3966.3728  0.3104\n",
       "              2         96        39954652.0  6320.9692  3986.6050  0.3148\n",
       "              1         168       43195992.0  6572.3657  4203.3413  0.3275\n",
       "              2         168       45199216.0  6723.0361  4282.5435  0.3350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.5687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.8487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.7476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0259  0.1610  0.1014  0.5687\n",
       "         MSE            0.0247  0.1572  0.1040  0.5551\n",
       "         RMSE           0.0240  0.1549  0.1040  0.5469\n",
       "96       MAE            0.0496  0.2226  0.1466  0.7883\n",
       "         MSE            0.0423  0.2056  0.1431  0.7281\n",
       "         RMSE           0.0467  0.2161  0.1472  0.7652\n",
       "168      MAE            0.0574  0.2396  0.1582  0.8487\n",
       "         MSE            0.0465  0.2156  0.1504  0.7638\n",
       "         RMSE           0.0445  0.2110  0.1482  0.7476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19130334.0</td>\n",
       "      <td>4373.7451</td>\n",
       "      <td>2707.7615</td>\n",
       "      <td>0.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19257273.0</td>\n",
       "      <td>4388.2192</td>\n",
       "      <td>2833.3518</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19222707.0</td>\n",
       "      <td>4384.3232</td>\n",
       "      <td>2859.8068</td>\n",
       "      <td>0.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39403782.0</td>\n",
       "      <td>6277.0898</td>\n",
       "      <td>3976.4889</td>\n",
       "      <td>0.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36126966.0</td>\n",
       "      <td>6010.5713</td>\n",
       "      <td>3983.8678</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38426698.0</td>\n",
       "      <td>6198.8057</td>\n",
       "      <td>4056.2445</td>\n",
       "      <td>0.3087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>44197604.0</td>\n",
       "      <td>6647.7009</td>\n",
       "      <td>4242.9424</td>\n",
       "      <td>0.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>40105646.0</td>\n",
       "      <td>6332.5686</td>\n",
       "      <td>4202.3823</td>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38959294.0</td>\n",
       "      <td>6241.6243</td>\n",
       "      <td>4155.4705</td>\n",
       "      <td>0.3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19130334.0  4373.7451  2707.7615  0.2175\n",
       "         MSE            19257273.0  4388.2192  2833.3518  0.2182\n",
       "         RMSE           19222707.0  4384.3232  2859.8068  0.2180\n",
       "96       MAE            39403782.0  6277.0898  3976.4889  0.3126\n",
       "         MSE            36126966.0  6010.5713  3983.8678  0.2993\n",
       "         RMSE           38426698.0  6198.8057  4056.2445  0.3087\n",
       "168      MAE            44197604.0  6647.7009  4242.9424  0.3312\n",
       "         MSE            40105646.0  6332.5686  4202.3823  0.3155\n",
       "         RMSE           38959294.0  6241.6243  4155.4705  0.3110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled_no_patching'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No channel independence (channel-mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
