{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder named \"datasets\" if it doesn't exist\n",
    "folder_name = \"datasets\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "df = pd.read_csv(\"datasets/top_5_countries.csv\", index_col=0, parse_dates=True)\n",
    "# Reset index for Data Loader\n",
    "df.reset_index(inplace=True)\n",
    "df = df.iloc[:,:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "\n",
    "# Split and save the datasets\n",
    "for country_prefix in top_5_countries:\n",
    "    # Filter columns with the specified prefix\n",
    "    country_columns = [col for col in df.columns if col.startswith(country_prefix)]\n",
    "    \n",
    "    # Insert the date column at the beginning of every dataset\n",
    "    country_columns.insert(0,\"date\")\n",
    "    country_df = df[country_columns]\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_name = f\"datasets/{country_prefix}_data.csv\"\n",
    "    country_df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "# parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_to_run_file = \"/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py\"\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Execute the script and capture the output\n",
    "        command = [\"python\", \"-u\", path_to_run_file] + model_arguments\n",
    "        output = subprocess.check_output(command, universal_newlines=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output  \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['DE_data.csv', 'GB_data.csv', 'ES_data.csv', 'FR_data.csv', 'IT_data.csv']\n",
    "num_cols = [\"5\", \"5\", \"3\", \"3\", \"3\"]\n",
    "pred_len = \"24\"\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    model_id = f\"_{pred_len}_{dataset[:2]}\"  # Create the model_id\n",
    "    model_arguments = [\n",
    "                \"--task_name\", \"long_term_forecast\",\n",
    "                \"--is_training\", \"1\", #True\n",
    "                \"--root_path\", \"datasets/\",\n",
    "                \"--data_path\", dataset,\n",
    "                # \"--train_epochs\", \"1\",\n",
    "                \"--model_id\", '1',\n",
    "                \"--model\", \"Informer\",\n",
    "                \"--data\", \"custom\", # Use a custom dataloader (same data preparation as in ARIMA)\n",
    "                \"--features\", \"M\", # Multivariate\n",
    "                \"--seq_len\", \"96\",\n",
    "                \"--label_len\", \"48\",\n",
    "                \"--pred_len\", pred_len,\n",
    "                \"--e_layers\", \"2\", \n",
    "                \"--d_layers\", \"5\",\n",
    "                \"--factor\", \"5\",\n",
    "                \"--enc_in\", num_cols[i], \n",
    "                \"--dec_in\", num_cols[i], \n",
    "                \"--c_out\", num_cols[i],\n",
    "                \"--des\", \"Exp\",\n",
    "                \"--itr\", \"2\",\n",
    "            ]\n",
    "\n",
    "model_output = run_output(path_to_run_file, model_arguments)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/GB_data.csv\")\n",
    "df_small = df.iloc[:240, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.to_csv(\"datasets/GB_data_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>GB_UKM_load_actual_entsoe_transparency</th>\n",
       "      <th>GB_UKM_solar_generation_actual</th>\n",
       "      <th>GB_UKM_wind_generation_actual</th>\n",
       "      <th>GB_UKM_wind_offshore_generation_actual</th>\n",
       "      <th>GB_UKM_wind_onshore_generation_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-26 00:00:00</td>\n",
       "      <td>30680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5348.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>3463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-26 01:00:00</td>\n",
       "      <td>29218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5194.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-26 02:00:00</td>\n",
       "      <td>28016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>2633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-26 03:00:00</td>\n",
       "      <td>27402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>3417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-26 04:00:00</td>\n",
       "      <td>27490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5206.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2015-11-04 19:00:00</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2015-11-04 20:00:00</td>\n",
       "      <td>46550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2015-11-04 21:00:00</td>\n",
       "      <td>42752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2015-11-04 22:00:00</td>\n",
       "      <td>38984.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2015-11-04 23:00:00</td>\n",
       "      <td>34184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  GB_UKM_load_actual_entsoe_transparency  \\\n",
       "0    2015-10-26 00:00:00                                 30680.0   \n",
       "1    2015-10-26 01:00:00                                 29218.0   \n",
       "2    2015-10-26 02:00:00                                 28016.0   \n",
       "3    2015-10-26 03:00:00                                 27402.0   \n",
       "4    2015-10-26 04:00:00                                 27490.0   \n",
       "..                   ...                                     ...   \n",
       "235  2015-11-04 19:00:00                                 49595.0   \n",
       "236  2015-11-04 20:00:00                                 46550.0   \n",
       "237  2015-11-04 21:00:00                                 42752.0   \n",
       "238  2015-11-04 22:00:00                                 38984.0   \n",
       "239  2015-11-04 23:00:00                                 34184.0   \n",
       "\n",
       "     GB_UKM_solar_generation_actual  GB_UKM_wind_generation_actual  \\\n",
       "0                               0.0                         5348.0   \n",
       "1                               0.0                         5194.0   \n",
       "2                               0.0                         4389.0   \n",
       "3                               0.0                         5104.0   \n",
       "4                               0.0                         5206.0   \n",
       "..                              ...                            ...   \n",
       "235                             0.0                         1012.0   \n",
       "236                             0.0                         1246.0   \n",
       "237                             0.0                         1441.0   \n",
       "238                             0.0                         1430.0   \n",
       "239                             0.0                         1400.0   \n",
       "\n",
       "     GB_UKM_wind_offshore_generation_actual  \\\n",
       "0                                    1885.0   \n",
       "1                                    1810.0   \n",
       "2                                    1756.0   \n",
       "3                                    1687.0   \n",
       "4                                    1749.0   \n",
       "..                                      ...   \n",
       "235                                   584.0   \n",
       "236                                   792.0   \n",
       "237                                   915.0   \n",
       "238                                   912.0   \n",
       "239                                   875.0   \n",
       "\n",
       "     GB_UKM_wind_onshore_generation_actual  \n",
       "0                                   3463.0  \n",
       "1                                   3383.0  \n",
       "2                                   2633.0  \n",
       "3                                   3417.0  \n",
       "4                                   3456.0  \n",
       "..                                     ...  \n",
       "235                                  429.0  \n",
       "236                                  455.0  \n",
       "237                                  526.0  \n",
       "238                                  518.0  \n",
       "239                                  525.0  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1rv2rKwQqgoHDNjXtRoAEWZ2ATz0gGAKu?usp=sharing#scrollTo=yu6zzic9t_Cz\n",
    "# Popen: https://colab.research.google.com/github/aviadr1/learn-python/blob/master/content/13_multiprocessing/notebooks/os_system_subprocess.ipynb\n",
    "import subprocess\n",
    "import os\n",
    "# parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_to_run_file = '/vol/cs-hu/riabchuv/my_work/TSLibrary/run.py' #\"/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py\"\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Execute the script and capture the output\n",
    "        command = [\"python\", \"-u\", path_to_run_file] + model_arguments\n",
    "        output = subprocess.check_output(command, universal_newlines=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output  \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp='GB_data_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 139\n",
      "val 39\n",
      "test 15\n",
      "Epoch: 1 running time: 0.020170950889587404 min.\n",
      "Epoch: 1, Steps: 5 | Train Loss: 0.9670790 Vali Loss: 1.8156426 Test Loss: 2.6099954\n",
      "Validation loss decreased (inf --> 1.815643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 15\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "mse:10694611.0, mae:2371.6455078125\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 139\n",
      "val 39\n",
      "test 15\n",
      "Epoch: 1 running time: 0.010464016596476238 min.\n",
      "Epoch: 1, Steps: 5 | Train Loss: 1.0279534 Vali Loss: 1.3119766 Test Loss: 2.0288160\n",
      "Validation loss decreased (inf --> 1.311977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 15\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "mse:10844241.0, mae:2239.444580078125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\", #True\n",
    "            \"--root_path\", \"datasets/\",\n",
    "            \"--data_path\", dp,\n",
    "            \"--train_epochs\", \"1\",\n",
    "            \"--model_id\", '1',\n",
    "            \"--model\", \"Informer\",\n",
    "            \"--data\", \"custom\", # This ensures a 70%,10%,20% train,val,test split see data_provider/data_loader.py\n",
    "            \"--features\", \"M\", # Multivariate\n",
    "            \"--seq_len\", \"20\",\n",
    "            \"--label_len\", \"10\",\n",
    "            \"--pred_len\", '10',\n",
    "            \"--e_layers\", \"3\", # Hyperparameters as in original model\n",
    "            \"--d_layers\", \"2\",\n",
    "            \"--factor\", \"3\",\n",
    "            \"--enc_in\", \"5\", #str((num_columns)-1),\n",
    "            \"--dec_in\", \"5\", #str((num_columns)-1),\n",
    "            \"--c_out\", \"5\", # str((num_columns)-1),\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\",\n",
    "            \"--train_epochs\", \"1\",\n",
    "            \"--inverse\",\n",
    "        ]\n",
    "\n",
    "model_output = run_output(path_to_run_file, model_arguments)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 139\n",
      "val 39\n",
      "test 15\n",
      "Epoch: 1 running time: 0.020879960060119628 min.\n",
      "Epoch: 1, Steps: 5 | Train Loss: 0.5335042 Vali Loss: 0.7527484 Test Loss: 1.1197095\n",
      "Validation loss decreased (inf --> 0.752748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 15\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "mse:13610822.0, mae:2585.323974609375\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 139\n",
      "val 39\n",
      "test 15\n",
      "Epoch: 1 running time: 0.009805583953857422 min.\n",
      "Epoch: 1, Steps: 5 | Train Loss: 0.5470862 Vali Loss: 0.5950965 Test Loss: 0.8450578\n",
      "Validation loss decreased (inf --> 0.595097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl20_ll10_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 15\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "test shape: (15, 10, 5) (15, 10, 5)\n",
      "mse:13095551.0, mae:2298.73974609375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\", #True\n",
    "            \"--root_path\", \"datasets/\",\n",
    "            \"--data_path\", dp,\n",
    "            \"--train_epochs\", \"1\",\n",
    "            \"--model_id\", '1',\n",
    "            \"--model\", \"Informer\",\n",
    "            \"--data\", \"custom\", # This ensures a 70%,10%,20% train,val,test split see data_provider/data_loader.py\n",
    "            \"--features\", \"M\", # Multivariate\n",
    "            \"--seq_len\", \"20\",\n",
    "            \"--label_len\", \"10\",\n",
    "            \"--pred_len\", '10',\n",
    "            \"--e_layers\", \"3\", # Hyperparameters as in original model\n",
    "            \"--d_layers\", \"2\",\n",
    "            \"--factor\", \"3\",\n",
    "            \"--enc_in\", \"5\", #str((num_columns)-1),\n",
    "            \"--dec_in\", \"5\", #str((num_columns)-1),\n",
    "            \"--c_out\", \"5\", # str((num_columns)-1),\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\",\n",
    "            \"--train_epochs\", \"1\",\n",
    "            \"--inverse\",\n",
    "        ]\n",
    "\n",
    "model_output = run_output(path_to_run_file, model_arguments)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([155.,  24.,  17.,  11.,   9.,  11.,   4.,   4.,   3.,   2.]),\n",
       " array([   0. ,  260.1,  520.2,  780.3, 1040.4, 1300.5, 1560.6, 1820.7,\n",
       "        2080.8, 2340.9, 2601. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/vol/cs-hu/riabchuv/my_work/datasets/GB_data_small.csv')\n",
    "plt.hist(df['GB_UKM_solar_generation_actual'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use CPU\\n>>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\\ntrain 149\\nval 15\\ntest 39\\nEpoch: 1 cost time: 31.332730054855347\\nEpoch: 1, Steps: 4 | Train Loss: 0.9952646 Vali Loss: nan Test Loss: 1.1890596\\nValidation loss decreased (inf --> nan).  Saving model ...\\nUpdating learning rate to 0.0001\\n>>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\ntest 39\\ntest shape: (39, 1, 10, 5) (39, 1, 10, 5)\\ntest shape: (39, 10, 5) (39, 10, 5)\\nmse:1.1777945756912231, mae:0.8684789538383484\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 149\n",
      "val 15\n",
      "test 39\n",
      "Epoch: 1 cost time: 31.332730054855347\n",
      "Epoch: 1, Steps: 4 | Train Loss: 0.9952646 Vali Loss: nan Test Loss: 1.1890596\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 39\n",
      "test shape: (39, 1, 10, 5) (39, 1, 10, 5)\n",
      "test shape: (39, 10, 5) (39, 10, 5)\n",
      "mse:1.1777945756912231, mae:0.8684789538383484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1777945756912231\n",
      "MAE: 0.8684789538383484\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the regular expression \n",
    "pattern = r\"mse:(.*?), mae:(.*?)$\"\n",
    "\n",
    "# Use re.search to find the pattern in the output string\n",
    "match = re.search(pattern, model_output)\n",
    "\n",
    "if match:\n",
    "    # Extract the MSE and MAE values from the matched groups\n",
    "    mse = float(match.group(1))\n",
    "    mae = float(match.group(2))\n",
    "    \n",
    "    \n",
    "    print(\"mse:\", mse)\n",
    "    print(\"mae:\", mae)\n",
    "else:\n",
    "    print(\"No match found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.86847895,   1.1777946 ,   1.0852624 ,   3.2318454 ,\n",
       "       769.5208    ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# metrics\n",
    "np.load(\"/Users/valentyna/Documents/Master_thesis_new/results/long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 10, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/Users/valentyna/Documents/Master_thesis_new/results/long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: run.py [-h] --task_name TASK_NAME --is_training IS_TRAINING --model_id\n",
      "              MODEL_ID --model MODEL --data DATA [--root_path ROOT_PATH]\n",
      "              [--data_path DATA_PATH] [--features FEATURES] [--target TARGET]\n",
      "              [--freq FREQ] [--checkpoints CHECKPOINTS] [--seq_len SEQ_LEN]\n",
      "              [--label_len LABEL_LEN] [--pred_len PRED_LEN]\n",
      "              [--seasonal_patterns SEASONAL_PATTERNS] [--inverse]\n",
      "              [--mask_rate MASK_RATE] [--anomaly_ratio ANOMALY_RATIO]\n",
      "              [--top_k TOP_K] [--num_kernels NUM_KERNELS] [--enc_in ENC_IN]\n",
      "              [--dec_in DEC_IN] [--c_out C_OUT] [--d_model D_MODEL]\n",
      "              [--n_heads N_HEADS] [--e_layers E_LAYERS] [--d_layers D_LAYERS]\n",
      "              [--d_ff D_FF] [--moving_avg MOVING_AVG] [--factor FACTOR]\n",
      "              [--distil] [--dropout DROPOUT] [--embed EMBED]\n",
      "              [--activation ACTIVATION] [--output_attention]\n",
      "              [--channel_independence CHANNEL_INDEPENDENCE]\n",
      "              [--decomp_method DECOMP_METHOD] [--use_norm USE_NORM]\n",
      "              [--down_sampling_layers DOWN_SAMPLING_LAYERS]\n",
      "              [--down_sampling_window DOWN_SAMPLING_WINDOW]\n",
      "              [--down_sampling_method DOWN_SAMPLING_METHOD]\n",
      "              [--seg_len SEG_LEN] [--num_workers NUM_WORKERS] [--itr ITR]\n",
      "              [--train_epochs TRAIN_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "              [--patience PATIENCE] [--learning_rate LEARNING_RATE]\n",
      "              [--des DES] [--loss LOSS] [--lradj LRADJ] [--use_amp]\n",
      "              [--use_gpu USE_GPU] [--gpu GPU] [--use_multi_gpu]\n",
      "              [--devices DEVICES]\n",
      "              [--p_hidden_dims P_HIDDEN_DIMS [P_HIDDEN_DIMS ...]]\n",
      "              [--p_hidden_layers P_HIDDEN_LAYERS]\n",
      "run.py: error: the following arguments are required: --task_name, --is_training, --model_id, --model, --data\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', '-u', '/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py']' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-u\u001b[39m\u001b[38;5;124m\"\u001b[39m, DIR]\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniversal_newlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', '-u', '/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py']' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "DIR = \"/Users/valentyna/Documents/Master_thesis_new/TSLibrary/run.py\"\n",
    "command = [\"python\", \"-u\", DIR]\n",
    "output = subprocess.check_output(command, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/valentyna/Documents/run.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def run_experiment(config):\n",
    "    fix_seed = 2021\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "\n",
    "    args = config.copy()  # Copy the configuration dictionary\n",
    "    \n",
    "    args['use_gpu'] = True if torch.cuda.is_available() and args['use_gpu'] else False\n",
    "\n",
    "    if args['use_gpu'] and args['use_multi_gpu']:\n",
    "        args['devices'] = args['devices'].replace(' ', '')\n",
    "        device_ids = args['devices'].split(',')\n",
    "        args['device_ids'] = [int(id_) for id_ in device_ids]\n",
    "        args['gpu'] = args['device_ids'][0]\n",
    "\n",
    "    print('Args in experiment:')\n",
    "    print(args)\n",
    "\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "    if args['is_training']:\n",
    "        for ii in range(args['itr']):\n",
    "            # setting record of experiments\n",
    "            setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "                args['task_name'],\n",
    "                args['model_id'],\n",
    "                args['model'],\n",
    "                args['data'],\n",
    "                args['features'],\n",
    "                args['seq_len'],\n",
    "                args['label_len'],\n",
    "                args['pred_len'],\n",
    "                args['d_model'],\n",
    "                args['n_heads'],\n",
    "                args['e_layers'],\n",
    "                args['d_layers'],\n",
    "                args['d_ff'],\n",
    "                args['factor'],\n",
    "                args['embed'],\n",
    "                args['distil'],\n",
    "                args['des'], ii)\n",
    "            exp = Exp(args)  # set experiments\n",
    "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            exp.train(setting)\n",
    "\n",
    "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.test(setting)\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        ii = 0\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args['task_name'],\n",
    "            args['model_id'],\n",
    "            args['model'],\n",
    "            args['data'],\n",
    "            args['features'],\n",
    "            args['seq_len'],\n",
    "            args['label_len'],\n",
    "            args['pred_len'],\n",
    "            args['d_model'],\n",
    "            args['n_heads'],\n",
    "            args['e_layers'],\n",
    "            args['d_layers'],\n",
    "            args['d_ff'],\n",
    "            args['factor'],\n",
    "            args['embed'],\n",
    "            args['distil'],\n",
    "            args['des'], ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting, test=1)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Example configuration\n",
    "config = {\n",
    "    'task_name': 'long_term_forecast',\n",
    "    'is_training': 1,\n",
    "    'model_id': 'test',\n",
    "    'model': 'Autoformer',\n",
    "    'data': 'ETTm1',\n",
    "    'root_path': './data/ETT/',\n",
    "    'data_path': 'ETTh1.csv',\n",
    "    'features': 'M',\n",
    "    'target': 'OT',\n",
    "    'freq': 'h',\n",
    "    'checkpoints': './checkpoints/',\n",
    "    'seq_len': 96,\n",
    "    'label_len': 48,\n",
    "    'pred_len': 96,\n",
    "    'seasonal_patterns': 'Monthly',\n",
    "    'inverse': False,\n",
    "    'mask_rate': 0.25,\n",
    "    'anomaly_ratio': 0.25,\n",
    "    'top_k': 5,\n",
    "    'num_kernels': 6,\n",
    "    'enc_in': 7,\n",
    "    'dec_in': 7,\n",
    "    'c_out': 7,\n",
    "    'd_model': 512,\n",
    "    'n_heads': 8,\n",
    "    'e_layers': 2,\n",
    "    'd_layers': 1,\n",
    "    'd_ff': 2048,\n",
    "    'moving_avg': 25,\n",
    "    'factor': 1,\n",
    "    'distil': True,\n",
    "    'dropout': 0.1,\n",
    "    'embed': 'timeF',\n",
    "    'activation': 'gelu',\n",
    "    'output_attention': False,\n",
    "    'num_workers': 10,\n",
    "    'itr': 1,\n",
    "    'train_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'patience': 3,\n",
    "    'learning_rate': 0.0001,\n",
    "    'des': 'test',\n",
    "    'loss': 'MSE',\n",
    "    'lradj': 'type1',\n",
    "    'use_amp': False,\n",
    "    'use_gpu': True,\n",
    "    'gpu': 0,\n",
    "    'use_multi_gpu': False,\n",
    "    'devices': '0,1,2,3',\n",
    "    'p_hidden_dims': [128, 128],\n",
    "    'p_hidden_layers': 2\n",
    "}\n",
    "\n",
    "# Run the experiment with the configuration\n",
    "run_experiment(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
